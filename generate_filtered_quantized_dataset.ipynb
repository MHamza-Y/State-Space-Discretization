{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "from offline_dataset.dataset_creater import GymParallelSampler\n",
    "\n",
    "from envs.env_creator import ibgym_env_creator, env_creator, IBGymModelQ_creator\n",
    "from state_quantization.transforms import quantize_transform_creator\n",
    "from q_learning.algorithm import QLPolicy\n",
    "from ppo.policy import LSTMPPOPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "episodes = 1000\n",
    "steps_per_episode = 1000\n",
    "workers = 8\n",
    "#env_kwargs = {'steps_per_episode': steps_per_episode, 'device':'cpu'}\n",
    "\n",
    "writer_path = os.path.join(\"tmp\", \"ibqf-out\")\n",
    "policy_save_path = 'tmp/q_learning/mb_q_policy_best_model_aeq-16bits_203871.pkl'\n",
    "policy = QLPolicy.load(policy_save_path)\n",
    "quant_model = 'model_aeq-16bits'\n",
    "model_path = f'tmp/state_quantization/{quant_model}'\n",
    "q_transform_kwargs = {'device': 'cpu', 'keys': ['obs', 'new_obs'], 'reshape': (steps_per_episode, -1, 6),\n",
    "                      'model_path': model_path}\n",
    "use_policy = False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "if os.path.exists(writer_path) and os.path.isdir(writer_path):\n",
    "    shutil.rmtree(writer_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-20 12:12:35,773\tWARNING deprecation.py:46 -- DeprecationWarning: `SampleBatchBuilder` has been deprecated. Use `a child class of `SampleCollector`` instead. This will raise an error in the future!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "start = time.time()\n",
    "if use_policy:\n",
    "\n",
    "    env_kwargs = {'steps_per_episode': steps_per_episode,'model_path':model_path}\n",
    "    parallel_sampler = GymParallelSampler(env_creator=env_creator, path=writer_path, episodes=episodes,\n",
    "                                      workers=workers, env_kwargs=env_kwargs, reward_threshold=None,\n",
    "                                      policy=policy)\n",
    "else:\n",
    "    env_kwargs = {'steps_per_episode': steps_per_episode}\n",
    "    parallel_sampler = GymParallelSampler(env_creator=ibgym_env_creator, path=writer_path, episodes=episodes,\n",
    "                                      workers=workers, env_kwargs=env_kwargs, reward_threshold=None,\n",
    "                                      buffer_transform=quantize_transform_creator,\n",
    "                                      buffer_transform_kwargs=q_transform_kwargs,\n",
    "                                      policy=None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes Sampled: 37\n",
      "Episodes Sampled: 38\n",
      "Episodes Sampled: 40\n",
      "Episodes Sampled: 44\n",
      "Episodes Sampled: 46\n",
      "Episodes Sampled: 47\n",
      "Episodes Sampled: 52\n",
      "Episodes Sampled: 54\n",
      "Episodes Sampled: 57\n",
      "Episodes Sampled: 60\n",
      "Episodes Sampled: 63\n",
      "Episodes Sampled: 66\n",
      "Episodes Sampled: 68\n",
      "Episodes Sampled: 71\n",
      "Episodes Sampled: 75\n",
      "Episodes Sampled: 76\n",
      "Episodes Sampled: 79\n",
      "Episodes Sampled: 83\n",
      "Episodes Sampled: 84\n",
      "Episodes Sampled: 86\n",
      "Episodes Sampled: 91\n",
      "Episodes Sampled: 92\n",
      "Episodes Sampled: 94\n",
      "Episodes Sampled: 99\n",
      "Episodes Sampled: 100\n",
      "Episodes Sampled: 102\n",
      "Episodes Sampled: 107\n",
      "Episodes Sampled: 108\n",
      "Episodes Sampled: 110\n",
      "Episodes Sampled: 115\n",
      "Episodes Sampled: 116\n",
      "Episodes Sampled: 118\n",
      "Episodes Sampled: 123\n",
      "Episodes Sampled: 123\n",
      "Episodes Sampled: 124\n",
      "Episodes Sampled: 129\n",
      "Episodes Sampled: 131\n",
      "Episodes Sampled: 132\n",
      "Episodes Sampled: 137\n",
      "Episodes Sampled: 139\n",
      "Episodes Sampled: 140\n",
      "Episodes Sampled: 145\n",
      "Episodes Sampled: 147\n",
      "Episodes Sampled: 147\n",
      "Episodes Sampled: 153\n",
      "Episodes Sampled: 155\n",
      "Episodes Sampled: 155\n",
      "Episodes Sampled: 161\n",
      "Episodes Sampled: 163\n",
      "Episodes Sampled: 163\n",
      "Episodes Sampled: 167\n",
      "Episodes Sampled: 171\n",
      "Episodes Sampled: 171\n",
      "Episodes Sampled: 175\n",
      "Episodes Sampled: 179\n",
      "Episodes Sampled: 179\n",
      "Episodes Sampled: 183\n",
      "Episodes Sampled: 187\n",
      "Episodes Sampled: 187\n",
      "Episodes Sampled: 189\n",
      "Episodes Sampled: 194\n",
      "Episodes Sampled: 195\n",
      "Episodes Sampled: 197\n",
      "Episodes Sampled: 202\n",
      "Episodes Sampled: 203\n",
      "Episodes Sampled: 205\n",
      "Episodes Sampled: 209\n",
      "Episodes Sampled: 211\n",
      "Episodes Sampled: 213\n",
      "Episodes Sampled: 217\n",
      "Episodes Sampled: 218\n",
      "Episodes Sampled: 221\n",
      "Episodes Sampled: 224\n",
      "Episodes Sampled: 226\n",
      "Episodes Sampled: 228\n",
      "Episodes Sampled: 231\n",
      "Episodes Sampled: 234\n",
      "Episodes Sampled: 236\n",
      "Episodes Sampled: 239\n",
      "Episodes Sampled: 241\n",
      "Episodes Sampled: 243\n",
      "Episodes Sampled: 247\n",
      "Episodes Sampled: 249\n",
      "Episodes Sampled: 251\n",
      "Episodes Sampled: 255\n",
      "Episodes Sampled: 257\n",
      "Episodes Sampled: 259\n",
      "Episodes Sampled: 263\n",
      "Episodes Sampled: 265\n",
      "Episodes Sampled: 267\n",
      "Episodes Sampled: 270\n",
      "Episodes Sampled: 273\n",
      "Episodes Sampled: 275\n",
      "Episodes Sampled: 278\n",
      "Episodes Sampled: 281\n",
      "Episodes Sampled: 283\n",
      "Episodes Sampled: 286\n",
      "Episodes Sampled: 288\n",
      "Episodes Sampled: 290\n",
      "Episodes Sampled: 294\n",
      "Episodes Sampled: 296\n",
      "Episodes Sampled: 298\n",
      "Episodes Sampled: 302\n",
      "Episodes Sampled: 304\n",
      "Episodes Sampled: 306\n",
      "Episodes Sampled: 310\n",
      "Episodes Sampled: 312\n",
      "Episodes Sampled: 314\n",
      "Episodes Sampled: 318\n",
      "Episodes Sampled: 320\n",
      "Episodes Sampled: 321\n",
      "Episodes Sampled: 326\n",
      "Episodes Sampled: 327\n",
      "Episodes Sampled: 329\n",
      "Episodes Sampled: 334\n",
      "Episodes Sampled: 335\n",
      "Episodes Sampled: 337\n",
      "Episodes Sampled: 340\n",
      "Episodes Sampled: 343\n",
      "Episodes Sampled: 345\n",
      "Episodes Sampled: 347\n",
      "Episodes Sampled: 351\n",
      "Episodes Sampled: 353\n",
      "Episodes Sampled: 355\n",
      "Episodes Sampled: 358\n",
      "Episodes Sampled: 360\n",
      "Episodes Sampled: 361\n",
      "Episodes Sampled: 366\n",
      "Episodes Sampled: 368\n",
      "Episodes Sampled: 369\n",
      "Episodes Sampled: 372\n",
      "Episodes Sampled: 375\n",
      "Episodes Sampled: 377\n",
      "Episodes Sampled: 380\n",
      "Episodes Sampled: 383\n",
      "Episodes Sampled: 385\n",
      "Episodes Sampled: 388\n",
      "Episodes Sampled: 391\n",
      "Episodes Sampled: 393\n",
      "Episodes Sampled: 396\n",
      "Episodes Sampled: 399\n",
      "Episodes Sampled: 401\n",
      "Episodes Sampled: 404\n",
      "Episodes Sampled: 406\n",
      "Episodes Sampled: 409\n",
      "Episodes Sampled: 412\n",
      "Episodes Sampled: 413\n",
      "Episodes Sampled: 417\n",
      "Episodes Sampled: 420\n",
      "Episodes Sampled: 421\n",
      "Episodes Sampled: 424\n",
      "Episodes Sampled: 427\n",
      "Episodes Sampled: 429\n",
      "Episodes Sampled: 431\n",
      "Episodes Sampled: 434\n",
      "Episodes Sampled: 437\n",
      "Episodes Sampled: 438\n",
      "Episodes Sampled: 442\n",
      "Episodes Sampled: 445\n",
      "Episodes Sampled: 446\n",
      "Episodes Sampled: 449\n",
      "Episodes Sampled: 453\n",
      "Episodes Sampled: 454\n",
      "Episodes Sampled: 457\n",
      "Episodes Sampled: 460\n",
      "Episodes Sampled: 462\n",
      "Episodes Sampled: 465\n",
      "Episodes Sampled: 468\n",
      "Episodes Sampled: 470\n",
      "Episodes Sampled: 471\n",
      "Episodes Sampled: 476\n",
      "Episodes Sampled: 478\n",
      "Episodes Sampled: 479\n",
      "Episodes Sampled: 483\n",
      "Episodes Sampled: 486\n",
      "Episodes Sampled: 487\n",
      "Episodes Sampled: 490\n",
      "Episodes Sampled: 494\n",
      "Episodes Sampled: 495\n",
      "Episodes Sampled: 498\n",
      "Episodes Sampled: 502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001B[33mWARN: Box bound precision lowered by casting to float32\u001B[0m\n",
      "  logger.warn(\n",
      "Process GymEnvSamplerProcess-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/offline_dataset/dataset_creater.py\", line 61, in run\n",
      "    new_obs, rew, done, info = self.env.step(action)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/envs/IBGym_mod_envs.py\", line 340, in step\n",
      "    discrete_obs = self.lstm_quantize(self.last_observation)[0]\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/state_quantization/transforms.py\", line 70, in __call__\n",
      "    x = self.normalize_transformer.transform(x)\n",
      "KeyboardInterrupt\n",
      "/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001B[33mWARN: Box bound precision lowered by casting to float32\u001B[0m\n",
      "  logger.warn(\n",
      "Process GymEnvSamplerProcess-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/offline_dataset/dataset_creater.py\", line 61, in run\n",
      "    new_obs, rew, done, info = self.env.step(action)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/envs/IBGym_mod_envs.py\", line 340, in step\n",
      "    discrete_obs = self.lstm_quantize(self.last_observation)[0]\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/state_quantization/transforms.py\", line 72, in __call__\n",
      "    self.y = self.model(x)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_quantization_models.py\", line 46, in forward\n",
      "    forcasting_out, _ = self.model(x)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_quantization_models.py\", line 18, in forward\n",
      "    forcasting_out = self.forcasting_model(x)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py\", line 86, in forward\n",
      "    self.lstm_layers_forward(x=x[:, i, :], h=h, c=c)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py\", line 73, in lstm_layers_forward\n",
      "    (h[layer_idx], c[layer_idx]) = self.lstm_layers[layer_idx](layer_input, (h[layer_idx], c[layer_idx]))\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py\", line 1189, in forward\n",
      "    ret = _VF.lstm_cell(\n",
      "KeyboardInterrupt\n",
      "/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001B[33mWARN: Box bound precision lowered by casting to float32\u001B[0m\n",
      "  logger.warn(\n",
      "Process GymEnvSamplerProcess-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/offline_dataset/dataset_creater.py\", line 61, in run\n",
      "    new_obs, rew, done, info = self.env.step(action)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/envs/IBGym_mod_envs.py\", line 340, in step\n",
      "    discrete_obs = self.lstm_quantize(self.last_observation)[0]\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/state_quantization/transforms.py\", line 72, in __call__\n",
      "    self.y = self.model(x)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_quantization_models.py\", line 46, in forward\n",
      "    forcasting_out, _ = self.model(x)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_quantization_models.py\", line 18, in forward\n",
      "    forcasting_out = self.forcasting_model(x)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py\", line 86, in forward\n",
      "    self.lstm_layers_forward(x=x[:, i, :], h=h, c=c)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py\", line 73, in lstm_layers_forward\n",
      "    (h[layer_idx], c[layer_idx]) = self.lstm_layers[layer_idx](layer_input, (h[layer_idx], c[layer_idx]))\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py\", line 1189, in forward\n",
      "    ret = _VF.lstm_cell(\n",
      "KeyboardInterrupt\n",
      "/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001B[33mWARN: Box bound precision lowered by casting to float32\u001B[0m\n",
      "  logger.warn(\n",
      "Process GymEnvSamplerProcess-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/offline_dataset/dataset_creater.py\", line 61, in run\n",
      "    new_obs, rew, done, info = self.env.step(action)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/envs/IBGym_mod_envs.py\", line 340, in step\n",
      "    discrete_obs = self.lstm_quantize(self.last_observation)[0]\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/state_quantization/transforms.py\", line 72, in __call__\n",
      "    self.y = self.model(x)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_quantization_models.py\", line 46, in forward\n",
      "    forcasting_out, _ = self.model(x)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_quantization_models.py\", line 18, in forward\n",
      "    forcasting_out = self.forcasting_model(x)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py\", line 86, in forward\n",
      "    self.lstm_layers_forward(x=x[:, i, :], h=h, c=c)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py\", line 73, in lstm_layers_forward\n",
      "    (h[layer_idx], c[layer_idx]) = self.lstm_layers[layer_idx](layer_input, (h[layer_idx], c[layer_idx]))\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py\", line 1189, in forward\n",
      "    ret = _VF.lstm_cell(\n",
      "KeyboardInterrupt\n",
      "/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001B[33mWARN: Box bound precision lowered by casting to float32\u001B[0m\n",
      "  logger.warn(\n",
      "Process GymEnvSamplerProcess-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/offline_dataset/dataset_creater.py\", line 61, in run\n",
      "    new_obs, rew, done, info = self.env.step(action)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/envs/IBGym_mod_envs.py\", line 340, in step\n",
      "    discrete_obs = self.lstm_quantize(self.last_observation)[0]\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/state_quantization/transforms.py\", line 72, in __call__\n",
      "    self.y = self.model(x)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_quantization_models.py\", line 46, in forward\n",
      "    forcasting_out, _ = self.model(x)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_quantization_models.py\", line 18, in forward\n",
      "    forcasting_out = self.forcasting_model(x)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py\", line 86, in forward\n",
      "    self.lstm_layers_forward(x=x[:, i, :], h=h, c=c)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py\", line 73, in lstm_layers_forward\n",
      "    (h[layer_idx], c[layer_idx]) = self.lstm_layers[layer_idx](layer_input, (h[layer_idx], c[layer_idx]))\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py\", line 1189, in forward\n",
      "    ret = _VF.lstm_cell(\n",
      "KeyboardInterrupt\n",
      "/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001B[33mWARN: Box bound precision lowered by casting to float32\u001B[0m\n",
      "  logger.warn(\n",
      "Process GymEnvSamplerProcess-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/offline_dataset/dataset_creater.py\", line 61, in run\n",
      "    new_obs, rew, done, info = self.env.step(action)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/envs/IBGym_mod_envs.py\", line 340, in step\n",
      "    discrete_obs = self.lstm_quantize(self.last_observation)[0]\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/state_quantization/transforms.py\", line 72, in __call__\n",
      "    self.y = self.model(x)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_quantization_models.py\", line 46, in forward\n",
      "    forcasting_out, _ = self.model(x)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_quantization_models.py\", line 20, in forward\n",
      "    autoencoder_out = self.autoencoder_quant_model(self.autoencoder_in)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/state_quantization/quantization_models.py\", line 199, in forward\n",
      "    dec_out = self.decoder_layers(b_out)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/container.py\", line 139, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py\", line 681, in forward\n",
      "    return F.gelu(input, approximate=self.approximate)\n",
      "KeyboardInterrupt\n",
      "/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001B[33mWARN: Box bound precision lowered by casting to float32\u001B[0m\n",
      "  logger.warn(\n",
      "Process GymEnvSamplerProcess-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/offline_dataset/dataset_creater.py\", line 61, in run\n",
      "    new_obs, rew, done, info = self.env.step(action)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/envs/IBGym_mod_envs.py\", line 341, in step\n",
      "    self.model_out = self.lstm_quantize.get_continuous_output()\n",
      "KeyboardInterrupt\n",
      "/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001B[33mWARN: Box bound precision lowered by casting to float32\u001B[0m\n",
      "  logger.warn(\n",
      "Process GymEnvSamplerProcess-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/offline_dataset/dataset_creater.py\", line 61, in run\n",
      "    new_obs, rew, done, info = self.env.step(action)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/envs/IBGym_mod_envs.py\", line 340, in step\n",
      "    discrete_obs = self.lstm_quantize(self.last_observation)[0]\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/state_quantization/transforms.py\", line 72, in __call__\n",
      "    self.y = self.model(x)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_quantization_models.py\", line 46, in forward\n",
      "    forcasting_out, _ = self.model(x)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_quantization_models.py\", line 18, in forward\n",
      "    forcasting_out = self.forcasting_model(x)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py\", line 86, in forward\n",
      "    self.lstm_layers_forward(x=x[:, i, :], h=h, c=c)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [5]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mparallel_sampler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msample\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m end \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(end \u001B[38;5;241m-\u001B[39m start)\n",
      "File \u001B[0;32m~/PycharmProjects/StateCompression/offline_dataset/dataset_creater.py:122\u001B[0m, in \u001B[0;36mGymParallelSampler.sample\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    120\u001B[0m     p\u001B[38;5;241m.\u001B[39mstart()\n\u001B[1;32m    121\u001B[0m \u001B[38;5;66;03m# self.print_process.start()\u001B[39;00m\n\u001B[0;32m--> 122\u001B[0m \u001B[43mprint_progress\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msampler_processes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mep_count\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/StateCompression/offline_dataset/dataset_creater.py:88\u001B[0m, in \u001B[0;36mprint_progress\u001B[0;34m(processes, ep_count)\u001B[0m\n\u001B[1;32m     86\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mprint_progress\u001B[39m(processes: List[GymEnvSamplerProcess], ep_count):\n\u001B[1;32m     87\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m---> 88\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     89\u001B[0m         any_process_alive \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m     90\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m processes:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "parallel_sampler.sample()\n",
    "end = time.time()\n",
    "print(end - start)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp/offline_rl_trajectories/trajectory_ep1000_model_aeq-16bits.npy\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'obs': array([37597., 49877., 58069., ..., 62109., 62109., 62141.]),\n 'actions': array([ 1,  9, 15, ...,  3,  3, 15]),\n 'rewards': array([-208.12060547, -226.02709961, -248.12010193, ..., -229.80134583,\n        -228.11502075, -229.41885376]),\n 'dones': array([False, False, False, ..., False, False,  True]),\n 'new_obs': array([49877., 58069., 49877., ..., 62109., 62141., 53949.]),\n 'unroll_id': array([ 0,  0,  0, ..., 66, 66, 66])}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path = os.path.join(\"tmp\", \"offline_rl_trajectories\",f\"trajectory_ep{episodes}_{quant_model}.npy\")\n",
    "parallel_sampler.create_merged_dataset(save_path=save_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
