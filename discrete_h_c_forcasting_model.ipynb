{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from state_quantization.dataset import load_dataset\n",
    "from state_quantization.dataset import DynamicsModelDataset\n",
    "from state_quantization.quantization_models import ForcastingDiscHC, ForcastingDiscHCConst\n",
    "from state_quantization.train import train_model, test_step\n",
    "from state_quantization.eval import eval_model, compare_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "print(f\"Using Device: {device}\")\n",
    "torch.backends.cudnn.benchmark = True\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clipping y\n",
      "torch.Size([672000, 39, 6])\n",
      "torch.Size([672000, 10, 2])\n",
      "torch.Size([288000, 39, 6])\n",
      "torch.Size([288000, 10, 2])\n",
      "{'batch_size': 500, 'shuffle': True, 'num_workers': 0, 'drop_last': True, 'pin_memory': True}\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[-0.2227, -0.6698],\n        [-0.3738, -0.6790],\n        [-0.5700, -0.7000],\n        [-0.3641, -0.6819],\n        [-0.5543, -0.6388],\n        [-0.7021, -0.6682],\n        [-0.3377, -0.6477],\n        [-0.6460, -0.5929],\n        [-0.4730, -0.5331],\n        [-0.4207, -0.4667]])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_input_key = 'merged_input'\n",
    "dataset_output_key = 'merged_output'\n",
    "dataset_file_path = 'tmp/ib-out/ib-samples-la.npy'\n",
    "normalized_data_params_save_path = 'state_quantization/NormalizeInputConfigs.pkl'\n",
    "dataset_device = 'cpu'\n",
    "y_indexes = [4, 6]\n",
    "\n",
    "train_dataset, val_dataset = load_dataset(file_path=dataset_file_path, input_key=dataset_input_key,\n",
    "                                          output_key=dataset_output_key, dataset_class=DynamicsModelDataset,\n",
    "                                          normalize=True, device=dataset_device, y_clip_range=y_indexes,\n",
    "                                          normalized_data_params_save_path=normalized_data_params_save_path)\n",
    "\n",
    "batch_size = 500\n",
    "params = {'batch_size': batch_size,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 0,\n",
    "          'drop_last': True,\n",
    "          'pin_memory': not train_dataset.x.is_cuda}\n",
    "print(params)\n",
    "train_loader = DataLoader(train_dataset, **params)\n",
    "val_loader = DataLoader(val_dataset, **params)\n",
    "train_dataset.y[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out Size:2\n",
      "9\n",
      "LSTM Layers\n",
      "ModuleList(\n",
      "  (0): LSTMCell(6, 16)\n",
      ")\n",
      "LSTM Dropout Layers\n",
      "ModuleList()\n",
      "Fully Connected Layers\n",
      "ModuleList(\n",
      "  (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (1): GELU(approximate=none)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=16, out_features=16, bias=True)\n",
      "  (4): GELU(approximate=none)\n",
      "  (5): Dropout(p=0.2, inplace=False)\n",
      "  (6): Linear(in_features=16, out_features=2, bias=True)\n",
      ")\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "model_dict_path = 'state_quantization/model_dict'\n",
    "model_path = 'state_quantization/model'\n",
    "num_of_features = train_dataset.get_features_size()\n",
    "seq_len = train_dataset.get_seq_len()\n",
    "hidden_size = 16\n",
    "out_size = train_dataset.get_output_feature_size()\n",
    "print(f'Out Size:{out_size}')\n",
    "look_ahead = train_dataset.get_look_ahead_size()\n",
    "n_layers = 1\n",
    "dropout_p = 0.2\n",
    "print(look_ahead)\n",
    "model = ForcastingDiscHC(features=num_of_features, hidden_size=hidden_size, out_size=out_size, seq_len=seq_len,\n",
    "                               n_layers=n_layers, dropout=dropout_p,\n",
    "                               look_ahead=look_ahead).to(device=device)\n",
    "\n",
    "load_to_gpu = model.is_cuda() and not train_dataset.x.is_cuda\n",
    "print(load_to_gpu)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained test\n",
      "--------\n",
      "Test loss: 1.0199950858950615\n",
      "\n",
      "Epoch 0\n",
      "---------\n",
      "Train loss: 0.3326351976332565\n",
      "Test loss: 0.20933338226233092\n",
      "lr: [0.001]\n",
      "Epoch time: epoch_time = 34.096s\n",
      "Epoch 1\n",
      "---------\n",
      "Train loss: 0.25464472519455567\n",
      "Test loss: 0.19997173501178622\n",
      "lr: [0.001]\n",
      "Epoch time: epoch_time = 33.299s\n",
      "Epoch 2\n",
      "---------\n",
      "Train loss: 0.25867640677218634\n",
      "Test loss: 0.2048993517075562\n",
      "lr: [0.001]\n",
      "Epoch time: epoch_time = 34.605s\n",
      "Epoch 3\n",
      "---------\n",
      "Train loss: 0.2544462426366018\n",
      "Test loss: 0.1981309620767004\n",
      "lr: [0.0001]\n",
      "Epoch time: epoch_time = 34.368s\n",
      "Epoch 4\n",
      "---------\n",
      "Train loss: 0.2540367470522012\n",
      "Test loss: 0.19503884120947784\n",
      "lr: [0.0001]\n",
      "Epoch time: epoch_time = 34.353s\n",
      "Epoch 5\n",
      "---------\n",
      "Train loss: 0.2543599897596453\n",
      "Test loss: 0.19358572436289656\n",
      "lr: [0.0001]\n",
      "Epoch time: epoch_time = 34.414s\n",
      "Epoch 6\n",
      "---------\n",
      "Train loss: 0.25449310128931846\n",
      "Test loss: 0.1912616823748168\n",
      "lr: [0.0001]\n",
      "Epoch time: epoch_time = 34.837s\n",
      "Epoch 7\n",
      "---------\n",
      "Train loss: 0.25293993542990867\n",
      "Test loss: 0.19286409584391448\n",
      "lr: [0.0001]\n",
      "Epoch time: epoch_time = 34.279s\n",
      "Epoch 8\n",
      "---------\n",
      "Train loss: 0.25216349775326397\n",
      "Test loss: 0.19187247041716343\n",
      "lr: [1e-05]\n",
      "Epoch time: epoch_time = 32.177s\n",
      "Epoch 9\n",
      "---------\n",
      "Train loss: 0.25164547430661816\n",
      "Test loss: 0.19166537964095673\n",
      "lr: [1e-05]\n",
      "Epoch time: epoch_time = 32.212s\n",
      "Epoch 10\n",
      "---------\n",
      "Train loss: 0.2513273728102268\n",
      "Test loss: 0.19129180261451337\n",
      "lr: [1e-05]\n",
      "Epoch time: epoch_time = 33.353s\n",
      "Epoch 11\n",
      "---------\n",
      "Train loss: 0.250511962199761\n",
      "Test loss: 0.19078835568183827\n",
      "lr: [1e-05]\n",
      "Epoch time: epoch_time = 34.706s\n",
      "Epoch 12\n",
      "---------\n",
      "Train loss: 0.25062468327537535\n",
      "Test loss: 0.19051014745814931\n",
      "lr: [1e-05]\n",
      "Epoch time: epoch_time = 34.016s\n",
      "Epoch 13\n",
      "---------\n",
      "Train loss: 0.2507276684711022\n",
      "Test loss: 0.1904487850713647\n",
      "lr: [1e-05]\n",
      "Epoch time: epoch_time = 34.276s\n",
      "Epoch 14\n",
      "---------\n",
      "Train loss: 0.2503454748297199\n",
      "Test loss: 0.19003328300702074\n",
      "lr: [1e-05]\n",
      "Epoch time: epoch_time = 34.907s\n",
      "Epoch 15\n",
      "---------\n",
      "Train loss: 0.24896313285543806\n",
      "Test loss: 0.18995596879782775\n",
      "lr: [1e-05]\n",
      "Epoch time: epoch_time = 33.682s\n",
      "Epoch 16\n",
      "---------\n",
      "Train loss: 0.24863141481321127\n",
      "Test loss: 0.18904576763614184\n",
      "lr: [1e-05]\n",
      "Epoch time: epoch_time = 33.061s\n",
      "Epoch 17\n",
      "---------\n",
      "Train loss: 0.2480331653329943\n",
      "Test loss: 0.1892358416484462\n",
      "lr: [1e-05]\n",
      "Epoch time: epoch_time = 33.663s\n",
      "Epoch 18\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "train_model(model=model, train_loader=train_loader, test_loader=val_loader, n_epochs=25, learning_rate=1e-3,\n",
    "            load_to_gpu=load_to_gpu, gamma=0.1, lr_milestones=[4, 9])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "torch.save(model.state_dict(), model_dict_path)\n",
    "torch.save(model, model_path)\n",
    "torch.cuda.empty_cache()\n",
    "del model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Model for evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "model_classes = [ForcastingDiscHC, ForcastingDiscHCConst]\n",
    "models = []\n",
    "for model_class in model_classes:\n",
    "    models.append(model_class(features=num_of_features, hidden_size=hidden_size, out_size=out_size,\n",
    "                              seq_len=seq_len, n_layers=n_layers, dropout_p=dropout_p,\n",
    "                              look_ahead=look_ahead).to(device))\n",
    "    models[-1].load_state_dict(torch.load(model_dict_path))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for la_model in models:\n",
    "    print(la_model.__class__.__name__)\n",
    "    test_step(model=la_model, data_loader=val_loader, loss_function=torch.nn.MSELoss(), load_to_gpu=load_to_gpu)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#value_keys = ['setpoint', 'velocity', 'gain', 'shift', 'fatigue', 'consumption']\n",
    "value_keys = ['fatigue', 'consumption']\n",
    "\n",
    "models = []\n",
    "for model_class in model_classes:\n",
    "    models.append(model_class(features=num_of_features, hidden_size=hidden_size, out_size=out_size,\n",
    "                              seq_len=seq_len, n_layers=n_layers, dropout_p=dropout_p,\n",
    "                              look_ahead=look_ahead).to(dataset_device))\n",
    "    models[-1].load_state_dict(torch.load(model_dict_path))\n",
    "\n",
    "compare_models(models, x=val_dataset.x[78], y=val_dataset.y[78], value_keys=value_keys)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
