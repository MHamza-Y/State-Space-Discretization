{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ray.tune as tune\n",
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "from ray.tune import register_env\n",
    "from envs.env_creator import env_creator, ibgym_env_creator_rllib\n",
    "from envs.IBGym_mod_envs import IBGymModded\n",
    "from ppo.policy import LSTMPPOPolicy"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Configure Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "register_env(\"IBGym-v1\", ibgym_env_creator_rllib)\n",
    "\n",
    "config = {\n",
    "    # Environment (RLlib understands openAI gym registered strings).\n",
    "    \"env\": \"IBGym-v1\",\n",
    "    # Use 2 environment workers (aka \"rollout workers\") that parallelly\n",
    "    # collect samples from their own environment clone(s).\n",
    "    \"num_workers\": 12,\n",
    "    \"num_gpus\": 1,\n",
    "\n",
    "    # Change this to \"framework: torch\", if you are using PyTorch.\n",
    "    # Also, use \"framework: tf2\" for tf2.x eager execution.\n",
    "    \"framework\": \"tf\",\n",
    "    \"entropy_coeff\": 0.0001,\n",
    "    # \"entropy_coeff_schedule\":PiecewiseSchedule(endpoints=[(0, 0.01), (143000, 0.00001)]),\n",
    "    \"lr\": 3e-5,\n",
    "    \"gamma\": 0.994,\n",
    "    \"clip_param\": 0.2,\n",
    "    \"seed\": 5321,\n",
    "    \"num_sgd_iter\": 2,\n",
    "    \"sgd_minibatch_size\": 1000,\n",
    "\n",
    "    # \"vf_loss_coeff\": 1e-9,\n",
    "    # \"vf_clip_param\": 1e7,\n",
    "    # Tweak the default model provided automatically by RLlib,\n",
    "    # given the environment's observation- and action spaces.\n",
    "    \"model\": {\n",
    "        # == LSTM ==\n",
    "        # Whether to wrap the model with an LSTM.\n",
    "        \"use_lstm\": False,\n",
    "        # Max seq len for training the LSTM, defaults to 20.\n",
    "        #\"max_seq_len\": 30,\n",
    "        # Size of the LSTM cell.\n",
    "        #\"lstm_cell_size\": 64,\n",
    "        # \"use_attention\": True,\n",
    "        # \"attention_num_transformer_units\": 2,\n",
    "        # \"attention_dim\": 128,\n",
    "        # \"vf_share_layers\": True,\n",
    "        # \"fcnet_hiddens\": [32, 32, 32],\n",
    "        # \"sgd_minibatch_size\": 1024,\n",
    "        \"vf_share_layers\": False,\n",
    "        # Whether to feed a_{t-1} to LSTM (one-hot encoded if discrete).\n",
    "        \"lstm_use_prev_action\": False,\n",
    "        # Whether to feed r_{t-1} to LSTM.\n",
    "        \"lstm_use_prev_reward\": False,\n",
    "        # Whether the LSTM is time-major (TxBx..) or batch-major (BxTx..).\n",
    "        \"_time_major\": False,\n",
    "    },\n",
    "    \"train_batch_size\": 32000,\n",
    "    \"timesteps_per_iteration\": 32000,\n",
    "    # \"output\": \"tmp/ib-out\",\n",
    "    # Set up a separate evaluation worker set for the\n",
    "    # `trainer.evaluate()` call after training (see below).\n",
    "    \"evaluation_num_workers\": 3,\n",
    "    # Only for evaluation runs, render the env.\n",
    "    \"evaluation_config\": {\n",
    "        \"render_env\": False,\n",
    "    },\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-15 17:45:23,870\tINFO services.py:1470 -- View the Ray dashboard at \u001B[1m\u001B[32mhttp://127.0.0.1:8265\u001B[39m\u001B[22m\n",
      "\u001B[2m\u001B[36m(PPOTrainer pid=18350)\u001B[0m 2022-10-15 17:45:29,741\tINFO trainer.py:2332 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "\u001B[2m\u001B[36m(PPOTrainer pid=18350)\u001B[0m 2022-10-15 17:45:29,745\tWARNING trainer.py:2540 -- You have specified 3 evaluation workers, but your `evaluation_interval` is None! Therefore, evaluation will not occur automatically with each call to `Trainer.train()`. Instead, you will have to call `Trainer.evaluate()` manually in order to trigger an evaluation run.\n",
      "\u001B[2m\u001B[36m(PPOTrainer pid=18350)\u001B[0m 2022-10-15 17:45:29,745\tWARNING ppo.py:386 -- `train_batch_size` (32000) cannot be achieved with your other settings (num_workers=12 num_envs_per_worker=1 rollout_fragment_length=200)! Auto-adjusting `rollout_fragment_length` to 2666.\n",
      "\u001B[2m\u001B[36m(PPOTrainer pid=18350)\u001B[0m 2022-10-15 17:45:29,745\tINFO ppo.py:414 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001B[2m\u001B[36m(PPOTrainer pid=18350)\u001B[0m 2022-10-15 17:45:29,745\tINFO trainer.py:903 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=18409)\u001B[0m /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001B[33mWARN: Box bound precision lowered by casting to float32\u001B[0m\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=18409)\u001B[0m   logger.warn(\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=18409)\u001B[0m 2022-10-15 17:45:36,522\tWARNING env.py:135 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=18396)\u001B[0m /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001B[33mWARN: Box bound precision lowered by casting to float32\u001B[0m\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=18396)\u001B[0m   logger.warn(\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=18396)\u001B[0m 2022-10-15 17:45:36,849\tWARNING env.py:135 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=18401)\u001B[0m /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001B[33mWARN: Box bound precision lowered by casting to float32\u001B[0m\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=18401)\u001B[0m   logger.warn(\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=18401)\u001B[0m 2022-10-15 17:45:36,884\tWARNING env.py:135 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=18410)\u001B[0m /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001B[33mWARN: Box bound precision lowered by casting to float32\u001B[0m\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=18410)\u001B[0m   logger.warn(\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=18410)\u001B[0m 2022-10-15 17:45:37,062\tWARNING env.py:135 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=18405)\u001B[0m /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001B[33mWARN: Box bound precision lowered by casting to float32\u001B[0m\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=18405)\u001B[0m   logger.warn(\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=18405)\u001B[0m 2022-10-15 17:45:37,020\tWARNING env.py:135 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=18393)\u001B[0m /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001B[33mWARN: Box bound precision lowered by casting to float32\u001B[0m\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=18393)\u001B[0m   logger.warn(\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=18393)\u001B[0m 2022-10-15 17:45:37,113\tWARNING env.py:135 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=18392)\u001B[0m /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001B[33mWARN: Box bound precision lowered by casting to float32\u001B[0m\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=18392)\u001B[0m   logger.warn(\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=18392)\u001B[0m 2022-10-15 17:45:37,178\tWARNING env.py:135 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=18408)\u001B[0m /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001B[33mWARN: Box bound precision lowered by casting to float32\u001B[0m\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=18408)\u001B[0m   logger.warn(\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=18408)\u001B[0m 2022-10-15 17:45:37,125\tWARNING env.py:135 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=18394)\u001B[0m /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001B[33mWARN: Box bound precision lowered by casting to float32\u001B[0m\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=18394)\u001B[0m   logger.warn(\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=18394)\u001B[0m 2022-10-15 17:45:37,248\tWARNING env.py:135 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=18406)\u001B[0m /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001B[33mWARN: Box bound precision lowered by casting to float32\u001B[0m\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=18406)\u001B[0m   logger.warn(\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=18406)\u001B[0m 2022-10-15 17:45:37,349\tWARNING env.py:135 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=18407)\u001B[0m /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001B[33mWARN: Box bound precision lowered by casting to float32\u001B[0m\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=18407)\u001B[0m   logger.warn(\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=18407)\u001B[0m 2022-10-15 17:45:37,410\tWARNING env.py:135 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=18411)\u001B[0m /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001B[33mWARN: Box bound precision lowered by casting to float32\u001B[0m\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=18411)\u001B[0m   logger.warn(\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=18411)\u001B[0m 2022-10-15 17:45:37,436\tWARNING env.py:135 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001B[2m\u001B[36m(PPOTrainer pid=18350)\u001B[0m 2022-10-15 17:45:42,079\tWARNING deprecation.py:46 -- DeprecationWarning: `simple_optimizer` has been deprecated. This will raise an error in the future!\n",
      "\u001B[2m\u001B[36m(PPOTrainer pid=18350)\u001B[0m 2022-10-15 17:45:42,079\tWARNING trainer.py:2540 -- You have specified 3 evaluation workers, but your `evaluation_interval` is None! Therefore, evaluation will not occur automatically with each call to `Trainer.train()`. Instead, you will have to call `Trainer.evaluate()` manually in order to trigger an evaluation run.\n",
      "\u001B[2m\u001B[36m(PPOTrainer pid=18350)\u001B[0m 2022-10-15 17:45:42,079\tWARNING ppo.py:386 -- `train_batch_size` (32000) cannot be achieved with your other settings (num_workers=12 num_envs_per_worker=1 rollout_fragment_length=2666)! Auto-adjusting `rollout_fragment_length` to 2666.\n",
      "\u001B[2m\u001B[36m(PPOTrainer pid=18350)\u001B[0m 2022-10-15 17:45:42,153\tINFO trainable.py:159 -- Trainable.setup took 12.412 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001B[2m\u001B[36m(PPOTrainer pid=18350)\u001B[0m 2022-10-15 17:45:42,153\tWARNING util.py:65 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:45:42 (running for 00:00:16.61)<br>Memory usage on this node: 11.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:45:47 (running for 00:00:21.63)<br>Memory usage on this node: 12.1/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:45:52 (running for 00:00:26.63)<br>Memory usage on this node: 12.1/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 63984\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 63984\n",
      "    num_agent_steps_trained: 63984\n",
      "    num_env_steps_sampled: 63984\n",
      "    num_env_steps_trained: 63984\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-45-54\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -242643.40926283607\n",
      "  episode_reward_mean: -352599.23873893346\n",
      "  episode_reward_min: -694923.1384058335\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 60\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.2951600551605225\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0006728667649440467\n",
      "          model: {}\n",
      "          policy_loss: -0.012838481925427914\n",
      "          total_loss: 9.986967086791992\n",
      "          vf_explained_var: -5.676632941487014e-09\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 63984\n",
      "    num_agent_steps_trained: 63984\n",
      "    num_env_steps_sampled: 63984\n",
      "    num_env_steps_trained: 63984\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 63984\n",
      "  num_agent_steps_trained: 63984\n",
      "  num_env_steps_sampled: 63984\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 63984\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.48421052631579\n",
      "    ram_util_percent: 77.85263157894735\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11956779291737236\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5458823456839624\n",
      "    mean_inference_ms: 1.2191272994951723\n",
      "    mean_raw_obs_processing_ms: 0.16932160312350497\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -242643.40926283607\n",
      "    episode_reward_mean: -352599.23873893346\n",
      "    episode_reward_min: -694923.1384058335\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -361214.9250836224\n",
      "      - -297482.9577690673\n",
      "      - -429252.797297751\n",
      "      - -290979.30222457944\n",
      "      - -275358.9130774087\n",
      "      - -473646.2695195466\n",
      "      - -263173.17150992766\n",
      "      - -275431.9582993242\n",
      "      - -279910.1271616703\n",
      "      - -316591.5226443282\n",
      "      - -334049.16635982064\n",
      "      - -341178.5692509274\n",
      "      - -326031.66129839636\n",
      "      - -341087.53307657625\n",
      "      - -307861.77434255974\n",
      "      - -573086.236083817\n",
      "      - -353797.61888711015\n",
      "      - -463182.431850514\n",
      "      - -280769.1395575516\n",
      "      - -346788.51894608495\n",
      "      - -353265.57653607376\n",
      "      - -346306.0355634894\n",
      "      - -242643.40926283607\n",
      "      - -365292.6778071133\n",
      "      - -281576.56157350633\n",
      "      - -304074.9576382395\n",
      "      - -266790.2540858295\n",
      "      - -355496.62049607973\n",
      "      - -248606.94962909128\n",
      "      - -316586.11470895115\n",
      "      - -530046.0323136444\n",
      "      - -317785.75873435964\n",
      "      - -366160.482723784\n",
      "      - -341588.72314470686\n",
      "      - -315960.96303285693\n",
      "      - -298275.1953284407\n",
      "      - -342399.67398286745\n",
      "      - -315512.13151448517\n",
      "      - -333253.7383419198\n",
      "      - -403552.05809924635\n",
      "      - -267113.61632089055\n",
      "      - -694923.1384058335\n",
      "      - -311966.75307983503\n",
      "      - -298485.56336493674\n",
      "      - -277432.83739347314\n",
      "      - -258271.84689744504\n",
      "      - -445755.09601673717\n",
      "      - -317902.2321793082\n",
      "      - -497393.01102722023\n",
      "      - -309393.2395351692\n",
      "      - -325849.1309214264\n",
      "      - -593595.916294958\n",
      "      - -348757.8165118428\n",
      "      - -321619.54683177266\n",
      "      - -368627.54501561896\n",
      "      - -337862.20100203156\n",
      "      - -270476.94407596235\n",
      "      - -550743.3117832718\n",
      "      - -274225.9830724766\n",
      "      - -509510.08584769606\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11956779291737236\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5458823456839624\n",
      "      mean_inference_ms: 1.2191272994951723\n",
      "      mean_raw_obs_processing_ms: 0.16932160312350497\n",
      "  time_since_restore: 12.625617504119873\n",
      "  time_this_iter_s: 12.625617504119873\n",
      "  time_total_s: 12.625617504119873\n",
      "  timers:\n",
      "    learn_throughput: 51521.315\n",
      "    learn_time_ms: 1241.894\n",
      "    load_throughput: 2872184.971\n",
      "    load_time_ms: 22.277\n",
      "    training_iteration_time_ms: 12620.56\n",
      "    update_time_ms: 4.159\n",
      "  timestamp: 1665848754\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 63984\n",
      "  training_iteration: 1\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:45:59 (running for 00:00:34.33)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.6256</td><td style=\"text-align: right;\">63984</td><td style=\"text-align: right;\"> -352599</td><td style=\"text-align: right;\">             -242643</td><td style=\"text-align: right;\">             -694923</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:46:05 (running for 00:00:39.50)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         12.6256</td><td style=\"text-align: right;\">63984</td><td style=\"text-align: right;\"> -352599</td><td style=\"text-align: right;\">             -242643</td><td style=\"text-align: right;\">             -694923</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 127968\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 127968\n",
      "    num_agent_steps_trained: 127968\n",
      "    num_env_steps_sampled: 127968\n",
      "    num_env_steps_trained: 127968\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-46-07\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -238017.92135176496\n",
      "  episode_reward_mean: -337174.52353516035\n",
      "  episode_reward_min: -694923.1384058335\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 120\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.2939796447753906\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00035324832424521446\n",
      "          model: {}\n",
      "          policy_loss: 0.010788892395794392\n",
      "          total_loss: 10.010529518127441\n",
      "          vf_explained_var: 2.3652637182181024e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 127968\n",
      "    num_agent_steps_trained: 127968\n",
      "    num_env_steps_sampled: 127968\n",
      "    num_env_steps_trained: 127968\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 127968\n",
      "  num_agent_steps_trained: 127968\n",
      "  num_env_steps_sampled: 127968\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 127968\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 96.42777777777776\n",
      "    ram_util_percent: 79.08333333333333\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12212586346895993\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.555084879024285\n",
      "    mean_inference_ms: 1.2670605723012462\n",
      "    mean_raw_obs_processing_ms: 0.169241794796322\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -238017.92135176496\n",
      "    episode_reward_mean: -337174.52353516035\n",
      "    episode_reward_min: -694923.1384058335\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -353265.57653607376\n",
      "      - -346306.0355634894\n",
      "      - -242643.40926283607\n",
      "      - -365292.6778071133\n",
      "      - -281576.56157350633\n",
      "      - -304074.9576382395\n",
      "      - -266790.2540858295\n",
      "      - -355496.62049607973\n",
      "      - -248606.94962909128\n",
      "      - -316586.11470895115\n",
      "      - -530046.0323136444\n",
      "      - -317785.75873435964\n",
      "      - -366160.482723784\n",
      "      - -341588.72314470686\n",
      "      - -315960.96303285693\n",
      "      - -298275.1953284407\n",
      "      - -342399.67398286745\n",
      "      - -315512.13151448517\n",
      "      - -333253.7383419198\n",
      "      - -403552.05809924635\n",
      "      - -267113.61632089055\n",
      "      - -694923.1384058335\n",
      "      - -311966.75307983503\n",
      "      - -298485.56336493674\n",
      "      - -277432.83739347314\n",
      "      - -258271.84689744504\n",
      "      - -445755.09601673717\n",
      "      - -317902.2321793082\n",
      "      - -497393.01102722023\n",
      "      - -309393.2395351692\n",
      "      - -325849.1309214264\n",
      "      - -593595.916294958\n",
      "      - -348757.8165118428\n",
      "      - -321619.54683177266\n",
      "      - -368627.54501561896\n",
      "      - -337862.20100203156\n",
      "      - -270476.94407596235\n",
      "      - -550743.3117832718\n",
      "      - -274225.9830724766\n",
      "      - -509510.08584769606\n",
      "      - -294214.8116880105\n",
      "      - -273888.4947901821\n",
      "      - -302788.87377771945\n",
      "      - -284515.85407743463\n",
      "      - -266577.4643716206\n",
      "      - -316698.33211020415\n",
      "      - -265864.85639782576\n",
      "      - -438299.69259398646\n",
      "      - -344174.64210853167\n",
      "      - -478625.0052823205\n",
      "      - -533486.1118441934\n",
      "      - -259639.37655206758\n",
      "      - -270853.6222214155\n",
      "      - -298142.50463631336\n",
      "      - -322025.04868175625\n",
      "      - -403758.5946260805\n",
      "      - -312242.2477662706\n",
      "      - -289665.98572335276\n",
      "      - -264149.08511230134\n",
      "      - -287178.8873702182\n",
      "      - -483263.5973962136\n",
      "      - -334924.43059646944\n",
      "      - -256046.1461742769\n",
      "      - -301528.0827204222\n",
      "      - -369947.6330806507\n",
      "      - -519695.67530598916\n",
      "      - -404420.6801560454\n",
      "      - -279798.19838474155\n",
      "      - -301947.8643346534\n",
      "      - -291248.42883301433\n",
      "      - -355636.20425850665\n",
      "      - -238017.92135176496\n",
      "      - -360761.2532088274\n",
      "      - -330872.7733715032\n",
      "      - -274903.8288214131\n",
      "      - -327952.3569032587\n",
      "      - -401566.6045403402\n",
      "      - -434520.83658735396\n",
      "      - -296082.58052648586\n",
      "      - -423113.66563043476\n",
      "      - -297562.0127536943\n",
      "      - -297912.6769934844\n",
      "      - -303340.46061886713\n",
      "      - -266595.796035477\n",
      "      - -324648.6728845974\n",
      "      - -277979.8148568234\n",
      "      - -277809.7571340357\n",
      "      - -302947.30825486797\n",
      "      - -303940.9968938916\n",
      "      - -307270.20490617095\n",
      "      - -293134.41691916354\n",
      "      - -262821.4254143861\n",
      "      - -264608.8541648357\n",
      "      - -304269.2068122424\n",
      "      - -348016.20208587655\n",
      "      - -486473.14970803383\n",
      "      - -259344.69539694677\n",
      "      - -302797.12937858043\n",
      "      - -258381.2727394905\n",
      "      - -259480.3155549677\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.12212586346895993\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.555084879024285\n",
      "      mean_inference_ms: 1.2670605723012462\n",
      "      mean_raw_obs_processing_ms: 0.169241794796322\n",
      "  time_since_restore: 25.62942886352539\n",
      "  time_this_iter_s: 13.003811359405518\n",
      "  time_total_s: 25.62942886352539\n",
      "  timers:\n",
      "    learn_throughput: 75328.981\n",
      "    learn_time_ms: 849.394\n",
      "    load_throughput: 4915306.229\n",
      "    load_time_ms: 13.017\n",
      "    training_iteration_time_ms: 12808.983\n",
      "    update_time_ms: 4.046\n",
      "  timestamp: 1665848767\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 127968\n",
      "  training_iteration: 2\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:46:12 (running for 00:00:47.38)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         25.6294</td><td style=\"text-align: right;\">127968</td><td style=\"text-align: right;\"> -337175</td><td style=\"text-align: right;\">             -238018</td><td style=\"text-align: right;\">             -694923</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:46:17 (running for 00:00:52.39)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         25.6294</td><td style=\"text-align: right;\">127968</td><td style=\"text-align: right;\"> -337175</td><td style=\"text-align: right;\">             -238018</td><td style=\"text-align: right;\">             -694923</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 191952\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 191952\n",
      "    num_agent_steps_trained: 191952\n",
      "    num_env_steps_sampled: 191952\n",
      "    num_env_steps_trained: 191952\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-46-20\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -225340.0318600059\n",
      "  episode_reward_mean: -304559.09038833174\n",
      "  episode_reward_min: -533422.1447766542\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 180\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.2924649715423584\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0003521831822581589\n",
      "          model: {}\n",
      "          policy_loss: 0.0038035293109714985\n",
      "          total_loss: 10.003544807434082\n",
      "          vf_explained_var: 5.676632941487014e-09\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 191952\n",
      "    num_agent_steps_trained: 191952\n",
      "    num_env_steps_sampled: 191952\n",
      "    num_env_steps_trained: 191952\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 191952\n",
      "  num_agent_steps_trained: 191952\n",
      "  num_env_steps_sampled: 191952\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 191952\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 94.50555555555555\n",
      "    ram_util_percent: 79.49444444444445\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12874435725448874\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5626389810805921\n",
      "    mean_inference_ms: 1.301875562805987\n",
      "    mean_raw_obs_processing_ms: 0.1694733649900126\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -225340.0318600059\n",
      "    episode_reward_mean: -304559.09038833174\n",
      "    episode_reward_min: -533422.1447766542\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -483263.5973962136\n",
      "      - -334924.43059646944\n",
      "      - -256046.1461742769\n",
      "      - -301528.0827204222\n",
      "      - -369947.6330806507\n",
      "      - -519695.67530598916\n",
      "      - -404420.6801560454\n",
      "      - -279798.19838474155\n",
      "      - -301947.8643346534\n",
      "      - -291248.42883301433\n",
      "      - -355636.20425850665\n",
      "      - -238017.92135176496\n",
      "      - -360761.2532088274\n",
      "      - -330872.7733715032\n",
      "      - -274903.8288214131\n",
      "      - -327952.3569032587\n",
      "      - -401566.6045403402\n",
      "      - -434520.83658735396\n",
      "      - -296082.58052648586\n",
      "      - -423113.66563043476\n",
      "      - -297562.0127536943\n",
      "      - -297912.6769934844\n",
      "      - -303340.46061886713\n",
      "      - -266595.796035477\n",
      "      - -324648.6728845974\n",
      "      - -277979.8148568234\n",
      "      - -277809.7571340357\n",
      "      - -302947.30825486797\n",
      "      - -303940.9968938916\n",
      "      - -307270.20490617095\n",
      "      - -293134.41691916354\n",
      "      - -262821.4254143861\n",
      "      - -264608.8541648357\n",
      "      - -304269.2068122424\n",
      "      - -348016.20208587655\n",
      "      - -486473.14970803383\n",
      "      - -259344.69539694677\n",
      "      - -302797.12937858043\n",
      "      - -258381.2727394905\n",
      "      - -259480.3155549677\n",
      "      - -291253.67138565367\n",
      "      - -285049.67439553194\n",
      "      - -288457.25826639123\n",
      "      - -266788.0007196321\n",
      "      - -262307.4658949915\n",
      "      - -289516.3210269389\n",
      "      - -286261.86496922147\n",
      "      - -273302.68797148473\n",
      "      - -335602.8228604197\n",
      "      - -277925.2172443944\n",
      "      - -255671.03674375988\n",
      "      - -310570.20558150497\n",
      "      - -317252.79340947693\n",
      "      - -238186.49795720264\n",
      "      - -265314.7327547383\n",
      "      - -356691.72545805573\n",
      "      - -257556.04792098707\n",
      "      - -313745.29200973647\n",
      "      - -290037.5736958382\n",
      "      - -302322.34242387954\n",
      "      - -307924.794973525\n",
      "      - -249265.55112916345\n",
      "      - -253917.52486630395\n",
      "      - -293711.7148896936\n",
      "      - -225340.0318600059\n",
      "      - -416364.16120177973\n",
      "      - -243783.558540644\n",
      "      - -256983.57945581555\n",
      "      - -282875.0484581546\n",
      "      - -254669.28574755832\n",
      "      - -270087.10232089425\n",
      "      - -286434.75939796085\n",
      "      - -269920.7994640877\n",
      "      - -259920.5384761629\n",
      "      - -236303.69979750548\n",
      "      - -241369.63659897252\n",
      "      - -264070.85080297047\n",
      "      - -268405.3311321854\n",
      "      - -249546.59554471434\n",
      "      - -314091.94804421614\n",
      "      - -421195.6405103793\n",
      "      - -264886.4304520147\n",
      "      - -303657.14879594534\n",
      "      - -266764.8532014114\n",
      "      - -306255.7061223183\n",
      "      - -256207.67765419223\n",
      "      - -273064.555873305\n",
      "      - -315197.0192170961\n",
      "      - -265857.7793884818\n",
      "      - -273990.51195284334\n",
      "      - -365205.9701935565\n",
      "      - -331543.40489983564\n",
      "      - -288891.0582606575\n",
      "      - -302273.9335352619\n",
      "      - -282430.1714595736\n",
      "      - -312398.74910848023\n",
      "      - -291508.0638889437\n",
      "      - -318910.81205883675\n",
      "      - -533422.1447766542\n",
      "      - -287864.5304024245\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.12874435725448874\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5626389810805921\n",
      "      mean_inference_ms: 1.301875562805987\n",
      "      mean_raw_obs_processing_ms: 0.1694733649900126\n",
      "  time_since_restore: 38.26528787612915\n",
      "  time_this_iter_s: 12.63585901260376\n",
      "  time_total_s: 38.26528787612915\n",
      "  timers:\n",
      "    learn_throughput: 91828.275\n",
      "    learn_time_ms: 696.779\n",
      "    load_throughput: 6598464.45\n",
      "    load_time_ms: 9.697\n",
      "    training_iteration_time_ms: 12748.785\n",
      "    update_time_ms: 3.668\n",
      "  timestamp: 1665848780\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 191952\n",
      "  training_iteration: 3\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:46:25 (running for 00:01:00.01)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         38.2653</td><td style=\"text-align: right;\">191952</td><td style=\"text-align: right;\"> -304559</td><td style=\"text-align: right;\">             -225340</td><td style=\"text-align: right;\">             -533422</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:46:30 (running for 00:01:05.02)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         38.2653</td><td style=\"text-align: right;\">191952</td><td style=\"text-align: right;\"> -304559</td><td style=\"text-align: right;\">             -225340</td><td style=\"text-align: right;\">             -533422</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 255936\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 255936\n",
      "    num_agent_steps_trained: 255936\n",
      "    num_env_steps_sampled: 255936\n",
      "    num_env_steps_trained: 255936\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-46-31\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -224770.42964126475\n",
      "  episode_reward_mean: -281661.99980539805\n",
      "  episode_reward_min: -533422.1447766542\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 252\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.2896173000335693\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00042265572119504213\n",
      "          model: {}\n",
      "          policy_loss: 0.006621160544455051\n",
      "          total_loss: 10.006376266479492\n",
      "          vf_explained_var: -9.461055050508094e-09\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 255936\n",
      "    num_agent_steps_trained: 255936\n",
      "    num_env_steps_sampled: 255936\n",
      "    num_env_steps_trained: 255936\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 255936\n",
      "  num_agent_steps_trained: 255936\n",
      "  num_env_steps_sampled: 255936\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 255936\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 92.525\n",
      "    ram_util_percent: 79.6625\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12774621517891344\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.556542332398416\n",
      "    mean_inference_ms: 1.2775384468520026\n",
      "    mean_raw_obs_processing_ms: 0.1671844500001393\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -224770.42964126475\n",
      "    episode_reward_mean: -281661.99980539805\n",
      "    episode_reward_min: -533422.1447766542\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -269920.7994640877\n",
      "      - -259920.5384761629\n",
      "      - -236303.69979750548\n",
      "      - -241369.63659897252\n",
      "      - -264070.85080297047\n",
      "      - -268405.3311321854\n",
      "      - -249546.59554471434\n",
      "      - -314091.94804421614\n",
      "      - -421195.6405103793\n",
      "      - -264886.4304520147\n",
      "      - -303657.14879594534\n",
      "      - -266764.8532014114\n",
      "      - -306255.7061223183\n",
      "      - -256207.67765419223\n",
      "      - -273064.555873305\n",
      "      - -315197.0192170961\n",
      "      - -265857.7793884818\n",
      "      - -273990.51195284334\n",
      "      - -365205.9701935565\n",
      "      - -331543.40489983564\n",
      "      - -288891.0582606575\n",
      "      - -302273.9335352619\n",
      "      - -282430.1714595736\n",
      "      - -312398.74910848023\n",
      "      - -291508.0638889437\n",
      "      - -318910.81205883675\n",
      "      - -533422.1447766542\n",
      "      - -287864.5304024245\n",
      "      - -256326.60968348937\n",
      "      - -258348.29079181186\n",
      "      - -267554.1690228821\n",
      "      - -255368.40347834205\n",
      "      - -295383.847872803\n",
      "      - -258856.116187892\n",
      "      - -245409.28388721994\n",
      "      - -269447.7931568926\n",
      "      - -276683.84453602735\n",
      "      - -281431.88905866933\n",
      "      - -296031.75964941253\n",
      "      - -365324.14976982604\n",
      "      - -269122.2055446852\n",
      "      - -298405.0516321815\n",
      "      - -268306.3670149248\n",
      "      - -282980.70612919057\n",
      "      - -350804.3676209804\n",
      "      - -286787.6651118477\n",
      "      - -309300.5745856583\n",
      "      - -269312.01512516337\n",
      "      - -279541.98419420887\n",
      "      - -275101.42841834\n",
      "      - -272707.98116087413\n",
      "      - -277956.01526937593\n",
      "      - -272360.8049347388\n",
      "      - -255139.06731150296\n",
      "      - -261426.53106006724\n",
      "      - -240420.19916828888\n",
      "      - -224770.42964126475\n",
      "      - -240355.5536069898\n",
      "      - -268523.72898737545\n",
      "      - -235076.53034278803\n",
      "      - -246179.7511278227\n",
      "      - -321908.9986205731\n",
      "      - -251316.7057129506\n",
      "      - -294529.39230389014\n",
      "      - -369712.70138051274\n",
      "      - -257699.09195989234\n",
      "      - -282569.1416958347\n",
      "      - -279002.9404369322\n",
      "      - -270684.55708808923\n",
      "      - -321628.6978033457\n",
      "      - -276939.39996166335\n",
      "      - -263109.0611646426\n",
      "      - -255690.89160455726\n",
      "      - -273363.4678946272\n",
      "      - -235305.61821601173\n",
      "      - -271167.7740556549\n",
      "      - -297915.4124346023\n",
      "      - -300065.1616119994\n",
      "      - -373663.0336891504\n",
      "      - -253180.76222959557\n",
      "      - -240115.24385191634\n",
      "      - -272766.72247480333\n",
      "      - -364743.4657611307\n",
      "      - -272523.9692313151\n",
      "      - -242368.78207923687\n",
      "      - -239846.8509693867\n",
      "      - -268736.6621247596\n",
      "      - -274278.76759825315\n",
      "      - -316680.30785932747\n",
      "      - -297186.0051501125\n",
      "      - -263097.7842058732\n",
      "      - -248785.75634944535\n",
      "      - -241588.57990182485\n",
      "      - -255842.92607442546\n",
      "      - -246851.51415010498\n",
      "      - -245982.33397105086\n",
      "      - -291239.3837217129\n",
      "      - -264732.59571275325\n",
      "      - -251805.97555568794\n",
      "      - -241672.86723558902\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.12774621517891344\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.556542332398416\n",
      "      mean_inference_ms: 1.2775384468520026\n",
      "      mean_raw_obs_processing_ms: 0.1671844500001393\n",
      "  time_since_restore: 49.486348390579224\n",
      "  time_this_iter_s: 11.221060514450073\n",
      "  time_total_s: 49.486348390579224\n",
      "  timers:\n",
      "    learn_throughput: 105028.612\n",
      "    learn_time_ms: 609.205\n",
      "    load_throughput: 8008425.569\n",
      "    load_time_ms: 7.99\n",
      "    training_iteration_time_ms: 12365.242\n",
      "    update_time_ms: 3.553\n",
      "  timestamp: 1665848791\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 255936\n",
      "  training_iteration: 4\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:46:36 (running for 00:01:11.27)<br>Memory usage on this node: 12.4/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         49.4863</td><td style=\"text-align: right;\">255936</td><td style=\"text-align: right;\"> -281662</td><td style=\"text-align: right;\">             -224770</td><td style=\"text-align: right;\">             -533422</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:46:41 (running for 00:01:16.27)<br>Memory usage on this node: 12.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         49.4863</td><td style=\"text-align: right;\">255936</td><td style=\"text-align: right;\"> -281662</td><td style=\"text-align: right;\">             -224770</td><td style=\"text-align: right;\">             -533422</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 319920\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 319920\n",
      "    num_agent_steps_trained: 319920\n",
      "    num_env_steps_sampled: 319920\n",
      "    num_env_steps_trained: 319920\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-46-42\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -223052.06472131092\n",
      "  episode_reward_mean: -271877.82551125047\n",
      "  episode_reward_min: -373663.0336891504\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 312\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.2863757610321045\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0005363111267797649\n",
      "          model: {}\n",
      "          policy_loss: 0.0034235448110848665\n",
      "          total_loss: 10.003201484680176\n",
      "          vf_explained_var: -1.8922110101016187e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 319920\n",
      "    num_agent_steps_trained: 319920\n",
      "    num_env_steps_sampled: 319920\n",
      "    num_env_steps_trained: 319920\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 319920\n",
      "  num_agent_steps_trained: 319920\n",
      "  num_env_steps_sampled: 319920\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 319920\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.75714285714287\n",
      "    ram_util_percent: 80.18571428571428\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12496957090996468\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5481516097504894\n",
      "    mean_inference_ms: 1.2433993552569602\n",
      "    mean_raw_obs_processing_ms: 0.16512908884890734\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -223052.06472131092\n",
      "    episode_reward_mean: -271877.82551125047\n",
      "    episode_reward_min: -373663.0336891504\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -246179.7511278227\n",
      "      - -321908.9986205731\n",
      "      - -251316.7057129506\n",
      "      - -294529.39230389014\n",
      "      - -369712.70138051274\n",
      "      - -257699.09195989234\n",
      "      - -282569.1416958347\n",
      "      - -279002.9404369322\n",
      "      - -270684.55708808923\n",
      "      - -321628.6978033457\n",
      "      - -276939.39996166335\n",
      "      - -263109.0611646426\n",
      "      - -255690.89160455726\n",
      "      - -273363.4678946272\n",
      "      - -235305.61821601173\n",
      "      - -271167.7740556549\n",
      "      - -297915.4124346023\n",
      "      - -300065.1616119994\n",
      "      - -373663.0336891504\n",
      "      - -253180.76222959557\n",
      "      - -240115.24385191634\n",
      "      - -272766.72247480333\n",
      "      - -364743.4657611307\n",
      "      - -272523.9692313151\n",
      "      - -242368.78207923687\n",
      "      - -239846.8509693867\n",
      "      - -268736.6621247596\n",
      "      - -274278.76759825315\n",
      "      - -316680.30785932747\n",
      "      - -297186.0051501125\n",
      "      - -263097.7842058732\n",
      "      - -248785.75634944535\n",
      "      - -241588.57990182485\n",
      "      - -255842.92607442546\n",
      "      - -246851.51415010498\n",
      "      - -245982.33397105086\n",
      "      - -291239.3837217129\n",
      "      - -264732.59571275325\n",
      "      - -251805.97555568794\n",
      "      - -241672.86723558902\n",
      "      - -250923.05103873526\n",
      "      - -238599.01857399693\n",
      "      - -242393.73676141285\n",
      "      - -267819.66902748577\n",
      "      - -243692.8883035575\n",
      "      - -300073.94439940265\n",
      "      - -223052.06472131092\n",
      "      - -249837.09960450337\n",
      "      - -290592.18263746\n",
      "      - -250262.68319600177\n",
      "      - -265915.9346209999\n",
      "      - -237008.96154319224\n",
      "      - -292095.29579759756\n",
      "      - -313868.36815775046\n",
      "      - -269650.6656931288\n",
      "      - -308188.72951599635\n",
      "      - -236923.71275296583\n",
      "      - -253993.16301446577\n",
      "      - -258900.6456432778\n",
      "      - -257953.8850211035\n",
      "      - -249113.9290916202\n",
      "      - -273483.01904397534\n",
      "      - -264878.74814730353\n",
      "      - -263846.2567149273\n",
      "      - -266038.7451919076\n",
      "      - -268876.4760630916\n",
      "      - -245212.97818313804\n",
      "      - -230814.21853052644\n",
      "      - -268914.87064151326\n",
      "      - -232732.44519648695\n",
      "      - -284760.258453035\n",
      "      - -278304.2497727017\n",
      "      - -238886.82701722358\n",
      "      - -258408.3920853899\n",
      "      - -254127.0249931392\n",
      "      - -290802.21822610596\n",
      "      - -267008.9105807382\n",
      "      - -270796.4812963445\n",
      "      - -249712.1683033649\n",
      "      - -279067.0932697349\n",
      "      - -268301.4111230627\n",
      "      - -225190.536959943\n",
      "      - -301917.68404658325\n",
      "      - -265207.3376197655\n",
      "      - -331669.2795225674\n",
      "      - -269289.31639227475\n",
      "      - -256344.56724930528\n",
      "      - -350814.12954017025\n",
      "      - -335094.8152952256\n",
      "      - -251748.57003756065\n",
      "      - -252466.22750886384\n",
      "      - -245048.30424594766\n",
      "      - -361979.8864910163\n",
      "      - -334893.7577559848\n",
      "      - -260616.18494990785\n",
      "      - -301265.91600894794\n",
      "      - -249413.47634808352\n",
      "      - -267735.2446542856\n",
      "      - -248062.44822224518\n",
      "      - -286713.3913556343\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.12496957090996468\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5481516097504894\n",
      "      mean_inference_ms: 1.2433993552569602\n",
      "      mean_raw_obs_processing_ms: 0.16512908884890734\n",
      "  time_since_restore: 59.79118609428406\n",
      "  time_this_iter_s: 10.304837703704834\n",
      "  time_total_s: 59.79118609428406\n",
      "  timers:\n",
      "    learn_throughput: 114984.696\n",
      "    learn_time_ms: 556.457\n",
      "    load_throughput: 9216262.479\n",
      "    load_time_ms: 6.943\n",
      "    training_iteration_time_ms: 11952.106\n",
      "    update_time_ms: 3.533\n",
      "  timestamp: 1665848802\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 319920\n",
      "  training_iteration: 5\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:46:47 (running for 00:01:21.65)<br>Memory usage on this node: 12.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         59.7912</td><td style=\"text-align: right;\">319920</td><td style=\"text-align: right;\"> -271878</td><td style=\"text-align: right;\">             -223052</td><td style=\"text-align: right;\">             -373663</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:46:52 (running for 00:01:26.65)<br>Memory usage on this node: 12.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         59.7912</td><td style=\"text-align: right;\">319920</td><td style=\"text-align: right;\"> -271878</td><td style=\"text-align: right;\">             -223052</td><td style=\"text-align: right;\">             -373663</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 383904\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 383904\n",
      "    num_agent_steps_trained: 383904\n",
      "    num_env_steps_sampled: 383904\n",
      "    num_env_steps_trained: 383904\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-46-52\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -212165.89986829588\n",
      "  episode_reward_mean: -262872.05475594173\n",
      "  episode_reward_min: -361979.8864910163\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 372\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.282223701477051\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0005764019442722201\n",
      "          model: {}\n",
      "          policy_loss: -0.013572406955063343\n",
      "          total_loss: 9.986214637756348\n",
      "          vf_explained_var: 1.0407160466741061e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 383904\n",
      "    num_agent_steps_trained: 383904\n",
      "    num_env_steps_sampled: 383904\n",
      "    num_env_steps_trained: 383904\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 383904\n",
      "  num_agent_steps_trained: 383904\n",
      "  num_env_steps_sampled: 383904\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 383904\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 87.95\n",
      "    ram_util_percent: 80.65\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1216678951184168\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5412953914721929\n",
      "    mean_inference_ms: 1.2100490476120154\n",
      "    mean_raw_obs_processing_ms: 0.16270474356671966\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -212165.89986829588\n",
      "    episode_reward_mean: -262872.05475594173\n",
      "    episode_reward_min: -361979.8864910163\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -249113.9290916202\n",
      "      - -273483.01904397534\n",
      "      - -264878.74814730353\n",
      "      - -263846.2567149273\n",
      "      - -266038.7451919076\n",
      "      - -268876.4760630916\n",
      "      - -245212.97818313804\n",
      "      - -230814.21853052644\n",
      "      - -268914.87064151326\n",
      "      - -232732.44519648695\n",
      "      - -284760.258453035\n",
      "      - -278304.2497727017\n",
      "      - -238886.82701722358\n",
      "      - -258408.3920853899\n",
      "      - -254127.0249931392\n",
      "      - -290802.21822610596\n",
      "      - -267008.9105807382\n",
      "      - -270796.4812963445\n",
      "      - -249712.1683033649\n",
      "      - -279067.0932697349\n",
      "      - -268301.4111230627\n",
      "      - -225190.536959943\n",
      "      - -301917.68404658325\n",
      "      - -265207.3376197655\n",
      "      - -331669.2795225674\n",
      "      - -269289.31639227475\n",
      "      - -256344.56724930528\n",
      "      - -350814.12954017025\n",
      "      - -335094.8152952256\n",
      "      - -251748.57003756065\n",
      "      - -252466.22750886384\n",
      "      - -245048.30424594766\n",
      "      - -361979.8864910163\n",
      "      - -334893.7577559848\n",
      "      - -260616.18494990785\n",
      "      - -301265.91600894794\n",
      "      - -249413.47634808352\n",
      "      - -267735.2446542856\n",
      "      - -248062.44822224518\n",
      "      - -286713.3913556343\n",
      "      - -259885.55848547295\n",
      "      - -233487.87731959837\n",
      "      - -264696.9199919688\n",
      "      - -260371.50863713457\n",
      "      - -266797.00860901526\n",
      "      - -241762.6356723281\n",
      "      - -236232.24440486604\n",
      "      - -252893.48706937896\n",
      "      - -265778.5168083377\n",
      "      - -274520.5175683708\n",
      "      - -232614.13107755303\n",
      "      - -244547.7224344928\n",
      "      - -266664.7684951786\n",
      "      - -249659.98001134035\n",
      "      - -252028.3479489112\n",
      "      - -322484.0165754011\n",
      "      - -240828.98974998872\n",
      "      - -224806.50868562158\n",
      "      - -277208.8285471909\n",
      "      - -239181.62460225096\n",
      "      - -293240.7965275097\n",
      "      - -247721.591042527\n",
      "      - -235278.8018542363\n",
      "      - -303906.71959712065\n",
      "      - -274105.94063281885\n",
      "      - -223329.49176691924\n",
      "      - -255923.20481878685\n",
      "      - -212165.89986829588\n",
      "      - -278668.25009767665\n",
      "      - -299734.8506631018\n",
      "      - -246146.21626491033\n",
      "      - -226187.2587366645\n",
      "      - -237502.7222285874\n",
      "      - -276299.50907530903\n",
      "      - -237054.4909867765\n",
      "      - -234569.20473635313\n",
      "      - -235048.2802312632\n",
      "      - -244158.99143769586\n",
      "      - -263530.1480110491\n",
      "      - -300772.54063932656\n",
      "      - -258185.15666325434\n",
      "      - -234079.50128971756\n",
      "      - -233462.6146138093\n",
      "      - -246613.1058582783\n",
      "      - -278277.50906393956\n",
      "      - -242723.93891490976\n",
      "      - -260054.89632275782\n",
      "      - -257087.67173237255\n",
      "      - -248133.60762505836\n",
      "      - -237528.30796449762\n",
      "      - -263360.3002973397\n",
      "      - -245495.24283488284\n",
      "      - -277278.58602629584\n",
      "      - -235351.30399686002\n",
      "      - -252804.71781966585\n",
      "      - -284509.30741507956\n",
      "      - -284629.9288795689\n",
      "      - -281443.37885967083\n",
      "      - -288035.6750448252\n",
      "      - -246796.82633041457\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1216678951184168\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5412953914721929\n",
      "      mean_inference_ms: 1.2100490476120154\n",
      "      mean_raw_obs_processing_ms: 0.16270474356671966\n",
      "  time_since_restore: 70.05036973953247\n",
      "  time_this_iter_s: 10.259183645248413\n",
      "  time_total_s: 70.05036973953247\n",
      "  timers:\n",
      "    learn_throughput: 121802.549\n",
      "    learn_time_ms: 525.309\n",
      "    load_throughput: 10222063.336\n",
      "    load_time_ms: 6.259\n",
      "    training_iteration_time_ms: 11669.109\n",
      "    update_time_ms: 3.533\n",
      "  timestamp: 1665848812\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 383904\n",
      "  training_iteration: 6\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:46:57 (running for 00:01:31.94)<br>Memory usage on this node: 12.6/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         70.0504</td><td style=\"text-align: right;\">383904</td><td style=\"text-align: right;\"> -262872</td><td style=\"text-align: right;\">             -212166</td><td style=\"text-align: right;\">             -361980</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 447888\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 447888\n",
      "    num_agent_steps_trained: 447888\n",
      "    num_env_steps_sampled: 447888\n",
      "    num_env_steps_trained: 447888\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-47-03\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -213272.52262748167\n",
      "  episode_reward_mean: -253590.271526377\n",
      "  episode_reward_min: -331986.68769621063\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 444\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.278351068496704\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0003412879887036979\n",
      "          model: {}\n",
      "          policy_loss: 0.004581911489367485\n",
      "          total_loss: 10.004321098327637\n",
      "          vf_explained_var: -1.6083793852317285e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 447888\n",
      "    num_agent_steps_trained: 447888\n",
      "    num_env_steps_sampled: 447888\n",
      "    num_env_steps_trained: 447888\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 447888\n",
      "  num_agent_steps_trained: 447888\n",
      "  num_env_steps_sampled: 447888\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 447888\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 88.52666666666666\n",
      "    ram_util_percent: 81.19333333333333\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11803456186071144\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5334362720982507\n",
      "    mean_inference_ms: 1.1926173190757752\n",
      "    mean_raw_obs_processing_ms: 0.15967792078955043\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -213272.52262748167\n",
      "    episode_reward_mean: -253590.271526377\n",
      "    episode_reward_min: -331986.68769621063\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -237502.7222285874\n",
      "      - -276299.50907530903\n",
      "      - -237054.4909867765\n",
      "      - -234569.20473635313\n",
      "      - -235048.2802312632\n",
      "      - -244158.99143769586\n",
      "      - -263530.1480110491\n",
      "      - -300772.54063932656\n",
      "      - -258185.15666325434\n",
      "      - -234079.50128971756\n",
      "      - -233462.6146138093\n",
      "      - -246613.1058582783\n",
      "      - -278277.50906393956\n",
      "      - -242723.93891490976\n",
      "      - -260054.89632275782\n",
      "      - -257087.67173237255\n",
      "      - -248133.60762505836\n",
      "      - -237528.30796449762\n",
      "      - -263360.3002973397\n",
      "      - -245495.24283488284\n",
      "      - -277278.58602629584\n",
      "      - -235351.30399686002\n",
      "      - -252804.71781966585\n",
      "      - -284509.30741507956\n",
      "      - -284629.9288795689\n",
      "      - -281443.37885967083\n",
      "      - -288035.6750448252\n",
      "      - -246796.82633041457\n",
      "      - -276709.63567663525\n",
      "      - -232194.0754805128\n",
      "      - -260028.7725003812\n",
      "      - -236578.20028167972\n",
      "      - -238922.08046531034\n",
      "      - -252559.7002936896\n",
      "      - -213272.52262748167\n",
      "      - -227688.89258860564\n",
      "      - -254691.24002056208\n",
      "      - -238252.1319465714\n",
      "      - -273475.003385312\n",
      "      - -254498.44292688588\n",
      "      - -222599.9517856761\n",
      "      - -263637.41063261713\n",
      "      - -289799.28852872\n",
      "      - -230359.17773420675\n",
      "      - -284092.2394892498\n",
      "      - -249202.29888211077\n",
      "      - -246177.5255680469\n",
      "      - -252903.8098443157\n",
      "      - -280548.20865749737\n",
      "      - -236902.50926691166\n",
      "      - -331986.68769621063\n",
      "      - -237324.53338096055\n",
      "      - -242069.97047537722\n",
      "      - -240211.9017493011\n",
      "      - -280633.6768549587\n",
      "      - -234584.66464438982\n",
      "      - -227264.7642275502\n",
      "      - -252214.23904217413\n",
      "      - -265562.13474838436\n",
      "      - -272024.9156423479\n",
      "      - -222993.34378350727\n",
      "      - -249145.22310986518\n",
      "      - -232209.1028524337\n",
      "      - -278434.6926434466\n",
      "      - -239260.05324199918\n",
      "      - -250112.02831598656\n",
      "      - -258422.64095762922\n",
      "      - -269728.315397171\n",
      "      - -276041.64321239886\n",
      "      - -237253.7768943042\n",
      "      - -236859.00390702146\n",
      "      - -245608.1405391795\n",
      "      - -236164.86497243104\n",
      "      - -225836.77379381532\n",
      "      - -245222.89194718635\n",
      "      - -232845.80636805462\n",
      "      - -268668.37105341296\n",
      "      - -272831.9551250679\n",
      "      - -296154.0274249437\n",
      "      - -229152.9383520238\n",
      "      - -249243.28776737928\n",
      "      - -239388.51278554817\n",
      "      - -256792.57165233686\n",
      "      - -283746.0158054048\n",
      "      - -225605.21329944357\n",
      "      - -231042.5286887918\n",
      "      - -254684.92042336185\n",
      "      - -238425.33721380268\n",
      "      - -255827.93541884195\n",
      "      - -224783.23948024184\n",
      "      - -227838.07647788821\n",
      "      - -227815.8356585535\n",
      "      - -313970.2608194886\n",
      "      - -227286.91669854926\n",
      "      - -312935.8995461748\n",
      "      - -244976.59930904114\n",
      "      - -280910.34642243653\n",
      "      - -287198.47924037464\n",
      "      - -232358.74190705392\n",
      "      - -257492.76818691456\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11803456186071144\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5334362720982507\n",
      "      mean_inference_ms: 1.1926173190757752\n",
      "      mean_raw_obs_processing_ms: 0.15967792078955043\n",
      "  time_since_restore: 80.65475010871887\n",
      "  time_this_iter_s: 10.604380369186401\n",
      "  time_total_s: 80.65475010871887\n",
      "  timers:\n",
      "    learn_throughput: 128254.965\n",
      "    learn_time_ms: 498.881\n",
      "    load_throughput: 11066475.193\n",
      "    load_time_ms: 5.782\n",
      "    training_iteration_time_ms: 11515.986\n",
      "    update_time_ms: 3.455\n",
      "  timestamp: 1665848823\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 447888\n",
      "  training_iteration: 7\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:47:03 (running for 00:01:37.53)<br>Memory usage on this node: 12.6/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         80.6548</td><td style=\"text-align: right;\">447888</td><td style=\"text-align: right;\"> -253590</td><td style=\"text-align: right;\">             -213273</td><td style=\"text-align: right;\">             -331987</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:47:08 (running for 00:01:42.62)<br>Memory usage on this node: 12.6/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         80.6548</td><td style=\"text-align: right;\">447888</td><td style=\"text-align: right;\"> -253590</td><td style=\"text-align: right;\">             -213273</td><td style=\"text-align: right;\">             -331987</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:47:13 (running for 00:01:47.85)<br>Memory usage on this node: 12.7/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         80.6548</td><td style=\"text-align: right;\">447888</td><td style=\"text-align: right;\"> -253590</td><td style=\"text-align: right;\">             -213273</td><td style=\"text-align: right;\">             -331987</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 511872\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 511872\n",
      "    num_agent_steps_trained: 511872\n",
      "    num_env_steps_sampled: 511872\n",
      "    num_env_steps_trained: 511872\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-47-14\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -219349.98053034037\n",
      "  episode_reward_mean: -247090.89971458598\n",
      "  episode_reward_min: -313970.2608194886\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 504\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.275519371032715\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0003656224289443344\n",
      "          model: {}\n",
      "          policy_loss: 0.008940943516790867\n",
      "          total_loss: 10.008686065673828\n",
      "          vf_explained_var: -2.6490953430879927e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 511872\n",
      "    num_agent_steps_trained: 511872\n",
      "    num_env_steps_sampled: 511872\n",
      "    num_env_steps_trained: 511872\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 511872\n",
      "  num_agent_steps_trained: 511872\n",
      "  num_env_steps_sampled: 511872\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 511872\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.46666666666668\n",
      "    ram_util_percent: 81.66666666666669\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1174281932402203\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5330272771843221\n",
      "    mean_inference_ms: 1.1885030036378748\n",
      "    mean_raw_obs_processing_ms: 0.15884091547171278\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -219349.98053034037\n",
      "    episode_reward_mean: -247090.89971458598\n",
      "    episode_reward_min: -313970.2608194886\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -222993.34378350727\n",
      "      - -249145.22310986518\n",
      "      - -232209.1028524337\n",
      "      - -278434.6926434466\n",
      "      - -239260.05324199918\n",
      "      - -250112.02831598656\n",
      "      - -258422.64095762922\n",
      "      - -269728.315397171\n",
      "      - -276041.64321239886\n",
      "      - -237253.7768943042\n",
      "      - -236859.00390702146\n",
      "      - -245608.1405391795\n",
      "      - -236164.86497243104\n",
      "      - -225836.77379381532\n",
      "      - -245222.89194718635\n",
      "      - -232845.80636805462\n",
      "      - -268668.37105341296\n",
      "      - -272831.9551250679\n",
      "      - -296154.0274249437\n",
      "      - -229152.9383520238\n",
      "      - -249243.28776737928\n",
      "      - -239388.51278554817\n",
      "      - -256792.57165233686\n",
      "      - -283746.0158054048\n",
      "      - -225605.21329944357\n",
      "      - -231042.5286887918\n",
      "      - -254684.92042336185\n",
      "      - -238425.33721380268\n",
      "      - -255827.93541884195\n",
      "      - -224783.23948024184\n",
      "      - -227838.07647788821\n",
      "      - -227815.8356585535\n",
      "      - -313970.2608194886\n",
      "      - -227286.91669854926\n",
      "      - -312935.8995461748\n",
      "      - -244976.59930904114\n",
      "      - -280910.34642243653\n",
      "      - -287198.47924037464\n",
      "      - -232358.74190705392\n",
      "      - -257492.76818691456\n",
      "      - -245943.34256171313\n",
      "      - -251873.1363831012\n",
      "      - -236052.4837478051\n",
      "      - -219349.98053034037\n",
      "      - -232890.6811367131\n",
      "      - -246769.1913782759\n",
      "      - -229363.0685217599\n",
      "      - -220427.1630853201\n",
      "      - -244391.0919916543\n",
      "      - -237056.02695175275\n",
      "      - -246610.28794387952\n",
      "      - -227787.3856827739\n",
      "      - -244781.29192275094\n",
      "      - -240716.25821927356\n",
      "      - -250801.5531943182\n",
      "      - -309007.9801526262\n",
      "      - -250056.21969084188\n",
      "      - -229151.33220294403\n",
      "      - -307269.916969102\n",
      "      - -242591.2553506979\n",
      "      - -237494.39429183933\n",
      "      - -232764.561703924\n",
      "      - -232656.60272730613\n",
      "      - -232011.8655095194\n",
      "      - -235793.4378638518\n",
      "      - -244759.7194967177\n",
      "      - -299752.62266736163\n",
      "      - -238502.8289235678\n",
      "      - -228710.1229077652\n",
      "      - -245161.46730768995\n",
      "      - -225832.14654578583\n",
      "      - -238673.1210043426\n",
      "      - -254976.97049475904\n",
      "      - -235695.70210904223\n",
      "      - -251813.7481499149\n",
      "      - -221962.19809817808\n",
      "      - -238288.67101173566\n",
      "      - -224297.91425803874\n",
      "      - -237119.71485105803\n",
      "      - -226679.26014745567\n",
      "      - -248312.52307781499\n",
      "      - -229142.2292925329\n",
      "      - -227353.25924953766\n",
      "      - -255916.6509066261\n",
      "      - -250583.9389638706\n",
      "      - -234892.92989148686\n",
      "      - -244129.1726014305\n",
      "      - -247074.0709869043\n",
      "      - -234351.19756176719\n",
      "      - -240185.89713110143\n",
      "      - -278402.0580871288\n",
      "      - -262228.4473263956\n",
      "      - -241107.2741422732\n",
      "      - -243198.26695427854\n",
      "      - -276257.2352857477\n",
      "      - -266033.234621886\n",
      "      - -239723.09976757236\n",
      "      - -223624.14666707217\n",
      "      - -262598.9032019385\n",
      "      - -232869.63736023515\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1174281932402203\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5330272771843221\n",
      "      mean_inference_ms: 1.1885030036378748\n",
      "      mean_raw_obs_processing_ms: 0.15884091547171278\n",
      "  time_since_restore: 91.91696214675903\n",
      "  time_this_iter_s: 11.262212038040161\n",
      "  time_total_s: 91.91696214675903\n",
      "  timers:\n",
      "    learn_throughput: 132115.582\n",
      "    learn_time_ms: 484.303\n",
      "    load_throughput: 11734450.386\n",
      "    load_time_ms: 5.453\n",
      "    training_iteration_time_ms: 11483.268\n",
      "    update_time_ms: 3.492\n",
      "  timestamp: 1665848834\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 511872\n",
      "  training_iteration: 8\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:47:19 (running for 00:01:53.86)<br>Memory usage on this node: 12.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">          91.917</td><td style=\"text-align: right;\">511872</td><td style=\"text-align: right;\"> -247091</td><td style=\"text-align: right;\">             -219350</td><td style=\"text-align: right;\">             -313970</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 575856\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 575856\n",
      "    num_agent_steps_trained: 575856\n",
      "    num_env_steps_sampled: 575856\n",
      "    num_env_steps_trained: 575856\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-47-24\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -215221.96417750447\n",
      "  episode_reward_mean: -241999.7593672701\n",
      "  episode_reward_min: -311939.56248644536\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 564\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.2712156772613525\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.000536667532287538\n",
      "          model: {}\n",
      "          policy_loss: -0.005494036711752415\n",
      "          total_loss: 9.99428653717041\n",
      "          vf_explained_var: 4.730527525254047e-09\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 575856\n",
      "    num_agent_steps_trained: 575856\n",
      "    num_env_steps_sampled: 575856\n",
      "    num_env_steps_trained: 575856\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 575856\n",
      "  num_agent_steps_trained: 575856\n",
      "  num_env_steps_sampled: 575856\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 575856\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.32142857142857\n",
      "    ram_util_percent: 82.95714285714287\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11587764660812812\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.531171628568535\n",
      "    mean_inference_ms: 1.1744441780029964\n",
      "    mean_raw_obs_processing_ms: 0.15705480972982325\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -215221.96417750447\n",
      "    episode_reward_mean: -241999.7593672701\n",
      "    episode_reward_min: -311939.56248644536\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -237494.39429183933\n",
      "      - -232764.561703924\n",
      "      - -232656.60272730613\n",
      "      - -232011.8655095194\n",
      "      - -235793.4378638518\n",
      "      - -244759.7194967177\n",
      "      - -299752.62266736163\n",
      "      - -238502.8289235678\n",
      "      - -228710.1229077652\n",
      "      - -245161.46730768995\n",
      "      - -225832.14654578583\n",
      "      - -238673.1210043426\n",
      "      - -254976.97049475904\n",
      "      - -235695.70210904223\n",
      "      - -251813.7481499149\n",
      "      - -221962.19809817808\n",
      "      - -238288.67101173566\n",
      "      - -224297.91425803874\n",
      "      - -237119.71485105803\n",
      "      - -226679.26014745567\n",
      "      - -248312.52307781499\n",
      "      - -229142.2292925329\n",
      "      - -227353.25924953766\n",
      "      - -255916.6509066261\n",
      "      - -250583.9389638706\n",
      "      - -234892.92989148686\n",
      "      - -244129.1726014305\n",
      "      - -247074.0709869043\n",
      "      - -234351.19756176719\n",
      "      - -240185.89713110143\n",
      "      - -278402.0580871288\n",
      "      - -262228.4473263956\n",
      "      - -241107.2741422732\n",
      "      - -243198.26695427854\n",
      "      - -276257.2352857477\n",
      "      - -266033.234621886\n",
      "      - -239723.09976757236\n",
      "      - -223624.14666707217\n",
      "      - -262598.9032019385\n",
      "      - -232869.63736023515\n",
      "      - -299259.183851645\n",
      "      - -291165.7887440427\n",
      "      - -231527.25467388297\n",
      "      - -225770.90124292197\n",
      "      - -238943.54836439897\n",
      "      - -266956.89593963843\n",
      "      - -238025.8153738249\n",
      "      - -227515.93957306334\n",
      "      - -223796.76847435074\n",
      "      - -229284.715637766\n",
      "      - -230967.62816335316\n",
      "      - -240339.59163332634\n",
      "      - -223397.72832698934\n",
      "      - -223260.31199280123\n",
      "      - -243786.40520763941\n",
      "      - -223778.38636353405\n",
      "      - -237865.70993070144\n",
      "      - -307183.8773673215\n",
      "      - -255652.36825231393\n",
      "      - -241552.34497958753\n",
      "      - -243945.0511976285\n",
      "      - -230413.52703667033\n",
      "      - -215221.96417750447\n",
      "      - -226325.4416931308\n",
      "      - -222358.3584257668\n",
      "      - -223513.63102196803\n",
      "      - -228943.338538747\n",
      "      - -236071.12203702723\n",
      "      - -247796.5250896608\n",
      "      - -224804.444309679\n",
      "      - -257804.17382793635\n",
      "      - -235585.7127960748\n",
      "      - -239286.89652640861\n",
      "      - -272650.71969994536\n",
      "      - -224870.03111552083\n",
      "      - -219553.3257488916\n",
      "      - -266128.45694762643\n",
      "      - -291872.21952894586\n",
      "      - -222620.57267785433\n",
      "      - -227777.95718918412\n",
      "      - -220753.10285463842\n",
      "      - -226950.19779443755\n",
      "      - -224586.82474563972\n",
      "      - -311939.56248644536\n",
      "      - -223785.84781608946\n",
      "      - -294868.68655900226\n",
      "      - -231497.63329046383\n",
      "      - -226649.31708282058\n",
      "      - -237286.4199887596\n",
      "      - -230943.86567670834\n",
      "      - -233325.53910938653\n",
      "      - -226472.11906308224\n",
      "      - -222847.39628219476\n",
      "      - -283481.122053212\n",
      "      - -288649.2201384903\n",
      "      - -223623.4829289295\n",
      "      - -228702.5405757553\n",
      "      - -222676.28297768754\n",
      "      - -232747.87275829088\n",
      "      - -229683.02571824696\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11587764660812812\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.531171628568535\n",
      "      mean_inference_ms: 1.1744441780029964\n",
      "      mean_raw_obs_processing_ms: 0.15705480972982325\n",
      "  time_since_restore: 101.57307410240173\n",
      "  time_this_iter_s: 9.6561119556427\n",
      "  time_total_s: 101.57307410240173\n",
      "  timers:\n",
      "    learn_throughput: 131729.339\n",
      "    learn_time_ms: 485.723\n",
      "    load_throughput: 12308153.53\n",
      "    load_time_ms: 5.199\n",
      "    training_iteration_time_ms: 11279.361\n",
      "    update_time_ms: 3.566\n",
      "  timestamp: 1665848844\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 575856\n",
      "  training_iteration: 9\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:47:29 (running for 00:02:03.51)<br>Memory usage on this node: 12.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         101.573</td><td style=\"text-align: right;\">575856</td><td style=\"text-align: right;\"> -242000</td><td style=\"text-align: right;\">             -215222</td><td style=\"text-align: right;\">             -311940</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 639840\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 639840\n",
      "    num_agent_steps_trained: 639840\n",
      "    num_env_steps_sampled: 639840\n",
      "    num_env_steps_trained: 639840\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-47-33\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -218721.96212867805\n",
      "  episode_reward_mean: -239425.50778217937\n",
      "  episode_reward_min: -313589.48054541077\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 636\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.266475200653076\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0003333302156534046\n",
      "          model: {}\n",
      "          policy_loss: 0.0069070556201040745\n",
      "          total_loss: 10.006647109985352\n",
      "          vf_explained_var: -1.7029899268550253e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 639840\n",
      "    num_agent_steps_trained: 639840\n",
      "    num_env_steps_sampled: 639840\n",
      "    num_env_steps_trained: 639840\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 639840\n",
      "  num_agent_steps_trained: 639840\n",
      "  num_env_steps_sampled: 639840\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 639840\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.85714285714288\n",
      "    ram_util_percent: 83.04285714285713\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11328258819853222\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5242172930607448\n",
      "    mean_inference_ms: 1.1513138927675848\n",
      "    mean_raw_obs_processing_ms: 0.15443803835899833\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -218721.96212867805\n",
      "    episode_reward_mean: -239425.50778217937\n",
      "    episode_reward_min: -313589.48054541077\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -239286.89652640861\n",
      "      - -272650.71969994536\n",
      "      - -224870.03111552083\n",
      "      - -219553.3257488916\n",
      "      - -266128.45694762643\n",
      "      - -291872.21952894586\n",
      "      - -222620.57267785433\n",
      "      - -227777.95718918412\n",
      "      - -220753.10285463842\n",
      "      - -226950.19779443755\n",
      "      - -224586.82474563972\n",
      "      - -311939.56248644536\n",
      "      - -223785.84781608946\n",
      "      - -294868.68655900226\n",
      "      - -231497.63329046383\n",
      "      - -226649.31708282058\n",
      "      - -237286.4199887596\n",
      "      - -230943.86567670834\n",
      "      - -233325.53910938653\n",
      "      - -226472.11906308224\n",
      "      - -222847.39628219476\n",
      "      - -283481.122053212\n",
      "      - -288649.2201384903\n",
      "      - -223623.4829289295\n",
      "      - -228702.5405757553\n",
      "      - -222676.28297768754\n",
      "      - -232747.87275829088\n",
      "      - -229683.02571824696\n",
      "      - -249255.47845194105\n",
      "      - -230952.57142148208\n",
      "      - -265192.5435504732\n",
      "      - -236390.23387404063\n",
      "      - -221606.46973685504\n",
      "      - -269630.5935172308\n",
      "      - -273247.53990063205\n",
      "      - -220631.3087054364\n",
      "      - -224608.64506700475\n",
      "      - -224530.65724300637\n",
      "      - -254238.29293818498\n",
      "      - -218930.45086697792\n",
      "      - -220350.49317352482\n",
      "      - -246664.8680654389\n",
      "      - -245401.23451355877\n",
      "      - -279793.2887946031\n",
      "      - -246297.1028935862\n",
      "      - -231443.9093713399\n",
      "      - -230133.78900247137\n",
      "      - -221222.922890223\n",
      "      - -227317.29758489897\n",
      "      - -241404.0348011992\n",
      "      - -243940.4828512248\n",
      "      - -246805.71971373237\n",
      "      - -225990.84418840965\n",
      "      - -255174.69604040266\n",
      "      - -237964.3201830792\n",
      "      - -234852.87663383444\n",
      "      - -218721.96212867805\n",
      "      - -221979.10848448687\n",
      "      - -236504.87886906305\n",
      "      - -218806.71410957398\n",
      "      - -232513.81848644148\n",
      "      - -232231.07446422827\n",
      "      - -233206.00967599626\n",
      "      - -235938.21530815758\n",
      "      - -219004.82938186158\n",
      "      - -231826.41400950003\n",
      "      - -224410.0604942533\n",
      "      - -229388.64988643752\n",
      "      - -219970.98132999978\n",
      "      - -245174.28129491917\n",
      "      - -235680.06472564276\n",
      "      - -230982.3328912056\n",
      "      - -248896.3691392657\n",
      "      - -252162.40825338598\n",
      "      - -234987.8092939962\n",
      "      - -221140.76262756682\n",
      "      - -225970.9368599573\n",
      "      - -238634.9127976592\n",
      "      - -241640.95702072734\n",
      "      - -237287.33052978592\n",
      "      - -273725.60496755684\n",
      "      - -235801.25891084885\n",
      "      - -261679.97056778736\n",
      "      - -232095.65418214322\n",
      "      - -250666.65366441666\n",
      "      - -231929.7706116736\n",
      "      - -228506.1047852062\n",
      "      - -227759.34432865225\n",
      "      - -233654.81216880193\n",
      "      - -256163.5833370104\n",
      "      - -241096.25518381572\n",
      "      - -313589.48054541077\n",
      "      - -234636.36903780533\n",
      "      - -251975.569805492\n",
      "      - -251305.13902999475\n",
      "      - -226157.00028906175\n",
      "      - -235038.8842254492\n",
      "      - -225657.6902495387\n",
      "      - -229243.1323538825\n",
      "      - -224604.7126011487\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11328258819853222\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5242172930607448\n",
      "      mean_inference_ms: 1.1513138927675848\n",
      "      mean_raw_obs_processing_ms: 0.15443803835899833\n",
      "  time_since_restore: 111.17681622505188\n",
      "  time_this_iter_s: 9.603742122650146\n",
      "  time_total_s: 111.17681622505188\n",
      "  timers:\n",
      "    learn_throughput: 131176.506\n",
      "    learn_time_ms: 487.77\n",
      "    load_throughput: 12918285.918\n",
      "    load_time_ms: 4.953\n",
      "    training_iteration_time_ms: 11111.321\n",
      "    update_time_ms: 3.715\n",
      "  timestamp: 1665848853\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 639840\n",
      "  training_iteration: 10\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:47:38 (running for 00:02:13.39)<br>Memory usage on this node: 12.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         111.177</td><td style=\"text-align: right;\">639840</td><td style=\"text-align: right;\"> -239426</td><td style=\"text-align: right;\">             -218722</td><td style=\"text-align: right;\">             -313589</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 703824\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 703824\n",
      "    num_agent_steps_trained: 703824\n",
      "    num_env_steps_sampled: 703824\n",
      "    num_env_steps_trained: 703824\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-47-43\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -219004.82938186158\n",
      "  episode_reward_mean: -237834.04827068042\n",
      "  episode_reward_min: -313589.48054541077\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 696\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.264876127243042\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0004856934829149395\n",
      "          model: {}\n",
      "          policy_loss: 0.0038115952629595995\n",
      "          total_loss: 10.003581047058105\n",
      "          vf_explained_var: -2.4598742598413992e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 703824\n",
      "    num_agent_steps_trained: 703824\n",
      "    num_env_steps_sampled: 703824\n",
      "    num_env_steps_trained: 703824\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 703824\n",
      "  num_agent_steps_trained: 703824\n",
      "  num_env_steps_sampled: 703824\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 703824\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 80.49285714285715\n",
      "    ram_util_percent: 82.92142857142856\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11209964103287418\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5199446524661634\n",
      "    mean_inference_ms: 1.140072031747802\n",
      "    mean_raw_obs_processing_ms: 0.15292428351446088\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -219004.82938186158\n",
      "    episode_reward_mean: -237834.04827068042\n",
      "    episode_reward_min: -313589.48054541077\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -232513.81848644148\n",
      "      - -232231.07446422827\n",
      "      - -233206.00967599626\n",
      "      - -235938.21530815758\n",
      "      - -219004.82938186158\n",
      "      - -231826.41400950003\n",
      "      - -224410.0604942533\n",
      "      - -229388.64988643752\n",
      "      - -219970.98132999978\n",
      "      - -245174.28129491917\n",
      "      - -235680.06472564276\n",
      "      - -230982.3328912056\n",
      "      - -248896.3691392657\n",
      "      - -252162.40825338598\n",
      "      - -234987.8092939962\n",
      "      - -221140.76262756682\n",
      "      - -225970.9368599573\n",
      "      - -238634.9127976592\n",
      "      - -241640.95702072734\n",
      "      - -237287.33052978592\n",
      "      - -273725.60496755684\n",
      "      - -235801.25891084885\n",
      "      - -261679.97056778736\n",
      "      - -232095.65418214322\n",
      "      - -250666.65366441666\n",
      "      - -231929.7706116736\n",
      "      - -228506.1047852062\n",
      "      - -227759.34432865225\n",
      "      - -233654.81216880193\n",
      "      - -256163.5833370104\n",
      "      - -241096.25518381572\n",
      "      - -313589.48054541077\n",
      "      - -234636.36903780533\n",
      "      - -251975.569805492\n",
      "      - -251305.13902999475\n",
      "      - -226157.00028906175\n",
      "      - -235038.8842254492\n",
      "      - -225657.6902495387\n",
      "      - -229243.1323538825\n",
      "      - -224604.7126011487\n",
      "      - -251625.03581021287\n",
      "      - -219565.11900456733\n",
      "      - -228954.85313544763\n",
      "      - -244055.4228214931\n",
      "      - -230134.79709933128\n",
      "      - -257573.7373836646\n",
      "      - -219855.10850157903\n",
      "      - -227346.57502932625\n",
      "      - -246225.32267301227\n",
      "      - -225282.63788149925\n",
      "      - -229291.47919053433\n",
      "      - -227963.0924540857\n",
      "      - -233962.82073805048\n",
      "      - -305218.57052265835\n",
      "      - -245727.99117887675\n",
      "      - -263045.6883988977\n",
      "      - -231006.67781664614\n",
      "      - -259504.18445114477\n",
      "      - -243656.7672769731\n",
      "      - -232971.16709140578\n",
      "      - -225764.22359557782\n",
      "      - -239411.89979128726\n",
      "      - -237285.41848454022\n",
      "      - -230722.66090415412\n",
      "      - -244603.83992194064\n",
      "      - -250329.30479372945\n",
      "      - -232093.2642169402\n",
      "      - -223789.44786168507\n",
      "      - -229604.97784886442\n",
      "      - -234365.2317522504\n",
      "      - -224712.6664841154\n",
      "      - -229492.89435738674\n",
      "      - -229525.67757161305\n",
      "      - -245961.60773968973\n",
      "      - -238401.33807740302\n",
      "      - -220969.86411741708\n",
      "      - -234737.29885264355\n",
      "      - -225807.47390477842\n",
      "      - -234154.7732406537\n",
      "      - -236201.38089623553\n",
      "      - -243733.22234586792\n",
      "      - -222204.90534671562\n",
      "      - -234407.8276434064\n",
      "      - -224026.68980825722\n",
      "      - -245461.12249015112\n",
      "      - -242680.56155681223\n",
      "      - -236212.08477626738\n",
      "      - -225035.46387326627\n",
      "      - -283006.7204026835\n",
      "      - -224096.8535327715\n",
      "      - -228229.15856201775\n",
      "      - -256751.14424177934\n",
      "      - -221462.11360769861\n",
      "      - -239228.00618872457\n",
      "      - -232244.60562413745\n",
      "      - -220467.43580576908\n",
      "      - -237658.20071208884\n",
      "      - -243400.36895389349\n",
      "      - -264984.25045043917\n",
      "      - -230876.5889562914\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11209964103287418\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5199446524661634\n",
      "      mean_inference_ms: 1.140072031747802\n",
      "      mean_raw_obs_processing_ms: 0.15292428351446088\n",
      "  time_since_restore: 121.18884372711182\n",
      "  time_this_iter_s: 10.012027502059937\n",
      "  time_total_s: 121.18884372711182\n",
      "  timers:\n",
      "    learn_throughput: 155464.199\n",
      "    learn_time_ms: 411.567\n",
      "    load_throughput: 21214385.994\n",
      "    load_time_ms: 3.016\n",
      "    training_iteration_time_ms: 10849.894\n",
      "    update_time_ms: 3.601\n",
      "  timestamp: 1665848863\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 703824\n",
      "  training_iteration: 11\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:47:49 (running for 00:02:23.61)<br>Memory usage on this node: 12.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         121.189</td><td style=\"text-align: right;\">703824</td><td style=\"text-align: right;\"> -237834</td><td style=\"text-align: right;\">             -219005</td><td style=\"text-align: right;\">             -313589</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 767808\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 767808\n",
      "    num_agent_steps_trained: 767808\n",
      "    num_env_steps_sampled: 767808\n",
      "    num_env_steps_trained: 767808\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-47-53\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -215000.75105470297\n",
      "  episode_reward_mean: -234696.59014041373\n",
      "  episode_reward_min: -284988.3347207834\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 756\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.2605090141296387\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0005598492571152747\n",
      "          model: {}\n",
      "          policy_loss: -0.00287074176594615\n",
      "          total_loss: 9.996916770935059\n",
      "          vf_explained_var: -1.797600468478322e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 767808\n",
      "    num_agent_steps_trained: 767808\n",
      "    num_env_steps_sampled: 767808\n",
      "    num_env_steps_trained: 767808\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 767808\n",
      "  num_agent_steps_trained: 767808\n",
      "  num_env_steps_sampled: 767808\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 767808\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.93846153846154\n",
      "    ram_util_percent: 83.13076923076923\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11051559676117487\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5167760659997195\n",
      "    mean_inference_ms: 1.1287953643845345\n",
      "    mean_raw_obs_processing_ms: 0.15131916797344322\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -215000.75105470297\n",
      "    episode_reward_mean: -234696.59014041373\n",
      "    episode_reward_min: -284988.3347207834\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -225764.22359557782\n",
      "      - -239411.89979128726\n",
      "      - -237285.41848454022\n",
      "      - -230722.66090415412\n",
      "      - -244603.83992194064\n",
      "      - -250329.30479372945\n",
      "      - -232093.2642169402\n",
      "      - -223789.44786168507\n",
      "      - -229604.97784886442\n",
      "      - -234365.2317522504\n",
      "      - -224712.6664841154\n",
      "      - -229492.89435738674\n",
      "      - -229525.67757161305\n",
      "      - -245961.60773968973\n",
      "      - -238401.33807740302\n",
      "      - -220969.86411741708\n",
      "      - -234737.29885264355\n",
      "      - -225807.47390477842\n",
      "      - -234154.7732406537\n",
      "      - -236201.38089623553\n",
      "      - -243733.22234586792\n",
      "      - -222204.90534671562\n",
      "      - -234407.8276434064\n",
      "      - -224026.68980825722\n",
      "      - -245461.12249015112\n",
      "      - -242680.56155681223\n",
      "      - -236212.08477626738\n",
      "      - -225035.46387326627\n",
      "      - -283006.7204026835\n",
      "      - -224096.8535327715\n",
      "      - -228229.15856201775\n",
      "      - -256751.14424177934\n",
      "      - -221462.11360769861\n",
      "      - -239228.00618872457\n",
      "      - -232244.60562413745\n",
      "      - -220467.43580576908\n",
      "      - -237658.20071208884\n",
      "      - -243400.36895389349\n",
      "      - -264984.25045043917\n",
      "      - -230876.5889562914\n",
      "      - -223422.9707584059\n",
      "      - -220193.25513776898\n",
      "      - -220654.16583752344\n",
      "      - -230739.06770003025\n",
      "      - -217995.77590010865\n",
      "      - -233310.10340448568\n",
      "      - -222311.61317056188\n",
      "      - -220312.61081873276\n",
      "      - -233054.40787990022\n",
      "      - -218096.316798165\n",
      "      - -280384.60749738273\n",
      "      - -222530.8490307876\n",
      "      - -227733.8286341807\n",
      "      - -225178.67239025305\n",
      "      - -221178.29072429094\n",
      "      - -230494.77434142248\n",
      "      - -236184.3199338337\n",
      "      - -230732.4003574667\n",
      "      - -229197.89816315123\n",
      "      - -227866.3877790773\n",
      "      - -234760.96999986967\n",
      "      - -227910.58942955371\n",
      "      - -229242.39751149353\n",
      "      - -226286.76185824675\n",
      "      - -222082.868099708\n",
      "      - -248103.4946937416\n",
      "      - -238478.8288213666\n",
      "      - -244609.12833616903\n",
      "      - -284988.3347207834\n",
      "      - -231177.4876583024\n",
      "      - -257580.2132916166\n",
      "      - -235552.15817659313\n",
      "      - -234567.5164353727\n",
      "      - -218579.23400501744\n",
      "      - -215000.75105470297\n",
      "      - -241400.97797147444\n",
      "      - -226276.22231480604\n",
      "      - -271199.47865698644\n",
      "      - -238281.57640410762\n",
      "      - -234778.13864319952\n",
      "      - -248942.3652419481\n",
      "      - -232253.345672185\n",
      "      - -220187.34145444943\n",
      "      - -237653.57168423495\n",
      "      - -238637.75465149348\n",
      "      - -230547.97665766437\n",
      "      - -226471.77704535567\n",
      "      - -251391.6866160286\n",
      "      - -217446.04342075274\n",
      "      - -222760.40054115083\n",
      "      - -236648.27286964367\n",
      "      - -240689.87406007134\n",
      "      - -242138.66689647382\n",
      "      - -228466.82604455834\n",
      "      - -255118.745719489\n",
      "      - -261255.22049788988\n",
      "      - -226949.86973197185\n",
      "      - -233620.19047642383\n",
      "      - -223855.1876502925\n",
      "      - -238091.88347670922\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11051559676117487\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5167760659997195\n",
      "      mean_inference_ms: 1.1287953643845345\n",
      "      mean_raw_obs_processing_ms: 0.15131916797344322\n",
      "  time_since_restore: 130.79921340942383\n",
      "  time_this_iter_s: 9.610369682312012\n",
      "  time_total_s: 130.79921340942383\n",
      "  timers:\n",
      "    learn_throughput: 153250.602\n",
      "    learn_time_ms: 417.512\n",
      "    load_throughput: 22035697.042\n",
      "    load_time_ms: 2.904\n",
      "    training_iteration_time_ms: 10510.497\n",
      "    update_time_ms: 3.594\n",
      "  timestamp: 1665848873\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 767808\n",
      "  training_iteration: 12\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:47:58 (running for 00:02:32.89)<br>Memory usage on this node: 12.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         130.799</td><td style=\"text-align: right;\">767808</td><td style=\"text-align: right;\"> -234697</td><td style=\"text-align: right;\">             -215001</td><td style=\"text-align: right;\">             -284988</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 831792\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 831792\n",
      "    num_agent_steps_trained: 831792\n",
      "    num_env_steps_sampled: 831792\n",
      "    num_env_steps_trained: 831792\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-48-02\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -214104.79944185197\n",
      "  episode_reward_mean: -231428.26363351566\n",
      "  episode_reward_min: -284159.22981024487\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 828\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.256251096725464\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0006242931704036891\n",
      "          model: {}\n",
      "          policy_loss: 0.004615913610905409\n",
      "          total_loss: 10.004413604736328\n",
      "          vf_explained_var: -2.6490953430879927e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 831792\n",
      "    num_agent_steps_trained: 831792\n",
      "    num_env_steps_sampled: 831792\n",
      "    num_env_steps_trained: 831792\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 831792\n",
      "  num_agent_steps_trained: 831792\n",
      "  num_env_steps_sampled: 831792\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 831792\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 80.32857142857144\n",
      "    ram_util_percent: 83.39999999999999\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10895670091651706\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.512263589555026\n",
      "    mean_inference_ms: 1.11522685750855\n",
      "    mean_raw_obs_processing_ms: 0.14976046050091107\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -214104.79944185197\n",
      "    episode_reward_mean: -231428.26363351566\n",
      "    episode_reward_min: -284159.22981024487\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -234567.5164353727\n",
      "      - -218579.23400501744\n",
      "      - -215000.75105470297\n",
      "      - -241400.97797147444\n",
      "      - -226276.22231480604\n",
      "      - -271199.47865698644\n",
      "      - -238281.57640410762\n",
      "      - -234778.13864319952\n",
      "      - -248942.3652419481\n",
      "      - -232253.345672185\n",
      "      - -220187.34145444943\n",
      "      - -237653.57168423495\n",
      "      - -238637.75465149348\n",
      "      - -230547.97665766437\n",
      "      - -226471.77704535567\n",
      "      - -251391.6866160286\n",
      "      - -217446.04342075274\n",
      "      - -222760.40054115083\n",
      "      - -236648.27286964367\n",
      "      - -240689.87406007134\n",
      "      - -242138.66689647382\n",
      "      - -228466.82604455834\n",
      "      - -255118.745719489\n",
      "      - -261255.22049788988\n",
      "      - -226949.86973197185\n",
      "      - -233620.19047642383\n",
      "      - -223855.1876502925\n",
      "      - -238091.88347670922\n",
      "      - -214104.79944185197\n",
      "      - -241010.63088674165\n",
      "      - -238652.57899014367\n",
      "      - -230046.1576823523\n",
      "      - -225218.28684877887\n",
      "      - -277925.3007340016\n",
      "      - -234352.3131325849\n",
      "      - -224842.0984064448\n",
      "      - -230743.78580915\n",
      "      - -225585.96353889306\n",
      "      - -224684.39629075825\n",
      "      - -284159.22981024487\n",
      "      - -229867.78368742595\n",
      "      - -221786.76680466192\n",
      "      - -224073.9913010695\n",
      "      - -225664.87258678864\n",
      "      - -223075.05238159315\n",
      "      - -222303.2207426727\n",
      "      - -227602.3593708222\n",
      "      - -229578.71533643885\n",
      "      - -224670.4466084926\n",
      "      - -226166.17256000938\n",
      "      - -243159.55745388803\n",
      "      - -243050.77440814624\n",
      "      - -225341.3131670973\n",
      "      - -224615.0776303121\n",
      "      - -227711.30696049545\n",
      "      - -225096.04961820997\n",
      "      - -230000.94165625746\n",
      "      - -226464.6341956439\n",
      "      - -216540.69109603023\n",
      "      - -219701.43028751967\n",
      "      - -230147.7426837237\n",
      "      - -223865.27019441023\n",
      "      - -227581.1942735715\n",
      "      - -226787.73783384715\n",
      "      - -229888.8759688691\n",
      "      - -237431.07253195\n",
      "      - -222153.52797445626\n",
      "      - -227348.32591883023\n",
      "      - -241204.40077276796\n",
      "      - -225468.9041976375\n",
      "      - -235756.84245006708\n",
      "      - -226425.27744978646\n",
      "      - -226862.72048836842\n",
      "      - -223143.8905421404\n",
      "      - -231875.87152886888\n",
      "      - -240886.39016815426\n",
      "      - -229822.90843620495\n",
      "      - -231702.7341007769\n",
      "      - -224736.5237449443\n",
      "      - -234536.9186304455\n",
      "      - -231493.62167029505\n",
      "      - -238812.81818427317\n",
      "      - -269816.25062707084\n",
      "      - -235157.80200557155\n",
      "      - -228441.05598941413\n",
      "      - -221326.55050614255\n",
      "      - -222150.38780581026\n",
      "      - -225755.3299674799\n",
      "      - -218899.71348981996\n",
      "      - -226972.27088670398\n",
      "      - -233021.41939232257\n",
      "      - -221069.65817663015\n",
      "      - -223437.39858648297\n",
      "      - -217431.50591066564\n",
      "      - -233355.69021688605\n",
      "      - -223143.71969387578\n",
      "      - -223760.11818549372\n",
      "      - -223288.07451369974\n",
      "      - -220011.43942255346\n",
      "      - -226846.81291057583\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.10895670091651706\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.512263589555026\n",
      "      mean_inference_ms: 1.11522685750855\n",
      "      mean_raw_obs_processing_ms: 0.14976046050091107\n",
      "  time_since_restore: 140.34787130355835\n",
      "  time_this_iter_s: 9.548657894134521\n",
      "  time_total_s: 140.34787130355835\n",
      "  timers:\n",
      "    learn_throughput: 150556.771\n",
      "    learn_time_ms: 424.983\n",
      "    load_throughput: 22150095.918\n",
      "    load_time_ms: 2.889\n",
      "    training_iteration_time_ms: 10201.736\n",
      "    update_time_ms: 3.78\n",
      "  timestamp: 1665848882\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 831792\n",
      "  training_iteration: 13\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:48:08 (running for 00:02:42.42)<br>Memory usage on this node: 12.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         140.348</td><td style=\"text-align: right;\">831792</td><td style=\"text-align: right;\"> -231428</td><td style=\"text-align: right;\">             -214105</td><td style=\"text-align: right;\">             -284159</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 895776\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 895776\n",
      "    num_agent_steps_trained: 895776\n",
      "    num_env_steps_sampled: 895776\n",
      "    num_env_steps_trained: 895776\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-48-12\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -217431.50591066564\n",
      "  episode_reward_mean: -229516.38356862048\n",
      "  episode_reward_min: -275030.25800669636\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 888\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.253739833831787\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00036737421760335565\n",
      "          model: {}\n",
      "          policy_loss: 0.0072363680228590965\n",
      "          total_loss: 10.006982803344727\n",
      "          vf_explained_var: -4.068253645073128e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 895776\n",
      "    num_agent_steps_trained: 895776\n",
      "    num_env_steps_sampled: 895776\n",
      "    num_env_steps_trained: 895776\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 895776\n",
      "  num_agent_steps_trained: 895776\n",
      "  num_env_steps_sampled: 895776\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 895776\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 78.95714285714287\n",
      "    ram_util_percent: 83.80714285714285\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10829933243797213\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5097281656738505\n",
      "    mean_inference_ms: 1.1053984912576202\n",
      "    mean_raw_obs_processing_ms: 0.14885898941518222\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -217431.50591066564\n",
      "    episode_reward_mean: -229516.38356862048\n",
      "    episode_reward_min: -275030.25800669636\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -230147.7426837237\n",
      "      - -223865.27019441023\n",
      "      - -227581.1942735715\n",
      "      - -226787.73783384715\n",
      "      - -229888.8759688691\n",
      "      - -237431.07253195\n",
      "      - -222153.52797445626\n",
      "      - -227348.32591883023\n",
      "      - -241204.40077276796\n",
      "      - -225468.9041976375\n",
      "      - -235756.84245006708\n",
      "      - -226425.27744978646\n",
      "      - -226862.72048836842\n",
      "      - -223143.8905421404\n",
      "      - -231875.87152886888\n",
      "      - -240886.39016815426\n",
      "      - -229822.90843620495\n",
      "      - -231702.7341007769\n",
      "      - -224736.5237449443\n",
      "      - -234536.9186304455\n",
      "      - -231493.62167029505\n",
      "      - -238812.81818427317\n",
      "      - -269816.25062707084\n",
      "      - -235157.80200557155\n",
      "      - -228441.05598941413\n",
      "      - -221326.55050614255\n",
      "      - -222150.38780581026\n",
      "      - -225755.3299674799\n",
      "      - -218899.71348981996\n",
      "      - -226972.27088670398\n",
      "      - -233021.41939232257\n",
      "      - -221069.65817663015\n",
      "      - -223437.39858648297\n",
      "      - -217431.50591066564\n",
      "      - -233355.69021688605\n",
      "      - -223143.71969387578\n",
      "      - -223760.11818549372\n",
      "      - -223288.07451369974\n",
      "      - -220011.43942255346\n",
      "      - -226846.81291057583\n",
      "      - -241088.54482842196\n",
      "      - -225004.14185541865\n",
      "      - -244508.06690752858\n",
      "      - -224856.59251868998\n",
      "      - -223620.29637279533\n",
      "      - -225209.8073807153\n",
      "      - -225154.3974884474\n",
      "      - -221540.14171287962\n",
      "      - -244044.7365117833\n",
      "      - -221054.38447208746\n",
      "      - -223243.0264338082\n",
      "      - -220581.27643012337\n",
      "      - -271439.9317205587\n",
      "      - -228836.71191797242\n",
      "      - -227546.42771036347\n",
      "      - -229262.8970562313\n",
      "      - -224618.30363915238\n",
      "      - -222825.32699439547\n",
      "      - -219439.56615170173\n",
      "      - -222749.33123980864\n",
      "      - -261281.70661879767\n",
      "      - -233657.4627993964\n",
      "      - -233615.00962645753\n",
      "      - -234753.41529541384\n",
      "      - -231111.47591778392\n",
      "      - -233745.532831562\n",
      "      - -275030.25800669636\n",
      "      - -220100.72872299005\n",
      "      - -227720.5795563124\n",
      "      - -221965.8031938816\n",
      "      - -218139.27417823722\n",
      "      - -224087.7495455733\n",
      "      - -222490.85876751342\n",
      "      - -229283.35165362924\n",
      "      - -218452.71433056524\n",
      "      - -217945.25452188554\n",
      "      - -226144.46865504334\n",
      "      - -222775.21105057295\n",
      "      - -232575.49099091574\n",
      "      - -227262.51751214932\n",
      "      - -226964.71827960003\n",
      "      - -225304.0888127596\n",
      "      - -230436.51054004693\n",
      "      - -219003.9028578558\n",
      "      - -227817.2518423407\n",
      "      - -225776.53869532642\n",
      "      - -226571.6364230601\n",
      "      - -228835.96745977245\n",
      "      - -225925.91387620542\n",
      "      - -224285.71609355975\n",
      "      - -225746.56131576188\n",
      "      - -237491.55005989538\n",
      "      - -220207.18090090787\n",
      "      - -230442.0949825688\n",
      "      - -262574.6741164038\n",
      "      - -224193.41221013165\n",
      "      - -239719.28448633096\n",
      "      - -223681.38990016768\n",
      "      - -237567.36241568794\n",
      "      - -228511.06044381688\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.10829933243797213\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5097281656738505\n",
      "      mean_inference_ms: 1.1053984912576202\n",
      "      mean_raw_obs_processing_ms: 0.14885898941518222\n",
      "  time_since_restore: 149.93145537376404\n",
      "  time_this_iter_s: 9.583584070205688\n",
      "  time_total_s: 149.93145537376404\n",
      "  timers:\n",
      "    learn_throughput: 144697.145\n",
      "    learn_time_ms: 442.193\n",
      "    load_throughput: 22304550.128\n",
      "    load_time_ms: 2.869\n",
      "    training_iteration_time_ms: 10038.023\n",
      "    update_time_ms: 3.905\n",
      "  timestamp: 1665848892\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 895776\n",
      "  training_iteration: 14\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:48:17 (running for 00:02:52.08)<br>Memory usage on this node: 13.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         149.931</td><td style=\"text-align: right;\">895776</td><td style=\"text-align: right;\"> -229516</td><td style=\"text-align: right;\">             -217432</td><td style=\"text-align: right;\">             -275030</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 959760\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 959760\n",
      "    num_agent_steps_trained: 959760\n",
      "    num_env_steps_sampled: 959760\n",
      "    num_env_steps_trained: 959760\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-48-22\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -215025.52542607233\n",
      "  episode_reward_mean: -230555.8826981993\n",
      "  episode_reward_min: -275455.6014913975\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 948\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.253085136413574\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0005205830675549805\n",
      "          model: {}\n",
      "          policy_loss: -0.0036726086400449276\n",
      "          total_loss: 9.99610710144043\n",
      "          vf_explained_var: -2.0814320933482122e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 959760\n",
      "    num_agent_steps_trained: 959760\n",
      "    num_env_steps_sampled: 959760\n",
      "    num_env_steps_trained: 959760\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 959760\n",
      "  num_agent_steps_trained: 959760\n",
      "  num_env_steps_sampled: 959760\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 959760\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.0076923076923\n",
      "    ram_util_percent: 84.1153846153846\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1073090367840603\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5075867622997601\n",
      "    mean_inference_ms: 1.0967980343689236\n",
      "    mean_raw_obs_processing_ms: 0.14787412309429\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -215025.52542607233\n",
      "    episode_reward_mean: -230555.8826981993\n",
      "    episode_reward_min: -275455.6014913975\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -261281.70661879767\n",
      "      - -233657.4627993964\n",
      "      - -233615.00962645753\n",
      "      - -234753.41529541384\n",
      "      - -231111.47591778392\n",
      "      - -233745.532831562\n",
      "      - -275030.25800669636\n",
      "      - -220100.72872299005\n",
      "      - -227720.5795563124\n",
      "      - -221965.8031938816\n",
      "      - -218139.27417823722\n",
      "      - -224087.7495455733\n",
      "      - -222490.85876751342\n",
      "      - -229283.35165362924\n",
      "      - -218452.71433056524\n",
      "      - -217945.25452188554\n",
      "      - -226144.46865504334\n",
      "      - -222775.21105057295\n",
      "      - -232575.49099091574\n",
      "      - -227262.51751214932\n",
      "      - -226964.71827960003\n",
      "      - -225304.0888127596\n",
      "      - -230436.51054004693\n",
      "      - -219003.9028578558\n",
      "      - -227817.2518423407\n",
      "      - -225776.53869532642\n",
      "      - -226571.6364230601\n",
      "      - -228835.96745977245\n",
      "      - -225925.91387620542\n",
      "      - -224285.71609355975\n",
      "      - -225746.56131576188\n",
      "      - -237491.55005989538\n",
      "      - -220207.18090090787\n",
      "      - -230442.0949825688\n",
      "      - -262574.6741164038\n",
      "      - -224193.41221013165\n",
      "      - -239719.28448633096\n",
      "      - -223681.38990016768\n",
      "      - -237567.36241568794\n",
      "      - -228511.06044381688\n",
      "      - -231197.4564418568\n",
      "      - -220766.4438460892\n",
      "      - -224169.87484494087\n",
      "      - -221359.51416062325\n",
      "      - -227600.18120554826\n",
      "      - -217162.69610716178\n",
      "      - -235530.9766955761\n",
      "      - -230165.29558792445\n",
      "      - -220919.68776619466\n",
      "      - -244156.89482298377\n",
      "      - -230670.9448593917\n",
      "      - -222054.5103283723\n",
      "      - -223580.96239894166\n",
      "      - -241935.82200881615\n",
      "      - -220182.07138121524\n",
      "      - -239965.77784958252\n",
      "      - -229418.16334311687\n",
      "      - -226921.70147104393\n",
      "      - -220987.574247669\n",
      "      - -232501.5558176801\n",
      "      - -224886.96299110953\n",
      "      - -217604.8385782771\n",
      "      - -224126.9345530842\n",
      "      - -231991.46425045416\n",
      "      - -265934.7919799253\n",
      "      - -230131.0071244926\n",
      "      - -219108.56313106327\n",
      "      - -275455.6014913975\n",
      "      - -265171.66448746406\n",
      "      - -237925.73896350592\n",
      "      - -230367.7383814571\n",
      "      - -226231.53150317265\n",
      "      - -261141.35628503098\n",
      "      - -237796.03970276777\n",
      "      - -215025.52542607233\n",
      "      - -221227.95298690896\n",
      "      - -224822.93560052337\n",
      "      - -230016.12172858248\n",
      "      - -233283.4668951861\n",
      "      - -253206.89722216636\n",
      "      - -224194.3470892927\n",
      "      - -270813.2073390565\n",
      "      - -220547.50028428968\n",
      "      - -240005.40303607736\n",
      "      - -216751.41522957556\n",
      "      - -228126.6983743946\n",
      "      - -226060.54897941978\n",
      "      - -219081.245686046\n",
      "      - -226716.80614246515\n",
      "      - -224840.94687824242\n",
      "      - -227620.06026241157\n",
      "      - -245714.4562715501\n",
      "      - -225705.34390654293\n",
      "      - -221004.28681747091\n",
      "      - -219308.10935071667\n",
      "      - -228910.63456262473\n",
      "      - -219588.41217497468\n",
      "      - -227958.33924593258\n",
      "      - -231643.6690224537\n",
      "      - -221095.9212114462\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1073090367840603\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5075867622997601\n",
      "      mean_inference_ms: 1.0967980343689236\n",
      "      mean_raw_obs_processing_ms: 0.14787412309429\n",
      "  time_since_restore: 159.53026270866394\n",
      "  time_this_iter_s: 9.598807334899902\n",
      "  time_total_s: 159.53026270866394\n",
      "  timers:\n",
      "    learn_throughput: 140156.633\n",
      "    learn_time_ms: 456.518\n",
      "    load_throughput: 22291581.289\n",
      "    load_time_ms: 2.87\n",
      "    training_iteration_time_ms: 9967.264\n",
      "    update_time_ms: 4.003\n",
      "  timestamp: 1665848902\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 959760\n",
      "  training_iteration: 15\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:48:27 (running for 00:03:01.73)<br>Memory usage on this node: 13.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">          159.53</td><td style=\"text-align: right;\">959760</td><td style=\"text-align: right;\"> -230556</td><td style=\"text-align: right;\">             -215026</td><td style=\"text-align: right;\">             -275456</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 1023744\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 1023744\n",
      "    num_agent_steps_trained: 1023744\n",
      "    num_env_steps_sampled: 1023744\n",
      "    num_env_steps_trained: 1023744\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-48-31\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -215025.52542607233\n",
      "  episode_reward_mean: -229189.6191036378\n",
      "  episode_reward_min: -272069.9775234155\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 1020\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.250271797180176\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00046909565571695566\n",
      "          model: {}\n",
      "          policy_loss: 0.006212172098457813\n",
      "          total_loss: 10.0059814453125\n",
      "          vf_explained_var: -1.1353265882974029e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 1023744\n",
      "    num_agent_steps_trained: 1023744\n",
      "    num_env_steps_sampled: 1023744\n",
      "    num_env_steps_trained: 1023744\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 1023744\n",
      "  num_agent_steps_trained: 1023744\n",
      "  num_env_steps_sampled: 1023744\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 1023744\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.47857142857141\n",
      "    ram_util_percent: 84.47857142857141\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10630772009094859\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5041910156474847\n",
      "    mean_inference_ms: 1.0852848555485002\n",
      "    mean_raw_obs_processing_ms: 0.14686267890941543\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -215025.52542607233\n",
      "    episode_reward_mean: -229189.6191036378\n",
      "    episode_reward_min: -272069.9775234155\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -261141.35628503098\n",
      "      - -237796.03970276777\n",
      "      - -215025.52542607233\n",
      "      - -221227.95298690896\n",
      "      - -224822.93560052337\n",
      "      - -230016.12172858248\n",
      "      - -233283.4668951861\n",
      "      - -253206.89722216636\n",
      "      - -224194.3470892927\n",
      "      - -270813.2073390565\n",
      "      - -220547.50028428968\n",
      "      - -240005.40303607736\n",
      "      - -216751.41522957556\n",
      "      - -228126.6983743946\n",
      "      - -226060.54897941978\n",
      "      - -219081.245686046\n",
      "      - -226716.80614246515\n",
      "      - -224840.94687824242\n",
      "      - -227620.06026241157\n",
      "      - -245714.4562715501\n",
      "      - -225705.34390654293\n",
      "      - -221004.28681747091\n",
      "      - -219308.10935071667\n",
      "      - -228910.63456262473\n",
      "      - -219588.41217497468\n",
      "      - -227958.33924593258\n",
      "      - -231643.6690224537\n",
      "      - -221095.9212114462\n",
      "      - -230018.877708615\n",
      "      - -223464.66971090314\n",
      "      - -234166.982644419\n",
      "      - -224634.27693243886\n",
      "      - -231526.55779925158\n",
      "      - -227423.28042539657\n",
      "      - -224660.6890631519\n",
      "      - -234250.33579339372\n",
      "      - -228950.55267273705\n",
      "      - -227296.08516255423\n",
      "      - -225194.4427764171\n",
      "      - -268792.7847169141\n",
      "      - -226009.3335418548\n",
      "      - -225967.39000507063\n",
      "      - -233932.71920402293\n",
      "      - -220755.73990876225\n",
      "      - -220696.8960407937\n",
      "      - -229215.64481248785\n",
      "      - -216948.90200099515\n",
      "      - -226237.30084375432\n",
      "      - -226030.85273352358\n",
      "      - -216916.29855104053\n",
      "      - -232395.62978064618\n",
      "      - -238780.51953535803\n",
      "      - -229405.41170979736\n",
      "      - -226184.86302635528\n",
      "      - -224017.4407880011\n",
      "      - -224336.08592262512\n",
      "      - -224426.3206282182\n",
      "      - -230062.04232576757\n",
      "      - -229903.45833225816\n",
      "      - -272069.9775234155\n",
      "      - -219716.3256026832\n",
      "      - -223729.8912820558\n",
      "      - -220014.9717163478\n",
      "      - -252484.46319205788\n",
      "      - -228114.1557016991\n",
      "      - -228422.7296968684\n",
      "      - -227763.91504212833\n",
      "      - -228897.19496100862\n",
      "      - -225452.8092574844\n",
      "      - -219535.8760332415\n",
      "      - -221139.42580855987\n",
      "      - -227682.95988559103\n",
      "      - -217850.05119393757\n",
      "      - -227931.78400975434\n",
      "      - -239609.30351602664\n",
      "      - -224292.3313208041\n",
      "      - -224683.5156270569\n",
      "      - -222536.8319277526\n",
      "      - -223810.5298753228\n",
      "      - -232478.5262729912\n",
      "      - -227839.4860243586\n",
      "      - -221064.62323282563\n",
      "      - -234265.50570449565\n",
      "      - -230087.22223920518\n",
      "      - -228188.985223732\n",
      "      - -225952.56313182082\n",
      "      - -225194.09470027668\n",
      "      - -236706.2861787833\n",
      "      - -223703.04213895285\n",
      "      - -248092.2476449311\n",
      "      - -227048.54055053453\n",
      "      - -225185.2854002109\n",
      "      - -218125.7372099976\n",
      "      - -232002.84846165217\n",
      "      - -237037.48524936472\n",
      "      - -235409.0892488742\n",
      "      - -230234.5502704448\n",
      "      - -225435.9589538937\n",
      "      - -231598.64731751083\n",
      "      - -222762.10922537197\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.10630772009094859\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5041910156474847\n",
      "      mean_inference_ms: 1.0852848555485002\n",
      "      mean_raw_obs_processing_ms: 0.14686267890941543\n",
      "  time_since_restore: 169.14257764816284\n",
      "  time_this_iter_s: 9.612314939498901\n",
      "  time_total_s: 169.14257764816284\n",
      "  timers:\n",
      "    learn_throughput: 125911.05\n",
      "    learn_time_ms: 508.168\n",
      "    load_throughput: 22180302.092\n",
      "    load_time_ms: 2.885\n",
      "    training_iteration_time_ms: 9902.339\n",
      "    update_time_ms: 4.035\n",
      "  timestamp: 1665848911\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1023744\n",
      "  training_iteration: 16\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:48:36 (running for 00:03:11.32)<br>Memory usage on this node: 13.1/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         169.143</td><td style=\"text-align: right;\">1023744</td><td style=\"text-align: right;\"> -229190</td><td style=\"text-align: right;\">             -215026</td><td style=\"text-align: right;\">             -272070</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 1087728\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 1087728\n",
      "    num_agent_steps_trained: 1087728\n",
      "    num_env_steps_sampled: 1087728\n",
      "    num_env_steps_trained: 1087728\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-48-41\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -217004.65725689786\n",
      "  episode_reward_mean: -227495.07538480364\n",
      "  episode_reward_min: -288548.9399285115\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 1080\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.246861457824707\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0003689402947202325\n",
      "          model: {}\n",
      "          policy_loss: 0.006923971232026815\n",
      "          total_loss: 10.006673812866211\n",
      "          vf_explained_var: 9.461055050508094e-09\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 1087728\n",
      "    num_agent_steps_trained: 1087728\n",
      "    num_env_steps_sampled: 1087728\n",
      "    num_env_steps_trained: 1087728\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 1087728\n",
      "  num_agent_steps_trained: 1087728\n",
      "  num_env_steps_sampled: 1087728\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 1087728\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.06153846153846\n",
      "    ram_util_percent: 85.03846153846152\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10593694837869176\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5019885427114286\n",
      "    mean_inference_ms: 1.0754317941635712\n",
      "    mean_raw_obs_processing_ms: 0.14633210647437978\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -217004.65725689786\n",
      "    episode_reward_mean: -227495.07538480364\n",
      "    episode_reward_min: -288548.9399285115\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -219716.3256026832\n",
      "      - -223729.8912820558\n",
      "      - -220014.9717163478\n",
      "      - -252484.46319205788\n",
      "      - -228114.1557016991\n",
      "      - -228422.7296968684\n",
      "      - -227763.91504212833\n",
      "      - -228897.19496100862\n",
      "      - -225452.8092574844\n",
      "      - -219535.8760332415\n",
      "      - -221139.42580855987\n",
      "      - -227682.95988559103\n",
      "      - -217850.05119393757\n",
      "      - -227931.78400975434\n",
      "      - -239609.30351602664\n",
      "      - -224292.3313208041\n",
      "      - -224683.5156270569\n",
      "      - -222536.8319277526\n",
      "      - -223810.5298753228\n",
      "      - -232478.5262729912\n",
      "      - -227839.4860243586\n",
      "      - -221064.62323282563\n",
      "      - -234265.50570449565\n",
      "      - -230087.22223920518\n",
      "      - -228188.985223732\n",
      "      - -225952.56313182082\n",
      "      - -225194.09470027668\n",
      "      - -236706.2861787833\n",
      "      - -223703.04213895285\n",
      "      - -248092.2476449311\n",
      "      - -227048.54055053453\n",
      "      - -225185.2854002109\n",
      "      - -218125.7372099976\n",
      "      - -232002.84846165217\n",
      "      - -237037.48524936472\n",
      "      - -235409.0892488742\n",
      "      - -230234.5502704448\n",
      "      - -225435.9589538937\n",
      "      - -231598.64731751083\n",
      "      - -222762.10922537197\n",
      "      - -227016.87748598863\n",
      "      - -228255.87963884478\n",
      "      - -225095.38471453762\n",
      "      - -220465.20077244486\n",
      "      - -223790.6540365423\n",
      "      - -227413.35698302515\n",
      "      - -222783.74099549206\n",
      "      - -222516.29349285693\n",
      "      - -231407.6348316864\n",
      "      - -221449.1419115729\n",
      "      - -221000.38009320476\n",
      "      - -221442.2011852991\n",
      "      - -218068.39275440705\n",
      "      - -231340.62432039803\n",
      "      - -221290.421068831\n",
      "      - -228885.24007766467\n",
      "      - -220570.07091923195\n",
      "      - -231518.26524216036\n",
      "      - -222801.40704285\n",
      "      - -226281.6215515918\n",
      "      - -218030.48959597867\n",
      "      - -226120.86953833365\n",
      "      - -219042.23316238087\n",
      "      - -223436.79501249205\n",
      "      - -222607.5968896308\n",
      "      - -237185.79130112904\n",
      "      - -226849.24393501855\n",
      "      - -288548.9399285115\n",
      "      - -217004.65725689786\n",
      "      - -234172.7680770777\n",
      "      - -227459.41300707302\n",
      "      - -222215.56111442755\n",
      "      - -231880.8974470464\n",
      "      - -221017.0682460563\n",
      "      - -223824.48392700328\n",
      "      - -231578.76091175142\n",
      "      - -222714.7470529699\n",
      "      - -220680.206734152\n",
      "      - -222543.55739252488\n",
      "      - -225990.14109209753\n",
      "      - -225720.80896985103\n",
      "      - -226379.99114994425\n",
      "      - -218228.69643407562\n",
      "      - -225574.77659539142\n",
      "      - -228812.87957978778\n",
      "      - -225436.43187482326\n",
      "      - -223748.88940185553\n",
      "      - -226249.80423604124\n",
      "      - -232139.09961368065\n",
      "      - -260258.55154848567\n",
      "      - -219114.483053792\n",
      "      - -227425.3123909804\n",
      "      - -228323.26652073374\n",
      "      - -224316.75239062824\n",
      "      - -234526.38827433914\n",
      "      - -224781.90163160514\n",
      "      - -222168.54656505198\n",
      "      - -226478.37922776095\n",
      "      - -247827.57928858642\n",
      "      - -223616.088961154\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.10593694837869176\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5019885427114286\n",
      "      mean_inference_ms: 1.0754317941635712\n",
      "      mean_raw_obs_processing_ms: 0.14633210647437978\n",
      "  time_since_restore: 178.3144669532776\n",
      "  time_this_iter_s: 9.171889305114746\n",
      "  time_total_s: 178.3144669532776\n",
      "  timers:\n",
      "    learn_throughput: 121955.002\n",
      "    learn_time_ms: 524.653\n",
      "    load_throughput: 22096113.551\n",
      "    load_time_ms: 2.896\n",
      "    training_iteration_time_ms: 9759.126\n",
      "    update_time_ms: 4.15\n",
      "  timestamp: 1665848921\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1087728\n",
      "  training_iteration: 17\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:48:46 (running for 00:03:20.57)<br>Memory usage on this node: 13.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         178.314</td><td style=\"text-align: right;\">1087728</td><td style=\"text-align: right;\"> -227495</td><td style=\"text-align: right;\">             -217005</td><td style=\"text-align: right;\">             -288549</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:48:51 (running for 00:03:25.58)<br>Memory usage on this node: 13.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         178.314</td><td style=\"text-align: right;\">1087728</td><td style=\"text-align: right;\"> -227495</td><td style=\"text-align: right;\">             -217005</td><td style=\"text-align: right;\">             -288549</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 1151712\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 1151712\n",
      "    num_agent_steps_trained: 1151712\n",
      "    num_env_steps_sampled: 1151712\n",
      "    num_env_steps_trained: 1151712\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-48-51\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -215330.53208459052\n",
      "  episode_reward_mean: -227654.6524875302\n",
      "  episode_reward_min: -288548.9399285115\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 1140\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.2423136234283447\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0004922968801110983\n",
      "          model: {}\n",
      "          policy_loss: -0.005687123164534569\n",
      "          total_loss: 9.994086265563965\n",
      "          vf_explained_var: -9.461055050508094e-09\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 1151712\n",
      "    num_agent_steps_trained: 1151712\n",
      "    num_env_steps_sampled: 1151712\n",
      "    num_env_steps_trained: 1151712\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 1151712\n",
      "  num_agent_steps_trained: 1151712\n",
      "  num_env_steps_sampled: 1151712\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 1151712\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 88.77857142857142\n",
      "    ram_util_percent: 85.67142857142856\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10557516726057908\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5020133494998705\n",
      "    mean_inference_ms: 1.0711459040161444\n",
      "    mean_raw_obs_processing_ms: 0.14633803877518925\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -215330.53208459052\n",
      "    episode_reward_mean: -227654.6524875302\n",
      "    episode_reward_min: -288548.9399285115\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -218030.48959597867\n",
      "      - -226120.86953833365\n",
      "      - -219042.23316238087\n",
      "      - -223436.79501249205\n",
      "      - -222607.5968896308\n",
      "      - -237185.79130112904\n",
      "      - -226849.24393501855\n",
      "      - -288548.9399285115\n",
      "      - -217004.65725689786\n",
      "      - -234172.7680770777\n",
      "      - -227459.41300707302\n",
      "      - -222215.56111442755\n",
      "      - -231880.8974470464\n",
      "      - -221017.0682460563\n",
      "      - -223824.48392700328\n",
      "      - -231578.76091175142\n",
      "      - -222714.7470529699\n",
      "      - -220680.206734152\n",
      "      - -222543.55739252488\n",
      "      - -225990.14109209753\n",
      "      - -225720.80896985103\n",
      "      - -226379.99114994425\n",
      "      - -218228.69643407562\n",
      "      - -225574.77659539142\n",
      "      - -228812.87957978778\n",
      "      - -225436.43187482326\n",
      "      - -223748.88940185553\n",
      "      - -226249.80423604124\n",
      "      - -232139.09961368065\n",
      "      - -260258.55154848567\n",
      "      - -219114.483053792\n",
      "      - -227425.3123909804\n",
      "      - -228323.26652073374\n",
      "      - -224316.75239062824\n",
      "      - -234526.38827433914\n",
      "      - -224781.90163160514\n",
      "      - -222168.54656505198\n",
      "      - -226478.37922776095\n",
      "      - -247827.57928858642\n",
      "      - -223616.088961154\n",
      "      - -231840.88169765242\n",
      "      - -242856.7765484186\n",
      "      - -226831.53653957474\n",
      "      - -215756.29862534927\n",
      "      - -225559.4599855142\n",
      "      - -222787.2543793861\n",
      "      - -220982.88421785715\n",
      "      - -227501.66719622543\n",
      "      - -217348.39933489883\n",
      "      - -228456.9563841913\n",
      "      - -221797.77200047747\n",
      "      - -228692.28555210726\n",
      "      - -221912.60838504456\n",
      "      - -236371.21042156764\n",
      "      - -215330.53208459052\n",
      "      - -220814.11920891874\n",
      "      - -224828.08010155163\n",
      "      - -240323.15862207132\n",
      "      - -232366.19531417257\n",
      "      - -227789.87027389178\n",
      "      - -227083.2245307989\n",
      "      - -231314.6166904066\n",
      "      - -223552.41001293182\n",
      "      - -222035.41925618576\n",
      "      - -223560.68390888747\n",
      "      - -225050.32990754856\n",
      "      - -232281.14337915482\n",
      "      - -228568.54526869682\n",
      "      - -227354.8799378289\n",
      "      - -222392.53854476492\n",
      "      - -228220.26528854138\n",
      "      - -241596.58427176008\n",
      "      - -227871.19347981288\n",
      "      - -225039.5201416184\n",
      "      - -221280.64939512924\n",
      "      - -224979.99623973385\n",
      "      - -232337.06886478484\n",
      "      - -229799.27987870036\n",
      "      - -218331.79905677057\n",
      "      - -223065.27194697436\n",
      "      - -223142.74767167447\n",
      "      - -233472.7435413739\n",
      "      - -249181.59864766663\n",
      "      - -227903.26985678193\n",
      "      - -230707.59339326655\n",
      "      - -226021.04031484996\n",
      "      - -227497.8052405515\n",
      "      - -223750.18096555013\n",
      "      - -225949.11697683393\n",
      "      - -220197.95857649407\n",
      "      - -220883.96471852672\n",
      "      - -219853.86524783506\n",
      "      - -227876.76538849314\n",
      "      - -234968.88278724608\n",
      "      - -227489.1639799495\n",
      "      - -224417.2486411638\n",
      "      - -237041.82903510475\n",
      "      - -229120.20714193545\n",
      "      - -228943.63571571285\n",
      "      - -227149.41470639783\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.10557516726057908\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5020133494998705\n",
      "      mean_inference_ms: 1.0711459040161444\n",
      "      mean_raw_obs_processing_ms: 0.14633803877518925\n",
      "  time_since_restore: 188.74782395362854\n",
      "  time_this_iter_s: 10.433357000350952\n",
      "  time_total_s: 188.74782395362854\n",
      "  timers:\n",
      "    learn_throughput: 120192.02\n",
      "    learn_time_ms: 532.348\n",
      "    load_throughput: 22367384.036\n",
      "    load_time_ms: 2.861\n",
      "    training_iteration_time_ms: 9676.434\n",
      "    update_time_ms: 4.129\n",
      "  timestamp: 1665848931\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1151712\n",
      "  training_iteration: 18\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:48:56 (running for 00:03:31.22)<br>Memory usage on this node: 13.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         188.748</td><td style=\"text-align: right;\">1151712</td><td style=\"text-align: right;\"> -227655</td><td style=\"text-align: right;\">             -215331</td><td style=\"text-align: right;\">             -288549</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 1215696\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 1215696\n",
      "    num_agent_steps_trained: 1215696\n",
      "    num_env_steps_sampled: 1215696\n",
      "    num_env_steps_trained: 1215696\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-49-00\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -212798.09276124195\n",
      "  episode_reward_mean: -226976.1396636184\n",
      "  episode_reward_min: -273072.189932048\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 1212\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.246368169784546\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0003787105088122189\n",
      "          model: {}\n",
      "          policy_loss: 0.006922560278326273\n",
      "          total_loss: 10.006672859191895\n",
      "          vf_explained_var: -9.461055272552699e-10\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 1215696\n",
      "    num_agent_steps_trained: 1215696\n",
      "    num_env_steps_sampled: 1215696\n",
      "    num_env_steps_trained: 1215696\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 1215696\n",
      "  num_agent_steps_trained: 1215696\n",
      "  num_env_steps_sampled: 1215696\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 1215696\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 78.52307692307691\n",
      "    ram_util_percent: 86.34615384615384\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10490891531953403\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5005953485184358\n",
      "    mean_inference_ms: 1.0658838200051282\n",
      "    mean_raw_obs_processing_ms: 0.1459350242494806\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -212798.09276124195\n",
      "    episode_reward_mean: -226976.1396636184\n",
      "    episode_reward_min: -273072.189932048\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -227871.19347981288\n",
      "      - -225039.5201416184\n",
      "      - -221280.64939512924\n",
      "      - -224979.99623973385\n",
      "      - -232337.06886478484\n",
      "      - -229799.27987870036\n",
      "      - -218331.79905677057\n",
      "      - -223065.27194697436\n",
      "      - -223142.74767167447\n",
      "      - -233472.7435413739\n",
      "      - -249181.59864766663\n",
      "      - -227903.26985678193\n",
      "      - -230707.59339326655\n",
      "      - -226021.04031484996\n",
      "      - -227497.8052405515\n",
      "      - -223750.18096555013\n",
      "      - -225949.11697683393\n",
      "      - -220197.95857649407\n",
      "      - -220883.96471852672\n",
      "      - -219853.86524783506\n",
      "      - -227876.76538849314\n",
      "      - -234968.88278724608\n",
      "      - -227489.1639799495\n",
      "      - -224417.2486411638\n",
      "      - -237041.82903510475\n",
      "      - -229120.20714193545\n",
      "      - -228943.63571571285\n",
      "      - -227149.41470639783\n",
      "      - -216360.8165120582\n",
      "      - -230687.66180623707\n",
      "      - -269698.8039858478\n",
      "      - -232696.35868309502\n",
      "      - -224205.8047281786\n",
      "      - -224225.61367376105\n",
      "      - -224688.6657883596\n",
      "      - -227553.38364206877\n",
      "      - -229962.15620066336\n",
      "      - -230327.25426320493\n",
      "      - -232910.41710024868\n",
      "      - -222254.5038074957\n",
      "      - -220411.8768257462\n",
      "      - -224531.32991092338\n",
      "      - -228678.99005288028\n",
      "      - -212798.09276124195\n",
      "      - -225814.72397111016\n",
      "      - -218915.93818788565\n",
      "      - -235195.9517999096\n",
      "      - -228068.28712994966\n",
      "      - -217880.09232900216\n",
      "      - -222518.83161952774\n",
      "      - -219871.93118996633\n",
      "      - -221983.89848484835\n",
      "      - -221198.23713994244\n",
      "      - -217783.08681572464\n",
      "      - -217750.89544970857\n",
      "      - -226938.03579722348\n",
      "      - -230182.3216347157\n",
      "      - -238311.31114419145\n",
      "      - -231420.49597017356\n",
      "      - -273072.189932048\n",
      "      - -270331.14485579234\n",
      "      - -221780.12791735874\n",
      "      - -223329.2759640794\n",
      "      - -220102.8887809698\n",
      "      - -222638.2592920486\n",
      "      - -221111.51521940413\n",
      "      - -223814.30695803443\n",
      "      - -228595.57985210695\n",
      "      - -223545.37755574798\n",
      "      - -224147.58703098958\n",
      "      - -218436.6854136387\n",
      "      - -222598.2818080826\n",
      "      - -227579.72486725854\n",
      "      - -222555.18244568937\n",
      "      - -219076.13410720447\n",
      "      - -227762.03246132008\n",
      "      - -219685.78962404854\n",
      "      - -223213.54455876705\n",
      "      - -242841.92909080902\n",
      "      - -220063.1478142713\n",
      "      - -215670.07490973608\n",
      "      - -220330.88430154455\n",
      "      - -225901.74290124065\n",
      "      - -227021.2923172454\n",
      "      - -218740.26884197455\n",
      "      - -230150.16575403608\n",
      "      - -223543.09490452672\n",
      "      - -225702.27841017334\n",
      "      - -223831.5249064705\n",
      "      - -221529.18721892752\n",
      "      - -228957.89612598636\n",
      "      - -216590.28042863644\n",
      "      - -227903.64225593436\n",
      "      - -243785.55977618246\n",
      "      - -241000.01223145507\n",
      "      - -236206.90739025545\n",
      "      - -226392.6183393285\n",
      "      - -220236.74990302324\n",
      "      - -215949.12887689835\n",
      "      - -217790.3710617735\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.10490891531953403\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5005953485184358\n",
      "      mean_inference_ms: 1.0658838200051282\n",
      "      mean_raw_obs_processing_ms: 0.1459350242494806\n",
      "  time_since_restore: 198.07763242721558\n",
      "  time_this_iter_s: 9.329808473587036\n",
      "  time_total_s: 198.07763242721558\n",
      "  timers:\n",
      "    learn_throughput: 120593.221\n",
      "    learn_time_ms: 530.577\n",
      "    load_throughput: 22523381.855\n",
      "    load_time_ms: 2.841\n",
      "    training_iteration_time_ms: 9643.871\n",
      "    update_time_ms: 4.147\n",
      "  timestamp: 1665848940\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1215696\n",
      "  training_iteration: 19\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:49:05 (running for 00:03:40.39)<br>Memory usage on this node: 13.4/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         198.078</td><td style=\"text-align: right;\">1215696</td><td style=\"text-align: right;\"> -226976</td><td style=\"text-align: right;\">             -212798</td><td style=\"text-align: right;\">             -273072</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 1279680\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 1279680\n",
      "    num_agent_steps_trained: 1279680\n",
      "    num_env_steps_sampled: 1279680\n",
      "    num_env_steps_trained: 1279680\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-49-10\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -210478.6686550575\n",
      "  episode_reward_mean: -225319.73001156942\n",
      "  episode_reward_min: -270331.14485579234\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 1272\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.243297576904297\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0004887444665655494\n",
      "          model: {}\n",
      "          policy_loss: 0.008289041928946972\n",
      "          total_loss: 10.008062362670898\n",
      "          vf_explained_var: 2.838316470743507e-09\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 1279680\n",
      "    num_agent_steps_trained: 1279680\n",
      "    num_env_steps_sampled: 1279680\n",
      "    num_env_steps_trained: 1279680\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 1279680\n",
      "  num_agent_steps_trained: 1279680\n",
      "  num_env_steps_sampled: 1279680\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 1279680\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.02857142857142\n",
      "    ram_util_percent: 87.02857142857144\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10470610573249207\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49961061564031356\n",
      "    mean_inference_ms: 1.0617004224714552\n",
      "    mean_raw_obs_processing_ms: 0.14570638965068253\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -210478.6686550575\n",
      "    episode_reward_mean: -225319.73001156942\n",
      "    episode_reward_min: -270331.14485579234\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -270331.14485579234\n",
      "      - -221780.12791735874\n",
      "      - -223329.2759640794\n",
      "      - -220102.8887809698\n",
      "      - -222638.2592920486\n",
      "      - -221111.51521940413\n",
      "      - -223814.30695803443\n",
      "      - -228595.57985210695\n",
      "      - -223545.37755574798\n",
      "      - -224147.58703098958\n",
      "      - -218436.6854136387\n",
      "      - -222598.2818080826\n",
      "      - -227579.72486725854\n",
      "      - -222555.18244568937\n",
      "      - -219076.13410720447\n",
      "      - -227762.03246132008\n",
      "      - -219685.78962404854\n",
      "      - -223213.54455876705\n",
      "      - -242841.92909080902\n",
      "      - -220063.1478142713\n",
      "      - -215670.07490973608\n",
      "      - -220330.88430154455\n",
      "      - -225901.74290124065\n",
      "      - -227021.2923172454\n",
      "      - -218740.26884197455\n",
      "      - -230150.16575403608\n",
      "      - -223543.09490452672\n",
      "      - -225702.27841017334\n",
      "      - -223831.5249064705\n",
      "      - -221529.18721892752\n",
      "      - -228957.89612598636\n",
      "      - -216590.28042863644\n",
      "      - -227903.64225593436\n",
      "      - -243785.55977618246\n",
      "      - -241000.01223145507\n",
      "      - -236206.90739025545\n",
      "      - -226392.6183393285\n",
      "      - -220236.74990302324\n",
      "      - -215949.12887689835\n",
      "      - -217790.3710617735\n",
      "      - -223214.27142213623\n",
      "      - -225566.8434480867\n",
      "      - -232102.96074708673\n",
      "      - -221841.62403341508\n",
      "      - -246600.24084439882\n",
      "      - -239229.80291349548\n",
      "      - -251240.45601838484\n",
      "      - -231326.1114350594\n",
      "      - -225927.50443070845\n",
      "      - -222314.89081636074\n",
      "      - -221459.8175179932\n",
      "      - -222806.4025399688\n",
      "      - -217554.3109340601\n",
      "      - -222541.90663713677\n",
      "      - -216965.25770320976\n",
      "      - -225097.8817660151\n",
      "      - -225564.7619263995\n",
      "      - -223233.64358775323\n",
      "      - -239021.8669286955\n",
      "      - -222942.12391883184\n",
      "      - -224797.2805340535\n",
      "      - -228749.82914880215\n",
      "      - -212915.18551411756\n",
      "      - -224018.3693573434\n",
      "      - -221898.51594155116\n",
      "      - -214032.67851104704\n",
      "      - -224369.82114865162\n",
      "      - -221465.17378428607\n",
      "      - -224913.96846010507\n",
      "      - -223739.87225233982\n",
      "      - -219240.94177882865\n",
      "      - -219300.19134219634\n",
      "      - -228012.7305172674\n",
      "      - -226243.92057884272\n",
      "      - -216478.7337056918\n",
      "      - -245497.7592519744\n",
      "      - -233426.6436842636\n",
      "      - -225619.8681337503\n",
      "      - -225388.50215825866\n",
      "      - -223159.19128678585\n",
      "      - -210478.6686550575\n",
      "      - -220836.6381642652\n",
      "      - -225336.08684755382\n",
      "      - -225424.76133330556\n",
      "      - -225430.66051728095\n",
      "      - -216379.27593242654\n",
      "      - -238664.48324682697\n",
      "      - -218362.6771383245\n",
      "      - -220739.21852286762\n",
      "      - -217783.04624952638\n",
      "      - -218720.58709401506\n",
      "      - -223874.9172142138\n",
      "      - -225789.47382016096\n",
      "      - -221710.19072914275\n",
      "      - -223411.78702456626\n",
      "      - -222330.6084227935\n",
      "      - -237392.4985946261\n",
      "      - -224872.208138918\n",
      "      - -227638.2649446771\n",
      "      - -216532.89543407198\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.10470610573249207\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.49961061564031356\n",
      "      mean_inference_ms: 1.0617004224714552\n",
      "      mean_raw_obs_processing_ms: 0.14570638965068253\n",
      "  time_since_restore: 207.98487067222595\n",
      "  time_this_iter_s: 9.907238245010376\n",
      "  time_total_s: 207.98487067222595\n",
      "  timers:\n",
      "    learn_throughput: 119539.338\n",
      "    learn_time_ms: 535.255\n",
      "    load_throughput: 22551393.422\n",
      "    load_time_ms: 2.837\n",
      "    training_iteration_time_ms: 9673.898\n",
      "    update_time_ms: 4.01\n",
      "  timestamp: 1665848950\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1279680\n",
      "  training_iteration: 20\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:49:16 (running for 00:03:50.55)<br>Memory usage on this node: 13.6/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         207.985</td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\"> -225320</td><td style=\"text-align: right;\">             -210479</td><td style=\"text-align: right;\">             -270331</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:49:21 (running for 00:03:55.55)<br>Memory usage on this node: 13.6/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         207.985</td><td style=\"text-align: right;\">1279680</td><td style=\"text-align: right;\"> -225320</td><td style=\"text-align: right;\">             -210479</td><td style=\"text-align: right;\">             -270331</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 1343664\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 1343664\n",
      "    num_agent_steps_trained: 1343664\n",
      "    num_env_steps_sampled: 1343664\n",
      "    num_env_steps_trained: 1343664\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-49-21\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -210478.6686550575\n",
      "  episode_reward_mean: -225786.88020844362\n",
      "  episode_reward_min: -277445.7807820719\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 1332\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.239436626434326\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.000743812182918191\n",
      "          model: {}\n",
      "          policy_loss: -0.0024379901587963104\n",
      "          total_loss: 9.997386932373047\n",
      "          vf_explained_var: -2.2706531765948057e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 1343664\n",
      "    num_agent_steps_trained: 1343664\n",
      "    num_env_steps_sampled: 1343664\n",
      "    num_env_steps_trained: 1343664\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 1343664\n",
      "  num_agent_steps_trained: 1343664\n",
      "  num_env_steps_sampled: 1343664\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 1343664\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 85.0142857142857\n",
      "    ram_util_percent: 87.92142857142858\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10455006427650528\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4993495076274591\n",
      "    mean_inference_ms: 1.0611361455837185\n",
      "    mean_raw_obs_processing_ms: 0.14537256703352125\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -210478.6686550575\n",
      "    episode_reward_mean: -225786.88020844362\n",
      "    episode_reward_min: -277445.7807820719\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -224797.2805340535\n",
      "      - -228749.82914880215\n",
      "      - -212915.18551411756\n",
      "      - -224018.3693573434\n",
      "      - -221898.51594155116\n",
      "      - -214032.67851104704\n",
      "      - -224369.82114865162\n",
      "      - -221465.17378428607\n",
      "      - -224913.96846010507\n",
      "      - -223739.87225233982\n",
      "      - -219240.94177882865\n",
      "      - -219300.19134219634\n",
      "      - -228012.7305172674\n",
      "      - -226243.92057884272\n",
      "      - -216478.7337056918\n",
      "      - -245497.7592519744\n",
      "      - -233426.6436842636\n",
      "      - -225619.8681337503\n",
      "      - -225388.50215825866\n",
      "      - -223159.19128678585\n",
      "      - -210478.6686550575\n",
      "      - -220836.6381642652\n",
      "      - -225336.08684755382\n",
      "      - -225424.76133330556\n",
      "      - -225430.66051728095\n",
      "      - -216379.27593242654\n",
      "      - -238664.48324682697\n",
      "      - -218362.6771383245\n",
      "      - -220739.21852286762\n",
      "      - -217783.04624952638\n",
      "      - -218720.58709401506\n",
      "      - -223874.9172142138\n",
      "      - -225789.47382016096\n",
      "      - -221710.19072914275\n",
      "      - -223411.78702456626\n",
      "      - -222330.6084227935\n",
      "      - -237392.4985946261\n",
      "      - -224872.208138918\n",
      "      - -227638.2649446771\n",
      "      - -216532.89543407198\n",
      "      - -220339.32299523978\n",
      "      - -226417.1865291823\n",
      "      - -221760.0496231877\n",
      "      - -220036.0086696038\n",
      "      - -223526.9124008457\n",
      "      - -273745.28182133514\n",
      "      - -226289.3116399258\n",
      "      - -272984.10122448887\n",
      "      - -222795.9146738301\n",
      "      - -226129.77133856414\n",
      "      - -223602.3718713294\n",
      "      - -220438.09068478373\n",
      "      - -224414.50679776867\n",
      "      - -214725.75475772817\n",
      "      - -215542.01760257024\n",
      "      - -221671.7607068211\n",
      "      - -241998.44347403973\n",
      "      - -218884.85617095785\n",
      "      - -222072.34499807123\n",
      "      - -222791.79664664727\n",
      "      - -227232.58639970818\n",
      "      - -225673.2780532449\n",
      "      - -223310.36656586037\n",
      "      - -217533.8975826843\n",
      "      - -226527.30349587815\n",
      "      - -218699.86183676645\n",
      "      - -277445.7807820719\n",
      "      - -222245.7293525032\n",
      "      - -218520.6251501189\n",
      "      - -217130.4704960012\n",
      "      - -220331.1877952101\n",
      "      - -215243.41237413112\n",
      "      - -229728.55839245592\n",
      "      - -217285.98365675632\n",
      "      - -221086.58263697007\n",
      "      - -221402.7582984095\n",
      "      - -223643.70949261409\n",
      "      - -222322.57492559004\n",
      "      - -222331.02588802832\n",
      "      - -220052.7047189509\n",
      "      - -238363.59624054434\n",
      "      - -217849.07657581946\n",
      "      - -221268.6522630341\n",
      "      - -225257.75787859262\n",
      "      - -221551.4557466311\n",
      "      - -222150.11131462187\n",
      "      - -234318.2205958351\n",
      "      - -246212.57384176765\n",
      "      - -263100.88463999605\n",
      "      - -227678.03738859162\n",
      "      - -226110.10660292162\n",
      "      - -223758.4783872895\n",
      "      - -238503.21216470344\n",
      "      - -220512.61303053744\n",
      "      - -227907.72875492446\n",
      "      - -231592.32713973802\n",
      "      - -225866.6896235065\n",
      "      - -219830.16689498877\n",
      "      - -222888.24323738035\n",
      "      - -231075.76088729218\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.10455006427650528\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4993495076274591\n",
      "      mean_inference_ms: 1.0611361455837185\n",
      "      mean_raw_obs_processing_ms: 0.14537256703352125\n",
      "  time_since_restore: 218.34984827041626\n",
      "  time_this_iter_s: 10.364977598190308\n",
      "  time_total_s: 218.34984827041626\n",
      "  timers:\n",
      "    learn_throughput: 118655.833\n",
      "    learn_time_ms: 539.24\n",
      "    load_throughput: 22337038.34\n",
      "    load_time_ms: 2.864\n",
      "    training_iteration_time_ms: 9709.121\n",
      "    update_time_ms: 4.066\n",
      "  timestamp: 1665848961\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1343664\n",
      "  training_iteration: 21\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:49:26 (running for 00:04:00.77)<br>Memory usage on this node: 13.7/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">          218.35</td><td style=\"text-align: right;\">1343664</td><td style=\"text-align: right;\"> -225787</td><td style=\"text-align: right;\">             -210479</td><td style=\"text-align: right;\">             -277446</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 1407648\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 1407648\n",
      "    num_agent_steps_trained: 1407648\n",
      "    num_env_steps_sampled: 1407648\n",
      "    num_env_steps_trained: 1407648\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-49-31\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -213593.4353700192\n",
      "  episode_reward_mean: -225550.09109216742\n",
      "  episode_reward_min: -263100.88463999605\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 1404\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.239346742630005\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.000701787939760834\n",
      "          model: {}\n",
      "          policy_loss: 0.0047050584107637405\n",
      "          total_loss: 10.004522323608398\n",
      "          vf_explained_var: -2.554484801464696e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 1407648\n",
      "    num_agent_steps_trained: 1407648\n",
      "    num_env_steps_sampled: 1407648\n",
      "    num_env_steps_trained: 1407648\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 1407648\n",
      "  num_agent_steps_trained: 1407648\n",
      "  num_env_steps_sampled: 1407648\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 1407648\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.97857142857141\n",
      "    ram_util_percent: 88.50714285714284\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10410630387799907\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4983249469461266\n",
      "    mean_inference_ms: 1.0593145111533722\n",
      "    mean_raw_obs_processing_ms: 0.14490897164034128\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -213593.4353700192\n",
      "    episode_reward_mean: -225550.09109216742\n",
      "    episode_reward_min: -263100.88463999605\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -229728.55839245592\n",
      "      - -217285.98365675632\n",
      "      - -221086.58263697007\n",
      "      - -221402.7582984095\n",
      "      - -223643.70949261409\n",
      "      - -222322.57492559004\n",
      "      - -222331.02588802832\n",
      "      - -220052.7047189509\n",
      "      - -238363.59624054434\n",
      "      - -217849.07657581946\n",
      "      - -221268.6522630341\n",
      "      - -225257.75787859262\n",
      "      - -221551.4557466311\n",
      "      - -222150.11131462187\n",
      "      - -234318.2205958351\n",
      "      - -246212.57384176765\n",
      "      - -263100.88463999605\n",
      "      - -227678.03738859162\n",
      "      - -226110.10660292162\n",
      "      - -223758.4783872895\n",
      "      - -238503.21216470344\n",
      "      - -220512.61303053744\n",
      "      - -227907.72875492446\n",
      "      - -231592.32713973802\n",
      "      - -225866.6896235065\n",
      "      - -219830.16689498877\n",
      "      - -222888.24323738035\n",
      "      - -231075.76088729218\n",
      "      - -223744.6931111929\n",
      "      - -221408.79479518064\n",
      "      - -230976.78338088517\n",
      "      - -222849.5512379697\n",
      "      - -228447.27966397617\n",
      "      - -224217.40701095667\n",
      "      - -235294.07468505765\n",
      "      - -219942.35070565616\n",
      "      - -225629.6304237564\n",
      "      - -228599.77102709888\n",
      "      - -223171.21093499375\n",
      "      - -227288.34214974867\n",
      "      - -235002.02124114847\n",
      "      - -217205.14899488355\n",
      "      - -218676.43828267112\n",
      "      - -222489.37813509366\n",
      "      - -222871.0649966206\n",
      "      - -223633.65098242435\n",
      "      - -221155.03910616747\n",
      "      - -220045.25039839215\n",
      "      - -232505.6599392077\n",
      "      - -224390.04550329995\n",
      "      - -231944.84366760385\n",
      "      - -223856.64552220065\n",
      "      - -228843.3254032209\n",
      "      - -230138.17692090242\n",
      "      - -214135.13491845358\n",
      "      - -220277.4772289775\n",
      "      - -216520.98375159892\n",
      "      - -217620.50698361738\n",
      "      - -222126.7418148425\n",
      "      - -229130.20562474386\n",
      "      - -225875.71703283078\n",
      "      - -225163.32402808487\n",
      "      - -222368.06874641677\n",
      "      - -217742.54561119305\n",
      "      - -225259.95672644873\n",
      "      - -223725.94746059392\n",
      "      - -220783.1027215875\n",
      "      - -223609.1419245059\n",
      "      - -224385.20368707847\n",
      "      - -221800.78439060907\n",
      "      - -223816.29819963258\n",
      "      - -237620.5485335443\n",
      "      - -222243.46726229176\n",
      "      - -223678.44077707638\n",
      "      - -220324.4962377093\n",
      "      - -220707.31024456734\n",
      "      - -217204.01306427794\n",
      "      - -221646.95567460288\n",
      "      - -220971.95596782476\n",
      "      - -261451.30853591944\n",
      "      - -229616.56101485976\n",
      "      - -213593.4353700192\n",
      "      - -215786.58747161017\n",
      "      - -223421.20798199615\n",
      "      - -221802.4423433305\n",
      "      - -226118.53486326593\n",
      "      - -237007.9869352257\n",
      "      - -230565.6522798566\n",
      "      - -224923.40607531933\n",
      "      - -220837.31440660905\n",
      "      - -220816.01707457512\n",
      "      - -233450.81858543976\n",
      "      - -229965.81662249303\n",
      "      - -236723.27823246762\n",
      "      - -226664.00614181216\n",
      "      - -224777.46391247006\n",
      "      - -220636.55053941102\n",
      "      - -223920.14407853864\n",
      "      - -227550.09416850642\n",
      "      - -218665.98453110456\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.10410630387799907\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4983249469461266\n",
      "      mean_inference_ms: 1.0593145111533722\n",
      "      mean_raw_obs_processing_ms: 0.14490897164034128\n",
      "  time_since_restore: 228.181569814682\n",
      "  time_this_iter_s: 9.831721544265747\n",
      "  time_total_s: 228.181569814682\n",
      "  timers:\n",
      "    learn_throughput: 119000.712\n",
      "    learn_time_ms: 537.677\n",
      "    load_throughput: 21853744.005\n",
      "    load_time_ms: 2.928\n",
      "    training_iteration_time_ms: 9731.064\n",
      "    update_time_ms: 4.162\n",
      "  timestamp: 1665848971\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1407648\n",
      "  training_iteration: 22\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:49:36 (running for 00:04:10.57)<br>Memory usage on this node: 13.7/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         228.182</td><td style=\"text-align: right;\">1407648</td><td style=\"text-align: right;\"> -225550</td><td style=\"text-align: right;\">             -213593</td><td style=\"text-align: right;\">             -263101</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 1471632\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 1471632\n",
      "    num_agent_steps_trained: 1471632\n",
      "    num_env_steps_sampled: 1471632\n",
      "    num_env_steps_trained: 1471632\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-49-40\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -210354.47477439442\n",
      "  episode_reward_mean: -224948.31110643188\n",
      "  episode_reward_min: -261451.30853591944\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 1464\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.239452838897705\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.000430287909694016\n",
      "          model: {}\n",
      "          policy_loss: 0.007540999911725521\n",
      "          total_loss: 10.007303237915039\n",
      "          vf_explained_var: 6.622738357719982e-09\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 1471632\n",
      "    num_agent_steps_trained: 1471632\n",
      "    num_env_steps_sampled: 1471632\n",
      "    num_env_steps_trained: 1471632\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 1471632\n",
      "  num_agent_steps_trained: 1471632\n",
      "  num_env_steps_sampled: 1471632\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 1471632\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.94285714285714\n",
      "    ram_util_percent: 88.75714285714285\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1039153094867622\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49712496938626927\n",
      "    mean_inference_ms: 1.0563933184775431\n",
      "    mean_raw_obs_processing_ms: 0.1447705718761437\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -210354.47477439442\n",
      "    episode_reward_mean: -224948.31110643188\n",
      "    episode_reward_min: -261451.30853591944\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -225875.71703283078\n",
      "      - -225163.32402808487\n",
      "      - -222368.06874641677\n",
      "      - -217742.54561119305\n",
      "      - -225259.95672644873\n",
      "      - -223725.94746059392\n",
      "      - -220783.1027215875\n",
      "      - -223609.1419245059\n",
      "      - -224385.20368707847\n",
      "      - -221800.78439060907\n",
      "      - -223816.29819963258\n",
      "      - -237620.5485335443\n",
      "      - -222243.46726229176\n",
      "      - -223678.44077707638\n",
      "      - -220324.4962377093\n",
      "      - -220707.31024456734\n",
      "      - -217204.01306427794\n",
      "      - -221646.95567460288\n",
      "      - -220971.95596782476\n",
      "      - -261451.30853591944\n",
      "      - -229616.56101485976\n",
      "      - -213593.4353700192\n",
      "      - -215786.58747161017\n",
      "      - -223421.20798199615\n",
      "      - -221802.4423433305\n",
      "      - -226118.53486326593\n",
      "      - -237007.9869352257\n",
      "      - -230565.6522798566\n",
      "      - -224923.40607531933\n",
      "      - -220837.31440660905\n",
      "      - -220816.01707457512\n",
      "      - -233450.81858543976\n",
      "      - -229965.81662249303\n",
      "      - -236723.27823246762\n",
      "      - -226664.00614181216\n",
      "      - -224777.46391247006\n",
      "      - -220636.55053941102\n",
      "      - -223920.14407853864\n",
      "      - -227550.09416850642\n",
      "      - -218665.98453110456\n",
      "      - -233640.12202371802\n",
      "      - -236145.83835533637\n",
      "      - -223084.73994041406\n",
      "      - -222491.28963099397\n",
      "      - -217967.63189453335\n",
      "      - -224484.060012715\n",
      "      - -223512.30350710472\n",
      "      - -225734.15263467433\n",
      "      - -222183.588060148\n",
      "      - -221607.4476410805\n",
      "      - -226047.56318073266\n",
      "      - -224745.82764167522\n",
      "      - -218144.80790012042\n",
      "      - -220537.3820734483\n",
      "      - -217932.05943989527\n",
      "      - -218342.943415369\n",
      "      - -227352.7968241895\n",
      "      - -217101.0185361305\n",
      "      - -222156.06017603807\n",
      "      - -229128.1393487578\n",
      "      - -223308.3490228083\n",
      "      - -234305.80317736452\n",
      "      - -221732.63999629556\n",
      "      - -223773.2383103041\n",
      "      - -227841.84857066412\n",
      "      - -225326.21301610838\n",
      "      - -219717.7851006789\n",
      "      - -225345.6901696885\n",
      "      - -231987.4105901287\n",
      "      - -228017.1635746577\n",
      "      - -252272.12381379597\n",
      "      - -226779.1749231774\n",
      "      - -220050.81064999508\n",
      "      - -226418.5009021835\n",
      "      - -222295.1022645169\n",
      "      - -210354.47477439442\n",
      "      - -230767.2386571455\n",
      "      - -230879.28269077433\n",
      "      - -214973.38762420084\n",
      "      - -226823.8566420657\n",
      "      - -230185.81638895703\n",
      "      - -224123.23784217914\n",
      "      - -222276.7623120655\n",
      "      - -216912.66765869223\n",
      "      - -217490.65993977894\n",
      "      - -225799.35124883545\n",
      "      - -226692.29130745816\n",
      "      - -222513.36091040654\n",
      "      - -217316.15575605494\n",
      "      - -218381.69430830787\n",
      "      - -234175.6841702297\n",
      "      - -220469.910327296\n",
      "      - -226750.03009705298\n",
      "      - -219616.96924707113\n",
      "      - -226245.33171140568\n",
      "      - -240267.1996629464\n",
      "      - -225783.7326444114\n",
      "      - -230075.3520661864\n",
      "      - -228662.38794413878\n",
      "      - -218560.758935983\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1039153094867622\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.49712496938626927\n",
      "      mean_inference_ms: 1.0563933184775431\n",
      "      mean_raw_obs_processing_ms: 0.1447705718761437\n",
      "  time_since_restore: 237.8067502975464\n",
      "  time_this_iter_s: 9.62518048286438\n",
      "  time_total_s: 237.8067502975464\n",
      "  timers:\n",
      "    learn_throughput: 118688.594\n",
      "    learn_time_ms: 539.091\n",
      "    load_throughput: 21739736.171\n",
      "    load_time_ms: 2.943\n",
      "    training_iteration_time_ms: 9738.708\n",
      "    update_time_ms: 4.067\n",
      "  timestamp: 1665848980\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1471632\n",
      "  training_iteration: 23\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:49:46 (running for 00:04:20.51)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         237.807</td><td style=\"text-align: right;\">1471632</td><td style=\"text-align: right;\"> -224948</td><td style=\"text-align: right;\">             -210354</td><td style=\"text-align: right;\">             -261451</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 1535616\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 1535616\n",
      "    num_agent_steps_trained: 1535616\n",
      "    num_env_steps_sampled: 1535616\n",
      "    num_env_steps_trained: 1535616\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-49-50\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -210354.47477439442\n",
      "  episode_reward_mean: -224519.8953894821\n",
      "  episode_reward_min: -252272.12381379597\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 1524\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.2424488067626953\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00039378658402711153\n",
      "          model: {}\n",
      "          policy_loss: -0.004268104210495949\n",
      "          total_loss: 9.995485305786133\n",
      "          vf_explained_var: -4.257474728319721e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 1535616\n",
      "    num_agent_steps_trained: 1535616\n",
      "    num_env_steps_sampled: 1535616\n",
      "    num_env_steps_trained: 1535616\n",
      "  iterations_since_restore: 24\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 1535616\n",
      "  num_agent_steps_trained: 1535616\n",
      "  num_env_steps_sampled: 1535616\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 1535616\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.16153846153847\n",
      "    ram_util_percent: 89.01538461538463\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10350197570619114\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49616886079769296\n",
      "    mean_inference_ms: 1.0534081751455036\n",
      "    mean_raw_obs_processing_ms: 0.14432224371623786\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -210354.47477439442\n",
      "    episode_reward_mean: -224519.8953894821\n",
      "    episode_reward_min: -252272.12381379597\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -223308.3490228083\n",
      "      - -234305.80317736452\n",
      "      - -221732.63999629556\n",
      "      - -223773.2383103041\n",
      "      - -227841.84857066412\n",
      "      - -225326.21301610838\n",
      "      - -219717.7851006789\n",
      "      - -225345.6901696885\n",
      "      - -231987.4105901287\n",
      "      - -228017.1635746577\n",
      "      - -252272.12381379597\n",
      "      - -226779.1749231774\n",
      "      - -220050.81064999508\n",
      "      - -226418.5009021835\n",
      "      - -222295.1022645169\n",
      "      - -210354.47477439442\n",
      "      - -230767.2386571455\n",
      "      - -230879.28269077433\n",
      "      - -214973.38762420084\n",
      "      - -226823.8566420657\n",
      "      - -230185.81638895703\n",
      "      - -224123.23784217914\n",
      "      - -222276.7623120655\n",
      "      - -216912.66765869223\n",
      "      - -217490.65993977894\n",
      "      - -225799.35124883545\n",
      "      - -226692.29130745816\n",
      "      - -222513.36091040654\n",
      "      - -217316.15575605494\n",
      "      - -218381.69430830787\n",
      "      - -234175.6841702297\n",
      "      - -220469.910327296\n",
      "      - -226750.03009705298\n",
      "      - -219616.96924707113\n",
      "      - -226245.33171140568\n",
      "      - -240267.1996629464\n",
      "      - -225783.7326444114\n",
      "      - -230075.3520661864\n",
      "      - -228662.38794413878\n",
      "      - -218560.758935983\n",
      "      - -217455.83281800986\n",
      "      - -228488.443271727\n",
      "      - -226509.534431473\n",
      "      - -224337.89912437572\n",
      "      - -229262.6430109326\n",
      "      - -219344.9154985802\n",
      "      - -217819.11373403436\n",
      "      - -225458.48391280632\n",
      "      - -220974.2169576043\n",
      "      - -221811.45034721505\n",
      "      - -225110.26333603566\n",
      "      - -228279.55181476512\n",
      "      - -230275.35534829207\n",
      "      - -225095.93828429165\n",
      "      - -224467.93288971274\n",
      "      - -230011.4911847326\n",
      "      - -224106.11898978738\n",
      "      - -226153.83581226316\n",
      "      - -230827.63375437591\n",
      "      - -215249.79213926973\n",
      "      - -213255.65918101204\n",
      "      - -222808.17534437697\n",
      "      - -222960.5447604948\n",
      "      - -214694.0018625184\n",
      "      - -216319.6421046075\n",
      "      - -222192.684988992\n",
      "      - -219591.78958795537\n",
      "      - -222440.7840150532\n",
      "      - -227335.04387140967\n",
      "      - -213621.17235422521\n",
      "      - -223331.2153925514\n",
      "      - -224323.73097862213\n",
      "      - -222069.69169268614\n",
      "      - -224719.6556554688\n",
      "      - -228133.6653401335\n",
      "      - -222343.70136420403\n",
      "      - -230381.7865040947\n",
      "      - -221334.77676652875\n",
      "      - -225938.56503847236\n",
      "      - -221800.21215310713\n",
      "      - -228799.97195879475\n",
      "      - -229389.4652137707\n",
      "      - -227747.09284461924\n",
      "      - -220753.5402659068\n",
      "      - -230322.60628045967\n",
      "      - -224719.0263923342\n",
      "      - -219141.39127490052\n",
      "      - -229151.79430020435\n",
      "      - -219251.7162225968\n",
      "      - -248234.05069006156\n",
      "      - -223602.1413320396\n",
      "      - -221400.98553411957\n",
      "      - -222445.85097193762\n",
      "      - -227254.00508510292\n",
      "      - -227479.927824391\n",
      "      - -221495.46261447057\n",
      "      - -220291.54692942038\n",
      "      - -223886.53257880165\n",
      "      - -221786.35104603865\n",
      "      - -218929.68502103898\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.10350197570619114\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.49616886079769296\n",
      "      mean_inference_ms: 1.0534081751455036\n",
      "      mean_raw_obs_processing_ms: 0.14432224371623786\n",
      "  time_since_restore: 247.34751081466675\n",
      "  time_this_iter_s: 9.540760517120361\n",
      "  time_total_s: 247.34751081466675\n",
      "  timers:\n",
      "    learn_throughput: 120247.969\n",
      "    learn_time_ms: 532.1\n",
      "    load_throughput: 21598366.824\n",
      "    load_time_ms: 2.962\n",
      "    training_iteration_time_ms: 9734.345\n",
      "    update_time_ms: 4.117\n",
      "  timestamp: 1665848990\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1535616\n",
      "  training_iteration: 24\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:49:55 (running for 00:04:29.85)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         247.348</td><td style=\"text-align: right;\">1535616</td><td style=\"text-align: right;\"> -224520</td><td style=\"text-align: right;\">             -210354</td><td style=\"text-align: right;\">             -252272</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 1599600\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 1599600\n",
      "    num_agent_steps_trained: 1599600\n",
      "    num_env_steps_sampled: 1599600\n",
      "    num_env_steps_trained: 1599600\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-49-59\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -209076.2528495645\n",
      "  episode_reward_mean: -225332.91215697798\n",
      "  episode_reward_min: -260155.72701965988\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 1596\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.2365453243255615\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0004526094126049429\n",
      "          model: {}\n",
      "          policy_loss: 0.005908408667892218\n",
      "          total_loss: 10.005674362182617\n",
      "          vf_explained_var: -3.311369312086754e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 1599600\n",
      "    num_agent_steps_trained: 1599600\n",
      "    num_env_steps_sampled: 1599600\n",
      "    num_env_steps_trained: 1599600\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 1599600\n",
      "  num_agent_steps_trained: 1599600\n",
      "  num_env_steps_sampled: 1599600\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 1599600\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.89285714285714\n",
      "    ram_util_percent: 88.99285714285715\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10301864576201401\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49491083834473415\n",
      "    mean_inference_ms: 1.0493778528479254\n",
      "    mean_raw_obs_processing_ms: 0.14377087875681072\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -209076.2528495645\n",
      "    episode_reward_mean: -225332.91215697798\n",
      "    episode_reward_min: -260155.72701965988\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -222069.69169268614\n",
      "      - -224719.6556554688\n",
      "      - -228133.6653401335\n",
      "      - -222343.70136420403\n",
      "      - -230381.7865040947\n",
      "      - -221334.77676652875\n",
      "      - -225938.56503847236\n",
      "      - -221800.21215310713\n",
      "      - -228799.97195879475\n",
      "      - -229389.4652137707\n",
      "      - -227747.09284461924\n",
      "      - -220753.5402659068\n",
      "      - -230322.60628045967\n",
      "      - -224719.0263923342\n",
      "      - -219141.39127490052\n",
      "      - -229151.79430020435\n",
      "      - -219251.7162225968\n",
      "      - -248234.05069006156\n",
      "      - -223602.1413320396\n",
      "      - -221400.98553411957\n",
      "      - -222445.85097193762\n",
      "      - -227254.00508510292\n",
      "      - -227479.927824391\n",
      "      - -221495.46261447057\n",
      "      - -220291.54692942038\n",
      "      - -223886.53257880165\n",
      "      - -221786.35104603865\n",
      "      - -218929.68502103898\n",
      "      - -222994.45499323405\n",
      "      - -225898.10198740783\n",
      "      - -229035.06179465566\n",
      "      - -227635.06009466396\n",
      "      - -227053.0258005599\n",
      "      - -219307.87905452322\n",
      "      - -218833.5476618119\n",
      "      - -227774.13650343445\n",
      "      - -214668.4593104145\n",
      "      - -226082.42285252552\n",
      "      - -221584.9778856553\n",
      "      - -228443.2295698911\n",
      "      - -221071.27818823466\n",
      "      - -227196.84168760545\n",
      "      - -222494.28818080635\n",
      "      - -225237.6371243956\n",
      "      - -222473.50447016757\n",
      "      - -209076.2528495645\n",
      "      - -247504.80713097122\n",
      "      - -226011.52334211222\n",
      "      - -245016.77487544407\n",
      "      - -226161.1857456095\n",
      "      - -222617.3918797097\n",
      "      - -221034.81495012488\n",
      "      - -231306.5950033969\n",
      "      - -232758.69427453153\n",
      "      - -227701.50719194155\n",
      "      - -220460.27195687918\n",
      "      - -238896.24893615226\n",
      "      - -223102.5806205841\n",
      "      - -218955.20227458727\n",
      "      - -230234.60757331547\n",
      "      - -218230.7640699774\n",
      "      - -222491.27907719344\n",
      "      - -236612.7097568355\n",
      "      - -221120.7606568975\n",
      "      - -223092.9041380901\n",
      "      - -226844.56306206304\n",
      "      - -233249.09257453145\n",
      "      - -217861.12764156313\n",
      "      - -216240.1416634777\n",
      "      - -220194.96286851197\n",
      "      - -219712.79033062686\n",
      "      - -221969.11498015825\n",
      "      - -225390.70230173343\n",
      "      - -224568.47046202354\n",
      "      - -225687.4288270904\n",
      "      - -220905.15353840502\n",
      "      - -260155.72701965988\n",
      "      - -224011.8145866995\n",
      "      - -233509.5772591161\n",
      "      - -222146.13823478724\n",
      "      - -222088.15527076606\n",
      "      - -219323.4526647933\n",
      "      - -225324.26211981534\n",
      "      - -216251.45372883574\n",
      "      - -226998.34029059825\n",
      "      - -251123.9256346866\n",
      "      - -226137.79994114564\n",
      "      - -227011.4050571731\n",
      "      - -218144.21400956681\n",
      "      - -221534.71249576285\n",
      "      - -230285.0756086492\n",
      "      - -219406.89095794974\n",
      "      - -218583.23683267282\n",
      "      - -219308.99504824716\n",
      "      - -234977.97538781565\n",
      "      - -218791.62121294448\n",
      "      - -229950.2903845456\n",
      "      - -226112.4539435598\n",
      "      - -216949.5781563856\n",
      "      - -219564.58924182702\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.10301864576201401\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.49491083834473415\n",
      "      mean_inference_ms: 1.0493778528479254\n",
      "      mean_raw_obs_processing_ms: 0.14377087875681072\n",
      "  time_since_restore: 256.9155330657959\n",
      "  time_this_iter_s: 9.56802225112915\n",
      "  time_total_s: 256.9155330657959\n",
      "  timers:\n",
      "    learn_throughput: 119940.903\n",
      "    learn_time_ms: 533.463\n",
      "    load_throughput: 21694746.013\n",
      "    load_time_ms: 2.949\n",
      "    training_iteration_time_ms: 9731.259\n",
      "    update_time_ms: 4.031\n",
      "  timestamp: 1665848999\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1599600\n",
      "  training_iteration: 25\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:50:05 (running for 00:04:39.65)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         256.916</td><td style=\"text-align: right;\">1599600</td><td style=\"text-align: right;\"> -225333</td><td style=\"text-align: right;\">             -209076</td><td style=\"text-align: right;\">             -260156</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 1663584\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 1663584\n",
      "    num_agent_steps_trained: 1663584\n",
      "    num_env_steps_sampled: 1663584\n",
      "    num_env_steps_trained: 1663584\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-50-09\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -214630.2204302724\n",
      "  episode_reward_mean: -224623.45794437767\n",
      "  episode_reward_min: -291711.94014148135\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 1656\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.231076955795288\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00028687724261544645\n",
      "          model: {}\n",
      "          policy_loss: 0.008890391327440739\n",
      "          total_loss: 10.008624076843262\n",
      "          vf_explained_var: -1.797600468478322e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 1663584\n",
      "    num_agent_steps_trained: 1663584\n",
      "    num_env_steps_sampled: 1663584\n",
      "    num_env_steps_trained: 1663584\n",
      "  iterations_since_restore: 26\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 1663584\n",
      "  num_agent_steps_trained: 1663584\n",
      "  num_env_steps_sampled: 1663584\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 1663584\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.8076923076923\n",
      "    ram_util_percent: 89.09230769230768\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10286821643510774\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49384480006360865\n",
      "    mean_inference_ms: 1.0470447058729269\n",
      "    mean_raw_obs_processing_ms: 0.14369208523483823\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -214630.2204302724\n",
      "    episode_reward_mean: -224623.45794437767\n",
      "    episode_reward_min: -291711.94014148135\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -218230.7640699774\n",
      "      - -222491.27907719344\n",
      "      - -236612.7097568355\n",
      "      - -221120.7606568975\n",
      "      - -223092.9041380901\n",
      "      - -226844.56306206304\n",
      "      - -233249.09257453145\n",
      "      - -217861.12764156313\n",
      "      - -216240.1416634777\n",
      "      - -220194.96286851197\n",
      "      - -219712.79033062686\n",
      "      - -221969.11498015825\n",
      "      - -225390.70230173343\n",
      "      - -224568.47046202354\n",
      "      - -225687.4288270904\n",
      "      - -220905.15353840502\n",
      "      - -260155.72701965988\n",
      "      - -224011.8145866995\n",
      "      - -233509.5772591161\n",
      "      - -222146.13823478724\n",
      "      - -222088.15527076606\n",
      "      - -219323.4526647933\n",
      "      - -225324.26211981534\n",
      "      - -216251.45372883574\n",
      "      - -226998.34029059825\n",
      "      - -251123.9256346866\n",
      "      - -226137.79994114564\n",
      "      - -227011.4050571731\n",
      "      - -218144.21400956681\n",
      "      - -221534.71249576285\n",
      "      - -230285.0756086492\n",
      "      - -219406.89095794974\n",
      "      - -218583.23683267282\n",
      "      - -219308.99504824716\n",
      "      - -234977.97538781565\n",
      "      - -218791.62121294448\n",
      "      - -229950.2903845456\n",
      "      - -226112.4539435598\n",
      "      - -216949.5781563856\n",
      "      - -219564.58924182702\n",
      "      - -258606.56910799255\n",
      "      - -217238.8435329851\n",
      "      - -218075.66042982615\n",
      "      - -228124.95837126792\n",
      "      - -224767.20844331814\n",
      "      - -222260.7221680136\n",
      "      - -218029.4513214972\n",
      "      - -219610.19499325362\n",
      "      - -222347.25280720514\n",
      "      - -225692.1747023672\n",
      "      - -215858.1150128841\n",
      "      - -214630.2204302724\n",
      "      - -217844.13382270775\n",
      "      - -219866.98278775768\n",
      "      - -220393.59021771981\n",
      "      - -243737.06165156336\n",
      "      - -225574.11520626958\n",
      "      - -223338.60164783435\n",
      "      - -225925.69245257342\n",
      "      - -223433.234209461\n",
      "      - -233017.7492026362\n",
      "      - -291711.94014148135\n",
      "      - -217340.1136278365\n",
      "      - -218971.35344397716\n",
      "      - -221698.87590471187\n",
      "      - -218137.2974490804\n",
      "      - -223045.65077266874\n",
      "      - -222665.1982134854\n",
      "      - -220226.91959366578\n",
      "      - -227897.71691591007\n",
      "      - -220707.59296389477\n",
      "      - -221078.89723994117\n",
      "      - -215749.77107730854\n",
      "      - -218153.74146612376\n",
      "      - -216174.80466704583\n",
      "      - -219845.5833979492\n",
      "      - -215309.2417394441\n",
      "      - -223227.45905795225\n",
      "      - -228143.4982640403\n",
      "      - -225969.18903165657\n",
      "      - -221888.2098345081\n",
      "      - -222079.5938034941\n",
      "      - -226001.8218740909\n",
      "      - -225658.2382653265\n",
      "      - -220245.96800482325\n",
      "      - -225842.2860919196\n",
      "      - -222803.96903740065\n",
      "      - -229569.1652541605\n",
      "      - -221962.16031578748\n",
      "      - -220091.98369421353\n",
      "      - -221582.8926891126\n",
      "      - -228696.31460195812\n",
      "      - -221328.0433431085\n",
      "      - -222995.86588877326\n",
      "      - -234374.1173977712\n",
      "      - -225826.07041512555\n",
      "      - -224672.03343253484\n",
      "      - -220354.79325392016\n",
      "      - -221954.29109918297\n",
      "      - -218126.94761579033\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.10286821643510774\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.49384480006360865\n",
      "      mean_inference_ms: 1.0470447058729269\n",
      "      mean_raw_obs_processing_ms: 0.14369208523483823\n",
      "  time_since_restore: 266.60468101501465\n",
      "  time_this_iter_s: 9.68914794921875\n",
      "  time_total_s: 266.60468101501465\n",
      "  timers:\n",
      "    learn_throughput: 129235.613\n",
      "    learn_time_ms: 495.096\n",
      "    load_throughput: 21817500.539\n",
      "    load_time_ms: 2.933\n",
      "    training_iteration_time_ms: 9738.918\n",
      "    update_time_ms: 4.042\n",
      "  timestamp: 1665849009\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1663584\n",
      "  training_iteration: 26\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:50:15 (running for 00:04:49.46)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         266.605</td><td style=\"text-align: right;\">1663584</td><td style=\"text-align: right;\"> -224623</td><td style=\"text-align: right;\">             -214630</td><td style=\"text-align: right;\">             -291712</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 1727568\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 1727568\n",
      "    num_agent_steps_trained: 1727568\n",
      "    num_env_steps_sampled: 1727568\n",
      "    num_env_steps_trained: 1727568\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-50-19\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -212375.2727784309\n",
      "  episode_reward_mean: -223495.4420534401\n",
      "  episode_reward_min: -291711.94014148135\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 1716\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.231023073196411\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.000344849715474993\n",
      "          model: {}\n",
      "          policy_loss: 0.0007876484305597842\n",
      "          total_loss: 10.000533103942871\n",
      "          vf_explained_var: -7.568844218042159e-09\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 1727568\n",
      "    num_agent_steps_trained: 1727568\n",
      "    num_env_steps_sampled: 1727568\n",
      "    num_env_steps_trained: 1727568\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 1727568\n",
      "  num_agent_steps_trained: 1727568\n",
      "  num_env_steps_sampled: 1727568\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 1727568\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 80.17142857142856\n",
      "    ram_util_percent: 89.24285714285715\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1025578377164981\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49318474331271306\n",
      "    mean_inference_ms: 1.0466413587504133\n",
      "    mean_raw_obs_processing_ms: 0.14336172014150045\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -212375.2727784309\n",
      "    episode_reward_mean: -223495.4420534401\n",
      "    episode_reward_min: -291711.94014148135\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -233017.7492026362\n",
      "      - -291711.94014148135\n",
      "      - -217340.1136278365\n",
      "      - -218971.35344397716\n",
      "      - -221698.87590471187\n",
      "      - -218137.2974490804\n",
      "      - -223045.65077266874\n",
      "      - -222665.1982134854\n",
      "      - -220226.91959366578\n",
      "      - -227897.71691591007\n",
      "      - -220707.59296389477\n",
      "      - -221078.89723994117\n",
      "      - -215749.77107730854\n",
      "      - -218153.74146612376\n",
      "      - -216174.80466704583\n",
      "      - -219845.5833979492\n",
      "      - -215309.2417394441\n",
      "      - -223227.45905795225\n",
      "      - -228143.4982640403\n",
      "      - -225969.18903165657\n",
      "      - -221888.2098345081\n",
      "      - -222079.5938034941\n",
      "      - -226001.8218740909\n",
      "      - -225658.2382653265\n",
      "      - -220245.96800482325\n",
      "      - -225842.2860919196\n",
      "      - -222803.96903740065\n",
      "      - -229569.1652541605\n",
      "      - -221962.16031578748\n",
      "      - -220091.98369421353\n",
      "      - -221582.8926891126\n",
      "      - -228696.31460195812\n",
      "      - -221328.0433431085\n",
      "      - -222995.86588877326\n",
      "      - -234374.1173977712\n",
      "      - -225826.07041512555\n",
      "      - -224672.03343253484\n",
      "      - -220354.79325392016\n",
      "      - -221954.29109918297\n",
      "      - -218126.94761579033\n",
      "      - -226606.2785926867\n",
      "      - -216710.59361815802\n",
      "      - -219066.0852923286\n",
      "      - -224484.2396491663\n",
      "      - -219962.34332567218\n",
      "      - -217529.17343933033\n",
      "      - -212375.2727784309\n",
      "      - -215907.32691241286\n",
      "      - -221150.92083865873\n",
      "      - -217818.74515720436\n",
      "      - -222981.31526995104\n",
      "      - -223273.92788083106\n",
      "      - -215012.10913235747\n",
      "      - -220349.49078592838\n",
      "      - -222637.79496127352\n",
      "      - -265231.54839641607\n",
      "      - -219876.9185314264\n",
      "      - -217874.6079874858\n",
      "      - -220224.97580092007\n",
      "      - -216684.97658515355\n",
      "      - -213890.72585276605\n",
      "      - -213282.12461678256\n",
      "      - -265870.6676669623\n",
      "      - -219468.98250483937\n",
      "      - -219824.46863771335\n",
      "      - -216817.34411215628\n",
      "      - -217954.49144737766\n",
      "      - -218818.7569876748\n",
      "      - -221784.3415793696\n",
      "      - -217568.78599470097\n",
      "      - -223260.8606004063\n",
      "      - -218162.46826768017\n",
      "      - -216142.06256319405\n",
      "      - -231792.47382395552\n",
      "      - -232962.94056212585\n",
      "      - -224918.8424000803\n",
      "      - -215987.45554583156\n",
      "      - -224677.98047680134\n",
      "      - -221406.4962697774\n",
      "      - -222122.93272852522\n",
      "      - -219004.13813284016\n",
      "      - -216679.30313440406\n",
      "      - -223257.68191830654\n",
      "      - -215624.4269020173\n",
      "      - -219581.30270255834\n",
      "      - -212521.33287733432\n",
      "      - -216386.04424831033\n",
      "      - -219030.38367656636\n",
      "      - -217812.1134875571\n",
      "      - -233976.2970488759\n",
      "      - -217834.0428557577\n",
      "      - -220188.98735109522\n",
      "      - -223743.47794753546\n",
      "      - -213234.35835821787\n",
      "      - -282321.7127316264\n",
      "      - -215339.56286616265\n",
      "      - -223202.77446342394\n",
      "      - -212944.17679377762\n",
      "      - -221091.8725923888\n",
      "      - -258169.00759693046\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1025578377164981\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.49318474331271306\n",
      "      mean_inference_ms: 1.0466413587504133\n",
      "      mean_raw_obs_processing_ms: 0.14336172014150045\n",
      "  time_since_restore: 276.63717246055603\n",
      "  time_this_iter_s: 10.032491445541382\n",
      "  time_total_s: 276.63717246055603\n",
      "  timers:\n",
      "    learn_throughput: 129408.577\n",
      "    learn_time_ms: 494.434\n",
      "    load_throughput: 21848762.284\n",
      "    load_time_ms: 2.928\n",
      "    training_iteration_time_ms: 9825.033\n",
      "    update_time_ms: 4.007\n",
      "  timestamp: 1665849019\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1727568\n",
      "  training_iteration: 27\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:50:24 (running for 00:04:59.25)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         276.637</td><td style=\"text-align: right;\">1727568</td><td style=\"text-align: right;\"> -223495</td><td style=\"text-align: right;\">             -212375</td><td style=\"text-align: right;\">             -291712</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 1791552\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 1791552\n",
      "    num_agent_steps_trained: 1791552\n",
      "    num_env_steps_sampled: 1791552\n",
      "    num_env_steps_trained: 1791552\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-50-29\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -211069.5063980216\n",
      "  episode_reward_mean: -221492.41562703715\n",
      "  episode_reward_min: -282321.7127316264\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 1788\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.227975606918335\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0004806556098628789\n",
      "          model: {}\n",
      "          policy_loss: 0.0027929595671594143\n",
      "          total_loss: 10.002567291259766\n",
      "          vf_explained_var: -2.0814320933482122e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 1791552\n",
      "    num_agent_steps_trained: 1791552\n",
      "    num_env_steps_sampled: 1791552\n",
      "    num_env_steps_trained: 1791552\n",
      "  iterations_since_restore: 28\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 1791552\n",
      "  num_agent_steps_trained: 1791552\n",
      "  num_env_steps_sampled: 1791552\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 1791552\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.39285714285715\n",
      "    ram_util_percent: 89.33571428571429\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10219540509846808\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4919735830077794\n",
      "    mean_inference_ms: 1.0454034739267024\n",
      "    mean_raw_obs_processing_ms: 0.14291738890742367\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -211069.5063980216\n",
      "    episode_reward_mean: -221492.41562703715\n",
      "    episode_reward_min: -282321.7127316264\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -216142.06256319405\n",
      "      - -231792.47382395552\n",
      "      - -232962.94056212585\n",
      "      - -224918.8424000803\n",
      "      - -215987.45554583156\n",
      "      - -224677.98047680134\n",
      "      - -221406.4962697774\n",
      "      - -222122.93272852522\n",
      "      - -219004.13813284016\n",
      "      - -216679.30313440406\n",
      "      - -223257.68191830654\n",
      "      - -215624.4269020173\n",
      "      - -219581.30270255834\n",
      "      - -212521.33287733432\n",
      "      - -216386.04424831033\n",
      "      - -219030.38367656636\n",
      "      - -217812.1134875571\n",
      "      - -233976.2970488759\n",
      "      - -217834.0428557577\n",
      "      - -220188.98735109522\n",
      "      - -223743.47794753546\n",
      "      - -213234.35835821787\n",
      "      - -282321.7127316264\n",
      "      - -215339.56286616265\n",
      "      - -223202.77446342394\n",
      "      - -212944.17679377762\n",
      "      - -221091.8725923888\n",
      "      - -258169.00759693046\n",
      "      - -227202.1251568122\n",
      "      - -220897.19996366868\n",
      "      - -220841.00571553182\n",
      "      - -221421.68180029976\n",
      "      - -214726.9188749265\n",
      "      - -216517.11650301053\n",
      "      - -220714.7284545126\n",
      "      - -222829.59645199016\n",
      "      - -214736.4071049914\n",
      "      - -218887.33816097578\n",
      "      - -220923.27295519735\n",
      "      - -213521.08012084314\n",
      "      - -218207.1657578778\n",
      "      - -215599.1571112954\n",
      "      - -224960.15115761443\n",
      "      - -223117.1896902504\n",
      "      - -221336.39572304828\n",
      "      - -224447.55460110822\n",
      "      - -224584.9082500546\n",
      "      - -212619.74019675227\n",
      "      - -221141.4482175122\n",
      "      - -216675.42867953103\n",
      "      - -221494.87222258534\n",
      "      - -214312.81851611924\n",
      "      - -217663.9690524049\n",
      "      - -227250.0484393657\n",
      "      - -214931.14655308294\n",
      "      - -224426.70628528597\n",
      "      - -224758.92032035574\n",
      "      - -211695.29278800287\n",
      "      - -218554.2127999992\n",
      "      - -231267.5032251509\n",
      "      - -222160.11423677622\n",
      "      - -225119.28578256103\n",
      "      - -220010.1024951198\n",
      "      - -215022.9292775836\n",
      "      - -218856.69379271718\n",
      "      - -217203.672427561\n",
      "      - -222990.6096894142\n",
      "      - -222060.08532347545\n",
      "      - -217014.29921830777\n",
      "      - -217165.5013726375\n",
      "      - -216798.00386126823\n",
      "      - -220561.10653241666\n",
      "      - -219934.5826666899\n",
      "      - -233837.260218874\n",
      "      - -223432.54360677465\n",
      "      - -224207.89182098027\n",
      "      - -218168.00867887354\n",
      "      - -214914.7056584062\n",
      "      - -224407.5309950366\n",
      "      - -222962.85343120387\n",
      "      - -225407.6714433512\n",
      "      - -215704.57639942627\n",
      "      - -220573.1771883388\n",
      "      - -224757.69782251955\n",
      "      - -226472.03058825294\n",
      "      - -226401.95901108236\n",
      "      - -218258.44494756\n",
      "      - -221588.87721423965\n",
      "      - -217856.19309702358\n",
      "      - -211069.5063980216\n",
      "      - -222835.6099795126\n",
      "      - -217576.04536037846\n",
      "      - -219286.38613172068\n",
      "      - -214541.63347863517\n",
      "      - -214294.44668974332\n",
      "      - -225062.2002794282\n",
      "      - -222179.81315546666\n",
      "      - -218277.4003012023\n",
      "      - -226488.06128215903\n",
      "      - -229564.76794284253\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.10219540509846808\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4919735830077794\n",
      "      mean_inference_ms: 1.0454034739267024\n",
      "      mean_raw_obs_processing_ms: 0.14291738890742367\n",
      "  time_since_restore: 286.3861815929413\n",
      "  time_this_iter_s: 9.749009132385254\n",
      "  time_total_s: 286.3861815929413\n",
      "  timers:\n",
      "    learn_throughput: 128097.866\n",
      "    learn_time_ms: 499.493\n",
      "    load_throughput: 21791812.258\n",
      "    load_time_ms: 2.936\n",
      "    training_iteration_time_ms: 9756.703\n",
      "    update_time_ms: 4.024\n",
      "  timestamp: 1665849029\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1791552\n",
      "  training_iteration: 28\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:50:34 (running for 00:05:09.03)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         286.386</td><td style=\"text-align: right;\">1791552</td><td style=\"text-align: right;\"> -221492</td><td style=\"text-align: right;\">             -211070</td><td style=\"text-align: right;\">             -282322</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 1855536\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 1855536\n",
      "    num_agent_steps_trained: 1855536\n",
      "    num_env_steps_sampled: 1855536\n",
      "    num_env_steps_trained: 1855536\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-50-39\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -209926.74031046574\n",
      "  episode_reward_mean: -220537.19347431188\n",
      "  episode_reward_min: -274396.7564709245\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 1848\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.2262609004974365\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.000552977726329118\n",
      "          model: {}\n",
      "          policy_loss: 0.0074158646166324615\n",
      "          total_loss: 10.007203102111816\n",
      "          vf_explained_var: -3.7844220202032375e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 1855536\n",
      "    num_agent_steps_trained: 1855536\n",
      "    num_env_steps_sampled: 1855536\n",
      "    num_env_steps_trained: 1855536\n",
      "  iterations_since_restore: 29\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 1855536\n",
      "  num_agent_steps_trained: 1855536\n",
      "  num_env_steps_sampled: 1855536\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 1855536\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.54615384615384\n",
      "    ram_util_percent: 89.28461538461536\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10223587127694528\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4913670349090994\n",
      "    mean_inference_ms: 1.043223556160345\n",
      "    mean_raw_obs_processing_ms: 0.14287923713759448\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -209926.74031046574\n",
      "    episode_reward_mean: -220537.19347431188\n",
      "    episode_reward_min: -274396.7564709245\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -222160.11423677622\n",
      "      - -225119.28578256103\n",
      "      - -220010.1024951198\n",
      "      - -215022.9292775836\n",
      "      - -218856.69379271718\n",
      "      - -217203.672427561\n",
      "      - -222990.6096894142\n",
      "      - -222060.08532347545\n",
      "      - -217014.29921830777\n",
      "      - -217165.5013726375\n",
      "      - -216798.00386126823\n",
      "      - -220561.10653241666\n",
      "      - -219934.5826666899\n",
      "      - -233837.260218874\n",
      "      - -223432.54360677465\n",
      "      - -224207.89182098027\n",
      "      - -218168.00867887354\n",
      "      - -214914.7056584062\n",
      "      - -224407.5309950366\n",
      "      - -222962.85343120387\n",
      "      - -225407.6714433512\n",
      "      - -215704.57639942627\n",
      "      - -220573.1771883388\n",
      "      - -224757.69782251955\n",
      "      - -226472.03058825294\n",
      "      - -226401.95901108236\n",
      "      - -218258.44494756\n",
      "      - -221588.87721423965\n",
      "      - -217856.19309702358\n",
      "      - -211069.5063980216\n",
      "      - -222835.6099795126\n",
      "      - -217576.04536037846\n",
      "      - -219286.38613172068\n",
      "      - -214541.63347863517\n",
      "      - -214294.44668974332\n",
      "      - -225062.2002794282\n",
      "      - -222179.81315546666\n",
      "      - -218277.4003012023\n",
      "      - -226488.06128215903\n",
      "      - -229564.76794284253\n",
      "      - -224071.33519846306\n",
      "      - -224269.82015649465\n",
      "      - -224894.0845892556\n",
      "      - -224381.19919213213\n",
      "      - -216701.17128481713\n",
      "      - -216221.6205898538\n",
      "      - -213416.11607260667\n",
      "      - -223548.47101114495\n",
      "      - -274396.7564709245\n",
      "      - -220903.42787076184\n",
      "      - -214544.74391391262\n",
      "      - -220899.08130536394\n",
      "      - -227797.7366917789\n",
      "      - -216018.7744738472\n",
      "      - -225519.16993659604\n",
      "      - -216647.71346742625\n",
      "      - -222517.37040769335\n",
      "      - -212315.74668966653\n",
      "      - -211188.7356094795\n",
      "      - -222686.1605393924\n",
      "      - -217744.3172623976\n",
      "      - -210374.2963542609\n",
      "      - -215699.3204080781\n",
      "      - -217420.05465363187\n",
      "      - -229223.1380768003\n",
      "      - -223957.75731736782\n",
      "      - -219305.36200651477\n",
      "      - -209926.74031046574\n",
      "      - -221589.27785080275\n",
      "      - -215280.05007213517\n",
      "      - -224076.7966151775\n",
      "      - -230650.9455608734\n",
      "      - -212841.5671644319\n",
      "      - -222320.4674664729\n",
      "      - -221158.66414084448\n",
      "      - -216866.62929291083\n",
      "      - -215540.95254413\n",
      "      - -223228.11314126605\n",
      "      - -212752.0553463896\n",
      "      - -215382.05642433948\n",
      "      - -216051.22913315846\n",
      "      - -216564.16480298806\n",
      "      - -216782.60297466593\n",
      "      - -216984.25861968184\n",
      "      - -224764.46462916795\n",
      "      - -221320.51937829965\n",
      "      - -219224.2306809551\n",
      "      - -222074.1497201769\n",
      "      - -221032.1062902531\n",
      "      - -219471.29702967816\n",
      "      - -216102.50898865252\n",
      "      - -219974.97575691555\n",
      "      - -213879.07599472842\n",
      "      - -215964.3291309898\n",
      "      - -221333.4115769939\n",
      "      - -223420.71281109043\n",
      "      - -217949.5998281227\n",
      "      - -221766.63647469878\n",
      "      - -227913.47067517528\n",
      "      - -217843.5256563089\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.10223587127694528\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4913670349090994\n",
      "      mean_inference_ms: 1.043223556160345\n",
      "      mean_raw_obs_processing_ms: 0.14287923713759448\n",
      "  time_since_restore: 296.04556703567505\n",
      "  time_this_iter_s: 9.659385442733765\n",
      "  time_total_s: 296.04556703567505\n",
      "  timers:\n",
      "    learn_throughput: 127504.772\n",
      "    learn_time_ms: 501.817\n",
      "    load_throughput: 21866564.584\n",
      "    load_time_ms: 2.926\n",
      "    training_iteration_time_ms: 9789.734\n",
      "    update_time_ms: 3.922\n",
      "  timestamp: 1665849039\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1855536\n",
      "  training_iteration: 29\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:50:44 (running for 00:05:18.65)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         296.046</td><td style=\"text-align: right;\">1855536</td><td style=\"text-align: right;\"> -220537</td><td style=\"text-align: right;\">             -209927</td><td style=\"text-align: right;\">             -274397</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 1919520\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 1919520\n",
      "    num_agent_steps_trained: 1919520\n",
      "    num_env_steps_sampled: 1919520\n",
      "    num_env_steps_trained: 1919520\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-50-49\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -209926.74031046574\n",
      "  episode_reward_mean: -221436.88570480817\n",
      "  episode_reward_min: -286348.52662425936\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 1908\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.2223832607269287\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00028886494692415\n",
      "          model: {}\n",
      "          policy_loss: -0.0009171814890578389\n",
      "          total_loss: 9.998818397521973\n",
      "          vf_explained_var: -6.149685560785656e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 1919520\n",
      "    num_agent_steps_trained: 1919520\n",
      "    num_env_steps_sampled: 1919520\n",
      "    num_env_steps_trained: 1919520\n",
      "  iterations_since_restore: 30\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 1919520\n",
      "  num_agent_steps_trained: 1919520\n",
      "  num_env_steps_sampled: 1919520\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 1919520\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.57857142857142\n",
      "    ram_util_percent: 89.41428571428573\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10197811376057446\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49121132347094315\n",
      "    mean_inference_ms: 1.0423560429878338\n",
      "    mean_raw_obs_processing_ms: 0.14258542496982904\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -209926.74031046574\n",
      "    episode_reward_mean: -221436.88570480817\n",
      "    episode_reward_min: -286348.52662425936\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -217744.3172623976\n",
      "      - -210374.2963542609\n",
      "      - -215699.3204080781\n",
      "      - -217420.05465363187\n",
      "      - -229223.1380768003\n",
      "      - -223957.75731736782\n",
      "      - -219305.36200651477\n",
      "      - -209926.74031046574\n",
      "      - -221589.27785080275\n",
      "      - -215280.05007213517\n",
      "      - -224076.7966151775\n",
      "      - -230650.9455608734\n",
      "      - -212841.5671644319\n",
      "      - -222320.4674664729\n",
      "      - -221158.66414084448\n",
      "      - -216866.62929291083\n",
      "      - -215540.95254413\n",
      "      - -223228.11314126605\n",
      "      - -212752.0553463896\n",
      "      - -215382.05642433948\n",
      "      - -216051.22913315846\n",
      "      - -216564.16480298806\n",
      "      - -216782.60297466593\n",
      "      - -216984.25861968184\n",
      "      - -224764.46462916795\n",
      "      - -221320.51937829965\n",
      "      - -219224.2306809551\n",
      "      - -222074.1497201769\n",
      "      - -221032.1062902531\n",
      "      - -219471.29702967816\n",
      "      - -216102.50898865252\n",
      "      - -219974.97575691555\n",
      "      - -213879.07599472842\n",
      "      - -215964.3291309898\n",
      "      - -221333.4115769939\n",
      "      - -223420.71281109043\n",
      "      - -217949.5998281227\n",
      "      - -221766.63647469878\n",
      "      - -227913.47067517528\n",
      "      - -217843.5256563089\n",
      "      - -220182.96778671897\n",
      "      - -219659.5689057286\n",
      "      - -220206.10302495785\n",
      "      - -220000.34862293865\n",
      "      - -215869.72738079235\n",
      "      - -273566.0385041226\n",
      "      - -217788.2149021036\n",
      "      - -218845.36531975222\n",
      "      - -218135.71556221897\n",
      "      - -218228.48460501913\n",
      "      - -218968.82337708218\n",
      "      - -216183.4751499616\n",
      "      - -215880.51509349336\n",
      "      - -213307.72111272975\n",
      "      - -228339.5778851804\n",
      "      - -221433.0545337453\n",
      "      - -219187.29200144793\n",
      "      - -227911.57201577481\n",
      "      - -214869.14521103777\n",
      "      - -218848.64679305025\n",
      "      - -223594.89832702276\n",
      "      - -215902.58663953724\n",
      "      - -211193.90377305786\n",
      "      - -218529.07728036217\n",
      "      - -214836.94579911383\n",
      "      - -216901.6662682755\n",
      "      - -215037.1953153653\n",
      "      - -217359.94514188316\n",
      "      - -219175.04038042636\n",
      "      - -219981.4096072254\n",
      "      - -235177.73203612698\n",
      "      - -220320.0350496019\n",
      "      - -214025.13821744695\n",
      "      - -215683.32413399577\n",
      "      - -229048.54000703426\n",
      "      - -229051.0117799065\n",
      "      - -229049.29021594746\n",
      "      - -215039.43851516905\n",
      "      - -213610.12264309142\n",
      "      - -253644.87471629886\n",
      "      - -225971.01159267346\n",
      "      - -221652.62427922495\n",
      "      - -216294.63491961663\n",
      "      - -213326.08145657077\n",
      "      - -219131.08318942392\n",
      "      - -224140.30748269407\n",
      "      - -221445.12654956253\n",
      "      - -286348.52662425936\n",
      "      - -237465.6495425283\n",
      "      - -211841.68791792382\n",
      "      - -219459.22095665886\n",
      "      - -223717.04577151596\n",
      "      - -223666.00784322165\n",
      "      - -218438.7924555015\n",
      "      - -213387.69020534397\n",
      "      - -220490.83941855974\n",
      "      - -267320.01704076555\n",
      "      - -217050.61691361657\n",
      "      - -216670.14336502805\n",
      "      - -215541.09715938603\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.10197811376057446\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.49121132347094315\n",
      "      mean_inference_ms: 1.0423560429878338\n",
      "      mean_raw_obs_processing_ms: 0.14258542496982904\n",
      "  time_since_restore: 306.0337839126587\n",
      "  time_this_iter_s: 9.988216876983643\n",
      "  time_total_s: 306.0337839126587\n",
      "  timers:\n",
      "    learn_throughput: 128628.984\n",
      "    learn_time_ms: 497.431\n",
      "    load_throughput: 21890286.641\n",
      "    load_time_ms: 2.923\n",
      "    training_iteration_time_ms: 9797.937\n",
      "    update_time_ms: 3.891\n",
      "  timestamp: 1665849049\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1919520\n",
      "  training_iteration: 30\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:50:49 (running for 00:05:23.70)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         306.034</td><td style=\"text-align: right;\">1919520</td><td style=\"text-align: right;\"> -221437</td><td style=\"text-align: right;\">             -209927</td><td style=\"text-align: right;\">             -286349</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:50:54 (running for 00:05:28.70)<br>Memory usage on this node: 13.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         306.034</td><td style=\"text-align: right;\">1919520</td><td style=\"text-align: right;\"> -221437</td><td style=\"text-align: right;\">             -209927</td><td style=\"text-align: right;\">             -286349</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:50:59 (running for 00:05:33.76)<br>Memory usage on this node: 13.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         306.034</td><td style=\"text-align: right;\">1919520</td><td style=\"text-align: right;\"> -221437</td><td style=\"text-align: right;\">             -209927</td><td style=\"text-align: right;\">             -286349</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 1983504\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 1983504\n",
      "    num_agent_steps_trained: 1983504\n",
      "    num_env_steps_sampled: 1983504\n",
      "    num_env_steps_trained: 1983504\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-50-59\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -210458.95154900773\n",
      "  episode_reward_mean: -220905.32970322523\n",
      "  episode_reward_min: -286348.52662425936\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 1980\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.2220797538757324\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.000270422751782462\n",
      "          model: {}\n",
      "          policy_loss: 0.005213574040681124\n",
      "          total_loss: 10.004944801330566\n",
      "          vf_explained_var: -1.5137688436084318e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 1983504\n",
      "    num_agent_steps_trained: 1983504\n",
      "    num_env_steps_sampled: 1983504\n",
      "    num_env_steps_trained: 1983504\n",
      "  iterations_since_restore: 31\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 1983504\n",
      "  num_agent_steps_trained: 1983504\n",
      "  num_env_steps_sampled: 1983504\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 1983504\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 86.28666666666666\n",
      "    ram_util_percent: 89.92666666666668\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10206702698344117\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4909612006615914\n",
      "    mean_inference_ms: 1.0433513511211996\n",
      "    mean_raw_obs_processing_ms: 0.14249613947558742\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -210458.95154900773\n",
      "    episode_reward_mean: -220905.32970322523\n",
      "    episode_reward_min: -286348.52662425936\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -214025.13821744695\n",
      "      - -215683.32413399577\n",
      "      - -229048.54000703426\n",
      "      - -229051.0117799065\n",
      "      - -229049.29021594746\n",
      "      - -215039.43851516905\n",
      "      - -213610.12264309142\n",
      "      - -253644.87471629886\n",
      "      - -225971.01159267346\n",
      "      - -221652.62427922495\n",
      "      - -216294.63491961663\n",
      "      - -213326.08145657077\n",
      "      - -219131.08318942392\n",
      "      - -224140.30748269407\n",
      "      - -221445.12654956253\n",
      "      - -286348.52662425936\n",
      "      - -237465.6495425283\n",
      "      - -211841.68791792382\n",
      "      - -219459.22095665886\n",
      "      - -223717.04577151596\n",
      "      - -223666.00784322165\n",
      "      - -218438.7924555015\n",
      "      - -213387.69020534397\n",
      "      - -220490.83941855974\n",
      "      - -267320.01704076555\n",
      "      - -217050.61691361657\n",
      "      - -216670.14336502805\n",
      "      - -215541.09715938603\n",
      "      - -220826.16866270846\n",
      "      - -217619.4526302399\n",
      "      - -223607.34985490408\n",
      "      - -222590.7236821519\n",
      "      - -215453.52031951328\n",
      "      - -224732.26510527037\n",
      "      - -217316.8917896731\n",
      "      - -222250.79994293282\n",
      "      - -217306.78955033844\n",
      "      - -213816.0839764302\n",
      "      - -220666.2044714889\n",
      "      - -222605.19383465685\n",
      "      - -215887.153689993\n",
      "      - -217958.12219786533\n",
      "      - -220379.66394833324\n",
      "      - -215391.52646761277\n",
      "      - -219924.77473490188\n",
      "      - -226412.6006357165\n",
      "      - -216739.96974620403\n",
      "      - -221068.41568542755\n",
      "      - -218610.9696372774\n",
      "      - -225935.72848847334\n",
      "      - -223930.81881280485\n",
      "      - -218273.34531982936\n",
      "      - -224755.3259250916\n",
      "      - -221229.84079675365\n",
      "      - -215802.976396024\n",
      "      - -221091.47029214766\n",
      "      - -216350.0624627982\n",
      "      - -219554.30305859164\n",
      "      - -217875.68512293245\n",
      "      - -211335.12912172524\n",
      "      - -216591.73673960424\n",
      "      - -219319.76129177804\n",
      "      - -220199.7798733567\n",
      "      - -218300.9260713903\n",
      "      - -228409.95836807674\n",
      "      - -228147.1166489331\n",
      "      - -213158.338774586\n",
      "      - -220347.41227487905\n",
      "      - -217248.75040936374\n",
      "      - -218404.95103769758\n",
      "      - -217738.799584064\n",
      "      - -216045.30639702748\n",
      "      - -217560.06594093321\n",
      "      - -220376.7570364641\n",
      "      - -212587.57039639485\n",
      "      - -220718.18925317333\n",
      "      - -221659.43490228022\n",
      "      - -226601.14596704987\n",
      "      - -215380.73126069055\n",
      "      - -222110.82471897887\n",
      "      - -219308.1515432907\n",
      "      - -216868.48616973218\n",
      "      - -223303.84525949226\n",
      "      - -215293.0036778758\n",
      "      - -222670.6110774718\n",
      "      - -211940.63423792596\n",
      "      - -219923.91544482304\n",
      "      - -216750.86306408202\n",
      "      - -217665.3207264403\n",
      "      - -219537.35682791236\n",
      "      - -216795.80124647205\n",
      "      - -217963.64005486766\n",
      "      - -215324.44398875683\n",
      "      - -221630.79253980838\n",
      "      - -220875.70763978793\n",
      "      - -210458.95154900773\n",
      "      - -214945.572465514\n",
      "      - -220822.3898343562\n",
      "      - -221257.53722508525\n",
      "      - -216479.1175293248\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.10206702698344117\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4909612006615914\n",
      "      mean_inference_ms: 1.0433513511211996\n",
      "      mean_raw_obs_processing_ms: 0.14249613947558742\n",
      "  time_since_restore: 316.67429995536804\n",
      "  time_this_iter_s: 10.64051604270935\n",
      "  time_total_s: 316.67429995536804\n",
      "  timers:\n",
      "    learn_throughput: 129185.695\n",
      "    learn_time_ms: 495.287\n",
      "    load_throughput: 21853032.192\n",
      "    load_time_ms: 2.928\n",
      "    training_iteration_time_ms: 9825.46\n",
      "    update_time_ms: 3.881\n",
      "  timestamp: 1665849059\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1983504\n",
      "  training_iteration: 31\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:51:05 (running for 00:05:39.41)<br>Memory usage on this node: 13.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         316.674</td><td style=\"text-align: right;\">1983504</td><td style=\"text-align: right;\"> -220905</td><td style=\"text-align: right;\">             -210459</td><td style=\"text-align: right;\">             -286349</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 2047488\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 2047488\n",
      "    num_agent_steps_trained: 2047488\n",
      "    num_env_steps_sampled: 2047488\n",
      "    num_env_steps_trained: 2047488\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-51-09\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -209338.3657564658\n",
      "  episode_reward_mean: -219033.4252700441\n",
      "  episode_reward_min: -258523.86899292102\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 2040\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.2242774963378906\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00043883765465579927\n",
      "          model: {}\n",
      "          policy_loss: 0.006239635404199362\n",
      "          total_loss: 10.00600528717041\n",
      "          vf_explained_var: -3.500590395333347e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 2047488\n",
      "    num_agent_steps_trained: 2047488\n",
      "    num_env_steps_sampled: 2047488\n",
      "    num_env_steps_trained: 2047488\n",
      "  iterations_since_restore: 32\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 2047488\n",
      "  num_agent_steps_trained: 2047488\n",
      "  num_env_steps_sampled: 2047488\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 2047488\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.93076923076923\n",
      "    ram_util_percent: 89.9076923076923\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10192928566484508\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49055146086374823\n",
      "    mean_inference_ms: 1.0417191858074817\n",
      "    mean_raw_obs_processing_ms: 0.14249050347069703\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -209338.3657564658\n",
      "    episode_reward_mean: -219033.4252700441\n",
      "    episode_reward_min: -258523.86899292102\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -216591.73673960424\n",
      "      - -219319.76129177804\n",
      "      - -220199.7798733567\n",
      "      - -218300.9260713903\n",
      "      - -228409.95836807674\n",
      "      - -228147.1166489331\n",
      "      - -213158.338774586\n",
      "      - -220347.41227487905\n",
      "      - -217248.75040936374\n",
      "      - -218404.95103769758\n",
      "      - -217738.799584064\n",
      "      - -216045.30639702748\n",
      "      - -217560.06594093321\n",
      "      - -220376.7570364641\n",
      "      - -212587.57039639485\n",
      "      - -220718.18925317333\n",
      "      - -221659.43490228022\n",
      "      - -226601.14596704987\n",
      "      - -215380.73126069055\n",
      "      - -222110.82471897887\n",
      "      - -219308.1515432907\n",
      "      - -216868.48616973218\n",
      "      - -223303.84525949226\n",
      "      - -215293.0036778758\n",
      "      - -222670.6110774718\n",
      "      - -211940.63423792596\n",
      "      - -219923.91544482304\n",
      "      - -216750.86306408202\n",
      "      - -217665.3207264403\n",
      "      - -219537.35682791236\n",
      "      - -216795.80124647205\n",
      "      - -217963.64005486766\n",
      "      - -215324.44398875683\n",
      "      - -221630.79253980838\n",
      "      - -220875.70763978793\n",
      "      - -210458.95154900773\n",
      "      - -214945.572465514\n",
      "      - -220822.3898343562\n",
      "      - -221257.53722508525\n",
      "      - -216479.1175293248\n",
      "      - -214184.03669630503\n",
      "      - -221851.33617880926\n",
      "      - -221086.05996722064\n",
      "      - -222075.9848052601\n",
      "      - -218351.27872219574\n",
      "      - -219700.62858174925\n",
      "      - -212719.0772541195\n",
      "      - -225286.2907565109\n",
      "      - -258523.86899292102\n",
      "      - -214426.9917687456\n",
      "      - -217057.01795751316\n",
      "      - -225060.29083063913\n",
      "      - -217538.2822618422\n",
      "      - -214144.20361285965\n",
      "      - -220276.93447900857\n",
      "      - -212043.42177381387\n",
      "      - -224714.75502862\n",
      "      - -214599.95115941582\n",
      "      - -218922.43818732497\n",
      "      - -219874.58614601166\n",
      "      - -213105.6209618292\n",
      "      - -215763.3450347538\n",
      "      - -213093.4190484846\n",
      "      - -219312.4350639747\n",
      "      - -217257.82216078584\n",
      "      - -219654.31703573273\n",
      "      - -218423.34093735876\n",
      "      - -217599.3337960969\n",
      "      - -216390.23163992888\n",
      "      - -214283.61125097098\n",
      "      - -221525.36720394573\n",
      "      - -217092.72210140162\n",
      "      - -218397.82490422082\n",
      "      - -218507.9364929123\n",
      "      - -209338.3657564658\n",
      "      - -221372.51116010392\n",
      "      - -215002.8908328479\n",
      "      - -220301.8194758458\n",
      "      - -220008.29021927048\n",
      "      - -211563.15096276495\n",
      "      - -220532.0602222503\n",
      "      - -221508.4627308696\n",
      "      - -217136.97926324487\n",
      "      - -226105.7971769535\n",
      "      - -223544.8464511313\n",
      "      - -217404.01384134375\n",
      "      - -224631.98256284403\n",
      "      - -219599.54104897476\n",
      "      - -217102.162619782\n",
      "      - -219437.71091559823\n",
      "      - -219755.1049577454\n",
      "      - -214709.73759496008\n",
      "      - -216160.22028333214\n",
      "      - -227080.15291736636\n",
      "      - -216288.26681992228\n",
      "      - -224567.35052406735\n",
      "      - -218051.39676543907\n",
      "      - -216985.233172179\n",
      "      - -221329.69314461786\n",
      "      - -220256.32374245167\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.10192928566484508\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.49055146086374823\n",
      "      mean_inference_ms: 1.0417191858074817\n",
      "      mean_raw_obs_processing_ms: 0.14249050347069703\n",
      "  time_since_restore: 325.9722456932068\n",
      "  time_this_iter_s: 9.297945737838745\n",
      "  time_total_s: 325.9722456932068\n",
      "  timers:\n",
      "    learn_throughput: 128915.692\n",
      "    learn_time_ms: 496.324\n",
      "    load_throughput: 22293988.647\n",
      "    load_time_ms: 2.87\n",
      "    training_iteration_time_ms: 9772.252\n",
      "    update_time_ms: 3.809\n",
      "  timestamp: 1665849069\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2047488\n",
      "  training_iteration: 32\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:51:14 (running for 00:05:48.77)<br>Memory usage on this node: 13.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">         325.972</td><td style=\"text-align: right;\">2047488</td><td style=\"text-align: right;\"> -219033</td><td style=\"text-align: right;\">             -209338</td><td style=\"text-align: right;\">             -258524</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 2111472\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 2111472\n",
      "    num_agent_steps_trained: 2111472\n",
      "    num_env_steps_sampled: 2111472\n",
      "    num_env_steps_trained: 2111472\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-51-18\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -209338.3657564658\n",
      "  episode_reward_mean: -219020.10826330565\n",
      "  episode_reward_min: -243982.4170248548\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 2100\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.226024866104126\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0007154454942792654\n",
      "          model: {}\n",
      "          policy_loss: -0.000993553432635963\n",
      "          total_loss: 9.998827934265137\n",
      "          vf_explained_var: 1.419158213167293e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 2111472\n",
      "    num_agent_steps_trained: 2111472\n",
      "    num_env_steps_sampled: 2111472\n",
      "    num_env_steps_trained: 2111472\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 2111472\n",
      "  num_agent_steps_trained: 2111472\n",
      "  num_env_steps_sampled: 2111472\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 2111472\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.82307692307691\n",
      "    ram_util_percent: 89.73076923076923\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10158773079889084\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.49009534417708556\n",
      "    mean_inference_ms: 1.03874613457793\n",
      "    mean_raw_obs_processing_ms: 0.14221492528155408\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -209338.3657564658\n",
      "    episode_reward_mean: -219020.10826330565\n",
      "    episode_reward_min: -243982.4170248548\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -213105.6209618292\n",
      "      - -215763.3450347538\n",
      "      - -213093.4190484846\n",
      "      - -219312.4350639747\n",
      "      - -217257.82216078584\n",
      "      - -219654.31703573273\n",
      "      - -218423.34093735876\n",
      "      - -217599.3337960969\n",
      "      - -216390.23163992888\n",
      "      - -214283.61125097098\n",
      "      - -221525.36720394573\n",
      "      - -217092.72210140162\n",
      "      - -218397.82490422082\n",
      "      - -218507.9364929123\n",
      "      - -209338.3657564658\n",
      "      - -221372.51116010392\n",
      "      - -215002.8908328479\n",
      "      - -220301.8194758458\n",
      "      - -220008.29021927048\n",
      "      - -211563.15096276495\n",
      "      - -220532.0602222503\n",
      "      - -221508.4627308696\n",
      "      - -217136.97926324487\n",
      "      - -226105.7971769535\n",
      "      - -223544.8464511313\n",
      "      - -217404.01384134375\n",
      "      - -224631.98256284403\n",
      "      - -219599.54104897476\n",
      "      - -217102.162619782\n",
      "      - -219437.71091559823\n",
      "      - -219755.1049577454\n",
      "      - -214709.73759496008\n",
      "      - -216160.22028333214\n",
      "      - -227080.15291736636\n",
      "      - -216288.26681992228\n",
      "      - -224567.35052406735\n",
      "      - -218051.39676543907\n",
      "      - -216985.233172179\n",
      "      - -221329.69314461786\n",
      "      - -220256.32374245167\n",
      "      - -223073.92844024187\n",
      "      - -221945.89291720034\n",
      "      - -215146.1406418168\n",
      "      - -214388.98221940926\n",
      "      - -211917.20132635775\n",
      "      - -215757.0364712335\n",
      "      - -221538.70153495105\n",
      "      - -243982.4170248548\n",
      "      - -216580.19926788996\n",
      "      - -216460.3090443826\n",
      "      - -217062.1960816691\n",
      "      - -218739.91106919988\n",
      "      - -221256.057204933\n",
      "      - -218131.67305218274\n",
      "      - -221779.0385761116\n",
      "      - -218235.9077935037\n",
      "      - -218495.01551956072\n",
      "      - -217973.3762222068\n",
      "      - -223131.3330780805\n",
      "      - -219482.93351817116\n",
      "      - -215807.97248412226\n",
      "      - -218520.4520214947\n",
      "      - -221014.01901126222\n",
      "      - -224764.55316372108\n",
      "      - -215947.63018321487\n",
      "      - -220943.87992324732\n",
      "      - -221902.3083393345\n",
      "      - -219244.55133065383\n",
      "      - -219392.73019165642\n",
      "      - -216478.59632108174\n",
      "      - -227335.12854257907\n",
      "      - -221822.05752255573\n",
      "      - -223019.3066570229\n",
      "      - -218045.61512595307\n",
      "      - -216538.74058709518\n",
      "      - -218303.20323568498\n",
      "      - -219067.81878508427\n",
      "      - -224575.99297774697\n",
      "      - -219865.65934834018\n",
      "      - -221747.0762345292\n",
      "      - -225898.23311909108\n",
      "      - -216699.8270653165\n",
      "      - -219253.25521790716\n",
      "      - -217837.95411282504\n",
      "      - -215298.02434728158\n",
      "      - -222144.41139453292\n",
      "      - -227281.40623470518\n",
      "      - -215082.46842624628\n",
      "      - -217371.06944134668\n",
      "      - -216801.06636447678\n",
      "      - -218162.57505272445\n",
      "      - -213674.55235587165\n",
      "      - -218014.82906993394\n",
      "      - -218278.29324339438\n",
      "      - -219549.6919111158\n",
      "      - -221235.4881511322\n",
      "      - -209909.14023734463\n",
      "      - -217677.28044721342\n",
      "      - -217603.9232543206\n",
      "      - -214640.40109867073\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.10158773079889084\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.49009534417708556\n",
      "      mean_inference_ms: 1.03874613457793\n",
      "      mean_raw_obs_processing_ms: 0.14221492528155408\n",
      "  time_since_restore: 335.39400267601013\n",
      "  time_this_iter_s: 9.421756982803345\n",
      "  time_total_s: 335.39400267601013\n",
      "  timers:\n",
      "    learn_throughput: 128548.726\n",
      "    learn_time_ms: 497.741\n",
      "    load_throughput: 22293433.057\n",
      "    load_time_ms: 2.87\n",
      "    training_iteration_time_ms: 9752.044\n",
      "    update_time_ms: 3.854\n",
      "  timestamp: 1665849078\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2111472\n",
      "  training_iteration: 33\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:51:24 (running for 00:05:58.50)<br>Memory usage on this node: 13.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         335.394</td><td style=\"text-align: right;\">2111472</td><td style=\"text-align: right;\"> -219020</td><td style=\"text-align: right;\">             -209338</td><td style=\"text-align: right;\">             -243982</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 2175456\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 2175456\n",
      "    num_agent_steps_trained: 2175456\n",
      "    num_env_steps_sampled: 2175456\n",
      "    num_env_steps_trained: 2175456\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-51-28\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -209909.14023734463\n",
      "  episode_reward_mean: -219904.12828523124\n",
      "  episode_reward_min: -286978.07677529176\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 2172\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.2273266315460205\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0004668017791118473\n",
      "          model: {}\n",
      "          policy_loss: 0.005257326643913984\n",
      "          total_loss: 10.005027770996094\n",
      "          vf_explained_var: -1.3245476715439963e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 2175456\n",
      "    num_agent_steps_trained: 2175456\n",
      "    num_env_steps_sampled: 2175456\n",
      "    num_env_steps_trained: 2175456\n",
      "  iterations_since_restore: 34\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 2175456\n",
      "  num_agent_steps_trained: 2175456\n",
      "  num_env_steps_sampled: 2175456\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 2175456\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.23571428571428\n",
      "    ram_util_percent: 90.0\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10127285521027356\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.48917918849097075\n",
      "    mean_inference_ms: 1.0354899904358692\n",
      "    mean_raw_obs_processing_ms: 0.1418971807338942\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -209909.14023734463\n",
      "    episode_reward_mean: -219904.12828523124\n",
      "    episode_reward_min: -286978.07677529176\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -223019.3066570229\n",
      "      - -218045.61512595307\n",
      "      - -216538.74058709518\n",
      "      - -218303.20323568498\n",
      "      - -219067.81878508427\n",
      "      - -224575.99297774697\n",
      "      - -219865.65934834018\n",
      "      - -221747.0762345292\n",
      "      - -225898.23311909108\n",
      "      - -216699.8270653165\n",
      "      - -219253.25521790716\n",
      "      - -217837.95411282504\n",
      "      - -215298.02434728158\n",
      "      - -222144.41139453292\n",
      "      - -227281.40623470518\n",
      "      - -215082.46842624628\n",
      "      - -217371.06944134668\n",
      "      - -216801.06636447678\n",
      "      - -218162.57505272445\n",
      "      - -213674.55235587165\n",
      "      - -218014.82906993394\n",
      "      - -218278.29324339438\n",
      "      - -219549.6919111158\n",
      "      - -221235.4881511322\n",
      "      - -209909.14023734463\n",
      "      - -217677.28044721342\n",
      "      - -217603.9232543206\n",
      "      - -214640.40109867073\n",
      "      - -286978.07677529176\n",
      "      - -220392.38971914683\n",
      "      - -219632.2128025781\n",
      "      - -213736.6924522191\n",
      "      - -217139.44849018368\n",
      "      - -213828.00391729127\n",
      "      - -218964.2402786606\n",
      "      - -219642.0721116389\n",
      "      - -224684.1877878507\n",
      "      - -218804.4241428675\n",
      "      - -219712.656464747\n",
      "      - -212482.2126231988\n",
      "      - -220917.70701040784\n",
      "      - -222478.60837875397\n",
      "      - -213621.4617151175\n",
      "      - -220086.71487576707\n",
      "      - -226034.24363480456\n",
      "      - -219879.05280892382\n",
      "      - -214207.872182406\n",
      "      - -216340.21039448847\n",
      "      - -213619.0688403976\n",
      "      - -220494.0806614104\n",
      "      - -218196.62028715995\n",
      "      - -217682.3832144595\n",
      "      - -219376.49708579175\n",
      "      - -217214.033911979\n",
      "      - -215765.61353921326\n",
      "      - -215762.11337410714\n",
      "      - -236084.64437260843\n",
      "      - -211210.94273688068\n",
      "      - -220042.54373339543\n",
      "      - -215604.81607761842\n",
      "      - -224406.31326883464\n",
      "      - -221718.7598164621\n",
      "      - -217180.84001181863\n",
      "      - -222463.0813387379\n",
      "      - -216421.91323616038\n",
      "      - -224848.09547074564\n",
      "      - -218499.3983918249\n",
      "      - -211542.7736445694\n",
      "      - -214832.44489512392\n",
      "      - -226029.92865575253\n",
      "      - -271486.198224664\n",
      "      - -217579.46323240336\n",
      "      - -220933.2406251696\n",
      "      - -215079.9266386572\n",
      "      - -215107.56427838572\n",
      "      - -213884.30564599752\n",
      "      - -213261.80615440413\n",
      "      - -224153.3842822309\n",
      "      - -210051.7342999934\n",
      "      - -219310.13874382715\n",
      "      - -226739.58884216464\n",
      "      - -214666.5277148253\n",
      "      - -214497.92062265615\n",
      "      - -214585.3956340656\n",
      "      - -235595.98370157462\n",
      "      - -219434.36582018968\n",
      "      - -220589.68279425421\n",
      "      - -213418.6757230442\n",
      "      - -213586.2788224937\n",
      "      - -215132.5010799426\n",
      "      - -220590.99045086015\n",
      "      - -221013.2353357228\n",
      "      - -214332.62330626402\n",
      "      - -220226.9329645175\n",
      "      - -219862.74494218428\n",
      "      - -220843.00905064435\n",
      "      - -217219.34395551647\n",
      "      - -225435.5354355215\n",
      "      - -217105.35033050657\n",
      "      - -222551.68124214394\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.10127285521027356\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.48917918849097075\n",
      "      mean_inference_ms: 1.0354899904358692\n",
      "      mean_raw_obs_processing_ms: 0.1418971807338942\n",
      "  time_since_restore: 344.81783080101013\n",
      "  time_this_iter_s: 9.423828125\n",
      "  time_total_s: 344.81783080101013\n",
      "  timers:\n",
      "    learn_throughput: 126985.643\n",
      "    learn_time_ms: 503.868\n",
      "    load_throughput: 22233223.463\n",
      "    load_time_ms: 2.878\n",
      "    training_iteration_time_ms: 9740.393\n",
      "    update_time_ms: 3.779\n",
      "  timestamp: 1665849088\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2175456\n",
      "  training_iteration: 34\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:51:33 (running for 00:06:07.67)<br>Memory usage on this node: 14.0/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         344.818</td><td style=\"text-align: right;\">2175456</td><td style=\"text-align: right;\"> -219904</td><td style=\"text-align: right;\">             -209909</td><td style=\"text-align: right;\">             -286978</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 2239440\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 2239440\n",
      "    num_agent_steps_trained: 2239440\n",
      "    num_env_steps_sampled: 2239440\n",
      "    num_env_steps_trained: 2239440\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-51-37\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -208737.53403211018\n",
      "  episode_reward_mean: -218871.8188395859\n",
      "  episode_reward_min: -271486.198224664\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 2232\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.228803873062134\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0003857347182929516\n",
      "          model: {}\n",
      "          policy_loss: 0.007035247981548309\n",
      "          total_loss: 10.006790161132812\n",
      "          vf_explained_var: 1.1353265882974029e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 2239440\n",
      "    num_agent_steps_trained: 2239440\n",
      "    num_env_steps_sampled: 2239440\n",
      "    num_env_steps_trained: 2239440\n",
      "  iterations_since_restore: 35\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 2239440\n",
      "  num_agent_steps_trained: 2239440\n",
      "  num_env_steps_sampled: 2239440\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 2239440\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 84.21538461538464\n",
      "    ram_util_percent: 90.48461538461538\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10113659069969039\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4885393790600156\n",
      "    mean_inference_ms: 1.0338311839203842\n",
      "    mean_raw_obs_processing_ms: 0.14188308907944197\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -208737.53403211018\n",
      "    episode_reward_mean: -218871.8188395859\n",
      "    episode_reward_min: -271486.198224664\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -224406.31326883464\n",
      "      - -221718.7598164621\n",
      "      - -217180.84001181863\n",
      "      - -222463.0813387379\n",
      "      - -216421.91323616038\n",
      "      - -224848.09547074564\n",
      "      - -218499.3983918249\n",
      "      - -211542.7736445694\n",
      "      - -214832.44489512392\n",
      "      - -226029.92865575253\n",
      "      - -271486.198224664\n",
      "      - -217579.46323240336\n",
      "      - -220933.2406251696\n",
      "      - -215079.9266386572\n",
      "      - -215107.56427838572\n",
      "      - -213884.30564599752\n",
      "      - -213261.80615440413\n",
      "      - -224153.3842822309\n",
      "      - -210051.7342999934\n",
      "      - -219310.13874382715\n",
      "      - -226739.58884216464\n",
      "      - -214666.5277148253\n",
      "      - -214497.92062265615\n",
      "      - -214585.3956340656\n",
      "      - -235595.98370157462\n",
      "      - -219434.36582018968\n",
      "      - -220589.68279425421\n",
      "      - -213418.6757230442\n",
      "      - -213586.2788224937\n",
      "      - -215132.5010799426\n",
      "      - -220590.99045086015\n",
      "      - -221013.2353357228\n",
      "      - -214332.62330626402\n",
      "      - -220226.9329645175\n",
      "      - -219862.74494218428\n",
      "      - -220843.00905064435\n",
      "      - -217219.34395551647\n",
      "      - -225435.5354355215\n",
      "      - -217105.35033050657\n",
      "      - -222551.68124214394\n",
      "      - -210383.84541033936\n",
      "      - -218559.22865023065\n",
      "      - -221159.95742958365\n",
      "      - -214196.4473943875\n",
      "      - -217613.35031644147\n",
      "      - -216855.27170172214\n",
      "      - -212226.24699540806\n",
      "      - -221154.10237342422\n",
      "      - -222256.2521420245\n",
      "      - -215721.85049891254\n",
      "      - -221277.00459570164\n",
      "      - -213469.83275089614\n",
      "      - -217263.40606939356\n",
      "      - -216186.63312800776\n",
      "      - -215598.86179918377\n",
      "      - -217839.31404138228\n",
      "      - -221311.44028921134\n",
      "      - -221409.6181988235\n",
      "      - -216903.2602857951\n",
      "      - -216930.96203684004\n",
      "      - -218388.6861294306\n",
      "      - -218841.78454539317\n",
      "      - -218692.81937044222\n",
      "      - -216954.998654015\n",
      "      - -217591.47321944183\n",
      "      - -214938.19674407959\n",
      "      - -223040.0344043979\n",
      "      - -217602.6557818004\n",
      "      - -216754.6174798797\n",
      "      - -218928.0258057427\n",
      "      - -218420.51660705902\n",
      "      - -215323.5330379384\n",
      "      - -214284.01036127523\n",
      "      - -220918.69239697905\n",
      "      - -215931.5852542507\n",
      "      - -222627.5401759211\n",
      "      - -216676.79190406966\n",
      "      - -225351.33798590084\n",
      "      - -222893.69849006814\n",
      "      - -211406.08769272012\n",
      "      - -217383.7668884446\n",
      "      - -216886.76569049218\n",
      "      - -217525.2239703489\n",
      "      - -224162.11229068952\n",
      "      - -219048.35735194938\n",
      "      - -215735.22300956058\n",
      "      - -212894.41918486735\n",
      "      - -218099.57003008333\n",
      "      - -212538.61569472303\n",
      "      - -216161.40193540687\n",
      "      - -221516.49182836886\n",
      "      - -219096.17160442274\n",
      "      - -208737.53403211018\n",
      "      - -219000.68161967097\n",
      "      - -220287.12357210237\n",
      "      - -218370.18786216612\n",
      "      - -221557.08154553128\n",
      "      - -226596.62844960182\n",
      "      - -222590.7403138795\n",
      "      - -218890.1363107992\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.10113659069969039\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4885393790600156\n",
      "      mean_inference_ms: 1.0338311839203842\n",
      "      mean_raw_obs_processing_ms: 0.14188308907944197\n",
      "  time_since_restore: 354.4184567928314\n",
      "  time_this_iter_s: 9.600625991821289\n",
      "  time_total_s: 354.4184567928314\n",
      "  timers:\n",
      "    learn_throughput: 127185.837\n",
      "    learn_time_ms: 503.075\n",
      "    load_throughput: 22201770.985\n",
      "    load_time_ms: 2.882\n",
      "    training_iteration_time_ms: 9743.62\n",
      "    update_time_ms: 3.889\n",
      "  timestamp: 1665849097\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2239440\n",
      "  training_iteration: 35\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:51:43 (running for 00:06:17.64)<br>Memory usage on this node: 14.0/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         354.418</td><td style=\"text-align: right;\">2239440</td><td style=\"text-align: right;\"> -218872</td><td style=\"text-align: right;\">             -208738</td><td style=\"text-align: right;\">             -271486</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 2303424\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 2303424\n",
      "    num_agent_steps_trained: 2303424\n",
      "    num_env_steps_sampled: 2303424\n",
      "    num_env_steps_trained: 2303424\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-51-48\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -208709.29199807203\n",
      "  episode_reward_mean: -217806.30967994127\n",
      "  episode_reward_min: -232965.20668357995\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 2292\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.229562759399414\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0004046894027851522\n",
      "          model: {}\n",
      "          policy_loss: -0.0005494729848578572\n",
      "          total_loss: 9.999207496643066\n",
      "          vf_explained_var: -3.311369312086754e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 2303424\n",
      "    num_agent_steps_trained: 2303424\n",
      "    num_env_steps_sampled: 2303424\n",
      "    num_env_steps_trained: 2303424\n",
      "  iterations_since_restore: 36\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 2303424\n",
      "  num_agent_steps_trained: 2303424\n",
      "  num_env_steps_sampled: 2303424\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 2303424\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.07333333333332\n",
      "    ram_util_percent: 90.92000000000002\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10096133925408518\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4885466803115527\n",
      "    mean_inference_ms: 1.033691389449717\n",
      "    mean_raw_obs_processing_ms: 0.1416793263765671\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -208709.29199807203\n",
      "    episode_reward_mean: -217806.30967994127\n",
      "    episode_reward_min: -232965.20668357995\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -218388.6861294306\n",
      "      - -218841.78454539317\n",
      "      - -218692.81937044222\n",
      "      - -216954.998654015\n",
      "      - -217591.47321944183\n",
      "      - -214938.19674407959\n",
      "      - -223040.0344043979\n",
      "      - -217602.6557818004\n",
      "      - -216754.6174798797\n",
      "      - -218928.0258057427\n",
      "      - -218420.51660705902\n",
      "      - -215323.5330379384\n",
      "      - -214284.01036127523\n",
      "      - -220918.69239697905\n",
      "      - -215931.5852542507\n",
      "      - -222627.5401759211\n",
      "      - -216676.79190406966\n",
      "      - -225351.33798590084\n",
      "      - -222893.69849006814\n",
      "      - -211406.08769272012\n",
      "      - -217383.7668884446\n",
      "      - -216886.76569049218\n",
      "      - -217525.2239703489\n",
      "      - -224162.11229068952\n",
      "      - -219048.35735194938\n",
      "      - -215735.22300956058\n",
      "      - -212894.41918486735\n",
      "      - -218099.57003008333\n",
      "      - -212538.61569472303\n",
      "      - -216161.40193540687\n",
      "      - -221516.49182836886\n",
      "      - -219096.17160442274\n",
      "      - -208737.53403211018\n",
      "      - -219000.68161967097\n",
      "      - -220287.12357210237\n",
      "      - -218370.18786216612\n",
      "      - -221557.08154553128\n",
      "      - -226596.62844960182\n",
      "      - -222590.7403138795\n",
      "      - -218890.1363107992\n",
      "      - -215082.30517126573\n",
      "      - -216546.39143438695\n",
      "      - -217851.42861847777\n",
      "      - -217236.85883428642\n",
      "      - -215688.57385205664\n",
      "      - -214387.4237679082\n",
      "      - -225219.1779241962\n",
      "      - -217272.5230492712\n",
      "      - -214746.54273736698\n",
      "      - -215077.87117971992\n",
      "      - -212495.07243184553\n",
      "      - -212236.78606212582\n",
      "      - -214705.2506204412\n",
      "      - -218535.8348859868\n",
      "      - -221781.2338330579\n",
      "      - -227549.62987194103\n",
      "      - -217303.63971808445\n",
      "      - -232965.20668357995\n",
      "      - -218485.20049036742\n",
      "      - -211886.9356492942\n",
      "      - -218970.03954286367\n",
      "      - -215426.52590669648\n",
      "      - -212875.708493192\n",
      "      - -220093.68139328828\n",
      "      - -225618.63862282803\n",
      "      - -219505.0407696357\n",
      "      - -216479.25969164746\n",
      "      - -208709.29199807203\n",
      "      - -216340.8159173445\n",
      "      - -214896.6941549239\n",
      "      - -214882.1901073146\n",
      "      - -214468.7099515631\n",
      "      - -216719.7949958136\n",
      "      - -215583.3728692914\n",
      "      - -219770.07468563443\n",
      "      - -219675.53679761736\n",
      "      - -215637.324160782\n",
      "      - -210870.15250740078\n",
      "      - -218470.42929672403\n",
      "      - -216901.95183708254\n",
      "      - -220340.0206557339\n",
      "      - -216458.7594840587\n",
      "      - -220661.31785402077\n",
      "      - -219174.3152042377\n",
      "      - -215996.15905635117\n",
      "      - -212796.4204092326\n",
      "      - -217218.796592614\n",
      "      - -210022.52758669114\n",
      "      - -223912.29380476702\n",
      "      - -221498.5163974674\n",
      "      - -218784.1842623707\n",
      "      - -219397.63488913147\n",
      "      - -225226.98239933624\n",
      "      - -214659.5436052791\n",
      "      - -217539.1763968415\n",
      "      - -215294.1956022117\n",
      "      - -218934.74783082734\n",
      "      - -226955.16309609453\n",
      "      - -213339.5606315668\n",
      "      - -210826.21249389162\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.10096133925408518\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4885466803115527\n",
      "      mean_inference_ms: 1.033691389449717\n",
      "      mean_raw_obs_processing_ms: 0.1416793263765671\n",
      "  time_since_restore: 364.6069095134735\n",
      "  time_this_iter_s: 10.18845272064209\n",
      "  time_total_s: 364.6069095134735\n",
      "  timers:\n",
      "    learn_throughput: 126360.387\n",
      "    learn_time_ms: 506.361\n",
      "    load_throughput: 22227514.94\n",
      "    load_time_ms: 2.879\n",
      "    training_iteration_time_ms: 9793.738\n",
      "    update_time_ms: 3.946\n",
      "  timestamp: 1665849108\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2303424\n",
      "  training_iteration: 36\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:51:53 (running for 00:06:27.92)<br>Memory usage on this node: 14.1/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         364.607</td><td style=\"text-align: right;\">2303424</td><td style=\"text-align: right;\"> -217806</td><td style=\"text-align: right;\">             -208709</td><td style=\"text-align: right;\">             -232965</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 2367408\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 2367408\n",
      "    num_agent_steps_trained: 2367408\n",
      "    num_env_steps_sampled: 2367408\n",
      "    num_env_steps_trained: 2367408\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-51-57\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -208647.7358469245\n",
      "  episode_reward_mean: -217310.9309224394\n",
      "  episode_reward_min: -226955.16309609453\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 2364\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.225297212600708\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0004026492533739656\n",
      "          model: {}\n",
      "          policy_loss: 0.00547567056491971\n",
      "          total_loss: 10.005233764648438\n",
      "          vf_explained_var: -3.0275376872168636e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 2367408\n",
      "    num_agent_steps_trained: 2367408\n",
      "    num_env_steps_sampled: 2367408\n",
      "    num_env_steps_trained: 2367408\n",
      "  iterations_since_restore: 37\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 2367408\n",
      "  num_agent_steps_trained: 2367408\n",
      "  num_env_steps_sampled: 2367408\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 2367408\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.14615384615384\n",
      "    ram_util_percent: 90.9\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10062691719975274\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4874534113686084\n",
      "    mean_inference_ms: 1.0314292351677778\n",
      "    mean_raw_obs_processing_ms: 0.14121745667802785\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -208647.7358469245\n",
      "    episode_reward_mean: -217310.9309224394\n",
      "    episode_reward_min: -226955.16309609453\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -216719.7949958136\n",
      "      - -215583.3728692914\n",
      "      - -219770.07468563443\n",
      "      - -219675.53679761736\n",
      "      - -215637.324160782\n",
      "      - -210870.15250740078\n",
      "      - -218470.42929672403\n",
      "      - -216901.95183708254\n",
      "      - -220340.0206557339\n",
      "      - -216458.7594840587\n",
      "      - -220661.31785402077\n",
      "      - -219174.3152042377\n",
      "      - -215996.15905635117\n",
      "      - -212796.4204092326\n",
      "      - -217218.796592614\n",
      "      - -210022.52758669114\n",
      "      - -223912.29380476702\n",
      "      - -221498.5163974674\n",
      "      - -218784.1842623707\n",
      "      - -219397.63488913147\n",
      "      - -225226.98239933624\n",
      "      - -214659.5436052791\n",
      "      - -217539.1763968415\n",
      "      - -215294.1956022117\n",
      "      - -218934.74783082734\n",
      "      - -226955.16309609453\n",
      "      - -213339.5606315668\n",
      "      - -210826.21249389162\n",
      "      - -218415.30902134717\n",
      "      - -211494.5121816344\n",
      "      - -214964.09624311965\n",
      "      - -218494.31889022898\n",
      "      - -222875.44132338988\n",
      "      - -214924.70543304752\n",
      "      - -214211.1096327262\n",
      "      - -216489.2792478216\n",
      "      - -223674.3975343265\n",
      "      - -215159.35634062366\n",
      "      - -211404.18990980994\n",
      "      - -216721.48063081992\n",
      "      - -216440.80365946903\n",
      "      - -216189.90812573064\n",
      "      - -210380.45870155276\n",
      "      - -217257.13021833767\n",
      "      - -225062.17952985858\n",
      "      - -217809.740192265\n",
      "      - -216891.4037463259\n",
      "      - -219470.4158789694\n",
      "      - -215230.8979918998\n",
      "      - -214171.70007706384\n",
      "      - -216635.37911298315\n",
      "      - -224540.79086315725\n",
      "      - -214660.31700168335\n",
      "      - -215053.4033148469\n",
      "      - -218805.49887583137\n",
      "      - -221453.70282217895\n",
      "      - -216825.94752539264\n",
      "      - -213680.97578858957\n",
      "      - -220155.74469545935\n",
      "      - -216710.20950066272\n",
      "      - -218670.98839767172\n",
      "      - -217525.16387693962\n",
      "      - -217598.1251245332\n",
      "      - -212828.30523694272\n",
      "      - -214509.30646972623\n",
      "      - -218463.3533584307\n",
      "      - -212751.45427942244\n",
      "      - -219172.4474807304\n",
      "      - -219935.72007935436\n",
      "      - -217415.93245400846\n",
      "      - -220452.5858929664\n",
      "      - -216615.87906380073\n",
      "      - -217430.9934319447\n",
      "      - -219018.90308628167\n",
      "      - -214894.7257179552\n",
      "      - -211353.32767410736\n",
      "      - -216925.34065407177\n",
      "      - -215784.90665872575\n",
      "      - -223139.3275009015\n",
      "      - -219623.22251591273\n",
      "      - -217902.91348579098\n",
      "      - -221282.27340299962\n",
      "      - -221689.54342112486\n",
      "      - -212004.12940218285\n",
      "      - -218563.06709599585\n",
      "      - -217453.80325659644\n",
      "      - -218972.09730742645\n",
      "      - -214252.6036623877\n",
      "      - -221275.40654204332\n",
      "      - -211417.9428750247\n",
      "      - -221961.49842049406\n",
      "      - -219125.2742934931\n",
      "      - -220972.2943612898\n",
      "      - -220773.7230615757\n",
      "      - -216402.32658822904\n",
      "      - -208647.7358469245\n",
      "      - -219553.3796994673\n",
      "      - -216551.41678115178\n",
      "      - -213952.63983083982\n",
      "      - -215309.04454025012\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.10062691719975274\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4874534113686084\n",
      "      mean_inference_ms: 1.0314292351677778\n",
      "      mean_raw_obs_processing_ms: 0.14121745667802785\n",
      "  time_since_restore: 373.60690093040466\n",
      "  time_this_iter_s: 8.999991416931152\n",
      "  time_total_s: 373.60690093040466\n",
      "  timers:\n",
      "    learn_throughput: 126516.186\n",
      "    learn_time_ms: 505.738\n",
      "    load_throughput: 22327560.579\n",
      "    load_time_ms: 2.866\n",
      "    training_iteration_time_ms: 9690.545\n",
      "    update_time_ms: 4.02\n",
      "  timestamp: 1665849117\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2367408\n",
      "  training_iteration: 37\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:52:02 (running for 00:06:36.50)<br>Memory usage on this node: 14.1/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         373.607</td><td style=\"text-align: right;\">2367408</td><td style=\"text-align: right;\"> -217311</td><td style=\"text-align: right;\">             -208648</td><td style=\"text-align: right;\">             -226955</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 2431392\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 2431392\n",
      "    num_agent_steps_trained: 2431392\n",
      "    num_env_steps_sampled: 2431392\n",
      "    num_env_steps_trained: 2431392\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-52-06\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -207900.96752774503\n",
      "  episode_reward_mean: -217367.72445037946\n",
      "  episode_reward_min: -226764.03085466946\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 2424\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.228321075439453\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00045503993169404566\n",
      "          model: {}\n",
      "          policy_loss: 0.006393748801201582\n",
      "          total_loss: 10.0061616897583\n",
      "          vf_explained_var: -4.1628641866964244e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 2431392\n",
      "    num_agent_steps_trained: 2431392\n",
      "    num_env_steps_sampled: 2431392\n",
      "    num_env_steps_trained: 2431392\n",
      "  iterations_since_restore: 38\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 2431392\n",
      "  num_agent_steps_trained: 2431392\n",
      "  num_env_steps_sampled: 2431392\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 2431392\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.47499999999998\n",
      "    ram_util_percent: 90.93333333333334\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10042129788203256\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.48662321295293154\n",
      "    mean_inference_ms: 1.0279937357084814\n",
      "    mean_raw_obs_processing_ms: 0.1411137507199193\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -207900.96752774503\n",
      "    episode_reward_mean: -217367.72445037946\n",
      "    episode_reward_min: -226764.03085466946\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -218670.98839767172\n",
      "      - -217525.16387693962\n",
      "      - -217598.1251245332\n",
      "      - -212828.30523694272\n",
      "      - -214509.30646972623\n",
      "      - -218463.3533584307\n",
      "      - -212751.45427942244\n",
      "      - -219172.4474807304\n",
      "      - -219935.72007935436\n",
      "      - -217415.93245400846\n",
      "      - -220452.5858929664\n",
      "      - -216615.87906380073\n",
      "      - -217430.9934319447\n",
      "      - -219018.90308628167\n",
      "      - -214894.7257179552\n",
      "      - -211353.32767410736\n",
      "      - -216925.34065407177\n",
      "      - -215784.90665872575\n",
      "      - -223139.3275009015\n",
      "      - -219623.22251591273\n",
      "      - -217902.91348579098\n",
      "      - -221282.27340299962\n",
      "      - -221689.54342112486\n",
      "      - -212004.12940218285\n",
      "      - -218563.06709599585\n",
      "      - -217453.80325659644\n",
      "      - -218972.09730742645\n",
      "      - -214252.6036623877\n",
      "      - -221275.40654204332\n",
      "      - -211417.9428750247\n",
      "      - -221961.49842049406\n",
      "      - -219125.2742934931\n",
      "      - -220972.2943612898\n",
      "      - -220773.7230615757\n",
      "      - -216402.32658822904\n",
      "      - -208647.7358469245\n",
      "      - -219553.3796994673\n",
      "      - -216551.41678115178\n",
      "      - -213952.63983083982\n",
      "      - -215309.04454025012\n",
      "      - -221693.71112220702\n",
      "      - -219962.1849251252\n",
      "      - -214592.24623645638\n",
      "      - -217185.79858994647\n",
      "      - -222005.71564919068\n",
      "      - -215593.09027344073\n",
      "      - -219145.6396205922\n",
      "      - -218431.09298701695\n",
      "      - -218162.57782009454\n",
      "      - -216398.9101824398\n",
      "      - -214507.38931711088\n",
      "      - -212920.34978529028\n",
      "      - -215608.3802466195\n",
      "      - -226764.03085466946\n",
      "      - -215118.44598429484\n",
      "      - -216826.8261138315\n",
      "      - -212744.98089182936\n",
      "      - -213882.6790695093\n",
      "      - -217802.85941052326\n",
      "      - -213647.7320312183\n",
      "      - -222406.06688874707\n",
      "      - -220077.27534891354\n",
      "      - -216523.13277846616\n",
      "      - -223093.42497906476\n",
      "      - -215795.63158595585\n",
      "      - -215741.15113622553\n",
      "      - -212114.88084412954\n",
      "      - -213705.2509238404\n",
      "      - -222549.9660011762\n",
      "      - -218339.689950548\n",
      "      - -207900.96752774503\n",
      "      - -216358.60030402231\n",
      "      - -217125.0893680523\n",
      "      - -210717.2096936681\n",
      "      - -225869.53346480327\n",
      "      - -220418.35154867847\n",
      "      - -218374.3215906526\n",
      "      - -220593.5860615898\n",
      "      - -218497.61399359087\n",
      "      - -217881.89685865596\n",
      "      - -213611.54395605784\n",
      "      - -218362.42787231796\n",
      "      - -212704.69870922153\n",
      "      - -221745.7893811567\n",
      "      - -222529.71773422565\n",
      "      - -216448.20770971358\n",
      "      - -216522.6788159566\n",
      "      - -222606.0735870323\n",
      "      - -215394.71002981512\n",
      "      - -219870.6933026112\n",
      "      - -214902.6971021193\n",
      "      - -216693.11433655737\n",
      "      - -214217.13339004482\n",
      "      - -215597.65543270417\n",
      "      - -217100.95433849448\n",
      "      - -224438.51241758003\n",
      "      - -212020.0712413058\n",
      "      - -214932.37665988185\n",
      "      - -220458.6023768387\n",
      "      - -217363.38185466614\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.10042129788203256\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.48662321295293154\n",
      "      mean_inference_ms: 1.0279937357084814\n",
      "      mean_raw_obs_processing_ms: 0.1411137507199193\n",
      "  time_since_restore: 382.55814123153687\n",
      "  time_this_iter_s: 8.951240301132202\n",
      "  time_total_s: 382.55814123153687\n",
      "  timers:\n",
      "    learn_throughput: 126625.869\n",
      "    learn_time_ms: 505.3\n",
      "    load_throughput: 22203975.273\n",
      "    load_time_ms: 2.882\n",
      "    training_iteration_time_ms: 9610.471\n",
      "    update_time_ms: 4.07\n",
      "  timestamp: 1665849126\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2431392\n",
      "  training_iteration: 38\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:52:11 (running for 00:06:45.55)<br>Memory usage on this node: 14.1/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">         382.558</td><td style=\"text-align: right;\">2431392</td><td style=\"text-align: right;\"> -217368</td><td style=\"text-align: right;\">             -207901</td><td style=\"text-align: right;\">             -226764</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 2495376\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 2495376\n",
      "    num_agent_steps_trained: 2495376\n",
      "    num_env_steps_sampled: 2495376\n",
      "    num_env_steps_trained: 2495376\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-52-15\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -207900.96752774503\n",
      "  episode_reward_mean: -216574.8876996893\n",
      "  episode_reward_min: -226968.00758351263\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 2484\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.228062629699707\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0006456156843341887\n",
      "          model: {}\n",
      "          policy_loss: -0.0009449039353057742\n",
      "          total_loss: 9.998861312866211\n",
      "          vf_explained_var: -8.514949634275126e-09\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 2495376\n",
      "    num_agent_steps_trained: 2495376\n",
      "    num_env_steps_sampled: 2495376\n",
      "    num_env_steps_trained: 2495376\n",
      "  iterations_since_restore: 39\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 2495376\n",
      "  num_agent_steps_trained: 2495376\n",
      "  num_env_steps_sampled: 2495376\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 2495376\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.73333333333333\n",
      "    ram_util_percent: 91.04166666666667\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10023740571814221\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.48591151720541137\n",
      "    mean_inference_ms: 1.0246923739648062\n",
      "    mean_raw_obs_processing_ms: 0.14074522371044315\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -207900.96752774503\n",
      "    episode_reward_mean: -216574.8876996893\n",
      "    episode_reward_min: -226968.00758351263\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -222406.06688874707\n",
      "      - -220077.27534891354\n",
      "      - -216523.13277846616\n",
      "      - -223093.42497906476\n",
      "      - -215795.63158595585\n",
      "      - -215741.15113622553\n",
      "      - -212114.88084412954\n",
      "      - -213705.2509238404\n",
      "      - -222549.9660011762\n",
      "      - -218339.689950548\n",
      "      - -207900.96752774503\n",
      "      - -216358.60030402231\n",
      "      - -217125.0893680523\n",
      "      - -210717.2096936681\n",
      "      - -225869.53346480327\n",
      "      - -220418.35154867847\n",
      "      - -218374.3215906526\n",
      "      - -220593.5860615898\n",
      "      - -218497.61399359087\n",
      "      - -217881.89685865596\n",
      "      - -213611.54395605784\n",
      "      - -218362.42787231796\n",
      "      - -212704.69870922153\n",
      "      - -221745.7893811567\n",
      "      - -222529.71773422565\n",
      "      - -216448.20770971358\n",
      "      - -216522.6788159566\n",
      "      - -222606.0735870323\n",
      "      - -215394.71002981512\n",
      "      - -219870.6933026112\n",
      "      - -214902.6971021193\n",
      "      - -216693.11433655737\n",
      "      - -214217.13339004482\n",
      "      - -215597.65543270417\n",
      "      - -217100.95433849448\n",
      "      - -224438.51241758003\n",
      "      - -212020.0712413058\n",
      "      - -214932.37665988185\n",
      "      - -220458.6023768387\n",
      "      - -217363.38185466614\n",
      "      - -211714.9441888788\n",
      "      - -218597.05727322493\n",
      "      - -215084.77228837836\n",
      "      - -212482.95051585638\n",
      "      - -211058.13605038525\n",
      "      - -216527.03317679794\n",
      "      - -226968.00758351263\n",
      "      - -218038.01732470878\n",
      "      - -216663.7518691801\n",
      "      - -211560.66423893487\n",
      "      - -216795.69143813598\n",
      "      - -219529.38954947778\n",
      "      - -216847.36311279345\n",
      "      - -213688.44628759313\n",
      "      - -219015.0305966149\n",
      "      - -210519.5365967037\n",
      "      - -213264.26610876145\n",
      "      - -220855.05410403514\n",
      "      - -214896.1057261422\n",
      "      - -215502.09445774156\n",
      "      - -221204.02684917703\n",
      "      - -216345.00314784714\n",
      "      - -216646.56214410113\n",
      "      - -212393.81427852402\n",
      "      - -211862.96394762115\n",
      "      - -211279.37693592568\n",
      "      - -212632.31541534996\n",
      "      - -226865.37468419323\n",
      "      - -210860.3691714256\n",
      "      - -212402.20221996467\n",
      "      - -225398.5591938798\n",
      "      - -218181.24892240364\n",
      "      - -208926.52182562186\n",
      "      - -221471.9618346718\n",
      "      - -212022.34622066992\n",
      "      - -213027.890358833\n",
      "      - -213223.98720837705\n",
      "      - -222213.0397106742\n",
      "      - -215550.88754687257\n",
      "      - -216940.6551772728\n",
      "      - -218715.8458241505\n",
      "      - -207980.02095429707\n",
      "      - -215316.31527564992\n",
      "      - -216025.06378565612\n",
      "      - -212546.8324568896\n",
      "      - -221918.50966538562\n",
      "      - -215527.51950899547\n",
      "      - -220707.66992040438\n",
      "      - -213377.30659379484\n",
      "      - -213453.5226301245\n",
      "      - -215231.64764774384\n",
      "      - -212103.85719889702\n",
      "      - -213552.84882324882\n",
      "      - -215614.68208873546\n",
      "      - -219088.34631601343\n",
      "      - -218054.28955055503\n",
      "      - -218515.02074240346\n",
      "      - -215209.73916399776\n",
      "      - -216299.79041438655\n",
      "      - -217587.84102950938\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.10023740571814221\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.48591151720541137\n",
      "      mean_inference_ms: 1.0246923739648062\n",
      "      mean_raw_obs_processing_ms: 0.14074522371044315\n",
      "  time_since_restore: 391.62517857551575\n",
      "  time_this_iter_s: 9.067037343978882\n",
      "  time_total_s: 391.62517857551575\n",
      "  timers:\n",
      "    learn_throughput: 126923.01\n",
      "    learn_time_ms: 504.117\n",
      "    load_throughput: 22340571.328\n",
      "    load_time_ms: 2.864\n",
      "    training_iteration_time_ms: 9551.222\n",
      "    update_time_ms: 4.19\n",
      "  timestamp: 1665849135\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2495376\n",
      "  training_iteration: 39\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:52:20 (running for 00:06:54.65)<br>Memory usage on this node: 14.1/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         391.625</td><td style=\"text-align: right;\">2495376</td><td style=\"text-align: right;\"> -216575</td><td style=\"text-align: right;\">             -207901</td><td style=\"text-align: right;\">             -226968</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 2559360\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 2559360\n",
      "    num_agent_steps_trained: 2559360\n",
      "    num_env_steps_sampled: 2559360\n",
      "    num_env_steps_trained: 2559360\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-52-23\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -207980.02095429707\n",
      "  episode_reward_mean: -216184.4258534462\n",
      "  episode_reward_min: -249658.92200190452\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 2556\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.224029541015625\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0004600784450303763\n",
      "          model: {}\n",
      "          policy_loss: 0.00474914675578475\n",
      "          total_loss: 10.004517555236816\n",
      "          vf_explained_var: -2.4598742598413992e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 2559360\n",
      "    num_agent_steps_trained: 2559360\n",
      "    num_env_steps_sampled: 2559360\n",
      "    num_env_steps_trained: 2559360\n",
      "  iterations_since_restore: 40\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 2559360\n",
      "  num_agent_steps_trained: 2559360\n",
      "  num_env_steps_sampled: 2559360\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 2559360\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.85384615384615\n",
      "    ram_util_percent: 91.0076923076923\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09983278379996324\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.48427954375637694\n",
      "    mean_inference_ms: 1.0209887085553444\n",
      "    mean_raw_obs_processing_ms: 0.14015107758460701\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -207980.02095429707\n",
      "    episode_reward_mean: -216184.4258534462\n",
      "    episode_reward_min: -249658.92200190452\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -208926.52182562186\n",
      "      - -221471.9618346718\n",
      "      - -212022.34622066992\n",
      "      - -213027.890358833\n",
      "      - -213223.98720837705\n",
      "      - -222213.0397106742\n",
      "      - -215550.88754687257\n",
      "      - -216940.6551772728\n",
      "      - -218715.8458241505\n",
      "      - -207980.02095429707\n",
      "      - -215316.31527564992\n",
      "      - -216025.06378565612\n",
      "      - -212546.8324568896\n",
      "      - -221918.50966538562\n",
      "      - -215527.51950899547\n",
      "      - -220707.66992040438\n",
      "      - -213377.30659379484\n",
      "      - -213453.5226301245\n",
      "      - -215231.64764774384\n",
      "      - -212103.85719889702\n",
      "      - -213552.84882324882\n",
      "      - -215614.68208873546\n",
      "      - -219088.34631601343\n",
      "      - -218054.28955055503\n",
      "      - -218515.02074240346\n",
      "      - -215209.73916399776\n",
      "      - -216299.79041438655\n",
      "      - -217587.84102950938\n",
      "      - -213390.77715964735\n",
      "      - -218156.2542514391\n",
      "      - -211132.74347472345\n",
      "      - -215423.79683156242\n",
      "      - -219321.13978297167\n",
      "      - -213836.90023712767\n",
      "      - -222405.0581301139\n",
      "      - -220245.34493328183\n",
      "      - -220464.30377805443\n",
      "      - -218685.56887009167\n",
      "      - -222202.4649716523\n",
      "      - -214057.63192566374\n",
      "      - -215215.20398778084\n",
      "      - -222249.61738964988\n",
      "      - -214735.44496016827\n",
      "      - -209983.9903504496\n",
      "      - -219204.1632678747\n",
      "      - -210038.34803159596\n",
      "      - -216616.62109774517\n",
      "      - -216346.034721699\n",
      "      - -221725.2059868509\n",
      "      - -210435.66853268817\n",
      "      - -212369.26692970554\n",
      "      - -214061.63385229016\n",
      "      - -216112.75399312162\n",
      "      - -215428.41547022524\n",
      "      - -214672.45018545675\n",
      "      - -214772.79204806502\n",
      "      - -210828.77005802444\n",
      "      - -211839.28381993985\n",
      "      - -215611.06768847414\n",
      "      - -213243.37686962943\n",
      "      - -213057.56803717642\n",
      "      - -217827.16165142722\n",
      "      - -223097.55296896494\n",
      "      - -215983.82563641065\n",
      "      - -216251.24388871194\n",
      "      - -210082.74309597258\n",
      "      - -222665.4291781978\n",
      "      - -210697.28531313007\n",
      "      - -208606.3437687874\n",
      "      - -218579.3572310623\n",
      "      - -219614.63482702622\n",
      "      - -214065.84193661113\n",
      "      - -212885.51707981524\n",
      "      - -212162.14192241445\n",
      "      - -216024.30665248577\n",
      "      - -212834.6675895214\n",
      "      - -214288.97519526677\n",
      "      - -209929.85635586132\n",
      "      - -214533.2219014056\n",
      "      - -211149.3565480628\n",
      "      - -220948.98689681903\n",
      "      - -229397.29728800632\n",
      "      - -221160.2112755325\n",
      "      - -216996.01643121976\n",
      "      - -213325.23803671444\n",
      "      - -249658.92200190452\n",
      "      - -214891.16062520587\n",
      "      - -218131.7823395919\n",
      "      - -213194.56340986965\n",
      "      - -217208.04147970834\n",
      "      - -222662.02934921347\n",
      "      - -218414.0158025438\n",
      "      - -216409.108571022\n",
      "      - -216215.9969614488\n",
      "      - -215933.34391812258\n",
      "      - -218126.7686248288\n",
      "      - -212945.6728024908\n",
      "      - -214626.64134733364\n",
      "      - -217251.83635445358\n",
      "      - -211591.86798868442\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09983278379996324\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.48427954375637694\n",
      "      mean_inference_ms: 1.0209887085553444\n",
      "      mean_raw_obs_processing_ms: 0.14015107758460701\n",
      "  time_since_restore: 400.37104082107544\n",
      "  time_this_iter_s: 8.745862245559692\n",
      "  time_total_s: 400.37104082107544\n",
      "  timers:\n",
      "    learn_throughput: 127804.158\n",
      "    learn_time_ms: 500.641\n",
      "    load_throughput: 22196262.18\n",
      "    load_time_ms: 2.883\n",
      "    training_iteration_time_ms: 9426.972\n",
      "    update_time_ms: 4.285\n",
      "  timestamp: 1665849143\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2559360\n",
      "  training_iteration: 40\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:52:28 (running for 00:07:03.37)<br>Memory usage on this node: 14.1/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         400.371</td><td style=\"text-align: right;\">2559360</td><td style=\"text-align: right;\"> -216184</td><td style=\"text-align: right;\">             -207980</td><td style=\"text-align: right;\">             -249659</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 2623344\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 2623344\n",
      "    num_agent_steps_trained: 2623344\n",
      "    num_env_steps_sampled: 2623344\n",
      "    num_env_steps_trained: 2623344\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-52-32\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -207816.02147320073\n",
      "  episode_reward_mean: -216205.03361394544\n",
      "  episode_reward_min: -249658.92200190452\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 2616\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.2212839126586914\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.000315980170853436\n",
      "          model: {}\n",
      "          policy_loss: 0.007486524526029825\n",
      "          total_loss: 10.007227897644043\n",
      "          vf_explained_var: -3.7844221090210795e-09\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 2623344\n",
      "    num_agent_steps_trained: 2623344\n",
      "    num_env_steps_sampled: 2623344\n",
      "    num_env_steps_trained: 2623344\n",
      "  iterations_since_restore: 41\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 2623344\n",
      "  num_agent_steps_trained: 2623344\n",
      "  num_env_steps_sampled: 2623344\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 2623344\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.39166666666667\n",
      "    ram_util_percent: 90.925\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0996287532064401\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4834134820163245\n",
      "    mean_inference_ms: 1.0181179705634913\n",
      "    mean_raw_obs_processing_ms: 0.14006787631269094\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -207816.02147320073\n",
      "    episode_reward_mean: -216205.03361394544\n",
      "    episode_reward_min: -249658.92200190452\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -213057.56803717642\n",
      "      - -217827.16165142722\n",
      "      - -223097.55296896494\n",
      "      - -215983.82563641065\n",
      "      - -216251.24388871194\n",
      "      - -210082.74309597258\n",
      "      - -222665.4291781978\n",
      "      - -210697.28531313007\n",
      "      - -208606.3437687874\n",
      "      - -218579.3572310623\n",
      "      - -219614.63482702622\n",
      "      - -214065.84193661113\n",
      "      - -212885.51707981524\n",
      "      - -212162.14192241445\n",
      "      - -216024.30665248577\n",
      "      - -212834.6675895214\n",
      "      - -214288.97519526677\n",
      "      - -209929.85635586132\n",
      "      - -214533.2219014056\n",
      "      - -211149.3565480628\n",
      "      - -220948.98689681903\n",
      "      - -229397.29728800632\n",
      "      - -221160.2112755325\n",
      "      - -216996.01643121976\n",
      "      - -213325.23803671444\n",
      "      - -249658.92200190452\n",
      "      - -214891.16062520587\n",
      "      - -218131.7823395919\n",
      "      - -213194.56340986965\n",
      "      - -217208.04147970834\n",
      "      - -222662.02934921347\n",
      "      - -218414.0158025438\n",
      "      - -216409.108571022\n",
      "      - -216215.9969614488\n",
      "      - -215933.34391812258\n",
      "      - -218126.7686248288\n",
      "      - -212945.6728024908\n",
      "      - -214626.64134733364\n",
      "      - -217251.83635445358\n",
      "      - -211591.86798868442\n",
      "      - -216125.55273064613\n",
      "      - -213518.78271700526\n",
      "      - -212212.77091539674\n",
      "      - -217328.74546553503\n",
      "      - -212952.25082316782\n",
      "      - -221910.19547204068\n",
      "      - -215537.25187016415\n",
      "      - -211310.82867912206\n",
      "      - -211489.75960569782\n",
      "      - -244855.40172839435\n",
      "      - -210175.97543428838\n",
      "      - -215320.2829068037\n",
      "      - -213576.64209382856\n",
      "      - -213686.91281742137\n",
      "      - -214663.82008045085\n",
      "      - -220866.81858300194\n",
      "      - -215703.36379971428\n",
      "      - -221202.44561687965\n",
      "      - -217400.76680027653\n",
      "      - -216124.02093064706\n",
      "      - -214505.0981408544\n",
      "      - -219139.82153289416\n",
      "      - -207816.02147320073\n",
      "      - -210198.35432751736\n",
      "      - -214781.84333008184\n",
      "      - -220710.8407906805\n",
      "      - -216868.11674668445\n",
      "      - -216263.50628701554\n",
      "      - -223682.8558397279\n",
      "      - -211570.54412749925\n",
      "      - -217626.9430692712\n",
      "      - -220874.38239616365\n",
      "      - -210147.7012230436\n",
      "      - -220065.020544282\n",
      "      - -216998.0831472789\n",
      "      - -215208.4590128874\n",
      "      - -216071.6454709871\n",
      "      - -214065.6230920023\n",
      "      - -212546.28935675518\n",
      "      - -210729.64489998767\n",
      "      - -216567.81170750677\n",
      "      - -219265.85803112743\n",
      "      - -219031.0342123572\n",
      "      - -214748.05461212946\n",
      "      - -212853.80878771082\n",
      "      - -213811.9528233544\n",
      "      - -214699.276708572\n",
      "      - -211425.7111231509\n",
      "      - -211471.5225825\n",
      "      - -218077.5438439556\n",
      "      - -214083.5886315282\n",
      "      - -214410.71746287282\n",
      "      - -212314.87052044246\n",
      "      - -214114.95866468182\n",
      "      - -217809.6147802537\n",
      "      - -212432.63537961885\n",
      "      - -212450.22799364204\n",
      "      - -217448.992203342\n",
      "      - -214484.63854618452\n",
      "      - -219740.62661728484\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.0996287532064401\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4834134820163245\n",
      "      mean_inference_ms: 1.0181179705634913\n",
      "      mean_raw_obs_processing_ms: 0.14006787631269094\n",
      "  time_since_restore: 409.3521468639374\n",
      "  time_this_iter_s: 8.981106042861938\n",
      "  time_total_s: 409.3521468639374\n",
      "  timers:\n",
      "    learn_throughput: 128206.709\n",
      "    learn_time_ms: 499.069\n",
      "    load_throughput: 22382121.143\n",
      "    load_time_ms: 2.859\n",
      "    training_iteration_time_ms: 9261.072\n",
      "    update_time_ms: 4.349\n",
      "  timestamp: 1665849152\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2623344\n",
      "  training_iteration: 41\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:52:38 (running for 00:07:12.44)<br>Memory usage on this node: 14.1/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    41</td><td style=\"text-align: right;\">         409.352</td><td style=\"text-align: right;\">2623344</td><td style=\"text-align: right;\"> -216205</td><td style=\"text-align: right;\">             -207816</td><td style=\"text-align: right;\">             -249659</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 2687328\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 2687328\n",
      "    num_agent_steps_trained: 2687328\n",
      "    num_env_steps_sampled: 2687328\n",
      "    num_env_steps_trained: 2687328\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-52-41\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -205852.8349482484\n",
      "  episode_reward_mean: -214828.25769325093\n",
      "  episode_reward_min: -223682.8558397279\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 2676\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.2156999111175537\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0005130969220772386\n",
      "          model: {}\n",
      "          policy_loss: -0.0007969269645400345\n",
      "          total_loss: 9.998983383178711\n",
      "          vf_explained_var: -1.8922110101016187e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 2687328\n",
      "    num_agent_steps_trained: 2687328\n",
      "    num_env_steps_sampled: 2687328\n",
      "    num_env_steps_trained: 2687328\n",
      "  iterations_since_restore: 42\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 2687328\n",
      "  num_agent_steps_trained: 2687328\n",
      "  num_env_steps_sampled: 2687328\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 2687328\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 78.55\n",
      "    ram_util_percent: 90.98333333333335\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09926723006086732\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4827763302982166\n",
      "    mean_inference_ms: 1.0140848925255312\n",
      "    mean_raw_obs_processing_ms: 0.1396931542579156\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -205852.8349482484\n",
      "    episode_reward_mean: -214828.25769325093\n",
      "    episode_reward_min: -223682.8558397279\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -214505.0981408544\n",
      "      - -219139.82153289416\n",
      "      - -207816.02147320073\n",
      "      - -210198.35432751736\n",
      "      - -214781.84333008184\n",
      "      - -220710.8407906805\n",
      "      - -216868.11674668445\n",
      "      - -216263.50628701554\n",
      "      - -223682.8558397279\n",
      "      - -211570.54412749925\n",
      "      - -217626.9430692712\n",
      "      - -220874.38239616365\n",
      "      - -210147.7012230436\n",
      "      - -220065.020544282\n",
      "      - -216998.0831472789\n",
      "      - -215208.4590128874\n",
      "      - -216071.6454709871\n",
      "      - -214065.6230920023\n",
      "      - -212546.28935675518\n",
      "      - -210729.64489998767\n",
      "      - -216567.81170750677\n",
      "      - -219265.85803112743\n",
      "      - -219031.0342123572\n",
      "      - -214748.05461212946\n",
      "      - -212853.80878771082\n",
      "      - -213811.9528233544\n",
      "      - -214699.276708572\n",
      "      - -211425.7111231509\n",
      "      - -211471.5225825\n",
      "      - -218077.5438439556\n",
      "      - -214083.5886315282\n",
      "      - -214410.71746287282\n",
      "      - -212314.87052044246\n",
      "      - -214114.95866468182\n",
      "      - -217809.6147802537\n",
      "      - -212432.63537961885\n",
      "      - -212450.22799364204\n",
      "      - -217448.992203342\n",
      "      - -214484.63854618452\n",
      "      - -219740.62661728484\n",
      "      - -216675.25792998655\n",
      "      - -210195.618178962\n",
      "      - -217849.76160716798\n",
      "      - -212228.2882443558\n",
      "      - -212788.784865192\n",
      "      - -220285.48162332867\n",
      "      - -212781.5256018617\n",
      "      - -208769.93757674727\n",
      "      - -214308.6525220824\n",
      "      - -215979.09918685985\n",
      "      - -214726.03679472042\n",
      "      - -216104.55276414665\n",
      "      - -217490.30009166303\n",
      "      - -217048.7518453418\n",
      "      - -219501.24160530616\n",
      "      - -213029.29367425328\n",
      "      - -214997.88968151412\n",
      "      - -219281.29684062218\n",
      "      - -212479.87698850705\n",
      "      - -211940.56214607012\n",
      "      - -215628.83054474322\n",
      "      - -216806.26902977104\n",
      "      - -207164.53663659282\n",
      "      - -212138.04733722724\n",
      "      - -219455.8166995478\n",
      "      - -216691.86676072227\n",
      "      - -217171.82791166956\n",
      "      - -213459.7278007733\n",
      "      - -221397.2080707311\n",
      "      - -208720.0196969882\n",
      "      - -216065.342918575\n",
      "      - -212134.29643542028\n",
      "      - -205852.8349482484\n",
      "      - -214909.23352169123\n",
      "      - -209793.85571132432\n",
      "      - -211965.0141316451\n",
      "      - -212846.4282078929\n",
      "      - -215717.65111299846\n",
      "      - -214694.0929782883\n",
      "      - -214815.67644717562\n",
      "      - -211221.3600509137\n",
      "      - -217913.28324872738\n",
      "      - -215284.70001061962\n",
      "      - -212592.47178841147\n",
      "      - -207361.06876080012\n",
      "      - -216223.52235113695\n",
      "      - -219298.97871790396\n",
      "      - -212315.38802070095\n",
      "      - -214877.4215498152\n",
      "      - -214672.62632267433\n",
      "      - -213555.36289008506\n",
      "      - -213647.90080299156\n",
      "      - -219138.6513556829\n",
      "      - -222502.72457299964\n",
      "      - -213744.83999397798\n",
      "      - -212858.82654027743\n",
      "      - -212985.21035446203\n",
      "      - -212458.15563812075\n",
      "      - -217607.85869138822\n",
      "      - -215560.3909516612\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09926723006086732\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4827763302982166\n",
      "      mean_inference_ms: 1.0140848925255312\n",
      "      mean_raw_obs_processing_ms: 0.1396931542579156\n",
      "  time_since_restore: 417.7663588523865\n",
      "  time_this_iter_s: 8.414211988449097\n",
      "  time_total_s: 417.7663588523865\n",
      "  timers:\n",
      "    learn_throughput: 129750.477\n",
      "    learn_time_ms: 493.131\n",
      "    load_throughput: 22317719.66\n",
      "    load_time_ms: 2.867\n",
      "    training_iteration_time_ms: 9172.796\n",
      "    update_time_ms: 4.426\n",
      "  timestamp: 1665849161\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2687328\n",
      "  training_iteration: 42\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:52:46 (running for 00:07:20.88)<br>Memory usage on this node: 14.1/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         417.766</td><td style=\"text-align: right;\">2687328</td><td style=\"text-align: right;\"> -214828</td><td style=\"text-align: right;\">             -205853</td><td style=\"text-align: right;\">             -223683</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:52:51 (running for 00:07:26.09)<br>Memory usage on this node: 14.1/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         417.766</td><td style=\"text-align: right;\">2687328</td><td style=\"text-align: right;\"> -214828</td><td style=\"text-align: right;\">             -205853</td><td style=\"text-align: right;\">             -223683</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 2751312\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 2751312\n",
      "    num_agent_steps_trained: 2751312\n",
      "    num_env_steps_sampled: 2751312\n",
      "    num_env_steps_trained: 2751312\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-52-51\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -205852.8349482484\n",
      "  episode_reward_mean: -214388.62221192883\n",
      "  episode_reward_min: -224903.46175937983\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 2748\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.215597629547119\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00032368669053539634\n",
      "          model: {}\n",
      "          policy_loss: 0.005437218118458986\n",
      "          total_loss: 10.005179405212402\n",
      "          vf_explained_var: -1.797600468478322e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 2751312\n",
      "    num_agent_steps_trained: 2751312\n",
      "    num_env_steps_sampled: 2751312\n",
      "    num_env_steps_trained: 2751312\n",
      "  iterations_since_restore: 43\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 2751312\n",
      "  num_agent_steps_trained: 2751312\n",
      "  num_env_steps_sampled: 2751312\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 2751312\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 80.16666666666667\n",
      "    ram_util_percent: 91.12000000000002\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09910224655564083\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4818147678555213\n",
      "    mean_inference_ms: 1.0116545466184388\n",
      "    mean_raw_obs_processing_ms: 0.1393893014405192\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -205852.8349482484\n",
      "    episode_reward_mean: -214388.62221192883\n",
      "    episode_reward_min: -224903.46175937983\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -205852.8349482484\n",
      "      - -214909.23352169123\n",
      "      - -209793.85571132432\n",
      "      - -211965.0141316451\n",
      "      - -212846.4282078929\n",
      "      - -215717.65111299846\n",
      "      - -214694.0929782883\n",
      "      - -214815.67644717562\n",
      "      - -211221.3600509137\n",
      "      - -217913.28324872738\n",
      "      - -215284.70001061962\n",
      "      - -212592.47178841147\n",
      "      - -207361.06876080012\n",
      "      - -216223.52235113695\n",
      "      - -219298.97871790396\n",
      "      - -212315.38802070095\n",
      "      - -214877.4215498152\n",
      "      - -214672.62632267433\n",
      "      - -213555.36289008506\n",
      "      - -213647.90080299156\n",
      "      - -219138.6513556829\n",
      "      - -222502.72457299964\n",
      "      - -213744.83999397798\n",
      "      - -212858.82654027743\n",
      "      - -212985.21035446203\n",
      "      - -212458.15563812075\n",
      "      - -217607.85869138822\n",
      "      - -215560.3909516612\n",
      "      - -213201.08684625092\n",
      "      - -211557.05684002372\n",
      "      - -214503.3495906947\n",
      "      - -210683.9843865472\n",
      "      - -215449.73840059488\n",
      "      - -212064.54946807437\n",
      "      - -218133.75160295493\n",
      "      - -218518.8534172508\n",
      "      - -219036.57604040328\n",
      "      - -214428.57460478586\n",
      "      - -220657.9944336524\n",
      "      - -220667.21660454132\n",
      "      - -211629.87610939262\n",
      "      - -215971.76729118996\n",
      "      - -216447.0423724076\n",
      "      - -214141.07702772602\n",
      "      - -217044.46862198188\n",
      "      - -213781.93394209142\n",
      "      - -215854.036025656\n",
      "      - -209846.84939018227\n",
      "      - -212987.253715964\n",
      "      - -213015.5295826074\n",
      "      - -217145.71742888927\n",
      "      - -213972.5119141979\n",
      "      - -213385.70034716916\n",
      "      - -214329.81521660893\n",
      "      - -212810.52990840026\n",
      "      - -215468.32860900206\n",
      "      - -218926.70498892906\n",
      "      - -212473.0418005786\n",
      "      - -219100.11846723425\n",
      "      - -212473.44579112457\n",
      "      - -211466.52126659954\n",
      "      - -209285.08574880703\n",
      "      - -218064.6071044603\n",
      "      - -220109.12824924907\n",
      "      - -218939.18876433393\n",
      "      - -212508.58667530565\n",
      "      - -212894.0768339174\n",
      "      - -214925.12877362405\n",
      "      - -212028.54756205165\n",
      "      - -216108.0675404175\n",
      "      - -215828.07719063223\n",
      "      - -213125.20934540455\n",
      "      - -211943.33562456374\n",
      "      - -210569.30313354818\n",
      "      - -215974.9704036135\n",
      "      - -213179.17094274636\n",
      "      - -216153.27839974532\n",
      "      - -209724.04968334374\n",
      "      - -212677.64341066408\n",
      "      - -210364.42877800253\n",
      "      - -219210.7055483806\n",
      "      - -209111.1395712153\n",
      "      - -211040.65480444618\n",
      "      - -219430.89578834048\n",
      "      - -212744.8666995739\n",
      "      - -214093.5288837277\n",
      "      - -209933.42336085805\n",
      "      - -212067.61842225143\n",
      "      - -213540.63900103566\n",
      "      - -215034.17132618392\n",
      "      - -217396.96712345243\n",
      "      - -212695.07979918696\n",
      "      - -214228.90265262162\n",
      "      - -215091.79808711944\n",
      "      - -213750.8873219113\n",
      "      - -224903.46175937983\n",
      "      - -214441.3743975553\n",
      "      - -215095.87688461668\n",
      "      - -212306.4541432182\n",
      "      - -210751.3597270564\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09910224655564083\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4818147678555213\n",
      "      mean_inference_ms: 1.0116545466184388\n",
      "      mean_raw_obs_processing_ms: 0.1393893014405192\n",
      "  time_since_restore: 428.2574620246887\n",
      "  time_this_iter_s: 10.491103172302246\n",
      "  time_total_s: 428.2574620246887\n",
      "  timers:\n",
      "    learn_throughput: 111179.74\n",
      "    learn_time_ms: 575.501\n",
      "    load_throughput: 22183052.194\n",
      "    load_time_ms: 2.884\n",
      "    training_iteration_time_ms: 9279.89\n",
      "    update_time_ms: 4.366\n",
      "  timestamp: 1665849171\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2751312\n",
      "  training_iteration: 43\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:52:57 (running for 00:07:31.42)<br>Memory usage on this node: 14.1/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    43</td><td style=\"text-align: right;\">         428.257</td><td style=\"text-align: right;\">2751312</td><td style=\"text-align: right;\"> -214389</td><td style=\"text-align: right;\">             -205853</td><td style=\"text-align: right;\">             -224903</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 2815296\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 2815296\n",
      "    num_agent_steps_trained: 2815296\n",
      "    num_env_steps_sampled: 2815296\n",
      "    num_env_steps_trained: 2815296\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-53-01\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -205781.0540200471\n",
      "  episode_reward_mean: -214398.3340799832\n",
      "  episode_reward_min: -252520.3002016456\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 2808\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.2142744064331055\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0006054143887013197\n",
      "          model: {}\n",
      "          policy_loss: 0.00807478278875351\n",
      "          total_loss: 10.00787353515625\n",
      "          vf_explained_var: -2.7437058847112894e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 2815296\n",
      "    num_agent_steps_trained: 2815296\n",
      "    num_env_steps_sampled: 2815296\n",
      "    num_env_steps_trained: 2815296\n",
      "  iterations_since_restore: 44\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 2815296\n",
      "  num_agent_steps_trained: 2815296\n",
      "  num_env_steps_sampled: 2815296\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 2815296\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.53846153846153\n",
      "    ram_util_percent: 91.5076923076923\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.099202365650925\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.48159679674196765\n",
      "    mean_inference_ms: 1.0098179432965815\n",
      "    mean_raw_obs_processing_ms: 0.13953556759534433\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -205781.0540200471\n",
      "    episode_reward_mean: -214398.3340799832\n",
      "    episode_reward_min: -252520.3002016456\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -211466.52126659954\n",
      "      - -209285.08574880703\n",
      "      - -218064.6071044603\n",
      "      - -220109.12824924907\n",
      "      - -218939.18876433393\n",
      "      - -212508.58667530565\n",
      "      - -212894.0768339174\n",
      "      - -214925.12877362405\n",
      "      - -212028.54756205165\n",
      "      - -216108.0675404175\n",
      "      - -215828.07719063223\n",
      "      - -213125.20934540455\n",
      "      - -211943.33562456374\n",
      "      - -210569.30313354818\n",
      "      - -215974.9704036135\n",
      "      - -213179.17094274636\n",
      "      - -216153.27839974532\n",
      "      - -209724.04968334374\n",
      "      - -212677.64341066408\n",
      "      - -210364.42877800253\n",
      "      - -219210.7055483806\n",
      "      - -209111.1395712153\n",
      "      - -211040.65480444618\n",
      "      - -219430.89578834048\n",
      "      - -212744.8666995739\n",
      "      - -214093.5288837277\n",
      "      - -209933.42336085805\n",
      "      - -212067.61842225143\n",
      "      - -213540.63900103566\n",
      "      - -215034.17132618392\n",
      "      - -217396.96712345243\n",
      "      - -212695.07979918696\n",
      "      - -214228.90265262162\n",
      "      - -215091.79808711944\n",
      "      - -213750.8873219113\n",
      "      - -224903.46175937983\n",
      "      - -214441.3743975553\n",
      "      - -215095.87688461668\n",
      "      - -212306.4541432182\n",
      "      - -210751.3597270564\n",
      "      - -212645.514783326\n",
      "      - -214522.73480241088\n",
      "      - -208996.46292094706\n",
      "      - -216932.40375451892\n",
      "      - -214292.34055081883\n",
      "      - -214846.41575908853\n",
      "      - -215220.20555662966\n",
      "      - -219561.68900298444\n",
      "      - -215518.38907011636\n",
      "      - -218599.1817101503\n",
      "      - -221032.4996371255\n",
      "      - -210907.12381573714\n",
      "      - -211439.5498986531\n",
      "      - -220722.68507257313\n",
      "      - -214089.5604123974\n",
      "      - -213059.1239078924\n",
      "      - -217381.23060513026\n",
      "      - -210741.204548236\n",
      "      - -211799.42318888227\n",
      "      - -214122.93341104657\n",
      "      - -212330.58792694693\n",
      "      - -213436.41298835585\n",
      "      - -214399.43742123485\n",
      "      - -219093.37253524025\n",
      "      - -218736.6152767438\n",
      "      - -211479.22348959558\n",
      "      - -212882.78523254395\n",
      "      - -219746.19819399188\n",
      "      - -216873.49978765156\n",
      "      - -212932.3023512777\n",
      "      - -214681.50307136227\n",
      "      - -211212.0203321225\n",
      "      - -213481.42499399587\n",
      "      - -213241.52538306938\n",
      "      - -210475.2148843542\n",
      "      - -217406.44612117822\n",
      "      - -209722.49642801544\n",
      "      - -207995.5798070048\n",
      "      - -215027.06759310357\n",
      "      - -214567.52587622116\n",
      "      - -214255.73817599716\n",
      "      - -218086.66480162618\n",
      "      - -205781.0540200471\n",
      "      - -216214.71600806076\n",
      "      - -212407.20857037924\n",
      "      - -252520.3002016456\n",
      "      - -210592.15508122172\n",
      "      - -211863.40830078183\n",
      "      - -219461.34236768837\n",
      "      - -219882.32283170088\n",
      "      - -215392.83021528024\n",
      "      - -207732.17606914326\n",
      "      - -215895.5658864962\n",
      "      - -212261.35999966788\n",
      "      - -207849.36654011274\n",
      "      - -211307.90683772683\n",
      "      - -212692.00279040265\n",
      "      - -213314.0970795267\n",
      "      - -212961.34910010578\n",
      "      - -210471.72028487502\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.099202365650925\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.48159679674196765\n",
      "      mean_inference_ms: 1.0098179432965815\n",
      "      mean_raw_obs_processing_ms: 0.13953556759534433\n",
      "  time_since_restore: 437.53898763656616\n",
      "  time_this_iter_s: 9.281525611877441\n",
      "  time_total_s: 437.53898763656616\n",
      "  timers:\n",
      "    learn_throughput: 110626.029\n",
      "    learn_time_ms: 578.381\n",
      "    load_throughput: 22258671.218\n",
      "    load_time_ms: 2.875\n",
      "    training_iteration_time_ms: 9265.51\n",
      "    update_time_ms: 4.254\n",
      "  timestamp: 1665849181\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2815296\n",
      "  training_iteration: 44\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:53:06 (running for 00:07:40.66)<br>Memory usage on this node: 14.2/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    44</td><td style=\"text-align: right;\">         437.539</td><td style=\"text-align: right;\">2815296</td><td style=\"text-align: right;\"> -214398</td><td style=\"text-align: right;\">             -205781</td><td style=\"text-align: right;\">             -252520</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 2879280\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 2879280\n",
      "    num_agent_steps_trained: 2879280\n",
      "    num_env_steps_sampled: 2879280\n",
      "    num_env_steps_trained: 2879280\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-53-10\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -205781.0540200471\n",
      "  episode_reward_mean: -214328.03415298808\n",
      "  episode_reward_min: -252520.3002016456\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 2868\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.210197687149048\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.000858970801346004\n",
      "          model: {}\n",
      "          policy_loss: -0.0009276125929318368\n",
      "          total_loss: 9.998923301696777\n",
      "          vf_explained_var: -2.6490953430879927e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 2879280\n",
      "    num_agent_steps_trained: 2879280\n",
      "    num_env_steps_sampled: 2879280\n",
      "    num_env_steps_trained: 2879280\n",
      "  iterations_since_restore: 45\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 2879280\n",
      "  num_agent_steps_trained: 2879280\n",
      "  num_env_steps_sampled: 2879280\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 2879280\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.09285714285716\n",
      "    ram_util_percent: 91.61428571428571\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09911542399143361\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.48194962288937804\n",
      "    mean_inference_ms: 1.007984333442067\n",
      "    mean_raw_obs_processing_ms: 0.13942608196596848\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -205781.0540200471\n",
      "    episode_reward_mean: -214328.03415298808\n",
      "    episode_reward_min: -252520.3002016456\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -212330.58792694693\n",
      "      - -213436.41298835585\n",
      "      - -214399.43742123485\n",
      "      - -219093.37253524025\n",
      "      - -218736.6152767438\n",
      "      - -211479.22348959558\n",
      "      - -212882.78523254395\n",
      "      - -219746.19819399188\n",
      "      - -216873.49978765156\n",
      "      - -212932.3023512777\n",
      "      - -214681.50307136227\n",
      "      - -211212.0203321225\n",
      "      - -213481.42499399587\n",
      "      - -213241.52538306938\n",
      "      - -210475.2148843542\n",
      "      - -217406.44612117822\n",
      "      - -209722.49642801544\n",
      "      - -207995.5798070048\n",
      "      - -215027.06759310357\n",
      "      - -214567.52587622116\n",
      "      - -214255.73817599716\n",
      "      - -218086.66480162618\n",
      "      - -205781.0540200471\n",
      "      - -216214.71600806076\n",
      "      - -212407.20857037924\n",
      "      - -252520.3002016456\n",
      "      - -210592.15508122172\n",
      "      - -211863.40830078183\n",
      "      - -219461.34236768837\n",
      "      - -219882.32283170088\n",
      "      - -215392.83021528024\n",
      "      - -207732.17606914326\n",
      "      - -215895.5658864962\n",
      "      - -212261.35999966788\n",
      "      - -207849.36654011274\n",
      "      - -211307.90683772683\n",
      "      - -212692.00279040265\n",
      "      - -213314.0970795267\n",
      "      - -212961.34910010578\n",
      "      - -210471.72028487502\n",
      "      - -211744.30711217632\n",
      "      - -213021.00767909165\n",
      "      - -214159.3496836698\n",
      "      - -209826.1650886124\n",
      "      - -211407.28249398083\n",
      "      - -215274.92343987047\n",
      "      - -215240.0557240093\n",
      "      - -208858.58756546112\n",
      "      - -225628.0667468819\n",
      "      - -214869.4451698212\n",
      "      - -215728.79079418996\n",
      "      - -216851.82720668253\n",
      "      - -217445.70310324378\n",
      "      - -211938.96317648355\n",
      "      - -208346.24512285076\n",
      "      - -208343.45819430726\n",
      "      - -219280.81719348632\n",
      "      - -218302.21661477885\n",
      "      - -216175.0756301404\n",
      "      - -218789.57330504517\n",
      "      - -210059.30792667024\n",
      "      - -218538.64034361238\n",
      "      - -218473.7212856163\n",
      "      - -217687.14023015788\n",
      "      - -213733.01717345018\n",
      "      - -211095.60035743698\n",
      "      - -219383.1446920703\n",
      "      - -217459.37828528014\n",
      "      - -216259.0652443377\n",
      "      - -214237.26521089015\n",
      "      - -211481.11804352893\n",
      "      - -213374.10368234795\n",
      "      - -211798.64139539702\n",
      "      - -216043.62721033482\n",
      "      - -212523.51197408355\n",
      "      - -211184.76895386382\n",
      "      - -207440.22279762235\n",
      "      - -214983.92441554824\n",
      "      - -208856.38585411283\n",
      "      - -209578.78046122578\n",
      "      - -206530.64981189312\n",
      "      - -220384.0839163853\n",
      "      - -218954.60034634577\n",
      "      - -208220.61979903028\n",
      "      - -210912.24714536426\n",
      "      - -212024.59594107812\n",
      "      - -217143.2830360331\n",
      "      - -217413.97606120122\n",
      "      - -212374.0235531646\n",
      "      - -216341.9009775507\n",
      "      - -212386.52533316932\n",
      "      - -211620.37997214665\n",
      "      - -216479.40587741043\n",
      "      - -225117.04376228715\n",
      "      - -214906.73805268577\n",
      "      - -209228.6511100848\n",
      "      - -210913.77678143643\n",
      "      - -216354.06124654546\n",
      "      - -212985.87546250728\n",
      "      - -216423.2256736222\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09911542399143361\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.48194962288937804\n",
      "      mean_inference_ms: 1.007984333442067\n",
      "      mean_raw_obs_processing_ms: 0.13942608196596848\n",
      "  time_since_restore: 447.0798764228821\n",
      "  time_this_iter_s: 9.540888786315918\n",
      "  time_total_s: 447.0798764228821\n",
      "  timers:\n",
      "    learn_throughput: 111081.508\n",
      "    learn_time_ms: 576.009\n",
      "    load_throughput: 22095749.7\n",
      "    load_time_ms: 2.896\n",
      "    training_iteration_time_ms: 9259.499\n",
      "    update_time_ms: 4.233\n",
      "  timestamp: 1665849190\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2879280\n",
      "  training_iteration: 45\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:53:15 (running for 00:07:50.27)<br>Memory usage on this node: 14.2/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    45</td><td style=\"text-align: right;\">          447.08</td><td style=\"text-align: right;\">2879280</td><td style=\"text-align: right;\"> -214328</td><td style=\"text-align: right;\">             -205781</td><td style=\"text-align: right;\">             -252520</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 2943264\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 2943264\n",
      "    num_agent_steps_trained: 2943264\n",
      "    num_env_steps_sampled: 2943264\n",
      "    num_env_steps_trained: 2943264\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-53-19\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -204940.06613914983\n",
      "  episode_reward_mean: -213080.25810674022\n",
      "  episode_reward_min: -225117.04376228715\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 2940\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.2134275436401367\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0002448953746352345\n",
      "          model: {}\n",
      "          policy_loss: 0.005803263280540705\n",
      "          total_loss: 10.005531311035156\n",
      "          vf_explained_var: -4.730527436436205e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 2943264\n",
      "    num_agent_steps_trained: 2943264\n",
      "    num_env_steps_sampled: 2943264\n",
      "    num_env_steps_trained: 2943264\n",
      "  iterations_since_restore: 46\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 2943264\n",
      "  num_agent_steps_trained: 2943264\n",
      "  num_env_steps_sampled: 2943264\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 2943264\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 78.9\n",
      "    ram_util_percent: 91.61538461538461\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0988206961825175\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.48121877336692004\n",
      "    mean_inference_ms: 1.0057242669278075\n",
      "    mean_raw_obs_processing_ms: 0.13915612311216857\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -204940.06613914983\n",
      "    episode_reward_mean: -213080.25810674022\n",
      "    episode_reward_min: -225117.04376228715\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -211798.64139539702\n",
      "      - -216043.62721033482\n",
      "      - -212523.51197408355\n",
      "      - -211184.76895386382\n",
      "      - -207440.22279762235\n",
      "      - -214983.92441554824\n",
      "      - -208856.38585411283\n",
      "      - -209578.78046122578\n",
      "      - -206530.64981189312\n",
      "      - -220384.0839163853\n",
      "      - -218954.60034634577\n",
      "      - -208220.61979903028\n",
      "      - -210912.24714536426\n",
      "      - -212024.59594107812\n",
      "      - -217143.2830360331\n",
      "      - -217413.97606120122\n",
      "      - -212374.0235531646\n",
      "      - -216341.9009775507\n",
      "      - -212386.52533316932\n",
      "      - -211620.37997214665\n",
      "      - -216479.40587741043\n",
      "      - -225117.04376228715\n",
      "      - -214906.73805268577\n",
      "      - -209228.6511100848\n",
      "      - -210913.77678143643\n",
      "      - -216354.06124654546\n",
      "      - -212985.87546250728\n",
      "      - -216423.2256736222\n",
      "      - -208742.98308064364\n",
      "      - -214313.53069220335\n",
      "      - -212558.7129857244\n",
      "      - -213027.57915659592\n",
      "      - -208736.41636501485\n",
      "      - -215121.06259018285\n",
      "      - -217109.83556952115\n",
      "      - -213191.08215782093\n",
      "      - -214185.8776401929\n",
      "      - -219358.40928929165\n",
      "      - -210213.5375148835\n",
      "      - -211011.3335338962\n",
      "      - -212086.56181423363\n",
      "      - -209316.4893255498\n",
      "      - -215530.39387178177\n",
      "      - -216980.61193712137\n",
      "      - -211032.7244017456\n",
      "      - -212596.31226536233\n",
      "      - -212614.38802672309\n",
      "      - -211425.42179647757\n",
      "      - -208789.4796027209\n",
      "      - -209754.76661172713\n",
      "      - -213381.3192757003\n",
      "      - -213544.278420392\n",
      "      - -218317.4243693708\n",
      "      - -204940.06613914983\n",
      "      - -213064.56010089038\n",
      "      - -213647.54644721837\n",
      "      - -211276.4911184034\n",
      "      - -216754.95619725325\n",
      "      - -218895.5705051367\n",
      "      - -216985.67058850272\n",
      "      - -214790.45447193668\n",
      "      - -213917.19849684453\n",
      "      - -209343.35525398952\n",
      "      - -213256.4553643142\n",
      "      - -218007.64306444486\n",
      "      - -217244.34987978553\n",
      "      - -209888.3840709216\n",
      "      - -215109.08325972853\n",
      "      - -208815.36005671916\n",
      "      - -207096.04279515875\n",
      "      - -213023.42072646745\n",
      "      - -213324.3087239335\n",
      "      - -212412.81269087398\n",
      "      - -206908.56183631453\n",
      "      - -209010.02601928453\n",
      "      - -209051.35542519705\n",
      "      - -219265.40437523415\n",
      "      - -208805.17661984888\n",
      "      - -211313.44846491967\n",
      "      - -215028.74955720978\n",
      "      - -209926.94448013598\n",
      "      - -210831.65700919201\n",
      "      - -215184.51167398246\n",
      "      - -213608.92454598442\n",
      "      - -213174.75754900576\n",
      "      - -213281.16647968508\n",
      "      - -210448.0716339008\n",
      "      - -211531.8666862097\n",
      "      - -213684.45352619447\n",
      "      - -216138.06266500222\n",
      "      - -211662.27556795612\n",
      "      - -211035.34344627245\n",
      "      - -219717.5857931845\n",
      "      - -213382.65694143058\n",
      "      - -217448.69096971536\n",
      "      - -210035.42312289262\n",
      "      - -212421.46153435434\n",
      "      - -213251.52452007763\n",
      "      - -216783.62649678992\n",
      "      - -211234.29456537234\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.0988206961825175\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.48121877336692004\n",
      "      mean_inference_ms: 1.0057242669278075\n",
      "      mean_raw_obs_processing_ms: 0.13915612311216857\n",
      "  time_since_restore: 456.0688781738281\n",
      "  time_this_iter_s: 8.989001750946045\n",
      "  time_total_s: 456.0688781738281\n",
      "  timers:\n",
      "    learn_throughput: 111555.637\n",
      "    learn_time_ms: 573.561\n",
      "    load_throughput: 21861042.769\n",
      "    load_time_ms: 2.927\n",
      "    training_iteration_time_ms: 9139.356\n",
      "    update_time_ms: 4.196\n",
      "  timestamp: 1665849199\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2943264\n",
      "  training_iteration: 46\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:53:24 (running for 00:07:59.36)<br>Memory usage on this node: 14.2/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    46</td><td style=\"text-align: right;\">         456.069</td><td style=\"text-align: right;\">2943264</td><td style=\"text-align: right;\"> -213080</td><td style=\"text-align: right;\">             -204940</td><td style=\"text-align: right;\">             -225117</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 3007248\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 3007248\n",
      "    num_agent_steps_trained: 3007248\n",
      "    num_env_steps_sampled: 3007248\n",
      "    num_env_steps_trained: 3007248\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-53-28\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -205798.15179681694\n",
      "  episode_reward_mean: -212653.0057965227\n",
      "  episode_reward_min: -222169.6376325864\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 3000\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.212869882583618\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0003671497688628733\n",
      "          model: {}\n",
      "          policy_loss: 0.00651486124843359\n",
      "          total_loss: 10.006267547607422\n",
      "          vf_explained_var: -1.3245476715439963e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 3007248\n",
      "    num_agent_steps_trained: 3007248\n",
      "    num_env_steps_sampled: 3007248\n",
      "    num_env_steps_trained: 3007248\n",
      "  iterations_since_restore: 47\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 3007248\n",
      "  num_agent_steps_trained: 3007248\n",
      "  num_env_steps_sampled: 3007248\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 3007248\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.41666666666667\n",
      "    ram_util_percent: 91.63333333333334\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09872554046105267\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.48051809872295004\n",
      "    mean_inference_ms: 1.0035269019414343\n",
      "    mean_raw_obs_processing_ms: 0.13907862403608784\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -205798.15179681694\n",
      "    episode_reward_mean: -212653.0057965227\n",
      "    episode_reward_min: -222169.6376325864\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -214790.45447193668\n",
      "      - -213917.19849684453\n",
      "      - -209343.35525398952\n",
      "      - -213256.4553643142\n",
      "      - -218007.64306444486\n",
      "      - -217244.34987978553\n",
      "      - -209888.3840709216\n",
      "      - -215109.08325972853\n",
      "      - -208815.36005671916\n",
      "      - -207096.04279515875\n",
      "      - -213023.42072646745\n",
      "      - -213324.3087239335\n",
      "      - -212412.81269087398\n",
      "      - -206908.56183631453\n",
      "      - -209010.02601928453\n",
      "      - -209051.35542519705\n",
      "      - -219265.40437523415\n",
      "      - -208805.17661984888\n",
      "      - -211313.44846491967\n",
      "      - -215028.74955720978\n",
      "      - -209926.94448013598\n",
      "      - -210831.65700919201\n",
      "      - -215184.51167398246\n",
      "      - -213608.92454598442\n",
      "      - -213174.75754900576\n",
      "      - -213281.16647968508\n",
      "      - -210448.0716339008\n",
      "      - -211531.8666862097\n",
      "      - -213684.45352619447\n",
      "      - -216138.06266500222\n",
      "      - -211662.27556795612\n",
      "      - -211035.34344627245\n",
      "      - -219717.5857931845\n",
      "      - -213382.65694143058\n",
      "      - -217448.69096971536\n",
      "      - -210035.42312289262\n",
      "      - -212421.46153435434\n",
      "      - -213251.52452007763\n",
      "      - -216783.62649678992\n",
      "      - -211234.29456537234\n",
      "      - -206548.36191444084\n",
      "      - -208342.36058726342\n",
      "      - -210359.99839143004\n",
      "      - -207590.6042773544\n",
      "      - -210863.53834244734\n",
      "      - -212493.15500123677\n",
      "      - -222169.6376325864\n",
      "      - -209026.76348581217\n",
      "      - -216866.56981327495\n",
      "      - -213175.68141380054\n",
      "      - -208103.24371067\n",
      "      - -215264.24719625377\n",
      "      - -212673.306448414\n",
      "      - -210631.8495787709\n",
      "      - -217722.89216855634\n",
      "      - -215151.22979749035\n",
      "      - -209524.2031328054\n",
      "      - -213898.5328254598\n",
      "      - -212215.38491951177\n",
      "      - -207471.1322724432\n",
      "      - -208505.65243194567\n",
      "      - -221036.51792419335\n",
      "      - -212261.777911752\n",
      "      - -212090.17985145358\n",
      "      - -218076.27402451166\n",
      "      - -217036.20967271095\n",
      "      - -210282.94364716185\n",
      "      - -218343.13224450825\n",
      "      - -215933.85960109127\n",
      "      - -212477.58908430103\n",
      "      - -212708.25201448\n",
      "      - -208321.22817960536\n",
      "      - -210682.8196570662\n",
      "      - -209713.70231192114\n",
      "      - -205798.15179681694\n",
      "      - -216775.4111126376\n",
      "      - -213026.03073554067\n",
      "      - -216018.39018777557\n",
      "      - -210197.4905942769\n",
      "      - -219612.24598155278\n",
      "      - -215003.93139653618\n",
      "      - -211610.47615362008\n",
      "      - -209284.2467331975\n",
      "      - -215952.23325506985\n",
      "      - -215441.89737423565\n",
      "      - -212204.50995705763\n",
      "      - -212718.80853582843\n",
      "      - -210486.16963551508\n",
      "      - -210139.94323280582\n",
      "      - -210263.2125870417\n",
      "      - -216272.7221017675\n",
      "      - -213517.6409998149\n",
      "      - -214940.87679616784\n",
      "      - -211480.85995320705\n",
      "      - -209393.18494448008\n",
      "      - -208035.10793845964\n",
      "      - -215136.34269985024\n",
      "      - -213452.34795770334\n",
      "      - -208981.99041407794\n",
      "      - -211598.63475003946\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09872554046105267\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.48051809872295004\n",
      "      mean_inference_ms: 1.0035269019414343\n",
      "      mean_raw_obs_processing_ms: 0.13907862403608784\n",
      "  time_since_restore: 464.9814383983612\n",
      "  time_this_iter_s: 8.912560224533081\n",
      "  time_total_s: 464.9814383983612\n",
      "  timers:\n",
      "    learn_throughput: 111527.617\n",
      "    learn_time_ms: 573.705\n",
      "    load_throughput: 21748368.853\n",
      "    load_time_ms: 2.942\n",
      "    training_iteration_time_ms: 9130.432\n",
      "    update_time_ms: 4.013\n",
      "  timestamp: 1665849208\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3007248\n",
      "  training_iteration: 47\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:53:33 (running for 00:08:08.23)<br>Memory usage on this node: 14.2/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    47</td><td style=\"text-align: right;\">         464.981</td><td style=\"text-align: right;\">3007248</td><td style=\"text-align: right;\"> -212653</td><td style=\"text-align: right;\">             -205798</td><td style=\"text-align: right;\">             -222170</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 3071232\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 3071232\n",
      "    num_agent_steps_trained: 3071232\n",
      "    num_env_steps_sampled: 3071232\n",
      "    num_env_steps_trained: 3071232\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-53-37\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -205251.8633657829\n",
      "  episode_reward_mean: -213164.45818073905\n",
      "  episode_reward_min: -253443.61497098755\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 3060\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.209899663925171\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0003461216692812741\n",
      "          model: {}\n",
      "          policy_loss: 0.0015112780965864658\n",
      "          total_loss: 10.001258850097656\n",
      "          vf_explained_var: -1.5137688436084318e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 3071232\n",
      "    num_agent_steps_trained: 3071232\n",
      "    num_env_steps_sampled: 3071232\n",
      "    num_env_steps_trained: 3071232\n",
      "  iterations_since_restore: 48\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 3071232\n",
      "  num_agent_steps_trained: 3071232\n",
      "  num_env_steps_sampled: 3071232\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 3071232\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.4\n",
      "    ram_util_percent: 91.58461538461538\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09840792970918645\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4800756083408793\n",
      "    mean_inference_ms: 1.0011183360537153\n",
      "    mean_raw_obs_processing_ms: 0.13865230953451227\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -205251.8633657829\n",
      "    episode_reward_mean: -213164.45818073905\n",
      "    episode_reward_min: -253443.61497098755\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -208505.65243194567\n",
      "      - -221036.51792419335\n",
      "      - -212261.777911752\n",
      "      - -212090.17985145358\n",
      "      - -218076.27402451166\n",
      "      - -217036.20967271095\n",
      "      - -210282.94364716185\n",
      "      - -218343.13224450825\n",
      "      - -215933.85960109127\n",
      "      - -212477.58908430103\n",
      "      - -212708.25201448\n",
      "      - -208321.22817960536\n",
      "      - -210682.8196570662\n",
      "      - -209713.70231192114\n",
      "      - -205798.15179681694\n",
      "      - -216775.4111126376\n",
      "      - -213026.03073554067\n",
      "      - -216018.39018777557\n",
      "      - -210197.4905942769\n",
      "      - -219612.24598155278\n",
      "      - -215003.93139653618\n",
      "      - -211610.47615362008\n",
      "      - -209284.2467331975\n",
      "      - -215952.23325506985\n",
      "      - -215441.89737423565\n",
      "      - -212204.50995705763\n",
      "      - -212718.80853582843\n",
      "      - -210486.16963551508\n",
      "      - -210139.94323280582\n",
      "      - -210263.2125870417\n",
      "      - -216272.7221017675\n",
      "      - -213517.6409998149\n",
      "      - -214940.87679616784\n",
      "      - -211480.85995320705\n",
      "      - -209393.18494448008\n",
      "      - -208035.10793845964\n",
      "      - -215136.34269985024\n",
      "      - -213452.34795770334\n",
      "      - -208981.99041407794\n",
      "      - -211598.63475003946\n",
      "      - -208488.92238108648\n",
      "      - -207642.7407871956\n",
      "      - -208750.67969517858\n",
      "      - -215343.0027247218\n",
      "      - -211021.5971355203\n",
      "      - -216084.46440809686\n",
      "      - -205251.8633657829\n",
      "      - -210553.60907394675\n",
      "      - -213690.66792586632\n",
      "      - -215628.82089296103\n",
      "      - -225315.11861256527\n",
      "      - -235385.9254021076\n",
      "      - -210969.00138953878\n",
      "      - -210193.92781942664\n",
      "      - -210096.0096704567\n",
      "      - -214069.33496797734\n",
      "      - -207303.96458062352\n",
      "      - -212709.040705153\n",
      "      - -253443.61497098755\n",
      "      - -210138.5329169618\n",
      "      - -208281.41655642632\n",
      "      - -210917.4492099684\n",
      "      - -214919.07860302366\n",
      "      - -218041.6004190985\n",
      "      - -214720.31982612188\n",
      "      - -216099.96820564813\n",
      "      - -208231.08983373936\n",
      "      - -211444.3118350584\n",
      "      - -208558.1495139932\n",
      "      - -208602.21319757157\n",
      "      - -209211.6501073573\n",
      "      - -217822.98318803558\n",
      "      - -214395.8766286053\n",
      "      - -214888.04782875974\n",
      "      - -212062.12096335253\n",
      "      - -210732.09572091387\n",
      "      - -212680.43691265708\n",
      "      - -215164.6011471523\n",
      "      - -215992.34953297427\n",
      "      - -212754.04732832496\n",
      "      - -218842.59614060415\n",
      "      - -214377.93836710378\n",
      "      - -210519.60805589415\n",
      "      - -207339.7126573086\n",
      "      - -215257.31045837826\n",
      "      - -206170.03995385868\n",
      "      - -213300.7478122565\n",
      "      - -210403.8019835244\n",
      "      - -215896.3699932453\n",
      "      - -210901.10135118212\n",
      "      - -211479.76441622918\n",
      "      - -209078.66864149072\n",
      "      - -211769.19273992142\n",
      "      - -210764.1549918665\n",
      "      - -214388.6538869249\n",
      "      - -212079.24167771242\n",
      "      - -216617.16745531475\n",
      "      - -214084.55833318763\n",
      "      - -208781.93671188923\n",
      "      - -211979.61007929596\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09840792970918645\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4800756083408793\n",
      "      mean_inference_ms: 1.0011183360537153\n",
      "      mean_raw_obs_processing_ms: 0.13865230953451227\n",
      "  time_since_restore: 473.81106209754944\n",
      "  time_this_iter_s: 8.829623699188232\n",
      "  time_total_s: 473.81106209754944\n",
      "  timers:\n",
      "    learn_throughput: 111615.637\n",
      "    learn_time_ms: 573.253\n",
      "    load_throughput: 21834718.949\n",
      "    load_time_ms: 2.93\n",
      "    training_iteration_time_ms: 9118.365\n",
      "    update_time_ms: 4.003\n",
      "  timestamp: 1665849217\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3071232\n",
      "  training_iteration: 48\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:53:42 (running for 00:08:17.17)<br>Memory usage on this node: 14.2/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    48</td><td style=\"text-align: right;\">         473.811</td><td style=\"text-align: right;\">3071232</td><td style=\"text-align: right;\"> -213164</td><td style=\"text-align: right;\">             -205252</td><td style=\"text-align: right;\">             -253444</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 3135216\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 3135216\n",
      "    num_agent_steps_trained: 3135216\n",
      "    num_env_steps_sampled: 3135216\n",
      "    num_env_steps_trained: 3135216\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-53-47\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -205926.5302903076\n",
      "  episode_reward_mean: -213928.3928186618\n",
      "  episode_reward_min: -252777.17906708206\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 3132\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.21120285987854\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0003468189388513565\n",
      "          model: {}\n",
      "          policy_loss: 0.0036095967516303062\n",
      "          total_loss: 10.003357887268066\n",
      "          vf_explained_var: -2.3652637182181024e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 3135216\n",
      "    num_agent_steps_trained: 3135216\n",
      "    num_env_steps_sampled: 3135216\n",
      "    num_env_steps_trained: 3135216\n",
      "  iterations_since_restore: 49\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 3135216\n",
      "  num_agent_steps_trained: 3135216\n",
      "  num_env_steps_sampled: 3135216\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 3135216\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.53076923076924\n",
      "    ram_util_percent: 91.74615384615383\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09804768355796088\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.47922031309108504\n",
      "    mean_inference_ms: 1.0001880632820892\n",
      "    mean_raw_obs_processing_ms: 0.138293776862345\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -205926.5302903076\n",
      "    episode_reward_mean: -213928.3928186618\n",
      "    episode_reward_min: -252777.17906708206\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -214395.8766286053\n",
      "      - -214888.04782875974\n",
      "      - -212062.12096335253\n",
      "      - -210732.09572091387\n",
      "      - -212680.43691265708\n",
      "      - -215164.6011471523\n",
      "      - -215992.34953297427\n",
      "      - -212754.04732832496\n",
      "      - -218842.59614060415\n",
      "      - -214377.93836710378\n",
      "      - -210519.60805589415\n",
      "      - -207339.7126573086\n",
      "      - -215257.31045837826\n",
      "      - -206170.03995385868\n",
      "      - -213300.7478122565\n",
      "      - -210403.8019835244\n",
      "      - -215896.3699932453\n",
      "      - -210901.10135118212\n",
      "      - -211479.76441622918\n",
      "      - -209078.66864149072\n",
      "      - -211769.19273992142\n",
      "      - -210764.1549918665\n",
      "      - -214388.6538869249\n",
      "      - -212079.24167771242\n",
      "      - -216617.16745531475\n",
      "      - -214084.55833318763\n",
      "      - -208781.93671188923\n",
      "      - -211979.61007929596\n",
      "      - -215284.60560645326\n",
      "      - -213480.12166213454\n",
      "      - -216865.45924755107\n",
      "      - -210180.86739557702\n",
      "      - -220328.1690024777\n",
      "      - -214974.15431509473\n",
      "      - -206936.91225037602\n",
      "      - -211410.67313348988\n",
      "      - -213281.24365479054\n",
      "      - -206515.54623899062\n",
      "      - -210395.60269196244\n",
      "      - -210513.62235413832\n",
      "      - -212645.19459698987\n",
      "      - -214481.4611697595\n",
      "      - -217951.31608563804\n",
      "      - -208809.8924962468\n",
      "      - -215263.2078433887\n",
      "      - -215481.6071680859\n",
      "      - -214874.03676099045\n",
      "      - -209846.65553793637\n",
      "      - -214813.5925918039\n",
      "      - -213216.81910008474\n",
      "      - -212462.5732354301\n",
      "      - -213161.68415382315\n",
      "      - -212055.58451554546\n",
      "      - -212418.39021835377\n",
      "      - -212655.03926114654\n",
      "      - -252777.17906708206\n",
      "      - -214522.55917023492\n",
      "      - -208184.82774057201\n",
      "      - -215232.21174699542\n",
      "      - -209127.65300950018\n",
      "      - -213340.9559571802\n",
      "      - -217451.59841417926\n",
      "      - -206729.68074641892\n",
      "      - -217987.07434519255\n",
      "      - -210440.24905107656\n",
      "      - -210595.34581289758\n",
      "      - -216249.28092385188\n",
      "      - -210654.75008070568\n",
      "      - -211703.6723826255\n",
      "      - -213469.08783534548\n",
      "      - -218220.99449203172\n",
      "      - -219836.17439932137\n",
      "      - -212992.04489954503\n",
      "      - -206724.21350705076\n",
      "      - -245269.47714087265\n",
      "      - -210927.68366282614\n",
      "      - -213347.1251303232\n",
      "      - -216206.20655625602\n",
      "      - -214313.81989262172\n",
      "      - -211225.49021095253\n",
      "      - -207031.61004370844\n",
      "      - -250341.75220083626\n",
      "      - -209043.28436952434\n",
      "      - -210873.550431042\n",
      "      - -215304.2055933312\n",
      "      - -215968.21677313244\n",
      "      - -209144.9613082205\n",
      "      - -214065.93765819952\n",
      "      - -212259.27621730173\n",
      "      - -209014.73455319268\n",
      "      - -206369.45040315986\n",
      "      - -208105.97603882416\n",
      "      - -209319.5192788586\n",
      "      - -216835.29458296733\n",
      "      - -205926.5302903076\n",
      "      - -216548.1594259486\n",
      "      - -213703.4973713935\n",
      "      - -219861.9170110201\n",
      "      - -220357.85878493678\n",
      "      - -222228.40929642707\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09804768355796088\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.47922031309108504\n",
      "      mean_inference_ms: 1.0001880632820892\n",
      "      mean_raw_obs_processing_ms: 0.138293776862345\n",
      "  time_since_restore: 483.43379187583923\n",
      "  time_this_iter_s: 9.622729778289795\n",
      "  time_total_s: 483.43379187583923\n",
      "  timers:\n",
      "    learn_throughput: 111956.47\n",
      "    learn_time_ms: 571.508\n",
      "    load_throughput: 21702640.945\n",
      "    load_time_ms: 2.948\n",
      "    training_iteration_time_ms: 9173.973\n",
      "    update_time_ms: 3.896\n",
      "  timestamp: 1665849227\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3135216\n",
      "  training_iteration: 49\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:53:52 (running for 00:08:27.23)<br>Memory usage on this node: 14.2/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    49</td><td style=\"text-align: right;\">         483.434</td><td style=\"text-align: right;\">3135216</td><td style=\"text-align: right;\"> -213928</td><td style=\"text-align: right;\">             -205927</td><td style=\"text-align: right;\">             -252777</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 3199200\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 3199200\n",
      "    num_agent_steps_trained: 3199200\n",
      "    num_env_steps_sampled: 3199200\n",
      "    num_env_steps_trained: 3199200\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-53-57\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -205926.5302903076\n",
      "  episode_reward_mean: -213490.41672878337\n",
      "  episode_reward_min: -250341.75220083626\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 3192\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.2071053981781006\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00043454914703033864\n",
      "          model: {}\n",
      "          policy_loss: 0.0060109589248895645\n",
      "          total_loss: 10.005776405334473\n",
      "          vf_explained_var: -3.973643103449831e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 3199200\n",
      "    num_agent_steps_trained: 3199200\n",
      "    num_env_steps_sampled: 3199200\n",
      "    num_env_steps_trained: 3199200\n",
      "  iterations_since_restore: 50\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 3199200\n",
      "  num_agent_steps_trained: 3199200\n",
      "  num_env_steps_sampled: 3199200\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 3199200\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.85\n",
      "    ram_util_percent: 91.90714285714286\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09810748498304242\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.47907934609306013\n",
      "    mean_inference_ms: 0.9998424063649071\n",
      "    mean_raw_obs_processing_ms: 0.13841435399279367\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -205926.5302903076\n",
      "    episode_reward_mean: -213490.41672878337\n",
      "    episode_reward_min: -250341.75220083626\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -213340.9559571802\n",
      "      - -217451.59841417926\n",
      "      - -206729.68074641892\n",
      "      - -217987.07434519255\n",
      "      - -210440.24905107656\n",
      "      - -210595.34581289758\n",
      "      - -216249.28092385188\n",
      "      - -210654.75008070568\n",
      "      - -211703.6723826255\n",
      "      - -213469.08783534548\n",
      "      - -218220.99449203172\n",
      "      - -219836.17439932137\n",
      "      - -212992.04489954503\n",
      "      - -206724.21350705076\n",
      "      - -245269.47714087265\n",
      "      - -210927.68366282614\n",
      "      - -213347.1251303232\n",
      "      - -216206.20655625602\n",
      "      - -214313.81989262172\n",
      "      - -211225.49021095253\n",
      "      - -207031.61004370844\n",
      "      - -250341.75220083626\n",
      "      - -209043.28436952434\n",
      "      - -210873.550431042\n",
      "      - -215304.2055933312\n",
      "      - -215968.21677313244\n",
      "      - -209144.9613082205\n",
      "      - -214065.93765819952\n",
      "      - -212259.27621730173\n",
      "      - -209014.73455319268\n",
      "      - -206369.45040315986\n",
      "      - -208105.97603882416\n",
      "      - -209319.5192788586\n",
      "      - -216835.29458296733\n",
      "      - -205926.5302903076\n",
      "      - -216548.1594259486\n",
      "      - -213703.4973713935\n",
      "      - -219861.9170110201\n",
      "      - -220357.85878493678\n",
      "      - -222228.40929642707\n",
      "      - -210255.27344895105\n",
      "      - -215913.0539488056\n",
      "      - -210418.09237377922\n",
      "      - -210825.87222250202\n",
      "      - -212728.4824872707\n",
      "      - -208265.27319601458\n",
      "      - -209717.7074293226\n",
      "      - -212818.5258028611\n",
      "      - -211934.77190955108\n",
      "      - -212357.369859386\n",
      "      - -220291.73015440468\n",
      "      - -218644.70006697642\n",
      "      - -207579.71203220426\n",
      "      - -215974.87547295346\n",
      "      - -216679.70733218442\n",
      "      - -208780.09952407438\n",
      "      - -214735.63186415023\n",
      "      - -213451.53273829003\n",
      "      - -214981.7890447408\n",
      "      - -208738.16798613517\n",
      "      - -214067.5073146114\n",
      "      - -211060.39401962465\n",
      "      - -211595.05543528908\n",
      "      - -210538.932962077\n",
      "      - -216256.16928831217\n",
      "      - -214864.35300033743\n",
      "      - -215126.6271422229\n",
      "      - -210274.91279875915\n",
      "      - -209506.17703814685\n",
      "      - -209777.92540730236\n",
      "      - -218107.8342650007\n",
      "      - -213344.20763130116\n",
      "      - -214491.76083719978\n",
      "      - -216105.18630903293\n",
      "      - -212753.44912991975\n",
      "      - -214955.68711354057\n",
      "      - -212957.35558663154\n",
      "      - -212875.1805508388\n",
      "      - -207778.13256266856\n",
      "      - -214566.21107810325\n",
      "      - -209182.06481232622\n",
      "      - -211444.37477478207\n",
      "      - -214133.14841586413\n",
      "      - -206518.48493808805\n",
      "      - -211840.01969877756\n",
      "      - -213207.32362026715\n",
      "      - -214291.83897438733\n",
      "      - -211990.6831526129\n",
      "      - -211390.6548265117\n",
      "      - -212056.9068440539\n",
      "      - -213068.82714444687\n",
      "      - -215921.94646689107\n",
      "      - -210112.11400160583\n",
      "      - -209643.8858817256\n",
      "      - -212682.19294876733\n",
      "      - -214258.04450201767\n",
      "      - -214575.25578947528\n",
      "      - -210671.83273556572\n",
      "      - -212313.8818102572\n",
      "      - -213653.69610082862\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09810748498304242\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.47907934609306013\n",
      "      mean_inference_ms: 0.9998424063649071\n",
      "      mean_raw_obs_processing_ms: 0.13841435399279367\n",
      "  time_since_restore: 493.11612939834595\n",
      "  time_this_iter_s: 9.682337522506714\n",
      "  time_total_s: 493.11612939834595\n",
      "  timers:\n",
      "    learn_throughput: 111952.407\n",
      "    learn_time_ms: 571.529\n",
      "    load_throughput: 21377629.475\n",
      "    load_time_ms: 2.993\n",
      "    training_iteration_time_ms: 9267.563\n",
      "    update_time_ms: 3.874\n",
      "  timestamp: 1665849237\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3199200\n",
      "  training_iteration: 50\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:54:02 (running for 00:08:36.47)<br>Memory usage on this node: 14.3/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         493.116</td><td style=\"text-align: right;\">3199200</td><td style=\"text-align: right;\"> -213490</td><td style=\"text-align: right;\">             -205927</td><td style=\"text-align: right;\">             -250342</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 3263184\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 3263184\n",
      "    num_agent_steps_trained: 3263184\n",
      "    num_env_steps_sampled: 3263184\n",
      "    num_env_steps_trained: 3263184\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-54-06\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -205485.70416347383\n",
      "  episode_reward_mean: -212157.60214277293\n",
      "  episode_reward_min: -222489.82992808786\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 3252\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.206263780593872\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00044187912135384977\n",
      "          model: {}\n",
      "          policy_loss: 0.0001812956907087937\n",
      "          total_loss: 9.999948501586914\n",
      "          vf_explained_var: -3.500590395333347e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 3263184\n",
      "    num_agent_steps_trained: 3263184\n",
      "    num_env_steps_sampled: 3263184\n",
      "    num_env_steps_trained: 3263184\n",
      "  iterations_since_restore: 51\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 3263184\n",
      "  num_agent_steps_trained: 3263184\n",
      "  num_env_steps_sampled: 3263184\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 3263184\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.35384615384615\n",
      "    ram_util_percent: 92.15384615384616\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0979617315083582\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4793465697811559\n",
      "    mean_inference_ms: 0.9986707664736221\n",
      "    mean_raw_obs_processing_ms: 0.13820059857068284\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -205485.70416347383\n",
      "    episode_reward_mean: -212157.60214277293\n",
      "    episode_reward_min: -222489.82992808786\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -214067.5073146114\n",
      "      - -211060.39401962465\n",
      "      - -211595.05543528908\n",
      "      - -210538.932962077\n",
      "      - -216256.16928831217\n",
      "      - -214864.35300033743\n",
      "      - -215126.6271422229\n",
      "      - -210274.91279875915\n",
      "      - -209506.17703814685\n",
      "      - -209777.92540730236\n",
      "      - -218107.8342650007\n",
      "      - -213344.20763130116\n",
      "      - -214491.76083719978\n",
      "      - -216105.18630903293\n",
      "      - -212753.44912991975\n",
      "      - -214955.68711354057\n",
      "      - -212957.35558663154\n",
      "      - -212875.1805508388\n",
      "      - -207778.13256266856\n",
      "      - -214566.21107810325\n",
      "      - -209182.06481232622\n",
      "      - -211444.37477478207\n",
      "      - -214133.14841586413\n",
      "      - -206518.48493808805\n",
      "      - -211840.01969877756\n",
      "      - -213207.32362026715\n",
      "      - -214291.83897438733\n",
      "      - -211990.6831526129\n",
      "      - -211390.6548265117\n",
      "      - -212056.9068440539\n",
      "      - -213068.82714444687\n",
      "      - -215921.94646689107\n",
      "      - -210112.11400160583\n",
      "      - -209643.8858817256\n",
      "      - -212682.19294876733\n",
      "      - -214258.04450201767\n",
      "      - -214575.25578947528\n",
      "      - -210671.83273556572\n",
      "      - -212313.8818102572\n",
      "      - -213653.69610082862\n",
      "      - -216166.59581177446\n",
      "      - -213854.62420948877\n",
      "      - -211475.09279439613\n",
      "      - -208538.63529951667\n",
      "      - -214641.30306162225\n",
      "      - -216394.1312628057\n",
      "      - -205485.70416347383\n",
      "      - -208950.18719920501\n",
      "      - -210399.99590966656\n",
      "      - -222489.82992808786\n",
      "      - -207540.13125218937\n",
      "      - -210196.27069649278\n",
      "      - -210492.22895311934\n",
      "      - -214075.9783051553\n",
      "      - -216255.18252708003\n",
      "      - -213845.26745169086\n",
      "      - -218491.38850903444\n",
      "      - -206768.1957308852\n",
      "      - -208191.6172289983\n",
      "      - -214001.24244364243\n",
      "      - -214307.3494142594\n",
      "      - -208064.7759954508\n",
      "      - -211805.2150638563\n",
      "      - -215179.26216953914\n",
      "      - -215867.18524394376\n",
      "      - -208906.9084094271\n",
      "      - -206201.40400532217\n",
      "      - -210702.0952639403\n",
      "      - -212109.60743411022\n",
      "      - -212820.42621726656\n",
      "      - -211318.70987663354\n",
      "      - -207398.51724322225\n",
      "      - -208128.4068149229\n",
      "      - -214004.85045627702\n",
      "      - -213734.17920930014\n",
      "      - -218972.04932297103\n",
      "      - -210914.05821817898\n",
      "      - -215227.86159943335\n",
      "      - -210753.2694944553\n",
      "      - -215266.6594466058\n",
      "      - -207339.78176623862\n",
      "      - -209282.05662841615\n",
      "      - -211895.9306876049\n",
      "      - -210616.91751928872\n",
      "      - -210296.68923661357\n",
      "      - -216076.1988595996\n",
      "      - -207079.45961870745\n",
      "      - -212308.51721587888\n",
      "      - -211973.911037358\n",
      "      - -215774.98255787857\n",
      "      - -209274.11391302152\n",
      "      - -208644.67223750296\n",
      "      - -210696.8686572228\n",
      "      - -207048.69552125185\n",
      "      - -210997.77044050454\n",
      "      - -215391.3290943691\n",
      "      - -211043.78779262883\n",
      "      - -213985.064165433\n",
      "      - -208720.89054795148\n",
      "      - -213415.94623221183\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.0979617315083582\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4793465697811559\n",
      "      mean_inference_ms: 0.9986707664736221\n",
      "      mean_raw_obs_processing_ms: 0.13820059857068284\n",
      "  time_since_restore: 502.3575403690338\n",
      "  time_this_iter_s: 9.241410970687866\n",
      "  time_total_s: 502.3575403690338\n",
      "  timers:\n",
      "    learn_throughput: 111516.318\n",
      "    learn_time_ms: 573.764\n",
      "    load_throughput: 21313114.761\n",
      "    load_time_ms: 3.002\n",
      "    training_iteration_time_ms: 9293.716\n",
      "    update_time_ms: 3.945\n",
      "  timestamp: 1665849246\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3263184\n",
      "  training_iteration: 51\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:54:11 (running for 00:08:45.82)<br>Memory usage on this node: 14.2/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    51</td><td style=\"text-align: right;\">         502.358</td><td style=\"text-align: right;\">3263184</td><td style=\"text-align: right;\"> -212158</td><td style=\"text-align: right;\">             -205486</td><td style=\"text-align: right;\">             -222490</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 3327168\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 3327168\n",
      "    num_agent_steps_trained: 3327168\n",
      "    num_env_steps_sampled: 3327168\n",
      "    num_env_steps_trained: 3327168\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-54-15\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -205785.2117677363\n",
      "  episode_reward_mean: -213035.37449688095\n",
      "  episode_reward_min: -254063.20921247025\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 3324\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.214769124984741\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0006139932083897293\n",
      "          model: {}\n",
      "          policy_loss: 0.0050265793688595295\n",
      "          total_loss: 10.004828453063965\n",
      "          vf_explained_var: -5.298190686175985e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 3327168\n",
      "    num_agent_steps_trained: 3327168\n",
      "    num_env_steps_sampled: 3327168\n",
      "    num_env_steps_trained: 3327168\n",
      "  iterations_since_restore: 52\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 3327168\n",
      "  num_agent_steps_trained: 3327168\n",
      "  num_env_steps_sampled: 3327168\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 3327168\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.26153846153846\n",
      "    ram_util_percent: 92.0\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09761190832236266\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.47873442157040386\n",
      "    mean_inference_ms: 0.9963485336567957\n",
      "    mean_raw_obs_processing_ms: 0.13784408969443437\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -205785.2117677363\n",
      "    episode_reward_mean: -213035.37449688095\n",
      "    episode_reward_min: -254063.20921247025\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -208128.4068149229\n",
      "      - -214004.85045627702\n",
      "      - -213734.17920930014\n",
      "      - -218972.04932297103\n",
      "      - -210914.05821817898\n",
      "      - -215227.86159943335\n",
      "      - -210753.2694944553\n",
      "      - -215266.6594466058\n",
      "      - -207339.78176623862\n",
      "      - -209282.05662841615\n",
      "      - -211895.9306876049\n",
      "      - -210616.91751928872\n",
      "      - -210296.68923661357\n",
      "      - -216076.1988595996\n",
      "      - -207079.45961870745\n",
      "      - -212308.51721587888\n",
      "      - -211973.911037358\n",
      "      - -215774.98255787857\n",
      "      - -209274.11391302152\n",
      "      - -208644.67223750296\n",
      "      - -210696.8686572228\n",
      "      - -207048.69552125185\n",
      "      - -210997.77044050454\n",
      "      - -215391.3290943691\n",
      "      - -211043.78779262883\n",
      "      - -213985.064165433\n",
      "      - -208720.89054795148\n",
      "      - -213415.94623221183\n",
      "      - -252213.87299011965\n",
      "      - -216104.54293458042\n",
      "      - -208459.61130749484\n",
      "      - -211005.13500220567\n",
      "      - -214561.26652875112\n",
      "      - -214185.04832946905\n",
      "      - -208928.7925464355\n",
      "      - -217172.7718723743\n",
      "      - -214128.89193490703\n",
      "      - -212754.68349683803\n",
      "      - -205785.2117677363\n",
      "      - -213436.2804559152\n",
      "      - -206546.4587983033\n",
      "      - -212880.80349130405\n",
      "      - -212120.03481837054\n",
      "      - -216480.17276811672\n",
      "      - -213147.3251186855\n",
      "      - -208707.02872911707\n",
      "      - -211015.25878341193\n",
      "      - -223104.67965359587\n",
      "      - -212203.29364240397\n",
      "      - -209153.57252268895\n",
      "      - -220584.19719632363\n",
      "      - -210653.28070503642\n",
      "      - -214059.00375619132\n",
      "      - -210554.47227084963\n",
      "      - -215393.3141214504\n",
      "      - -212490.32895660782\n",
      "      - -210483.91429578277\n",
      "      - -213597.65668472525\n",
      "      - -254063.20921247025\n",
      "      - -206944.42958850943\n",
      "      - -214101.8630176176\n",
      "      - -212479.33864087996\n",
      "      - -210527.1591427979\n",
      "      - -210467.7705819821\n",
      "      - -210029.46439497758\n",
      "      - -217803.51790510333\n",
      "      - -213866.4128501337\n",
      "      - -215742.2095078166\n",
      "      - -209835.52371120753\n",
      "      - -212435.75846933838\n",
      "      - -211740.3685387763\n",
      "      - -210387.1718983979\n",
      "      - -213029.20970807312\n",
      "      - -214572.5999583555\n",
      "      - -211715.21749234854\n",
      "      - -214639.78862984126\n",
      "      - -208604.55069916448\n",
      "      - -213665.8479898747\n",
      "      - -213425.77703879977\n",
      "      - -210651.8552871465\n",
      "      - -211815.19091089338\n",
      "      - -209856.47791827223\n",
      "      - -209489.25876145056\n",
      "      - -211815.67552073236\n",
      "      - -212347.64053412553\n",
      "      - -212112.86382522166\n",
      "      - -209191.07741289545\n",
      "      - -214069.42786900766\n",
      "      - -212744.40017364346\n",
      "      - -220739.63583597686\n",
      "      - -211505.34954018076\n",
      "      - -212018.27262267054\n",
      "      - -212793.43648120025\n",
      "      - -208367.44504168938\n",
      "      - -208675.36315029158\n",
      "      - -215264.27179564815\n",
      "      - -214239.31707390014\n",
      "      - -212732.97121087927\n",
      "      - -212878.55073429097\n",
      "      - -209375.95523989716\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09761190832236266\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.47873442157040386\n",
      "      mean_inference_ms: 0.9963485336567957\n",
      "      mean_raw_obs_processing_ms: 0.13784408969443437\n",
      "  time_since_restore: 511.22775888442993\n",
      "  time_this_iter_s: 8.870218515396118\n",
      "  time_total_s: 511.22775888442993\n",
      "  timers:\n",
      "    learn_throughput: 110665.137\n",
      "    learn_time_ms: 578.177\n",
      "    load_throughput: 20946803.139\n",
      "    load_time_ms: 3.055\n",
      "    training_iteration_time_ms: 9339.254\n",
      "    update_time_ms: 3.873\n",
      "  timestamp: 1665849255\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3327168\n",
      "  training_iteration: 52\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:54:20 (running for 00:08:54.71)<br>Memory usage on this node: 14.2/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    52</td><td style=\"text-align: right;\">         511.228</td><td style=\"text-align: right;\">3327168</td><td style=\"text-align: right;\"> -213035</td><td style=\"text-align: right;\">             -205785</td><td style=\"text-align: right;\">             -254063</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 3391152\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 3391152\n",
      "    num_agent_steps_trained: 3391152\n",
      "    num_env_steps_sampled: 3391152\n",
      "    num_env_steps_trained: 3391152\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-54-23\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -205015.58719139427\n",
      "  episode_reward_mean: -211825.408540887\n",
      "  episode_reward_min: -220739.63583597686\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 3384\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.214702844619751\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.000260598782915622\n",
      "          model: {}\n",
      "          policy_loss: 0.007322394754737616\n",
      "          total_loss: 10.007054328918457\n",
      "          vf_explained_var: -2.7437058847112894e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 3391152\n",
      "    num_agent_steps_trained: 3391152\n",
      "    num_env_steps_sampled: 3391152\n",
      "    num_env_steps_trained: 3391152\n",
      "  iterations_since_restore: 53\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 3391152\n",
      "  num_agent_steps_trained: 3391152\n",
      "  num_env_steps_sampled: 3391152\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 3391152\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 80.23333333333335\n",
      "    ram_util_percent: 91.86666666666667\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0975452061538957\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4780962755324038\n",
      "    mean_inference_ms: 0.9938039315423163\n",
      "    mean_raw_obs_processing_ms: 0.13780266819272363\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -205015.58719139427\n",
      "    episode_reward_mean: -211825.408540887\n",
      "    episode_reward_min: -220739.63583597686\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -214101.8630176176\n",
      "      - -212479.33864087996\n",
      "      - -210527.1591427979\n",
      "      - -210467.7705819821\n",
      "      - -210029.46439497758\n",
      "      - -217803.51790510333\n",
      "      - -213866.4128501337\n",
      "      - -215742.2095078166\n",
      "      - -209835.52371120753\n",
      "      - -212435.75846933838\n",
      "      - -211740.3685387763\n",
      "      - -210387.1718983979\n",
      "      - -213029.20970807312\n",
      "      - -214572.5999583555\n",
      "      - -211715.21749234854\n",
      "      - -214639.78862984126\n",
      "      - -208604.55069916448\n",
      "      - -213665.8479898747\n",
      "      - -213425.77703879977\n",
      "      - -210651.8552871465\n",
      "      - -211815.19091089338\n",
      "      - -209856.47791827223\n",
      "      - -209489.25876145056\n",
      "      - -211815.67552073236\n",
      "      - -212347.64053412553\n",
      "      - -212112.86382522166\n",
      "      - -209191.07741289545\n",
      "      - -214069.42786900766\n",
      "      - -212744.40017364346\n",
      "      - -220739.63583597686\n",
      "      - -211505.34954018076\n",
      "      - -212018.27262267054\n",
      "      - -212793.43648120025\n",
      "      - -208367.44504168938\n",
      "      - -208675.36315029158\n",
      "      - -215264.27179564815\n",
      "      - -214239.31707390014\n",
      "      - -212732.97121087927\n",
      "      - -212878.55073429097\n",
      "      - -209375.95523989716\n",
      "      - -208508.9950233974\n",
      "      - -207245.90134801308\n",
      "      - -217248.91085823879\n",
      "      - -213502.6964337982\n",
      "      - -208946.86613336173\n",
      "      - -212270.5902921975\n",
      "      - -213172.73546971928\n",
      "      - -207312.10939968895\n",
      "      - -211694.54089635317\n",
      "      - -211241.2357894867\n",
      "      - -210625.84215504763\n",
      "      - -216561.0853762405\n",
      "      - -207320.80946431047\n",
      "      - -214106.69349974024\n",
      "      - -207994.59150160063\n",
      "      - -210219.22387987666\n",
      "      - -216790.85143186394\n",
      "      - -211783.4495579474\n",
      "      - -211194.33733172744\n",
      "      - -207120.292637064\n",
      "      - -210659.50166452728\n",
      "      - -213274.68338401386\n",
      "      - -214707.3537466473\n",
      "      - -213532.76815048954\n",
      "      - -210875.59718798994\n",
      "      - -210121.72898125346\n",
      "      - -212596.4358014707\n",
      "      - -209070.71797510286\n",
      "      - -205015.58719139427\n",
      "      - -212877.7273650523\n",
      "      - -214213.7621610035\n",
      "      - -207490.78988534675\n",
      "      - -207724.41264311134\n",
      "      - -210002.53406322157\n",
      "      - -214617.04105153566\n",
      "      - -211220.1908650888\n",
      "      - -208188.42128670277\n",
      "      - -211881.86623559045\n",
      "      - -209757.89260244544\n",
      "      - -209407.6404392611\n",
      "      - -207915.79580792095\n",
      "      - -209390.41238147448\n",
      "      - -212289.98601394752\n",
      "      - -213921.07358300293\n",
      "      - -211040.10323900185\n",
      "      - -215284.64796958535\n",
      "      - -210571.0813646596\n",
      "      - -216155.3429855264\n",
      "      - -218231.95551915755\n",
      "      - -212710.70737255976\n",
      "      - -215040.382674682\n",
      "      - -213724.61916485257\n",
      "      - -209218.22216771997\n",
      "      - -209379.829645641\n",
      "      - -211676.1677958957\n",
      "      - -209875.3123530287\n",
      "      - -216848.7672062555\n",
      "      - -209527.092503401\n",
      "      - -214467.30498327664\n",
      "      - -211419.65108068637\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.0975452061538957\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4780962755324038\n",
      "      mean_inference_ms: 0.9938039315423163\n",
      "      mean_raw_obs_processing_ms: 0.13780266819272363\n",
      "  time_since_restore: 519.7574017047882\n",
      "  time_this_iter_s: 8.529642820358276\n",
      "  time_total_s: 519.7574017047882\n",
      "  timers:\n",
      "    learn_throughput: 129764.135\n",
      "    learn_time_ms: 493.079\n",
      "    load_throughput: 21235369.062\n",
      "    load_time_ms: 3.013\n",
      "    training_iteration_time_ms: 9143.02\n",
      "    update_time_ms: 3.933\n",
      "  timestamp: 1665849263\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3391152\n",
      "  training_iteration: 53\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:54:28 (running for 00:09:03.20)<br>Memory usage on this node: 14.2/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    53</td><td style=\"text-align: right;\">         519.757</td><td style=\"text-align: right;\">3391152</td><td style=\"text-align: right;\"> -211825</td><td style=\"text-align: right;\">             -205016</td><td style=\"text-align: right;\">             -220740</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 3455136\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 3455136\n",
      "    num_agent_steps_trained: 3455136\n",
      "    num_env_steps_sampled: 3455136\n",
      "    num_env_steps_trained: 3455136\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-54-32\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -205015.58719139427\n",
      "  episode_reward_mean: -210983.42617350107\n",
      "  episode_reward_min: -218231.95551915755\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 3444\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.207289218902588\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0004114539478905499\n",
      "          model: {}\n",
      "          policy_loss: -0.00039842535625211895\n",
      "          total_loss: 9.999364852905273\n",
      "          vf_explained_var: 1.8922110545105397e-09\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 3455136\n",
      "    num_agent_steps_trained: 3455136\n",
      "    num_env_steps_sampled: 3455136\n",
      "    num_env_steps_trained: 3455136\n",
      "  iterations_since_restore: 54\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 3455136\n",
      "  num_agent_steps_trained: 3455136\n",
      "  num_env_steps_sampled: 3455136\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 3455136\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.9\n",
      "    ram_util_percent: 91.84166666666668\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0973153697373676\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.47775668451007275\n",
      "    mean_inference_ms: 0.9916015970821249\n",
      "    mean_raw_obs_processing_ms: 0.13746917674905357\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -205015.58719139427\n",
      "    episode_reward_mean: -210983.42617350107\n",
      "    episode_reward_min: -218231.95551915755\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -210659.50166452728\n",
      "      - -213274.68338401386\n",
      "      - -214707.3537466473\n",
      "      - -213532.76815048954\n",
      "      - -210875.59718798994\n",
      "      - -210121.72898125346\n",
      "      - -212596.4358014707\n",
      "      - -209070.71797510286\n",
      "      - -205015.58719139427\n",
      "      - -212877.7273650523\n",
      "      - -214213.7621610035\n",
      "      - -207490.78988534675\n",
      "      - -207724.41264311134\n",
      "      - -210002.53406322157\n",
      "      - -214617.04105153566\n",
      "      - -211220.1908650888\n",
      "      - -208188.42128670277\n",
      "      - -211881.86623559045\n",
      "      - -209757.89260244544\n",
      "      - -209407.6404392611\n",
      "      - -207915.79580792095\n",
      "      - -209390.41238147448\n",
      "      - -212289.98601394752\n",
      "      - -213921.07358300293\n",
      "      - -211040.10323900185\n",
      "      - -215284.64796958535\n",
      "      - -210571.0813646596\n",
      "      - -216155.3429855264\n",
      "      - -218231.95551915755\n",
      "      - -212710.70737255976\n",
      "      - -215040.382674682\n",
      "      - -213724.61916485257\n",
      "      - -209218.22216771997\n",
      "      - -209379.829645641\n",
      "      - -211676.1677958957\n",
      "      - -209875.3123530287\n",
      "      - -216848.7672062555\n",
      "      - -209527.092503401\n",
      "      - -214467.30498327664\n",
      "      - -211419.65108068637\n",
      "      - -210062.6776785599\n",
      "      - -211075.80314717922\n",
      "      - -212819.1827867353\n",
      "      - -208387.9771837607\n",
      "      - -209460.75435299648\n",
      "      - -210106.3040968467\n",
      "      - -208475.17868597794\n",
      "      - -215401.97710855238\n",
      "      - -211464.3396442735\n",
      "      - -209713.2473925397\n",
      "      - -210988.1173736313\n",
      "      - -213477.8261800458\n",
      "      - -207670.3383078726\n",
      "      - -211471.67898163947\n",
      "      - -208891.4263176594\n",
      "      - -210870.28771466017\n",
      "      - -212182.55006590107\n",
      "      - -205615.6882371431\n",
      "      - -208909.80658694557\n",
      "      - -207430.0082687428\n",
      "      - -212517.52705458298\n",
      "      - -217254.5702515849\n",
      "      - -212820.51226104016\n",
      "      - -209381.25388666845\n",
      "      - -210081.16711021785\n",
      "      - -212132.1778699424\n",
      "      - -209760.543827802\n",
      "      - -209506.6216069899\n",
      "      - -212743.89762796502\n",
      "      - -211342.74897502476\n",
      "      - -209560.8614523895\n",
      "      - -209444.06375945848\n",
      "      - -213906.58412904543\n",
      "      - -210649.32705744717\n",
      "      - -212689.50160842703\n",
      "      - -217018.70044257824\n",
      "      - -212185.8611407784\n",
      "      - -210996.84736895104\n",
      "      - -208587.49377669784\n",
      "      - -209323.85284889265\n",
      "      - -212102.23173776892\n",
      "      - -211839.58962099242\n",
      "      - -206756.53862577202\n",
      "      - -210300.9160994507\n",
      "      - -212704.09670762267\n",
      "      - -205544.08216014694\n",
      "      - -208796.31264341238\n",
      "      - -211102.1927784967\n",
      "      - -211481.6466483093\n",
      "      - -214125.70287868442\n",
      "      - -210908.70487560003\n",
      "      - -211276.3604991283\n",
      "      - -210494.42693363686\n",
      "      - -206106.9161634201\n",
      "      - -213111.14549462145\n",
      "      - -209049.66150259282\n",
      "      - -207006.98769093744\n",
      "      - -206404.8579066152\n",
      "      - -210084.96509537022\n",
      "      - -206840.88862585643\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.0973153697373676\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.47775668451007275\n",
      "      mean_inference_ms: 0.9916015970821249\n",
      "      mean_raw_obs_processing_ms: 0.13746917674905357\n",
      "  time_since_restore: 528.720306634903\n",
      "  time_this_iter_s: 8.962904930114746\n",
      "  time_total_s: 528.720306634903\n",
      "  timers:\n",
      "    learn_throughput: 130957.55\n",
      "    learn_time_ms: 488.586\n",
      "    load_throughput: 21253195.256\n",
      "    load_time_ms: 3.011\n",
      "    training_iteration_time_ms: 9111.244\n",
      "    update_time_ms: 4.048\n",
      "  timestamp: 1665849272\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3455136\n",
      "  training_iteration: 54\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:54:37 (running for 00:09:12.26)<br>Memory usage on this node: 14.2/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    54</td><td style=\"text-align: right;\">          528.72</td><td style=\"text-align: right;\">3455136</td><td style=\"text-align: right;\"> -210983</td><td style=\"text-align: right;\">             -205016</td><td style=\"text-align: right;\">             -218232</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 3519120\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 3519120\n",
      "    num_agent_steps_trained: 3519120\n",
      "    num_env_steps_sampled: 3519120\n",
      "    num_env_steps_trained: 3519120\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-54-41\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -203118.68321805607\n",
      "  episode_reward_mean: -211019.47068532533\n",
      "  episode_reward_min: -222935.03357007974\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 3516\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1982550621032715\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00041645433520898223\n",
      "          model: {}\n",
      "          policy_loss: 0.004186750389635563\n",
      "          total_loss: 10.003950119018555\n",
      "          vf_explained_var: -2.176042634971509e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 3519120\n",
      "    num_agent_steps_trained: 3519120\n",
      "    num_env_steps_sampled: 3519120\n",
      "    num_env_steps_trained: 3519120\n",
      "  iterations_since_restore: 55\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 3519120\n",
      "  num_agent_steps_trained: 3519120\n",
      "  num_env_steps_sampled: 3519120\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 3519120\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.28461538461536\n",
      "    ram_util_percent: 91.84615384615384\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09701282810324308\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.476951072767208\n",
      "    mean_inference_ms: 0.9899861610704918\n",
      "    mean_raw_obs_processing_ms: 0.13716249973544198\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -203118.68321805607\n",
      "    episode_reward_mean: -211019.47068532533\n",
      "    episode_reward_min: -222935.03357007974\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -213906.58412904543\n",
      "      - -210649.32705744717\n",
      "      - -212689.50160842703\n",
      "      - -217018.70044257824\n",
      "      - -212185.8611407784\n",
      "      - -210996.84736895104\n",
      "      - -208587.49377669784\n",
      "      - -209323.85284889265\n",
      "      - -212102.23173776892\n",
      "      - -211839.58962099242\n",
      "      - -206756.53862577202\n",
      "      - -210300.9160994507\n",
      "      - -212704.09670762267\n",
      "      - -205544.08216014694\n",
      "      - -208796.31264341238\n",
      "      - -211102.1927784967\n",
      "      - -211481.6466483093\n",
      "      - -214125.70287868442\n",
      "      - -210908.70487560003\n",
      "      - -211276.3604991283\n",
      "      - -210494.42693363686\n",
      "      - -206106.9161634201\n",
      "      - -213111.14549462145\n",
      "      - -209049.66150259282\n",
      "      - -207006.98769093744\n",
      "      - -206404.8579066152\n",
      "      - -210084.96509537022\n",
      "      - -206840.88862585643\n",
      "      - -210391.891241351\n",
      "      - -212110.5959177922\n",
      "      - -213259.18962926575\n",
      "      - -213287.79115396354\n",
      "      - -211609.01136006363\n",
      "      - -211079.4258697327\n",
      "      - -208363.22800122935\n",
      "      - -215750.58484894852\n",
      "      - -212470.50213636758\n",
      "      - -220644.18013192146\n",
      "      - -222935.03357007974\n",
      "      - -210327.8880526199\n",
      "      - -209753.37434507985\n",
      "      - -206252.33147033927\n",
      "      - -212981.51487569723\n",
      "      - -213377.6321586182\n",
      "      - -216809.54242508957\n",
      "      - -213984.2761781251\n",
      "      - -211566.04905757096\n",
      "      - -209298.18495832983\n",
      "      - -209409.87951403536\n",
      "      - -211684.4659802897\n",
      "      - -213554.00770785913\n",
      "      - -216813.54579120298\n",
      "      - -209132.75010182313\n",
      "      - -209001.48612923795\n",
      "      - -211232.51135178603\n",
      "      - -210205.13389194\n",
      "      - -206148.3344183971\n",
      "      - -210000.78834284213\n",
      "      - -210466.92453573528\n",
      "      - -210575.55878566133\n",
      "      - -211374.334865092\n",
      "      - -206691.84428331832\n",
      "      - -203118.68321805607\n",
      "      - -212081.61370880538\n",
      "      - -210526.96991309596\n",
      "      - -209118.7208484412\n",
      "      - -213504.31530599284\n",
      "      - -212054.0816851767\n",
      "      - -215931.83068890506\n",
      "      - -209953.15856281645\n",
      "      - -215266.73468146255\n",
      "      - -208914.02243199697\n",
      "      - -209116.8695372074\n",
      "      - -208503.3508341941\n",
      "      - -215297.39455270467\n",
      "      - -212424.75370925068\n",
      "      - -213502.58836536683\n",
      "      - -211585.8209884705\n",
      "      - -208312.21201009068\n",
      "      - -210689.34071572422\n",
      "      - -213696.94610437658\n",
      "      - -208563.08803244037\n",
      "      - -208737.82552187244\n",
      "      - -209551.76867502744\n",
      "      - -212395.37167573217\n",
      "      - -211961.97202105913\n",
      "      - -213827.89559243983\n",
      "      - -211836.63796960103\n",
      "      - -208860.56934348273\n",
      "      - -209934.18996212236\n",
      "      - -207457.67249150778\n",
      "      - -208361.72617955928\n",
      "      - -206421.00380864553\n",
      "      - -210836.86264486125\n",
      "      - -212132.85797600108\n",
      "      - -213699.07215036478\n",
      "      - -209430.4115556198\n",
      "      - -211864.6069773301\n",
      "      - -208295.32214971\n",
      "      - -210238.61980036515\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09701282810324308\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.476951072767208\n",
      "      mean_inference_ms: 0.9899861610704918\n",
      "      mean_raw_obs_processing_ms: 0.13716249973544198\n",
      "  time_since_restore: 537.7727792263031\n",
      "  time_this_iter_s: 9.052472591400146\n",
      "  time_total_s: 537.7727792263031\n",
      "  timers:\n",
      "    learn_throughput: 131653.755\n",
      "    learn_time_ms: 486.002\n",
      "    load_throughput: 21319718.071\n",
      "    load_time_ms: 3.001\n",
      "    training_iteration_time_ms: 9062.397\n",
      "    update_time_ms: 4.06\n",
      "  timestamp: 1665849281\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3519120\n",
      "  training_iteration: 55\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:54:46 (running for 00:09:21.37)<br>Memory usage on this node: 14.2/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    55</td><td style=\"text-align: right;\">         537.773</td><td style=\"text-align: right;\">3519120</td><td style=\"text-align: right;\"> -211019</td><td style=\"text-align: right;\">             -203119</td><td style=\"text-align: right;\">             -222935</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 3583104\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 3583104\n",
      "    num_agent_steps_trained: 3583104\n",
      "    num_env_steps_sampled: 3583104\n",
      "    num_env_steps_trained: 3583104\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-54-50\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -201808.07272266195\n",
      "  episode_reward_mean: -210785.8362546799\n",
      "  episode_reward_min: -245124.63321021755\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 3576\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1948721408843994\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0004444870864972472\n",
      "          model: {}\n",
      "          policy_loss: 0.007085422985255718\n",
      "          total_loss: 10.006854057312012\n",
      "          vf_explained_var: -3.311369312086754e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 3583104\n",
      "    num_agent_steps_trained: 3583104\n",
      "    num_env_steps_sampled: 3583104\n",
      "    num_env_steps_trained: 3583104\n",
      "  iterations_since_restore: 56\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 3583104\n",
      "  num_agent_steps_trained: 3583104\n",
      "  num_env_steps_sampled: 3583104\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 3583104\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.95384615384616\n",
      "    ram_util_percent: 91.84615384615383\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09696548594040603\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4763151540277177\n",
      "    mean_inference_ms: 0.9885078893202537\n",
      "    mean_raw_obs_processing_ms: 0.13727990567024456\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -201808.07272266195\n",
      "    episode_reward_mean: -210785.8362546799\n",
      "    episode_reward_min: -245124.63321021755\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -211374.334865092\n",
      "      - -206691.84428331832\n",
      "      - -203118.68321805607\n",
      "      - -212081.61370880538\n",
      "      - -210526.96991309596\n",
      "      - -209118.7208484412\n",
      "      - -213504.31530599284\n",
      "      - -212054.0816851767\n",
      "      - -215931.83068890506\n",
      "      - -209953.15856281645\n",
      "      - -215266.73468146255\n",
      "      - -208914.02243199697\n",
      "      - -209116.8695372074\n",
      "      - -208503.3508341941\n",
      "      - -215297.39455270467\n",
      "      - -212424.75370925068\n",
      "      - -213502.58836536683\n",
      "      - -211585.8209884705\n",
      "      - -208312.21201009068\n",
      "      - -210689.34071572422\n",
      "      - -213696.94610437658\n",
      "      - -208563.08803244037\n",
      "      - -208737.82552187244\n",
      "      - -209551.76867502744\n",
      "      - -212395.37167573217\n",
      "      - -211961.97202105913\n",
      "      - -213827.89559243983\n",
      "      - -211836.63796960103\n",
      "      - -208860.56934348273\n",
      "      - -209934.18996212236\n",
      "      - -207457.67249150778\n",
      "      - -208361.72617955928\n",
      "      - -206421.00380864553\n",
      "      - -210836.86264486125\n",
      "      - -212132.85797600108\n",
      "      - -213699.07215036478\n",
      "      - -209430.4115556198\n",
      "      - -211864.6069773301\n",
      "      - -208295.32214971\n",
      "      - -210238.61980036515\n",
      "      - -207338.31140420132\n",
      "      - -206326.51441978253\n",
      "      - -208033.5548253872\n",
      "      - -212328.99938361032\n",
      "      - -212563.0722964421\n",
      "      - -207411.70372840035\n",
      "      - -211492.1453430359\n",
      "      - -210254.61201345734\n",
      "      - -207179.7600583468\n",
      "      - -208290.914006622\n",
      "      - -206980.40525558623\n",
      "      - -245124.63321021755\n",
      "      - -210715.59903708383\n",
      "      - -210769.8368923599\n",
      "      - -211670.19143710166\n",
      "      - -209189.1412531159\n",
      "      - -213923.2856873502\n",
      "      - -216201.5688714043\n",
      "      - -201808.07272266195\n",
      "      - -207456.83403639676\n",
      "      - -210283.9793258086\n",
      "      - -206391.56223875514\n",
      "      - -213180.77021031122\n",
      "      - -210411.98159932092\n",
      "      - -215079.99746563623\n",
      "      - -206991.4545399558\n",
      "      - -209247.5343909033\n",
      "      - -207071.06547497673\n",
      "      - -210399.4790778576\n",
      "      - -207585.3435915685\n",
      "      - -211787.43929007027\n",
      "      - -211222.21949070683\n",
      "      - -216801.6133006082\n",
      "      - -209506.8624571863\n",
      "      - -215398.50391919253\n",
      "      - -205682.18457767591\n",
      "      - -213979.14389137737\n",
      "      - -210215.08065466478\n",
      "      - -207334.22868626413\n",
      "      - -216741.30087413147\n",
      "      - -214996.61144249275\n",
      "      - -216554.70822793228\n",
      "      - -208774.38171209669\n",
      "      - -218336.240635892\n",
      "      - -209512.946814616\n",
      "      - -217194.20019062306\n",
      "      - -211220.7132687445\n",
      "      - -209314.8551791633\n",
      "      - -208879.16113170717\n",
      "      - -209529.4625667536\n",
      "      - -208108.6852278309\n",
      "      - -209367.40705151932\n",
      "      - -208190.8727294331\n",
      "      - -211736.25306065008\n",
      "      - -211704.60480006618\n",
      "      - -210033.22255930724\n",
      "      - -203958.02587622218\n",
      "      - -205655.19031687643\n",
      "      - -210112.78771212028\n",
      "      - -208959.33248612063\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09696548594040603\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4763151540277177\n",
      "      mean_inference_ms: 0.9885078893202537\n",
      "      mean_raw_obs_processing_ms: 0.13727990567024456\n",
      "  time_since_restore: 546.7024223804474\n",
      "  time_this_iter_s: 8.929643154144287\n",
      "  time_total_s: 546.7024223804474\n",
      "  timers:\n",
      "    learn_throughput: 131803.376\n",
      "    learn_time_ms: 485.45\n",
      "    load_throughput: 21428325.386\n",
      "    load_time_ms: 2.986\n",
      "    training_iteration_time_ms: 9056.692\n",
      "    update_time_ms: 4.093\n",
      "  timestamp: 1665849290\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3583104\n",
      "  training_iteration: 56\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:54:55 (running for 00:09:30.25)<br>Memory usage on this node: 14.2/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    56</td><td style=\"text-align: right;\">         546.702</td><td style=\"text-align: right;\">3583104</td><td style=\"text-align: right;\"> -210786</td><td style=\"text-align: right;\">             -201808</td><td style=\"text-align: right;\">             -245125</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 3647088\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 3647088\n",
      "    num_agent_steps_trained: 3647088\n",
      "    num_env_steps_sampled: 3647088\n",
      "    num_env_steps_trained: 3647088\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-55-00\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -203839.79857227998\n",
      "  episode_reward_mean: -210978.2659158189\n",
      "  episode_reward_min: -259902.21632882685\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 3636\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1866345405578613\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0003313217603135854\n",
      "          model: {}\n",
      "          policy_loss: 0.0006525729550048709\n",
      "          total_loss: 10.00040054321289\n",
      "          vf_explained_var: -1.6083793852317285e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 3647088\n",
      "    num_agent_steps_trained: 3647088\n",
      "    num_env_steps_sampled: 3647088\n",
      "    num_env_steps_trained: 3647088\n",
      "  iterations_since_restore: 57\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 3647088\n",
      "  num_agent_steps_trained: 3647088\n",
      "  num_env_steps_sampled: 3647088\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 3647088\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.0\n",
      "    ram_util_percent: 91.8076923076923\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09685707033117726\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.47618796545798375\n",
      "    mean_inference_ms: 0.9870547646744734\n",
      "    mean_raw_obs_processing_ms: 0.13713235919329286\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -203839.79857227998\n",
      "    episode_reward_mean: -210978.2659158189\n",
      "    episode_reward_min: -259902.21632882685\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -210283.9793258086\n",
      "      - -206391.56223875514\n",
      "      - -213180.77021031122\n",
      "      - -210411.98159932092\n",
      "      - -215079.99746563623\n",
      "      - -206991.4545399558\n",
      "      - -209247.5343909033\n",
      "      - -207071.06547497673\n",
      "      - -210399.4790778576\n",
      "      - -207585.3435915685\n",
      "      - -211787.43929007027\n",
      "      - -211222.21949070683\n",
      "      - -216801.6133006082\n",
      "      - -209506.8624571863\n",
      "      - -215398.50391919253\n",
      "      - -205682.18457767591\n",
      "      - -213979.14389137737\n",
      "      - -210215.08065466478\n",
      "      - -207334.22868626413\n",
      "      - -216741.30087413147\n",
      "      - -214996.61144249275\n",
      "      - -216554.70822793228\n",
      "      - -208774.38171209669\n",
      "      - -218336.240635892\n",
      "      - -209512.946814616\n",
      "      - -217194.20019062306\n",
      "      - -211220.7132687445\n",
      "      - -209314.8551791633\n",
      "      - -208879.16113170717\n",
      "      - -209529.4625667536\n",
      "      - -208108.6852278309\n",
      "      - -209367.40705151932\n",
      "      - -208190.8727294331\n",
      "      - -211736.25306065008\n",
      "      - -211704.60480006618\n",
      "      - -210033.22255930724\n",
      "      - -203958.02587622218\n",
      "      - -205655.19031687643\n",
      "      - -210112.78771212028\n",
      "      - -208959.33248612063\n",
      "      - -210265.44208102644\n",
      "      - -207673.38017438143\n",
      "      - -209663.91258709092\n",
      "      - -208359.5447217971\n",
      "      - -206264.85821905266\n",
      "      - -213614.89891766914\n",
      "      - -210356.1941540446\n",
      "      - -209766.418893212\n",
      "      - -209637.9654037485\n",
      "      - -206690.63584577144\n",
      "      - -205566.85990686686\n",
      "      - -213016.52057744778\n",
      "      - -208633.186883583\n",
      "      - -211035.49150173098\n",
      "      - -205441.9550549212\n",
      "      - -211011.2417971847\n",
      "      - -206363.12777308127\n",
      "      - -209591.20745984153\n",
      "      - -209801.45351530067\n",
      "      - -211233.21826897038\n",
      "      - -209202.41237196338\n",
      "      - -259902.21632882685\n",
      "      - -211742.62740684528\n",
      "      - -211977.25434934482\n",
      "      - -207558.7382348126\n",
      "      - -208597.72897866345\n",
      "      - -212080.41493395268\n",
      "      - -214116.29281515713\n",
      "      - -212124.90371172625\n",
      "      - -205516.92052645245\n",
      "      - -212055.50731871242\n",
      "      - -210401.9323946593\n",
      "      - -214040.68103370108\n",
      "      - -212972.68136576825\n",
      "      - -205046.18237176526\n",
      "      - -209967.45864327016\n",
      "      - -207984.07878092598\n",
      "      - -214119.97272274058\n",
      "      - -209044.0722019984\n",
      "      - -215739.4242161344\n",
      "      - -213555.51492642055\n",
      "      - -207447.13756371805\n",
      "      - -214146.26108152882\n",
      "      - -210559.50262144607\n",
      "      - -207947.47999660813\n",
      "      - -210399.2741318756\n",
      "      - -217063.56945627692\n",
      "      - -203839.79857227998\n",
      "      - -208364.9888365938\n",
      "      - -216155.01906584357\n",
      "      - -211372.98777140395\n",
      "      - -206945.39612386792\n",
      "      - -205433.74148471587\n",
      "      - -208449.74519094374\n",
      "      - -233506.8287634325\n",
      "      - -209606.60941582714\n",
      "      - -209420.4723092638\n",
      "      - -209779.56732214696\n",
      "      - -212427.60386360757\n",
      "      - -205774.67059280234\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09685707033117726\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.47618796545798375\n",
      "      mean_inference_ms: 0.9870547646744734\n",
      "      mean_raw_obs_processing_ms: 0.13713235919329286\n",
      "  time_since_restore: 555.9664852619171\n",
      "  time_this_iter_s: 9.264062881469727\n",
      "  time_total_s: 555.9664852619171\n",
      "  timers:\n",
      "    learn_throughput: 131625.654\n",
      "    learn_time_ms: 486.106\n",
      "    load_throughput: 21365035.477\n",
      "    load_time_ms: 2.995\n",
      "    training_iteration_time_ms: 9091.864\n",
      "    update_time_ms: 4.226\n",
      "  timestamp: 1665849300\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3647088\n",
      "  training_iteration: 57\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:55:05 (running for 00:09:39.63)<br>Memory usage on this node: 14.2/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    57</td><td style=\"text-align: right;\">         555.966</td><td style=\"text-align: right;\">3647088</td><td style=\"text-align: right;\"> -210978</td><td style=\"text-align: right;\">             -203840</td><td style=\"text-align: right;\">             -259902</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 3711072\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 3711072\n",
      "    num_agent_steps_trained: 3711072\n",
      "    num_env_steps_sampled: 3711072\n",
      "    num_env_steps_trained: 3711072\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-55-09\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -201461.50059973146\n",
      "  episode_reward_mean: -210180.51263287605\n",
      "  episode_reward_min: -233506.8287634325\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 3708\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.180028200149536\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0005239498568698764\n",
      "          model: {}\n",
      "          policy_loss: 0.004522498231381178\n",
      "          total_loss: 10.004308700561523\n",
      "          vf_explained_var: -3.500590395333347e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 3711072\n",
      "    num_agent_steps_trained: 3711072\n",
      "    num_env_steps_sampled: 3711072\n",
      "    num_env_steps_trained: 3711072\n",
      "  iterations_since_restore: 58\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 3711072\n",
      "  num_agent_steps_trained: 3711072\n",
      "  num_env_steps_sampled: 3711072\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 3711072\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.83076923076925\n",
      "    ram_util_percent: 91.88461538461537\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09666068129697158\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.47535526229548536\n",
      "    mean_inference_ms: 0.9856683221559084\n",
      "    mean_raw_obs_processing_ms: 0.13670223244278176\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -201461.50059973146\n",
      "    episode_reward_mean: -210180.51263287605\n",
      "    episode_reward_min: -233506.8287634325\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -214040.68103370108\n",
      "      - -212972.68136576825\n",
      "      - -205046.18237176526\n",
      "      - -209967.45864327016\n",
      "      - -207984.07878092598\n",
      "      - -214119.97272274058\n",
      "      - -209044.0722019984\n",
      "      - -215739.4242161344\n",
      "      - -213555.51492642055\n",
      "      - -207447.13756371805\n",
      "      - -214146.26108152882\n",
      "      - -210559.50262144607\n",
      "      - -207947.47999660813\n",
      "      - -210399.2741318756\n",
      "      - -217063.56945627692\n",
      "      - -203839.79857227998\n",
      "      - -208364.9888365938\n",
      "      - -216155.01906584357\n",
      "      - -211372.98777140395\n",
      "      - -206945.39612386792\n",
      "      - -205433.74148471587\n",
      "      - -208449.74519094374\n",
      "      - -233506.8287634325\n",
      "      - -209606.60941582714\n",
      "      - -209420.4723092638\n",
      "      - -209779.56732214696\n",
      "      - -212427.60386360757\n",
      "      - -205774.67059280234\n",
      "      - -214224.9242854197\n",
      "      - -210727.3053908672\n",
      "      - -213319.28746402755\n",
      "      - -204931.5726661441\n",
      "      - -208223.48393864\n",
      "      - -207521.7862768944\n",
      "      - -215568.07415777125\n",
      "      - -209279.658030094\n",
      "      - -207087.36093858004\n",
      "      - -213191.79138691118\n",
      "      - -213247.66663279248\n",
      "      - -212899.17547052083\n",
      "      - -207980.45940524535\n",
      "      - -214384.37180972844\n",
      "      - -211066.227339926\n",
      "      - -207238.08183510372\n",
      "      - -212978.20049976197\n",
      "      - -211102.85098963793\n",
      "      - -210191.66015978297\n",
      "      - -207100.533075617\n",
      "      - -208698.07731351873\n",
      "      - -209273.66107420105\n",
      "      - -209687.76538411772\n",
      "      - -210010.76910250972\n",
      "      - -210762.56515518462\n",
      "      - -219861.7254172579\n",
      "      - -209402.92191212653\n",
      "      - -211194.8143789855\n",
      "      - -231705.61406406356\n",
      "      - -209701.8791999734\n",
      "      - -201461.50059973146\n",
      "      - -213202.79568820563\n",
      "      - -203828.76169329876\n",
      "      - -207146.79565277038\n",
      "      - -206728.15629588696\n",
      "      - -209273.49458452186\n",
      "      - -203312.19797307035\n",
      "      - -214995.79274573407\n",
      "      - -206726.8065182492\n",
      "      - -206443.20530418702\n",
      "      - -209952.12860396545\n",
      "      - -206931.79739942777\n",
      "      - -205265.7710461763\n",
      "      - -210344.44542995165\n",
      "      - -207310.09932757722\n",
      "      - -209189.8230548308\n",
      "      - -214369.9906335174\n",
      "      - -209235.13995040103\n",
      "      - -208846.04543682572\n",
      "      - -212867.79797045633\n",
      "      - -207628.86068739797\n",
      "      - -209724.5759419537\n",
      "      - -208862.48560561455\n",
      "      - -211519.99474434834\n",
      "      - -207951.1809466489\n",
      "      - -206143.58215300468\n",
      "      - -212120.51460011193\n",
      "      - -207922.19575430773\n",
      "      - -206133.91672531984\n",
      "      - -211923.4354479843\n",
      "      - -206659.5777052576\n",
      "      - -208509.8697193272\n",
      "      - -207429.3745127538\n",
      "      - -207988.27808496545\n",
      "      - -213235.08663046017\n",
      "      - -210360.32471257195\n",
      "      - -210943.8532968366\n",
      "      - -205591.0841986998\n",
      "      - -213886.8064768173\n",
      "      - -208614.73187859126\n",
      "      - -206793.89904381995\n",
      "      - -207000.103329712\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09666068129697158\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.47535526229548536\n",
      "      mean_inference_ms: 0.9856683221559084\n",
      "      mean_raw_obs_processing_ms: 0.13670223244278176\n",
      "  time_since_restore: 564.8788597583771\n",
      "  time_this_iter_s: 8.912374496459961\n",
      "  time_total_s: 564.8788597583771\n",
      "  timers:\n",
      "    learn_throughput: 131398.724\n",
      "    learn_time_ms: 486.945\n",
      "    load_throughput: 21471700.828\n",
      "    load_time_ms: 2.98\n",
      "    training_iteration_time_ms: 9100.1\n",
      "    update_time_ms: 4.251\n",
      "  timestamp: 1665849309\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3711072\n",
      "  training_iteration: 58\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:55:14 (running for 00:09:48.57)<br>Memory usage on this node: 14.2/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    58</td><td style=\"text-align: right;\">         564.879</td><td style=\"text-align: right;\">3711072</td><td style=\"text-align: right;\"> -210181</td><td style=\"text-align: right;\">             -201462</td><td style=\"text-align: right;\">             -233507</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 3775056\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 3775056\n",
      "    num_agent_steps_trained: 3775056\n",
      "    num_env_steps_sampled: 3775056\n",
      "    num_env_steps_trained: 3775056\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-55-18\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -203312.19797307035\n",
      "  episode_reward_mean: -209374.6505903025\n",
      "  episode_reward_min: -215670.8942806155\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 3768\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1737704277038574\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0002744872763287276\n",
      "          model: {}\n",
      "          policy_loss: 0.00665265042334795\n",
      "          total_loss: 10.006390571594238\n",
      "          vf_explained_var: -3.7844220202032375e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 3775056\n",
      "    num_agent_steps_trained: 3775056\n",
      "    num_env_steps_sampled: 3775056\n",
      "    num_env_steps_trained: 3775056\n",
      "  iterations_since_restore: 59\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 3775056\n",
      "  num_agent_steps_trained: 3775056\n",
      "  num_env_steps_sampled: 3775056\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 3775056\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 78.73846153846154\n",
      "    ram_util_percent: 91.89230769230768\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09670051724766131\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4750026206832103\n",
      "    mean_inference_ms: 0.9843429763291829\n",
      "    mean_raw_obs_processing_ms: 0.13675138148484345\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -203312.19797307035\n",
      "    episode_reward_mean: -209374.6505903025\n",
      "    episode_reward_min: -215670.8942806155\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -203828.76169329876\n",
      "      - -207146.79565277038\n",
      "      - -206728.15629588696\n",
      "      - -209273.49458452186\n",
      "      - -203312.19797307035\n",
      "      - -214995.79274573407\n",
      "      - -206726.8065182492\n",
      "      - -206443.20530418702\n",
      "      - -209952.12860396545\n",
      "      - -206931.79739942777\n",
      "      - -205265.7710461763\n",
      "      - -210344.44542995165\n",
      "      - -207310.09932757722\n",
      "      - -209189.8230548308\n",
      "      - -214369.9906335174\n",
      "      - -209235.13995040103\n",
      "      - -208846.04543682572\n",
      "      - -212867.79797045633\n",
      "      - -207628.86068739797\n",
      "      - -209724.5759419537\n",
      "      - -208862.48560561455\n",
      "      - -211519.99474434834\n",
      "      - -207951.1809466489\n",
      "      - -206143.58215300468\n",
      "      - -212120.51460011193\n",
      "      - -207922.19575430773\n",
      "      - -206133.91672531984\n",
      "      - -211923.4354479843\n",
      "      - -206659.5777052576\n",
      "      - -208509.8697193272\n",
      "      - -207429.3745127538\n",
      "      - -207988.27808496545\n",
      "      - -213235.08663046017\n",
      "      - -210360.32471257195\n",
      "      - -210943.8532968366\n",
      "      - -205591.0841986998\n",
      "      - -213886.8064768173\n",
      "      - -208614.73187859126\n",
      "      - -206793.89904381995\n",
      "      - -207000.103329712\n",
      "      - -210970.98359943827\n",
      "      - -214177.35509617618\n",
      "      - -210693.142382062\n",
      "      - -206651.85984958836\n",
      "      - -212765.34606412056\n",
      "      - -206306.96166250316\n",
      "      - -206107.47183043664\n",
      "      - -206235.94351769943\n",
      "      - -210819.71738728828\n",
      "      - -215670.8942806155\n",
      "      - -207709.87758911512\n",
      "      - -211170.8017881385\n",
      "      - -204713.25308241096\n",
      "      - -213253.5168147773\n",
      "      - -212843.39226904846\n",
      "      - -209626.1710936573\n",
      "      - -211646.2847128376\n",
      "      - -206263.22297475758\n",
      "      - -213252.28069422027\n",
      "      - -208836.27403445897\n",
      "      - -210898.93037235143\n",
      "      - -213296.43387552074\n",
      "      - -205879.114095916\n",
      "      - -212134.21754186455\n",
      "      - -208130.41170765384\n",
      "      - -212117.0178292916\n",
      "      - -212887.2137343572\n",
      "      - -206705.8582907105\n",
      "      - -204405.81821514183\n",
      "      - -206538.20388308994\n",
      "      - -209859.3150621139\n",
      "      - -211430.24503932384\n",
      "      - -211310.76969828492\n",
      "      - -213399.00478112523\n",
      "      - -210149.0667055777\n",
      "      - -211308.4907135658\n",
      "      - -209569.24825240904\n",
      "      - -207035.1277012073\n",
      "      - -209289.8228463231\n",
      "      - -208205.12577325117\n",
      "      - -210892.19657761182\n",
      "      - -205611.0431909559\n",
      "      - -209431.48740442746\n",
      "      - -208753.33091264125\n",
      "      - -205832.4590903534\n",
      "      - -208756.2796853091\n",
      "      - -211744.28779670192\n",
      "      - -212321.71191340042\n",
      "      - -206568.82351210737\n",
      "      - -209618.32932645417\n",
      "      - -207703.0352655596\n",
      "      - -211497.79747343424\n",
      "      - -210086.38161152526\n",
      "      - -209134.36894179278\n",
      "      - -210046.55441885005\n",
      "      - -211620.74986013232\n",
      "      - -209057.7391807344\n",
      "      - -210343.94746517192\n",
      "      - -214952.22845823504\n",
      "      - -209516.13828507107\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09670051724766131\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4750026206832103\n",
      "      mean_inference_ms: 0.9843429763291829\n",
      "      mean_raw_obs_processing_ms: 0.13675138148484345\n",
      "  time_since_restore: 574.0474109649658\n",
      "  time_this_iter_s: 9.168551206588745\n",
      "  time_total_s: 574.0474109649658\n",
      "  timers:\n",
      "    learn_throughput: 130058.68\n",
      "    learn_time_ms: 491.963\n",
      "    load_throughput: 21446134.377\n",
      "    load_time_ms: 2.983\n",
      "    training_iteration_time_ms: 9054.635\n",
      "    update_time_ms: 4.431\n",
      "  timestamp: 1665849318\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3775056\n",
      "  training_iteration: 59\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:55:23 (running for 00:09:57.69)<br>Memory usage on this node: 14.2/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    59</td><td style=\"text-align: right;\">         574.047</td><td style=\"text-align: right;\">3775056</td><td style=\"text-align: right;\"> -209375</td><td style=\"text-align: right;\">             -203312</td><td style=\"text-align: right;\">             -215671</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 3839040\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 3839040\n",
      "    num_agent_steps_trained: 3839040\n",
      "    num_env_steps_sampled: 3839040\n",
      "    num_env_steps_trained: 3839040\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-55-27\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -201707.28689280717\n",
      "  episode_reward_mean: -210576.08077530647\n",
      "  episode_reward_min: -256120.8199570944\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 3828\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.174952507019043\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0004958385834470391\n",
      "          model: {}\n",
      "          policy_loss: 0.00013840523024555296\n",
      "          total_loss: 9.999919891357422\n",
      "          vf_explained_var: -2.7437058847112894e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 3839040\n",
      "    num_agent_steps_trained: 3839040\n",
      "    num_env_steps_sampled: 3839040\n",
      "    num_env_steps_trained: 3839040\n",
      "  iterations_since_restore: 60\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 3839040\n",
      "  num_agent_steps_trained: 3839040\n",
      "  num_env_steps_sampled: 3839040\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 3839040\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 78.72307692307692\n",
      "    ram_util_percent: 91.94615384615385\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09653005207186904\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4753723766783514\n",
      "    mean_inference_ms: 0.982786843458839\n",
      "    mean_raw_obs_processing_ms: 0.13658804697771543\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -201707.28689280717\n",
      "    episode_reward_mean: -210576.08077530647\n",
      "    episode_reward_min: -256120.8199570944\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -210898.93037235143\n",
      "      - -213296.43387552074\n",
      "      - -205879.114095916\n",
      "      - -212134.21754186455\n",
      "      - -208130.41170765384\n",
      "      - -212117.0178292916\n",
      "      - -212887.2137343572\n",
      "      - -206705.8582907105\n",
      "      - -204405.81821514183\n",
      "      - -206538.20388308994\n",
      "      - -209859.3150621139\n",
      "      - -211430.24503932384\n",
      "      - -211310.76969828492\n",
      "      - -213399.00478112523\n",
      "      - -210149.0667055777\n",
      "      - -211308.4907135658\n",
      "      - -209569.24825240904\n",
      "      - -207035.1277012073\n",
      "      - -209289.8228463231\n",
      "      - -208205.12577325117\n",
      "      - -210892.19657761182\n",
      "      - -205611.0431909559\n",
      "      - -209431.48740442746\n",
      "      - -208753.33091264125\n",
      "      - -205832.4590903534\n",
      "      - -208756.2796853091\n",
      "      - -211744.28779670192\n",
      "      - -212321.71191340042\n",
      "      - -206568.82351210737\n",
      "      - -209618.32932645417\n",
      "      - -207703.0352655596\n",
      "      - -211497.79747343424\n",
      "      - -210086.38161152526\n",
      "      - -209134.36894179278\n",
      "      - -210046.55441885005\n",
      "      - -211620.74986013232\n",
      "      - -209057.7391807344\n",
      "      - -210343.94746517192\n",
      "      - -214952.22845823504\n",
      "      - -209516.13828507107\n",
      "      - -213007.56000533723\n",
      "      - -210459.8709266047\n",
      "      - -207624.68962233156\n",
      "      - -213270.14374286914\n",
      "      - -211255.89488418226\n",
      "      - -208087.20412352576\n",
      "      - -211515.04557022202\n",
      "      - -209426.0329747714\n",
      "      - -211082.36276094447\n",
      "      - -210548.65041430554\n",
      "      - -210138.54302888762\n",
      "      - -209547.40227702918\n",
      "      - -212364.9577835867\n",
      "      - -206858.97447560445\n",
      "      - -206515.92814257205\n",
      "      - -212751.9495215693\n",
      "      - -203583.1193892133\n",
      "      - -209498.1191146309\n",
      "      - -214752.93251599505\n",
      "      - -207800.74209381035\n",
      "      - -207002.80455217842\n",
      "      - -242322.9854993742\n",
      "      - -211566.5052386399\n",
      "      - -211488.29398744385\n",
      "      - -209297.9961594546\n",
      "      - -211602.3156284559\n",
      "      - -210589.70966682298\n",
      "      - -208371.01994328533\n",
      "      - -207879.8081453632\n",
      "      - -208601.6817481603\n",
      "      - -206502.2745604588\n",
      "      - -210771.2867823307\n",
      "      - -213005.264439036\n",
      "      - -210226.69738122946\n",
      "      - -207319.2893190492\n",
      "      - -212814.1526422144\n",
      "      - -205212.48854780797\n",
      "      - -208833.48464419536\n",
      "      - -210717.19105897762\n",
      "      - -209427.57062296942\n",
      "      - -212515.12951066738\n",
      "      - -208377.1610557146\n",
      "      - -209168.5264717991\n",
      "      - -207019.9273836226\n",
      "      - -210065.36297914863\n",
      "      - -206136.3093626355\n",
      "      - -208995.94965130178\n",
      "      - -207275.30650629895\n",
      "      - -204692.09279301873\n",
      "      - -201707.28689280717\n",
      "      - -215247.0256886988\n",
      "      - -256120.8199570944\n",
      "      - -210074.9123544248\n",
      "      - -212546.9032966731\n",
      "      - -213439.4482716434\n",
      "      - -214088.75881328242\n",
      "      - -211408.81712270144\n",
      "      - -210944.210146104\n",
      "      - -210257.8894450847\n",
      "      - -215844.96940293978\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09653005207186904\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4753723766783514\n",
      "      mean_inference_ms: 0.982786843458839\n",
      "      mean_raw_obs_processing_ms: 0.13658804697771543\n",
      "  time_since_restore: 583.2454504966736\n",
      "  time_this_iter_s: 9.198039531707764\n",
      "  time_total_s: 583.2454504966736\n",
      "  timers:\n",
      "    learn_throughput: 129574.74\n",
      "    learn_time_ms: 493.8\n",
      "    load_throughput: 21733926.185\n",
      "    load_time_ms: 2.944\n",
      "    training_iteration_time_ms: 9006.364\n",
      "    update_time_ms: 4.498\n",
      "  timestamp: 1665849327\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3839040\n",
      "  training_iteration: 60\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:55:32 (running for 00:10:06.96)<br>Memory usage on this node: 14.2/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    60</td><td style=\"text-align: right;\">         583.245</td><td style=\"text-align: right;\">3839040</td><td style=\"text-align: right;\"> -210576</td><td style=\"text-align: right;\">             -201707</td><td style=\"text-align: right;\">             -256121</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 3903024\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 3903024\n",
      "    num_agent_steps_trained: 3903024\n",
      "    num_env_steps_sampled: 3903024\n",
      "    num_env_steps_trained: 3903024\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-55-36\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -201707.28689280717\n",
      "  episode_reward_mean: -209576.0651266085\n",
      "  episode_reward_min: -256120.8199570944\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 3900\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1814608573913574\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0010279242414981127\n",
      "          model: {}\n",
      "          policy_loss: 0.00456530274823308\n",
      "          total_loss: 10.0044527053833\n",
      "          vf_explained_var: -5.676632941487014e-09\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 3903024\n",
      "    num_agent_steps_trained: 3903024\n",
      "    num_env_steps_sampled: 3903024\n",
      "    num_env_steps_trained: 3903024\n",
      "  iterations_since_restore: 61\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 3903024\n",
      "  num_agent_steps_trained: 3903024\n",
      "  num_env_steps_sampled: 3903024\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 3903024\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 78.89230769230768\n",
      "    ram_util_percent: 92.01538461538462\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09628350074990001\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4748391217904819\n",
      "    mean_inference_ms: 0.9807037521965765\n",
      "    mean_raw_obs_processing_ms: 0.1362400628105069\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -201707.28689280717\n",
      "    episode_reward_mean: -209576.0651266085\n",
      "    episode_reward_min: -256120.8199570944\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -213005.264439036\n",
      "      - -210226.69738122946\n",
      "      - -207319.2893190492\n",
      "      - -212814.1526422144\n",
      "      - -205212.48854780797\n",
      "      - -208833.48464419536\n",
      "      - -210717.19105897762\n",
      "      - -209427.57062296942\n",
      "      - -212515.12951066738\n",
      "      - -208377.1610557146\n",
      "      - -209168.5264717991\n",
      "      - -207019.9273836226\n",
      "      - -210065.36297914863\n",
      "      - -206136.3093626355\n",
      "      - -208995.94965130178\n",
      "      - -207275.30650629895\n",
      "      - -204692.09279301873\n",
      "      - -201707.28689280717\n",
      "      - -215247.0256886988\n",
      "      - -256120.8199570944\n",
      "      - -210074.9123544248\n",
      "      - -212546.9032966731\n",
      "      - -213439.4482716434\n",
      "      - -214088.75881328242\n",
      "      - -211408.81712270144\n",
      "      - -210944.210146104\n",
      "      - -210257.8894450847\n",
      "      - -215844.96940293978\n",
      "      - -215657.41741826187\n",
      "      - -207966.52056595375\n",
      "      - -208663.73426098598\n",
      "      - -203955.71667422587\n",
      "      - -204179.02387439078\n",
      "      - -206757.74506949692\n",
      "      - -206027.6081455497\n",
      "      - -208643.93861596353\n",
      "      - -213254.1544382324\n",
      "      - -205634.44741907567\n",
      "      - -206008.1332630267\n",
      "      - -208683.71131466108\n",
      "      - -206455.58129745704\n",
      "      - -214143.8499800085\n",
      "      - -209018.08630358445\n",
      "      - -211040.56808669918\n",
      "      - -215243.19244856024\n",
      "      - -206292.11913036506\n",
      "      - -209215.8100289213\n",
      "      - -214602.5541857446\n",
      "      - -208316.01106799385\n",
      "      - -215653.6880432909\n",
      "      - -213059.8384023157\n",
      "      - -209235.8873165778\n",
      "      - -206583.44568622936\n",
      "      - -206875.40605702435\n",
      "      - -205463.459137061\n",
      "      - -208862.47174779308\n",
      "      - -211894.97829574844\n",
      "      - -205325.25392316398\n",
      "      - -206313.29986465097\n",
      "      - -210709.6609585532\n",
      "      - -208187.57059646747\n",
      "      - -207799.2236145302\n",
      "      - -212310.8184974548\n",
      "      - -203031.78741224817\n",
      "      - -207482.22071093493\n",
      "      - -207784.99604266725\n",
      "      - -206940.5108671043\n",
      "      - -209772.40741854897\n",
      "      - -208115.08159050945\n",
      "      - -213401.63551408632\n",
      "      - -214363.30752940138\n",
      "      - -209520.2091773616\n",
      "      - -207146.52597444362\n",
      "      - -207173.0419820482\n",
      "      - -206798.979287159\n",
      "      - -207023.2940812978\n",
      "      - -211667.48531339422\n",
      "      - -206613.3030823473\n",
      "      - -211998.33953811124\n",
      "      - -215345.72175261346\n",
      "      - -205254.88262775363\n",
      "      - -211346.07161449344\n",
      "      - -211887.18527857863\n",
      "      - -208259.0078182971\n",
      "      - -210327.71202646635\n",
      "      - -212162.0256542466\n",
      "      - -209074.61883956607\n",
      "      - -206347.67935060165\n",
      "      - -207283.186474445\n",
      "      - -206670.85349381287\n",
      "      - -206275.29313800362\n",
      "      - -204523.8820822391\n",
      "      - -207907.25526345792\n",
      "      - -206936.2757455121\n",
      "      - -211309.78899026354\n",
      "      - -206361.16175342226\n",
      "      - -205028.45410399852\n",
      "      - -211116.62841394127\n",
      "      - -204906.81011461603\n",
      "      - -208931.02111169847\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09628350074990001\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4748391217904819\n",
      "      mean_inference_ms: 0.9807037521965765\n",
      "      mean_raw_obs_processing_ms: 0.1362400628105069\n",
      "  time_since_restore: 592.26864361763\n",
      "  time_this_iter_s: 9.023193120956421\n",
      "  time_total_s: 592.26864361763\n",
      "  timers:\n",
      "    learn_throughput: 121029.72\n",
      "    learn_time_ms: 528.664\n",
      "    load_throughput: 21859084.086\n",
      "    load_time_ms: 2.927\n",
      "    training_iteration_time_ms: 8984.297\n",
      "    update_time_ms: 4.359\n",
      "  timestamp: 1665849336\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3903024\n",
      "  training_iteration: 61\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:55:41 (running for 00:10:16.10)<br>Memory usage on this node: 14.2/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    61</td><td style=\"text-align: right;\">         592.269</td><td style=\"text-align: right;\">3903024</td><td style=\"text-align: right;\"> -209576</td><td style=\"text-align: right;\">             -201707</td><td style=\"text-align: right;\">             -256121</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 3967008\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 3967008\n",
      "    num_agent_steps_trained: 3967008\n",
      "    num_env_steps_sampled: 3967008\n",
      "    num_env_steps_trained: 3967008\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-55-45\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -203031.78741224817\n",
      "  episode_reward_mean: -209232.53969680224\n",
      "  episode_reward_min: -218036.92408632408\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 3960\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.175597906112671\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.000632068607956171\n",
      "          model: {}\n",
      "          policy_loss: 0.007625813130289316\n",
      "          total_loss: 10.007433891296387\n",
      "          vf_explained_var: -1.8922110101016187e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 3967008\n",
      "    num_agent_steps_trained: 3967008\n",
      "    num_env_steps_sampled: 3967008\n",
      "    num_env_steps_trained: 3967008\n",
      "  iterations_since_restore: 62\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 3967008\n",
      "  num_agent_steps_trained: 3967008\n",
      "  num_env_steps_sampled: 3967008\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 3967008\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.525\n",
      "    ram_util_percent: 92.05833333333334\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09626396542366812\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.47424785194344066\n",
      "    mean_inference_ms: 0.9784984591361074\n",
      "    mean_raw_obs_processing_ms: 0.13627700682386912\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -203031.78741224817\n",
      "    episode_reward_mean: -209232.53969680224\n",
      "    episode_reward_min: -218036.92408632408\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -208187.57059646747\n",
      "      - -207799.2236145302\n",
      "      - -212310.8184974548\n",
      "      - -203031.78741224817\n",
      "      - -207482.22071093493\n",
      "      - -207784.99604266725\n",
      "      - -206940.5108671043\n",
      "      - -209772.40741854897\n",
      "      - -208115.08159050945\n",
      "      - -213401.63551408632\n",
      "      - -214363.30752940138\n",
      "      - -209520.2091773616\n",
      "      - -207146.52597444362\n",
      "      - -207173.0419820482\n",
      "      - -206798.979287159\n",
      "      - -207023.2940812978\n",
      "      - -211667.48531339422\n",
      "      - -206613.3030823473\n",
      "      - -211998.33953811124\n",
      "      - -215345.72175261346\n",
      "      - -205254.88262775363\n",
      "      - -211346.07161449344\n",
      "      - -211887.18527857863\n",
      "      - -208259.0078182971\n",
      "      - -210327.71202646635\n",
      "      - -212162.0256542466\n",
      "      - -209074.61883956607\n",
      "      - -206347.67935060165\n",
      "      - -207283.186474445\n",
      "      - -206670.85349381287\n",
      "      - -206275.29313800362\n",
      "      - -204523.8820822391\n",
      "      - -207907.25526345792\n",
      "      - -206936.2757455121\n",
      "      - -211309.78899026354\n",
      "      - -206361.16175342226\n",
      "      - -205028.45410399852\n",
      "      - -211116.62841394127\n",
      "      - -204906.81011461603\n",
      "      - -208931.02111169847\n",
      "      - -206139.77228214062\n",
      "      - -207416.7576886872\n",
      "      - -205847.60427965337\n",
      "      - -211103.87072794326\n",
      "      - -212236.23137056653\n",
      "      - -215053.023356148\n",
      "      - -209093.61437541735\n",
      "      - -211988.04303398245\n",
      "      - -210632.10838444234\n",
      "      - -206593.2970405797\n",
      "      - -206239.89247043565\n",
      "      - -205861.9227757846\n",
      "      - -216947.25479469742\n",
      "      - -203340.36714864903\n",
      "      - -207122.08584794964\n",
      "      - -204332.72094966928\n",
      "      - -208945.31784897097\n",
      "      - -206092.76770333722\n",
      "      - -217169.48466092095\n",
      "      - -213937.07565591385\n",
      "      - -210054.905799956\n",
      "      - -212056.96402696366\n",
      "      - -209110.1729039847\n",
      "      - -206497.64245822834\n",
      "      - -206490.84063455346\n",
      "      - -211240.6919405915\n",
      "      - -212801.02223728172\n",
      "      - -210333.54464873974\n",
      "      - -215016.6900906646\n",
      "      - -209376.69401792597\n",
      "      - -208051.51461715376\n",
      "      - -209516.22402372918\n",
      "      - -207235.07665360405\n",
      "      - -210607.75964537094\n",
      "      - -206623.1589236934\n",
      "      - -208384.8406777475\n",
      "      - -207247.4202502239\n",
      "      - -207441.90983600024\n",
      "      - -210577.98777724805\n",
      "      - -205935.23737989433\n",
      "      - -209300.26742885137\n",
      "      - -218036.92408632408\n",
      "      - -208078.93768103386\n",
      "      - -206741.52268921683\n",
      "      - -212542.8446228931\n",
      "      - -213210.66941731726\n",
      "      - -212504.89315913082\n",
      "      - -211113.52207613073\n",
      "      - -212599.86889342612\n",
      "      - -207598.8554575081\n",
      "      - -215225.21741068776\n",
      "      - -213557.6158123122\n",
      "      - -204614.9560407447\n",
      "      - -204571.72624929395\n",
      "      - -208277.83500275144\n",
      "      - -214396.55501730295\n",
      "      - -207485.39794855803\n",
      "      - -211954.34189741377\n",
      "      - -207755.87172048152\n",
      "      - -208606.3822512594\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09626396542366812\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.47424785194344066\n",
      "      mean_inference_ms: 0.9784984591361074\n",
      "      mean_raw_obs_processing_ms: 0.13627700682386912\n",
      "  time_since_restore: 600.7783620357513\n",
      "  time_this_iter_s: 8.509718418121338\n",
      "  time_total_s: 600.7783620357513\n",
      "  timers:\n",
      "    learn_throughput: 120649.008\n",
      "    learn_time_ms: 530.332\n",
      "    load_throughput: 22207282.526\n",
      "    load_time_ms: 2.881\n",
      "    training_iteration_time_ms: 8948.167\n",
      "    update_time_ms: 4.348\n",
      "  timestamp: 1665849345\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3967008\n",
      "  training_iteration: 62\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:55:50 (running for 00:10:25.38)<br>Memory usage on this node: 14.2/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    62</td><td style=\"text-align: right;\">         600.778</td><td style=\"text-align: right;\">3967008</td><td style=\"text-align: right;\"> -209233</td><td style=\"text-align: right;\">             -203032</td><td style=\"text-align: right;\">             -218037</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 4030992\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 4030992\n",
      "    num_agent_steps_trained: 4030992\n",
      "    num_env_steps_sampled: 4030992\n",
      "    num_env_steps_trained: 4030992\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-55-54\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -202873.63778807785\n",
      "  episode_reward_mean: -208681.10574136637\n",
      "  episode_reward_min: -218309.91540856118\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 4020\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1752097606658936\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.000434400251833722\n",
      "          model: {}\n",
      "          policy_loss: 0.0009986298391595483\n",
      "          total_loss: 10.00076675415039\n",
      "          vf_explained_var: -1.8922110101016187e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 4030992\n",
      "    num_agent_steps_trained: 4030992\n",
      "    num_env_steps_sampled: 4030992\n",
      "    num_env_steps_trained: 4030992\n",
      "  iterations_since_restore: 63\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 4030992\n",
      "  num_agent_steps_trained: 4030992\n",
      "  num_env_steps_sampled: 4030992\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 4030992\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.03076923076924\n",
      "    ram_util_percent: 92.06923076923077\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09610824476310714\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4741382462378133\n",
      "    mean_inference_ms: 0.9763733022910523\n",
      "    mean_raw_obs_processing_ms: 0.1361273627067544\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -202873.63778807785\n",
      "    episode_reward_mean: -208681.10574136637\n",
      "    episode_reward_min: -218309.91540856118\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -210054.905799956\n",
      "      - -212056.96402696366\n",
      "      - -209110.1729039847\n",
      "      - -206497.64245822834\n",
      "      - -206490.84063455346\n",
      "      - -211240.6919405915\n",
      "      - -212801.02223728172\n",
      "      - -210333.54464873974\n",
      "      - -215016.6900906646\n",
      "      - -209376.69401792597\n",
      "      - -208051.51461715376\n",
      "      - -209516.22402372918\n",
      "      - -207235.07665360405\n",
      "      - -210607.75964537094\n",
      "      - -206623.1589236934\n",
      "      - -208384.8406777475\n",
      "      - -207247.4202502239\n",
      "      - -207441.90983600024\n",
      "      - -210577.98777724805\n",
      "      - -205935.23737989433\n",
      "      - -209300.26742885137\n",
      "      - -218036.92408632408\n",
      "      - -208078.93768103386\n",
      "      - -206741.52268921683\n",
      "      - -212542.8446228931\n",
      "      - -213210.66941731726\n",
      "      - -212504.89315913082\n",
      "      - -211113.52207613073\n",
      "      - -212599.86889342612\n",
      "      - -207598.8554575081\n",
      "      - -215225.21741068776\n",
      "      - -213557.6158123122\n",
      "      - -204614.9560407447\n",
      "      - -204571.72624929395\n",
      "      - -208277.83500275144\n",
      "      - -214396.55501730295\n",
      "      - -207485.39794855803\n",
      "      - -211954.34189741377\n",
      "      - -207755.87172048152\n",
      "      - -208606.3822512594\n",
      "      - -209934.17023919534\n",
      "      - -207144.2978394184\n",
      "      - -203973.0516660672\n",
      "      - -207126.09398378406\n",
      "      - -207878.34798137678\n",
      "      - -207829.7407183996\n",
      "      - -205383.24044289853\n",
      "      - -205894.42383043273\n",
      "      - -207793.77994021037\n",
      "      - -218309.91540856118\n",
      "      - -207767.20960756383\n",
      "      - -206880.07200154124\n",
      "      - -207902.46604610234\n",
      "      - -206669.50374320717\n",
      "      - -205585.3117891383\n",
      "      - -206834.77689973582\n",
      "      - -208498.66769791287\n",
      "      - -204777.57405031557\n",
      "      - -205103.29280454994\n",
      "      - -208364.154985267\n",
      "      - -202897.45083190346\n",
      "      - -211768.88676249265\n",
      "      - -207630.1540892372\n",
      "      - -207891.80923858946\n",
      "      - -209096.19717647787\n",
      "      - -210341.4454603013\n",
      "      - -207953.89249996742\n",
      "      - -207999.83211969552\n",
      "      - -211214.5672738103\n",
      "      - -206900.48548338737\n",
      "      - -213228.32099894382\n",
      "      - -206297.861276185\n",
      "      - -202873.63778807785\n",
      "      - -206041.0984082826\n",
      "      - -206593.1631473924\n",
      "      - -207733.66991410244\n",
      "      - -204913.14690428667\n",
      "      - -206927.1515099815\n",
      "      - -208351.41931379033\n",
      "      - -208637.84712281643\n",
      "      - -214557.90738147649\n",
      "      - -207297.07855430717\n",
      "      - -205911.12350927395\n",
      "      - -207944.12235945396\n",
      "      - -211141.69392268496\n",
      "      - -211265.30941729742\n",
      "      - -212484.55964670287\n",
      "      - -208462.683507047\n",
      "      - -208196.882590671\n",
      "      - -205857.21210767663\n",
      "      - -204294.46568886854\n",
      "      - -209778.18310403905\n",
      "      - -207227.6704447716\n",
      "      - -208664.17993844015\n",
      "      - -208785.74409012715\n",
      "      - -205319.76873677436\n",
      "      - -207332.80085309304\n",
      "      - -209164.13974112118\n",
      "      - -207900.3912359195\n",
      "      - -208808.02490529625\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09610824476310714\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4741382462378133\n",
      "      mean_inference_ms: 0.9763733022910523\n",
      "      mean_raw_obs_processing_ms: 0.1361273627067544\n",
      "  time_since_restore: 609.6976211071014\n",
      "  time_this_iter_s: 8.919259071350098\n",
      "  time_total_s: 609.6976211071014\n",
      "  timers:\n",
      "    learn_throughput: 119807.095\n",
      "    learn_time_ms: 534.059\n",
      "    load_throughput: 22127632.059\n",
      "    load_time_ms: 2.892\n",
      "    training_iteration_time_ms: 8986.975\n",
      "    update_time_ms: 4.254\n",
      "  timestamp: 1665849354\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4030992\n",
      "  training_iteration: 63\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:56:00 (running for 00:10:34.42)<br>Memory usage on this node: 14.2/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    63</td><td style=\"text-align: right;\">         609.698</td><td style=\"text-align: right;\">4030992</td><td style=\"text-align: right;\"> -208681</td><td style=\"text-align: right;\">             -202874</td><td style=\"text-align: right;\">             -218310</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 4094976\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 4094976\n",
      "    num_agent_steps_trained: 4094976\n",
      "    num_env_steps_sampled: 4094976\n",
      "    num_env_steps_trained: 4094976\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-56-04\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -202873.63778807785\n",
      "  episode_reward_mean: -208479.31249779358\n",
      "  episode_reward_min: -247614.49995284187\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 4092\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1698086261749268\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00035724075860343874\n",
      "          model: {}\n",
      "          policy_loss: 0.005069557577371597\n",
      "          total_loss: 10.0048246383667\n",
      "          vf_explained_var: -3.216758770463457e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 4094976\n",
      "    num_agent_steps_trained: 4094976\n",
      "    num_env_steps_sampled: 4094976\n",
      "    num_env_steps_trained: 4094976\n",
      "  iterations_since_restore: 64\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 4094976\n",
      "  num_agent_steps_trained: 4094976\n",
      "  num_env_steps_sampled: 4094976\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 4094976\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 80.36923076923077\n",
      "    ram_util_percent: 92.04615384615386\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09589969249106833\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4736624356255995\n",
      "    mean_inference_ms: 0.9750337293998499\n",
      "    mean_raw_obs_processing_ms: 0.13589017246961757\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -202873.63778807785\n",
      "    episode_reward_mean: -208479.31249779358\n",
      "    episode_reward_min: -247614.49995284187\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -202873.63778807785\n",
      "      - -206041.0984082826\n",
      "      - -206593.1631473924\n",
      "      - -207733.66991410244\n",
      "      - -204913.14690428667\n",
      "      - -206927.1515099815\n",
      "      - -208351.41931379033\n",
      "      - -208637.84712281643\n",
      "      - -214557.90738147649\n",
      "      - -207297.07855430717\n",
      "      - -205911.12350927395\n",
      "      - -207944.12235945396\n",
      "      - -211141.69392268496\n",
      "      - -211265.30941729742\n",
      "      - -212484.55964670287\n",
      "      - -208462.683507047\n",
      "      - -208196.882590671\n",
      "      - -205857.21210767663\n",
      "      - -204294.46568886854\n",
      "      - -209778.18310403905\n",
      "      - -207227.6704447716\n",
      "      - -208664.17993844015\n",
      "      - -208785.74409012715\n",
      "      - -205319.76873677436\n",
      "      - -207332.80085309304\n",
      "      - -209164.13974112118\n",
      "      - -207900.3912359195\n",
      "      - -208808.02490529625\n",
      "      - -207144.55372676186\n",
      "      - -210695.72940714593\n",
      "      - -204649.0085636414\n",
      "      - -203523.38934951677\n",
      "      - -202976.80097285105\n",
      "      - -205859.53271381347\n",
      "      - -203555.42263365234\n",
      "      - -211996.30114476077\n",
      "      - -213397.11730716605\n",
      "      - -206040.9614570241\n",
      "      - -209512.27535883422\n",
      "      - -211721.77678450843\n",
      "      - -211710.9154685238\n",
      "      - -213036.3141476862\n",
      "      - -209829.26795766776\n",
      "      - -212977.3707890411\n",
      "      - -206215.41922039044\n",
      "      - -211473.5407088871\n",
      "      - -208824.89368466646\n",
      "      - -204696.95612374216\n",
      "      - -203017.45404057793\n",
      "      - -207779.50849088377\n",
      "      - -205979.03601691718\n",
      "      - -209621.13818209933\n",
      "      - -204252.88562400095\n",
      "      - -209494.74538527185\n",
      "      - -205124.5871678149\n",
      "      - -207843.10638638306\n",
      "      - -205208.11435367446\n",
      "      - -211193.33709219203\n",
      "      - -206547.93318228328\n",
      "      - -212158.85176293025\n",
      "      - -209391.57076462315\n",
      "      - -208789.0212702821\n",
      "      - -213006.04482409803\n",
      "      - -209460.6410404567\n",
      "      - -211142.3620615007\n",
      "      - -210691.9654000056\n",
      "      - -205126.1109282304\n",
      "      - -208910.28552065534\n",
      "      - -208154.48827968127\n",
      "      - -210713.45032871206\n",
      "      - -207811.17885463563\n",
      "      - -204084.4243959294\n",
      "      - -208968.58044541493\n",
      "      - -206169.94347990566\n",
      "      - -213285.58422226447\n",
      "      - -208481.06216911768\n",
      "      - -212243.60285748917\n",
      "      - -207151.43153438554\n",
      "      - -208695.44104209804\n",
      "      - -212102.45655906684\n",
      "      - -210523.9886896001\n",
      "      - -208244.2251065922\n",
      "      - -206115.37166009683\n",
      "      - -207518.11009640875\n",
      "      - -205656.71551988443\n",
      "      - -209393.8335799233\n",
      "      - -206755.5240999609\n",
      "      - -203752.07217768126\n",
      "      - -205741.5497778901\n",
      "      - -203810.41336843654\n",
      "      - -206705.75444959468\n",
      "      - -209686.5279647204\n",
      "      - -208753.84613863836\n",
      "      - -206838.2583539487\n",
      "      - -204966.38455999782\n",
      "      - -209341.77770881073\n",
      "      - -206100.21642531766\n",
      "      - -210049.03119502836\n",
      "      - -247614.49995284187\n",
      "      - -205460.1819263458\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09589969249106833\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4736624356255995\n",
      "      mean_inference_ms: 0.9750337293998499\n",
      "      mean_raw_obs_processing_ms: 0.13589017246961757\n",
      "  time_since_restore: 618.8146965503693\n",
      "  time_this_iter_s: 9.117075443267822\n",
      "  time_total_s: 618.8146965503693\n",
      "  timers:\n",
      "    learn_throughput: 119866.059\n",
      "    learn_time_ms: 533.796\n",
      "    load_throughput: 21872802.244\n",
      "    load_time_ms: 2.925\n",
      "    training_iteration_time_ms: 9002.372\n",
      "    update_time_ms: 4.2\n",
      "  timestamp: 1665849364\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4094976\n",
      "  training_iteration: 64\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:56:09 (running for 00:10:43.55)<br>Memory usage on this node: 14.2/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    64</td><td style=\"text-align: right;\">         618.815</td><td style=\"text-align: right;\">4094976</td><td style=\"text-align: right;\"> -208479</td><td style=\"text-align: right;\">             -202874</td><td style=\"text-align: right;\">             -247614</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 4158960\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 4158960\n",
      "    num_agent_steps_trained: 4158960\n",
      "    num_env_steps_sampled: 4158960\n",
      "    num_env_steps_trained: 4158960\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-56-13\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -202020.49268645237\n",
      "  episode_reward_mean: -208212.63322002982\n",
      "  episode_reward_min: -247614.49995284187\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 4152\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.168926239013672\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00032398023176938295\n",
      "          model: {}\n",
      "          policy_loss: 0.006847952958196402\n",
      "          total_loss: 10.006595611572266\n",
      "          vf_explained_var: -1.9868215517249155e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 4158960\n",
      "    num_agent_steps_trained: 4158960\n",
      "    num_env_steps_sampled: 4158960\n",
      "    num_env_steps_trained: 4158960\n",
      "  iterations_since_restore: 65\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 4158960\n",
      "  num_agent_steps_trained: 4158960\n",
      "  num_env_steps_sampled: 4158960\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 4158960\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.2076923076923\n",
      "    ram_util_percent: 92.09230769230768\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09593609424323896\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4734847348610606\n",
      "    mean_inference_ms: 0.9741607122553846\n",
      "    mean_raw_obs_processing_ms: 0.13598302946153631\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -202020.49268645237\n",
      "    episode_reward_mean: -208212.63322002982\n",
      "    episode_reward_min: -247614.49995284187\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -209391.57076462315\n",
      "      - -208789.0212702821\n",
      "      - -213006.04482409803\n",
      "      - -209460.6410404567\n",
      "      - -211142.3620615007\n",
      "      - -210691.9654000056\n",
      "      - -205126.1109282304\n",
      "      - -208910.28552065534\n",
      "      - -208154.48827968127\n",
      "      - -210713.45032871206\n",
      "      - -207811.17885463563\n",
      "      - -204084.4243959294\n",
      "      - -208968.58044541493\n",
      "      - -206169.94347990566\n",
      "      - -213285.58422226447\n",
      "      - -208481.06216911768\n",
      "      - -212243.60285748917\n",
      "      - -207151.43153438554\n",
      "      - -208695.44104209804\n",
      "      - -212102.45655906684\n",
      "      - -210523.9886896001\n",
      "      - -208244.2251065922\n",
      "      - -206115.37166009683\n",
      "      - -207518.11009640875\n",
      "      - -205656.71551988443\n",
      "      - -209393.8335799233\n",
      "      - -206755.5240999609\n",
      "      - -203752.07217768126\n",
      "      - -205741.5497778901\n",
      "      - -203810.41336843654\n",
      "      - -206705.75444959468\n",
      "      - -209686.5279647204\n",
      "      - -208753.84613863836\n",
      "      - -206838.2583539487\n",
      "      - -204966.38455999782\n",
      "      - -209341.77770881073\n",
      "      - -206100.21642531766\n",
      "      - -210049.03119502836\n",
      "      - -247614.49995284187\n",
      "      - -205460.1819263458\n",
      "      - -204803.702103232\n",
      "      - -208098.39405896\n",
      "      - -209246.86688074705\n",
      "      - -206052.11453638945\n",
      "      - -212850.5187017053\n",
      "      - -206631.86553746898\n",
      "      - -209789.93531270008\n",
      "      - -207563.40394416242\n",
      "      - -203167.87516184265\n",
      "      - -208274.7746550907\n",
      "      - -208774.8367240844\n",
      "      - -210180.646285058\n",
      "      - -207398.87271115868\n",
      "      - -209570.2685677632\n",
      "      - -202020.49268645237\n",
      "      - -206166.02739609443\n",
      "      - -203700.99780502508\n",
      "      - -207162.7833706888\n",
      "      - -204983.37936801987\n",
      "      - -206292.8435840227\n",
      "      - -211946.23927084656\n",
      "      - -206921.4617587225\n",
      "      - -203942.62938810588\n",
      "      - -206458.41293652926\n",
      "      - -210817.64649719466\n",
      "      - -206618.2679848306\n",
      "      - -205876.9896500323\n",
      "      - -206157.2799386372\n",
      "      - -209491.47572379254\n",
      "      - -205532.9619751425\n",
      "      - -209372.28243023614\n",
      "      - -206754.34985534966\n",
      "      - -211217.40516317787\n",
      "      - -210725.26256994222\n",
      "      - -212650.47236522674\n",
      "      - -208230.9640341341\n",
      "      - -203482.93684084833\n",
      "      - -212362.04016840114\n",
      "      - -205241.0064582148\n",
      "      - -204896.23616731877\n",
      "      - -210473.59099530164\n",
      "      - -208465.99551115293\n",
      "      - -207802.69437159816\n",
      "      - -206842.1823818471\n",
      "      - -211034.50747261502\n",
      "      - -209431.33667291602\n",
      "      - -205338.5998460437\n",
      "      - -210526.4607513448\n",
      "      - -208155.80257187886\n",
      "      - -207546.0917300382\n",
      "      - -207915.21386419027\n",
      "      - -204286.1810987242\n",
      "      - -210629.02468498895\n",
      "      - -205012.43753857978\n",
      "      - -209013.51508632742\n",
      "      - -208272.39176397075\n",
      "      - -205720.06593688845\n",
      "      - -202881.9193436428\n",
      "      - -207055.56836853255\n",
      "      - -206024.89271477642\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09593609424323896\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4734847348610606\n",
      "      mean_inference_ms: 0.9741607122553846\n",
      "      mean_raw_obs_processing_ms: 0.13598302946153631\n",
      "  time_since_restore: 628.052309513092\n",
      "  time_this_iter_s: 9.237612962722778\n",
      "  time_total_s: 628.052309513092\n",
      "  timers:\n",
      "    learn_throughput: 118852.683\n",
      "    learn_time_ms: 538.347\n",
      "    load_throughput: 21776074.906\n",
      "    load_time_ms: 2.938\n",
      "    training_iteration_time_ms: 9020.904\n",
      "    update_time_ms: 4.132\n",
      "  timestamp: 1665849373\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4158960\n",
      "  training_iteration: 65\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:56:18 (running for 00:10:52.75)<br>Memory usage on this node: 14.2/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    65</td><td style=\"text-align: right;\">         628.052</td><td style=\"text-align: right;\">4158960</td><td style=\"text-align: right;\"> -208213</td><td style=\"text-align: right;\">             -202020</td><td style=\"text-align: right;\">             -247614</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 4222944\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 4222944\n",
      "    num_agent_steps_trained: 4222944\n",
      "    num_env_steps_sampled: 4222944\n",
      "    num_env_steps_trained: 4222944\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-56-22\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -202881.9193436428\n",
      "  episode_reward_mean: -207668.24339773544\n",
      "  episode_reward_min: -213795.3228298671\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 4212\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.173933744430542\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0005599631113000214\n",
      "          model: {}\n",
      "          policy_loss: 0.000814837112557143\n",
      "          total_loss: 10.000609397888184\n",
      "          vf_explained_var: -2.932926967957883e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 4222944\n",
      "    num_agent_steps_trained: 4222944\n",
      "    num_env_steps_sampled: 4222944\n",
      "    num_env_steps_trained: 4222944\n",
      "  iterations_since_restore: 66\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 4222944\n",
      "  num_agent_steps_trained: 4222944\n",
      "  num_env_steps_sampled: 4222944\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 4222944\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.30769230769232\n",
      "    ram_util_percent: 92.0923076923077\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09583873476716931\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4734915496974355\n",
      "    mean_inference_ms: 0.9729841363673037\n",
      "    mean_raw_obs_processing_ms: 0.13588797944304487\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -202881.9193436428\n",
      "    episode_reward_mean: -207668.24339773544\n",
      "    episode_reward_min: -213795.3228298671\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -211946.23927084656\n",
      "      - -206921.4617587225\n",
      "      - -203942.62938810588\n",
      "      - -206458.41293652926\n",
      "      - -210817.64649719466\n",
      "      - -206618.2679848306\n",
      "      - -205876.9896500323\n",
      "      - -206157.2799386372\n",
      "      - -209491.47572379254\n",
      "      - -205532.9619751425\n",
      "      - -209372.28243023614\n",
      "      - -206754.34985534966\n",
      "      - -211217.40516317787\n",
      "      - -210725.26256994222\n",
      "      - -212650.47236522674\n",
      "      - -208230.9640341341\n",
      "      - -203482.93684084833\n",
      "      - -212362.04016840114\n",
      "      - -205241.0064582148\n",
      "      - -204896.23616731877\n",
      "      - -210473.59099530164\n",
      "      - -208465.99551115293\n",
      "      - -207802.69437159816\n",
      "      - -206842.1823818471\n",
      "      - -211034.50747261502\n",
      "      - -209431.33667291602\n",
      "      - -205338.5998460437\n",
      "      - -210526.4607513448\n",
      "      - -208155.80257187886\n",
      "      - -207546.0917300382\n",
      "      - -207915.21386419027\n",
      "      - -204286.1810987242\n",
      "      - -210629.02468498895\n",
      "      - -205012.43753857978\n",
      "      - -209013.51508632742\n",
      "      - -208272.39176397075\n",
      "      - -205720.06593688845\n",
      "      - -202881.9193436428\n",
      "      - -207055.56836853255\n",
      "      - -206024.89271477642\n",
      "      - -206215.31206821423\n",
      "      - -206890.35289102516\n",
      "      - -205656.2216959985\n",
      "      - -205489.70603812413\n",
      "      - -206601.04686614958\n",
      "      - -213795.3228298671\n",
      "      - -207656.4641515524\n",
      "      - -207679.78361223204\n",
      "      - -207412.60502541598\n",
      "      - -210465.69310628463\n",
      "      - -211241.89928215608\n",
      "      - -209544.11760485862\n",
      "      - -209842.35541535416\n",
      "      - -205431.97397651838\n",
      "      - -210274.76004178877\n",
      "      - -209626.69022180786\n",
      "      - -206309.19103770013\n",
      "      - -208625.22524927938\n",
      "      - -206435.58889193548\n",
      "      - -206468.28203047763\n",
      "      - -206228.41887924916\n",
      "      - -207939.795538378\n",
      "      - -204432.07204749444\n",
      "      - -205800.44044603643\n",
      "      - -206607.1672332942\n",
      "      - -204485.59100436282\n",
      "      - -205194.12662532306\n",
      "      - -206044.44758805103\n",
      "      - -208106.92873686837\n",
      "      - -209864.17431970392\n",
      "      - -206054.9309145974\n",
      "      - -206363.26921251934\n",
      "      - -205347.12119557758\n",
      "      - -205566.73041138248\n",
      "      - -206417.58646874447\n",
      "      - -206707.41289187828\n",
      "      - -205401.6932027053\n",
      "      - -208605.70884353307\n",
      "      - -208331.65637391515\n",
      "      - -204949.17403053615\n",
      "      - -207576.48621112492\n",
      "      - -208684.3378773343\n",
      "      - -210053.93019816742\n",
      "      - -206292.9354848504\n",
      "      - -207292.5897188293\n",
      "      - -206072.32141052402\n",
      "      - -210373.57722689034\n",
      "      - -208461.57373200086\n",
      "      - -205193.7024588452\n",
      "      - -212676.42207840062\n",
      "      - -207899.4277261946\n",
      "      - -208573.98546285863\n",
      "      - -206970.71400237252\n",
      "      - -210576.40529248808\n",
      "      - -207872.5027949937\n",
      "      - -207967.09311925646\n",
      "      - -210507.03041746083\n",
      "      - -205385.8989220914\n",
      "      - -210097.20408553357\n",
      "      - -207060.3696703914\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09583873476716931\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4734915496974355\n",
      "      mean_inference_ms: 0.9729841363673037\n",
      "      mean_raw_obs_processing_ms: 0.13588797944304487\n",
      "  time_since_restore: 637.0356001853943\n",
      "  time_this_iter_s: 8.983290672302246\n",
      "  time_total_s: 637.0356001853943\n",
      "  timers:\n",
      "    learn_throughput: 119044.895\n",
      "    learn_time_ms: 537.478\n",
      "    load_throughput: 21781730.662\n",
      "    load_time_ms: 2.938\n",
      "    training_iteration_time_ms: 9026.034\n",
      "    update_time_ms: 4.016\n",
      "  timestamp: 1665849382\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4222944\n",
      "  training_iteration: 66\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:56:27 (running for 00:11:01.96)<br>Memory usage on this node: 14.3/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    66</td><td style=\"text-align: right;\">         637.036</td><td style=\"text-align: right;\">4222944</td><td style=\"text-align: right;\"> -207668</td><td style=\"text-align: right;\">             -202882</td><td style=\"text-align: right;\">             -213795</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 4286928\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 4286928\n",
      "    num_agent_steps_trained: 4286928\n",
      "    num_env_steps_sampled: 4286928\n",
      "    num_env_steps_trained: 4286928\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-56-31\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -201957.53488388745\n",
      "  episode_reward_mean: -207954.24058263513\n",
      "  episode_reward_min: -215639.8551689474\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 4284\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.174314498901367\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.000840349355712533\n",
      "          model: {}\n",
      "          policy_loss: 0.0035911151207983494\n",
      "          total_loss: 10.00344181060791\n",
      "          vf_explained_var: -3.0275376872168636e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 4286928\n",
      "    num_agent_steps_trained: 4286928\n",
      "    num_env_steps_sampled: 4286928\n",
      "    num_env_steps_trained: 4286928\n",
      "  iterations_since_restore: 67\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 4286928\n",
      "  num_agent_steps_trained: 4286928\n",
      "  num_env_steps_sampled: 4286928\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 4286928\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.74615384615385\n",
      "    ram_util_percent: 92.14615384615385\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0957777498704791\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.47297215073761045\n",
      "    mean_inference_ms: 0.9720618967826402\n",
      "    mean_raw_obs_processing_ms: 0.13568357763679387\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -201957.53488388745\n",
      "    episode_reward_mean: -207954.24058263513\n",
      "    episode_reward_min: -215639.8551689474\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -205347.12119557758\n",
      "      - -205566.73041138248\n",
      "      - -206417.58646874447\n",
      "      - -206707.41289187828\n",
      "      - -205401.6932027053\n",
      "      - -208605.70884353307\n",
      "      - -208331.65637391515\n",
      "      - -204949.17403053615\n",
      "      - -207576.48621112492\n",
      "      - -208684.3378773343\n",
      "      - -210053.93019816742\n",
      "      - -206292.9354848504\n",
      "      - -207292.5897188293\n",
      "      - -206072.32141052402\n",
      "      - -210373.57722689034\n",
      "      - -208461.57373200086\n",
      "      - -205193.7024588452\n",
      "      - -212676.42207840062\n",
      "      - -207899.4277261946\n",
      "      - -208573.98546285863\n",
      "      - -206970.71400237252\n",
      "      - -210576.40529248808\n",
      "      - -207872.5027949937\n",
      "      - -207967.09311925646\n",
      "      - -210507.03041746083\n",
      "      - -205385.8989220914\n",
      "      - -210097.20408553357\n",
      "      - -207060.3696703914\n",
      "      - -205456.47014319673\n",
      "      - -204758.14573248947\n",
      "      - -210642.99162038253\n",
      "      - -208303.3960557269\n",
      "      - -213213.85642687956\n",
      "      - -211670.21637243978\n",
      "      - -209898.93076016792\n",
      "      - -209722.68710998687\n",
      "      - -210070.94951796278\n",
      "      - -205879.2638736918\n",
      "      - -213874.05082496605\n",
      "      - -202846.6101282207\n",
      "      - -205475.41747734876\n",
      "      - -206344.6381566642\n",
      "      - -211052.75407525626\n",
      "      - -204374.22155443934\n",
      "      - -201957.53488388745\n",
      "      - -209805.16990730655\n",
      "      - -211898.47242267488\n",
      "      - -207320.12138743536\n",
      "      - -206316.11406846135\n",
      "      - -205411.83230162854\n",
      "      - -205598.73470659246\n",
      "      - -206805.4598604001\n",
      "      - -206320.91721591388\n",
      "      - -208745.0635194626\n",
      "      - -212957.22280045383\n",
      "      - -202899.89200157736\n",
      "      - -208144.93116568273\n",
      "      - -205308.97902729266\n",
      "      - -206146.56226172613\n",
      "      - -206058.1371381267\n",
      "      - -209576.5326359216\n",
      "      - -207050.0496442815\n",
      "      - -207991.59090671485\n",
      "      - -209479.35246541226\n",
      "      - -215639.8551689474\n",
      "      - -205566.750724944\n",
      "      - -209942.1318951882\n",
      "      - -205297.78947178076\n",
      "      - -203689.8268087902\n",
      "      - -214417.21249096235\n",
      "      - -209763.19259384676\n",
      "      - -206661.35334133517\n",
      "      - -208684.846432446\n",
      "      - -206599.06809480878\n",
      "      - -207279.59769462617\n",
      "      - -208463.80440423\n",
      "      - -205544.80921804527\n",
      "      - -212050.7861334749\n",
      "      - -209208.57091801698\n",
      "      - -208468.75628215566\n",
      "      - -209794.86365038302\n",
      "      - -210280.21368340417\n",
      "      - -213367.7287648428\n",
      "      - -206687.80836036027\n",
      "      - -208402.62655059018\n",
      "      - -208809.32884838997\n",
      "      - -208903.86137474515\n",
      "      - -205413.21756307088\n",
      "      - -207956.188928065\n",
      "      - -207912.7410827952\n",
      "      - -202868.49000850963\n",
      "      - -205019.17436068857\n",
      "      - -207105.81299347072\n",
      "      - -207463.03283266982\n",
      "      - -207199.92316368435\n",
      "      - -206549.56613139302\n",
      "      - -211072.12891568744\n",
      "      - -209070.43143810407\n",
      "      - -210528.20416756877\n",
      "      - -207447.5023118414\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.0957777498704791\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.47297215073761045\n",
      "      mean_inference_ms: 0.9720618967826402\n",
      "      mean_raw_obs_processing_ms: 0.13568357763679387\n",
      "  time_since_restore: 646.310201883316\n",
      "  time_this_iter_s: 9.274601697921753\n",
      "  time_total_s: 646.310201883316\n",
      "  timers:\n",
      "    learn_throughput: 119063.269\n",
      "    learn_time_ms: 537.395\n",
      "    load_throughput: 18343826.488\n",
      "    load_time_ms: 3.488\n",
      "    training_iteration_time_ms: 9027.046\n",
      "    update_time_ms: 3.996\n",
      "  timestamp: 1665849391\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4286928\n",
      "  training_iteration: 67\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:56:36 (running for 00:11:11.16)<br>Memory usage on this node: 14.2/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    67</td><td style=\"text-align: right;\">          646.31</td><td style=\"text-align: right;\">4286928</td><td style=\"text-align: right;\"> -207954</td><td style=\"text-align: right;\">             -201958</td><td style=\"text-align: right;\">             -215640</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 4350912\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 4350912\n",
      "    num_agent_steps_trained: 4350912\n",
      "    num_env_steps_sampled: 4350912\n",
      "    num_env_steps_trained: 4350912\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-56-40\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -202386.70511208934\n",
      "  episode_reward_mean: -208851.34969061072\n",
      "  episode_reward_min: -261963.46807071698\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 4344\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.181178092956543\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0006076385616324842\n",
      "          model: {}\n",
      "          policy_loss: 0.006034711841493845\n",
      "          total_loss: 10.005836486816406\n",
      "          vf_explained_var: -1.9868215517249155e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 4350912\n",
      "    num_agent_steps_trained: 4350912\n",
      "    num_env_steps_sampled: 4350912\n",
      "    num_env_steps_trained: 4350912\n",
      "  iterations_since_restore: 68\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 4350912\n",
      "  num_agent_steps_trained: 4350912\n",
      "  num_env_steps_sampled: 4350912\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 4350912\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.30833333333334\n",
      "    ram_util_percent: 92.125\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09584164656698997\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4726236727307216\n",
      "    mean_inference_ms: 0.9710843340878043\n",
      "    mean_raw_obs_processing_ms: 0.13579836528821407\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -202386.70511208934\n",
      "    episode_reward_mean: -208851.34969061072\n",
      "    episode_reward_min: -261963.46807071698\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -209576.5326359216\n",
      "      - -207050.0496442815\n",
      "      - -207991.59090671485\n",
      "      - -209479.35246541226\n",
      "      - -215639.8551689474\n",
      "      - -205566.750724944\n",
      "      - -209942.1318951882\n",
      "      - -205297.78947178076\n",
      "      - -203689.8268087902\n",
      "      - -214417.21249096235\n",
      "      - -209763.19259384676\n",
      "      - -206661.35334133517\n",
      "      - -208684.846432446\n",
      "      - -206599.06809480878\n",
      "      - -207279.59769462617\n",
      "      - -208463.80440423\n",
      "      - -205544.80921804527\n",
      "      - -212050.7861334749\n",
      "      - -209208.57091801698\n",
      "      - -208468.75628215566\n",
      "      - -209794.86365038302\n",
      "      - -210280.21368340417\n",
      "      - -213367.7287648428\n",
      "      - -206687.80836036027\n",
      "      - -208402.62655059018\n",
      "      - -208809.32884838997\n",
      "      - -208903.86137474515\n",
      "      - -205413.21756307088\n",
      "      - -207956.188928065\n",
      "      - -207912.7410827952\n",
      "      - -202868.49000850963\n",
      "      - -205019.17436068857\n",
      "      - -207105.81299347072\n",
      "      - -207463.03283266982\n",
      "      - -207199.92316368435\n",
      "      - -206549.56613139302\n",
      "      - -211072.12891568744\n",
      "      - -209070.43143810407\n",
      "      - -210528.20416756877\n",
      "      - -207447.5023118414\n",
      "      - -204692.26099962127\n",
      "      - -208257.32898005837\n",
      "      - -261963.46807071698\n",
      "      - -209704.07611979544\n",
      "      - -205050.05476109948\n",
      "      - -206814.66710390447\n",
      "      - -206843.67000774917\n",
      "      - -208838.7424179386\n",
      "      - -208716.3935125199\n",
      "      - -208254.03902149605\n",
      "      - -210534.42029434512\n",
      "      - -212519.12602231116\n",
      "      - -210535.40006880084\n",
      "      - -211577.69621154488\n",
      "      - -209407.8368676567\n",
      "      - -211295.9417819953\n",
      "      - -207357.8289835181\n",
      "      - -208840.00805381002\n",
      "      - -210052.62401049517\n",
      "      - -209475.39528749083\n",
      "      - -209180.03138366865\n",
      "      - -210210.735273429\n",
      "      - -205950.24368157645\n",
      "      - -207099.12089608997\n",
      "      - -204256.40536665008\n",
      "      - -211795.51324082853\n",
      "      - -205756.30641449083\n",
      "      - -216274.97596583533\n",
      "      - -210588.30477309413\n",
      "      - -203164.50218539385\n",
      "      - -212745.63231616517\n",
      "      - -212688.92096997777\n",
      "      - -205997.4163205679\n",
      "      - -203433.1729887438\n",
      "      - -207233.43823708026\n",
      "      - -204172.74314819992\n",
      "      - -204958.66602162377\n",
      "      - -203358.6677333858\n",
      "      - -206244.56903246528\n",
      "      - -208645.7607482851\n",
      "      - -205596.56677258716\n",
      "      - -208798.10050703582\n",
      "      - -207764.7918493812\n",
      "      - -202386.70511208934\n",
      "      - -213991.0633228989\n",
      "      - -207924.5153731526\n",
      "      - -207361.5698216628\n",
      "      - -210193.8285163382\n",
      "      - -203909.9355283541\n",
      "      - -211387.38015301613\n",
      "      - -212050.77704239867\n",
      "      - -204482.2634623998\n",
      "      - -207772.22714184734\n",
      "      - -209812.14686513893\n",
      "      - -210512.13997969497\n",
      "      - -206123.90730385517\n",
      "      - -207431.42652814413\n",
      "      - -213465.15479032334\n",
      "      - -204135.92141975657\n",
      "      - -212319.71984038255\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09584164656698997\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4726236727307216\n",
      "      mean_inference_ms: 0.9710843340878043\n",
      "      mean_raw_obs_processing_ms: 0.13579836528821407\n",
      "  time_since_restore: 655.2512397766113\n",
      "  time_this_iter_s: 8.941037893295288\n",
      "  time_total_s: 655.2512397766113\n",
      "  timers:\n",
      "    learn_throughput: 119588.28\n",
      "    learn_time_ms: 535.036\n",
      "    load_throughput: 18266290.984\n",
      "    load_time_ms: 3.503\n",
      "    training_iteration_time_ms: 9030.135\n",
      "    update_time_ms: 4.148\n",
      "  timestamp: 1665849400\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4350912\n",
      "  training_iteration: 68\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:56:45 (running for 00:11:20.03)<br>Memory usage on this node: 14.3/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    68</td><td style=\"text-align: right;\">         655.251</td><td style=\"text-align: right;\">4350912</td><td style=\"text-align: right;\"> -208851</td><td style=\"text-align: right;\">             -202387</td><td style=\"text-align: right;\">             -261963</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 4414896\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 4414896\n",
      "    num_agent_steps_trained: 4414896\n",
      "    num_env_steps_sampled: 4414896\n",
      "    num_env_steps_trained: 4414896\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-56-49\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -200032.17883427243\n",
      "  episode_reward_mean: -207273.98294155343\n",
      "  episode_reward_min: -216742.88772202234\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 4404\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.177366018295288\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0003693365433719009\n",
      "          model: {}\n",
      "          policy_loss: 0.0006331181502901018\n",
      "          total_loss: 10.000388145446777\n",
      "          vf_explained_var: -2.932926967957883e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 4414896\n",
      "    num_agent_steps_trained: 4414896\n",
      "    num_env_steps_sampled: 4414896\n",
      "    num_env_steps_trained: 4414896\n",
      "  iterations_since_restore: 69\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 4414896\n",
      "  num_agent_steps_trained: 4414896\n",
      "  num_env_steps_sampled: 4414896\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 4414896\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.38461538461539\n",
      "    ram_util_percent: 92.17692307692307\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09570746921223507\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.47269032098554803\n",
      "    mean_inference_ms: 0.9699220110280057\n",
      "    mean_raw_obs_processing_ms: 0.13560772997101597\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -200032.17883427243\n",
      "    episode_reward_mean: -207273.98294155343\n",
      "    episode_reward_min: -216742.88772202234\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -209180.03138366865\n",
      "      - -210210.735273429\n",
      "      - -205950.24368157645\n",
      "      - -207099.12089608997\n",
      "      - -204256.40536665008\n",
      "      - -211795.51324082853\n",
      "      - -205756.30641449083\n",
      "      - -216274.97596583533\n",
      "      - -210588.30477309413\n",
      "      - -203164.50218539385\n",
      "      - -212745.63231616517\n",
      "      - -212688.92096997777\n",
      "      - -205997.4163205679\n",
      "      - -203433.1729887438\n",
      "      - -207233.43823708026\n",
      "      - -204172.74314819992\n",
      "      - -204958.66602162377\n",
      "      - -203358.6677333858\n",
      "      - -206244.56903246528\n",
      "      - -208645.7607482851\n",
      "      - -205596.56677258716\n",
      "      - -208798.10050703582\n",
      "      - -207764.7918493812\n",
      "      - -202386.70511208934\n",
      "      - -213991.0633228989\n",
      "      - -207924.5153731526\n",
      "      - -207361.5698216628\n",
      "      - -210193.8285163382\n",
      "      - -203909.9355283541\n",
      "      - -211387.38015301613\n",
      "      - -212050.77704239867\n",
      "      - -204482.2634623998\n",
      "      - -207772.22714184734\n",
      "      - -209812.14686513893\n",
      "      - -210512.13997969497\n",
      "      - -206123.90730385517\n",
      "      - -207431.42652814413\n",
      "      - -213465.15479032334\n",
      "      - -204135.92141975657\n",
      "      - -212319.71984038255\n",
      "      - -205774.3060385686\n",
      "      - -210154.98506772716\n",
      "      - -206278.01592152772\n",
      "      - -211324.5562600858\n",
      "      - -202139.50912775003\n",
      "      - -201059.77146305027\n",
      "      - -206630.1545718758\n",
      "      - -209743.1320126944\n",
      "      - -204772.31118450704\n",
      "      - -207018.71490996666\n",
      "      - -205110.8450775705\n",
      "      - -206149.62671313994\n",
      "      - -207921.13785370358\n",
      "      - -204787.65709549584\n",
      "      - -202744.62921258315\n",
      "      - -208735.64527964988\n",
      "      - -205618.99452133675\n",
      "      - -206079.81547771138\n",
      "      - -207226.07830759604\n",
      "      - -209617.7925052806\n",
      "      - -200032.17883427243\n",
      "      - -206673.56214375538\n",
      "      - -209917.79142773268\n",
      "      - -207426.26465965688\n",
      "      - -206572.54574052713\n",
      "      - -211809.27945708053\n",
      "      - -206255.55790547538\n",
      "      - -205653.52579175076\n",
      "      - -206444.74373941196\n",
      "      - -205343.49711736303\n",
      "      - -207870.36093349665\n",
      "      - -206668.3427317596\n",
      "      - -208649.45492107\n",
      "      - -207770.9015818162\n",
      "      - -207639.9309102343\n",
      "      - -207668.04501229787\n",
      "      - -200477.65005922713\n",
      "      - -206842.37008842564\n",
      "      - -207119.21058840683\n",
      "      - -204462.7256479139\n",
      "      - -207482.86952316054\n",
      "      - -208198.23578390025\n",
      "      - -205603.5707160699\n",
      "      - -209679.97614936123\n",
      "      - -205823.67769263207\n",
      "      - -206047.2742627191\n",
      "      - -206124.28714927734\n",
      "      - -206857.14229819048\n",
      "      - -205667.05348406942\n",
      "      - -209668.1534150669\n",
      "      - -205195.78398138858\n",
      "      - -216742.88772202234\n",
      "      - -209110.82331501244\n",
      "      - -207060.11222615006\n",
      "      - -206663.258405943\n",
      "      - -207325.33280357256\n",
      "      - -205566.86268661876\n",
      "      - -204221.96944994517\n",
      "      - -206064.8414634537\n",
      "      - -206933.29570528184\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09570746921223507\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.47269032098554803\n",
      "      mean_inference_ms: 0.9699220110280057\n",
      "      mean_raw_obs_processing_ms: 0.13560772997101597\n",
      "  time_since_restore: 664.3095052242279\n",
      "  time_this_iter_s: 9.058265447616577\n",
      "  time_total_s: 664.3095052242279\n",
      "  timers:\n",
      "    learn_throughput: 120305.2\n",
      "    learn_time_ms: 531.847\n",
      "    load_throughput: 18346083.711\n",
      "    load_time_ms: 3.488\n",
      "    training_iteration_time_ms: 9019.17\n",
      "    update_time_ms: 4.105\n",
      "  timestamp: 1665849409\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4414896\n",
      "  training_iteration: 69\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:56:54 (running for 00:11:29.21)<br>Memory usage on this node: 14.3/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    69</td><td style=\"text-align: right;\">          664.31</td><td style=\"text-align: right;\">4414896</td><td style=\"text-align: right;\"> -207274</td><td style=\"text-align: right;\">             -200032</td><td style=\"text-align: right;\">             -216743</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 4478880\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 4478880\n",
      "    num_agent_steps_trained: 4478880\n",
      "    num_env_steps_sampled: 4478880\n",
      "    num_env_steps_trained: 4478880\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-56-59\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -200477.65005922713\n",
      "  episode_reward_mean: -207195.6106418372\n",
      "  episode_reward_min: -217519.04003644868\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 4476\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.167266368865967\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.000252281577559188\n",
      "          model: {}\n",
      "          policy_loss: 0.003830237779766321\n",
      "          total_loss: 10.003564834594727\n",
      "          vf_explained_var: -4.9197485196827984e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 4478880\n",
      "    num_agent_steps_trained: 4478880\n",
      "    num_env_steps_sampled: 4478880\n",
      "    num_env_steps_trained: 4478880\n",
      "  iterations_since_restore: 70\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 4478880\n",
      "  num_agent_steps_trained: 4478880\n",
      "  num_env_steps_sampled: 4478880\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 4478880\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 78.32307692307691\n",
      "    ram_util_percent: 92.25384615384615\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09573457863069994\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.47251504681227124\n",
      "    mean_inference_ms: 0.9693191839055916\n",
      "    mean_raw_obs_processing_ms: 0.1352360802833166\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -200477.65005922713\n",
      "    episode_reward_mean: -207195.6106418372\n",
      "    episode_reward_min: -217519.04003644868\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -208649.45492107\n",
      "      - -207770.9015818162\n",
      "      - -207639.9309102343\n",
      "      - -207668.04501229787\n",
      "      - -200477.65005922713\n",
      "      - -206842.37008842564\n",
      "      - -207119.21058840683\n",
      "      - -204462.7256479139\n",
      "      - -207482.86952316054\n",
      "      - -208198.23578390025\n",
      "      - -205603.5707160699\n",
      "      - -209679.97614936123\n",
      "      - -205823.67769263207\n",
      "      - -206047.2742627191\n",
      "      - -206124.28714927734\n",
      "      - -206857.14229819048\n",
      "      - -205667.05348406942\n",
      "      - -209668.1534150669\n",
      "      - -205195.78398138858\n",
      "      - -216742.88772202234\n",
      "      - -209110.82331501244\n",
      "      - -207060.11222615006\n",
      "      - -206663.258405943\n",
      "      - -207325.33280357256\n",
      "      - -205566.86268661876\n",
      "      - -204221.96944994517\n",
      "      - -206064.8414634537\n",
      "      - -206933.29570528184\n",
      "      - -207452.74573711702\n",
      "      - -203539.40134719544\n",
      "      - -215989.73291714603\n",
      "      - -205197.23950181084\n",
      "      - -204860.54763399367\n",
      "      - -208149.6991246476\n",
      "      - -208686.77630773597\n",
      "      - -207737.88465969134\n",
      "      - -205306.57695975652\n",
      "      - -205893.73873291578\n",
      "      - -207512.78442577677\n",
      "      - -211208.03781472542\n",
      "      - -209069.3530231575\n",
      "      - -206846.19339333483\n",
      "      - -207368.374488535\n",
      "      - -205266.14134142565\n",
      "      - -207239.51134903965\n",
      "      - -210662.00443616815\n",
      "      - -217519.04003644868\n",
      "      - -206653.82450686247\n",
      "      - -203598.48081204892\n",
      "      - -210158.13353156662\n",
      "      - -211436.72026779156\n",
      "      - -205907.62530800106\n",
      "      - -207051.23359937902\n",
      "      - -208708.07102145776\n",
      "      - -211311.08662220315\n",
      "      - -214162.6742258146\n",
      "      - -202868.37614289863\n",
      "      - -210263.83837293807\n",
      "      - -208775.4557787063\n",
      "      - -208017.348592043\n",
      "      - -207217.60880889965\n",
      "      - -206999.69311053655\n",
      "      - -206693.51964843154\n",
      "      - -200759.6988731997\n",
      "      - -203479.7670829479\n",
      "      - -208830.05878086525\n",
      "      - -209267.16185066802\n",
      "      - -201815.6101569082\n",
      "      - -206908.3169150734\n",
      "      - -203521.4613983056\n",
      "      - -204629.58989011895\n",
      "      - -208483.3969783508\n",
      "      - -203177.14255690447\n",
      "      - -204738.8098910093\n",
      "      - -206858.62327812295\n",
      "      - -208551.6299263055\n",
      "      - -204493.5695527896\n",
      "      - -207263.7058990197\n",
      "      - -204621.6442718745\n",
      "      - -204338.5569738566\n",
      "      - -213335.15171307733\n",
      "      - -202062.83912964532\n",
      "      - -205577.8858354026\n",
      "      - -214430.46603828768\n",
      "      - -206614.60521430557\n",
      "      - -206316.05969180627\n",
      "      - -210716.82474673013\n",
      "      - -208083.031364838\n",
      "      - -205528.07527186567\n",
      "      - -201625.12076593254\n",
      "      - -205307.86597481553\n",
      "      - -212980.27471050728\n",
      "      - -206030.68231569027\n",
      "      - -202262.14805219934\n",
      "      - -208361.89831110882\n",
      "      - -210603.08689045228\n",
      "      - -205797.8379563999\n",
      "      - -203659.90223203387\n",
      "      - -209477.0097009337\n",
      "      - -207054.38336794157\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09573457863069994\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.47251504681227124\n",
      "      mean_inference_ms: 0.9693191839055916\n",
      "      mean_raw_obs_processing_ms: 0.1352360802833166\n",
      "  time_since_restore: 673.7868490219116\n",
      "  time_this_iter_s: 9.477343797683716\n",
      "  time_total_s: 673.7868490219116\n",
      "  timers:\n",
      "    learn_throughput: 120866.515\n",
      "    learn_time_ms: 529.377\n",
      "    load_throughput: 18195697.819\n",
      "    load_time_ms: 3.516\n",
      "    training_iteration_time_ms: 9046.982\n",
      "    update_time_ms: 4.045\n",
      "  timestamp: 1665849419\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4478880\n",
      "  training_iteration: 70\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:57:04 (running for 00:11:38.72)<br>Memory usage on this node: 14.3/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    70</td><td style=\"text-align: right;\">         673.787</td><td style=\"text-align: right;\">4478880</td><td style=\"text-align: right;\"> -207196</td><td style=\"text-align: right;\">             -200478</td><td style=\"text-align: right;\">             -217519</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 4542864\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 4542864\n",
      "    num_agent_steps_trained: 4542864\n",
      "    num_env_steps_sampled: 4542864\n",
      "    num_env_steps_trained: 4542864\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-57-08\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -200716.73290927336\n",
      "  episode_reward_mean: -207211.7237501441\n",
      "  episode_reward_min: -239550.58016012295\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 4536\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1660404205322266\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0009987859521061182\n",
      "          model: {}\n",
      "          policy_loss: 0.005539108999073505\n",
      "          total_loss: 10.005422592163086\n",
      "          vf_explained_var: -1.9868215517249155e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 4542864\n",
      "    num_agent_steps_trained: 4542864\n",
      "    num_env_steps_sampled: 4542864\n",
      "    num_env_steps_trained: 4542864\n",
      "  iterations_since_restore: 71\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 4542864\n",
      "  num_agent_steps_trained: 4542864\n",
      "  num_env_steps_sampled: 4542864\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 4542864\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 80.73076923076923\n",
      "    ram_util_percent: 92.37692307692308\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09591669657740011\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.47215229570570627\n",
      "    mean_inference_ms: 0.969546798080566\n",
      "    mean_raw_obs_processing_ms: 0.135294787115912\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -200716.73290927336\n",
      "    episode_reward_mean: -207211.7237501441\n",
      "    episode_reward_min: -239550.58016012295\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -207217.60880889965\n",
      "      - -206999.69311053655\n",
      "      - -206693.51964843154\n",
      "      - -200759.6988731997\n",
      "      - -203479.7670829479\n",
      "      - -208830.05878086525\n",
      "      - -209267.16185066802\n",
      "      - -201815.6101569082\n",
      "      - -206908.3169150734\n",
      "      - -203521.4613983056\n",
      "      - -204629.58989011895\n",
      "      - -208483.3969783508\n",
      "      - -203177.14255690447\n",
      "      - -204738.8098910093\n",
      "      - -206858.62327812295\n",
      "      - -208551.6299263055\n",
      "      - -204493.5695527896\n",
      "      - -207263.7058990197\n",
      "      - -204621.6442718745\n",
      "      - -204338.5569738566\n",
      "      - -213335.15171307733\n",
      "      - -202062.83912964532\n",
      "      - -205577.8858354026\n",
      "      - -214430.46603828768\n",
      "      - -206614.60521430557\n",
      "      - -206316.05969180627\n",
      "      - -210716.82474673013\n",
      "      - -208083.031364838\n",
      "      - -205528.07527186567\n",
      "      - -201625.12076593254\n",
      "      - -205307.86597481553\n",
      "      - -212980.27471050728\n",
      "      - -206030.68231569027\n",
      "      - -202262.14805219934\n",
      "      - -208361.89831110882\n",
      "      - -210603.08689045228\n",
      "      - -205797.8379563999\n",
      "      - -203659.90223203387\n",
      "      - -209477.0097009337\n",
      "      - -207054.38336794157\n",
      "      - -206477.6683816935\n",
      "      - -204678.3601146042\n",
      "      - -204069.8528689078\n",
      "      - -200716.73290927336\n",
      "      - -239550.58016012295\n",
      "      - -210534.03062403758\n",
      "      - -207214.2240274729\n",
      "      - -204278.081738826\n",
      "      - -206509.24614053496\n",
      "      - -204736.38897310977\n",
      "      - -207696.66759416403\n",
      "      - -203774.21301618908\n",
      "      - -207108.1860219171\n",
      "      - -208329.28563351533\n",
      "      - -204714.53472939855\n",
      "      - -208350.01172965832\n",
      "      - -210056.69773294526\n",
      "      - -204067.3230581637\n",
      "      - -209009.826256437\n",
      "      - -207277.1723477156\n",
      "      - -207187.23672188606\n",
      "      - -208922.8451925209\n",
      "      - -204381.94059751736\n",
      "      - -202906.4630265234\n",
      "      - -209358.05586782563\n",
      "      - -206018.87064346438\n",
      "      - -213798.33275670177\n",
      "      - -209480.96071315193\n",
      "      - -205774.06140732788\n",
      "      - -213611.97196992455\n",
      "      - -205033.62102496353\n",
      "      - -206375.77687601413\n",
      "      - -204298.42724993135\n",
      "      - -237495.70201472528\n",
      "      - -203222.50607700544\n",
      "      - -200890.34018600624\n",
      "      - -202744.25135636763\n",
      "      - -206386.63505486297\n",
      "      - -204158.12148538037\n",
      "      - -205387.6081420041\n",
      "      - -209262.8526654342\n",
      "      - -206057.47099718702\n",
      "      - -207708.22482676676\n",
      "      - -209600.11322278346\n",
      "      - -206340.35251813935\n",
      "      - -205180.91089192728\n",
      "      - -205371.14932926025\n",
      "      - -207918.8582799595\n",
      "      - -210021.03954656806\n",
      "      - -205433.42176245572\n",
      "      - -208979.62161621382\n",
      "      - -205874.81259328627\n",
      "      - -206864.40306081975\n",
      "      - -205973.090886074\n",
      "      - -207062.8601012484\n",
      "      - -205773.95049572366\n",
      "      - -205928.30764945943\n",
      "      - -212137.37275498928\n",
      "      - -206911.05351387803\n",
      "      - -207714.9807512788\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09591669657740011\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.47215229570570627\n",
      "      mean_inference_ms: 0.969546798080566\n",
      "      mean_raw_obs_processing_ms: 0.135294787115912\n",
      "  time_since_restore: 683.431960105896\n",
      "  time_this_iter_s: 9.645111083984375\n",
      "  time_total_s: 683.431960105896\n",
      "  timers:\n",
      "    learn_throughput: 128979.18\n",
      "    learn_time_ms: 496.08\n",
      "    load_throughput: 18238483.875\n",
      "    load_time_ms: 3.508\n",
      "    training_iteration_time_ms: 9109.183\n",
      "    update_time_ms: 3.967\n",
      "  timestamp: 1665849428\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4542864\n",
      "  training_iteration: 71\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:57:13 (running for 00:11:48.31)<br>Memory usage on this node: 14.3/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    71</td><td style=\"text-align: right;\">         683.432</td><td style=\"text-align: right;\">4542864</td><td style=\"text-align: right;\"> -207212</td><td style=\"text-align: right;\">             -200717</td><td style=\"text-align: right;\">             -239551</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 4606848\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 4606848\n",
      "    num_agent_steps_trained: 4606848\n",
      "    num_env_steps_sampled: 4606848\n",
      "    num_env_steps_trained: 4606848\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-57-18\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -200890.34018600624\n",
      "  episode_reward_mean: -207005.36654379603\n",
      "  episode_reward_min: -237495.70201472528\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 4596\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.164699077606201\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.000467446050606668\n",
      "          model: {}\n",
      "          policy_loss: 0.0008386489353142679\n",
      "          total_loss: 10.000615119934082\n",
      "          vf_explained_var: -1.6083793852317285e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 4606848\n",
      "    num_agent_steps_trained: 4606848\n",
      "    num_env_steps_sampled: 4606848\n",
      "    num_env_steps_trained: 4606848\n",
      "  iterations_since_restore: 72\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 4606848\n",
      "  num_agent_steps_trained: 4606848\n",
      "  num_env_steps_sampled: 4606848\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 4606848\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.71538461538461\n",
      "    ram_util_percent: 92.36153846153846\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09570555097086972\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4721104604309889\n",
      "    mean_inference_ms: 0.9696563904507011\n",
      "    mean_raw_obs_processing_ms: 0.1351501169858901\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -200890.34018600624\n",
      "    episode_reward_mean: -207005.36654379603\n",
      "    episode_reward_min: -237495.70201472528\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -207187.23672188606\n",
      "      - -208922.8451925209\n",
      "      - -204381.94059751736\n",
      "      - -202906.4630265234\n",
      "      - -209358.05586782563\n",
      "      - -206018.87064346438\n",
      "      - -213798.33275670177\n",
      "      - -209480.96071315193\n",
      "      - -205774.06140732788\n",
      "      - -213611.97196992455\n",
      "      - -205033.62102496353\n",
      "      - -206375.77687601413\n",
      "      - -204298.42724993135\n",
      "      - -237495.70201472528\n",
      "      - -203222.50607700544\n",
      "      - -200890.34018600624\n",
      "      - -202744.25135636763\n",
      "      - -206386.63505486297\n",
      "      - -204158.12148538037\n",
      "      - -205387.6081420041\n",
      "      - -209262.8526654342\n",
      "      - -206057.47099718702\n",
      "      - -207708.22482676676\n",
      "      - -209600.11322278346\n",
      "      - -206340.35251813935\n",
      "      - -205180.91089192728\n",
      "      - -205371.14932926025\n",
      "      - -207918.8582799595\n",
      "      - -210021.03954656806\n",
      "      - -205433.42176245572\n",
      "      - -208979.62161621382\n",
      "      - -205874.81259328627\n",
      "      - -206864.40306081975\n",
      "      - -205973.090886074\n",
      "      - -207062.8601012484\n",
      "      - -205773.95049572366\n",
      "      - -205928.30764945943\n",
      "      - -212137.37275498928\n",
      "      - -206911.05351387803\n",
      "      - -207714.9807512788\n",
      "      - -203770.3727894231\n",
      "      - -208300.1132597488\n",
      "      - -207163.18956815798\n",
      "      - -205880.9680826737\n",
      "      - -206116.886999463\n",
      "      - -205933.91078775242\n",
      "      - -205555.82483749615\n",
      "      - -208705.96654167876\n",
      "      - -202786.09932352867\n",
      "      - -209248.48672262943\n",
      "      - -205660.55003629686\n",
      "      - -213251.56287860638\n",
      "      - -207842.17389806645\n",
      "      - -206108.7786631136\n",
      "      - -207141.2481430611\n",
      "      - -209387.68028810696\n",
      "      - -205273.58270543837\n",
      "      - -208682.34556432118\n",
      "      - -206595.52502155892\n",
      "      - -205654.00692888992\n",
      "      - -207664.4262531362\n",
      "      - -203893.53691702214\n",
      "      - -202899.45519597534\n",
      "      - -210533.57349299232\n",
      "      - -206247.79091081448\n",
      "      - -203696.20516024274\n",
      "      - -211552.27508843545\n",
      "      - -212854.16256442727\n",
      "      - -211392.83230677285\n",
      "      - -207514.88017444196\n",
      "      - -205709.5034631206\n",
      "      - -210909.58333914826\n",
      "      - -203332.3509693191\n",
      "      - -205865.01101489534\n",
      "      - -204833.81086664333\n",
      "      - -206419.7160699609\n",
      "      - -207790.3856533989\n",
      "      - -205476.78219194664\n",
      "      - -209823.62258703462\n",
      "      - -204329.64909622612\n",
      "      - -200998.0218255995\n",
      "      - -204703.44952693104\n",
      "      - -208171.9023599637\n",
      "      - -207108.36187604684\n",
      "      - -206235.8751827563\n",
      "      - -202991.18883585098\n",
      "      - -206375.85568970235\n",
      "      - -205023.7799516157\n",
      "      - -207404.35113107387\n",
      "      - -203219.01577950505\n",
      "      - -204825.00218083395\n",
      "      - -203829.65830160788\n",
      "      - -206261.34751504258\n",
      "      - -205889.2852610621\n",
      "      - -207857.0294422917\n",
      "      - -210740.7170320938\n",
      "      - -204567.23657899618\n",
      "      - -209188.40948018787\n",
      "      - -205674.64733698263\n",
      "      - -204124.11690793574\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09570555097086972\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4721104604309889\n",
      "      mean_inference_ms: 0.9696563904507011\n",
      "      mean_raw_obs_processing_ms: 0.1351501169858901\n",
      "  time_since_restore: 692.7256433963776\n",
      "  time_this_iter_s: 9.293683290481567\n",
      "  time_total_s: 692.7256433963776\n",
      "  timers:\n",
      "    learn_throughput: 130488.834\n",
      "    learn_time_ms: 490.341\n",
      "    load_throughput: 18231669.178\n",
      "    load_time_ms: 3.509\n",
      "    training_iteration_time_ms: 9187.442\n",
      "    update_time_ms: 4.001\n",
      "  timestamp: 1665849438\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4606848\n",
      "  training_iteration: 72\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:57:23 (running for 00:11:57.73)<br>Memory usage on this node: 14.3/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    72</td><td style=\"text-align: right;\">         692.726</td><td style=\"text-align: right;\">4606848</td><td style=\"text-align: right;\"> -207005</td><td style=\"text-align: right;\">             -200890</td><td style=\"text-align: right;\">             -237496</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 4670832\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 4670832\n",
      "    num_agent_steps_trained: 4670832\n",
      "    num_env_steps_sampled: 4670832\n",
      "    num_env_steps_trained: 4670832\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-57-28\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -200638.00236882488\n",
      "  episode_reward_mean: -207485.6411149632\n",
      "  episode_reward_min: -258609.28478549703\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 4668\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.165470838546753\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0009907885687425733\n",
      "          model: {}\n",
      "          policy_loss: 0.003714491380378604\n",
      "          total_loss: 10.003595352172852\n",
      "          vf_explained_var: -2.0814320933482122e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 4670832\n",
      "    num_agent_steps_trained: 4670832\n",
      "    num_env_steps_sampled: 4670832\n",
      "    num_env_steps_trained: 4670832\n",
      "  iterations_since_restore: 73\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 4670832\n",
      "  num_agent_steps_trained: 4670832\n",
      "  num_env_steps_sampled: 4670832\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 4670832\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.28\n",
      "    ram_util_percent: 90.74000000000001\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0956890642818806\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.47198353723098685\n",
      "    mean_inference_ms: 0.9703829102364472\n",
      "    mean_raw_obs_processing_ms: 0.13504116219795992\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -200638.00236882488\n",
      "    episode_reward_mean: -207485.6411149632\n",
      "    episode_reward_min: -258609.28478549703\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -203332.3509693191\n",
      "      - -205865.01101489534\n",
      "      - -204833.81086664333\n",
      "      - -206419.7160699609\n",
      "      - -207790.3856533989\n",
      "      - -205476.78219194664\n",
      "      - -209823.62258703462\n",
      "      - -204329.64909622612\n",
      "      - -200998.0218255995\n",
      "      - -204703.44952693104\n",
      "      - -208171.9023599637\n",
      "      - -207108.36187604684\n",
      "      - -206235.8751827563\n",
      "      - -202991.18883585098\n",
      "      - -206375.85568970235\n",
      "      - -205023.7799516157\n",
      "      - -207404.35113107387\n",
      "      - -203219.01577950505\n",
      "      - -204825.00218083395\n",
      "      - -203829.65830160788\n",
      "      - -206261.34751504258\n",
      "      - -205889.2852610621\n",
      "      - -207857.0294422917\n",
      "      - -210740.7170320938\n",
      "      - -204567.23657899618\n",
      "      - -209188.40948018787\n",
      "      - -205674.64733698263\n",
      "      - -204124.11690793574\n",
      "      - -206815.9130801974\n",
      "      - -205202.52837631814\n",
      "      - -210465.71189794323\n",
      "      - -208071.74330176707\n",
      "      - -202416.377734263\n",
      "      - -206360.81836488112\n",
      "      - -202305.62666921125\n",
      "      - -204813.4647574908\n",
      "      - -206487.95124798117\n",
      "      - -203299.66022729868\n",
      "      - -206818.66478798812\n",
      "      - -206477.60554779397\n",
      "      - -203338.374271818\n",
      "      - -206040.84783040034\n",
      "      - -209512.58928114065\n",
      "      - -208790.37969483278\n",
      "      - -206716.7794853589\n",
      "      - -200638.00236882488\n",
      "      - -204944.23475969848\n",
      "      - -209611.95581165468\n",
      "      - -210964.30607153816\n",
      "      - -203381.62775282998\n",
      "      - -206203.91214017986\n",
      "      - -206429.39427874488\n",
      "      - -205423.7907978512\n",
      "      - -205368.74223558503\n",
      "      - -211586.57037225468\n",
      "      - -208044.4394319114\n",
      "      - -203915.79302573987\n",
      "      - -205168.31682175325\n",
      "      - -204319.43950968684\n",
      "      - -205251.3809275304\n",
      "      - -207787.86372134328\n",
      "      - -205722.59859003194\n",
      "      - -205532.51580554625\n",
      "      - -205687.59507575707\n",
      "      - -204960.4689073726\n",
      "      - -205412.1770793586\n",
      "      - -204289.36211151685\n",
      "      - -207213.9180859687\n",
      "      - -203849.9836739323\n",
      "      - -210583.8539153555\n",
      "      - -206164.36565213354\n",
      "      - -209443.98010476807\n",
      "      - -207317.66841715606\n",
      "      - -207248.40669142932\n",
      "      - -205171.7950431166\n",
      "      - -204624.30156485614\n",
      "      - -202965.20966596855\n",
      "      - -209190.47806637894\n",
      "      - -258609.28478549703\n",
      "      - -202987.92742166328\n",
      "      - -210655.62001893425\n",
      "      - -208250.56234635966\n",
      "      - -207721.0224942445\n",
      "      - -204286.0625812723\n",
      "      - -206524.21331676436\n",
      "      - -245151.7944397746\n",
      "      - -207229.72641916774\n",
      "      - -213101.47042605304\n",
      "      - -208637.0498966183\n",
      "      - -207436.63335133635\n",
      "      - -205646.44110017887\n",
      "      - -229355.24343377398\n",
      "      - -209546.7442417051\n",
      "      - -208110.5805783322\n",
      "      - -208323.1778329137\n",
      "      - -203093.53959540275\n",
      "      - -211347.50339656844\n",
      "      - -208126.69301381233\n",
      "      - -204620.04864588112\n",
      "      - -208388.7064801048\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.0956890642818806\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.47198353723098685\n",
      "      mean_inference_ms: 0.9703829102364472\n",
      "      mean_raw_obs_processing_ms: 0.13504116219795992\n",
      "  time_since_restore: 702.9235556125641\n",
      "  time_this_iter_s: 10.197912216186523\n",
      "  time_total_s: 702.9235556125641\n",
      "  timers:\n",
      "    learn_throughput: 129836.356\n",
      "    learn_time_ms: 492.805\n",
      "    load_throughput: 18211255.608\n",
      "    load_time_ms: 3.513\n",
      "    training_iteration_time_ms: 9315.196\n",
      "    update_time_ms: 4.055\n",
      "  timestamp: 1665849448\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4670832\n",
      "  training_iteration: 73\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:57:28 (running for 00:12:02.96)<br>Memory usage on this node: 13.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    73</td><td style=\"text-align: right;\">         702.924</td><td style=\"text-align: right;\">4670832</td><td style=\"text-align: right;\"> -207486</td><td style=\"text-align: right;\">             -200638</td><td style=\"text-align: right;\">             -258609</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:57:33 (running for 00:12:07.97)<br>Memory usage on this node: 13.4/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    73</td><td style=\"text-align: right;\">         702.924</td><td style=\"text-align: right;\">4670832</td><td style=\"text-align: right;\"> -207486</td><td style=\"text-align: right;\">             -200638</td><td style=\"text-align: right;\">             -258609</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 4734816\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 4734816\n",
      "    num_agent_steps_trained: 4734816\n",
      "    num_env_steps_sampled: 4734816\n",
      "    num_env_steps_trained: 4734816\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-57-38\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -200882.7375880243\n",
      "  episode_reward_mean: -207635.96542270127\n",
      "  episode_reward_min: -258609.28478549703\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 4728\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.161393642425537\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00030503064044751227\n",
      "          model: {}\n",
      "          policy_loss: 0.0064501045271754265\n",
      "          total_loss: 10.006194114685059\n",
      "          vf_explained_var: -2.2706531765948057e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 4734816\n",
      "    num_agent_steps_trained: 4734816\n",
      "    num_env_steps_sampled: 4734816\n",
      "    num_env_steps_trained: 4734816\n",
      "  iterations_since_restore: 74\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 4734816\n",
      "  num_agent_steps_trained: 4734816\n",
      "  num_env_steps_sampled: 4734816\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 4734816\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.82142857142857\n",
      "    ram_util_percent: 86.96428571428571\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09585221202866219\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4721117078435089\n",
      "    mean_inference_ms: 0.970902163694802\n",
      "    mean_raw_obs_processing_ms: 0.1353245980437355\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -200882.7375880243\n",
      "    episode_reward_mean: -207635.96542270127\n",
      "    episode_reward_min: -258609.28478549703\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -207787.86372134328\n",
      "      - -205722.59859003194\n",
      "      - -205532.51580554625\n",
      "      - -205687.59507575707\n",
      "      - -204960.4689073726\n",
      "      - -205412.1770793586\n",
      "      - -204289.36211151685\n",
      "      - -207213.9180859687\n",
      "      - -203849.9836739323\n",
      "      - -210583.8539153555\n",
      "      - -206164.36565213354\n",
      "      - -209443.98010476807\n",
      "      - -207317.66841715606\n",
      "      - -207248.40669142932\n",
      "      - -205171.7950431166\n",
      "      - -204624.30156485614\n",
      "      - -202965.20966596855\n",
      "      - -209190.47806637894\n",
      "      - -258609.28478549703\n",
      "      - -202987.92742166328\n",
      "      - -210655.62001893425\n",
      "      - -208250.56234635966\n",
      "      - -207721.0224942445\n",
      "      - -204286.0625812723\n",
      "      - -206524.21331676436\n",
      "      - -245151.7944397746\n",
      "      - -207229.72641916774\n",
      "      - -213101.47042605304\n",
      "      - -208637.0498966183\n",
      "      - -207436.63335133635\n",
      "      - -205646.44110017887\n",
      "      - -229355.24343377398\n",
      "      - -209546.7442417051\n",
      "      - -208110.5805783322\n",
      "      - -208323.1778329137\n",
      "      - -203093.53959540275\n",
      "      - -211347.50339656844\n",
      "      - -208126.69301381233\n",
      "      - -204620.04864588112\n",
      "      - -208388.7064801048\n",
      "      - -202248.47442342408\n",
      "      - -203820.41253122603\n",
      "      - -203353.9930216981\n",
      "      - -203733.58924120144\n",
      "      - -202019.49671017568\n",
      "      - -204556.6208887752\n",
      "      - -207829.62659698198\n",
      "      - -204311.91561734752\n",
      "      - -207235.47262440817\n",
      "      - -206866.84518268172\n",
      "      - -203541.28550644466\n",
      "      - -204752.52855022482\n",
      "      - -206251.26465492832\n",
      "      - -206552.42351647356\n",
      "      - -201851.4055196477\n",
      "      - -203733.1566316282\n",
      "      - -209360.4506598729\n",
      "      - -204718.80705736764\n",
      "      - -208687.44980251798\n",
      "      - -205193.01152765274\n",
      "      - -229090.214801925\n",
      "      - -210095.3973723067\n",
      "      - -203869.8176725213\n",
      "      - -207128.05923438258\n",
      "      - -205345.33432604154\n",
      "      - -205037.43053461757\n",
      "      - -205588.2976367664\n",
      "      - -206863.1152670543\n",
      "      - -206549.0262570503\n",
      "      - -205658.64265187655\n",
      "      - -201741.01331627625\n",
      "      - -204927.54298991285\n",
      "      - -203627.40444739332\n",
      "      - -208744.0774073168\n",
      "      - -208296.38034493625\n",
      "      - -206858.67404470735\n",
      "      - -206154.49377454584\n",
      "      - -204892.83692033964\n",
      "      - -201636.0232541909\n",
      "      - -202248.73733725725\n",
      "      - -205670.92747526773\n",
      "      - -206144.47728449802\n",
      "      - -206231.61939805283\n",
      "      - -205666.54492906737\n",
      "      - -200882.7375880243\n",
      "      - -235087.1008320407\n",
      "      - -212055.04723877672\n",
      "      - -205418.73997012016\n",
      "      - -205994.3436357235\n",
      "      - -204920.89933857968\n",
      "      - -206990.8208226601\n",
      "      - -209940.15792651012\n",
      "      - -201857.97035349818\n",
      "      - -201543.32836271025\n",
      "      - -203034.0336047279\n",
      "      - -208408.06596605227\n",
      "      - -203642.45276963257\n",
      "      - -202237.75626060652\n",
      "      - -202913.1289715242\n",
      "      - -209669.05169760692\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09585221202866219\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4721117078435089\n",
      "      mean_inference_ms: 0.970902163694802\n",
      "      mean_raw_obs_processing_ms: 0.1353245980437355\n",
      "  time_since_restore: 712.8482565879822\n",
      "  time_this_iter_s: 9.92470097541809\n",
      "  time_total_s: 712.8482565879822\n",
      "  timers:\n",
      "    learn_throughput: 129522.916\n",
      "    learn_time_ms: 493.998\n",
      "    load_throughput: 18312408.539\n",
      "    load_time_ms: 3.494\n",
      "    training_iteration_time_ms: 9396.112\n",
      "    update_time_ms: 4.056\n",
      "  timestamp: 1665849458\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4734816\n",
      "  training_iteration: 74\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:57:43 (running for 00:12:17.91)<br>Memory usage on this node: 13.4/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    74</td><td style=\"text-align: right;\">         712.848</td><td style=\"text-align: right;\">4734816</td><td style=\"text-align: right;\"> -207636</td><td style=\"text-align: right;\">             -200883</td><td style=\"text-align: right;\">             -258609</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 4798800\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 4798800\n",
      "    num_agent_steps_trained: 4798800\n",
      "    num_env_steps_sampled: 4798800\n",
      "    num_env_steps_trained: 4798800\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-57-47\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -200682.21756853638\n",
      "  episode_reward_mean: -206594.06918572477\n",
      "  episode_reward_min: -235087.1008320407\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 4788\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.162649154663086\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00043813063530251384\n",
      "          model: {}\n",
      "          policy_loss: 0.0012696778867393732\n",
      "          total_loss: 10.0010404586792\n",
      "          vf_explained_var: -3.7844220202032375e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 4798800\n",
      "    num_agent_steps_trained: 4798800\n",
      "    num_env_steps_sampled: 4798800\n",
      "    num_env_steps_trained: 4798800\n",
      "  iterations_since_restore: 75\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 4798800\n",
      "  num_agent_steps_trained: 4798800\n",
      "  num_env_steps_sampled: 4798800\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 4798800\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.45384615384616\n",
      "    ram_util_percent: 86.6923076923077\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09574746649640455\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.47245832194248805\n",
      "    mean_inference_ms: 0.9709536810260693\n",
      "    mean_raw_obs_processing_ms: 0.13531320592813484\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -200682.21756853638\n",
      "    episode_reward_mean: -206594.06918572477\n",
      "    episode_reward_min: -235087.1008320407\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -229090.214801925\n",
      "      - -210095.3973723067\n",
      "      - -203869.8176725213\n",
      "      - -207128.05923438258\n",
      "      - -205345.33432604154\n",
      "      - -205037.43053461757\n",
      "      - -205588.2976367664\n",
      "      - -206863.1152670543\n",
      "      - -206549.0262570503\n",
      "      - -205658.64265187655\n",
      "      - -201741.01331627625\n",
      "      - -204927.54298991285\n",
      "      - -203627.40444739332\n",
      "      - -208744.0774073168\n",
      "      - -208296.38034493625\n",
      "      - -206858.67404470735\n",
      "      - -206154.49377454584\n",
      "      - -204892.83692033964\n",
      "      - -201636.0232541909\n",
      "      - -202248.73733725725\n",
      "      - -205670.92747526773\n",
      "      - -206144.47728449802\n",
      "      - -206231.61939805283\n",
      "      - -205666.54492906737\n",
      "      - -200882.7375880243\n",
      "      - -235087.1008320407\n",
      "      - -212055.04723877672\n",
      "      - -205418.73997012016\n",
      "      - -205994.3436357235\n",
      "      - -204920.89933857968\n",
      "      - -206990.8208226601\n",
      "      - -209940.15792651012\n",
      "      - -201857.97035349818\n",
      "      - -201543.32836271025\n",
      "      - -203034.0336047279\n",
      "      - -208408.06596605227\n",
      "      - -203642.45276963257\n",
      "      - -202237.75626060652\n",
      "      - -202913.1289715242\n",
      "      - -209669.05169760692\n",
      "      - -213318.80336516112\n",
      "      - -200753.69353638226\n",
      "      - -205535.32014970583\n",
      "      - -207483.94931382002\n",
      "      - -203443.28170671215\n",
      "      - -206457.9297799567\n",
      "      - -207122.90935012346\n",
      "      - -203693.50880088564\n",
      "      - -207020.191879698\n",
      "      - -205032.97064915914\n",
      "      - -213695.19195181353\n",
      "      - -204665.38247029125\n",
      "      - -209499.35379689472\n",
      "      - -201232.84875557024\n",
      "      - -209409.0898110608\n",
      "      - -205749.79790939816\n",
      "      - -209929.83676093552\n",
      "      - -211259.40539988168\n",
      "      - -200682.21756853638\n",
      "      - -209214.92274671592\n",
      "      - -210612.39460157495\n",
      "      - -205514.92987208033\n",
      "      - -211816.56707666878\n",
      "      - -205332.96877903413\n",
      "      - -208714.12199409129\n",
      "      - -207926.45281823073\n",
      "      - -208660.88790194152\n",
      "      - -204461.0388583406\n",
      "      - -212125.03443056825\n",
      "      - -205552.07007140928\n",
      "      - -204674.79224092033\n",
      "      - -213309.71978729917\n",
      "      - -204986.68882453837\n",
      "      - -204781.99548829012\n",
      "      - -203672.94133299915\n",
      "      - -207669.5306059374\n",
      "      - -200730.69363219664\n",
      "      - -206802.44953434818\n",
      "      - -203768.0241302432\n",
      "      - -208447.88729589086\n",
      "      - -209132.8328166551\n",
      "      - -204000.26041601493\n",
      "      - -204820.50857370574\n",
      "      - -206517.99260255173\n",
      "      - -201265.8204138336\n",
      "      - -202888.57779609173\n",
      "      - -205438.0044511156\n",
      "      - -204958.73169766934\n",
      "      - -204554.7342459182\n",
      "      - -205039.04255373465\n",
      "      - -206691.72468504985\n",
      "      - -203367.822376142\n",
      "      - -204428.66955343558\n",
      "      - -203394.3698036937\n",
      "      - -208875.1133074352\n",
      "      - -209245.51743183317\n",
      "      - -206111.76603111048\n",
      "      - -210735.5474614747\n",
      "      - -204511.3493051041\n",
      "      - -206005.01405351036\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09574746649640455\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.47245832194248805\n",
      "      mean_inference_ms: 0.9709536810260693\n",
      "      mean_raw_obs_processing_ms: 0.13531320592813484\n",
      "  time_since_restore: 722.356119632721\n",
      "  time_this_iter_s: 9.50786304473877\n",
      "  time_total_s: 722.356119632721\n",
      "  timers:\n",
      "    learn_throughput: 129170.61\n",
      "    learn_time_ms: 495.345\n",
      "    load_throughput: 18272260.685\n",
      "    load_time_ms: 3.502\n",
      "    training_iteration_time_ms: 9423.299\n",
      "    update_time_ms: 4.178\n",
      "  timestamp: 1665849467\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4798800\n",
      "  training_iteration: 75\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:57:52 (running for 00:12:27.37)<br>Memory usage on this node: 13.4/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    75</td><td style=\"text-align: right;\">         722.356</td><td style=\"text-align: right;\">4798800</td><td style=\"text-align: right;\"> -206594</td><td style=\"text-align: right;\">             -200682</td><td style=\"text-align: right;\">             -235087</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 4862784\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 4862784\n",
      "    num_agent_steps_trained: 4862784\n",
      "    num_env_steps_sampled: 4862784\n",
      "    num_env_steps_trained: 4862784\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-57-57\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -199052.90785792537\n",
      "  episode_reward_mean: -205236.9559650635\n",
      "  episode_reward_min: -211823.29987861638\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 4860\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1603899002075195\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.000551213335711509\n",
      "          model: {}\n",
      "          policy_loss: 0.0035223939921706915\n",
      "          total_loss: 10.003315925598145\n",
      "          vf_explained_var: -2.554484801464696e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 4862784\n",
      "    num_agent_steps_trained: 4862784\n",
      "    num_env_steps_sampled: 4862784\n",
      "    num_env_steps_trained: 4862784\n",
      "  iterations_since_restore: 76\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 4862784\n",
      "  num_agent_steps_trained: 4862784\n",
      "  num_env_steps_sampled: 4862784\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 4862784\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.02307692307691\n",
      "    ram_util_percent: 86.77692307692307\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09566093631194851\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.47201745015169905\n",
      "    mean_inference_ms: 0.9701723189948166\n",
      "    mean_raw_obs_processing_ms: 0.13511477499391805\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -199052.90785792537\n",
      "    episode_reward_mean: -205236.9559650635\n",
      "    episode_reward_min: -211823.29987861638\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -204986.68882453837\n",
      "      - -204781.99548829012\n",
      "      - -203672.94133299915\n",
      "      - -207669.5306059374\n",
      "      - -200730.69363219664\n",
      "      - -206802.44953434818\n",
      "      - -203768.0241302432\n",
      "      - -208447.88729589086\n",
      "      - -209132.8328166551\n",
      "      - -204000.26041601493\n",
      "      - -204820.50857370574\n",
      "      - -206517.99260255173\n",
      "      - -201265.8204138336\n",
      "      - -202888.57779609173\n",
      "      - -205438.0044511156\n",
      "      - -204958.73169766934\n",
      "      - -204554.7342459182\n",
      "      - -205039.04255373465\n",
      "      - -206691.72468504985\n",
      "      - -203367.822376142\n",
      "      - -204428.66955343558\n",
      "      - -203394.3698036937\n",
      "      - -208875.1133074352\n",
      "      - -209245.51743183317\n",
      "      - -206111.76603111048\n",
      "      - -210735.5474614747\n",
      "      - -204511.3493051041\n",
      "      - -206005.01405351036\n",
      "      - -203893.64486329898\n",
      "      - -204349.39934573392\n",
      "      - -206331.93442470857\n",
      "      - -201664.00592252833\n",
      "      - -207396.60854546237\n",
      "      - -203263.9576762574\n",
      "      - -205081.01769720102\n",
      "      - -204405.14853309508\n",
      "      - -205936.96563428873\n",
      "      - -205829.8452317114\n",
      "      - -206900.0161420483\n",
      "      - -206916.42388991895\n",
      "      - -205653.57975388537\n",
      "      - -199052.90785792537\n",
      "      - -205771.35948545556\n",
      "      - -203914.54192731943\n",
      "      - -202482.36800363287\n",
      "      - -202834.9832607824\n",
      "      - -207032.4269151856\n",
      "      - -205350.2765017939\n",
      "      - -206409.57519345096\n",
      "      - -207083.6291235923\n",
      "      - -205311.3460601337\n",
      "      - -204559.51992660118\n",
      "      - -206520.19386198526\n",
      "      - -204877.52890933378\n",
      "      - -204819.54117481847\n",
      "      - -203340.07392250578\n",
      "      - -207636.26363887967\n",
      "      - -204360.38248785006\n",
      "      - -206367.6024293929\n",
      "      - -203457.15468126323\n",
      "      - -210183.78172405832\n",
      "      - -208564.98293144963\n",
      "      - -204227.73164620306\n",
      "      - -203112.46889262385\n",
      "      - -199667.93160365822\n",
      "      - -205203.63940054632\n",
      "      - -204636.24265127318\n",
      "      - -203466.55986576132\n",
      "      - -202798.4387976498\n",
      "      - -204777.0712362072\n",
      "      - -203574.98667434123\n",
      "      - -207819.4704456461\n",
      "      - -206296.62412690185\n",
      "      - -205024.12256413072\n",
      "      - -202993.49253819117\n",
      "      - -210860.9598753877\n",
      "      - -202776.64375905442\n",
      "      - -207180.77966902222\n",
      "      - -206485.17743409096\n",
      "      - -211823.29987861638\n",
      "      - -203507.11332325006\n",
      "      - -202579.3076013272\n",
      "      - -205517.86369255607\n",
      "      - -204091.77440524357\n",
      "      - -205267.58639350676\n",
      "      - -205944.59938550054\n",
      "      - -204333.61592460284\n",
      "      - -204356.61035449454\n",
      "      - -205359.69411998073\n",
      "      - -205535.8206940136\n",
      "      - -206146.36237158414\n",
      "      - -201234.9561559908\n",
      "      - -203584.18681745007\n",
      "      - -205773.72323044564\n",
      "      - -206036.08661061648\n",
      "      - -206126.25554919962\n",
      "      - -207955.0683363022\n",
      "      - -205129.638769231\n",
      "      - -205068.93638434517\n",
      "      - -207024.15722932995\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09566093631194851\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.47201745015169905\n",
      "      mean_inference_ms: 0.9701723189948166\n",
      "      mean_raw_obs_processing_ms: 0.13511477499391805\n",
      "  time_since_restore: 731.7334172725677\n",
      "  time_this_iter_s: 9.377297639846802\n",
      "  time_total_s: 731.7334172725677\n",
      "  timers:\n",
      "    learn_throughput: 119310.227\n",
      "    learn_time_ms: 536.283\n",
      "    load_throughput: 18233774.995\n",
      "    load_time_ms: 3.509\n",
      "    training_iteration_time_ms: 9462.776\n",
      "    update_time_ms: 4.213\n",
      "  timestamp: 1665849477\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4862784\n",
      "  training_iteration: 76\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:58:02 (running for 00:12:36.88)<br>Memory usage on this node: 13.4/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    76</td><td style=\"text-align: right;\">         731.733</td><td style=\"text-align: right;\">4862784</td><td style=\"text-align: right;\"> -205237</td><td style=\"text-align: right;\">             -199053</td><td style=\"text-align: right;\">             -211823</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 4926768\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 4926768\n",
      "    num_agent_steps_trained: 4926768\n",
      "    num_env_steps_sampled: 4926768\n",
      "    num_env_steps_trained: 4926768\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-58-06\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -199606.1946573924\n",
      "  episode_reward_mean: -205468.31264879394\n",
      "  episode_reward_min: -228340.49620741204\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 4920\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.15058970451355\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0009552846313454211\n",
      "          model: {}\n",
      "          policy_loss: 0.006461989600211382\n",
      "          total_loss: 10.006338119506836\n",
      "          vf_explained_var: -3.311369312086754e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 4926768\n",
      "    num_agent_steps_trained: 4926768\n",
      "    num_env_steps_sampled: 4926768\n",
      "    num_env_steps_trained: 4926768\n",
      "  iterations_since_restore: 77\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 4926768\n",
      "  num_agent_steps_trained: 4926768\n",
      "  num_env_steps_sampled: 4926768\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 4926768\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 84.33333333333333\n",
      "    ram_util_percent: 86.8\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09571717462920017\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.47173119113691553\n",
      "    mean_inference_ms: 0.9689781385376288\n",
      "    mean_raw_obs_processing_ms: 0.13526237142038716\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -199606.1946573924\n",
      "    episode_reward_mean: -205468.31264879394\n",
      "    episode_reward_min: -228340.49620741204\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -210183.78172405832\n",
      "      - -208564.98293144963\n",
      "      - -204227.73164620306\n",
      "      - -203112.46889262385\n",
      "      - -199667.93160365822\n",
      "      - -205203.63940054632\n",
      "      - -204636.24265127318\n",
      "      - -203466.55986576132\n",
      "      - -202798.4387976498\n",
      "      - -204777.0712362072\n",
      "      - -203574.98667434123\n",
      "      - -207819.4704456461\n",
      "      - -206296.62412690185\n",
      "      - -205024.12256413072\n",
      "      - -202993.49253819117\n",
      "      - -210860.9598753877\n",
      "      - -202776.64375905442\n",
      "      - -207180.77966902222\n",
      "      - -206485.17743409096\n",
      "      - -211823.29987861638\n",
      "      - -203507.11332325006\n",
      "      - -202579.3076013272\n",
      "      - -205517.86369255607\n",
      "      - -204091.77440524357\n",
      "      - -205267.58639350676\n",
      "      - -205944.59938550054\n",
      "      - -204333.61592460284\n",
      "      - -204356.61035449454\n",
      "      - -205359.69411998073\n",
      "      - -205535.8206940136\n",
      "      - -206146.36237158414\n",
      "      - -201234.9561559908\n",
      "      - -203584.18681745007\n",
      "      - -205773.72323044564\n",
      "      - -206036.08661061648\n",
      "      - -206126.25554919962\n",
      "      - -207955.0683363022\n",
      "      - -205129.638769231\n",
      "      - -205068.93638434517\n",
      "      - -207024.15722932995\n",
      "      - -206992.29150207425\n",
      "      - -207131.53059345938\n",
      "      - -204157.15894304487\n",
      "      - -202431.5407240126\n",
      "      - -207355.5069181697\n",
      "      - -210079.1524804572\n",
      "      - -205559.87989587692\n",
      "      - -208150.49093249993\n",
      "      - -205142.9349861327\n",
      "      - -204946.87617654665\n",
      "      - -206729.3086362001\n",
      "      - -207019.42504012643\n",
      "      - -209583.24380591014\n",
      "      - -202701.68810927655\n",
      "      - -207446.05809255276\n",
      "      - -205553.03921261322\n",
      "      - -205990.70400309912\n",
      "      - -205383.88782568264\n",
      "      - -204745.63011756886\n",
      "      - -206430.53382490043\n",
      "      - -206367.53413423456\n",
      "      - -204013.72508473732\n",
      "      - -199606.1946573924\n",
      "      - -204688.78551298135\n",
      "      - -208318.219405624\n",
      "      - -203929.23036759338\n",
      "      - -228340.49620741204\n",
      "      - -207586.74711862352\n",
      "      - -204437.86616592726\n",
      "      - -203593.348378146\n",
      "      - -208202.55272764765\n",
      "      - -205995.38721510436\n",
      "      - -208787.38819819217\n",
      "      - -202358.0618109371\n",
      "      - -203317.36804336874\n",
      "      - -202767.8055043248\n",
      "      - -203779.2970268429\n",
      "      - -206906.35782351263\n",
      "      - -201791.50364179397\n",
      "      - -202763.24352949345\n",
      "      - -206829.47844717483\n",
      "      - -204408.4573248075\n",
      "      - -203937.2945600639\n",
      "      - -207185.30968066354\n",
      "      - -204769.1889742053\n",
      "      - -203840.74689835464\n",
      "      - -205676.51694587394\n",
      "      - -207590.03868040876\n",
      "      - -202951.11749246932\n",
      "      - -203115.86171607586\n",
      "      - -204255.1186732147\n",
      "      - -205032.49625233444\n",
      "      - -203880.03651345594\n",
      "      - -208514.53845126025\n",
      "      - -203172.20340714793\n",
      "      - -204050.3326581247\n",
      "      - -203249.00704687138\n",
      "      - -203642.0348278494\n",
      "      - -205522.05002936794\n",
      "      - -202079.6788617894\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09571717462920017\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.47173119113691553\n",
      "      mean_inference_ms: 0.9689781385376288\n",
      "      mean_raw_obs_processing_ms: 0.13526237142038716\n",
      "  time_since_restore: 740.618057012558\n",
      "  time_this_iter_s: 8.884639739990234\n",
      "  time_total_s: 740.618057012558\n",
      "  timers:\n",
      "    learn_throughput: 119913.014\n",
      "    learn_time_ms: 533.587\n",
      "    load_throughput: 21578916.033\n",
      "    load_time_ms: 2.965\n",
      "    training_iteration_time_ms: 9423.87\n",
      "    update_time_ms: 4.105\n",
      "  timestamp: 1665849486\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4926768\n",
      "  training_iteration: 77\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:58:11 (running for 00:12:45.83)<br>Memory usage on this node: 13.4/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    77</td><td style=\"text-align: right;\">         740.618</td><td style=\"text-align: right;\">4926768</td><td style=\"text-align: right;\"> -205468</td><td style=\"text-align: right;\">             -199606</td><td style=\"text-align: right;\">             -228340</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 4990752\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 4990752\n",
      "    num_agent_steps_trained: 4990752\n",
      "    num_env_steps_sampled: 4990752\n",
      "    num_env_steps_trained: 4990752\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-58-15\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -199606.1946573924\n",
      "  episode_reward_mean: -206041.46326571508\n",
      "  episode_reward_min: -228340.49620741204\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 4980\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1569156646728516\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0006169806001707911\n",
      "          model: {}\n",
      "          policy_loss: 0.0014065036084502935\n",
      "          total_loss: 10.001214027404785\n",
      "          vf_explained_var: -4.257474728319721e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 4990752\n",
      "    num_agent_steps_trained: 4990752\n",
      "    num_env_steps_sampled: 4990752\n",
      "    num_env_steps_trained: 4990752\n",
      "  iterations_since_restore: 78\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 4990752\n",
      "  num_agent_steps_trained: 4990752\n",
      "  num_env_steps_sampled: 4990752\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 4990752\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 78.5142857142857\n",
      "    ram_util_percent: 86.9857142857143\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0955778305815442\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4718315283927953\n",
      "    mean_inference_ms: 0.9684407112929222\n",
      "    mean_raw_obs_processing_ms: 0.13520207695167308\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -199606.1946573924\n",
      "    episode_reward_mean: -206041.46326571508\n",
      "    episode_reward_min: -228340.49620741204\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -206367.53413423456\n",
      "      - -204013.72508473732\n",
      "      - -199606.1946573924\n",
      "      - -204688.78551298135\n",
      "      - -208318.219405624\n",
      "      - -203929.23036759338\n",
      "      - -228340.49620741204\n",
      "      - -207586.74711862352\n",
      "      - -204437.86616592726\n",
      "      - -203593.348378146\n",
      "      - -208202.55272764765\n",
      "      - -205995.38721510436\n",
      "      - -208787.38819819217\n",
      "      - -202358.0618109371\n",
      "      - -203317.36804336874\n",
      "      - -202767.8055043248\n",
      "      - -203779.2970268429\n",
      "      - -206906.35782351263\n",
      "      - -201791.50364179397\n",
      "      - -202763.24352949345\n",
      "      - -206829.47844717483\n",
      "      - -204408.4573248075\n",
      "      - -203937.2945600639\n",
      "      - -207185.30968066354\n",
      "      - -204769.1889742053\n",
      "      - -203840.74689835464\n",
      "      - -205676.51694587394\n",
      "      - -207590.03868040876\n",
      "      - -202951.11749246932\n",
      "      - -203115.86171607586\n",
      "      - -204255.1186732147\n",
      "      - -205032.49625233444\n",
      "      - -203880.03651345594\n",
      "      - -208514.53845126025\n",
      "      - -203172.20340714793\n",
      "      - -204050.3326581247\n",
      "      - -203249.00704687138\n",
      "      - -203642.0348278494\n",
      "      - -205522.05002936794\n",
      "      - -202079.6788617894\n",
      "      - -204871.47301416958\n",
      "      - -207277.5756588328\n",
      "      - -210362.55901287985\n",
      "      - -206360.12444103236\n",
      "      - -206398.59415148056\n",
      "      - -222995.04912854536\n",
      "      - -204642.20622447794\n",
      "      - -209079.50856739577\n",
      "      - -204411.37380117617\n",
      "      - -207904.3419253215\n",
      "      - -201474.83754386\n",
      "      - -208132.5641353379\n",
      "      - -201102.53515957663\n",
      "      - -206831.0737100771\n",
      "      - -205402.8728336936\n",
      "      - -212831.34550147702\n",
      "      - -206474.4348443581\n",
      "      - -208627.93027407568\n",
      "      - -204397.63123763682\n",
      "      - -209051.41852974496\n",
      "      - -207531.28677728472\n",
      "      - -204856.98460911625\n",
      "      - -204544.49648317895\n",
      "      - -204372.15345795162\n",
      "      - -207173.66521593492\n",
      "      - -207468.3995161222\n",
      "      - -202143.35400420477\n",
      "      - -204659.4158123175\n",
      "      - -204645.3126592872\n",
      "      - -207887.30181339194\n",
      "      - -203046.71436361008\n",
      "      - -201238.59037909622\n",
      "      - -204126.04909953964\n",
      "      - -207974.90220110075\n",
      "      - -207260.76463240417\n",
      "      - -207577.49545624695\n",
      "      - -205892.93983001183\n",
      "      - -206544.89248857455\n",
      "      - -200742.1541820821\n",
      "      - -220000.23684776822\n",
      "      - -204774.29275282135\n",
      "      - -205307.77182787698\n",
      "      - -205252.1159551669\n",
      "      - -204288.08255471208\n",
      "      - -204265.68727783032\n",
      "      - -201880.86190013294\n",
      "      - -204740.76811767337\n",
      "      - -205119.84450155622\n",
      "      - -208377.3831520778\n",
      "      - -206522.79632192763\n",
      "      - -208107.80949161167\n",
      "      - -212258.41582652234\n",
      "      - -213629.2598271464\n",
      "      - -204828.68663675798\n",
      "      - -205937.47458860432\n",
      "      - -206640.16977362928\n",
      "      - -203869.31512482493\n",
      "      - -204160.94239857272\n",
      "      - -205604.61992091613\n",
      "      - -209010.84910136816\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.0955778305815442\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4718315283927953\n",
      "      mean_inference_ms: 0.9684407112929222\n",
      "      mean_raw_obs_processing_ms: 0.13520207695167308\n",
      "  time_since_restore: 750.0825674533844\n",
      "  time_this_iter_s: 9.464510440826416\n",
      "  time_total_s: 750.0825674533844\n",
      "  timers:\n",
      "    learn_throughput: 120362.837\n",
      "    learn_time_ms: 531.593\n",
      "    load_throughput: 21589679.104\n",
      "    load_time_ms: 2.964\n",
      "    training_iteration_time_ms: 9476.277\n",
      "    update_time_ms: 3.945\n",
      "  timestamp: 1665849495\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4990752\n",
      "  training_iteration: 78\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:58:20 (running for 00:12:55.19)<br>Memory usage on this node: 13.4/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    78</td><td style=\"text-align: right;\">         750.083</td><td style=\"text-align: right;\">4990752</td><td style=\"text-align: right;\"> -206041</td><td style=\"text-align: right;\">             -199606</td><td style=\"text-align: right;\">             -228340</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 5054736\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 5054736\n",
      "    num_agent_steps_trained: 5054736\n",
      "    num_env_steps_sampled: 5054736\n",
      "    num_env_steps_trained: 5054736\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-58-25\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -200290.11160576128\n",
      "  episode_reward_mean: -206454.1657879221\n",
      "  episode_reward_min: -244240.69625734192\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 5052\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.162109613418579\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0003490650560706854\n",
      "          model: {}\n",
      "          policy_loss: 0.0037844632752239704\n",
      "          total_loss: 10.00353717803955\n",
      "          vf_explained_var: -1.797600468478322e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 5054736\n",
      "    num_agent_steps_trained: 5054736\n",
      "    num_env_steps_sampled: 5054736\n",
      "    num_env_steps_trained: 5054736\n",
      "  iterations_since_restore: 79\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 5054736\n",
      "  num_agent_steps_trained: 5054736\n",
      "  num_env_steps_sampled: 5054736\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 5054736\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 85.30769230769232\n",
      "    ram_util_percent: 86.9923076923077\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09553227160547556\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.47153227196551883\n",
      "    mean_inference_ms: 0.9687006458942602\n",
      "    mean_raw_obs_processing_ms: 0.13504790515040047\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -200290.11160576128\n",
      "    episode_reward_mean: -206454.1657879221\n",
      "    episode_reward_min: -244240.69625734192\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -204126.04909953964\n",
      "      - -207974.90220110075\n",
      "      - -207260.76463240417\n",
      "      - -207577.49545624695\n",
      "      - -205892.93983001183\n",
      "      - -206544.89248857455\n",
      "      - -200742.1541820821\n",
      "      - -220000.23684776822\n",
      "      - -204774.29275282135\n",
      "      - -205307.77182787698\n",
      "      - -205252.1159551669\n",
      "      - -204288.08255471208\n",
      "      - -204265.68727783032\n",
      "      - -201880.86190013294\n",
      "      - -204740.76811767337\n",
      "      - -205119.84450155622\n",
      "      - -208377.3831520778\n",
      "      - -206522.79632192763\n",
      "      - -208107.80949161167\n",
      "      - -212258.41582652234\n",
      "      - -213629.2598271464\n",
      "      - -204828.68663675798\n",
      "      - -205937.47458860432\n",
      "      - -206640.16977362928\n",
      "      - -203869.31512482493\n",
      "      - -204160.94239857272\n",
      "      - -205604.61992091613\n",
      "      - -209010.84910136816\n",
      "      - -207513.35586582223\n",
      "      - -202550.1080242329\n",
      "      - -205538.2545378764\n",
      "      - -207517.72551085526\n",
      "      - -208091.29924930228\n",
      "      - -201075.88461905267\n",
      "      - -205732.82233063105\n",
      "      - -206652.08005535713\n",
      "      - -205574.8115211797\n",
      "      - -202740.11540984391\n",
      "      - -207193.93423877258\n",
      "      - -201232.17220360055\n",
      "      - -206727.75272227425\n",
      "      - -201340.5966351855\n",
      "      - -209498.8029784741\n",
      "      - -209581.80671736976\n",
      "      - -206162.00845476706\n",
      "      - -201912.00217895576\n",
      "      - -202169.84226242892\n",
      "      - -204722.3976866938\n",
      "      - -205116.25090500474\n",
      "      - -204519.54672486024\n",
      "      - -205262.29123491884\n",
      "      - -201156.50347452558\n",
      "      - -219954.00597774927\n",
      "      - -205291.85754966072\n",
      "      - -208198.11165527304\n",
      "      - -203648.01877837785\n",
      "      - -207689.50513989717\n",
      "      - -205273.66859104516\n",
      "      - -207264.93915620956\n",
      "      - -210377.55005107084\n",
      "      - -207806.8291164669\n",
      "      - -209935.67769905037\n",
      "      - -207307.14130158554\n",
      "      - -244240.69625734192\n",
      "      - -207255.08429958278\n",
      "      - -201756.65201956013\n",
      "      - -206410.94487077795\n",
      "      - -206652.80980840628\n",
      "      - -203599.37498837966\n",
      "      - -209621.23273862572\n",
      "      - -201483.22381372956\n",
      "      - -204538.5109886194\n",
      "      - -206922.44078152525\n",
      "      - -204870.34693682942\n",
      "      - -205932.87902776373\n",
      "      - -205012.45735472103\n",
      "      - -206323.06167715866\n",
      "      - -235475.66033804935\n",
      "      - -203812.81205399512\n",
      "      - -204511.97973508062\n",
      "      - -207557.99641859616\n",
      "      - -204363.23913121576\n",
      "      - -206197.17768019572\n",
      "      - -206646.24135985353\n",
      "      - -203690.8916521198\n",
      "      - -205225.38016272895\n",
      "      - -204196.18940332846\n",
      "      - -200703.17364116822\n",
      "      - -205237.02313910087\n",
      "      - -204041.44520775462\n",
      "      - -206686.04386299025\n",
      "      - -206557.086807449\n",
      "      - -207464.456706902\n",
      "      - -203188.14248112548\n",
      "      - -208036.71773190465\n",
      "      - -201629.16230962978\n",
      "      - -202684.532674923\n",
      "      - -200290.11160576128\n",
      "      - -201586.11336711445\n",
      "      - -203989.033410375\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09553227160547556\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.47153227196551883\n",
      "      mean_inference_ms: 0.9687006458942602\n",
      "      mean_raw_obs_processing_ms: 0.13504790515040047\n",
      "  time_since_restore: 759.7104589939117\n",
      "  time_this_iter_s: 9.627891540527344\n",
      "  time_total_s: 759.7104589939117\n",
      "  timers:\n",
      "    learn_throughput: 120163.395\n",
      "    learn_time_ms: 532.475\n",
      "    load_throughput: 21425417.113\n",
      "    load_time_ms: 2.986\n",
      "    training_iteration_time_ms: 9533.157\n",
      "    update_time_ms: 3.822\n",
      "  timestamp: 1665849505\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5054736\n",
      "  training_iteration: 79\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:58:30 (running for 00:13:04.95)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    79</td><td style=\"text-align: right;\">          759.71</td><td style=\"text-align: right;\">5054736</td><td style=\"text-align: right;\"> -206454</td><td style=\"text-align: right;\">             -200290</td><td style=\"text-align: right;\">             -244241</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 5118720\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 5118720\n",
      "    num_agent_steps_trained: 5118720\n",
      "    num_env_steps_sampled: 5118720\n",
      "    num_env_steps_trained: 5118720\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-58-34\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -199834.0616782613\n",
      "  episode_reward_mean: -206121.16536554712\n",
      "  episode_reward_min: -244240.69625734192\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 5112\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.160750150680542\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0006136974552646279\n",
      "          model: {}\n",
      "          policy_loss: 0.006638089660555124\n",
      "          total_loss: 10.006444931030273\n",
      "          vf_explained_var: -1.3245476715439963e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 5118720\n",
      "    num_agent_steps_trained: 5118720\n",
      "    num_env_steps_sampled: 5118720\n",
      "    num_env_steps_trained: 5118720\n",
      "  iterations_since_restore: 80\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 5118720\n",
      "  num_agent_steps_trained: 5118720\n",
      "  num_env_steps_sampled: 5118720\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 5118720\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.61538461538461\n",
      "    ram_util_percent: 87.0769230769231\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0956093461330213\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.47131018644883227\n",
      "    mean_inference_ms: 0.9685744824943591\n",
      "    mean_raw_obs_processing_ms: 0.1352138124966584\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -199834.0616782613\n",
      "    episode_reward_mean: -206121.16536554712\n",
      "    episode_reward_min: -244240.69625734192\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -207806.8291164669\n",
      "      - -209935.67769905037\n",
      "      - -207307.14130158554\n",
      "      - -244240.69625734192\n",
      "      - -207255.08429958278\n",
      "      - -201756.65201956013\n",
      "      - -206410.94487077795\n",
      "      - -206652.80980840628\n",
      "      - -203599.37498837966\n",
      "      - -209621.23273862572\n",
      "      - -201483.22381372956\n",
      "      - -204538.5109886194\n",
      "      - -206922.44078152525\n",
      "      - -204870.34693682942\n",
      "      - -205932.87902776373\n",
      "      - -205012.45735472103\n",
      "      - -206323.06167715866\n",
      "      - -235475.66033804935\n",
      "      - -203812.81205399512\n",
      "      - -204511.97973508062\n",
      "      - -207557.99641859616\n",
      "      - -204363.23913121576\n",
      "      - -206197.17768019572\n",
      "      - -206646.24135985353\n",
      "      - -203690.8916521198\n",
      "      - -205225.38016272895\n",
      "      - -204196.18940332846\n",
      "      - -200703.17364116822\n",
      "      - -205237.02313910087\n",
      "      - -204041.44520775462\n",
      "      - -206686.04386299025\n",
      "      - -206557.086807449\n",
      "      - -207464.456706902\n",
      "      - -203188.14248112548\n",
      "      - -208036.71773190465\n",
      "      - -201629.16230962978\n",
      "      - -202684.532674923\n",
      "      - -200290.11160576128\n",
      "      - -201586.11336711445\n",
      "      - -203989.033410375\n",
      "      - -201514.5539344529\n",
      "      - -206744.9685217427\n",
      "      - -204286.76303470362\n",
      "      - -207814.84158173352\n",
      "      - -207925.15830812222\n",
      "      - -205102.5879843833\n",
      "      - -205603.49919158273\n",
      "      - -208582.58608530887\n",
      "      - -202781.81719736822\n",
      "      - -204401.63105047063\n",
      "      - -206299.26903696847\n",
      "      - -205326.81209195266\n",
      "      - -207063.33853248385\n",
      "      - -205668.34811296803\n",
      "      - -204501.5049015805\n",
      "      - -206716.8457795891\n",
      "      - -206230.64289275344\n",
      "      - -205134.83812709927\n",
      "      - -205638.4810312196\n",
      "      - -203209.98700069927\n",
      "      - -203252.91270689367\n",
      "      - -207621.8349251481\n",
      "      - -207733.3457368983\n",
      "      - -205908.41221809978\n",
      "      - -207922.80715000222\n",
      "      - -209553.82845884576\n",
      "      - -200403.16545117018\n",
      "      - -209662.5363629406\n",
      "      - -203082.62030537342\n",
      "      - -204038.8120241662\n",
      "      - -205502.52408403487\n",
      "      - -207634.4649654403\n",
      "      - -205667.63277311093\n",
      "      - -204091.06161586675\n",
      "      - -208563.467352452\n",
      "      - -209373.59294402786\n",
      "      - -206652.72067126835\n",
      "      - -206999.5872102027\n",
      "      - -202325.79087852626\n",
      "      - -205890.85651778473\n",
      "      - -208547.3793169432\n",
      "      - -206035.51918508476\n",
      "      - -207461.3814855621\n",
      "      - -208459.57205395767\n",
      "      - -199834.0616782613\n",
      "      - -204466.9623072465\n",
      "      - -205816.5011881779\n",
      "      - -206401.83811234328\n",
      "      - -202665.71579457197\n",
      "      - -206084.89003390598\n",
      "      - -210511.43069477798\n",
      "      - -206398.00579036807\n",
      "      - -202660.4830460051\n",
      "      - -203456.82684145033\n",
      "      - -207702.11072006158\n",
      "      - -209362.93837601785\n",
      "      - -203839.04121237955\n",
      "      - -202946.84208568378\n",
      "      - -202381.08002477948\n",
      "      - -201213.53329621433\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.0956093461330213\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.47131018644883227\n",
      "      mean_inference_ms: 0.9685744824943591\n",
      "      mean_raw_obs_processing_ms: 0.1352138124966584\n",
      "  time_since_restore: 769.0797688961029\n",
      "  time_this_iter_s: 9.369309902191162\n",
      "  time_total_s: 769.0797688961029\n",
      "  timers:\n",
      "    learn_throughput: 119205.48\n",
      "    learn_time_ms: 536.754\n",
      "    load_throughput: 21650640.329\n",
      "    load_time_ms: 2.955\n",
      "    training_iteration_time_ms: 9522.637\n",
      "    update_time_ms: 3.881\n",
      "  timestamp: 1665849514\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5118720\n",
      "  training_iteration: 80\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:58:40 (running for 00:13:14.70)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">          769.08</td><td style=\"text-align: right;\">5118720</td><td style=\"text-align: right;\"> -206121</td><td style=\"text-align: right;\">             -199834</td><td style=\"text-align: right;\">             -244241</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 5182704\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 5182704\n",
      "    num_agent_steps_trained: 5182704\n",
      "    num_env_steps_sampled: 5182704\n",
      "    num_env_steps_trained: 5182704\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-58-44\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -199304.6081685397\n",
      "  episode_reward_mean: -205308.78081098758\n",
      "  episode_reward_min: -211749.53843715962\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 5172\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.164889097213745\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0009284801199100912\n",
      "          model: {}\n",
      "          policy_loss: 0.0021053410600870848\n",
      "          total_loss: 10.001974105834961\n",
      "          vf_explained_var: 2.176042634971509e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 5182704\n",
      "    num_agent_steps_trained: 5182704\n",
      "    num_env_steps_sampled: 5182704\n",
      "    num_env_steps_trained: 5182704\n",
      "  iterations_since_restore: 81\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 5182704\n",
      "  num_agent_steps_trained: 5182704\n",
      "  num_env_steps_sampled: 5182704\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 5182704\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.36153846153846\n",
      "    ram_util_percent: 87.10769230769232\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09546833238661455\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4715287147769977\n",
      "    mean_inference_ms: 0.9688123175171468\n",
      "    mean_raw_obs_processing_ms: 0.13513774448080892\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -199304.6081685397\n",
      "    episode_reward_mean: -205308.78081098758\n",
      "    episode_reward_min: -211749.53843715962\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -203252.91270689367\n",
      "      - -207621.8349251481\n",
      "      - -207733.3457368983\n",
      "      - -205908.41221809978\n",
      "      - -207922.80715000222\n",
      "      - -209553.82845884576\n",
      "      - -200403.16545117018\n",
      "      - -209662.5363629406\n",
      "      - -203082.62030537342\n",
      "      - -204038.8120241662\n",
      "      - -205502.52408403487\n",
      "      - -207634.4649654403\n",
      "      - -205667.63277311093\n",
      "      - -204091.06161586675\n",
      "      - -208563.467352452\n",
      "      - -209373.59294402786\n",
      "      - -206652.72067126835\n",
      "      - -206999.5872102027\n",
      "      - -202325.79087852626\n",
      "      - -205890.85651778473\n",
      "      - -208547.3793169432\n",
      "      - -206035.51918508476\n",
      "      - -207461.3814855621\n",
      "      - -208459.57205395767\n",
      "      - -199834.0616782613\n",
      "      - -204466.9623072465\n",
      "      - -205816.5011881779\n",
      "      - -206401.83811234328\n",
      "      - -202665.71579457197\n",
      "      - -206084.89003390598\n",
      "      - -210511.43069477798\n",
      "      - -206398.00579036807\n",
      "      - -202660.4830460051\n",
      "      - -203456.82684145033\n",
      "      - -207702.11072006158\n",
      "      - -209362.93837601785\n",
      "      - -203839.04121237955\n",
      "      - -202946.84208568378\n",
      "      - -202381.08002477948\n",
      "      - -201213.53329621433\n",
      "      - -203292.6982226507\n",
      "      - -211749.53843715962\n",
      "      - -210289.81612514608\n",
      "      - -199304.6081685397\n",
      "      - -204685.72069329908\n",
      "      - -206466.5686691866\n",
      "      - -210200.21645435065\n",
      "      - -202885.68257633186\n",
      "      - -203176.21628778882\n",
      "      - -206294.66032373183\n",
      "      - -205500.91059245923\n",
      "      - -204203.6130335195\n",
      "      - -200679.4758660632\n",
      "      - -205190.981543936\n",
      "      - -201764.18100427047\n",
      "      - -206568.1829344297\n",
      "      - -201300.69728245153\n",
      "      - -203901.1895754666\n",
      "      - -204966.9794699596\n",
      "      - -203205.4254726223\n",
      "      - -200639.61889431078\n",
      "      - -204030.17490996717\n",
      "      - -210724.6058062318\n",
      "      - -209843.61828931168\n",
      "      - -203927.00961920878\n",
      "      - -207551.06901041337\n",
      "      - -206896.67756794285\n",
      "      - -208722.34325265166\n",
      "      - -206172.2892372037\n",
      "      - -200763.51847280958\n",
      "      - -202157.5314466568\n",
      "      - -205372.88056598284\n",
      "      - -204821.57980790953\n",
      "      - -205660.05607051085\n",
      "      - -203752.45929581745\n",
      "      - -203767.25315104058\n",
      "      - -204976.47665491424\n",
      "      - -204136.40631531292\n",
      "      - -209271.7582727862\n",
      "      - -207492.31192818668\n",
      "      - -203631.9817992384\n",
      "      - -205523.8153418312\n",
      "      - -204176.3099422909\n",
      "      - -207741.04707891532\n",
      "      - -207280.1715407029\n",
      "      - -204028.16778974212\n",
      "      - -206220.7032536257\n",
      "      - -204481.40225077618\n",
      "      - -203538.89408405015\n",
      "      - -205170.19880333074\n",
      "      - -208769.99342554732\n",
      "      - -203621.88365988998\n",
      "      - -210680.45320075276\n",
      "      - -201871.65364593864\n",
      "      - -203519.80115404804\n",
      "      - -206309.69508141401\n",
      "      - -201560.0026730343\n",
      "      - -202369.83586365258\n",
      "      - -200571.12749724142\n",
      "      - -205375.8541141579\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09546833238661455\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4715287147769977\n",
      "      mean_inference_ms: 0.9688123175171468\n",
      "      mean_raw_obs_processing_ms: 0.13513774448080892\n",
      "  time_since_restore: 778.9034123420715\n",
      "  time_this_iter_s: 9.823643445968628\n",
      "  time_total_s: 778.9034123420715\n",
      "  timers:\n",
      "    learn_throughput: 119671.305\n",
      "    learn_time_ms: 534.665\n",
      "    load_throughput: 21525433.899\n",
      "    load_time_ms: 2.972\n",
      "    training_iteration_time_ms: 9540.538\n",
      "    update_time_ms: 4.045\n",
      "  timestamp: 1665849524\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5182704\n",
      "  training_iteration: 81\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:58:49 (running for 00:13:24.12)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    81</td><td style=\"text-align: right;\">         778.903</td><td style=\"text-align: right;\">5182704</td><td style=\"text-align: right;\"> -205309</td><td style=\"text-align: right;\">             -199305</td><td style=\"text-align: right;\">             -211750</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 5246688\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 5246688\n",
      "    num_agent_steps_trained: 5246688\n",
      "    num_env_steps_sampled: 5246688\n",
      "    num_env_steps_trained: 5246688\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-58-54\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -200457.38040644577\n",
      "  episode_reward_mean: -205212.40878358844\n",
      "  episode_reward_min: -212197.46950945715\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 5244\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.170206069946289\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0006616329192183912\n",
      "          model: {}\n",
      "          policy_loss: 0.0034205836709588766\n",
      "          total_loss: 10.00323486328125\n",
      "          vf_explained_var: -1.2299371299206996e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 5246688\n",
      "    num_agent_steps_trained: 5246688\n",
      "    num_env_steps_sampled: 5246688\n",
      "    num_env_steps_trained: 5246688\n",
      "  iterations_since_restore: 82\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 5246688\n",
      "  num_agent_steps_trained: 5246688\n",
      "  num_env_steps_sampled: 5246688\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 5246688\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 78.27857142857142\n",
      "    ram_util_percent: 87.19285714285714\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09539278136705759\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.47116995611614776\n",
      "    mean_inference_ms: 0.9691908032764707\n",
      "    mean_raw_obs_processing_ms: 0.1349476319899646\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -200457.38040644577\n",
      "    episode_reward_mean: -205212.40878358844\n",
      "    episode_reward_min: -212197.46950945715\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -204821.57980790953\n",
      "      - -205660.05607051085\n",
      "      - -203752.45929581745\n",
      "      - -203767.25315104058\n",
      "      - -204976.47665491424\n",
      "      - -204136.40631531292\n",
      "      - -209271.7582727862\n",
      "      - -207492.31192818668\n",
      "      - -203631.9817992384\n",
      "      - -205523.8153418312\n",
      "      - -204176.3099422909\n",
      "      - -207741.04707891532\n",
      "      - -207280.1715407029\n",
      "      - -204028.16778974212\n",
      "      - -206220.7032536257\n",
      "      - -204481.40225077618\n",
      "      - -203538.89408405015\n",
      "      - -205170.19880333074\n",
      "      - -208769.99342554732\n",
      "      - -203621.88365988998\n",
      "      - -210680.45320075276\n",
      "      - -201871.65364593864\n",
      "      - -203519.80115404804\n",
      "      - -206309.69508141401\n",
      "      - -201560.0026730343\n",
      "      - -202369.83586365258\n",
      "      - -200571.12749724142\n",
      "      - -205375.8541141579\n",
      "      - -203975.79581028392\n",
      "      - -205815.864189804\n",
      "      - -204131.3485343569\n",
      "      - -200966.55964898778\n",
      "      - -203926.37108710207\n",
      "      - -202321.871400512\n",
      "      - -205774.27043522024\n",
      "      - -205382.66357404285\n",
      "      - -202920.8321599949\n",
      "      - -202087.32431332287\n",
      "      - -202828.6760078482\n",
      "      - -207464.69211561303\n",
      "      - -204599.01956356535\n",
      "      - -204057.69929512535\n",
      "      - -205700.7837965823\n",
      "      - -210294.10457389682\n",
      "      - -207038.58437574864\n",
      "      - -207172.21284465442\n",
      "      - -201683.96406659667\n",
      "      - -211659.7526906119\n",
      "      - -205701.36473945592\n",
      "      - -200457.38040644577\n",
      "      - -209066.45296983235\n",
      "      - -210923.60967066116\n",
      "      - -203883.30415089463\n",
      "      - -206452.60987397394\n",
      "      - -201742.79976137387\n",
      "      - -208968.6277205861\n",
      "      - -206839.60620531673\n",
      "      - -203926.9859633147\n",
      "      - -203034.31612236932\n",
      "      - -202766.8868585429\n",
      "      - -207637.46147624045\n",
      "      - -204036.63160926796\n",
      "      - -204411.140916133\n",
      "      - -208530.16040852046\n",
      "      - -206215.75324200324\n",
      "      - -202547.17065868128\n",
      "      - -203467.17368885377\n",
      "      - -205603.41340251948\n",
      "      - -203890.22502257305\n",
      "      - -205960.9930568589\n",
      "      - -205548.2557111466\n",
      "      - -206833.71880120147\n",
      "      - -205216.7476073492\n",
      "      - -204772.7750755194\n",
      "      - -206203.10301959893\n",
      "      - -208339.38725511177\n",
      "      - -207607.1533299631\n",
      "      - -207373.83230235675\n",
      "      - -204412.71493090855\n",
      "      - -207540.04782491998\n",
      "      - -202462.74462318863\n",
      "      - -203827.27857156887\n",
      "      - -202882.28359254735\n",
      "      - -204535.28988192845\n",
      "      - -204312.8685100366\n",
      "      - -205065.6258599477\n",
      "      - -212197.46950945715\n",
      "      - -204734.48873862298\n",
      "      - -206215.9666112099\n",
      "      - -209389.8517467971\n",
      "      - -203690.89950986582\n",
      "      - -201277.15525750647\n",
      "      - -201139.02735849988\n",
      "      - -203582.57233201634\n",
      "      - -201850.8329963174\n",
      "      - -202105.69635430558\n",
      "      - -211342.63121223458\n",
      "      - -206789.10937219553\n",
      "      - -208413.41990634974\n",
      "      - -205390.17845122743\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09539278136705759\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.47116995611614776\n",
      "      mean_inference_ms: 0.9691908032764707\n",
      "      mean_raw_obs_processing_ms: 0.1349476319899646\n",
      "  time_since_restore: 788.3714294433594\n",
      "  time_this_iter_s: 9.468017101287842\n",
      "  time_total_s: 788.3714294433594\n",
      "  timers:\n",
      "    learn_throughput: 118583.385\n",
      "    learn_time_ms: 539.57\n",
      "    load_throughput: 21345493.147\n",
      "    load_time_ms: 2.998\n",
      "    training_iteration_time_ms: 9558.273\n",
      "    update_time_ms: 4.198\n",
      "  timestamp: 1665849534\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5246688\n",
      "  training_iteration: 82\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:58:59 (running for 00:13:33.73)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    82</td><td style=\"text-align: right;\">         788.371</td><td style=\"text-align: right;\">5246688</td><td style=\"text-align: right;\"> -205212</td><td style=\"text-align: right;\">             -200457</td><td style=\"text-align: right;\">             -212197</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 5310672\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 5310672\n",
      "    num_agent_steps_trained: 5310672\n",
      "    num_env_steps_sampled: 5310672\n",
      "    num_env_steps_trained: 5310672\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-59-03\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -199630.0755139631\n",
      "  episode_reward_mean: -205347.1548640604\n",
      "  episode_reward_min: -216929.79307791026\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 5304\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1748461723327637\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.000989897409453988\n",
      "          model: {}\n",
      "          policy_loss: 0.005528916604816914\n",
      "          total_loss: 10.005410194396973\n",
      "          vf_explained_var: -4.1628641866964244e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 5310672\n",
      "    num_agent_steps_trained: 5310672\n",
      "    num_env_steps_sampled: 5310672\n",
      "    num_env_steps_trained: 5310672\n",
      "  iterations_since_restore: 83\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 5310672\n",
      "  num_agent_steps_trained: 5310672\n",
      "  num_env_steps_sampled: 5310672\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 5310672\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.59230769230768\n",
      "    ram_util_percent: 87.26153846153845\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09547897750382274\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4709970017166173\n",
      "    mean_inference_ms: 0.9690884559695792\n",
      "    mean_raw_obs_processing_ms: 0.13512442504757932\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -199630.0755139631\n",
      "    episode_reward_mean: -205347.1548640604\n",
      "    episode_reward_min: -216929.79307791026\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -207637.46147624045\n",
      "      - -204036.63160926796\n",
      "      - -204411.140916133\n",
      "      - -208530.16040852046\n",
      "      - -206215.75324200324\n",
      "      - -202547.17065868128\n",
      "      - -203467.17368885377\n",
      "      - -205603.41340251948\n",
      "      - -203890.22502257305\n",
      "      - -205960.9930568589\n",
      "      - -205548.2557111466\n",
      "      - -206833.71880120147\n",
      "      - -205216.7476073492\n",
      "      - -204772.7750755194\n",
      "      - -206203.10301959893\n",
      "      - -208339.38725511177\n",
      "      - -207607.1533299631\n",
      "      - -207373.83230235675\n",
      "      - -204412.71493090855\n",
      "      - -207540.04782491998\n",
      "      - -202462.74462318863\n",
      "      - -203827.27857156887\n",
      "      - -202882.28359254735\n",
      "      - -204535.28988192845\n",
      "      - -204312.8685100366\n",
      "      - -205065.6258599477\n",
      "      - -212197.46950945715\n",
      "      - -204734.48873862298\n",
      "      - -206215.9666112099\n",
      "      - -209389.8517467971\n",
      "      - -203690.89950986582\n",
      "      - -201277.15525750647\n",
      "      - -201139.02735849988\n",
      "      - -203582.57233201634\n",
      "      - -201850.8329963174\n",
      "      - -202105.69635430558\n",
      "      - -211342.63121223458\n",
      "      - -206789.10937219553\n",
      "      - -208413.41990634974\n",
      "      - -205390.17845122743\n",
      "      - -204527.80876234273\n",
      "      - -206408.05957654747\n",
      "      - -201775.1146964314\n",
      "      - -204313.84118439458\n",
      "      - -204273.89394701738\n",
      "      - -203663.2996235028\n",
      "      - -206198.5293990341\n",
      "      - -200509.6306851328\n",
      "      - -206875.38376358428\n",
      "      - -202162.2616783206\n",
      "      - -203541.8810655665\n",
      "      - -202107.86389842484\n",
      "      - -210213.36110852877\n",
      "      - -205647.272047891\n",
      "      - -206181.34144456114\n",
      "      - -207848.44571429107\n",
      "      - -205223.4462735276\n",
      "      - -201998.206742527\n",
      "      - -202116.9664725079\n",
      "      - -202617.38898557526\n",
      "      - -204733.0494117554\n",
      "      - -206295.99355112176\n",
      "      - -206700.66865113337\n",
      "      - -202629.51619223677\n",
      "      - -204849.3489078757\n",
      "      - -205205.49335834614\n",
      "      - -204451.87945355914\n",
      "      - -199630.0755139631\n",
      "      - -202148.67592600553\n",
      "      - -206789.97178856932\n",
      "      - -208245.3001902557\n",
      "      - -216929.79307791026\n",
      "      - -202762.99716002535\n",
      "      - -203148.921921115\n",
      "      - -205666.2604218905\n",
      "      - -205561.0500266159\n",
      "      - -203898.17501063852\n",
      "      - -202034.61841016758\n",
      "      - -212927.13625989045\n",
      "      - -205403.17976666562\n",
      "      - -204019.6198016214\n",
      "      - -206456.32631671702\n",
      "      - -202569.8575619208\n",
      "      - -201800.2917028265\n",
      "      - -207368.7584748603\n",
      "      - -208253.562835753\n",
      "      - -205814.1517431071\n",
      "      - -205149.1772532915\n",
      "      - -207134.24744274266\n",
      "      - -212737.260981567\n",
      "      - -207644.99965347868\n",
      "      - -207452.44032312316\n",
      "      - -202455.74208749764\n",
      "      - -203764.41242021034\n",
      "      - -204960.4181201698\n",
      "      - -204547.9627598347\n",
      "      - -207136.4044588792\n",
      "      - -205841.7118819664\n",
      "      - -204716.12133687251\n",
      "      - -209322.66744459502\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09547897750382274\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4709970017166173\n",
      "      mean_inference_ms: 0.9690884559695792\n",
      "      mean_raw_obs_processing_ms: 0.13512442504757932\n",
      "  time_since_restore: 797.881157875061\n",
      "  time_this_iter_s: 9.50972843170166\n",
      "  time_total_s: 797.881157875061\n",
      "  timers:\n",
      "    learn_throughput: 118909.715\n",
      "    learn_time_ms: 538.089\n",
      "    load_throughput: 21354155.332\n",
      "    load_time_ms: 2.996\n",
      "    training_iteration_time_ms: 9489.802\n",
      "    update_time_ms: 4.1\n",
      "  timestamp: 1665849543\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5310672\n",
      "  training_iteration: 83\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:59:09 (running for 00:13:43.50)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    83</td><td style=\"text-align: right;\">         797.881</td><td style=\"text-align: right;\">5310672</td><td style=\"text-align: right;\"> -205347</td><td style=\"text-align: right;\">             -199630</td><td style=\"text-align: right;\">             -216930</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 5374656\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 5374656\n",
      "    num_agent_steps_trained: 5374656\n",
      "    num_env_steps_sampled: 5374656\n",
      "    num_env_steps_trained: 5374656\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-59-13\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -197986.91388865016\n",
      "  episode_reward_mean: -205408.08145923528\n",
      "  episode_reward_min: -216929.79307791026\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 5364\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1730661392211914\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00028312389622442424\n",
      "          model: {}\n",
      "          policy_loss: 0.0008859940571710467\n",
      "          total_loss: 10.000624656677246\n",
      "          vf_explained_var: -2.7437058847112894e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 5374656\n",
      "    num_agent_steps_trained: 5374656\n",
      "    num_env_steps_sampled: 5374656\n",
      "    num_env_steps_trained: 5374656\n",
      "  iterations_since_restore: 84\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 5374656\n",
      "  num_agent_steps_trained: 5374656\n",
      "  num_env_steps_sampled: 5374656\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 5374656\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 85.35384615384616\n",
      "    ram_util_percent: 87.37692307692308\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09535421498035841\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.47132802745076174\n",
      "    mean_inference_ms: 0.9693002040329799\n",
      "    mean_raw_obs_processing_ms: 0.13506532425663878\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -197986.91388865016\n",
      "    episode_reward_mean: -205408.08145923528\n",
      "    episode_reward_min: -216929.79307791026\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -204733.0494117554\n",
      "      - -206295.99355112176\n",
      "      - -206700.66865113337\n",
      "      - -202629.51619223677\n",
      "      - -204849.3489078757\n",
      "      - -205205.49335834614\n",
      "      - -204451.87945355914\n",
      "      - -199630.0755139631\n",
      "      - -202148.67592600553\n",
      "      - -206789.97178856932\n",
      "      - -208245.3001902557\n",
      "      - -216929.79307791026\n",
      "      - -202762.99716002535\n",
      "      - -203148.921921115\n",
      "      - -205666.2604218905\n",
      "      - -205561.0500266159\n",
      "      - -203898.17501063852\n",
      "      - -202034.61841016758\n",
      "      - -212927.13625989045\n",
      "      - -205403.17976666562\n",
      "      - -204019.6198016214\n",
      "      - -206456.32631671702\n",
      "      - -202569.8575619208\n",
      "      - -201800.2917028265\n",
      "      - -207368.7584748603\n",
      "      - -208253.562835753\n",
      "      - -205814.1517431071\n",
      "      - -205149.1772532915\n",
      "      - -207134.24744274266\n",
      "      - -212737.260981567\n",
      "      - -207644.99965347868\n",
      "      - -207452.44032312316\n",
      "      - -202455.74208749764\n",
      "      - -203764.41242021034\n",
      "      - -204960.4181201698\n",
      "      - -204547.9627598347\n",
      "      - -207136.4044588792\n",
      "      - -205841.7118819664\n",
      "      - -204716.12133687251\n",
      "      - -209322.66744459502\n",
      "      - -204697.52904719926\n",
      "      - -204520.9565839977\n",
      "      - -204524.07511527406\n",
      "      - -213434.66509459025\n",
      "      - -203909.3232681628\n",
      "      - -204236.57100097556\n",
      "      - -202524.94787845353\n",
      "      - -208426.08168231984\n",
      "      - -208408.76982119278\n",
      "      - -211153.01566583238\n",
      "      - -207538.52233960765\n",
      "      - -203095.678587355\n",
      "      - -205858.59548879013\n",
      "      - -212758.26072181668\n",
      "      - -202038.8425125112\n",
      "      - -204830.76141783537\n",
      "      - -206228.3205450863\n",
      "      - -202783.90703750652\n",
      "      - -202169.50539540453\n",
      "      - -203951.7383774448\n",
      "      - -205899.1780368114\n",
      "      - -211751.50745256242\n",
      "      - -203465.10897591806\n",
      "      - -209479.78867630416\n",
      "      - -209982.3252577578\n",
      "      - -210066.982576646\n",
      "      - -203971.64945318486\n",
      "      - -205313.91444358852\n",
      "      - -206923.44735485982\n",
      "      - -206307.1680640506\n",
      "      - -205856.553466837\n",
      "      - -201544.15661035787\n",
      "      - -206639.3754649981\n",
      "      - -202189.74239536907\n",
      "      - -205168.03398224124\n",
      "      - -200976.03713910555\n",
      "      - -204806.4378091252\n",
      "      - -205232.28676908085\n",
      "      - -206935.7083593234\n",
      "      - -203883.61842039385\n",
      "      - -204093.84772917026\n",
      "      - -207682.55443141106\n",
      "      - -198495.85079742127\n",
      "      - -203873.5616365789\n",
      "      - -201608.45817391772\n",
      "      - -204985.0117509397\n",
      "      - -202247.1342483438\n",
      "      - -203828.18530291287\n",
      "      - -209009.2529878167\n",
      "      - -197986.91388865016\n",
      "      - -207185.83257851296\n",
      "      - -204592.88001631884\n",
      "      - -205289.0384120652\n",
      "      - -205071.03609790275\n",
      "      - -202446.9158009478\n",
      "      - -207575.26010622183\n",
      "      - -203343.29276015118\n",
      "      - -200789.1909157423\n",
      "      - -200870.90765308213\n",
      "      - -207191.6927447727\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09535421498035841\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.47132802745076174\n",
      "      mean_inference_ms: 0.9693002040329799\n",
      "      mean_raw_obs_processing_ms: 0.13506532425663878\n",
      "  time_since_restore: 807.6771402359009\n",
      "  time_this_iter_s: 9.795982360839844\n",
      "  time_total_s: 807.6771402359009\n",
      "  timers:\n",
      "    learn_throughput: 119524.457\n",
      "    learn_time_ms: 535.321\n",
      "    load_throughput: 21411229.227\n",
      "    load_time_ms: 2.988\n",
      "    training_iteration_time_ms: 9476.785\n",
      "    update_time_ms: 4.072\n",
      "  timestamp: 1665849553\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5374656\n",
      "  training_iteration: 84\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:59:18 (running for 00:13:53.00)<br>Memory usage on this node: 13.6/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    84</td><td style=\"text-align: right;\">         807.677</td><td style=\"text-align: right;\">5374656</td><td style=\"text-align: right;\"> -205408</td><td style=\"text-align: right;\">             -197987</td><td style=\"text-align: right;\">             -216930</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 5438640\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 5438640\n",
      "    num_agent_steps_trained: 5438640\n",
      "    num_env_steps_sampled: 5438640\n",
      "    num_env_steps_trained: 5438640\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-59-22\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -197986.91388865016\n",
      "  episode_reward_mean: -204443.4410009335\n",
      "  episode_reward_min: -210602.09631121613\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 5436\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1672050952911377\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0005593117675743997\n",
      "          model: {}\n",
      "          policy_loss: 0.0035071438178420067\n",
      "          total_loss: 10.003302574157715\n",
      "          vf_explained_var: -2.176042634971509e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 5438640\n",
      "    num_agent_steps_trained: 5438640\n",
      "    num_env_steps_sampled: 5438640\n",
      "    num_env_steps_trained: 5438640\n",
      "  iterations_since_restore: 85\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 5438640\n",
      "  num_agent_steps_trained: 5438640\n",
      "  num_env_steps_sampled: 5438640\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 5438640\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 80.11428571428571\n",
      "    ram_util_percent: 88.0357142857143\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09527270463755749\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.47095227333383727\n",
      "    mean_inference_ms: 0.9696168399141605\n",
      "    mean_raw_obs_processing_ms: 0.13486698730046037\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -197986.91388865016\n",
      "    episode_reward_mean: -204443.4410009335\n",
      "    episode_reward_min: -210602.09631121613\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -206639.3754649981\n",
      "      - -202189.74239536907\n",
      "      - -205168.03398224124\n",
      "      - -200976.03713910555\n",
      "      - -204806.4378091252\n",
      "      - -205232.28676908085\n",
      "      - -206935.7083593234\n",
      "      - -203883.61842039385\n",
      "      - -204093.84772917026\n",
      "      - -207682.55443141106\n",
      "      - -198495.85079742127\n",
      "      - -203873.5616365789\n",
      "      - -201608.45817391772\n",
      "      - -204985.0117509397\n",
      "      - -202247.1342483438\n",
      "      - -203828.18530291287\n",
      "      - -209009.2529878167\n",
      "      - -197986.91388865016\n",
      "      - -207185.83257851296\n",
      "      - -204592.88001631884\n",
      "      - -205289.0384120652\n",
      "      - -205071.03609790275\n",
      "      - -202446.9158009478\n",
      "      - -207575.26010622183\n",
      "      - -203343.29276015118\n",
      "      - -200789.1909157423\n",
      "      - -200870.90765308213\n",
      "      - -207191.6927447727\n",
      "      - -204070.23019755984\n",
      "      - -206070.8448078451\n",
      "      - -204646.15044140592\n",
      "      - -201142.51762497533\n",
      "      - -203810.3442839803\n",
      "      - -203630.30146048177\n",
      "      - -206119.13483477815\n",
      "      - -204239.6834259704\n",
      "      - -201604.8959174155\n",
      "      - -205105.92938946307\n",
      "      - -203515.67925426087\n",
      "      - -204191.28845428344\n",
      "      - -203525.72603391175\n",
      "      - -205654.71368319177\n",
      "      - -201083.90835157115\n",
      "      - -208482.09540649923\n",
      "      - -203363.40903642488\n",
      "      - -202861.26120348068\n",
      "      - -205903.19174887286\n",
      "      - -205824.72469854826\n",
      "      - -205626.30887944077\n",
      "      - -205335.9178768588\n",
      "      - -206048.02540259645\n",
      "      - -200442.45330298162\n",
      "      - -206476.72032722144\n",
      "      - -205570.69750015473\n",
      "      - -204230.47833053433\n",
      "      - -207564.81082894353\n",
      "      - -205941.5894637098\n",
      "      - -208106.00874113565\n",
      "      - -203262.04860513064\n",
      "      - -204906.63009990897\n",
      "      - -201889.5208238627\n",
      "      - -204478.4038757734\n",
      "      - -204828.03726786445\n",
      "      - -204650.26286025776\n",
      "      - -203495.92169319457\n",
      "      - -207814.24623029018\n",
      "      - -203287.65329664358\n",
      "      - -206176.95227026343\n",
      "      - -204821.75923539142\n",
      "      - -205262.23772356217\n",
      "      - -201730.37005807058\n",
      "      - -203503.856081429\n",
      "      - -202749.24387256952\n",
      "      - -208016.6624451035\n",
      "      - -202605.3942371543\n",
      "      - -206536.6632759786\n",
      "      - -205273.06055694126\n",
      "      - -210602.09631121613\n",
      "      - -199916.41509120396\n",
      "      - -203501.40464949745\n",
      "      - -201553.98727886146\n",
      "      - -204426.6044284692\n",
      "      - -204442.55119286713\n",
      "      - -204415.01246856694\n",
      "      - -205500.32594167648\n",
      "      - -204945.14550300446\n",
      "      - -203902.90542618503\n",
      "      - -202693.46304435004\n",
      "      - -205175.48755731975\n",
      "      - -204546.85302528058\n",
      "      - -202692.2390252598\n",
      "      - -205970.2383821489\n",
      "      - -204718.78445273224\n",
      "      - -206622.9782309483\n",
      "      - -208343.82123010146\n",
      "      - -205265.3641846731\n",
      "      - -203230.15297252245\n",
      "      - -202837.86890688862\n",
      "      - -205094.8758510745\n",
      "      - -204469.50114809436\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09527270463755749\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.47095227333383727\n",
      "      mean_inference_ms: 0.9696168399141605\n",
      "      mean_raw_obs_processing_ms: 0.13486698730046037\n",
      "  time_since_restore: 817.077094078064\n",
      "  time_this_iter_s: 9.399953842163086\n",
      "  time_total_s: 817.077094078064\n",
      "  timers:\n",
      "    learn_throughput: 119355.68\n",
      "    learn_time_ms: 536.078\n",
      "    load_throughput: 21449391.141\n",
      "    load_time_ms: 2.983\n",
      "    training_iteration_time_ms: 9465.873\n",
      "    update_time_ms: 4.03\n",
      "  timestamp: 1665849562\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5438640\n",
      "  training_iteration: 85\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:59:28 (running for 00:14:02.48)<br>Memory usage on this node: 13.6/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    85</td><td style=\"text-align: right;\">         817.077</td><td style=\"text-align: right;\">5438640</td><td style=\"text-align: right;\"> -204443</td><td style=\"text-align: right;\">             -197987</td><td style=\"text-align: right;\">             -210602</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 5502624\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 5502624\n",
      "    num_agent_steps_trained: 5502624\n",
      "    num_env_steps_sampled: 5502624\n",
      "    num_env_steps_trained: 5502624\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-59-32\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -199916.41509120396\n",
      "  episode_reward_mean: -205676.30206225548\n",
      "  episode_reward_min: -245934.1166822318\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 5496\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1619317531585693\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0005424089031293988\n",
      "          model: {}\n",
      "          policy_loss: 0.00674948887899518\n",
      "          total_loss: 10.006540298461914\n",
      "          vf_explained_var: -3.500590395333347e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 5502624\n",
      "    num_agent_steps_trained: 5502624\n",
      "    num_env_steps_sampled: 5502624\n",
      "    num_env_steps_trained: 5502624\n",
      "  iterations_since_restore: 86\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 5502624\n",
      "  num_agent_steps_trained: 5502624\n",
      "  num_env_steps_sampled: 5502624\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 5502624\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.00769230769232\n",
      "    ram_util_percent: 88.06153846153848\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09533944122550224\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.47085048216544806\n",
      "    mean_inference_ms: 0.9692652381261315\n",
      "    mean_raw_obs_processing_ms: 0.13502053848865708\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -199916.41509120396\n",
      "    episode_reward_mean: -205676.30206225548\n",
      "    episode_reward_min: -245934.1166822318\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -201889.5208238627\n",
      "      - -204478.4038757734\n",
      "      - -204828.03726786445\n",
      "      - -204650.26286025776\n",
      "      - -203495.92169319457\n",
      "      - -207814.24623029018\n",
      "      - -203287.65329664358\n",
      "      - -206176.95227026343\n",
      "      - -204821.75923539142\n",
      "      - -205262.23772356217\n",
      "      - -201730.37005807058\n",
      "      - -203503.856081429\n",
      "      - -202749.24387256952\n",
      "      - -208016.6624451035\n",
      "      - -202605.3942371543\n",
      "      - -206536.6632759786\n",
      "      - -205273.06055694126\n",
      "      - -210602.09631121613\n",
      "      - -199916.41509120396\n",
      "      - -203501.40464949745\n",
      "      - -201553.98727886146\n",
      "      - -204426.6044284692\n",
      "      - -204442.55119286713\n",
      "      - -204415.01246856694\n",
      "      - -205500.32594167648\n",
      "      - -204945.14550300446\n",
      "      - -203902.90542618503\n",
      "      - -202693.46304435004\n",
      "      - -205175.48755731975\n",
      "      - -204546.85302528058\n",
      "      - -202692.2390252598\n",
      "      - -205970.2383821489\n",
      "      - -204718.78445273224\n",
      "      - -206622.9782309483\n",
      "      - -208343.82123010146\n",
      "      - -205265.3641846731\n",
      "      - -203230.15297252245\n",
      "      - -202837.86890688862\n",
      "      - -205094.8758510745\n",
      "      - -204469.50114809436\n",
      "      - -206914.20649678027\n",
      "      - -201109.41956244738\n",
      "      - -204975.89556981248\n",
      "      - -205431.4127034853\n",
      "      - -203885.61257852174\n",
      "      - -201639.13036788098\n",
      "      - -206090.0610993012\n",
      "      - -202366.19574792593\n",
      "      - -206865.0053993284\n",
      "      - -209443.7518588043\n",
      "      - -206974.7203667489\n",
      "      - -201860.27764349632\n",
      "      - -209317.3792420016\n",
      "      - -206653.2609667453\n",
      "      - -202652.45334253222\n",
      "      - -210559.39127536427\n",
      "      - -203515.71382427582\n",
      "      - -206188.68648754826\n",
      "      - -207232.7072953867\n",
      "      - -206858.19645550122\n",
      "      - -209896.2999347176\n",
      "      - -203610.49679926017\n",
      "      - -202462.94151355966\n",
      "      - -203140.9064381055\n",
      "      - -205089.1725291427\n",
      "      - -203601.8900204825\n",
      "      - -236468.0434202405\n",
      "      - -201475.1987678901\n",
      "      - -205291.53599463272\n",
      "      - -202827.20431336417\n",
      "      - -203764.50109485956\n",
      "      - -207344.62995701548\n",
      "      - -206919.8789126306\n",
      "      - -203325.0608542317\n",
      "      - -201950.48535802445\n",
      "      - -203753.58484215924\n",
      "      - -205039.12285350464\n",
      "      - -207283.4444109861\n",
      "      - -207140.07335933982\n",
      "      - -204010.54741702965\n",
      "      - -206997.61224981755\n",
      "      - -205968.74964037922\n",
      "      - -206734.63177800376\n",
      "      - -204243.58014445665\n",
      "      - -205315.58264433008\n",
      "      - -202260.91550887155\n",
      "      - -203097.81488087273\n",
      "      - -207717.28565355414\n",
      "      - -208981.12765057548\n",
      "      - -206119.95396845124\n",
      "      - -201272.85292922187\n",
      "      - -207459.21664577187\n",
      "      - -203797.39110559723\n",
      "      - -206976.713626108\n",
      "      - -200263.35977871495\n",
      "      - -208228.58634709785\n",
      "      - -245934.1166822318\n",
      "      - -206952.75158348426\n",
      "      - -207944.52033664437\n",
      "      - -204446.62388900534\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09533944122550224\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.47085048216544806\n",
      "      mean_inference_ms: 0.9692652381261315\n",
      "      mean_raw_obs_processing_ms: 0.13502053848865708\n",
      "  time_since_restore: 826.423276424408\n",
      "  time_this_iter_s: 9.346182346343994\n",
      "  time_total_s: 826.423276424408\n",
      "  timers:\n",
      "    learn_throughput: 129371.745\n",
      "    learn_time_ms: 494.575\n",
      "    load_throughput: 21525606.553\n",
      "    load_time_ms: 2.972\n",
      "    training_iteration_time_ms: 9462.694\n",
      "    update_time_ms: 3.995\n",
      "  timestamp: 1665849572\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5502624\n",
      "  training_iteration: 86\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:59:37 (running for 00:14:12.33)<br>Memory usage on this node: 13.6/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    86</td><td style=\"text-align: right;\">         826.423</td><td style=\"text-align: right;\">5502624</td><td style=\"text-align: right;\"> -205676</td><td style=\"text-align: right;\">             -199916</td><td style=\"text-align: right;\">             -245934</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:59:42 (running for 00:14:17.34)<br>Memory usage on this node: 13.7/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    86</td><td style=\"text-align: right;\">         826.423</td><td style=\"text-align: right;\">5502624</td><td style=\"text-align: right;\"> -205676</td><td style=\"text-align: right;\">             -199916</td><td style=\"text-align: right;\">             -245934</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 5566608\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 5566608\n",
      "    num_agent_steps_trained: 5566608\n",
      "    num_env_steps_sampled: 5566608\n",
      "    num_env_steps_trained: 5566608\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-59-43\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -200263.35977871495\n",
      "  episode_reward_mean: -205873.27080879902\n",
      "  episode_reward_min: -245934.1166822318\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 5556\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.163386344909668\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0005775976460427046\n",
      "          model: {}\n",
      "          policy_loss: 0.0017817853949964046\n",
      "          total_loss: 10.001582145690918\n",
      "          vf_explained_var: -2.7437058847112894e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 5566608\n",
      "    num_agent_steps_trained: 5566608\n",
      "    num_env_steps_sampled: 5566608\n",
      "    num_env_steps_trained: 5566608\n",
      "  iterations_since_restore: 87\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 5566608\n",
      "  num_agent_steps_trained: 5566608\n",
      "  num_env_steps_sampled: 5566608\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 5566608\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 85.56666666666665\n",
      "    ram_util_percent: 88.13333333333334\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0952992893382671\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4714079195836536\n",
      "    mean_inference_ms: 0.9698774918325622\n",
      "    mean_raw_obs_processing_ms: 0.13507945762356202\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -200263.35977871495\n",
      "    episode_reward_mean: -205873.27080879902\n",
      "    episode_reward_min: -245934.1166822318\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -209896.2999347176\n",
      "      - -203610.49679926017\n",
      "      - -202462.94151355966\n",
      "      - -203140.9064381055\n",
      "      - -205089.1725291427\n",
      "      - -203601.8900204825\n",
      "      - -236468.0434202405\n",
      "      - -201475.1987678901\n",
      "      - -205291.53599463272\n",
      "      - -202827.20431336417\n",
      "      - -203764.50109485956\n",
      "      - -207344.62995701548\n",
      "      - -206919.8789126306\n",
      "      - -203325.0608542317\n",
      "      - -201950.48535802445\n",
      "      - -203753.58484215924\n",
      "      - -205039.12285350464\n",
      "      - -207283.4444109861\n",
      "      - -207140.07335933982\n",
      "      - -204010.54741702965\n",
      "      - -206997.61224981755\n",
      "      - -205968.74964037922\n",
      "      - -206734.63177800376\n",
      "      - -204243.58014445665\n",
      "      - -205315.58264433008\n",
      "      - -202260.91550887155\n",
      "      - -203097.81488087273\n",
      "      - -207717.28565355414\n",
      "      - -208981.12765057548\n",
      "      - -206119.95396845124\n",
      "      - -201272.85292922187\n",
      "      - -207459.21664577187\n",
      "      - -203797.39110559723\n",
      "      - -206976.713626108\n",
      "      - -200263.35977871495\n",
      "      - -208228.58634709785\n",
      "      - -245934.1166822318\n",
      "      - -206952.75158348426\n",
      "      - -207944.52033664437\n",
      "      - -204446.62388900534\n",
      "      - -202862.07783783437\n",
      "      - -202839.0170902347\n",
      "      - -203466.26370519595\n",
      "      - -208059.81097263293\n",
      "      - -208018.53687181365\n",
      "      - -211165.47271820574\n",
      "      - -204623.95099065453\n",
      "      - -208060.22366589968\n",
      "      - -206200.52495533752\n",
      "      - -213734.92472041535\n",
      "      - -205408.90304056546\n",
      "      - -207051.25786461952\n",
      "      - -206696.6858147625\n",
      "      - -205812.34234644007\n",
      "      - -204544.95150141357\n",
      "      - -202476.66719569603\n",
      "      - -206279.8716144048\n",
      "      - -206050.0439677024\n",
      "      - -204409.8237870232\n",
      "      - -208287.7225891944\n",
      "      - -207202.33127279955\n",
      "      - -204747.3582775748\n",
      "      - -201136.10642693756\n",
      "      - -204814.26248108558\n",
      "      - -205240.96443157762\n",
      "      - -206133.3188068582\n",
      "      - -207103.4594327375\n",
      "      - -205659.85535972854\n",
      "      - -204979.18946093923\n",
      "      - -203969.87766604713\n",
      "      - -202299.120155703\n",
      "      - -204191.96963365783\n",
      "      - -209556.5354194288\n",
      "      - -200958.41452795043\n",
      "      - -204348.236725459\n",
      "      - -203930.2704436562\n",
      "      - -204652.89413607164\n",
      "      - -200769.73268587058\n",
      "      - -205824.93794998724\n",
      "      - -203998.97611494144\n",
      "      - -207739.7199267455\n",
      "      - -204754.96975408655\n",
      "      - -204034.33678556187\n",
      "      - -203721.24771255488\n",
      "      - -203845.91595826996\n",
      "      - -206430.08015334868\n",
      "      - -206774.33444615043\n",
      "      - -204176.63268049972\n",
      "      - -204109.49725806885\n",
      "      - -203839.44565034847\n",
      "      - -203144.06292443365\n",
      "      - -206796.43893517033\n",
      "      - -204297.08805475055\n",
      "      - -205556.3410689747\n",
      "      - -207215.67282710434\n",
      "      - -204345.13061353294\n",
      "      - -204248.5849328439\n",
      "      - -204806.8661332539\n",
      "      - -204185.06280226252\n",
      "      - -200630.36176851424\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.0952992893382671\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4714079195836536\n",
      "      mean_inference_ms: 0.9698774918325622\n",
      "      mean_raw_obs_processing_ms: 0.13507945762356202\n",
      "  time_since_restore: 837.059972524643\n",
      "  time_this_iter_s: 10.636696100234985\n",
      "  time_total_s: 837.059972524643\n",
      "  timers:\n",
      "    learn_throughput: 128854.29\n",
      "    learn_time_ms: 496.561\n",
      "    load_throughput: 21585511.481\n",
      "    load_time_ms: 2.964\n",
      "    training_iteration_time_ms: 9637.982\n",
      "    update_time_ms: 4.202\n",
      "  timestamp: 1665849583\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5566608\n",
      "  training_iteration: 87\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:59:48 (running for 00:14:22.61)<br>Memory usage on this node: 13.6/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    87</td><td style=\"text-align: right;\">          837.06</td><td style=\"text-align: right;\">5566608</td><td style=\"text-align: right;\"> -205873</td><td style=\"text-align: right;\">             -200263</td><td style=\"text-align: right;\">             -245934</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:59:53 (running for 00:14:27.62)<br>Memory usage on this node: 13.6/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    87</td><td style=\"text-align: right;\">          837.06</td><td style=\"text-align: right;\">5566608</td><td style=\"text-align: right;\"> -205873</td><td style=\"text-align: right;\">             -200263</td><td style=\"text-align: right;\">             -245934</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 5630592\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 5630592\n",
      "    num_agent_steps_trained: 5630592\n",
      "    num_env_steps_sampled: 5630592\n",
      "    num_env_steps_trained: 5630592\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_17-59-53\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -199541.4655563403\n",
      "  episode_reward_mean: -205031.02766073932\n",
      "  episode_reward_min: -226212.44300665898\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 5628\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1645755767822266\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0006093898555263877\n",
      "          model: {}\n",
      "          policy_loss: 0.003484750632196665\n",
      "          total_loss: 10.003289222717285\n",
      "          vf_explained_var: -3.689811478579941e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 5630592\n",
      "    num_agent_steps_trained: 5630592\n",
      "    num_env_steps_sampled: 5630592\n",
      "    num_env_steps_trained: 5630592\n",
      "  iterations_since_restore: 88\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 5630592\n",
      "  num_agent_steps_trained: 5630592\n",
      "  num_env_steps_sampled: 5630592\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 5630592\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 86.23571428571428\n",
      "    ram_util_percent: 88.43571428571428\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09537933347075349\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4714529208316007\n",
      "    mean_inference_ms: 0.9713858238867633\n",
      "    mean_raw_obs_processing_ms: 0.1350987671811276\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -199541.4655563403\n",
      "    episode_reward_mean: -205031.02766073932\n",
      "    episode_reward_min: -226212.44300665898\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -209556.5354194288\n",
      "      - -200958.41452795043\n",
      "      - -204348.236725459\n",
      "      - -203930.2704436562\n",
      "      - -204652.89413607164\n",
      "      - -200769.73268587058\n",
      "      - -205824.93794998724\n",
      "      - -203998.97611494144\n",
      "      - -207739.7199267455\n",
      "      - -204754.96975408655\n",
      "      - -204034.33678556187\n",
      "      - -203721.24771255488\n",
      "      - -203845.91595826996\n",
      "      - -206430.08015334868\n",
      "      - -206774.33444615043\n",
      "      - -204176.63268049972\n",
      "      - -204109.49725806885\n",
      "      - -203839.44565034847\n",
      "      - -203144.06292443365\n",
      "      - -206796.43893517033\n",
      "      - -204297.08805475055\n",
      "      - -205556.3410689747\n",
      "      - -207215.67282710434\n",
      "      - -204345.13061353294\n",
      "      - -204248.5849328439\n",
      "      - -204806.8661332539\n",
      "      - -204185.06280226252\n",
      "      - -200630.36176851424\n",
      "      - -202511.7621369282\n",
      "      - -203025.19381083912\n",
      "      - -199541.4655563403\n",
      "      - -209394.12280415103\n",
      "      - -204274.6166840779\n",
      "      - -208345.3736457245\n",
      "      - -204760.5563315293\n",
      "      - -201966.75154086444\n",
      "      - -203500.30975983906\n",
      "      - -209212.23447234186\n",
      "      - -226212.44300665898\n",
      "      - -209104.47444144156\n",
      "      - -213512.74531237237\n",
      "      - -204599.94055644737\n",
      "      - -204917.13151659063\n",
      "      - -202523.43786695442\n",
      "      - -209350.19813754866\n",
      "      - -202111.7249869488\n",
      "      - -205632.94376550513\n",
      "      - -202264.9858126906\n",
      "      - -203521.62406455755\n",
      "      - -205301.81607474797\n",
      "      - -200239.307204336\n",
      "      - -204005.4329488446\n",
      "      - -202835.6329833153\n",
      "      - -205374.94934075422\n",
      "      - -206887.87633388312\n",
      "      - -204827.23373708755\n",
      "      - -200870.52268281995\n",
      "      - -201089.85704830306\n",
      "      - -205863.48459288327\n",
      "      - -205036.86829632433\n",
      "      - -209155.38545717348\n",
      "      - -203863.9568169518\n",
      "      - -204989.725046335\n",
      "      - -203726.93246289628\n",
      "      - -204865.4295008403\n",
      "      - -202258.88326332433\n",
      "      - -206539.38718343328\n",
      "      - -204950.2265250307\n",
      "      - -209020.66540895155\n",
      "      - -205702.1121202009\n",
      "      - -205816.52571277317\n",
      "      - -202581.39342290472\n",
      "      - -206704.2826268015\n",
      "      - -199997.3034888578\n",
      "      - -201995.4904890723\n",
      "      - -209293.59801448093\n",
      "      - -210260.02359390465\n",
      "      - -204668.15770929397\n",
      "      - -203864.40867183008\n",
      "      - -201208.61353550656\n",
      "      - -206002.72276786887\n",
      "      - -205536.36265663418\n",
      "      - -204636.849790567\n",
      "      - -207545.51951408814\n",
      "      - -208319.1884280059\n",
      "      - -206823.8370364322\n",
      "      - -203918.80440744426\n",
      "      - -203920.08013845666\n",
      "      - -206528.59591261516\n",
      "      - -201737.1395083156\n",
      "      - -207495.32881495537\n",
      "      - -206684.51052198734\n",
      "      - -200332.09097038\n",
      "      - -202437.12001476026\n",
      "      - -204818.2596004211\n",
      "      - -204388.60718654134\n",
      "      - -200313.3476440554\n",
      "      - -209581.7097989712\n",
      "      - -202520.12609070627\n",
      "      - -206791.25837666818\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09537933347075349\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4714529208316007\n",
      "      mean_inference_ms: 0.9713858238867633\n",
      "      mean_raw_obs_processing_ms: 0.1350987671811276\n",
      "  time_since_restore: 847.3459143638611\n",
      "  time_this_iter_s: 10.28594183921814\n",
      "  time_total_s: 847.3459143638611\n",
      "  timers:\n",
      "    learn_throughput: 128089.123\n",
      "    learn_time_ms: 499.527\n",
      "    load_throughput: 21590894.964\n",
      "    load_time_ms: 2.963\n",
      "    training_iteration_time_ms: 9719.589\n",
      "    update_time_ms: 4.116\n",
      "  timestamp: 1665849593\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5630592\n",
      "  training_iteration: 88\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 17:59:58 (running for 00:14:32.94)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    88</td><td style=\"text-align: right;\">         847.346</td><td style=\"text-align: right;\">5630592</td><td style=\"text-align: right;\"> -205031</td><td style=\"text-align: right;\">             -199541</td><td style=\"text-align: right;\">             -226212</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:00:03 (running for 00:14:37.95)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    88</td><td style=\"text-align: right;\">         847.346</td><td style=\"text-align: right;\">5630592</td><td style=\"text-align: right;\"> -205031</td><td style=\"text-align: right;\">             -199541</td><td style=\"text-align: right;\">             -226212</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 5694576\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 5694576\n",
      "    num_agent_steps_trained: 5694576\n",
      "    num_env_steps_sampled: 5694576\n",
      "    num_env_steps_trained: 5694576\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-00-03\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -198714.20763095247\n",
      "  episode_reward_mean: -204706.9049491493\n",
      "  episode_reward_min: -217826.79932011658\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 5688\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.164236068725586\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0005631299572996795\n",
      "          model: {}\n",
      "          policy_loss: 0.006756358314305544\n",
      "          total_loss: 10.006550788879395\n",
      "          vf_explained_var: -3.500590395333347e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 5694576\n",
      "    num_agent_steps_trained: 5694576\n",
      "    num_env_steps_sampled: 5694576\n",
      "    num_env_steps_trained: 5694576\n",
      "  iterations_since_restore: 89\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 5694576\n",
      "  num_agent_steps_trained: 5694576\n",
      "  num_env_steps_sampled: 5694576\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 5694576\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.29999999999998\n",
      "    ram_util_percent: 89.24666666666667\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09557477990097425\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.47179748575142194\n",
      "    mean_inference_ms: 0.9722714225741982\n",
      "    mean_raw_obs_processing_ms: 0.13544384788599995\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -198714.20763095247\n",
      "    episode_reward_mean: -204706.9049491493\n",
      "    episode_reward_min: -217826.79932011658\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -209155.38545717348\n",
      "      - -203863.9568169518\n",
      "      - -204989.725046335\n",
      "      - -203726.93246289628\n",
      "      - -204865.4295008403\n",
      "      - -202258.88326332433\n",
      "      - -206539.38718343328\n",
      "      - -204950.2265250307\n",
      "      - -209020.66540895155\n",
      "      - -205702.1121202009\n",
      "      - -205816.52571277317\n",
      "      - -202581.39342290472\n",
      "      - -206704.2826268015\n",
      "      - -199997.3034888578\n",
      "      - -201995.4904890723\n",
      "      - -209293.59801448093\n",
      "      - -210260.02359390465\n",
      "      - -204668.15770929397\n",
      "      - -203864.40867183008\n",
      "      - -201208.61353550656\n",
      "      - -206002.72276786887\n",
      "      - -205536.36265663418\n",
      "      - -204636.849790567\n",
      "      - -207545.51951408814\n",
      "      - -208319.1884280059\n",
      "      - -206823.8370364322\n",
      "      - -203918.80440744426\n",
      "      - -203920.08013845666\n",
      "      - -206528.59591261516\n",
      "      - -201737.1395083156\n",
      "      - -207495.32881495537\n",
      "      - -206684.51052198734\n",
      "      - -200332.09097038\n",
      "      - -202437.12001476026\n",
      "      - -204818.2596004211\n",
      "      - -204388.60718654134\n",
      "      - -200313.3476440554\n",
      "      - -209581.7097989712\n",
      "      - -202520.12609070627\n",
      "      - -206791.25837666818\n",
      "      - -201192.2252992619\n",
      "      - -202804.3214998217\n",
      "      - -200949.06795498962\n",
      "      - -204933.4266372364\n",
      "      - -201288.08843207726\n",
      "      - -207781.50779010713\n",
      "      - -205100.5453572471\n",
      "      - -200335.49929237965\n",
      "      - -211784.5886680087\n",
      "      - -201879.61337627028\n",
      "      - -211176.8728079719\n",
      "      - -203498.92523396527\n",
      "      - -205735.44022265615\n",
      "      - -204906.9122145992\n",
      "      - -204773.72260574435\n",
      "      - -200883.57741135353\n",
      "      - -201111.43838527027\n",
      "      - -217826.79932011658\n",
      "      - -204221.0565411355\n",
      "      - -204694.92193806052\n",
      "      - -204383.4422187994\n",
      "      - -206156.40942214106\n",
      "      - -207306.6631586222\n",
      "      - -206272.83079156882\n",
      "      - -206893.60864696145\n",
      "      - -202317.82479776346\n",
      "      - -204943.54653504948\n",
      "      - -205143.35223633298\n",
      "      - -203896.54493263247\n",
      "      - -205152.3868995404\n",
      "      - -201230.8339562748\n",
      "      - -198714.20763095247\n",
      "      - -202252.26533590615\n",
      "      - -202749.58630419397\n",
      "      - -199886.88697364935\n",
      "      - -201387.9009742979\n",
      "      - -203135.6094464207\n",
      "      - -205221.236439364\n",
      "      - -199992.8870084371\n",
      "      - -209645.52156228904\n",
      "      - -202113.27390297264\n",
      "      - -206358.72637590315\n",
      "      - -208119.08876439408\n",
      "      - -203569.4328154714\n",
      "      - -206288.40387415365\n",
      "      - -207794.41877753878\n",
      "      - -203034.9278373057\n",
      "      - -201480.41544791876\n",
      "      - -204675.41213157855\n",
      "      - -204824.78412193112\n",
      "      - -207584.90584737825\n",
      "      - -205342.85334361487\n",
      "      - -209576.3709585776\n",
      "      - -205332.87825733738\n",
      "      - -201661.87685737005\n",
      "      - -203912.98162566792\n",
      "      - -200978.3214906887\n",
      "      - -203349.69829506692\n",
      "      - -204085.3911001647\n",
      "      - -205250.27659998366\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09557477990097425\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.47179748575142194\n",
      "      mean_inference_ms: 0.9722714225741982\n",
      "      mean_raw_obs_processing_ms: 0.13544384788599995\n",
      "  time_since_restore: 857.884076833725\n",
      "  time_this_iter_s: 10.538162469863892\n",
      "  time_total_s: 857.884076833725\n",
      "  timers:\n",
      "    learn_throughput: 128795.585\n",
      "    learn_time_ms: 496.787\n",
      "    load_throughput: 21577007.577\n",
      "    load_time_ms: 2.965\n",
      "    training_iteration_time_ms: 9810.656\n",
      "    update_time_ms: 4.2\n",
      "  timestamp: 1665849603\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5694576\n",
      "  training_iteration: 89\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:00:09 (running for 00:14:43.93)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    89</td><td style=\"text-align: right;\">         857.884</td><td style=\"text-align: right;\">5694576</td><td style=\"text-align: right;\"> -204707</td><td style=\"text-align: right;\">             -198714</td><td style=\"text-align: right;\">             -217827</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 5758560\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 5758560\n",
      "    num_agent_steps_trained: 5758560\n",
      "    num_env_steps_sampled: 5758560\n",
      "    num_env_steps_trained: 5758560\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-00-13\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -198714.20763095247\n",
      "  episode_reward_mean: -204243.08680619925\n",
      "  episode_reward_min: -212576.95014575298\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 5748\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1601064205169678\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0004892592551186681\n",
      "          model: {}\n",
      "          policy_loss: 0.001644402858801186\n",
      "          total_loss: 10.001425743103027\n",
      "          vf_explained_var: -4.635916894812908e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 5758560\n",
      "    num_agent_steps_trained: 5758560\n",
      "    num_env_steps_sampled: 5758560\n",
      "    num_env_steps_trained: 5758560\n",
      "  iterations_since_restore: 90\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 5758560\n",
      "  num_agent_steps_trained: 5758560\n",
      "  num_env_steps_sampled: 5758560\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 5758560\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.03846153846153\n",
      "    ram_util_percent: 89.32307692307693\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09548575851164777\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.47215939740491847\n",
      "    mean_inference_ms: 0.9722788709377493\n",
      "    mean_raw_obs_processing_ms: 0.1354362264696221\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -198714.20763095247\n",
      "    episode_reward_mean: -204243.08680619925\n",
      "    episode_reward_min: -212576.95014575298\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -204383.4422187994\n",
      "      - -206156.40942214106\n",
      "      - -207306.6631586222\n",
      "      - -206272.83079156882\n",
      "      - -206893.60864696145\n",
      "      - -202317.82479776346\n",
      "      - -204943.54653504948\n",
      "      - -205143.35223633298\n",
      "      - -203896.54493263247\n",
      "      - -205152.3868995404\n",
      "      - -201230.8339562748\n",
      "      - -198714.20763095247\n",
      "      - -202252.26533590615\n",
      "      - -202749.58630419397\n",
      "      - -199886.88697364935\n",
      "      - -201387.9009742979\n",
      "      - -203135.6094464207\n",
      "      - -205221.236439364\n",
      "      - -199992.8870084371\n",
      "      - -209645.52156228904\n",
      "      - -202113.27390297264\n",
      "      - -206358.72637590315\n",
      "      - -208119.08876439408\n",
      "      - -203569.4328154714\n",
      "      - -206288.40387415365\n",
      "      - -207794.41877753878\n",
      "      - -203034.9278373057\n",
      "      - -201480.41544791876\n",
      "      - -204675.41213157855\n",
      "      - -204824.78412193112\n",
      "      - -207584.90584737825\n",
      "      - -205342.85334361487\n",
      "      - -209576.3709585776\n",
      "      - -205332.87825733738\n",
      "      - -201661.87685737005\n",
      "      - -203912.98162566792\n",
      "      - -200978.3214906887\n",
      "      - -203349.69829506692\n",
      "      - -204085.3911001647\n",
      "      - -205250.27659998366\n",
      "      - -209808.57925463232\n",
      "      - -204412.29277075804\n",
      "      - -199497.73760847628\n",
      "      - -199223.00868824794\n",
      "      - -203100.55849960542\n",
      "      - -202644.7788540968\n",
      "      - -206959.83038212603\n",
      "      - -199730.40950196297\n",
      "      - -199917.7056507744\n",
      "      - -203054.3399008363\n",
      "      - -207586.87907220368\n",
      "      - -205506.19777396502\n",
      "      - -204830.6644553946\n",
      "      - -204194.1477556414\n",
      "      - -204696.6499475368\n",
      "      - -208677.1093307022\n",
      "      - -203362.9982764624\n",
      "      - -203923.07699846473\n",
      "      - -202210.13369767473\n",
      "      - -204289.72141476566\n",
      "      - -201401.67974013812\n",
      "      - -204757.43759252486\n",
      "      - -206943.4720625896\n",
      "      - -206264.8138387684\n",
      "      - -201797.35162163954\n",
      "      - -206396.21082659837\n",
      "      - -205726.74785014248\n",
      "      - -202206.80866808738\n",
      "      - -203531.85823518093\n",
      "      - -200330.55578996637\n",
      "      - -202457.2238683467\n",
      "      - -200800.14834864665\n",
      "      - -204091.29325626924\n",
      "      - -201633.74432439945\n",
      "      - -202570.42558351462\n",
      "      - -204404.637602724\n",
      "      - -199725.8778179619\n",
      "      - -208601.45639888637\n",
      "      - -202438.84106602147\n",
      "      - -205473.1808498835\n",
      "      - -203829.65142881768\n",
      "      - -201600.02772086873\n",
      "      - -206174.600966057\n",
      "      - -207280.10386916238\n",
      "      - -203315.85248766295\n",
      "      - -204490.9961773761\n",
      "      - -205638.4574124801\n",
      "      - -204144.2805198292\n",
      "      - -208493.6799974642\n",
      "      - -212576.95014575298\n",
      "      - -201593.5967384574\n",
      "      - -203917.3405969759\n",
      "      - -204714.03299177327\n",
      "      - -202613.5009961488\n",
      "      - -207769.68156679277\n",
      "      - -206818.98225315704\n",
      "      - -203647.07088061963\n",
      "      - -204624.94035764682\n",
      "      - -204558.3951070696\n",
      "      - -205307.9695329828\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09548575851164777\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.47215939740491847\n",
      "      mean_inference_ms: 0.9722788709377493\n",
      "      mean_raw_obs_processing_ms: 0.1354362264696221\n",
      "  time_since_restore: 866.9967818260193\n",
      "  time_this_iter_s: 9.112704992294312\n",
      "  time_total_s: 866.9967818260193\n",
      "  timers:\n",
      "    learn_throughput: 128909.865\n",
      "    learn_time_ms: 496.347\n",
      "    load_throughput: 21516459.719\n",
      "    load_time_ms: 2.974\n",
      "    training_iteration_time_ms: 9784.756\n",
      "    update_time_ms: 4.166\n",
      "  timestamp: 1665849613\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5758560\n",
      "  training_iteration: 90\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:00:18 (running for 00:14:52.85)<br>Memory usage on this node: 13.7/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    90</td><td style=\"text-align: right;\">         866.997</td><td style=\"text-align: right;\">5758560</td><td style=\"text-align: right;\"> -204243</td><td style=\"text-align: right;\">             -198714</td><td style=\"text-align: right;\">             -212577</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 5822544\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 5822544\n",
      "    num_agent_steps_trained: 5822544\n",
      "    num_env_steps_sampled: 5822544\n",
      "    num_env_steps_trained: 5822544\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-00-22\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -199725.8778179619\n",
      "  episode_reward_mean: -203973.1144210914\n",
      "  episode_reward_min: -212576.95014575298\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 5820\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1550726890563965\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0006179846823215485\n",
      "          model: {}\n",
      "          policy_loss: 0.00283757783472538\n",
      "          total_loss: 10.002644538879395\n",
      "          vf_explained_var: -4.635916894812908e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 5822544\n",
      "    num_agent_steps_trained: 5822544\n",
      "    num_env_steps_sampled: 5822544\n",
      "    num_env_steps_trained: 5822544\n",
      "  iterations_since_restore: 91\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 5822544\n",
      "  num_agent_steps_trained: 5822544\n",
      "  num_env_steps_sampled: 5822544\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 5822544\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.61538461538461\n",
      "    ram_util_percent: 88.4076923076923\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09539531759189142\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.47170744004858833\n",
      "    mean_inference_ms: 0.9720312009434552\n",
      "    mean_raw_obs_processing_ms: 0.13521994408457216\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -199725.8778179619\n",
      "    episode_reward_mean: -203973.1144210914\n",
      "    episode_reward_min: -212576.95014575298\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -204091.29325626924\n",
      "      - -201633.74432439945\n",
      "      - -202570.42558351462\n",
      "      - -204404.637602724\n",
      "      - -199725.8778179619\n",
      "      - -208601.45639888637\n",
      "      - -202438.84106602147\n",
      "      - -205473.1808498835\n",
      "      - -203829.65142881768\n",
      "      - -201600.02772086873\n",
      "      - -206174.600966057\n",
      "      - -207280.10386916238\n",
      "      - -203315.85248766295\n",
      "      - -204490.9961773761\n",
      "      - -205638.4574124801\n",
      "      - -204144.2805198292\n",
      "      - -208493.6799974642\n",
      "      - -212576.95014575298\n",
      "      - -201593.5967384574\n",
      "      - -203917.3405969759\n",
      "      - -204714.03299177327\n",
      "      - -202613.5009961488\n",
      "      - -207769.68156679277\n",
      "      - -206818.98225315704\n",
      "      - -203647.07088061963\n",
      "      - -204624.94035764682\n",
      "      - -204558.3951070696\n",
      "      - -205307.9695329828\n",
      "      - -201479.27966334065\n",
      "      - -200835.62993998427\n",
      "      - -201409.35882824773\n",
      "      - -202359.56994943583\n",
      "      - -202627.3640812876\n",
      "      - -203318.174015443\n",
      "      - -206385.50236697897\n",
      "      - -203685.05998232137\n",
      "      - -209422.9954205065\n",
      "      - -208172.2531927201\n",
      "      - -207451.03703191472\n",
      "      - -204821.1262590588\n",
      "      - -203446.42177693642\n",
      "      - -204563.2174412644\n",
      "      - -202906.1455686229\n",
      "      - -204672.4916410347\n",
      "      - -201665.51244627786\n",
      "      - -204073.47246646916\n",
      "      - -201020.28393772247\n",
      "      - -202788.06675771988\n",
      "      - -202207.27068716864\n",
      "      - -206679.73531353878\n",
      "      - -202301.6152456164\n",
      "      - -202825.25376502483\n",
      "      - -203161.69196834197\n",
      "      - -200830.54817954855\n",
      "      - -202328.4119294533\n",
      "      - -205922.5637980233\n",
      "      - -203546.59760779687\n",
      "      - -203438.34114565456\n",
      "      - -201858.6646232668\n",
      "      - -204499.20657934467\n",
      "      - -199765.49329918087\n",
      "      - -202908.213875861\n",
      "      - -204533.77427851202\n",
      "      - -203917.43586799607\n",
      "      - -209009.70052483855\n",
      "      - -203453.1006864526\n",
      "      - -201792.5443347639\n",
      "      - -203701.48334073933\n",
      "      - -205363.03586624324\n",
      "      - -200332.73814434482\n",
      "      - -199944.92069597734\n",
      "      - -202190.35486375436\n",
      "      - -204547.2348999301\n",
      "      - -201458.01680079577\n",
      "      - -203406.58149971688\n",
      "      - -206390.7372060273\n",
      "      - -205079.22723680417\n",
      "      - -204275.96757999508\n",
      "      - -204672.6573740894\n",
      "      - -201264.58367276692\n",
      "      - -205211.559891274\n",
      "      - -207437.33572114367\n",
      "      - -202567.46660567922\n",
      "      - -203865.50105992454\n",
      "      - -204847.60187675685\n",
      "      - -200457.97291010438\n",
      "      - -201367.9782166454\n",
      "      - -202383.01793877408\n",
      "      - -201469.36032920142\n",
      "      - -207656.57836120675\n",
      "      - -204188.20757729496\n",
      "      - -201575.6815529373\n",
      "      - -203636.05721217938\n",
      "      - -205751.99861977517\n",
      "      - -206550.18266650505\n",
      "      - -202834.2165486135\n",
      "      - -204067.89344750915\n",
      "      - -204229.03459343352\n",
      "      - -204187.21055405206\n",
      "      - -206266.3521205135\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09539531759189142\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.47170744004858833\n",
      "      mean_inference_ms: 0.9720312009434552\n",
      "      mean_raw_obs_processing_ms: 0.13521994408457216\n",
      "  time_since_restore: 876.3631296157837\n",
      "  time_this_iter_s: 9.366347789764404\n",
      "  time_total_s: 876.3631296157837\n",
      "  timers:\n",
      "    learn_throughput: 129292.028\n",
      "    learn_time_ms: 494.88\n",
      "    load_throughput: 21508010.125\n",
      "    load_time_ms: 2.975\n",
      "    training_iteration_time_ms: 9739.097\n",
      "    update_time_ms: 4.194\n",
      "  timestamp: 1665849622\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5822544\n",
      "  training_iteration: 91\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:00:27 (running for 00:15:02.09)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    91</td><td style=\"text-align: right;\">         876.363</td><td style=\"text-align: right;\">5822544</td><td style=\"text-align: right;\"> -203973</td><td style=\"text-align: right;\">             -199726</td><td style=\"text-align: right;\">             -212577</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 5886528\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 5886528\n",
      "    num_agent_steps_trained: 5886528\n",
      "    num_env_steps_sampled: 5886528\n",
      "    num_env_steps_trained: 5886528\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-00-31\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -198360.07036493655\n",
      "  episode_reward_mean: -204098.82005663638\n",
      "  episode_reward_min: -209146.27942662948\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 5880\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1556124687194824\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.000390266184695065\n",
      "          model: {}\n",
      "          policy_loss: 0.006770114414393902\n",
      "          total_loss: 10.006532669067383\n",
      "          vf_explained_var: -1.5137688436084318e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 5886528\n",
      "    num_agent_steps_trained: 5886528\n",
      "    num_env_steps_sampled: 5886528\n",
      "    num_env_steps_trained: 5886528\n",
      "  iterations_since_restore: 92\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 5886528\n",
      "  num_agent_steps_trained: 5886528\n",
      "  num_env_steps_sampled: 5886528\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 5886528\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 80.02142857142857\n",
      "    ram_util_percent: 88.35000000000001\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09546500342257139\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.47151145066807415\n",
      "    mean_inference_ms: 0.971827244997101\n",
      "    mean_raw_obs_processing_ms: 0.13537694302162007\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -198360.07036493655\n",
      "    episode_reward_mean: -204098.82005663638\n",
      "    episode_reward_min: -209146.27942662948\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -199765.49329918087\n",
      "      - -202908.213875861\n",
      "      - -204533.77427851202\n",
      "      - -203917.43586799607\n",
      "      - -209009.70052483855\n",
      "      - -203453.1006864526\n",
      "      - -201792.5443347639\n",
      "      - -203701.48334073933\n",
      "      - -205363.03586624324\n",
      "      - -200332.73814434482\n",
      "      - -199944.92069597734\n",
      "      - -202190.35486375436\n",
      "      - -204547.2348999301\n",
      "      - -201458.01680079577\n",
      "      - -203406.58149971688\n",
      "      - -206390.7372060273\n",
      "      - -205079.22723680417\n",
      "      - -204275.96757999508\n",
      "      - -204672.6573740894\n",
      "      - -201264.58367276692\n",
      "      - -205211.559891274\n",
      "      - -207437.33572114367\n",
      "      - -202567.46660567922\n",
      "      - -203865.50105992454\n",
      "      - -204847.60187675685\n",
      "      - -200457.97291010438\n",
      "      - -201367.9782166454\n",
      "      - -202383.01793877408\n",
      "      - -201469.36032920142\n",
      "      - -207656.57836120675\n",
      "      - -204188.20757729496\n",
      "      - -201575.6815529373\n",
      "      - -203636.05721217938\n",
      "      - -205751.99861977517\n",
      "      - -206550.18266650505\n",
      "      - -202834.2165486135\n",
      "      - -204067.89344750915\n",
      "      - -204229.03459343352\n",
      "      - -204187.21055405206\n",
      "      - -206266.3521205135\n",
      "      - -202085.28903810348\n",
      "      - -199469.6857586864\n",
      "      - -202670.84421281517\n",
      "      - -205154.15486034378\n",
      "      - -204686.42761031454\n",
      "      - -206738.65446373718\n",
      "      - -206705.94864069746\n",
      "      - -205162.18353500843\n",
      "      - -202782.2513584897\n",
      "      - -208008.81838746916\n",
      "      - -200978.31104906308\n",
      "      - -207436.838037245\n",
      "      - -206895.51835976454\n",
      "      - -202153.69305195665\n",
      "      - -204614.2530342913\n",
      "      - -206475.97240037005\n",
      "      - -204458.34328194745\n",
      "      - -198360.07036493655\n",
      "      - -205139.43718700745\n",
      "      - -202729.0528610799\n",
      "      - -206650.72568961114\n",
      "      - -199825.03659725838\n",
      "      - -203601.43748865562\n",
      "      - -205922.96995960994\n",
      "      - -204948.13755684794\n",
      "      - -204391.25629880492\n",
      "      - -204215.14926335964\n",
      "      - -206864.3493104909\n",
      "      - -204342.64207040335\n",
      "      - -204944.40133193508\n",
      "      - -204152.9090762965\n",
      "      - -201882.43370059386\n",
      "      - -204520.32685213798\n",
      "      - -205356.95817698052\n",
      "      - -204604.0621895409\n",
      "      - -201020.4141390413\n",
      "      - -203718.82465604896\n",
      "      - -202497.4728808138\n",
      "      - -204775.8943411799\n",
      "      - -201490.80365007574\n",
      "      - -204215.0979194009\n",
      "      - -201610.78435749406\n",
      "      - -203875.5281940522\n",
      "      - -202722.93196661473\n",
      "      - -209146.27942662948\n",
      "      - -207419.53358960157\n",
      "      - -204943.82664430168\n",
      "      - -207431.88653897826\n",
      "      - -201720.55833156843\n",
      "      - -209116.6485903282\n",
      "      - -201503.33357358054\n",
      "      - -209069.4768987777\n",
      "      - -205773.52658482376\n",
      "      - -205752.39093502707\n",
      "      - -200037.64255429726\n",
      "      - -204368.0164901162\n",
      "      - -207460.84205648742\n",
      "      - -203731.9528289536\n",
      "      - -202316.27931357737\n",
      "      - -206674.50629369676\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09546500342257139\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.47151145066807415\n",
      "      mean_inference_ms: 0.971827244997101\n",
      "      mean_raw_obs_processing_ms: 0.13537694302162007\n",
      "  time_since_restore: 885.7338497638702\n",
      "  time_this_iter_s: 9.370720148086548\n",
      "  time_total_s: 885.7338497638702\n",
      "  timers:\n",
      "    learn_throughput: 130432.289\n",
      "    learn_time_ms: 490.553\n",
      "    load_throughput: 21541848.381\n",
      "    load_time_ms: 2.97\n",
      "    training_iteration_time_ms: 9728.857\n",
      "    update_time_ms: 4.053\n",
      "  timestamp: 1665849631\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5886528\n",
      "  training_iteration: 92\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:00:37 (running for 00:15:11.49)<br>Memory usage on this node: 13.6/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    92</td><td style=\"text-align: right;\">         885.734</td><td style=\"text-align: right;\">5886528</td><td style=\"text-align: right;\"> -204099</td><td style=\"text-align: right;\">             -198360</td><td style=\"text-align: right;\">             -209146</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 5950512\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 5950512\n",
      "    num_agent_steps_trained: 5950512\n",
      "    num_env_steps_sampled: 5950512\n",
      "    num_env_steps_trained: 5950512\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-00-41\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -199825.03659725838\n",
      "  episode_reward_mean: -204557.07873713208\n",
      "  episode_reward_min: -218219.03698395018\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 5940\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.155733823776245\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0006416862597689033\n",
      "          model: {}\n",
      "          policy_loss: 0.0009501308086328208\n",
      "          total_loss: 10.000761985778809\n",
      "          vf_explained_var: -2.7437058847112894e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 5950512\n",
      "    num_agent_steps_trained: 5950512\n",
      "    num_env_steps_sampled: 5950512\n",
      "    num_env_steps_trained: 5950512\n",
      "  iterations_since_restore: 93\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 5950512\n",
      "  num_agent_steps_trained: 5950512\n",
      "  num_env_steps_sampled: 5950512\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 5950512\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.1846153846154\n",
      "    ram_util_percent: 87.6076923076923\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09533438336295827\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4717717756654185\n",
      "    mean_inference_ms: 0.9712759456731268\n",
      "    mean_raw_obs_processing_ms: 0.1352857234051909\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -199825.03659725838\n",
      "    episode_reward_mean: -204557.07873713208\n",
      "    episode_reward_min: -218219.03698395018\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -206650.72568961114\n",
      "      - -199825.03659725838\n",
      "      - -203601.43748865562\n",
      "      - -205922.96995960994\n",
      "      - -204948.13755684794\n",
      "      - -204391.25629880492\n",
      "      - -204215.14926335964\n",
      "      - -206864.3493104909\n",
      "      - -204342.64207040335\n",
      "      - -204944.40133193508\n",
      "      - -204152.9090762965\n",
      "      - -201882.43370059386\n",
      "      - -204520.32685213798\n",
      "      - -205356.95817698052\n",
      "      - -204604.0621895409\n",
      "      - -201020.4141390413\n",
      "      - -203718.82465604896\n",
      "      - -202497.4728808138\n",
      "      - -204775.8943411799\n",
      "      - -201490.80365007574\n",
      "      - -204215.0979194009\n",
      "      - -201610.78435749406\n",
      "      - -203875.5281940522\n",
      "      - -202722.93196661473\n",
      "      - -209146.27942662948\n",
      "      - -207419.53358960157\n",
      "      - -204943.82664430168\n",
      "      - -207431.88653897826\n",
      "      - -201720.55833156843\n",
      "      - -209116.6485903282\n",
      "      - -201503.33357358054\n",
      "      - -209069.4768987777\n",
      "      - -205773.52658482376\n",
      "      - -205752.39093502707\n",
      "      - -200037.64255429726\n",
      "      - -204368.0164901162\n",
      "      - -207460.84205648742\n",
      "      - -203731.9528289536\n",
      "      - -202316.27931357737\n",
      "      - -206674.50629369676\n",
      "      - -208326.6107768955\n",
      "      - -206235.7087610535\n",
      "      - -205657.079662038\n",
      "      - -205685.69461548346\n",
      "      - -201954.91630186338\n",
      "      - -209183.09588996234\n",
      "      - -202920.16531228684\n",
      "      - -208520.8008168755\n",
      "      - -205597.69805306545\n",
      "      - -203481.85110849503\n",
      "      - -202540.99183410365\n",
      "      - -208497.22618585738\n",
      "      - -205278.2595329271\n",
      "      - -202543.41445385898\n",
      "      - -205182.17713051327\n",
      "      - -204733.79089926725\n",
      "      - -201741.53757578094\n",
      "      - -206563.6315363196\n",
      "      - -205438.93318270467\n",
      "      - -203924.56888262107\n",
      "      - -202455.4484780436\n",
      "      - -200661.02764499313\n",
      "      - -206557.57166824496\n",
      "      - -205002.9289044496\n",
      "      - -203863.78394217844\n",
      "      - -203789.44830080384\n",
      "      - -203722.0820136996\n",
      "      - -204581.67933615562\n",
      "      - -202424.31458316464\n",
      "      - -206734.2155565604\n",
      "      - -202818.6031463216\n",
      "      - -206150.939400938\n",
      "      - -203772.16166383534\n",
      "      - -202166.16377611703\n",
      "      - -204427.73986824718\n",
      "      - -202055.55965951673\n",
      "      - -202134.33741058788\n",
      "      - -203746.02860885486\n",
      "      - -201767.2519321067\n",
      "      - -208277.7958534464\n",
      "      - -204936.12229954381\n",
      "      - -204964.79390636145\n",
      "      - -202309.39668851343\n",
      "      - -204361.768180151\n",
      "      - -201766.68165195722\n",
      "      - -202640.1824827142\n",
      "      - -205458.0994421842\n",
      "      - -206462.06752280064\n",
      "      - -206285.32505440665\n",
      "      - -204074.77331743788\n",
      "      - -205355.4732456324\n",
      "      - -200568.58181126785\n",
      "      - -204895.03078083746\n",
      "      - -205520.39958015727\n",
      "      - -203286.28637702146\n",
      "      - -204751.44289571382\n",
      "      - -202769.443246952\n",
      "      - -218219.03698395018\n",
      "      - -201330.4382154548\n",
      "      - -206018.04745191842\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09533438336295827\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4717717756654185\n",
      "      mean_inference_ms: 0.9712759456731268\n",
      "      mean_raw_obs_processing_ms: 0.1352857234051909\n",
      "  time_since_restore: 894.9096295833588\n",
      "  time_this_iter_s: 9.175779819488525\n",
      "  time_total_s: 894.9096295833588\n",
      "  timers:\n",
      "    learn_throughput: 131960.254\n",
      "    learn_time_ms: 484.873\n",
      "    load_throughput: 21471872.621\n",
      "    load_time_ms: 2.98\n",
      "    training_iteration_time_ms: 9695.268\n",
      "    update_time_ms: 4.163\n",
      "  timestamp: 1665849641\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5950512\n",
      "  training_iteration: 93\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:00:46 (running for 00:15:20.58)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    93</td><td style=\"text-align: right;\">          894.91</td><td style=\"text-align: right;\">5950512</td><td style=\"text-align: right;\"> -204557</td><td style=\"text-align: right;\">             -199825</td><td style=\"text-align: right;\">             -218219</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 6014496\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 6014496\n",
      "    num_agent_steps_trained: 6014496\n",
      "    num_env_steps_sampled: 6014496\n",
      "    num_env_steps_trained: 6014496\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-00-50\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -198708.7039161356\n",
      "  episode_reward_mean: -204359.76749232912\n",
      "  episode_reward_min: -218219.03698395018\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 6012\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1570684909820557\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.000579666462726891\n",
      "          model: {}\n",
      "          policy_loss: 0.003319996641948819\n",
      "          total_loss: 10.003119468688965\n",
      "          vf_explained_var: -2.554484801464696e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 6014496\n",
      "    num_agent_steps_trained: 6014496\n",
      "    num_env_steps_sampled: 6014496\n",
      "    num_env_steps_trained: 6014496\n",
      "  iterations_since_restore: 94\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 6014496\n",
      "  num_agent_steps_trained: 6014496\n",
      "  num_env_steps_sampled: 6014496\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 6014496\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.88461538461539\n",
      "    ram_util_percent: 87.53846153846153\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09525999574820826\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4716153299887074\n",
      "    mean_inference_ms: 0.9708668729615604\n",
      "    mean_raw_obs_processing_ms: 0.13508780831090178\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -198708.7039161356\n",
      "    episode_reward_mean: -204359.76749232912\n",
      "    episode_reward_min: -218219.03698395018\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -203772.16166383534\n",
      "      - -202166.16377611703\n",
      "      - -204427.73986824718\n",
      "      - -202055.55965951673\n",
      "      - -202134.33741058788\n",
      "      - -203746.02860885486\n",
      "      - -201767.2519321067\n",
      "      - -208277.7958534464\n",
      "      - -204936.12229954381\n",
      "      - -204964.79390636145\n",
      "      - -202309.39668851343\n",
      "      - -204361.768180151\n",
      "      - -201766.68165195722\n",
      "      - -202640.1824827142\n",
      "      - -205458.0994421842\n",
      "      - -206462.06752280064\n",
      "      - -206285.32505440665\n",
      "      - -204074.77331743788\n",
      "      - -205355.4732456324\n",
      "      - -200568.58181126785\n",
      "      - -204895.03078083746\n",
      "      - -205520.39958015727\n",
      "      - -203286.28637702146\n",
      "      - -204751.44289571382\n",
      "      - -202769.443246952\n",
      "      - -218219.03698395018\n",
      "      - -201330.4382154548\n",
      "      - -206018.04745191842\n",
      "      - -205256.76056696897\n",
      "      - -205893.74299111322\n",
      "      - -202825.65539857835\n",
      "      - -210070.22714316525\n",
      "      - -203871.07565038695\n",
      "      - -202793.86425722798\n",
      "      - -203272.13595311064\n",
      "      - -201639.4776890799\n",
      "      - -206095.42545554574\n",
      "      - -204322.16942392528\n",
      "      - -204765.54802402956\n",
      "      - -207736.53827591703\n",
      "      - -202368.44196040707\n",
      "      - -204375.02632884483\n",
      "      - -204257.54945610816\n",
      "      - -203814.89780912493\n",
      "      - -208103.16084195577\n",
      "      - -204150.52157010898\n",
      "      - -207437.61578449953\n",
      "      - -202324.23098787974\n",
      "      - -203797.3251147982\n",
      "      - -200754.64634106154\n",
      "      - -202630.95288398289\n",
      "      - -201190.01004627772\n",
      "      - -201672.4963472831\n",
      "      - -203363.41564608942\n",
      "      - -201932.09448435332\n",
      "      - -200469.77920826286\n",
      "      - -206262.19186410907\n",
      "      - -206725.64911161657\n",
      "      - -205790.51328579\n",
      "      - -201779.10790813473\n",
      "      - -200934.3126410881\n",
      "      - -201711.63456141678\n",
      "      - -203809.678974141\n",
      "      - -202858.06132018744\n",
      "      - -210854.42743820936\n",
      "      - -204787.93046327296\n",
      "      - -201179.23636498547\n",
      "      - -202622.91065991824\n",
      "      - -202368.77405038962\n",
      "      - -203621.266490709\n",
      "      - -206539.97007108765\n",
      "      - -206820.01580626194\n",
      "      - -208842.93759040485\n",
      "      - -203907.47710939814\n",
      "      - -205802.35105846604\n",
      "      - -203946.6458496727\n",
      "      - -207984.3933517409\n",
      "      - -206499.92975266953\n",
      "      - -207972.4892396739\n",
      "      - -209863.64486313792\n",
      "      - -205673.99439820333\n",
      "      - -206005.91268798357\n",
      "      - -202276.68231323414\n",
      "      - -206239.4548489606\n",
      "      - -201962.28423721794\n",
      "      - -202014.37238917232\n",
      "      - -206556.28601886597\n",
      "      - -203400.39078459435\n",
      "      - -203139.22142843108\n",
      "      - -202942.508962568\n",
      "      - -201094.99841114928\n",
      "      - -200862.12232550702\n",
      "      - -204913.08206089158\n",
      "      - -204569.95189638902\n",
      "      - -207740.70362948414\n",
      "      - -205937.06358726573\n",
      "      - -204531.2476110864\n",
      "      - -198708.7039161356\n",
      "      - -204739.60935150943\n",
      "      - -203677.39300000848\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09525999574820826\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4716153299887074\n",
      "      mean_inference_ms: 0.9708668729615604\n",
      "      mean_raw_obs_processing_ms: 0.13508780831090178\n",
      "  time_since_restore: 904.3733701705933\n",
      "  time_this_iter_s: 9.463740587234497\n",
      "  time_total_s: 904.3733701705933\n",
      "  timers:\n",
      "    learn_throughput: 130157.876\n",
      "    learn_time_ms: 491.588\n",
      "    load_throughput: 21376096.979\n",
      "    load_time_ms: 2.993\n",
      "    training_iteration_time_ms: 9662.085\n",
      "    update_time_ms: 4.219\n",
      "  timestamp: 1665849650\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6014496\n",
      "  training_iteration: 94\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:00:55 (running for 00:15:30.18)<br>Memory usage on this node: 13.7/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    94</td><td style=\"text-align: right;\">         904.373</td><td style=\"text-align: right;\">6014496</td><td style=\"text-align: right;\"> -204360</td><td style=\"text-align: right;\">             -198709</td><td style=\"text-align: right;\">             -218219</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 6078480\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 6078480\n",
      "    num_agent_steps_trained: 6078480\n",
      "    num_env_steps_sampled: 6078480\n",
      "    num_env_steps_trained: 6078480\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-01-00\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -198708.7039161356\n",
      "  episode_reward_mean: -204652.8286351112\n",
      "  episode_reward_min: -211044.23716134846\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 6072\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1542742252349854\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0004743323370348662\n",
      "          model: {}\n",
      "          policy_loss: 0.007212648168206215\n",
      "          total_loss: 10.00699234008789\n",
      "          vf_explained_var: -3.595200936956644e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 6078480\n",
      "    num_agent_steps_trained: 6078480\n",
      "    num_env_steps_sampled: 6078480\n",
      "    num_env_steps_trained: 6078480\n",
      "  iterations_since_restore: 95\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 6078480\n",
      "  num_agent_steps_trained: 6078480\n",
      "  num_env_steps_sampled: 6078480\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 6078480\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.00714285714285\n",
      "    ram_util_percent: 88.3142857142857\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09551621872822\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4714721670425341\n",
      "    mean_inference_ms: 0.9711701724655708\n",
      "    mean_raw_obs_processing_ms: 0.13533407196809763\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -198708.7039161356\n",
      "    episode_reward_mean: -204652.8286351112\n",
      "    episode_reward_min: -211044.23716134846\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -200934.3126410881\n",
      "      - -201711.63456141678\n",
      "      - -203809.678974141\n",
      "      - -202858.06132018744\n",
      "      - -210854.42743820936\n",
      "      - -204787.93046327296\n",
      "      - -201179.23636498547\n",
      "      - -202622.91065991824\n",
      "      - -202368.77405038962\n",
      "      - -203621.266490709\n",
      "      - -206539.97007108765\n",
      "      - -206820.01580626194\n",
      "      - -208842.93759040485\n",
      "      - -203907.47710939814\n",
      "      - -205802.35105846604\n",
      "      - -203946.6458496727\n",
      "      - -207984.3933517409\n",
      "      - -206499.92975266953\n",
      "      - -207972.4892396739\n",
      "      - -209863.64486313792\n",
      "      - -205673.99439820333\n",
      "      - -206005.91268798357\n",
      "      - -202276.68231323414\n",
      "      - -206239.4548489606\n",
      "      - -201962.28423721794\n",
      "      - -202014.37238917232\n",
      "      - -206556.28601886597\n",
      "      - -203400.39078459435\n",
      "      - -203139.22142843108\n",
      "      - -202942.508962568\n",
      "      - -201094.99841114928\n",
      "      - -200862.12232550702\n",
      "      - -204913.08206089158\n",
      "      - -204569.95189638902\n",
      "      - -207740.70362948414\n",
      "      - -205937.06358726573\n",
      "      - -204531.2476110864\n",
      "      - -198708.7039161356\n",
      "      - -204739.60935150943\n",
      "      - -203677.39300000848\n",
      "      - -207087.59424139617\n",
      "      - -205261.9986776862\n",
      "      - -203532.44468344565\n",
      "      - -205092.15394264238\n",
      "      - -205696.35858131075\n",
      "      - -204408.7732227385\n",
      "      - -202418.5508659806\n",
      "      - -201632.42945783242\n",
      "      - -207333.07036352984\n",
      "      - -204676.84587967326\n",
      "      - -203884.4299975837\n",
      "      - -208288.22753211527\n",
      "      - -205152.13993375804\n",
      "      - -211044.23716134846\n",
      "      - -209629.40120582655\n",
      "      - -203979.02723359282\n",
      "      - -207180.9623250027\n",
      "      - -203275.42312060267\n",
      "      - -203174.47969259508\n",
      "      - -206768.036422277\n",
      "      - -204543.59740494963\n",
      "      - -206171.93827223635\n",
      "      - -204406.47353895102\n",
      "      - -209014.08072287866\n",
      "      - -199812.67283125556\n",
      "      - -203706.75617028493\n",
      "      - -201801.05709311183\n",
      "      - -203761.62930214428\n",
      "      - -201990.24835754698\n",
      "      - -201557.90532987777\n",
      "      - -203625.49827095328\n",
      "      - -203091.88405081496\n",
      "      - -205142.113316696\n",
      "      - -203126.2003576778\n",
      "      - -203416.5951083334\n",
      "      - -202675.47404984236\n",
      "      - -207958.2718992847\n",
      "      - -202303.34528752178\n",
      "      - -203887.94646894533\n",
      "      - -201594.41299301345\n",
      "      - -205550.2229337793\n",
      "      - -204298.6790961351\n",
      "      - -202600.87781415062\n",
      "      - -206836.8915746461\n",
      "      - -207176.83903214365\n",
      "      - -207892.953531825\n",
      "      - -204141.944798072\n",
      "      - -202020.86811859938\n",
      "      - -207959.66820726515\n",
      "      - -208805.31979495948\n",
      "      - -208477.15604511587\n",
      "      - -203440.41417699307\n",
      "      - -207942.56754829755\n",
      "      - -201246.2933097195\n",
      "      - -203610.16340558993\n",
      "      - -204423.30639425354\n",
      "      - -206204.21273980435\n",
      "      - -205469.53292286544\n",
      "      - -201391.77534888187\n",
      "      - -202774.41983527734\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09551621872822\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4714721670425341\n",
      "      mean_inference_ms: 0.9711701724655708\n",
      "      mean_raw_obs_processing_ms: 0.13533407196809763\n",
      "  time_since_restore: 914.4442775249481\n",
      "  time_this_iter_s: 10.070907354354858\n",
      "  time_total_s: 914.4442775249481\n",
      "  timers:\n",
      "    learn_throughput: 131955.258\n",
      "    learn_time_ms: 484.892\n",
      "    load_throughput: 21407813.269\n",
      "    load_time_ms: 2.989\n",
      "    training_iteration_time_ms: 9729.257\n",
      "    update_time_ms: 4.207\n",
      "  timestamp: 1665849660\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6078480\n",
      "  training_iteration: 95\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:01:00 (running for 00:15:35.31)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    95</td><td style=\"text-align: right;\">         914.444</td><td style=\"text-align: right;\">6078480</td><td style=\"text-align: right;\"> -204653</td><td style=\"text-align: right;\">             -198709</td><td style=\"text-align: right;\">             -211044</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:01:05 (running for 00:15:40.31)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    95</td><td style=\"text-align: right;\">         914.444</td><td style=\"text-align: right;\">6078480</td><td style=\"text-align: right;\"> -204653</td><td style=\"text-align: right;\">             -198709</td><td style=\"text-align: right;\">             -211044</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 6142464\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 6142464\n",
      "    num_agent_steps_trained: 6142464\n",
      "    num_env_steps_sampled: 6142464\n",
      "    num_env_steps_trained: 6142464\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-01-10\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -199812.67283125556\n",
      "  episode_reward_mean: -203996.53817413948\n",
      "  episode_reward_min: -209014.08072287866\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 6132\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.157299280166626\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00037009239895269275\n",
      "          model: {}\n",
      "          policy_loss: 0.002240918343886733\n",
      "          total_loss: 10.001999855041504\n",
      "          vf_explained_var: -2.554484801464696e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 6142464\n",
      "    num_agent_steps_trained: 6142464\n",
      "    num_env_steps_sampled: 6142464\n",
      "    num_env_steps_trained: 6142464\n",
      "  iterations_since_restore: 96\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 6142464\n",
      "  num_agent_steps_trained: 6142464\n",
      "  num_env_steps_sampled: 6142464\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 6142464\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.86153846153846\n",
      "    ram_util_percent: 87.30769230769229\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09556940342225355\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.47156004862311846\n",
      "    mean_inference_ms: 0.9714936214404298\n",
      "    mean_raw_obs_processing_ms: 0.1352952998140368\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -199812.67283125556\n",
      "    episode_reward_mean: -203996.53817413948\n",
      "    episode_reward_min: -209014.08072287866\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -204543.59740494963\n",
      "      - -206171.93827223635\n",
      "      - -204406.47353895102\n",
      "      - -209014.08072287866\n",
      "      - -199812.67283125556\n",
      "      - -203706.75617028493\n",
      "      - -201801.05709311183\n",
      "      - -203761.62930214428\n",
      "      - -201990.24835754698\n",
      "      - -201557.90532987777\n",
      "      - -203625.49827095328\n",
      "      - -203091.88405081496\n",
      "      - -205142.113316696\n",
      "      - -203126.2003576778\n",
      "      - -203416.5951083334\n",
      "      - -202675.47404984236\n",
      "      - -207958.2718992847\n",
      "      - -202303.34528752178\n",
      "      - -203887.94646894533\n",
      "      - -201594.41299301345\n",
      "      - -205550.2229337793\n",
      "      - -204298.6790961351\n",
      "      - -202600.87781415062\n",
      "      - -206836.8915746461\n",
      "      - -207176.83903214365\n",
      "      - -207892.953531825\n",
      "      - -204141.944798072\n",
      "      - -202020.86811859938\n",
      "      - -207959.66820726515\n",
      "      - -208805.31979495948\n",
      "      - -208477.15604511587\n",
      "      - -203440.41417699307\n",
      "      - -207942.56754829755\n",
      "      - -201246.2933097195\n",
      "      - -203610.16340558993\n",
      "      - -204423.30639425354\n",
      "      - -206204.21273980435\n",
      "      - -205469.53292286544\n",
      "      - -201391.77534888187\n",
      "      - -202774.41983527734\n",
      "      - -202236.40252544175\n",
      "      - -201623.69083809629\n",
      "      - -200656.47815785676\n",
      "      - -207446.0573923656\n",
      "      - -203715.09013480454\n",
      "      - -202134.9731768843\n",
      "      - -201942.77108599266\n",
      "      - -207010.28189731916\n",
      "      - -202307.11361399517\n",
      "      - -205111.76976821752\n",
      "      - -203633.90645897845\n",
      "      - -204047.63384202527\n",
      "      - -203598.65088726243\n",
      "      - -206121.06787015445\n",
      "      - -204744.22681616875\n",
      "      - -204775.2982934831\n",
      "      - -206062.08286731117\n",
      "      - -200871.27929369648\n",
      "      - -205359.8012286377\n",
      "      - -207595.54884126963\n",
      "      - -202780.62439803468\n",
      "      - -203612.92574275268\n",
      "      - -204136.56483078608\n",
      "      - -202380.46357097596\n",
      "      - -203468.88914110773\n",
      "      - -205957.22918642333\n",
      "      - -206472.25123844206\n",
      "      - -206915.05415833008\n",
      "      - -202976.02208146072\n",
      "      - -203498.28336551238\n",
      "      - -200176.30983923856\n",
      "      - -204956.01562708596\n",
      "      - -202830.57167434483\n",
      "      - -199969.23030406548\n",
      "      - -206660.88360793208\n",
      "      - -205184.64058106506\n",
      "      - -205717.68174974815\n",
      "      - -203223.77024044268\n",
      "      - -202701.5923690851\n",
      "      - -202756.2234700131\n",
      "      - -200545.251231899\n",
      "      - -203300.44118307414\n",
      "      - -202069.12707329323\n",
      "      - -199937.59460648886\n",
      "      - -201752.81347374705\n",
      "      - -206200.1667452112\n",
      "      - -204674.36288683754\n",
      "      - -207554.93480397007\n",
      "      - -204993.75849907935\n",
      "      - -201391.65216051092\n",
      "      - -204186.19268545532\n",
      "      - -202890.13644531867\n",
      "      - -204115.00032245406\n",
      "      - -200415.585526038\n",
      "      - -205651.9422576791\n",
      "      - -201898.48001333885\n",
      "      - -202328.9227450564\n",
      "      - -203933.90772904636\n",
      "      - -205066.24786532336\n",
      "      - -203525.7395386293\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09556940342225355\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.47156004862311846\n",
      "      mean_inference_ms: 0.9714936214404298\n",
      "      mean_raw_obs_processing_ms: 0.1352952998140368\n",
      "  time_since_restore: 924.0442633628845\n",
      "  time_this_iter_s: 9.599985837936401\n",
      "  time_total_s: 924.0442633628845\n",
      "  timers:\n",
      "    learn_throughput: 131878.275\n",
      "    learn_time_ms: 485.175\n",
      "    load_throughput: 21393648.68\n",
      "    load_time_ms: 2.991\n",
      "    training_iteration_time_ms: 9754.732\n",
      "    update_time_ms: 4.372\n",
      "  timestamp: 1665849670\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6142464\n",
      "  training_iteration: 96\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:01:15 (running for 00:15:49.93)<br>Memory usage on this node: 13.4/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    96</td><td style=\"text-align: right;\">         924.044</td><td style=\"text-align: right;\">6142464</td><td style=\"text-align: right;\"> -203997</td><td style=\"text-align: right;\">             -199813</td><td style=\"text-align: right;\">             -209014</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 6206448\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 6206448\n",
      "    num_agent_steps_trained: 6206448\n",
      "    num_env_steps_sampled: 6206448\n",
      "    num_env_steps_trained: 6206448\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-01-20\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -199665.46509165905\n",
      "  episode_reward_mean: -203798.7671190874\n",
      "  episode_reward_min: -216912.6671203973\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 6204\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.153872013092041\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0004328920040279627\n",
      "          model: {}\n",
      "          policy_loss: 0.002410107757896185\n",
      "          total_loss: 10.002179145812988\n",
      "          vf_explained_var: -4.068253645073128e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 6206448\n",
      "    num_agent_steps_trained: 6206448\n",
      "    num_env_steps_sampled: 6206448\n",
      "    num_env_steps_trained: 6206448\n",
      "  iterations_since_restore: 97\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 6206448\n",
      "  num_agent_steps_trained: 6206448\n",
      "  num_env_steps_sampled: 6206448\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 6206448\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 84.17857142857143\n",
      "    ram_util_percent: 86.98571428571428\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0955644623536449\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.471538741242185\n",
      "    mean_inference_ms: 0.9716543697139671\n",
      "    mean_raw_obs_processing_ms: 0.13528851499536224\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -199665.46509165905\n",
      "    episode_reward_mean: -203798.7671190874\n",
      "    episode_reward_min: -216912.6671203973\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -202830.57167434483\n",
      "      - -199969.23030406548\n",
      "      - -206660.88360793208\n",
      "      - -205184.64058106506\n",
      "      - -205717.68174974815\n",
      "      - -203223.77024044268\n",
      "      - -202701.5923690851\n",
      "      - -202756.2234700131\n",
      "      - -200545.251231899\n",
      "      - -203300.44118307414\n",
      "      - -202069.12707329323\n",
      "      - -199937.59460648886\n",
      "      - -201752.81347374705\n",
      "      - -206200.1667452112\n",
      "      - -204674.36288683754\n",
      "      - -207554.93480397007\n",
      "      - -204993.75849907935\n",
      "      - -201391.65216051092\n",
      "      - -204186.19268545532\n",
      "      - -202890.13644531867\n",
      "      - -204115.00032245406\n",
      "      - -200415.585526038\n",
      "      - -205651.9422576791\n",
      "      - -201898.48001333885\n",
      "      - -202328.9227450564\n",
      "      - -203933.90772904636\n",
      "      - -205066.24786532336\n",
      "      - -203525.7395386293\n",
      "      - -202893.38558980662\n",
      "      - -200461.99480603496\n",
      "      - -205130.44468689762\n",
      "      - -202494.8046103408\n",
      "      - -202976.4643986632\n",
      "      - -202868.27678501568\n",
      "      - -204824.6203549605\n",
      "      - -200273.0954189276\n",
      "      - -202015.25729350362\n",
      "      - -207611.96240514418\n",
      "      - -200937.10383368703\n",
      "      - -204443.820680535\n",
      "      - -204025.77690270983\n",
      "      - -206079.93412086228\n",
      "      - -203957.94399624053\n",
      "      - -199856.69721409524\n",
      "      - -203689.04573353555\n",
      "      - -204506.05358057134\n",
      "      - -216912.6671203973\n",
      "      - -206974.93433920265\n",
      "      - -200388.03305852282\n",
      "      - -202770.70728091415\n",
      "      - -202626.1705312324\n",
      "      - -207567.64631418796\n",
      "      - -200398.00579598235\n",
      "      - -207656.46555438984\n",
      "      - -205419.90336052538\n",
      "      - -200936.39173610875\n",
      "      - -200232.89411492326\n",
      "      - -201526.62414352817\n",
      "      - -202911.5517883254\n",
      "      - -202814.68360550105\n",
      "      - -201782.378072409\n",
      "      - -203487.93642297105\n",
      "      - -200288.67293318582\n",
      "      - -210296.20655983806\n",
      "      - -207867.48921902606\n",
      "      - -199665.46509165905\n",
      "      - -203503.65109753597\n",
      "      - -201338.7055402751\n",
      "      - -200966.0400584018\n",
      "      - -205418.5598162809\n",
      "      - -203883.20733564225\n",
      "      - -203560.52332518267\n",
      "      - -203723.54678773484\n",
      "      - -203259.88526846163\n",
      "      - -205705.68816444278\n",
      "      - -206325.68720547075\n",
      "      - -204639.67156036824\n",
      "      - -203084.24463089884\n",
      "      - -207312.8625784876\n",
      "      - -206360.50846508492\n",
      "      - -204087.76938786564\n",
      "      - -202280.10816603233\n",
      "      - -209077.2843193237\n",
      "      - -201219.4261584738\n",
      "      - -207012.6988208307\n",
      "      - -202100.33745370127\n",
      "      - -203836.0341534664\n",
      "      - -205513.99277727705\n",
      "      - -203333.7791402457\n",
      "      - -206887.15604895126\n",
      "      - -200871.08162092644\n",
      "      - -200943.1060518247\n",
      "      - -204329.45572732645\n",
      "      - -206914.42382265948\n",
      "      - -204170.23700501063\n",
      "      - -201758.29922695653\n",
      "      - -205140.22278588227\n",
      "      - -204178.47326699458\n",
      "      - -203795.53391981017\n",
      "      - -206296.14897740138\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.0955644623536449\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.471538741242185\n",
      "      mean_inference_ms: 0.9716543697139671\n",
      "      mean_raw_obs_processing_ms: 0.13528851499536224\n",
      "  time_since_restore: 934.0775763988495\n",
      "  time_this_iter_s: 10.033313035964966\n",
      "  time_total_s: 934.0775763988495\n",
      "  timers:\n",
      "    learn_throughput: 130007.331\n",
      "    learn_time_ms: 492.157\n",
      "    load_throughput: 21497156.108\n",
      "    load_time_ms: 2.976\n",
      "    training_iteration_time_ms: 9694.367\n",
      "    update_time_ms: 4.425\n",
      "  timestamp: 1665849680\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6206448\n",
      "  training_iteration: 97\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:01:25 (running for 00:15:59.88)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    97</td><td style=\"text-align: right;\">         934.078</td><td style=\"text-align: right;\">6206448</td><td style=\"text-align: right;\"> -203799</td><td style=\"text-align: right;\">             -199665</td><td style=\"text-align: right;\">             -216913</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 6270432\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 6270432\n",
      "    num_agent_steps_trained: 6270432\n",
      "    num_env_steps_sampled: 6270432\n",
      "    num_env_steps_trained: 6270432\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-01-30\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -199147.32871245008\n",
      "  episode_reward_mean: -203887.47349808694\n",
      "  episode_reward_min: -223609.04830784185\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 6264\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1609907150268555\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0005589912761934102\n",
      "          model: {}\n",
      "          policy_loss: 0.006300130393356085\n",
      "          total_loss: 10.006096839904785\n",
      "          vf_explained_var: -4.9197485196827984e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 6270432\n",
      "    num_agent_steps_trained: 6270432\n",
      "    num_env_steps_sampled: 6270432\n",
      "    num_env_steps_trained: 6270432\n",
      "  iterations_since_restore: 98\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 6270432\n",
      "  num_agent_steps_trained: 6270432\n",
      "  num_env_steps_sampled: 6270432\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 6270432\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.2357142857143\n",
      "    ram_util_percent: 86.99285714285715\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09563798224605918\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.47142655477091355\n",
      "    mean_inference_ms: 0.9718896926153349\n",
      "    mean_raw_obs_processing_ms: 0.13550741380200818\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -199147.32871245008\n",
      "    episode_reward_mean: -203887.47349808694\n",
      "    episode_reward_min: -223609.04830784185\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -201782.378072409\n",
      "      - -203487.93642297105\n",
      "      - -200288.67293318582\n",
      "      - -210296.20655983806\n",
      "      - -207867.48921902606\n",
      "      - -199665.46509165905\n",
      "      - -203503.65109753597\n",
      "      - -201338.7055402751\n",
      "      - -200966.0400584018\n",
      "      - -205418.5598162809\n",
      "      - -203883.20733564225\n",
      "      - -203560.52332518267\n",
      "      - -203723.54678773484\n",
      "      - -203259.88526846163\n",
      "      - -205705.68816444278\n",
      "      - -206325.68720547075\n",
      "      - -204639.67156036824\n",
      "      - -203084.24463089884\n",
      "      - -207312.8625784876\n",
      "      - -206360.50846508492\n",
      "      - -204087.76938786564\n",
      "      - -202280.10816603233\n",
      "      - -209077.2843193237\n",
      "      - -201219.4261584738\n",
      "      - -207012.6988208307\n",
      "      - -202100.33745370127\n",
      "      - -203836.0341534664\n",
      "      - -205513.99277727705\n",
      "      - -203333.7791402457\n",
      "      - -206887.15604895126\n",
      "      - -200871.08162092644\n",
      "      - -200943.1060518247\n",
      "      - -204329.45572732645\n",
      "      - -206914.42382265948\n",
      "      - -204170.23700501063\n",
      "      - -201758.29922695653\n",
      "      - -205140.22278588227\n",
      "      - -204178.47326699458\n",
      "      - -203795.53391981017\n",
      "      - -206296.14897740138\n",
      "      - -204180.13016993875\n",
      "      - -202310.88560097123\n",
      "      - -202551.03641283256\n",
      "      - -201330.46416190758\n",
      "      - -199597.55922844744\n",
      "      - -201619.63523907767\n",
      "      - -199979.97368198246\n",
      "      - -204411.00196457573\n",
      "      - -200892.97730275063\n",
      "      - -207619.11943278526\n",
      "      - -203831.46000915562\n",
      "      - -208407.65328514902\n",
      "      - -202928.739493637\n",
      "      - -206110.1875618567\n",
      "      - -204064.7249598978\n",
      "      - -203359.5446273412\n",
      "      - -204720.42217922088\n",
      "      - -205411.38271732128\n",
      "      - -203101.39353070242\n",
      "      - -202123.92352620023\n",
      "      - -199403.02991460534\n",
      "      - -203589.53242655972\n",
      "      - -203051.1317667993\n",
      "      - -205899.69707503635\n",
      "      - -202070.48573108253\n",
      "      - -203097.20618058994\n",
      "      - -203158.22994711983\n",
      "      - -202993.19546544354\n",
      "      - -206767.33304575767\n",
      "      - -202857.7238000494\n",
      "      - -202185.1886096234\n",
      "      - -201068.83522591935\n",
      "      - -202720.74500639355\n",
      "      - -206884.4665082342\n",
      "      - -204545.67759151026\n",
      "      - -201469.2353933933\n",
      "      - -204240.7489141758\n",
      "      - -199147.32871245008\n",
      "      - -202161.49716779034\n",
      "      - -203167.15762397245\n",
      "      - -204058.41853917376\n",
      "      - -200359.9041831442\n",
      "      - -201087.38078673993\n",
      "      - -223609.04830784185\n",
      "      - -201979.95727692355\n",
      "      - -204823.89931947427\n",
      "      - -201471.40068369158\n",
      "      - -204803.9913595871\n",
      "      - -200446.18371777906\n",
      "      - -203471.28805105278\n",
      "      - -203520.35067119257\n",
      "      - -204923.8113005666\n",
      "      - -203250.3786572152\n",
      "      - -204361.62795047226\n",
      "      - -206579.26228029735\n",
      "      - -206305.57412792224\n",
      "      - -204573.30272426587\n",
      "      - -203094.78642988473\n",
      "      - -205218.2689259968\n",
      "      - -205561.35435889362\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09563798224605918\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.47142655477091355\n",
      "      mean_inference_ms: 0.9718896926153349\n",
      "      mean_raw_obs_processing_ms: 0.13550741380200818\n",
      "  time_since_restore: 943.7929496765137\n",
      "  time_this_iter_s: 9.715373277664185\n",
      "  time_total_s: 943.7929496765137\n",
      "  timers:\n",
      "    learn_throughput: 129431.7\n",
      "    learn_time_ms: 494.346\n",
      "    load_throughput: 21514907.255\n",
      "    load_time_ms: 2.974\n",
      "    training_iteration_time_ms: 9637.678\n",
      "    update_time_ms: 4.414\n",
      "  timestamp: 1665849690\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6270432\n",
      "  training_iteration: 98\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:01:35 (running for 00:16:09.75)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    98</td><td style=\"text-align: right;\">         943.793</td><td style=\"text-align: right;\">6270432</td><td style=\"text-align: right;\"> -203887</td><td style=\"text-align: right;\">             -199147</td><td style=\"text-align: right;\">             -223609</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 6334416\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 6334416\n",
      "    num_agent_steps_trained: 6334416\n",
      "    num_env_steps_sampled: 6334416\n",
      "    num_env_steps_trained: 6334416\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-01-39\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -198737.52283484826\n",
      "  episode_reward_mean: -203291.27372667738\n",
      "  episode_reward_min: -223609.04830784185\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 6324\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1624088287353516\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00048488646280020475\n",
      "          model: {}\n",
      "          policy_loss: 0.001171893090941012\n",
      "          total_loss: 10.00095272064209\n",
      "          vf_explained_var: -2.7437058847112894e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 6334416\n",
      "    num_agent_steps_trained: 6334416\n",
      "    num_env_steps_sampled: 6334416\n",
      "    num_env_steps_trained: 6334416\n",
      "  iterations_since_restore: 99\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 6334416\n",
      "  num_agent_steps_trained: 6334416\n",
      "  num_env_steps_sampled: 6334416\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 6334416\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.06923076923077\n",
      "    ram_util_percent: 86.9923076923077\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09558505407766325\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4715799912679921\n",
      "    mean_inference_ms: 0.9717414975574726\n",
      "    mean_raw_obs_processing_ms: 0.13555404157268258\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -198737.52283484826\n",
      "    episode_reward_mean: -203291.27372667738\n",
      "    episode_reward_min: -223609.04830784185\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -199403.02991460534\n",
      "      - -203589.53242655972\n",
      "      - -203051.1317667993\n",
      "      - -205899.69707503635\n",
      "      - -202070.48573108253\n",
      "      - -203097.20618058994\n",
      "      - -203158.22994711983\n",
      "      - -202993.19546544354\n",
      "      - -206767.33304575767\n",
      "      - -202857.7238000494\n",
      "      - -202185.1886096234\n",
      "      - -201068.83522591935\n",
      "      - -202720.74500639355\n",
      "      - -206884.4665082342\n",
      "      - -204545.67759151026\n",
      "      - -201469.2353933933\n",
      "      - -204240.7489141758\n",
      "      - -199147.32871245008\n",
      "      - -202161.49716779034\n",
      "      - -203167.15762397245\n",
      "      - -204058.41853917376\n",
      "      - -200359.9041831442\n",
      "      - -201087.38078673993\n",
      "      - -223609.04830784185\n",
      "      - -201979.95727692355\n",
      "      - -204823.89931947427\n",
      "      - -201471.40068369158\n",
      "      - -204803.9913595871\n",
      "      - -200446.18371777906\n",
      "      - -203471.28805105278\n",
      "      - -203520.35067119257\n",
      "      - -204923.8113005666\n",
      "      - -203250.3786572152\n",
      "      - -204361.62795047226\n",
      "      - -206579.26228029735\n",
      "      - -206305.57412792224\n",
      "      - -204573.30272426587\n",
      "      - -203094.78642988473\n",
      "      - -205218.2689259968\n",
      "      - -205561.35435889362\n",
      "      - -205137.13198703545\n",
      "      - -203300.8614696829\n",
      "      - -202947.79049503847\n",
      "      - -199379.13789821853\n",
      "      - -201732.76690614992\n",
      "      - -201024.63894727477\n",
      "      - -205623.35709735562\n",
      "      - -201374.14214557034\n",
      "      - -204250.04897788624\n",
      "      - -202860.73050005984\n",
      "      - -204026.07574294915\n",
      "      - -200980.17505365386\n",
      "      - -202163.43754268184\n",
      "      - -203548.31132706214\n",
      "      - -201720.68216554384\n",
      "      - -199453.34107197684\n",
      "      - -202986.10360492644\n",
      "      - -205197.8013823075\n",
      "      - -205820.8325279272\n",
      "      - -205246.4955740281\n",
      "      - -202164.87464154253\n",
      "      - -202936.88410845917\n",
      "      - -199689.4334209065\n",
      "      - -205054.55242942943\n",
      "      - -200859.07998229912\n",
      "      - -201324.35238410268\n",
      "      - -198969.44211212374\n",
      "      - -203262.71152048706\n",
      "      - -203331.156477352\n",
      "      - -203310.84431702606\n",
      "      - -201464.2106906885\n",
      "      - -204650.36817747634\n",
      "      - -203594.32274781066\n",
      "      - -202983.01833392793\n",
      "      - -204701.02187565397\n",
      "      - -204478.59758754462\n",
      "      - -201499.72126979844\n",
      "      - -205596.53448630235\n",
      "      - -203517.12476944862\n",
      "      - -202222.61548153168\n",
      "      - -200127.06045641904\n",
      "      - -207108.4971150892\n",
      "      - -207388.74577057557\n",
      "      - -206542.23522115333\n",
      "      - -201407.6961395168\n",
      "      - -203816.83092852752\n",
      "      - -202030.8869062875\n",
      "      - -204330.203391618\n",
      "      - -204330.14804948703\n",
      "      - -206505.1851348765\n",
      "      - -203813.00558792855\n",
      "      - -199122.1176944661\n",
      "      - -202460.86633702452\n",
      "      - -199977.9028500106\n",
      "      - -202350.7723988875\n",
      "      - -204635.03873575924\n",
      "      - -200614.107547202\n",
      "      - -205655.44548632586\n",
      "      - -199809.7390918723\n",
      "      - -198737.52283484826\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09558505407766325\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4715799912679921\n",
      "      mean_inference_ms: 0.9717414975574726\n",
      "      mean_raw_obs_processing_ms: 0.13555404157268258\n",
      "  time_since_restore: 953.3862857818604\n",
      "  time_this_iter_s: 9.59333610534668\n",
      "  time_total_s: 953.3862857818604\n",
      "  timers:\n",
      "    learn_throughput: 128826.851\n",
      "    learn_time_ms: 496.667\n",
      "    load_throughput: 21740264.506\n",
      "    load_time_ms: 2.943\n",
      "    training_iteration_time_ms: 9543.114\n",
      "    update_time_ms: 4.4\n",
      "  timestamp: 1665849699\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6334416\n",
      "  training_iteration: 99\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:01:44 (running for 00:16:19.37)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">    99</td><td style=\"text-align: right;\">         953.386</td><td style=\"text-align: right;\">6334416</td><td style=\"text-align: right;\"> -203291</td><td style=\"text-align: right;\">             -198738</td><td style=\"text-align: right;\">             -223609</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 6398400\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 6398400\n",
      "    num_agent_steps_trained: 6398400\n",
      "    num_env_steps_sampled: 6398400\n",
      "    num_env_steps_trained: 6398400\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-01-48\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -197776.74024757353\n",
      "  episode_reward_mean: -203003.5358390092\n",
      "  episode_reward_min: -209175.1073175916\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 6396\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1600842475891113\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.000675452989526093\n",
      "          model: {}\n",
      "          policy_loss: 0.003431726712733507\n",
      "          total_loss: 10.003251075744629\n",
      "          vf_explained_var: -5.676632941487014e-09\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 6398400\n",
      "    num_agent_steps_trained: 6398400\n",
      "    num_env_steps_sampled: 6398400\n",
      "    num_env_steps_trained: 6398400\n",
      "  iterations_since_restore: 100\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 6398400\n",
      "  num_agent_steps_trained: 6398400\n",
      "  num_env_steps_sampled: 6398400\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 6398400\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.9923076923077\n",
      "    ram_util_percent: 86.93846153846154\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09551809790566193\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.47125093647472305\n",
      "    mean_inference_ms: 0.971035468079929\n",
      "    mean_raw_obs_processing_ms: 0.1354408808806954\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -197776.74024757353\n",
      "    episode_reward_mean: -203003.5358390092\n",
      "    episode_reward_min: -209175.1073175916\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -203594.32274781066\n",
      "      - -202983.01833392793\n",
      "      - -204701.02187565397\n",
      "      - -204478.59758754462\n",
      "      - -201499.72126979844\n",
      "      - -205596.53448630235\n",
      "      - -203517.12476944862\n",
      "      - -202222.61548153168\n",
      "      - -200127.06045641904\n",
      "      - -207108.4971150892\n",
      "      - -207388.74577057557\n",
      "      - -206542.23522115333\n",
      "      - -201407.6961395168\n",
      "      - -203816.83092852752\n",
      "      - -202030.8869062875\n",
      "      - -204330.203391618\n",
      "      - -204330.14804948703\n",
      "      - -206505.1851348765\n",
      "      - -203813.00558792855\n",
      "      - -199122.1176944661\n",
      "      - -202460.86633702452\n",
      "      - -199977.9028500106\n",
      "      - -202350.7723988875\n",
      "      - -204635.03873575924\n",
      "      - -200614.107547202\n",
      "      - -205655.44548632586\n",
      "      - -199809.7390918723\n",
      "      - -198737.52283484826\n",
      "      - -202377.85112718327\n",
      "      - -198994.25569481085\n",
      "      - -202950.6629259677\n",
      "      - -202568.14824934615\n",
      "      - -202360.3908794427\n",
      "      - -202086.0883147943\n",
      "      - -204453.89114804933\n",
      "      - -199822.16454522725\n",
      "      - -204057.87510911174\n",
      "      - -204005.8053660809\n",
      "      - -202624.20487653758\n",
      "      - -208692.897471188\n",
      "      - -205326.26312191164\n",
      "      - -199880.83445889625\n",
      "      - -199755.16950631418\n",
      "      - -200453.54851645225\n",
      "      - -202397.65920791935\n",
      "      - -199282.2939269689\n",
      "      - -207769.01085964285\n",
      "      - -199897.45148911892\n",
      "      - -205353.04655426217\n",
      "      - -204779.08701032866\n",
      "      - -201265.8586446322\n",
      "      - -200701.60948274122\n",
      "      - -199765.5790340385\n",
      "      - -201798.5484897433\n",
      "      - -202182.68916916283\n",
      "      - -202290.6650271369\n",
      "      - -201997.22561758125\n",
      "      - -200578.85251249056\n",
      "      - -204769.18802175845\n",
      "      - -200770.9398917699\n",
      "      - -205069.3165798089\n",
      "      - -203608.28335953076\n",
      "      - -203674.72728987903\n",
      "      - -202601.7317793347\n",
      "      - -203220.2322404093\n",
      "      - -205807.2202757795\n",
      "      - -204320.36688998019\n",
      "      - -204593.17466593024\n",
      "      - -201466.1471525379\n",
      "      - -197776.74024757353\n",
      "      - -204586.4586863361\n",
      "      - -202388.32584823764\n",
      "      - -206264.23438516448\n",
      "      - -202292.28234910118\n",
      "      - -206664.05560504465\n",
      "      - -204947.33470416715\n",
      "      - -205611.20295988958\n",
      "      - -203152.6936178288\n",
      "      - -201529.60941364733\n",
      "      - -202824.12061261473\n",
      "      - -209175.1073175916\n",
      "      - -200524.55023003544\n",
      "      - -198316.2790150434\n",
      "      - -202211.60006008373\n",
      "      - -201136.41172632875\n",
      "      - -203669.62774105603\n",
      "      - -203822.29168714266\n",
      "      - -199867.55884596094\n",
      "      - -203013.99047930457\n",
      "      - -204056.1278422406\n",
      "      - -205957.95911720942\n",
      "      - -201495.45680353304\n",
      "      - -205842.98953597838\n",
      "      - -201722.7376354011\n",
      "      - -207930.59847984105\n",
      "      - -202824.41320825298\n",
      "      - -201740.68494139216\n",
      "      - -204670.31679728828\n",
      "      - -204195.85202765936\n",
      "      - -200414.05126627127\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09551809790566193\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.47125093647472305\n",
      "      mean_inference_ms: 0.971035468079929\n",
      "      mean_raw_obs_processing_ms: 0.1354408808806954\n",
      "  time_since_restore: 962.3106830120087\n",
      "  time_this_iter_s: 8.924397230148315\n",
      "  time_total_s: 962.3106830120087\n",
      "  timers:\n",
      "    learn_throughput: 129556.875\n",
      "    learn_time_ms: 493.868\n",
      "    load_throughput: 21633187.736\n",
      "    load_time_ms: 2.958\n",
      "    training_iteration_time_ms: 9524.186\n",
      "    update_time_ms: 4.327\n",
      "  timestamp: 1665849708\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6398400\n",
      "  training_iteration: 100\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:01:54 (running for 00:16:28.67)<br>Memory usage on this node: 13.4/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         962.311</td><td style=\"text-align: right;\">6398400</td><td style=\"text-align: right;\"> -203004</td><td style=\"text-align: right;\">             -197777</td><td style=\"text-align: right;\">             -209175</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 6462384\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 6462384\n",
      "    num_agent_steps_trained: 6462384\n",
      "    num_env_steps_sampled: 6462384\n",
      "    num_env_steps_trained: 6462384\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-01-59\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -197776.74024757353\n",
      "  episode_reward_mean: -203789.241668278\n",
      "  episode_reward_min: -209175.1073175916\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 6456\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.160029888153076\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0006216650945134461\n",
      "          model: {}\n",
      "          policy_loss: 0.005307353567332029\n",
      "          total_loss: 10.005115509033203\n",
      "          vf_explained_var: -2.3652637182181024e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 6462384\n",
      "    num_agent_steps_trained: 6462384\n",
      "    num_env_steps_sampled: 6462384\n",
      "    num_env_steps_trained: 6462384\n",
      "  iterations_since_restore: 101\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 6462384\n",
      "  num_agent_steps_trained: 6462384\n",
      "  num_env_steps_sampled: 6462384\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 6462384\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.29285714285713\n",
      "    ram_util_percent: 86.95714285714287\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09557059052908246\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4711040565269311\n",
      "    mean_inference_ms: 0.97122774906025\n",
      "    mean_raw_obs_processing_ms: 0.13559702052677203\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -197776.74024757353\n",
      "    episode_reward_mean: -203789.241668278\n",
      "    episode_reward_min: -209175.1073175916\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -205069.3165798089\n",
      "      - -203608.28335953076\n",
      "      - -203674.72728987903\n",
      "      - -202601.7317793347\n",
      "      - -203220.2322404093\n",
      "      - -205807.2202757795\n",
      "      - -204320.36688998019\n",
      "      - -204593.17466593024\n",
      "      - -201466.1471525379\n",
      "      - -197776.74024757353\n",
      "      - -204586.4586863361\n",
      "      - -202388.32584823764\n",
      "      - -206264.23438516448\n",
      "      - -202292.28234910118\n",
      "      - -206664.05560504465\n",
      "      - -204947.33470416715\n",
      "      - -205611.20295988958\n",
      "      - -203152.6936178288\n",
      "      - -201529.60941364733\n",
      "      - -202824.12061261473\n",
      "      - -209175.1073175916\n",
      "      - -200524.55023003544\n",
      "      - -198316.2790150434\n",
      "      - -202211.60006008373\n",
      "      - -201136.41172632875\n",
      "      - -203669.62774105603\n",
      "      - -203822.29168714266\n",
      "      - -199867.55884596094\n",
      "      - -203013.99047930457\n",
      "      - -204056.1278422406\n",
      "      - -205957.95911720942\n",
      "      - -201495.45680353304\n",
      "      - -205842.98953597838\n",
      "      - -201722.7376354011\n",
      "      - -207930.59847984105\n",
      "      - -202824.41320825298\n",
      "      - -201740.68494139216\n",
      "      - -204670.31679728828\n",
      "      - -204195.85202765936\n",
      "      - -200414.05126627127\n",
      "      - -203725.32864311978\n",
      "      - -204005.18025339325\n",
      "      - -199663.42403062157\n",
      "      - -199695.16936042174\n",
      "      - -201765.54840967758\n",
      "      - -205657.84690799142\n",
      "      - -206796.21996158123\n",
      "      - -201612.54041529525\n",
      "      - -202955.936192462\n",
      "      - -206971.5344819543\n",
      "      - -200393.93806268697\n",
      "      - -198399.21687399904\n",
      "      - -202052.12439506818\n",
      "      - -202272.6879105856\n",
      "      - -205811.82854032013\n",
      "      - -207904.66181658776\n",
      "      - -205122.430229903\n",
      "      - -201340.82388940133\n",
      "      - -201960.31044982572\n",
      "      - -202278.35257432782\n",
      "      - -207546.77991393398\n",
      "      - -204382.13420603683\n",
      "      - -205592.8127498198\n",
      "      - -202888.26322541106\n",
      "      - -203213.81916145957\n",
      "      - -203987.6863127305\n",
      "      - -208785.5937837865\n",
      "      - -203453.84441248685\n",
      "      - -207782.28285473533\n",
      "      - -205282.92773219026\n",
      "      - -205635.44248789732\n",
      "      - -204309.26300676458\n",
      "      - -203284.95386877336\n",
      "      - -207426.1118460941\n",
      "      - -200344.11288704933\n",
      "      - -204162.18982197714\n",
      "      - -206361.7516538628\n",
      "      - -205302.92625544604\n",
      "      - -202338.2983335225\n",
      "      - -208698.34074443812\n",
      "      - -204506.59905109584\n",
      "      - -206251.2082712469\n",
      "      - -203498.41051601077\n",
      "      - -204905.8130629808\n",
      "      - -203031.68534108347\n",
      "      - -203217.0077832858\n",
      "      - -203815.27447425868\n",
      "      - -203246.38335704044\n",
      "      - -203242.3934976304\n",
      "      - -201452.9607900019\n",
      "      - -202719.03500216574\n",
      "      - -205012.89117532183\n",
      "      - -204368.12990317805\n",
      "      - -207473.89911612598\n",
      "      - -206127.31650525308\n",
      "      - -203464.44857984455\n",
      "      - -205343.40273710695\n",
      "      - -204937.29305645032\n",
      "      - -201460.60655607271\n",
      "      - -204697.90597359661\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09557059052908246\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4711040565269311\n",
      "      mean_inference_ms: 0.97122774906025\n",
      "      mean_raw_obs_processing_ms: 0.13559702052677203\n",
      "  time_since_restore: 972.2439801692963\n",
      "  time_this_iter_s: 9.933297157287598\n",
      "  time_total_s: 972.2439801692963\n",
      "  timers:\n",
      "    learn_throughput: 129780.852\n",
      "    learn_time_ms: 493.016\n",
      "    load_throughput: 21677222.269\n",
      "    load_time_ms: 2.952\n",
      "    training_iteration_time_ms: 9580.851\n",
      "    update_time_ms: 4.254\n",
      "  timestamp: 1665849719\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6462384\n",
      "  training_iteration: 101\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:01:59 (running for 00:16:33.76)<br>Memory usage on this node: 13.4/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   101</td><td style=\"text-align: right;\">         972.244</td><td style=\"text-align: right;\">6462384</td><td style=\"text-align: right;\"> -203789</td><td style=\"text-align: right;\">             -197777</td><td style=\"text-align: right;\">             -209175</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:02:04 (running for 00:16:38.77)<br>Memory usage on this node: 13.4/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   101</td><td style=\"text-align: right;\">         972.244</td><td style=\"text-align: right;\">6462384</td><td style=\"text-align: right;\"> -203789</td><td style=\"text-align: right;\">             -197777</td><td style=\"text-align: right;\">             -209175</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 6526368\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 6526368\n",
      "    num_agent_steps_trained: 6526368\n",
      "    num_env_steps_sampled: 6526368\n",
      "    num_env_steps_trained: 6526368\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-02-08\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -198793.0811515486\n",
      "  episode_reward_mean: -203629.0762632535\n",
      "  episode_reward_min: -209659.61945730326\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 6516\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1702358722686768\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00029327356605790555\n",
      "          model: {}\n",
      "          policy_loss: 0.002376863034442067\n",
      "          total_loss: 10.002119064331055\n",
      "          vf_explained_var: -3.12214822884016e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 6526368\n",
      "    num_agent_steps_trained: 6526368\n",
      "    num_env_steps_sampled: 6526368\n",
      "    num_env_steps_trained: 6526368\n",
      "  iterations_since_restore: 102\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 6526368\n",
      "  num_agent_steps_trained: 6526368\n",
      "  num_env_steps_sampled: 6526368\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 6526368\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 80.59285714285714\n",
      "    ram_util_percent: 86.9\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09555340417945665\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4712940154479002\n",
      "    mean_inference_ms: 0.9713543889322791\n",
      "    mean_raw_obs_processing_ms: 0.13553801801599347\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -198793.0811515486\n",
      "    episode_reward_mean: -203629.0762632535\n",
      "    episode_reward_min: -209659.61945730326\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -207546.77991393398\n",
      "      - -204382.13420603683\n",
      "      - -205592.8127498198\n",
      "      - -202888.26322541106\n",
      "      - -203213.81916145957\n",
      "      - -203987.6863127305\n",
      "      - -208785.5937837865\n",
      "      - -203453.84441248685\n",
      "      - -207782.28285473533\n",
      "      - -205282.92773219026\n",
      "      - -205635.44248789732\n",
      "      - -204309.26300676458\n",
      "      - -203284.95386877336\n",
      "      - -207426.1118460941\n",
      "      - -200344.11288704933\n",
      "      - -204162.18982197714\n",
      "      - -206361.7516538628\n",
      "      - -205302.92625544604\n",
      "      - -202338.2983335225\n",
      "      - -208698.34074443812\n",
      "      - -204506.59905109584\n",
      "      - -206251.2082712469\n",
      "      - -203498.41051601077\n",
      "      - -204905.8130629808\n",
      "      - -203031.68534108347\n",
      "      - -203217.0077832858\n",
      "      - -203815.27447425868\n",
      "      - -203246.38335704044\n",
      "      - -203242.3934976304\n",
      "      - -201452.9607900019\n",
      "      - -202719.03500216574\n",
      "      - -205012.89117532183\n",
      "      - -204368.12990317805\n",
      "      - -207473.89911612598\n",
      "      - -206127.31650525308\n",
      "      - -203464.44857984455\n",
      "      - -205343.40273710695\n",
      "      - -204937.29305645032\n",
      "      - -201460.60655607271\n",
      "      - -204697.90597359661\n",
      "      - -202659.08964302056\n",
      "      - -203094.5714283455\n",
      "      - -204598.536457955\n",
      "      - -200722.44125934274\n",
      "      - -204690.29430148506\n",
      "      - -203379.36734919867\n",
      "      - -199657.34554614712\n",
      "      - -201513.677405835\n",
      "      - -202423.9286130548\n",
      "      - -205659.0938793414\n",
      "      - -205969.08140707904\n",
      "      - -203308.88536881443\n",
      "      - -201802.01211791506\n",
      "      - -200401.3494751139\n",
      "      - -198793.0811515486\n",
      "      - -204524.80249515828\n",
      "      - -200158.19884064214\n",
      "      - -206561.5265376769\n",
      "      - -204358.668232152\n",
      "      - -201906.5831104296\n",
      "      - -207008.62931942602\n",
      "      - -202684.87643286536\n",
      "      - -202478.62422712534\n",
      "      - -204529.8683977569\n",
      "      - -201044.04863191216\n",
      "      - -205362.5707183483\n",
      "      - -202791.9734444386\n",
      "      - -203692.71503217015\n",
      "      - -203135.60271809623\n",
      "      - -199214.37584612286\n",
      "      - -204825.25674518853\n",
      "      - -202960.5257004002\n",
      "      - -200885.42012512346\n",
      "      - -199269.19625665204\n",
      "      - -205168.85955704912\n",
      "      - -204163.63221717963\n",
      "      - -204192.26314206902\n",
      "      - -204355.78701955237\n",
      "      - -202250.2054208582\n",
      "      - -204561.94010693088\n",
      "      - -201453.1529245467\n",
      "      - -201281.46105075793\n",
      "      - -201660.60157487256\n",
      "      - -204761.99793112528\n",
      "      - -202434.16029616122\n",
      "      - -204338.1100480156\n",
      "      - -200725.227413902\n",
      "      - -203242.92226839444\n",
      "      - -201611.21466349735\n",
      "      - -202556.73394693522\n",
      "      - -203312.1182585881\n",
      "      - -200164.17777137973\n",
      "      - -201945.7802189515\n",
      "      - -204677.19453129734\n",
      "      - -201662.04223000046\n",
      "      - -209659.61945730326\n",
      "      - -202662.76594292605\n",
      "      - -201314.86805733648\n",
      "      - -202930.1809937812\n",
      "      - -206202.19105789106\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09555340417945665\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4712940154479002\n",
      "      mean_inference_ms: 0.9713543889322791\n",
      "      mean_raw_obs_processing_ms: 0.13553801801599347\n",
      "  time_since_restore: 981.7722187042236\n",
      "  time_this_iter_s: 9.528238534927368\n",
      "  time_total_s: 981.7722187042236\n",
      "  timers:\n",
      "    learn_throughput: 128543.942\n",
      "    learn_time_ms: 497.76\n",
      "    load_throughput: 21733046.155\n",
      "    load_time_ms: 2.944\n",
      "    training_iteration_time_ms: 9596.957\n",
      "    update_time_ms: 4.267\n",
      "  timestamp: 1665849728\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6526368\n",
      "  training_iteration: 102\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:02:13 (running for 00:16:48.31)<br>Memory usage on this node: 13.4/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   102</td><td style=\"text-align: right;\">         981.772</td><td style=\"text-align: right;\">6526368</td><td style=\"text-align: right;\"> -203629</td><td style=\"text-align: right;\">             -198793</td><td style=\"text-align: right;\">             -209660</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 6590352\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 6590352\n",
      "    num_agent_steps_trained: 6590352\n",
      "    num_env_steps_sampled: 6590352\n",
      "    num_env_steps_trained: 6590352\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-02-17\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -197823.33430373808\n",
      "  episode_reward_mean: -202869.5076738259\n",
      "  episode_reward_min: -209659.61945730326\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 6588\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.170722007751465\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0005642342148348689\n",
      "          model: {}\n",
      "          policy_loss: 0.003279130207374692\n",
      "          total_loss: 10.003074645996094\n",
      "          vf_explained_var: -2.176042634971509e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 6590352\n",
      "    num_agent_steps_trained: 6590352\n",
      "    num_env_steps_sampled: 6590352\n",
      "    num_env_steps_trained: 6590352\n",
      "  iterations_since_restore: 103\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 6590352\n",
      "  num_agent_steps_trained: 6590352\n",
      "  num_env_steps_sampled: 6590352\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 6590352\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.86923076923077\n",
      "    ram_util_percent: 86.9\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09549716370132011\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4709398832385469\n",
      "    mean_inference_ms: 0.9707632251279534\n",
      "    mean_raw_obs_processing_ms: 0.1353827257443035\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -197823.33430373808\n",
      "    episode_reward_mean: -202869.5076738259\n",
      "    episode_reward_min: -209659.61945730326\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -200885.42012512346\n",
      "      - -199269.19625665204\n",
      "      - -205168.85955704912\n",
      "      - -204163.63221717963\n",
      "      - -204192.26314206902\n",
      "      - -204355.78701955237\n",
      "      - -202250.2054208582\n",
      "      - -204561.94010693088\n",
      "      - -201453.1529245467\n",
      "      - -201281.46105075793\n",
      "      - -201660.60157487256\n",
      "      - -204761.99793112528\n",
      "      - -202434.16029616122\n",
      "      - -204338.1100480156\n",
      "      - -200725.227413902\n",
      "      - -203242.92226839444\n",
      "      - -201611.21466349735\n",
      "      - -202556.73394693522\n",
      "      - -203312.1182585881\n",
      "      - -200164.17777137973\n",
      "      - -201945.7802189515\n",
      "      - -204677.19453129734\n",
      "      - -201662.04223000046\n",
      "      - -209659.61945730326\n",
      "      - -202662.76594292605\n",
      "      - -201314.86805733648\n",
      "      - -202930.1809937812\n",
      "      - -206202.19105789106\n",
      "      - -203949.72161582139\n",
      "      - -200129.86902089792\n",
      "      - -199555.66487545057\n",
      "      - -201978.56772771178\n",
      "      - -201780.21648082518\n",
      "      - -204606.30041830835\n",
      "      - -204042.15532865917\n",
      "      - -200951.9864781257\n",
      "      - -203229.93304556608\n",
      "      - -201589.0465777249\n",
      "      - -197823.33430373808\n",
      "      - -204039.60756284438\n",
      "      - -202660.39968319456\n",
      "      - -203708.43765289112\n",
      "      - -206370.92811953436\n",
      "      - -202044.95557731102\n",
      "      - -204486.87135709633\n",
      "      - -206887.98250542983\n",
      "      - -201861.13159636702\n",
      "      - -203585.8502789908\n",
      "      - -201147.87164184742\n",
      "      - -204791.23536270103\n",
      "      - -204984.5545855616\n",
      "      - -203559.31255799803\n",
      "      - -201916.9729233407\n",
      "      - -199425.15852286614\n",
      "      - -201037.14353637438\n",
      "      - -200714.5999512351\n",
      "      - -200777.86406460797\n",
      "      - -201813.98122483914\n",
      "      - -203389.46605737292\n",
      "      - -200867.69809395986\n",
      "      - -204151.80692492542\n",
      "      - -202204.80638995624\n",
      "      - -198681.08228470114\n",
      "      - -200928.14465556716\n",
      "      - -205935.91041618795\n",
      "      - -201889.83816170716\n",
      "      - -203596.6133953416\n",
      "      - -205354.04982574584\n",
      "      - -202203.0668715908\n",
      "      - -202299.90263756004\n",
      "      - -202040.40584633665\n",
      "      - -203664.7606023115\n",
      "      - -204294.08032093124\n",
      "      - -201881.44428844485\n",
      "      - -204283.3812382027\n",
      "      - -202303.39947047946\n",
      "      - -203043.57684490306\n",
      "      - -202763.9767660163\n",
      "      - -202751.58740725537\n",
      "      - -200695.86532521556\n",
      "      - -204520.76021582106\n",
      "      - -204885.73872133536\n",
      "      - -202647.73071519716\n",
      "      - -202568.18635139422\n",
      "      - -206544.60903135853\n",
      "      - -204465.49339932788\n",
      "      - -203624.09796772685\n",
      "      - -203557.09886942813\n",
      "      - -202818.9204345679\n",
      "      - -202902.27491684147\n",
      "      - -204656.43468340873\n",
      "      - -204392.78983912364\n",
      "      - -203304.0038851928\n",
      "      - -204023.45033639955\n",
      "      - -203139.55811823354\n",
      "      - -203008.29351914453\n",
      "      - -203342.8088725205\n",
      "      - -201897.9383386207\n",
      "      - -201336.93660349314\n",
      "      - -201193.2996777998\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09549716370132011\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4709398832385469\n",
      "      mean_inference_ms: 0.9707632251279534\n",
      "      mean_raw_obs_processing_ms: 0.1353827257443035\n",
      "  time_since_restore: 990.6943414211273\n",
      "  time_this_iter_s: 8.922122716903687\n",
      "  time_total_s: 990.6943414211273\n",
      "  timers:\n",
      "    learn_throughput: 127440.004\n",
      "    learn_time_ms: 502.072\n",
      "    load_throughput: 22022677.428\n",
      "    load_time_ms: 2.905\n",
      "    training_iteration_time_ms: 9571.581\n",
      "    update_time_ms: 4.226\n",
      "  timestamp: 1665849737\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6590352\n",
      "  training_iteration: 103\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:02:22 (running for 00:16:57.14)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   103</td><td style=\"text-align: right;\">         990.694</td><td style=\"text-align: right;\">6590352</td><td style=\"text-align: right;\"> -202870</td><td style=\"text-align: right;\">             -197823</td><td style=\"text-align: right;\">             -209660</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 6654336\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 6654336\n",
      "    num_agent_steps_trained: 6654336\n",
      "    num_env_steps_sampled: 6654336\n",
      "    num_env_steps_trained: 6654336\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-02-26\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -198024.4444429469\n",
      "  episode_reward_mean: -203103.12781371613\n",
      "  episode_reward_min: -236445.83985408902\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 6648\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1670548915863037\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0006706859567202628\n",
      "          model: {}\n",
      "          policy_loss: 0.007312648463994265\n",
      "          total_loss: 10.007129669189453\n",
      "          vf_explained_var: -3.4059798537100505e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 6654336\n",
      "    num_agent_steps_trained: 6654336\n",
      "    num_env_steps_sampled: 6654336\n",
      "    num_env_steps_trained: 6654336\n",
      "  iterations_since_restore: 104\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 6654336\n",
      "  num_agent_steps_trained: 6654336\n",
      "  num_env_steps_sampled: 6654336\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 6654336\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.29230769230769\n",
      "    ram_util_percent: 86.93076923076924\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09550587060915686\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.47073543058981293\n",
      "    mean_inference_ms: 0.9702756420853964\n",
      "    mean_raw_obs_processing_ms: 0.13550291080615812\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -198024.4444429469\n",
      "    episode_reward_mean: -203103.12781371613\n",
      "    episode_reward_min: -236445.83985408902\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -204151.80692492542\n",
      "      - -202204.80638995624\n",
      "      - -198681.08228470114\n",
      "      - -200928.14465556716\n",
      "      - -205935.91041618795\n",
      "      - -201889.83816170716\n",
      "      - -203596.6133953416\n",
      "      - -205354.04982574584\n",
      "      - -202203.0668715908\n",
      "      - -202299.90263756004\n",
      "      - -202040.40584633665\n",
      "      - -203664.7606023115\n",
      "      - -204294.08032093124\n",
      "      - -201881.44428844485\n",
      "      - -204283.3812382027\n",
      "      - -202303.39947047946\n",
      "      - -203043.57684490306\n",
      "      - -202763.9767660163\n",
      "      - -202751.58740725537\n",
      "      - -200695.86532521556\n",
      "      - -204520.76021582106\n",
      "      - -204885.73872133536\n",
      "      - -202647.73071519716\n",
      "      - -202568.18635139422\n",
      "      - -206544.60903135853\n",
      "      - -204465.49339932788\n",
      "      - -203624.09796772685\n",
      "      - -203557.09886942813\n",
      "      - -202818.9204345679\n",
      "      - -202902.27491684147\n",
      "      - -204656.43468340873\n",
      "      - -204392.78983912364\n",
      "      - -203304.0038851928\n",
      "      - -204023.45033639955\n",
      "      - -203139.55811823354\n",
      "      - -203008.29351914453\n",
      "      - -203342.8088725205\n",
      "      - -201897.9383386207\n",
      "      - -201336.93660349314\n",
      "      - -201193.2996777998\n",
      "      - -203389.507087481\n",
      "      - -205747.99400352954\n",
      "      - -199590.42262195444\n",
      "      - -204045.97662952158\n",
      "      - -203271.12528578565\n",
      "      - -201046.72882565574\n",
      "      - -236445.83985408902\n",
      "      - -202673.33902843637\n",
      "      - -203677.90526175537\n",
      "      - -199743.06249752297\n",
      "      - -201254.80252625528\n",
      "      - -202517.69358891496\n",
      "      - -202667.57687445762\n",
      "      - -204968.21068529808\n",
      "      - -206809.48694923412\n",
      "      - -200845.1498518445\n",
      "      - -208118.4435539284\n",
      "      - -202620.5655895129\n",
      "      - -201560.99725702842\n",
      "      - -200766.93705917304\n",
      "      - -201982.8073140536\n",
      "      - -199392.71628454202\n",
      "      - -202643.9427441242\n",
      "      - -204677.2981941563\n",
      "      - -200185.92219194214\n",
      "      - -198024.4444429469\n",
      "      - -200319.1297172312\n",
      "      - -202536.6725838832\n",
      "      - -201409.27751560212\n",
      "      - -203939.50869823364\n",
      "      - -207071.31786340335\n",
      "      - -204199.73619150158\n",
      "      - -208102.7276291176\n",
      "      - -202799.7152252639\n",
      "      - -202301.81769742668\n",
      "      - -200284.54271692623\n",
      "      - -200445.52016427973\n",
      "      - -200835.44625593725\n",
      "      - -199983.85247595745\n",
      "      - -202559.4515663973\n",
      "      - -200248.71044212882\n",
      "      - -201936.8975821524\n",
      "      - -202926.4405973844\n",
      "      - -202224.93791684034\n",
      "      - -202900.31972433472\n",
      "      - -207902.76986581105\n",
      "      - -202744.49026981965\n",
      "      - -202309.97085318365\n",
      "      - -199658.8936955511\n",
      "      - -204550.20087150027\n",
      "      - -202184.81485169625\n",
      "      - -201508.97542529218\n",
      "      - -203255.82035424124\n",
      "      - -202861.40652200053\n",
      "      - -204857.9881343977\n",
      "      - -199421.33552811557\n",
      "      - -205908.86886234238\n",
      "      - -200782.45062488434\n",
      "      - -200060.9568870405\n",
      "      - -202810.79568827443\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09550587060915686\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.47073543058981293\n",
      "      mean_inference_ms: 0.9702756420853964\n",
      "      mean_raw_obs_processing_ms: 0.13550291080615812\n",
      "  time_since_restore: 999.8383655548096\n",
      "  time_this_iter_s: 9.144024133682251\n",
      "  time_total_s: 999.8383655548096\n",
      "  timers:\n",
      "    learn_throughput: 129445.192\n",
      "    learn_time_ms: 494.294\n",
      "    load_throughput: 21923369.207\n",
      "    load_time_ms: 2.919\n",
      "    training_iteration_time_ms: 9539.75\n",
      "    update_time_ms: 4.295\n",
      "  timestamp: 1665849746\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6654336\n",
      "  training_iteration: 104\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:02:32 (running for 00:17:06.43)<br>Memory usage on this node: 13.4/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   104</td><td style=\"text-align: right;\">         999.838</td><td style=\"text-align: right;\">6654336</td><td style=\"text-align: right;\"> -203103</td><td style=\"text-align: right;\">             -198024</td><td style=\"text-align: right;\">             -236446</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 6718320\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 6718320\n",
      "    num_agent_steps_trained: 6718320\n",
      "    num_env_steps_sampled: 6718320\n",
      "    num_env_steps_trained: 6718320\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-02-36\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -198024.4444429469\n",
      "  episode_reward_mean: -202668.0148050614\n",
      "  episode_reward_min: -209188.913197681\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 6708\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1629066467285156\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0005477445665746927\n",
      "          model: {}\n",
      "          policy_loss: 0.002418721094727516\n",
      "          total_loss: 10.00221061706543\n",
      "          vf_explained_var: -4.068253645073128e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 6718320\n",
      "    num_agent_steps_trained: 6718320\n",
      "    num_env_steps_sampled: 6718320\n",
      "    num_env_steps_trained: 6718320\n",
      "  iterations_since_restore: 105\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 6718320\n",
      "  num_agent_steps_trained: 6718320\n",
      "  num_env_steps_sampled: 6718320\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 6718320\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.93076923076923\n",
      "    ram_util_percent: 86.9\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09541493725072328\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.47081130985026204\n",
      "    mean_inference_ms: 0.969961693959069\n",
      "    mean_raw_obs_processing_ms: 0.13541248023280272\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -198024.4444429469\n",
      "    episode_reward_mean: -202668.0148050614\n",
      "    episode_reward_min: -209188.913197681\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -201982.8073140536\n",
      "      - -199392.71628454202\n",
      "      - -202643.9427441242\n",
      "      - -204677.2981941563\n",
      "      - -200185.92219194214\n",
      "      - -198024.4444429469\n",
      "      - -200319.1297172312\n",
      "      - -202536.6725838832\n",
      "      - -201409.27751560212\n",
      "      - -203939.50869823364\n",
      "      - -207071.31786340335\n",
      "      - -204199.73619150158\n",
      "      - -208102.7276291176\n",
      "      - -202799.7152252639\n",
      "      - -202301.81769742668\n",
      "      - -200284.54271692623\n",
      "      - -200445.52016427973\n",
      "      - -200835.44625593725\n",
      "      - -199983.85247595745\n",
      "      - -202559.4515663973\n",
      "      - -200248.71044212882\n",
      "      - -201936.8975821524\n",
      "      - -202926.4405973844\n",
      "      - -202224.93791684034\n",
      "      - -202900.31972433472\n",
      "      - -207902.76986581105\n",
      "      - -202744.49026981965\n",
      "      - -202309.97085318365\n",
      "      - -199658.8936955511\n",
      "      - -204550.20087150027\n",
      "      - -202184.81485169625\n",
      "      - -201508.97542529218\n",
      "      - -203255.82035424124\n",
      "      - -202861.40652200053\n",
      "      - -204857.9881343977\n",
      "      - -199421.33552811557\n",
      "      - -205908.86886234238\n",
      "      - -200782.45062488434\n",
      "      - -200060.9568870405\n",
      "      - -202810.79568827443\n",
      "      - -202229.21087558338\n",
      "      - -200069.2271543858\n",
      "      - -201152.5950392527\n",
      "      - -204834.44104551716\n",
      "      - -204892.54582502553\n",
      "      - -204042.47702018515\n",
      "      - -204069.39746455848\n",
      "      - -203144.02623256916\n",
      "      - -201993.08992415748\n",
      "      - -201662.11602028835\n",
      "      - -203328.6804992368\n",
      "      - -202721.5501050069\n",
      "      - -204781.03418323316\n",
      "      - -200694.8451411987\n",
      "      - -203440.33329124318\n",
      "      - -203772.04276454076\n",
      "      - -199254.6088867496\n",
      "      - -203384.73398194014\n",
      "      - -201467.15978585274\n",
      "      - -201072.83525741135\n",
      "      - -206012.73901781082\n",
      "      - -200676.07709969577\n",
      "      - -202686.7096187543\n",
      "      - -205953.52696965338\n",
      "      - -199753.71363876833\n",
      "      - -204950.12778851468\n",
      "      - -202999.34564469152\n",
      "      - -201340.35561197283\n",
      "      - -198286.47947472456\n",
      "      - -202750.41228809257\n",
      "      - -209188.913197681\n",
      "      - -207110.65277732408\n",
      "      - -204219.9499228099\n",
      "      - -203786.65620050003\n",
      "      - -203596.47209488016\n",
      "      - -201710.7562065595\n",
      "      - -202544.44035110134\n",
      "      - -203244.4266663036\n",
      "      - -203192.34584881132\n",
      "      - -205023.64038551456\n",
      "      - -201930.10400745904\n",
      "      - -202731.2668273157\n",
      "      - -201939.75387456987\n",
      "      - -203145.92894797205\n",
      "      - -203563.63515725048\n",
      "      - -203863.63637542987\n",
      "      - -202567.3180135643\n",
      "      - -198905.00524559795\n",
      "      - -201691.8024213682\n",
      "      - -202794.37083160403\n",
      "      - -202194.17156633094\n",
      "      - -199953.9055798343\n",
      "      - -203235.4903315628\n",
      "      - -204348.67060842295\n",
      "      - -202577.62301331075\n",
      "      - -202410.69451440222\n",
      "      - -202472.9935479987\n",
      "      - -202332.01317826717\n",
      "      - -204363.0671603577\n",
      "      - -203992.44583150736\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09541493725072328\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.47081130985026204\n",
      "      mean_inference_ms: 0.969961693959069\n",
      "      mean_raw_obs_processing_ms: 0.13541248023280272\n",
      "  time_since_restore: 1009.2438497543335\n",
      "  time_this_iter_s: 9.405484199523926\n",
      "  time_total_s: 1009.2438497543335\n",
      "  timers:\n",
      "    learn_throughput: 128910.441\n",
      "    learn_time_ms: 496.345\n",
      "    load_throughput: 21890286.641\n",
      "    load_time_ms: 2.923\n",
      "    training_iteration_time_ms: 9473.165\n",
      "    update_time_ms: 4.356\n",
      "  timestamp: 1665849756\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6718320\n",
      "  training_iteration: 105\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:02:41 (running for 00:17:16.13)<br>Memory usage on this node: 13.4/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   105</td><td style=\"text-align: right;\">         1009.24</td><td style=\"text-align: right;\">6718320</td><td style=\"text-align: right;\"> -202668</td><td style=\"text-align: right;\">             -198024</td><td style=\"text-align: right;\">             -209189</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 6782304\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 6782304\n",
      "    num_agent_steps_trained: 6782304\n",
      "    num_env_steps_sampled: 6782304\n",
      "    num_env_steps_trained: 6782304\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-02-45\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -198325.721627572\n",
      "  episode_reward_mean: -203083.6776374626\n",
      "  episode_reward_min: -229575.18688274364\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 6780\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.161491870880127\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0007220992119982839\n",
      "          model: {}\n",
      "          policy_loss: 0.0035069428849965334\n",
      "          total_loss: 10.003336906433105\n",
      "          vf_explained_var: -1.7029899268550253e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 6782304\n",
      "    num_agent_steps_trained: 6782304\n",
      "    num_env_steps_sampled: 6782304\n",
      "    num_env_steps_trained: 6782304\n",
      "  iterations_since_restore: 106\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 6782304\n",
      "  num_agent_steps_trained: 6782304\n",
      "  num_env_steps_sampled: 6782304\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 6782304\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.4076923076923\n",
      "    ram_util_percent: 86.84615384615383\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.095360094376508\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.47045778123029613\n",
      "    mean_inference_ms: 0.969868220699858\n",
      "    mean_raw_obs_processing_ms: 0.13525061568807414\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -198325.721627572\n",
      "    episode_reward_mean: -203083.6776374626\n",
      "    episode_reward_min: -229575.18688274364\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -204219.9499228099\n",
      "      - -203786.65620050003\n",
      "      - -203596.47209488016\n",
      "      - -201710.7562065595\n",
      "      - -202544.44035110134\n",
      "      - -203244.4266663036\n",
      "      - -203192.34584881132\n",
      "      - -205023.64038551456\n",
      "      - -201930.10400745904\n",
      "      - -202731.2668273157\n",
      "      - -201939.75387456987\n",
      "      - -203145.92894797205\n",
      "      - -203563.63515725048\n",
      "      - -203863.63637542987\n",
      "      - -202567.3180135643\n",
      "      - -198905.00524559795\n",
      "      - -201691.8024213682\n",
      "      - -202794.37083160403\n",
      "      - -202194.17156633094\n",
      "      - -199953.9055798343\n",
      "      - -203235.4903315628\n",
      "      - -204348.67060842295\n",
      "      - -202577.62301331075\n",
      "      - -202410.69451440222\n",
      "      - -202472.9935479987\n",
      "      - -202332.01317826717\n",
      "      - -204363.0671603577\n",
      "      - -203992.44583150736\n",
      "      - -202285.2033150253\n",
      "      - -202068.61048453941\n",
      "      - -201606.27534944017\n",
      "      - -203785.7001406134\n",
      "      - -200253.3658668468\n",
      "      - -201404.67882769354\n",
      "      - -207618.5504906399\n",
      "      - -201710.81175963\n",
      "      - -201734.94906917485\n",
      "      - -201674.62857860362\n",
      "      - -203456.8358369472\n",
      "      - -199971.52923235856\n",
      "      - -203896.57239290344\n",
      "      - -203208.41871117186\n",
      "      - -201452.11228855725\n",
      "      - -199459.12138286288\n",
      "      - -201697.75476297896\n",
      "      - -203669.44102007698\n",
      "      - -203952.95685014562\n",
      "      - -201341.0920543829\n",
      "      - -204161.41840028128\n",
      "      - -204830.5557464869\n",
      "      - -203149.35250323225\n",
      "      - -200676.074248399\n",
      "      - -202801.63214922053\n",
      "      - -199712.59389887165\n",
      "      - -201346.84387950107\n",
      "      - -202362.24859490476\n",
      "      - -201454.66011026973\n",
      "      - -201708.47269566523\n",
      "      - -205182.9500442757\n",
      "      - -201294.79621876753\n",
      "      - -202263.8612234571\n",
      "      - -204744.60636357276\n",
      "      - -203655.93146824196\n",
      "      - -204766.43322435158\n",
      "      - -200145.36819412917\n",
      "      - -202050.6625151403\n",
      "      - -205825.6542250913\n",
      "      - -201886.106858582\n",
      "      - -202988.70486180848\n",
      "      - -201810.64005539793\n",
      "      - -203878.38556583732\n",
      "      - -201920.07810578088\n",
      "      - -203385.5608757294\n",
      "      - -205264.0930177048\n",
      "      - -201597.40366151676\n",
      "      - -203091.9031827727\n",
      "      - -205134.58915067787\n",
      "      - -205343.46602114674\n",
      "      - -201161.81690959883\n",
      "      - -202979.54611659204\n",
      "      - -229575.18688274364\n",
      "      - -198325.721627572\n",
      "      - -201362.5838082733\n",
      "      - -205276.8778021944\n",
      "      - -204028.07403989724\n",
      "      - -205941.96405622122\n",
      "      - -203289.24011003858\n",
      "      - -204445.96279144415\n",
      "      - -202042.65820137388\n",
      "      - -200230.55687882742\n",
      "      - -207992.970642252\n",
      "      - -205389.18058592183\n",
      "      - -203284.7722173794\n",
      "      - -204161.39856009334\n",
      "      - -203094.01420372122\n",
      "      - -201711.85906969552\n",
      "      - -203056.47754667784\n",
      "      - -202552.6302573067\n",
      "      - -203493.49734915883\n",
      "      - -201954.5339032611\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.095360094376508\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.47045778123029613\n",
      "      mean_inference_ms: 0.969868220699858\n",
      "      mean_raw_obs_processing_ms: 0.13525061568807414\n",
      "  time_since_restore: 1018.5910623073578\n",
      "  time_this_iter_s: 9.347212553024292\n",
      "  time_total_s: 1018.5910623073578\n",
      "  timers:\n",
      "    learn_throughput: 128462.025\n",
      "    learn_time_ms: 498.077\n",
      "    load_throughput: 21827792.818\n",
      "    load_time_ms: 2.931\n",
      "    training_iteration_time_ms: 9447.915\n",
      "    update_time_ms: 4.259\n",
      "  timestamp: 1665849765\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6782304\n",
      "  training_iteration: 106\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:02:50 (running for 00:17:25.14)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   106</td><td style=\"text-align: right;\">         1018.59</td><td style=\"text-align: right;\">6782304</td><td style=\"text-align: right;\"> -203084</td><td style=\"text-align: right;\">             -198326</td><td style=\"text-align: right;\">             -229575</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 6846288\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 6846288\n",
      "    num_agent_steps_trained: 6846288\n",
      "    num_env_steps_sampled: 6846288\n",
      "    num_env_steps_trained: 6846288\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-02-55\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -198019.8611500153\n",
      "  episode_reward_mean: -203301.26052771456\n",
      "  episode_reward_min: -229575.18688274364\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 6840\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1637654304504395\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00046325832954607904\n",
      "          model: {}\n",
      "          policy_loss: 0.006791442167013884\n",
      "          total_loss: 10.00656795501709\n",
      "          vf_explained_var: -1.8922110101016187e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 6846288\n",
      "    num_agent_steps_trained: 6846288\n",
      "    num_env_steps_sampled: 6846288\n",
      "    num_env_steps_trained: 6846288\n",
      "  iterations_since_restore: 107\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 6846288\n",
      "  num_agent_steps_trained: 6846288\n",
      "  num_env_steps_sampled: 6846288\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 6846288\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.10714285714286\n",
      "    ram_util_percent: 86.83571428571427\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09539747528999933\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.47033742680065144\n",
      "    mean_inference_ms: 0.9697861295792499\n",
      "    mean_raw_obs_processing_ms: 0.13539644662558645\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -198019.8611500153\n",
      "    episode_reward_mean: -203301.26052771456\n",
      "    episode_reward_min: -229575.18688274364\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -202263.8612234571\n",
      "      - -204744.60636357276\n",
      "      - -203655.93146824196\n",
      "      - -204766.43322435158\n",
      "      - -200145.36819412917\n",
      "      - -202050.6625151403\n",
      "      - -205825.6542250913\n",
      "      - -201886.106858582\n",
      "      - -202988.70486180848\n",
      "      - -201810.64005539793\n",
      "      - -203878.38556583732\n",
      "      - -201920.07810578088\n",
      "      - -203385.5608757294\n",
      "      - -205264.0930177048\n",
      "      - -201597.40366151676\n",
      "      - -203091.9031827727\n",
      "      - -205134.58915067787\n",
      "      - -205343.46602114674\n",
      "      - -201161.81690959883\n",
      "      - -202979.54611659204\n",
      "      - -229575.18688274364\n",
      "      - -198325.721627572\n",
      "      - -201362.5838082733\n",
      "      - -205276.8778021944\n",
      "      - -204028.07403989724\n",
      "      - -205941.96405622122\n",
      "      - -203289.24011003858\n",
      "      - -204445.96279144415\n",
      "      - -202042.65820137388\n",
      "      - -200230.55687882742\n",
      "      - -207992.970642252\n",
      "      - -205389.18058592183\n",
      "      - -203284.7722173794\n",
      "      - -204161.39856009334\n",
      "      - -203094.01420372122\n",
      "      - -201711.85906969552\n",
      "      - -203056.47754667784\n",
      "      - -202552.6302573067\n",
      "      - -203493.49734915883\n",
      "      - -201954.5339032611\n",
      "      - -205188.704265779\n",
      "      - -200190.4797552763\n",
      "      - -205239.98392674845\n",
      "      - -204260.41681583962\n",
      "      - -205036.2434444171\n",
      "      - -204717.44266630165\n",
      "      - -202777.03852166425\n",
      "      - -201407.2522009088\n",
      "      - -200379.89289772307\n",
      "      - -202398.30781603203\n",
      "      - -205080.91731654239\n",
      "      - -202210.07452300712\n",
      "      - -205352.70489861383\n",
      "      - -203676.98806414404\n",
      "      - -202129.48366268998\n",
      "      - -208559.23724931956\n",
      "      - -204969.84693640066\n",
      "      - -201100.73092195948\n",
      "      - -202964.70134879882\n",
      "      - -207076.65339692702\n",
      "      - -200346.96992217982\n",
      "      - -199850.467718126\n",
      "      - -204229.58029634357\n",
      "      - -200667.08085686408\n",
      "      - -202330.06465156726\n",
      "      - -200002.9524540173\n",
      "      - -203959.49150177813\n",
      "      - -207489.32536423396\n",
      "      - -206325.86489058493\n",
      "      - -200951.74399316372\n",
      "      - -201089.2905450428\n",
      "      - -203219.56624148955\n",
      "      - -200533.59858220676\n",
      "      - -201884.4349344662\n",
      "      - -201256.9539439274\n",
      "      - -202090.54325392196\n",
      "      - -200382.69295816007\n",
      "      - -204484.2963194867\n",
      "      - -201673.90344566587\n",
      "      - -198019.8611500153\n",
      "      - -202105.13318329782\n",
      "      - -203827.14557857078\n",
      "      - -204557.9997655166\n",
      "      - -203085.8210673415\n",
      "      - -208597.21999871574\n",
      "      - -206353.2060562729\n",
      "      - -201974.77707702227\n",
      "      - -201285.73876764622\n",
      "      - -202319.72669786605\n",
      "      - -204043.58795543713\n",
      "      - -203382.35319262094\n",
      "      - -200785.2215791497\n",
      "      - -201334.01181784598\n",
      "      - -203398.58533399916\n",
      "      - -201620.2305010627\n",
      "      - -202351.90669813918\n",
      "      - -201131.5016286294\n",
      "      - -201798.30299745678\n",
      "      - -203818.47051076897\n",
      "      - -201744.35658057683\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09539747528999933\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.47033742680065144\n",
      "      mean_inference_ms: 0.9697861295792499\n",
      "      mean_raw_obs_processing_ms: 0.13539644662558645\n",
      "  time_since_restore: 1028.087551832199\n",
      "  time_this_iter_s: 9.496489524841309\n",
      "  time_total_s: 1028.087551832199\n",
      "  timers:\n",
      "    learn_throughput: 129903.358\n",
      "    learn_time_ms: 492.551\n",
      "    load_throughput: 21811117.109\n",
      "    load_time_ms: 2.934\n",
      "    training_iteration_time_ms: 9394.16\n",
      "    update_time_ms: 4.152\n",
      "  timestamp: 1665849775\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6846288\n",
      "  training_iteration: 107\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:03:00 (running for 00:17:35.16)<br>Memory usage on this node: 13.4/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   107</td><td style=\"text-align: right;\">         1028.09</td><td style=\"text-align: right;\">6846288</td><td style=\"text-align: right;\"> -203301</td><td style=\"text-align: right;\">             -198020</td><td style=\"text-align: right;\">             -229575</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 6910272\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 6910272\n",
      "    num_agent_steps_trained: 6910272\n",
      "    num_env_steps_sampled: 6910272\n",
      "    num_env_steps_trained: 6910272\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-03-04\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -198019.8611500153\n",
      "  episode_reward_mean: -202723.7370126496\n",
      "  episode_reward_min: -209161.98678694793\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 6900\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1621546745300293\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0007091466686688364\n",
      "          model: {}\n",
      "          policy_loss: 0.0019078647019341588\n",
      "          total_loss: 10.001734733581543\n",
      "          vf_explained_var: -3.216758770463457e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 6910272\n",
      "    num_agent_steps_trained: 6910272\n",
      "    num_env_steps_sampled: 6910272\n",
      "    num_env_steps_trained: 6910272\n",
      "  iterations_since_restore: 108\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 6910272\n",
      "  num_agent_steps_trained: 6910272\n",
      "  num_env_steps_sampled: 6910272\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 6910272\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.52307692307694\n",
      "    ram_util_percent: 86.79999999999998\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09531357542540811\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.47041856972567714\n",
      "    mean_inference_ms: 0.9695028677580457\n",
      "    mean_raw_obs_processing_ms: 0.13531068413210753\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -198019.8611500153\n",
      "    episode_reward_mean: -202723.7370126496\n",
      "    episode_reward_min: -209161.98678694793\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -200346.96992217982\n",
      "      - -199850.467718126\n",
      "      - -204229.58029634357\n",
      "      - -200667.08085686408\n",
      "      - -202330.06465156726\n",
      "      - -200002.9524540173\n",
      "      - -203959.49150177813\n",
      "      - -207489.32536423396\n",
      "      - -206325.86489058493\n",
      "      - -200951.74399316372\n",
      "      - -201089.2905450428\n",
      "      - -203219.56624148955\n",
      "      - -200533.59858220676\n",
      "      - -201884.4349344662\n",
      "      - -201256.9539439274\n",
      "      - -202090.54325392196\n",
      "      - -200382.69295816007\n",
      "      - -204484.2963194867\n",
      "      - -201673.90344566587\n",
      "      - -198019.8611500153\n",
      "      - -202105.13318329782\n",
      "      - -203827.14557857078\n",
      "      - -204557.9997655166\n",
      "      - -203085.8210673415\n",
      "      - -208597.21999871574\n",
      "      - -206353.2060562729\n",
      "      - -201974.77707702227\n",
      "      - -201285.73876764622\n",
      "      - -202319.72669786605\n",
      "      - -204043.58795543713\n",
      "      - -203382.35319262094\n",
      "      - -200785.2215791497\n",
      "      - -201334.01181784598\n",
      "      - -203398.58533399916\n",
      "      - -201620.2305010627\n",
      "      - -202351.90669813918\n",
      "      - -201131.5016286294\n",
      "      - -201798.30299745678\n",
      "      - -203818.47051076897\n",
      "      - -201744.35658057683\n",
      "      - -205207.28109321787\n",
      "      - -202252.27002046703\n",
      "      - -206976.61310502255\n",
      "      - -201677.88922548533\n",
      "      - -204623.2513642886\n",
      "      - -201503.0368643666\n",
      "      - -204809.0893341332\n",
      "      - -203581.60758352317\n",
      "      - -203014.32060595838\n",
      "      - -203883.163533286\n",
      "      - -200872.20777310178\n",
      "      - -201710.85161110715\n",
      "      - -202736.34448379782\n",
      "      - -204770.26409944083\n",
      "      - -200740.47301537296\n",
      "      - -200701.4479219485\n",
      "      - -199873.75708340696\n",
      "      - -206384.30818450113\n",
      "      - -201299.54201015283\n",
      "      - -202852.85933365146\n",
      "      - -203427.83333026673\n",
      "      - -202682.26702582985\n",
      "      - -199112.63554248333\n",
      "      - -199846.62734321854\n",
      "      - -201091.10801938135\n",
      "      - -202545.97677673437\n",
      "      - -199917.09741555512\n",
      "      - -200509.60403059423\n",
      "      - -200789.09802025213\n",
      "      - -203495.30831611625\n",
      "      - -201934.6042441958\n",
      "      - -200171.4797854867\n",
      "      - -202816.0780067791\n",
      "      - -205231.31743207734\n",
      "      - -204762.61654355182\n",
      "      - -207184.69513117927\n",
      "      - -204545.49824850183\n",
      "      - -199642.62760285116\n",
      "      - -202149.54811148584\n",
      "      - -205537.50940586237\n",
      "      - -205831.17772962333\n",
      "      - -203020.20113141832\n",
      "      - -204858.12520571915\n",
      "      - -208132.15227114613\n",
      "      - -199140.0084386647\n",
      "      - -202210.74230206024\n",
      "      - -207686.9933423764\n",
      "      - -200478.54157801124\n",
      "      - -200165.77799508534\n",
      "      - -200032.1627165948\n",
      "      - -202229.23019397777\n",
      "      - -202996.09656824058\n",
      "      - -200056.60112521754\n",
      "      - -200270.68016824193\n",
      "      - -209161.98678694793\n",
      "      - -204247.85978272866\n",
      "      - -198596.28078520074\n",
      "      - -202708.63105577457\n",
      "      - -207559.25726558856\n",
      "      - -205823.10623252817\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09531357542540811\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.47041856972567714\n",
      "      mean_inference_ms: 0.9695028677580457\n",
      "      mean_raw_obs_processing_ms: 0.13531068413210753\n",
      "  time_since_restore: 1037.3549625873566\n",
      "  time_this_iter_s: 9.26741075515747\n",
      "  time_total_s: 1037.3549625873566\n",
      "  timers:\n",
      "    learn_throughput: 130536.888\n",
      "    learn_time_ms: 490.16\n",
      "    load_throughput: 21757008.394\n",
      "    load_time_ms: 2.941\n",
      "    training_iteration_time_ms: 9349.472\n",
      "    update_time_ms: 4.263\n",
      "  timestamp: 1665849784\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6910272\n",
      "  training_iteration: 108\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:03:09 (running for 00:17:44.09)<br>Memory usage on this node: 13.4/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   108</td><td style=\"text-align: right;\">         1037.35</td><td style=\"text-align: right;\">6910272</td><td style=\"text-align: right;\"> -202724</td><td style=\"text-align: right;\">             -198020</td><td style=\"text-align: right;\">             -209162</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 6974256\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 6974256\n",
      "    num_agent_steps_trained: 6974256\n",
      "    num_env_steps_sampled: 6974256\n",
      "    num_env_steps_trained: 6974256\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-03-13\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -198596.28078520074\n",
      "  episode_reward_mean: -202608.18568475195\n",
      "  episode_reward_min: -209161.98678694793\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 6972\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.157299041748047\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0006118750898167491\n",
      "          model: {}\n",
      "          policy_loss: 0.003028400707989931\n",
      "          total_loss: 10.00283432006836\n",
      "          vf_explained_var: -2.838316426334586e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 6974256\n",
      "    num_agent_steps_trained: 6974256\n",
      "    num_env_steps_sampled: 6974256\n",
      "    num_env_steps_trained: 6974256\n",
      "  iterations_since_restore: 109\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 6974256\n",
      "  num_agent_steps_trained: 6974256\n",
      "  num_env_steps_sampled: 6974256\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 6974256\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.46923076923078\n",
      "    ram_util_percent: 86.8307692307692\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09525435062632007\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.47017551853100775\n",
      "    mean_inference_ms: 0.9693196945575144\n",
      "    mean_raw_obs_processing_ms: 0.13514080145151003\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -198596.28078520074\n",
      "    episode_reward_mean: -202608.18568475195\n",
      "    episode_reward_min: -209161.98678694793\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -202816.0780067791\n",
      "      - -205231.31743207734\n",
      "      - -204762.61654355182\n",
      "      - -207184.69513117927\n",
      "      - -204545.49824850183\n",
      "      - -199642.62760285116\n",
      "      - -202149.54811148584\n",
      "      - -205537.50940586237\n",
      "      - -205831.17772962333\n",
      "      - -203020.20113141832\n",
      "      - -204858.12520571915\n",
      "      - -208132.15227114613\n",
      "      - -199140.0084386647\n",
      "      - -202210.74230206024\n",
      "      - -207686.9933423764\n",
      "      - -200478.54157801124\n",
      "      - -200165.77799508534\n",
      "      - -200032.1627165948\n",
      "      - -202229.23019397777\n",
      "      - -202996.09656824058\n",
      "      - -200056.60112521754\n",
      "      - -200270.68016824193\n",
      "      - -209161.98678694793\n",
      "      - -204247.85978272866\n",
      "      - -198596.28078520074\n",
      "      - -202708.63105577457\n",
      "      - -207559.25726558856\n",
      "      - -205823.10623252817\n",
      "      - -202453.7011333524\n",
      "      - -201441.1246581373\n",
      "      - -201767.4051775497\n",
      "      - -199533.15065044136\n",
      "      - -202247.97222526406\n",
      "      - -201998.23093622673\n",
      "      - -203533.22619884508\n",
      "      - -200745.1706846577\n",
      "      - -200304.77895602037\n",
      "      - -200003.4024112823\n",
      "      - -202911.3952456878\n",
      "      - -198831.30305276022\n",
      "      - -207562.61766939957\n",
      "      - -200320.22067475106\n",
      "      - -200955.19297005757\n",
      "      - -207758.91935778706\n",
      "      - -205250.9769545523\n",
      "      - -201037.76012820101\n",
      "      - -200286.73362429734\n",
      "      - -203901.71506097793\n",
      "      - -203463.39656787066\n",
      "      - -200849.7792116052\n",
      "      - -200378.2109426967\n",
      "      - -201717.51757230947\n",
      "      - -204685.74782622585\n",
      "      - -202683.51135425462\n",
      "      - -200195.1707548213\n",
      "      - -200565.9332332119\n",
      "      - -201389.21691569514\n",
      "      - -203251.79547045534\n",
      "      - -204813.2625564475\n",
      "      - -201545.05035899364\n",
      "      - -200765.71099397837\n",
      "      - -199299.73281395892\n",
      "      - -200908.6226683603\n",
      "      - -202959.09133834759\n",
      "      - -203119.43360191883\n",
      "      - -202967.99468866616\n",
      "      - -199892.08931778182\n",
      "      - -202383.79563568297\n",
      "      - -200287.65772967102\n",
      "      - -203721.17805342813\n",
      "      - -207296.00142516455\n",
      "      - -199980.27317906942\n",
      "      - -202664.93922218255\n",
      "      - -198702.06049460216\n",
      "      - -198812.73242938376\n",
      "      - -200494.53666474938\n",
      "      - -202316.60819974262\n",
      "      - -205374.25309039888\n",
      "      - -202519.8646554454\n",
      "      - -199510.5569423771\n",
      "      - -201975.84278780528\n",
      "      - -205317.14073117758\n",
      "      - -203381.00155333118\n",
      "      - -199626.30067827489\n",
      "      - -203180.43450497498\n",
      "      - -201287.72959388286\n",
      "      - -202054.43729820498\n",
      "      - -208535.15457991735\n",
      "      - -208992.5432727802\n",
      "      - -203883.91244883757\n",
      "      - -204467.88739785212\n",
      "      - -202493.00559230027\n",
      "      - -200297.45032073322\n",
      "      - -201179.2560295224\n",
      "      - -205257.05002076796\n",
      "      - -201640.749244841\n",
      "      - -202387.8033101556\n",
      "      - -202647.30372614868\n",
      "      - -203249.25567016038\n",
      "      - -199528.08287634174\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09525435062632007\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.47017551853100775\n",
      "      mean_inference_ms: 0.9693196945575144\n",
      "      mean_raw_obs_processing_ms: 0.13514080145151003\n",
      "  time_since_restore: 1046.744554758072\n",
      "  time_this_iter_s: 9.389592170715332\n",
      "  time_total_s: 1046.744554758072\n",
      "  timers:\n",
      "    learn_throughput: 131030.019\n",
      "    learn_time_ms: 488.316\n",
      "    load_throughput: 21513872.404\n",
      "    load_time_ms: 2.974\n",
      "    training_iteration_time_ms: 9329.274\n",
      "    update_time_ms: 4.166\n",
      "  timestamp: 1665849793\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6974256\n",
      "  training_iteration: 109\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:03:18 (running for 00:17:53.38)<br>Memory usage on this node: 13.4/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   109</td><td style=\"text-align: right;\">         1046.74</td><td style=\"text-align: right;\">6974256</td><td style=\"text-align: right;\"> -202608</td><td style=\"text-align: right;\">             -198596</td><td style=\"text-align: right;\">             -209162</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 7038240\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 7038240\n",
      "    num_agent_steps_trained: 7038240\n",
      "    num_env_steps_sampled: 7038240\n",
      "    num_env_steps_trained: 7038240\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-03-23\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -198164.3052731837\n",
      "  episode_reward_mean: -202485.67775966198\n",
      "  episode_reward_min: -234782.98529948207\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 7032\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1559624671936035\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0006241085357032716\n",
      "          model: {}\n",
      "          policy_loss: 0.006736636161804199\n",
      "          total_loss: 10.006545066833496\n",
      "          vf_explained_var: -3.12214822884016e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 7038240\n",
      "    num_agent_steps_trained: 7038240\n",
      "    num_env_steps_sampled: 7038240\n",
      "    num_env_steps_trained: 7038240\n",
      "  iterations_since_restore: 110\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 7038240\n",
      "  num_agent_steps_trained: 7038240\n",
      "  num_env_steps_sampled: 7038240\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 7038240\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 80.3076923076923\n",
      "    ram_util_percent: 86.83846153846153\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09526782202320845\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46998542829391887\n",
      "    mean_inference_ms: 0.9691472152659832\n",
      "    mean_raw_obs_processing_ms: 0.13526510442409645\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -198164.3052731837\n",
      "    episode_reward_mean: -202485.67775966198\n",
      "    episode_reward_min: -234782.98529948207\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -200765.71099397837\n",
      "      - -199299.73281395892\n",
      "      - -200908.6226683603\n",
      "      - -202959.09133834759\n",
      "      - -203119.43360191883\n",
      "      - -202967.99468866616\n",
      "      - -199892.08931778182\n",
      "      - -202383.79563568297\n",
      "      - -200287.65772967102\n",
      "      - -203721.17805342813\n",
      "      - -207296.00142516455\n",
      "      - -199980.27317906942\n",
      "      - -202664.93922218255\n",
      "      - -198702.06049460216\n",
      "      - -198812.73242938376\n",
      "      - -200494.53666474938\n",
      "      - -202316.60819974262\n",
      "      - -205374.25309039888\n",
      "      - -202519.8646554454\n",
      "      - -199510.5569423771\n",
      "      - -201975.84278780528\n",
      "      - -205317.14073117758\n",
      "      - -203381.00155333118\n",
      "      - -199626.30067827489\n",
      "      - -203180.43450497498\n",
      "      - -201287.72959388286\n",
      "      - -202054.43729820498\n",
      "      - -208535.15457991735\n",
      "      - -208992.5432727802\n",
      "      - -203883.91244883757\n",
      "      - -204467.88739785212\n",
      "      - -202493.00559230027\n",
      "      - -200297.45032073322\n",
      "      - -201179.2560295224\n",
      "      - -205257.05002076796\n",
      "      - -201640.749244841\n",
      "      - -202387.8033101556\n",
      "      - -202647.30372614868\n",
      "      - -203249.25567016038\n",
      "      - -199528.08287634174\n",
      "      - -200415.3350600684\n",
      "      - -202759.93567432096\n",
      "      - -198645.755669864\n",
      "      - -202410.841930031\n",
      "      - -205660.20619728236\n",
      "      - -203862.60375268746\n",
      "      - -204643.7717989672\n",
      "      - -205678.0132140182\n",
      "      - -201422.70278885675\n",
      "      - -200938.29549406495\n",
      "      - -201087.35537314537\n",
      "      - -200794.20379192464\n",
      "      - -201637.6326992071\n",
      "      - -206699.49998634186\n",
      "      - -205900.40278661667\n",
      "      - -201705.75439771265\n",
      "      - -203003.8429642365\n",
      "      - -203536.12498503932\n",
      "      - -206620.72957136156\n",
      "      - -201175.54754106567\n",
      "      - -204275.8877803445\n",
      "      - -199369.83969828585\n",
      "      - -202543.5573856085\n",
      "      - -198717.5374209761\n",
      "      - -201126.62945701467\n",
      "      - -199394.35649525182\n",
      "      - -204084.11388151813\n",
      "      - -202665.9184968355\n",
      "      - -202109.83453208517\n",
      "      - -207665.9349134977\n",
      "      - -201522.16919494074\n",
      "      - -201832.81602933593\n",
      "      - -199348.73942930013\n",
      "      - -200113.26208256272\n",
      "      - -204242.38371010893\n",
      "      - -234782.98529948207\n",
      "      - -202643.5419215305\n",
      "      - -203725.97404378536\n",
      "      - -200876.93854720084\n",
      "      - -198358.624284787\n",
      "      - -204313.63811587243\n",
      "      - -200374.26306167955\n",
      "      - -201040.32921811225\n",
      "      - -200345.75750779134\n",
      "      - -198770.64731280573\n",
      "      - -200221.21680298803\n",
      "      - -203695.5225349318\n",
      "      - -199846.5511154738\n",
      "      - -198441.87002652118\n",
      "      - -201570.0266323953\n",
      "      - -201035.01164679643\n",
      "      - -202208.2865963399\n",
      "      - -199991.10219980637\n",
      "      - -200712.11062873126\n",
      "      - -203890.51913007972\n",
      "      - -204730.2332849153\n",
      "      - -202609.86741426014\n",
      "      - -200736.22617048875\n",
      "      - -198164.3052731837\n",
      "      - -202511.2162288425\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09526782202320845\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46998542829391887\n",
      "      mean_inference_ms: 0.9691472152659832\n",
      "      mean_raw_obs_processing_ms: 0.13526510442409645\n",
      "  time_since_restore: 1055.9700593948364\n",
      "  time_this_iter_s: 9.225504636764526\n",
      "  time_total_s: 1055.9700593948364\n",
      "  timers:\n",
      "    learn_throughput: 130229.387\n",
      "    learn_time_ms: 491.318\n",
      "    load_throughput: 21584469.826\n",
      "    load_time_ms: 2.964\n",
      "    training_iteration_time_ms: 9359.444\n",
      "    update_time_ms: 4.153\n",
      "  timestamp: 1665849803\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7038240\n",
      "  training_iteration: 110\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:03:28 (running for 00:18:02.71)<br>Memory usage on this node: 13.4/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   110</td><td style=\"text-align: right;\">         1055.97</td><td style=\"text-align: right;\">7038240</td><td style=\"text-align: right;\"> -202486</td><td style=\"text-align: right;\">             -198164</td><td style=\"text-align: right;\">             -234783</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 7102224\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 7102224\n",
      "    num_agent_steps_trained: 7102224\n",
      "    num_env_steps_sampled: 7102224\n",
      "    num_env_steps_trained: 7102224\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-03-32\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -196496.62224666588\n",
      "  episode_reward_mean: -202031.51674437933\n",
      "  episode_reward_min: -234782.98529948207\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 7092\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1525022983551025\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0004052871372550726\n",
      "          model: {}\n",
      "          policy_loss: 0.002350329887121916\n",
      "          total_loss: 10.002117156982422\n",
      "          vf_explained_var: -2.4598742598413992e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 7102224\n",
      "    num_agent_steps_trained: 7102224\n",
      "    num_env_steps_sampled: 7102224\n",
      "    num_env_steps_trained: 7102224\n",
      "  iterations_since_restore: 111\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 7102224\n",
      "  num_agent_steps_trained: 7102224\n",
      "  num_env_steps_sampled: 7102224\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 7102224\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 80.9923076923077\n",
      "    ram_util_percent: 86.83846153846154\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09517502355802554\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4701146247131602\n",
      "    mean_inference_ms: 0.9687767370026863\n",
      "    mean_raw_obs_processing_ms: 0.1351742094688928\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -196496.62224666588\n",
      "    episode_reward_mean: -202031.51674437933\n",
      "    episode_reward_min: -234782.98529948207\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -204275.8877803445\n",
      "      - -199369.83969828585\n",
      "      - -202543.5573856085\n",
      "      - -198717.5374209761\n",
      "      - -201126.62945701467\n",
      "      - -199394.35649525182\n",
      "      - -204084.11388151813\n",
      "      - -202665.9184968355\n",
      "      - -202109.83453208517\n",
      "      - -207665.9349134977\n",
      "      - -201522.16919494074\n",
      "      - -201832.81602933593\n",
      "      - -199348.73942930013\n",
      "      - -200113.26208256272\n",
      "      - -204242.38371010893\n",
      "      - -234782.98529948207\n",
      "      - -202643.5419215305\n",
      "      - -203725.97404378536\n",
      "      - -200876.93854720084\n",
      "      - -198358.624284787\n",
      "      - -204313.63811587243\n",
      "      - -200374.26306167955\n",
      "      - -201040.32921811225\n",
      "      - -200345.75750779134\n",
      "      - -198770.64731280573\n",
      "      - -200221.21680298803\n",
      "      - -203695.5225349318\n",
      "      - -199846.5511154738\n",
      "      - -198441.87002652118\n",
      "      - -201570.0266323953\n",
      "      - -201035.01164679643\n",
      "      - -202208.2865963399\n",
      "      - -199991.10219980637\n",
      "      - -200712.11062873126\n",
      "      - -203890.51913007972\n",
      "      - -204730.2332849153\n",
      "      - -202609.86741426014\n",
      "      - -200736.22617048875\n",
      "      - -198164.3052731837\n",
      "      - -202511.2162288425\n",
      "      - -202210.4300279687\n",
      "      - -203901.6439635999\n",
      "      - -204136.34370354796\n",
      "      - -201785.333384451\n",
      "      - -200900.487506189\n",
      "      - -205802.77007881267\n",
      "      - -206330.79492913894\n",
      "      - -199354.80853782687\n",
      "      - -202412.33135659556\n",
      "      - -203172.88103627533\n",
      "      - -201020.5105273329\n",
      "      - -200421.83831687094\n",
      "      - -203073.52471091357\n",
      "      - -201132.2611744721\n",
      "      - -201941.293378478\n",
      "      - -203858.14528824168\n",
      "      - -196496.62224666588\n",
      "      - -200957.21719195065\n",
      "      - -198657.8609097237\n",
      "      - -200855.582526405\n",
      "      - -202107.5545405671\n",
      "      - -201474.530729929\n",
      "      - -199654.9898535853\n",
      "      - -203542.62608726035\n",
      "      - -199155.820243031\n",
      "      - -201732.60851851897\n",
      "      - -200699.6853554661\n",
      "      - -203649.9317238835\n",
      "      - -203911.26902995654\n",
      "      - -201630.68324733453\n",
      "      - -205709.37973346104\n",
      "      - -198383.096922719\n",
      "      - -200799.29543979256\n",
      "      - -203280.28831603815\n",
      "      - -200207.29857644552\n",
      "      - -201998.63522899404\n",
      "      - -202478.21066489106\n",
      "      - -203785.7077067876\n",
      "      - -201219.3169639088\n",
      "      - -199791.69730635337\n",
      "      - -200008.1658425607\n",
      "      - -203421.29950227236\n",
      "      - -205910.49771039633\n",
      "      - -200850.96390700445\n",
      "      - -203108.2234807683\n",
      "      - -199517.0137771257\n",
      "      - -199227.46163611228\n",
      "      - -200105.66283816422\n",
      "      - -202238.53058411673\n",
      "      - -205749.5699369866\n",
      "      - -200189.1852543382\n",
      "      - -206369.61392157935\n",
      "      - -200588.7229161255\n",
      "      - -203700.88206039535\n",
      "      - -200597.0946580805\n",
      "      - -204048.17520618116\n",
      "      - -197432.68881068332\n",
      "      - -199323.29371392145\n",
      "      - -200038.9236089672\n",
      "      - -202480.65258130594\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09517502355802554\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4701146247131602\n",
      "      mean_inference_ms: 0.9687767370026863\n",
      "      mean_raw_obs_processing_ms: 0.1351742094688928\n",
      "  time_since_restore: 1065.2985949516296\n",
      "  time_this_iter_s: 9.328535556793213\n",
      "  time_total_s: 1065.2985949516296\n",
      "  timers:\n",
      "    learn_throughput: 130006.279\n",
      "    learn_time_ms: 492.161\n",
      "    load_throughput: 21598888.31\n",
      "    load_time_ms: 2.962\n",
      "    training_iteration_time_ms: 9298.887\n",
      "    update_time_ms: 4.178\n",
      "  timestamp: 1665849812\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7102224\n",
      "  training_iteration: 111\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:03:37 (running for 00:18:12.20)<br>Memory usage on this node: 13.4/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   111</td><td style=\"text-align: right;\">          1065.3</td><td style=\"text-align: right;\">7102224</td><td style=\"text-align: right;\"> -202032</td><td style=\"text-align: right;\">             -196497</td><td style=\"text-align: right;\">             -234783</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 7166208\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 7166208\n",
      "    num_agent_steps_trained: 7166208\n",
      "    num_env_steps_sampled: 7166208\n",
      "    num_env_steps_trained: 7166208\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-03-42\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -197432.68881068332\n",
      "  episode_reward_mean: -201907.03794301755\n",
      "  episode_reward_min: -206463.48816313394\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 7164\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.151885986328125\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0004311231314204633\n",
      "          model: {}\n",
      "          policy_loss: 0.002612803829833865\n",
      "          total_loss: 10.0023832321167\n",
      "          vf_explained_var: -5.108969602929392e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 7166208\n",
      "    num_agent_steps_trained: 7166208\n",
      "    num_env_steps_sampled: 7166208\n",
      "    num_env_steps_trained: 7166208\n",
      "  iterations_since_restore: 112\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 7166208\n",
      "  num_agent_steps_trained: 7166208\n",
      "  num_env_steps_sampled: 7166208\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 7166208\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.7076923076923\n",
      "    ram_util_percent: 86.88461538461539\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09512613630221906\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46979382879323067\n",
      "    mean_inference_ms: 0.9686720415403305\n",
      "    mean_raw_obs_processing_ms: 0.1350569418422663\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -197432.68881068332\n",
      "    episode_reward_mean: -201907.03794301755\n",
      "    episode_reward_min: -206463.48816313394\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -200799.29543979256\n",
      "      - -203280.28831603815\n",
      "      - -200207.29857644552\n",
      "      - -201998.63522899404\n",
      "      - -202478.21066489106\n",
      "      - -203785.7077067876\n",
      "      - -201219.3169639088\n",
      "      - -199791.69730635337\n",
      "      - -200008.1658425607\n",
      "      - -203421.29950227236\n",
      "      - -205910.49771039633\n",
      "      - -200850.96390700445\n",
      "      - -203108.2234807683\n",
      "      - -199517.0137771257\n",
      "      - -199227.46163611228\n",
      "      - -200105.66283816422\n",
      "      - -202238.53058411673\n",
      "      - -205749.5699369866\n",
      "      - -200189.1852543382\n",
      "      - -206369.61392157935\n",
      "      - -200588.7229161255\n",
      "      - -203700.88206039535\n",
      "      - -200597.0946580805\n",
      "      - -204048.17520618116\n",
      "      - -197432.68881068332\n",
      "      - -199323.29371392145\n",
      "      - -200038.9236089672\n",
      "      - -202480.65258130594\n",
      "      - -201726.97539270262\n",
      "      - -197684.1097121119\n",
      "      - -200802.36405952938\n",
      "      - -201688.54292807664\n",
      "      - -201428.74927327348\n",
      "      - -205284.02291393868\n",
      "      - -201246.10754188424\n",
      "      - -205141.56401389115\n",
      "      - -202904.30014590497\n",
      "      - -203116.98108416336\n",
      "      - -202672.2381931217\n",
      "      - -202385.42707855528\n",
      "      - -201126.48821606903\n",
      "      - -202968.76883019338\n",
      "      - -202549.33551851893\n",
      "      - -201738.4746388367\n",
      "      - -200474.17410298547\n",
      "      - -201577.3570141274\n",
      "      - -199522.26666373652\n",
      "      - -201848.93382333906\n",
      "      - -202661.13935219115\n",
      "      - -202787.87283628373\n",
      "      - -202934.0532440759\n",
      "      - -201636.43019292998\n",
      "      - -201260.5171956517\n",
      "      - -203855.47817744865\n",
      "      - -203442.0066636769\n",
      "      - -205126.11559259365\n",
      "      - -200723.28409299155\n",
      "      - -204318.64211462592\n",
      "      - -202581.5661927923\n",
      "      - -200263.2299997789\n",
      "      - -200300.8990426115\n",
      "      - -201414.70376972028\n",
      "      - -201059.7941236871\n",
      "      - -198389.35355540662\n",
      "      - -200698.43107763233\n",
      "      - -203704.55959249884\n",
      "      - -201851.44971603263\n",
      "      - -202749.32168718163\n",
      "      - -200763.22763285754\n",
      "      - -201586.33489421202\n",
      "      - -200994.43261285528\n",
      "      - -202909.57216090697\n",
      "      - -199985.10889071575\n",
      "      - -202734.52639899935\n",
      "      - -203795.52959198048\n",
      "      - -203341.82937716114\n",
      "      - -200968.47885276694\n",
      "      - -201786.82520332868\n",
      "      - -198590.34326928563\n",
      "      - -201460.7854938276\n",
      "      - -204144.70797405211\n",
      "      - -202685.49749876733\n",
      "      - -200734.08262188022\n",
      "      - -203363.21373198918\n",
      "      - -204162.66043080372\n",
      "      - -199949.50613069828\n",
      "      - -202202.44361249843\n",
      "      - -200958.74013338142\n",
      "      - -202509.1856213419\n",
      "      - -200853.48476721434\n",
      "      - -200695.70736441307\n",
      "      - -206463.48816313394\n",
      "      - -200593.05099176135\n",
      "      - -200251.7909985076\n",
      "      - -203622.21155825636\n",
      "      - -198478.0409327452\n",
      "      - -200680.57658915073\n",
      "      - -205806.99794545464\n",
      "      - -201875.92089494716\n",
      "      - -203642.3904467909\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09512613630221906\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46979382879323067\n",
      "      mean_inference_ms: 0.9686720415403305\n",
      "      mean_raw_obs_processing_ms: 0.1350569418422663\n",
      "  time_since_restore: 1074.6916258335114\n",
      "  time_this_iter_s: 9.393030881881714\n",
      "  time_total_s: 1074.6916258335114\n",
      "  timers:\n",
      "    learn_throughput: 130298.073\n",
      "    learn_time_ms: 491.059\n",
      "    load_throughput: 21677922.675\n",
      "    load_time_ms: 2.952\n",
      "    training_iteration_time_ms: 9285.525\n",
      "    update_time_ms: 4.208\n",
      "  timestamp: 1665849822\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7166208\n",
      "  training_iteration: 112\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:03:47 (running for 00:18:21.49)<br>Memory usage on this node: 13.4/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   112</td><td style=\"text-align: right;\">         1074.69</td><td style=\"text-align: right;\">7166208</td><td style=\"text-align: right;\"> -201907</td><td style=\"text-align: right;\">             -197433</td><td style=\"text-align: right;\">             -206463</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 7230192\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 7230192\n",
      "    num_agent_steps_trained: 7230192\n",
      "    num_env_steps_sampled: 7230192\n",
      "    num_env_steps_trained: 7230192\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-03-51\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -197028.03334603945\n",
      "  episode_reward_mean: -201865.9339225139\n",
      "  episode_reward_min: -210262.1120102955\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 7224\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.156367778778076\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0004146574647165835\n",
      "          model: {}\n",
      "          policy_loss: 0.006918126717209816\n",
      "          total_loss: 10.006685256958008\n",
      "          vf_explained_var: -1.6083793852317285e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 7230192\n",
      "    num_agent_steps_trained: 7230192\n",
      "    num_env_steps_sampled: 7230192\n",
      "    num_env_steps_trained: 7230192\n",
      "  iterations_since_restore: 113\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 7230192\n",
      "  num_agent_steps_trained: 7230192\n",
      "  num_env_steps_sampled: 7230192\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 7230192\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 80.08461538461538\n",
      "    ram_util_percent: 86.83076923076922\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09515554434844525\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4695632725721562\n",
      "    mean_inference_ms: 0.9682735046796709\n",
      "    mean_raw_obs_processing_ms: 0.13519112758638904\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -197028.03334603945\n",
      "    episode_reward_mean: -201865.9339225139\n",
      "    episode_reward_min: -210262.1120102955\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -200300.8990426115\n",
      "      - -201414.70376972028\n",
      "      - -201059.7941236871\n",
      "      - -198389.35355540662\n",
      "      - -200698.43107763233\n",
      "      - -203704.55959249884\n",
      "      - -201851.44971603263\n",
      "      - -202749.32168718163\n",
      "      - -200763.22763285754\n",
      "      - -201586.33489421202\n",
      "      - -200994.43261285528\n",
      "      - -202909.57216090697\n",
      "      - -199985.10889071575\n",
      "      - -202734.52639899935\n",
      "      - -203795.52959198048\n",
      "      - -203341.82937716114\n",
      "      - -200968.47885276694\n",
      "      - -201786.82520332868\n",
      "      - -198590.34326928563\n",
      "      - -201460.7854938276\n",
      "      - -204144.70797405211\n",
      "      - -202685.49749876733\n",
      "      - -200734.08262188022\n",
      "      - -203363.21373198918\n",
      "      - -204162.66043080372\n",
      "      - -199949.50613069828\n",
      "      - -202202.44361249843\n",
      "      - -200958.74013338142\n",
      "      - -202509.1856213419\n",
      "      - -200853.48476721434\n",
      "      - -200695.70736441307\n",
      "      - -206463.48816313394\n",
      "      - -200593.05099176135\n",
      "      - -200251.7909985076\n",
      "      - -203622.21155825636\n",
      "      - -198478.0409327452\n",
      "      - -200680.57658915073\n",
      "      - -205806.99794545464\n",
      "      - -201875.92089494716\n",
      "      - -203642.3904467909\n",
      "      - -200447.7683975936\n",
      "      - -201656.99493780296\n",
      "      - -200663.14273570466\n",
      "      - -203480.63317957136\n",
      "      - -202661.73603808586\n",
      "      - -200497.36641325237\n",
      "      - -200827.74194124507\n",
      "      - -200256.10060902484\n",
      "      - -201461.86210920612\n",
      "      - -205149.37507728196\n",
      "      - -204647.5992535794\n",
      "      - -200916.87091498202\n",
      "      - -200844.79721273307\n",
      "      - -200727.80971788723\n",
      "      - -204802.7999751763\n",
      "      - -205443.19894545723\n",
      "      - -199503.24936036536\n",
      "      - -200681.1386118089\n",
      "      - -201386.2563422352\n",
      "      - -197624.40828731493\n",
      "      - -200744.55340510185\n",
      "      - -202304.7542130807\n",
      "      - -210262.1120102955\n",
      "      - -199694.0005335767\n",
      "      - -201881.5081152236\n",
      "      - -201859.6180870982\n",
      "      - -197028.03334603945\n",
      "      - -205429.08270002014\n",
      "      - -204777.85766072912\n",
      "      - -203316.20164173108\n",
      "      - -198793.35047342442\n",
      "      - -201225.906927163\n",
      "      - -202042.70895302139\n",
      "      - -202875.66981455646\n",
      "      - -204564.1815224199\n",
      "      - -201690.76040047014\n",
      "      - -204672.94889613698\n",
      "      - -201372.95097533538\n",
      "      - -206849.57230657316\n",
      "      - -201931.91085252227\n",
      "      - -201730.36910182383\n",
      "      - -201174.29579773473\n",
      "      - -197734.8101360523\n",
      "      - -199625.6648165151\n",
      "      - -202051.93080894428\n",
      "      - -202257.23556485548\n",
      "      - -198463.9637163188\n",
      "      - -199026.3535610625\n",
      "      - -200461.23146948763\n",
      "      - -201825.9116280656\n",
      "      - -203122.77868278397\n",
      "      - -205353.3822957121\n",
      "      - -201764.607203611\n",
      "      - -200843.12510864105\n",
      "      - -198835.90860817907\n",
      "      - -198658.80033045262\n",
      "      - -204463.01563989598\n",
      "      - -205984.58951933845\n",
      "      - -203306.70248927767\n",
      "      - -200150.9775263525\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09515554434844525\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4695632725721562\n",
      "      mean_inference_ms: 0.9682735046796709\n",
      "      mean_raw_obs_processing_ms: 0.13519112758638904\n",
      "  time_since_restore: 1083.624413728714\n",
      "  time_this_iter_s: 8.932787895202637\n",
      "  time_total_s: 1083.624413728714\n",
      "  timers:\n",
      "    learn_throughput: 130868.815\n",
      "    learn_time_ms: 488.917\n",
      "    load_throughput: 21509733.993\n",
      "    load_time_ms: 2.975\n",
      "    training_iteration_time_ms: 9286.58\n",
      "    update_time_ms: 4.243\n",
      "  timestamp: 1665849831\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7230192\n",
      "  training_iteration: 113\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:03:56 (running for 00:18:30.57)<br>Memory usage on this node: 13.4/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   113</td><td style=\"text-align: right;\">         1083.62</td><td style=\"text-align: right;\">7230192</td><td style=\"text-align: right;\"> -201866</td><td style=\"text-align: right;\">             -197028</td><td style=\"text-align: right;\">             -210262</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 7294176\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 7294176\n",
      "    num_agent_steps_trained: 7294176\n",
      "    num_env_steps_sampled: 7294176\n",
      "    num_env_steps_trained: 7294176\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-04-00\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -197028.03334603945\n",
      "  episode_reward_mean: -201453.0274302896\n",
      "  episode_reward_min: -210262.1120102955\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 7284\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.156071662902832\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0003253307077102363\n",
      "          model: {}\n",
      "          policy_loss: 0.0032285405322909355\n",
      "          total_loss: 10.002978324890137\n",
      "          vf_explained_var: -3.500590395333347e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 7294176\n",
      "    num_agent_steps_trained: 7294176\n",
      "    num_env_steps_sampled: 7294176\n",
      "    num_env_steps_trained: 7294176\n",
      "  iterations_since_restore: 114\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 7294176\n",
      "  num_agent_steps_trained: 7294176\n",
      "  num_env_steps_sampled: 7294176\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 7294176\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.5153846153846\n",
      "    ram_util_percent: 86.81538461538459\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09507782728366573\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4697177796114815\n",
      "    mean_inference_ms: 0.9677072410193958\n",
      "    mean_raw_obs_processing_ms: 0.13514869450029837\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -197028.03334603945\n",
      "    episode_reward_mean: -201453.0274302896\n",
      "    episode_reward_min: -210262.1120102955\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -200744.55340510185\n",
      "      - -202304.7542130807\n",
      "      - -210262.1120102955\n",
      "      - -199694.0005335767\n",
      "      - -201881.5081152236\n",
      "      - -201859.6180870982\n",
      "      - -197028.03334603945\n",
      "      - -205429.08270002014\n",
      "      - -204777.85766072912\n",
      "      - -203316.20164173108\n",
      "      - -198793.35047342442\n",
      "      - -201225.906927163\n",
      "      - -202042.70895302139\n",
      "      - -202875.66981455646\n",
      "      - -204564.1815224199\n",
      "      - -201690.76040047014\n",
      "      - -204672.94889613698\n",
      "      - -201372.95097533538\n",
      "      - -206849.57230657316\n",
      "      - -201931.91085252227\n",
      "      - -201730.36910182383\n",
      "      - -201174.29579773473\n",
      "      - -197734.8101360523\n",
      "      - -199625.6648165151\n",
      "      - -202051.93080894428\n",
      "      - -202257.23556485548\n",
      "      - -198463.9637163188\n",
      "      - -199026.3535610625\n",
      "      - -200461.23146948763\n",
      "      - -201825.9116280656\n",
      "      - -203122.77868278397\n",
      "      - -205353.3822957121\n",
      "      - -201764.607203611\n",
      "      - -200843.12510864105\n",
      "      - -198835.90860817907\n",
      "      - -198658.80033045262\n",
      "      - -204463.01563989598\n",
      "      - -205984.58951933845\n",
      "      - -203306.70248927767\n",
      "      - -200150.9775263525\n",
      "      - -199390.9055854087\n",
      "      - -199280.8544785484\n",
      "      - -203918.55779472963\n",
      "      - -203458.97415500827\n",
      "      - -201260.3550334677\n",
      "      - -199239.457472925\n",
      "      - -200525.83990205868\n",
      "      - -201219.3145872237\n",
      "      - -204507.99424075874\n",
      "      - -199710.05883149552\n",
      "      - -204552.1883841092\n",
      "      - -199116.91622904933\n",
      "      - -198334.3863795913\n",
      "      - -200363.6523924817\n",
      "      - -201727.7124848594\n",
      "      - -199782.17198431797\n",
      "      - -198737.7326156845\n",
      "      - -200290.54421993397\n",
      "      - -198744.07264708754\n",
      "      - -198869.93738088993\n",
      "      - -201124.53285543373\n",
      "      - -204815.19404520723\n",
      "      - -200771.64261815549\n",
      "      - -197339.36073089053\n",
      "      - -201347.78914078855\n",
      "      - -200724.64223060742\n",
      "      - -198645.62951513383\n",
      "      - -204633.9611884199\n",
      "      - -204882.01338352\n",
      "      - -199805.70720427477\n",
      "      - -202948.79662222927\n",
      "      - -200650.63864807395\n",
      "      - -200696.8998404513\n",
      "      - -201306.95892675326\n",
      "      - -198801.25237110627\n",
      "      - -202940.77318643182\n",
      "      - -200425.40191467738\n",
      "      - -198675.1212102414\n",
      "      - -203036.80818105515\n",
      "      - -198841.19423899692\n",
      "      - -198987.7920986425\n",
      "      - -202294.68830422818\n",
      "      - -199509.64787333083\n",
      "      - -200388.5924407665\n",
      "      - -201408.65637761087\n",
      "      - -201748.75721311173\n",
      "      - -202774.09361663635\n",
      "      - -204847.6318570807\n",
      "      - -200694.90945765987\n",
      "      - -201447.2307736844\n",
      "      - -200056.09487102734\n",
      "      - -200640.41659689645\n",
      "      - -200869.59746538763\n",
      "      - -205399.3151369721\n",
      "      - -200411.95886674\n",
      "      - -200802.97875392908\n",
      "      - -205028.70327672048\n",
      "      - -200719.05242758023\n",
      "      - -199252.61989722433\n",
      "      - -202420.72403203262\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09507782728366573\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4697177796114815\n",
      "      mean_inference_ms: 0.9677072410193958\n",
      "      mean_raw_obs_processing_ms: 0.13514869450029837\n",
      "  time_since_restore: 1092.9986553192139\n",
      "  time_this_iter_s: 9.374241590499878\n",
      "  time_total_s: 1092.9986553192139\n",
      "  timers:\n",
      "    learn_throughput: 130622.306\n",
      "    learn_time_ms: 489.84\n",
      "    load_throughput: 21737623.089\n",
      "    load_time_ms: 2.943\n",
      "    training_iteration_time_ms: 9309.355\n",
      "    update_time_ms: 4.246\n",
      "  timestamp: 1665849840\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7294176\n",
      "  training_iteration: 114\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:04:05 (running for 00:18:39.98)<br>Memory usage on this node: 13.4/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   114</td><td style=\"text-align: right;\">            1093</td><td style=\"text-align: right;\">7294176</td><td style=\"text-align: right;\"> -201453</td><td style=\"text-align: right;\">             -197028</td><td style=\"text-align: right;\">             -210262</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 7358160\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 7358160\n",
      "    num_agent_steps_trained: 7358160\n",
      "    num_env_steps_sampled: 7358160\n",
      "    num_env_steps_trained: 7358160\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-04-09\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -196820.46437565066\n",
      "  episode_reward_mean: -201521.81090403371\n",
      "  episode_reward_min: -219701.79957358804\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 7356\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1476569175720215\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00026212798547931015\n",
      "          model: {}\n",
      "          policy_loss: 0.003176466329023242\n",
      "          total_loss: 10.002915382385254\n",
      "          vf_explained_var: -3.689811478579941e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 7358160\n",
      "    num_agent_steps_trained: 7358160\n",
      "    num_env_steps_sampled: 7358160\n",
      "    num_env_steps_trained: 7358160\n",
      "  iterations_since_restore: 115\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 7358160\n",
      "  num_agent_steps_trained: 7358160\n",
      "  num_env_steps_sampled: 7358160\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 7358160\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.43846153846155\n",
      "    ram_util_percent: 86.79999999999998\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09502969287949652\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46947052717525845\n",
      "    mean_inference_ms: 0.9676623517054358\n",
      "    mean_raw_obs_processing_ms: 0.13496905786000338\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -196820.46437565066\n",
      "    episode_reward_mean: -201521.81090403371\n",
      "    episode_reward_min: -219701.79957358804\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -200696.8998404513\n",
      "      - -201306.95892675326\n",
      "      - -198801.25237110627\n",
      "      - -202940.77318643182\n",
      "      - -200425.40191467738\n",
      "      - -198675.1212102414\n",
      "      - -203036.80818105515\n",
      "      - -198841.19423899692\n",
      "      - -198987.7920986425\n",
      "      - -202294.68830422818\n",
      "      - -199509.64787333083\n",
      "      - -200388.5924407665\n",
      "      - -201408.65637761087\n",
      "      - -201748.75721311173\n",
      "      - -202774.09361663635\n",
      "      - -204847.6318570807\n",
      "      - -200694.90945765987\n",
      "      - -201447.2307736844\n",
      "      - -200056.09487102734\n",
      "      - -200640.41659689645\n",
      "      - -200869.59746538763\n",
      "      - -205399.3151369721\n",
      "      - -200411.95886674\n",
      "      - -200802.97875392908\n",
      "      - -205028.70327672048\n",
      "      - -200719.05242758023\n",
      "      - -199252.61989722433\n",
      "      - -202420.72403203262\n",
      "      - -206673.3436325624\n",
      "      - -202155.40258655683\n",
      "      - -202848.72447789996\n",
      "      - -206047.74810526142\n",
      "      - -198724.3255242644\n",
      "      - -199228.73679858388\n",
      "      - -199780.24553012353\n",
      "      - -201039.13168437133\n",
      "      - -201660.82633771826\n",
      "      - -200859.4348829695\n",
      "      - -200566.23152673244\n",
      "      - -201421.3424178057\n",
      "      - -200605.89418220683\n",
      "      - -201024.53415840905\n",
      "      - -200332.87843559016\n",
      "      - -201093.2408116077\n",
      "      - -200336.99653226466\n",
      "      - -199010.5978101398\n",
      "      - -205199.93827109807\n",
      "      - -200278.2313698804\n",
      "      - -198514.11705169218\n",
      "      - -200587.77073410948\n",
      "      - -200717.17762033222\n",
      "      - -200366.89708246748\n",
      "      - -202135.11325838297\n",
      "      - -202913.73436748868\n",
      "      - -199538.95537662867\n",
      "      - -205493.22724459265\n",
      "      - -219701.79957358804\n",
      "      - -200707.2556956328\n",
      "      - -200738.37943685343\n",
      "      - -202390.71200472675\n",
      "      - -200993.3001596111\n",
      "      - -201821.824881034\n",
      "      - -210362.1332774926\n",
      "      - -198903.86001015513\n",
      "      - -202112.02763724932\n",
      "      - -202938.50881592787\n",
      "      - -200436.6086755303\n",
      "      - -201835.93249827882\n",
      "      - -200595.21667518892\n",
      "      - -199457.40365846574\n",
      "      - -201001.22487647788\n",
      "      - -202001.4346103577\n",
      "      - -199950.18001607875\n",
      "      - -200984.39905590535\n",
      "      - -201560.7382156333\n",
      "      - -200999.43360485404\n",
      "      - -203297.85246624926\n",
      "      - -202150.8009117779\n",
      "      - -200513.3217421214\n",
      "      - -201885.02944548253\n",
      "      - -201983.70692157093\n",
      "      - -202864.80672637533\n",
      "      - -204465.64938206895\n",
      "      - -200274.59413593082\n",
      "      - -204225.13888973204\n",
      "      - -200743.77200610292\n",
      "      - -199959.8905963961\n",
      "      - -201032.16420820256\n",
      "      - -199252.78896785856\n",
      "      - -202405.932280364\n",
      "      - -202589.69800249193\n",
      "      - -199093.32879639152\n",
      "      - -200567.81996594224\n",
      "      - -202062.12699488853\n",
      "      - -202198.17515969262\n",
      "      - -199161.4007907585\n",
      "      - -196820.46437565066\n",
      "      - -200648.72670691344\n",
      "      - -200755.77728868873\n",
      "      - -200153.0812439545\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09502969287949652\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46947052717525845\n",
      "      mean_inference_ms: 0.9676623517054358\n",
      "      mean_raw_obs_processing_ms: 0.13496905786000338\n",
      "  time_since_restore: 1102.404964208603\n",
      "  time_this_iter_s: 9.406308889389038\n",
      "  time_total_s: 1102.404964208603\n",
      "  timers:\n",
      "    learn_throughput: 129764.549\n",
      "    learn_time_ms: 493.078\n",
      "    load_throughput: 21847339.352\n",
      "    load_time_ms: 2.929\n",
      "    training_iteration_time_ms: 9309.477\n",
      "    update_time_ms: 4.113\n",
      "  timestamp: 1665849849\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7358160\n",
      "  training_iteration: 115\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:04:15 (running for 00:18:49.47)<br>Memory usage on this node: 13.4/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   115</td><td style=\"text-align: right;\">          1102.4</td><td style=\"text-align: right;\">7358160</td><td style=\"text-align: right;\"> -201522</td><td style=\"text-align: right;\">             -196820</td><td style=\"text-align: right;\">             -219702</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 7422144\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 7422144\n",
      "    num_agent_steps_trained: 7422144\n",
      "    num_env_steps_sampled: 7422144\n",
      "    num_env_steps_trained: 7422144\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-04-19\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -196820.46437565066\n",
      "  episode_reward_mean: -201444.1571800085\n",
      "  episode_reward_min: -210362.1332774926\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 7416\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.153381824493408\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0015040693106129766\n",
      "          model: {}\n",
      "          policy_loss: 0.00590597465634346\n",
      "          total_loss: 10.005892753601074\n",
      "          vf_explained_var: -6.528127727278843e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 7422144\n",
      "    num_agent_steps_trained: 7422144\n",
      "    num_env_steps_sampled: 7422144\n",
      "    num_env_steps_trained: 7422144\n",
      "  iterations_since_restore: 116\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 7422144\n",
      "  num_agent_steps_trained: 7422144\n",
      "  num_env_steps_sampled: 7422144\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 7422144\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.06153846153846\n",
      "    ram_util_percent: 86.79999999999998\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09509614407281611\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4692897907904177\n",
      "    mean_inference_ms: 0.9676633251132982\n",
      "    mean_raw_obs_processing_ms: 0.13510708396082868\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -196820.46437565066\n",
      "    episode_reward_mean: -201444.1571800085\n",
      "    episode_reward_min: -210362.1332774926\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -200993.3001596111\n",
      "      - -201821.824881034\n",
      "      - -210362.1332774926\n",
      "      - -198903.86001015513\n",
      "      - -202112.02763724932\n",
      "      - -202938.50881592787\n",
      "      - -200436.6086755303\n",
      "      - -201835.93249827882\n",
      "      - -200595.21667518892\n",
      "      - -199457.40365846574\n",
      "      - -201001.22487647788\n",
      "      - -202001.4346103577\n",
      "      - -199950.18001607875\n",
      "      - -200984.39905590535\n",
      "      - -201560.7382156333\n",
      "      - -200999.43360485404\n",
      "      - -203297.85246624926\n",
      "      - -202150.8009117779\n",
      "      - -200513.3217421214\n",
      "      - -201885.02944548253\n",
      "      - -201983.70692157093\n",
      "      - -202864.80672637533\n",
      "      - -204465.64938206895\n",
      "      - -200274.59413593082\n",
      "      - -204225.13888973204\n",
      "      - -200743.77200610292\n",
      "      - -199959.8905963961\n",
      "      - -201032.16420820256\n",
      "      - -199252.78896785856\n",
      "      - -202405.932280364\n",
      "      - -202589.69800249193\n",
      "      - -199093.32879639152\n",
      "      - -200567.81996594224\n",
      "      - -202062.12699488853\n",
      "      - -202198.17515969262\n",
      "      - -199161.4007907585\n",
      "      - -196820.46437565066\n",
      "      - -200648.72670691344\n",
      "      - -200755.77728868873\n",
      "      - -200153.0812439545\n",
      "      - -202650.39565428375\n",
      "      - -200188.1956546518\n",
      "      - -200127.18187590453\n",
      "      - -202233.85397878187\n",
      "      - -205784.93541067952\n",
      "      - -200565.14755913467\n",
      "      - -208304.96023182312\n",
      "      - -198514.85028308723\n",
      "      - -199004.90241924115\n",
      "      - -202235.6580862322\n",
      "      - -199721.3418664514\n",
      "      - -197084.85335784664\n",
      "      - -204941.00955690013\n",
      "      - -200049.09872817312\n",
      "      - -203395.50534509678\n",
      "      - -200974.54184067328\n",
      "      - -203637.1009768465\n",
      "      - -203695.48220071133\n",
      "      - -200768.3507713955\n",
      "      - -202130.0341309132\n",
      "      - -200767.5196866703\n",
      "      - -200781.10017996925\n",
      "      - -201597.38857800802\n",
      "      - -204120.18301748333\n",
      "      - -205302.13216201126\n",
      "      - -202030.50379165134\n",
      "      - -198408.0446850919\n",
      "      - -202097.4361484591\n",
      "      - -201771.54576109236\n",
      "      - -201736.7391639439\n",
      "      - -203207.82043032747\n",
      "      - -202662.9063015861\n",
      "      - -199100.02290558626\n",
      "      - -198802.91588640152\n",
      "      - -200043.7781178712\n",
      "      - -199448.03721067501\n",
      "      - -203362.33364415728\n",
      "      - -202596.78065266853\n",
      "      - -202830.77695860562\n",
      "      - -202187.7796974165\n",
      "      - -206685.49467361835\n",
      "      - -201453.81524563834\n",
      "      - -201466.9364152172\n",
      "      - -200225.89941804463\n",
      "      - -200742.2696760801\n",
      "      - -197938.58680487354\n",
      "      - -199954.04619312682\n",
      "      - -200541.35499103056\n",
      "      - -198648.2048253596\n",
      "      - -199284.8132208321\n",
      "      - -200648.43188573702\n",
      "      - -201368.176005455\n",
      "      - -200573.31666256956\n",
      "      - -203350.56226190217\n",
      "      - -200478.61062404004\n",
      "      - -202974.75357509992\n",
      "      - -203958.87126578993\n",
      "      - -199968.60114201327\n",
      "      - -199704.9257295755\n",
      "      - -200524.62780249803\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09509614407281611\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4692897907904177\n",
      "      mean_inference_ms: 0.9676633251132982\n",
      "      mean_raw_obs_processing_ms: 0.13510708396082868\n",
      "  time_since_restore: 1111.7252750396729\n",
      "  time_this_iter_s: 9.320310831069946\n",
      "  time_total_s: 1111.7252750396729\n",
      "  timers:\n",
      "    learn_throughput: 132298.686\n",
      "    learn_time_ms: 483.633\n",
      "    load_throughput: 21896180.537\n",
      "    load_time_ms: 2.922\n",
      "    training_iteration_time_ms: 9306.795\n",
      "    update_time_ms: 4.115\n",
      "  timestamp: 1665849859\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7422144\n",
      "  training_iteration: 116\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:04:24 (running for 00:18:58.80)<br>Memory usage on this node: 13.4/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   116</td><td style=\"text-align: right;\">         1111.73</td><td style=\"text-align: right;\">7422144</td><td style=\"text-align: right;\"> -201444</td><td style=\"text-align: right;\">             -196820</td><td style=\"text-align: right;\">             -210362</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 7486128\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 7486128\n",
      "    num_agent_steps_trained: 7486128\n",
      "    num_env_steps_sampled: 7486128\n",
      "    num_env_steps_trained: 7486128\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-04-28\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -197739.18136940358\n",
      "  episode_reward_mean: -201156.35366746993\n",
      "  episode_reward_min: -206851.62666571108\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 7476\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1540627479553223\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0005352548905648291\n",
      "          model: {}\n",
      "          policy_loss: 0.0035927840508520603\n",
      "          total_loss: 10.00338363647461\n",
      "          vf_explained_var: -3.7844220202032375e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 7486128\n",
      "    num_agent_steps_trained: 7486128\n",
      "    num_env_steps_sampled: 7486128\n",
      "    num_env_steps_trained: 7486128\n",
      "  iterations_since_restore: 117\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 7486128\n",
      "  num_agent_steps_trained: 7486128\n",
      "  num_env_steps_sampled: 7486128\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 7486128\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 84.81538461538463\n",
      "    ram_util_percent: 86.83846153846153\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09507026898146392\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4694535667838183\n",
      "    mean_inference_ms: 0.9675132301681266\n",
      "    mean_raw_obs_processing_ms: 0.13508906443316865\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -197739.18136940358\n",
      "    episode_reward_mean: -201156.35366746993\n",
      "    episode_reward_min: -206851.62666571108\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -200767.5196866703\n",
      "      - -200781.10017996925\n",
      "      - -201597.38857800802\n",
      "      - -204120.18301748333\n",
      "      - -205302.13216201126\n",
      "      - -202030.50379165134\n",
      "      - -198408.0446850919\n",
      "      - -202097.4361484591\n",
      "      - -201771.54576109236\n",
      "      - -201736.7391639439\n",
      "      - -203207.82043032747\n",
      "      - -202662.9063015861\n",
      "      - -199100.02290558626\n",
      "      - -198802.91588640152\n",
      "      - -200043.7781178712\n",
      "      - -199448.03721067501\n",
      "      - -203362.33364415728\n",
      "      - -202596.78065266853\n",
      "      - -202830.77695860562\n",
      "      - -202187.7796974165\n",
      "      - -206685.49467361835\n",
      "      - -201453.81524563834\n",
      "      - -201466.9364152172\n",
      "      - -200225.89941804463\n",
      "      - -200742.2696760801\n",
      "      - -197938.58680487354\n",
      "      - -199954.04619312682\n",
      "      - -200541.35499103056\n",
      "      - -198648.2048253596\n",
      "      - -199284.8132208321\n",
      "      - -200648.43188573702\n",
      "      - -201368.176005455\n",
      "      - -200573.31666256956\n",
      "      - -203350.56226190217\n",
      "      - -200478.61062404004\n",
      "      - -202974.75357509992\n",
      "      - -203958.87126578993\n",
      "      - -199968.60114201327\n",
      "      - -199704.9257295755\n",
      "      - -200524.62780249803\n",
      "      - -198203.24183108562\n",
      "      - -200506.77508668537\n",
      "      - -202870.8358079966\n",
      "      - -204525.6797351593\n",
      "      - -199596.5896509521\n",
      "      - -200002.39457244982\n",
      "      - -201417.75687745647\n",
      "      - -199483.5957076215\n",
      "      - -198097.1372389756\n",
      "      - -200791.0668503853\n",
      "      - -206851.62666571108\n",
      "      - -202069.08953682473\n",
      "      - -200655.9675604027\n",
      "      - -197739.18136940358\n",
      "      - -202406.1845548433\n",
      "      - -200057.45099900366\n",
      "      - -200716.11756804175\n",
      "      - -204037.9030401127\n",
      "      - -200784.23047205727\n",
      "      - -200681.78221198454\n",
      "      - -204740.43902834144\n",
      "      - -201376.20864757412\n",
      "      - -202581.09235488152\n",
      "      - -201856.80839800616\n",
      "      - -199011.99742334976\n",
      "      - -201688.13134968388\n",
      "      - -199269.5586756366\n",
      "      - -201165.62452379553\n",
      "      - -201955.4853179804\n",
      "      - -201188.7293718187\n",
      "      - -202499.04303958948\n",
      "      - -201203.33043203928\n",
      "      - -199396.45265486275\n",
      "      - -199481.9826032085\n",
      "      - -198238.42633056478\n",
      "      - -203183.00953768342\n",
      "      - -203033.42329441733\n",
      "      - -200232.76263384722\n",
      "      - -202787.72181379166\n",
      "      - -201995.47427858217\n",
      "      - -200727.70722108323\n",
      "      - -199638.03640160093\n",
      "      - -201972.61923688572\n",
      "      - -200752.69511605272\n",
      "      - -205122.98821204263\n",
      "      - -199422.71542418876\n",
      "      - -198621.2643610977\n",
      "      - -199689.7675625091\n",
      "      - -197831.76419591383\n",
      "      - -199673.28679845596\n",
      "      - -201547.66964512816\n",
      "      - -202566.2189599162\n",
      "      - -200294.67538336644\n",
      "      - -199325.1947234358\n",
      "      - -200744.52823849322\n",
      "      - -203293.62570342593\n",
      "      - -198493.9335322878\n",
      "      - -204179.07128432734\n",
      "      - -200028.67878164008\n",
      "      - -199980.573520157\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09507026898146392\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4694535667838183\n",
      "      mean_inference_ms: 0.9675132301681266\n",
      "      mean_raw_obs_processing_ms: 0.13508906443316865\n",
      "  time_since_restore: 1121.3623056411743\n",
      "  time_this_iter_s: 9.637030601501465\n",
      "  time_total_s: 1121.3623056411743\n",
      "  timers:\n",
      "    learn_throughput: 132578.476\n",
      "    learn_time_ms: 482.612\n",
      "    load_throughput: 22069765.389\n",
      "    load_time_ms: 2.899\n",
      "    training_iteration_time_ms: 9320.631\n",
      "    update_time_ms: 4.004\n",
      "  timestamp: 1665849868\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7486128\n",
      "  training_iteration: 117\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:04:34 (running for 00:19:08.46)<br>Memory usage on this node: 13.4/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   117</td><td style=\"text-align: right;\">         1121.36</td><td style=\"text-align: right;\">7486128</td><td style=\"text-align: right;\"> -201156</td><td style=\"text-align: right;\">             -197739</td><td style=\"text-align: right;\">             -206852</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 7550112\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 7550112\n",
      "    num_agent_steps_trained: 7550112\n",
      "    num_env_steps_sampled: 7550112\n",
      "    num_env_steps_trained: 7550112\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-04-38\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -196550.47090199013\n",
      "  episode_reward_mean: -200855.68711281093\n",
      "  episode_reward_min: -208364.1896946651\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 7548\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.149707555770874\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0010426006047055125\n",
      "          model: {}\n",
      "          policy_loss: 0.002495621331036091\n",
      "          total_loss: 10.002388954162598\n",
      "          vf_explained_var: -3.216758770463457e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 7550112\n",
      "    num_agent_steps_trained: 7550112\n",
      "    num_env_steps_sampled: 7550112\n",
      "    num_env_steps_trained: 7550112\n",
      "  iterations_since_restore: 118\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 7550112\n",
      "  num_agent_steps_trained: 7550112\n",
      "  num_env_steps_sampled: 7550112\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 7550112\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.31428571428572\n",
      "    ram_util_percent: 86.82142857142857\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09506795819013551\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46933827677839124\n",
      "    mean_inference_ms: 0.9676137295019429\n",
      "    mean_raw_obs_processing_ms: 0.13492887261502307\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -196550.47090199013\n",
      "    episode_reward_mean: -200855.68711281093\n",
      "    episode_reward_min: -208364.1896946651\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -199396.45265486275\n",
      "      - -199481.9826032085\n",
      "      - -198238.42633056478\n",
      "      - -203183.00953768342\n",
      "      - -203033.42329441733\n",
      "      - -200232.76263384722\n",
      "      - -202787.72181379166\n",
      "      - -201995.47427858217\n",
      "      - -200727.70722108323\n",
      "      - -199638.03640160093\n",
      "      - -201972.61923688572\n",
      "      - -200752.69511605272\n",
      "      - -205122.98821204263\n",
      "      - -199422.71542418876\n",
      "      - -198621.2643610977\n",
      "      - -199689.7675625091\n",
      "      - -197831.76419591383\n",
      "      - -199673.28679845596\n",
      "      - -201547.66964512816\n",
      "      - -202566.2189599162\n",
      "      - -200294.67538336644\n",
      "      - -199325.1947234358\n",
      "      - -200744.52823849322\n",
      "      - -203293.62570342593\n",
      "      - -198493.9335322878\n",
      "      - -204179.07128432734\n",
      "      - -200028.67878164008\n",
      "      - -199980.573520157\n",
      "      - -200815.15795742074\n",
      "      - -205193.50158150695\n",
      "      - -201470.10045512105\n",
      "      - -199909.5967018847\n",
      "      - -199272.73283533304\n",
      "      - -201168.8660145036\n",
      "      - -200220.9245150832\n",
      "      - -198404.34699364417\n",
      "      - -199237.33947872082\n",
      "      - -201249.8791206031\n",
      "      - -200959.52233080892\n",
      "      - -199523.3901315774\n",
      "      - -198925.7174634313\n",
      "      - -200022.40879051632\n",
      "      - -204318.84830327638\n",
      "      - -203727.2981451229\n",
      "      - -200684.6982274738\n",
      "      - -201923.15678490014\n",
      "      - -199711.5474022209\n",
      "      - -200397.988280289\n",
      "      - -200506.51613804736\n",
      "      - -203881.38186973555\n",
      "      - -202079.60882565708\n",
      "      - -198453.97523168416\n",
      "      - -198744.27641031606\n",
      "      - -199720.01676168278\n",
      "      - -202823.43384605862\n",
      "      - -201677.5062298167\n",
      "      - -200763.16180022448\n",
      "      - -201477.89203648973\n",
      "      - -198955.2956825998\n",
      "      - -203179.60556427398\n",
      "      - -202246.4729809927\n",
      "      - -200449.5564203046\n",
      "      - -200653.083308078\n",
      "      - -200579.41925514562\n",
      "      - -208364.1896946651\n",
      "      - -196550.47090199013\n",
      "      - -201649.5235574057\n",
      "      - -203073.73289648726\n",
      "      - -199700.0138400465\n",
      "      - -198465.9057689342\n",
      "      - -201178.49293939827\n",
      "      - -201846.4769918978\n",
      "      - -202352.70731890982\n",
      "      - -199583.14518737636\n",
      "      - -201889.6265406522\n",
      "      - -198735.64356187766\n",
      "      - -205781.10472932988\n",
      "      - -201561.37497842734\n",
      "      - -201697.47233289355\n",
      "      - -198792.18227577407\n",
      "      - -203204.60590237612\n",
      "      - -200338.13812503708\n",
      "      - -199660.69742815022\n",
      "      - -201990.91145483693\n",
      "      - -202854.03563409092\n",
      "      - -202032.15015305954\n",
      "      - -201748.9444379003\n",
      "      - -199249.72806868664\n",
      "      - -200985.02804155916\n",
      "      - -198538.21281377747\n",
      "      - -198932.1338250284\n",
      "      - -199020.49745720057\n",
      "      - -199927.6459650788\n",
      "      - -200824.19664761054\n",
      "      - -199810.83624618893\n",
      "      - -197108.78550154672\n",
      "      - -199955.63922417845\n",
      "      - -205726.12989654863\n",
      "      - -197849.59723067703\n",
      "      - -199004.2423879851\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09506795819013551\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46933827677839124\n",
      "      mean_inference_ms: 0.9676137295019429\n",
      "      mean_raw_obs_processing_ms: 0.13492887261502307\n",
      "  time_since_restore: 1131.0010809898376\n",
      "  time_this_iter_s: 9.63877534866333\n",
      "  time_total_s: 1131.0010809898376\n",
      "  timers:\n",
      "    learn_throughput: 132704.243\n",
      "    learn_time_ms: 482.155\n",
      "    load_throughput: 22123071.804\n",
      "    load_time_ms: 2.892\n",
      "    training_iteration_time_ms: 9357.594\n",
      "    update_time_ms: 3.87\n",
      "  timestamp: 1665849878\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7550112\n",
      "  training_iteration: 118\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:04:43 (running for 00:19:18.00)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   118</td><td style=\"text-align: right;\">            1131</td><td style=\"text-align: right;\">7550112</td><td style=\"text-align: right;\"> -200856</td><td style=\"text-align: right;\">             -196550</td><td style=\"text-align: right;\">             -208364</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 7614096\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 7614096\n",
      "    num_agent_steps_trained: 7614096\n",
      "    num_env_steps_sampled: 7614096\n",
      "    num_env_steps_trained: 7614096\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-04-49\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -196546.31287368652\n",
      "  episode_reward_mean: -200816.7087770864\n",
      "  episode_reward_min: -209274.33448804775\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 7608\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1564886569976807\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00036395140341483057\n",
      "          model: {}\n",
      "          policy_loss: 0.007080391515046358\n",
      "          total_loss: 10.0068359375\n",
      "          vf_explained_var: -5.298190686175985e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 7614096\n",
      "    num_agent_steps_trained: 7614096\n",
      "    num_env_steps_sampled: 7614096\n",
      "    num_env_steps_trained: 7614096\n",
      "  iterations_since_restore: 119\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 7614096\n",
      "  num_agent_steps_trained: 7614096\n",
      "  num_env_steps_sampled: 7614096\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 7614096\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 87.39285714285714\n",
      "    ram_util_percent: 86.99285714285713\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09516420378991679\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4695257962996061\n",
      "    mean_inference_ms: 0.9681858297288164\n",
      "    mean_raw_obs_processing_ms: 0.1351414524848969\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -196546.31287368652\n",
      "    episode_reward_mean: -200816.7087770864\n",
      "    episode_reward_min: -209274.33448804775\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -202246.4729809927\n",
      "      - -200449.5564203046\n",
      "      - -200653.083308078\n",
      "      - -200579.41925514562\n",
      "      - -208364.1896946651\n",
      "      - -196550.47090199013\n",
      "      - -201649.5235574057\n",
      "      - -203073.73289648726\n",
      "      - -199700.0138400465\n",
      "      - -198465.9057689342\n",
      "      - -201178.49293939827\n",
      "      - -201846.4769918978\n",
      "      - -202352.70731890982\n",
      "      - -199583.14518737636\n",
      "      - -201889.6265406522\n",
      "      - -198735.64356187766\n",
      "      - -205781.10472932988\n",
      "      - -201561.37497842734\n",
      "      - -201697.47233289355\n",
      "      - -198792.18227577407\n",
      "      - -203204.60590237612\n",
      "      - -200338.13812503708\n",
      "      - -199660.69742815022\n",
      "      - -201990.91145483693\n",
      "      - -202854.03563409092\n",
      "      - -202032.15015305954\n",
      "      - -201748.9444379003\n",
      "      - -199249.72806868664\n",
      "      - -200985.02804155916\n",
      "      - -198538.21281377747\n",
      "      - -198932.1338250284\n",
      "      - -199020.49745720057\n",
      "      - -199927.6459650788\n",
      "      - -200824.19664761054\n",
      "      - -199810.83624618893\n",
      "      - -197108.78550154672\n",
      "      - -199955.63922417845\n",
      "      - -205726.12989654863\n",
      "      - -197849.59723067703\n",
      "      - -199004.2423879851\n",
      "      - -200764.29566427524\n",
      "      - -202143.18355816577\n",
      "      - -200473.34447076928\n",
      "      - -199024.60597575537\n",
      "      - -200995.35189342062\n",
      "      - -201374.08795634523\n",
      "      - -203810.05064628334\n",
      "      - -201569.9602114522\n",
      "      - -209274.33448804775\n",
      "      - -200595.96584344938\n",
      "      - -198475.5496530742\n",
      "      - -200067.99725886347\n",
      "      - -198312.49330072105\n",
      "      - -201360.78038619098\n",
      "      - -202565.0478661878\n",
      "      - -205658.43301099693\n",
      "      - -204124.16360105167\n",
      "      - -197273.4385907338\n",
      "      - -198795.47790422893\n",
      "      - -200564.17925377088\n",
      "      - -197926.2913854432\n",
      "      - -201289.2041010878\n",
      "      - -201483.37482716347\n",
      "      - -203487.625499245\n",
      "      - -201428.75414545255\n",
      "      - -202883.11095249437\n",
      "      - -203086.50254855273\n",
      "      - -197382.4970467894\n",
      "      - -197560.20904885884\n",
      "      - -202492.28759038047\n",
      "      - -198383.86612009114\n",
      "      - -202107.28176310204\n",
      "      - -204893.5362762912\n",
      "      - -201860.40390229036\n",
      "      - -201242.23686903375\n",
      "      - -202577.038512817\n",
      "      - -199776.92724899185\n",
      "      - -198603.36015030125\n",
      "      - -201337.12922421208\n",
      "      - -199000.19381862713\n",
      "      - -197799.94663256116\n",
      "      - -199314.6997919325\n",
      "      - -200551.50068440463\n",
      "      - -196546.31287368652\n",
      "      - -202017.9483072034\n",
      "      - -201517.30130817706\n",
      "      - -202854.22080130226\n",
      "      - -200601.97011401012\n",
      "      - -200704.3600955722\n",
      "      - -198188.86828620188\n",
      "      - -201178.17508343895\n",
      "      - -200640.0575941409\n",
      "      - -200828.2662487598\n",
      "      - -198863.05912280802\n",
      "      - -200132.59488971718\n",
      "      - -199123.27901130242\n",
      "      - -199188.57805439335\n",
      "      - -199925.66978969224\n",
      "      - -201622.7600859543\n",
      "      - -200133.9844462691\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09516420378991679\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4695257962996061\n",
      "      mean_inference_ms: 0.9681858297288164\n",
      "      mean_raw_obs_processing_ms: 0.1351414524848969\n",
      "  time_since_restore: 1141.4570245742798\n",
      "  time_this_iter_s: 10.455943584442139\n",
      "  time_total_s: 1141.4570245742798\n",
      "  timers:\n",
      "    learn_throughput: 131766.496\n",
      "    learn_time_ms: 485.586\n",
      "    load_throughput: 22458166.074\n",
      "    load_time_ms: 2.849\n",
      "    training_iteration_time_ms: 9464.067\n",
      "    update_time_ms: 3.914\n",
      "  timestamp: 1665849889\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7614096\n",
      "  training_iteration: 119\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:04:49 (running for 00:19:23.61)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   119</td><td style=\"text-align: right;\">         1141.46</td><td style=\"text-align: right;\">7614096</td><td style=\"text-align: right;\"> -200817</td><td style=\"text-align: right;\">             -196546</td><td style=\"text-align: right;\">             -209274</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:04:54 (running for 00:19:28.61)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   119</td><td style=\"text-align: right;\">         1141.46</td><td style=\"text-align: right;\">7614096</td><td style=\"text-align: right;\"> -200817</td><td style=\"text-align: right;\">             -196546</td><td style=\"text-align: right;\">             -209274</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 7678080\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 7678080\n",
      "    num_agent_steps_trained: 7678080\n",
      "    num_env_steps_sampled: 7678080\n",
      "    num_env_steps_trained: 7678080\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-04-58\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -196546.31287368652\n",
      "  episode_reward_mean: -201048.437487677\n",
      "  episode_reward_min: -207961.76101730025\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 7668\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1524384021759033\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00026843350497074425\n",
      "          model: {}\n",
      "          policy_loss: 0.00331737007945776\n",
      "          total_loss: 10.003055572509766\n",
      "          vf_explained_var: -3.216758770463457e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 7678080\n",
      "    num_agent_steps_trained: 7678080\n",
      "    num_env_steps_sampled: 7678080\n",
      "    num_env_steps_trained: 7678080\n",
      "  iterations_since_restore: 120\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 7678080\n",
      "  num_agent_steps_trained: 7678080\n",
      "  num_env_steps_sampled: 7678080\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 7678080\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.62307692307694\n",
      "    ram_util_percent: 87.03076923076924\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0951102430114193\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46982441758357507\n",
      "    mean_inference_ms: 0.9681489194097143\n",
      "    mean_raw_obs_processing_ms: 0.1351222091625418\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -196546.31287368652\n",
      "    episode_reward_mean: -201048.437487677\n",
      "    episode_reward_min: -207961.76101730025\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -197926.2913854432\n",
      "      - -201289.2041010878\n",
      "      - -201483.37482716347\n",
      "      - -203487.625499245\n",
      "      - -201428.75414545255\n",
      "      - -202883.11095249437\n",
      "      - -203086.50254855273\n",
      "      - -197382.4970467894\n",
      "      - -197560.20904885884\n",
      "      - -202492.28759038047\n",
      "      - -198383.86612009114\n",
      "      - -202107.28176310204\n",
      "      - -204893.5362762912\n",
      "      - -201860.40390229036\n",
      "      - -201242.23686903375\n",
      "      - -202577.038512817\n",
      "      - -199776.92724899185\n",
      "      - -198603.36015030125\n",
      "      - -201337.12922421208\n",
      "      - -199000.19381862713\n",
      "      - -197799.94663256116\n",
      "      - -199314.6997919325\n",
      "      - -200551.50068440463\n",
      "      - -196546.31287368652\n",
      "      - -202017.9483072034\n",
      "      - -201517.30130817706\n",
      "      - -202854.22080130226\n",
      "      - -200601.97011401012\n",
      "      - -200704.3600955722\n",
      "      - -198188.86828620188\n",
      "      - -201178.17508343895\n",
      "      - -200640.0575941409\n",
      "      - -200828.2662487598\n",
      "      - -198863.05912280802\n",
      "      - -200132.59488971718\n",
      "      - -199123.27901130242\n",
      "      - -199188.57805439335\n",
      "      - -199925.66978969224\n",
      "      - -201622.7600859543\n",
      "      - -200133.9844462691\n",
      "      - -199751.04119668755\n",
      "      - -199356.9535863573\n",
      "      - -200470.2253483021\n",
      "      - -202826.00606624552\n",
      "      - -198801.111871541\n",
      "      - -199484.74836191811\n",
      "      - -201798.939274221\n",
      "      - -202741.5985481355\n",
      "      - -203168.32800504938\n",
      "      - -197283.55128963487\n",
      "      - -207961.76101730025\n",
      "      - -202996.87707580373\n",
      "      - -199896.47940090197\n",
      "      - -204072.6427371607\n",
      "      - -201447.41311124957\n",
      "      - -202207.16869568735\n",
      "      - -203661.36690560126\n",
      "      - -201350.95532577188\n",
      "      - -203783.80557429075\n",
      "      - -206425.02055065712\n",
      "      - -204545.9454880273\n",
      "      - -207514.31238759143\n",
      "      - -203855.15985975624\n",
      "      - -198506.9795516572\n",
      "      - -203393.86002501953\n",
      "      - -198830.4029852954\n",
      "      - -199670.1478645498\n",
      "      - -201309.98612196784\n",
      "      - -198425.7715867983\n",
      "      - -196877.73223607705\n",
      "      - -201254.24537391303\n",
      "      - -199445.25433729045\n",
      "      - -200147.45511291534\n",
      "      - -198538.7259979503\n",
      "      - -204493.8460104138\n",
      "      - -201703.3622228379\n",
      "      - -199502.74943881837\n",
      "      - -200468.15086191113\n",
      "      - -200580.77594239957\n",
      "      - -202350.24681264875\n",
      "      - -204184.9507541089\n",
      "      - -202106.60248550886\n",
      "      - -201487.21253493335\n",
      "      - -198501.3026283931\n",
      "      - -198632.15418146105\n",
      "      - -201605.5791080212\n",
      "      - -205429.90444342428\n",
      "      - -203665.0192155506\n",
      "      - -202335.01846277452\n",
      "      - -201038.23406988173\n",
      "      - -199737.2150508918\n",
      "      - -199159.37215072208\n",
      "      - -202131.36325035634\n",
      "      - -199055.306795574\n",
      "      - -204099.49743161045\n",
      "      - -200577.14692432169\n",
      "      - -198527.1918581271\n",
      "      - -200963.0741106944\n",
      "      - -200411.8734479974\n",
      "      - -199759.24145023944\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.0951102430114193\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46982441758357507\n",
      "      mean_inference_ms: 0.9681489194097143\n",
      "      mean_raw_obs_processing_ms: 0.1351222091625418\n",
      "  time_since_restore: 1150.643441915512\n",
      "  time_this_iter_s: 9.1864173412323\n",
      "  time_total_s: 1150.643441915512\n",
      "  timers:\n",
      "    learn_throughput: 131945.695\n",
      "    learn_time_ms: 484.927\n",
      "    load_throughput: 22675246.689\n",
      "    load_time_ms: 2.822\n",
      "    training_iteration_time_ms: 9460.16\n",
      "    update_time_ms: 3.986\n",
      "  timestamp: 1665849898\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7678080\n",
      "  training_iteration: 120\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:05:03 (running for 00:19:37.85)<br>Memory usage on this node: 13.4/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   120</td><td style=\"text-align: right;\">         1150.64</td><td style=\"text-align: right;\">7678080</td><td style=\"text-align: right;\"> -201048</td><td style=\"text-align: right;\">             -196546</td><td style=\"text-align: right;\">             -207962</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 7742064\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 7742064\n",
      "    num_agent_steps_trained: 7742064\n",
      "    num_env_steps_sampled: 7742064\n",
      "    num_env_steps_trained: 7742064\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-05-07\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -197545.18461481755\n",
      "  episode_reward_mean: -200991.64017604568\n",
      "  episode_reward_min: -207541.57125183215\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 7740\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1550588607788086\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0004898428451269865\n",
      "          model: {}\n",
      "          policy_loss: 0.003156780730932951\n",
      "          total_loss: 10.002939224243164\n",
      "          vf_explained_var: -4.352085269943018e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 7742064\n",
      "    num_agent_steps_trained: 7742064\n",
      "    num_env_steps_sampled: 7742064\n",
      "    num_env_steps_trained: 7742064\n",
      "  iterations_since_restore: 121\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 7742064\n",
      "  num_agent_steps_trained: 7742064\n",
      "  num_env_steps_sampled: 7742064\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 7742064\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 78.82307692307693\n",
      "    ram_util_percent: 86.9\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09506943133789424\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46949252514360723\n",
      "    mean_inference_ms: 0.9678886752382683\n",
      "    mean_raw_obs_processing_ms: 0.13490317689554698\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -197545.18461481755\n",
      "    episode_reward_mean: -200991.64017604568\n",
      "    episode_reward_min: -207541.57125183215\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -200147.45511291534\n",
      "      - -198538.7259979503\n",
      "      - -204493.8460104138\n",
      "      - -201703.3622228379\n",
      "      - -199502.74943881837\n",
      "      - -200468.15086191113\n",
      "      - -200580.77594239957\n",
      "      - -202350.24681264875\n",
      "      - -204184.9507541089\n",
      "      - -202106.60248550886\n",
      "      - -201487.21253493335\n",
      "      - -198501.3026283931\n",
      "      - -198632.15418146105\n",
      "      - -201605.5791080212\n",
      "      - -205429.90444342428\n",
      "      - -203665.0192155506\n",
      "      - -202335.01846277452\n",
      "      - -201038.23406988173\n",
      "      - -199737.2150508918\n",
      "      - -199159.37215072208\n",
      "      - -202131.36325035634\n",
      "      - -199055.306795574\n",
      "      - -204099.49743161045\n",
      "      - -200577.14692432169\n",
      "      - -198527.1918581271\n",
      "      - -200963.0741106944\n",
      "      - -200411.8734479974\n",
      "      - -199759.24145023944\n",
      "      - -201740.1464527191\n",
      "      - -201263.1417769335\n",
      "      - -199531.54275741693\n",
      "      - -203845.26611811647\n",
      "      - -202346.33186899984\n",
      "      - -201632.10061793268\n",
      "      - -201547.5833751133\n",
      "      - -198888.95141246778\n",
      "      - -203073.37187602624\n",
      "      - -200227.19817913708\n",
      "      - -200256.71847802986\n",
      "      - -204557.30529610926\n",
      "      - -203744.228109684\n",
      "      - -201476.21895158387\n",
      "      - -197635.9674875726\n",
      "      - -201456.6121062386\n",
      "      - -197545.18461481755\n",
      "      - -199840.18892156507\n",
      "      - -200616.40950451355\n",
      "      - -199187.96572592208\n",
      "      - -198414.71381736477\n",
      "      - -199140.60693852475\n",
      "      - -200809.26583800715\n",
      "      - -201256.87817394978\n",
      "      - -200918.94635828704\n",
      "      - -202904.92507606174\n",
      "      - -200171.97936602018\n",
      "      - -202881.88939402756\n",
      "      - -204129.90755111244\n",
      "      - -199364.4515821656\n",
      "      - -198928.0272410496\n",
      "      - -200799.8513758974\n",
      "      - -199315.06148341743\n",
      "      - -199958.89318559086\n",
      "      - -200754.06703556931\n",
      "      - -200973.82009508554\n",
      "      - -198893.6663457075\n",
      "      - -202515.63032127306\n",
      "      - -200837.21310573735\n",
      "      - -202203.88288640152\n",
      "      - -203858.06972079427\n",
      "      - -199073.62116542793\n",
      "      - -202333.64849169162\n",
      "      - -204150.41690878526\n",
      "      - -202712.95818833789\n",
      "      - -200371.6018576191\n",
      "      - -200955.50660104456\n",
      "      - -200612.97803164762\n",
      "      - -199728.13355928165\n",
      "      - -198468.80222352463\n",
      "      - -201518.0748965038\n",
      "      - -199929.92482587876\n",
      "      - -199193.42139412966\n",
      "      - -201262.33488101888\n",
      "      - -203827.01196435248\n",
      "      - -199228.50059059716\n",
      "      - -203370.22327639576\n",
      "      - -198751.55229491982\n",
      "      - -200712.32690835977\n",
      "      - -199223.76255562075\n",
      "      - -202970.29817170821\n",
      "      - -199104.68264638988\n",
      "      - -199119.40722970385\n",
      "      - -199909.5882286047\n",
      "      - -204496.37037280356\n",
      "      - -201668.19188990226\n",
      "      - -203565.89235057824\n",
      "      - -198819.3901327366\n",
      "      - -198120.27626736413\n",
      "      - -199584.27706108635\n",
      "      - -207541.57125183215\n",
      "      - -198202.51810928682\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09506943133789424\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46949252514360723\n",
      "      mean_inference_ms: 0.9678886752382683\n",
      "      mean_raw_obs_processing_ms: 0.13490317689554698\n",
      "  time_since_restore: 1159.834567785263\n",
      "  time_this_iter_s: 9.191125869750977\n",
      "  time_total_s: 1159.834567785263\n",
      "  timers:\n",
      "    learn_throughput: 132613.624\n",
      "    learn_time_ms: 482.484\n",
      "    load_throughput: 22636802.397\n",
      "    load_time_ms: 2.827\n",
      "    training_iteration_time_ms: 9446.577\n",
      "    update_time_ms: 3.906\n",
      "  timestamp: 1665849907\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7742064\n",
      "  training_iteration: 121\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:05:12 (running for 00:19:46.94)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   121</td><td style=\"text-align: right;\">         1159.83</td><td style=\"text-align: right;\">7742064</td><td style=\"text-align: right;\"> -200992</td><td style=\"text-align: right;\">             -197545</td><td style=\"text-align: right;\">             -207542</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 7806048\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 7806048\n",
      "    num_agent_steps_trained: 7806048\n",
      "    num_env_steps_sampled: 7806048\n",
      "    num_env_steps_trained: 7806048\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-05-17\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -197068.52377735902\n",
      "  episode_reward_mean: -201081.3571646468\n",
      "  episode_reward_min: -207541.57125183215\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 7800\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.154980421066284\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0009144122595898807\n",
      "          model: {}\n",
      "          policy_loss: 0.00620920117944479\n",
      "          total_loss: 10.00607681274414\n",
      "          vf_explained_var: -4.730527436436205e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 7806048\n",
      "    num_agent_steps_trained: 7806048\n",
      "    num_env_steps_sampled: 7806048\n",
      "    num_env_steps_trained: 7806048\n",
      "  iterations_since_restore: 122\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 7806048\n",
      "  num_agent_steps_trained: 7806048\n",
      "  num_env_steps_sampled: 7806048\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 7806048\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 85.97857142857144\n",
      "    ram_util_percent: 86.9857142857143\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09517851868211323\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46960003371724973\n",
      "    mean_inference_ms: 0.9681235487389087\n",
      "    mean_raw_obs_processing_ms: 0.1350925575236905\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -197068.52377735902\n",
      "    episode_reward_mean: -201081.3571646468\n",
      "    episode_reward_min: -207541.57125183215\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -199315.06148341743\n",
      "      - -199958.89318559086\n",
      "      - -200754.06703556931\n",
      "      - -200973.82009508554\n",
      "      - -198893.6663457075\n",
      "      - -202515.63032127306\n",
      "      - -200837.21310573735\n",
      "      - -202203.88288640152\n",
      "      - -203858.06972079427\n",
      "      - -199073.62116542793\n",
      "      - -202333.64849169162\n",
      "      - -204150.41690878526\n",
      "      - -202712.95818833789\n",
      "      - -200371.6018576191\n",
      "      - -200955.50660104456\n",
      "      - -200612.97803164762\n",
      "      - -199728.13355928165\n",
      "      - -198468.80222352463\n",
      "      - -201518.0748965038\n",
      "      - -199929.92482587876\n",
      "      - -199193.42139412966\n",
      "      - -201262.33488101888\n",
      "      - -203827.01196435248\n",
      "      - -199228.50059059716\n",
      "      - -203370.22327639576\n",
      "      - -198751.55229491982\n",
      "      - -200712.32690835977\n",
      "      - -199223.76255562075\n",
      "      - -202970.29817170821\n",
      "      - -199104.68264638988\n",
      "      - -199119.40722970385\n",
      "      - -199909.5882286047\n",
      "      - -204496.37037280356\n",
      "      - -201668.19188990226\n",
      "      - -203565.89235057824\n",
      "      - -198819.3901327366\n",
      "      - -198120.27626736413\n",
      "      - -199584.27706108635\n",
      "      - -207541.57125183215\n",
      "      - -198202.51810928682\n",
      "      - -201838.77871588268\n",
      "      - -203788.85724889959\n",
      "      - -200947.70460541043\n",
      "      - -201874.14722000094\n",
      "      - -200996.18069565334\n",
      "      - -202939.39189872716\n",
      "      - -202759.38170076066\n",
      "      - -198274.07906387432\n",
      "      - -197068.52377735902\n",
      "      - -199702.16154530385\n",
      "      - -206020.0932220816\n",
      "      - -201507.4034760129\n",
      "      - -203174.05942498535\n",
      "      - -199100.59130680404\n",
      "      - -203680.37974508703\n",
      "      - -199567.92968427786\n",
      "      - -203671.14803465203\n",
      "      - -199388.3226605764\n",
      "      - -200955.8444511011\n",
      "      - -198420.292518898\n",
      "      - -202705.49498177262\n",
      "      - -198759.97480109957\n",
      "      - -200385.12500394214\n",
      "      - -203320.14025852148\n",
      "      - -203202.9220866364\n",
      "      - -201600.06937656458\n",
      "      - -198609.25943663297\n",
      "      - -201592.23334177095\n",
      "      - -202285.98929401708\n",
      "      - -199420.4050006024\n",
      "      - -202119.86242133137\n",
      "      - -199656.18213597155\n",
      "      - -202338.87131597914\n",
      "      - -201669.58539687152\n",
      "      - -200274.8601939516\n",
      "      - -201859.853593169\n",
      "      - -202548.0251074453\n",
      "      - -201880.1260682675\n",
      "      - -201645.66762165845\n",
      "      - -205059.0246569033\n",
      "      - -202760.53768008456\n",
      "      - -202724.61932299024\n",
      "      - -200352.88687436885\n",
      "      - -199746.93492520653\n",
      "      - -201650.97512551668\n",
      "      - -200396.8828246373\n",
      "      - -200906.89453932442\n",
      "      - -199664.3465786835\n",
      "      - -197891.75963444795\n",
      "      - -201465.10351789687\n",
      "      - -198650.08687517373\n",
      "      - -199180.68920978394\n",
      "      - -199735.93078638837\n",
      "      - -199439.69963374652\n",
      "      - -201359.43133197643\n",
      "      - -199154.2269607721\n",
      "      - -201798.9987536597\n",
      "      - -200840.0252838792\n",
      "      - -204615.51198837164\n",
      "      - -201353.66302160127\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09517851868211323\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46960003371724973\n",
      "      mean_inference_ms: 0.9681235487389087\n",
      "      mean_raw_obs_processing_ms: 0.1350925575236905\n",
      "  time_since_restore: 1170.0809848308563\n",
      "  time_this_iter_s: 10.246417045593262\n",
      "  time_total_s: 1170.0809848308563\n",
      "  timers:\n",
      "    learn_throughput: 133033.098\n",
      "    learn_time_ms: 480.963\n",
      "    load_throughput: 22661460.598\n",
      "    load_time_ms: 2.823\n",
      "    training_iteration_time_ms: 9531.946\n",
      "    update_time_ms: 3.752\n",
      "  timestamp: 1665849917\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7806048\n",
      "  training_iteration: 122\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:05:17 (running for 00:19:52.34)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   122</td><td style=\"text-align: right;\">         1170.08</td><td style=\"text-align: right;\">7806048</td><td style=\"text-align: right;\"> -201081</td><td style=\"text-align: right;\">             -197069</td><td style=\"text-align: right;\">             -207542</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:05:22 (running for 00:19:57.35)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   122</td><td style=\"text-align: right;\">         1170.08</td><td style=\"text-align: right;\">7806048</td><td style=\"text-align: right;\"> -201081</td><td style=\"text-align: right;\">             -197069</td><td style=\"text-align: right;\">             -207542</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:05:27 (running for 00:20:02.36)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   122</td><td style=\"text-align: right;\">         1170.08</td><td style=\"text-align: right;\">7806048</td><td style=\"text-align: right;\"> -201081</td><td style=\"text-align: right;\">             -197069</td><td style=\"text-align: right;\">             -207542</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 7870032\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 7870032\n",
      "    num_agent_steps_trained: 7870032\n",
      "    num_env_steps_sampled: 7870032\n",
      "    num_env_steps_trained: 7870032\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-05-27\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -197891.75963444795\n",
      "  episode_reward_mean: -201717.62737495202\n",
      "  episode_reward_min: -207894.76134957568\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 7860\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1590518951416016\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00046730050235055387\n",
      "          model: {}\n",
      "          policy_loss: 0.0024245711974799633\n",
      "          total_loss: 10.002202987670898\n",
      "          vf_explained_var: -2.4598742598413992e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 7870032\n",
      "    num_agent_steps_trained: 7870032\n",
      "    num_env_steps_sampled: 7870032\n",
      "    num_env_steps_trained: 7870032\n",
      "  iterations_since_restore: 123\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 7870032\n",
      "  num_agent_steps_trained: 7870032\n",
      "  num_env_steps_sampled: 7870032\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 7870032\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 80.77333333333334\n",
      "    ram_util_percent: 87.05333333333334\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09514716541137577\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4699959937778971\n",
      "    mean_inference_ms: 0.9686559188681556\n",
      "    mean_raw_obs_processing_ms: 0.1351201861246714\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -197891.75963444795\n",
      "    episode_reward_mean: -201717.62737495202\n",
      "    episode_reward_min: -207894.76134957568\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -202705.49498177262\n",
      "      - -198759.97480109957\n",
      "      - -200385.12500394214\n",
      "      - -203320.14025852148\n",
      "      - -203202.9220866364\n",
      "      - -201600.06937656458\n",
      "      - -198609.25943663297\n",
      "      - -201592.23334177095\n",
      "      - -202285.98929401708\n",
      "      - -199420.4050006024\n",
      "      - -202119.86242133137\n",
      "      - -199656.18213597155\n",
      "      - -202338.87131597914\n",
      "      - -201669.58539687152\n",
      "      - -200274.8601939516\n",
      "      - -201859.853593169\n",
      "      - -202548.0251074453\n",
      "      - -201880.1260682675\n",
      "      - -201645.66762165845\n",
      "      - -205059.0246569033\n",
      "      - -202760.53768008456\n",
      "      - -202724.61932299024\n",
      "      - -200352.88687436885\n",
      "      - -199746.93492520653\n",
      "      - -201650.97512551668\n",
      "      - -200396.8828246373\n",
      "      - -200906.89453932442\n",
      "      - -199664.3465786835\n",
      "      - -197891.75963444795\n",
      "      - -201465.10351789687\n",
      "      - -198650.08687517373\n",
      "      - -199180.68920978394\n",
      "      - -199735.93078638837\n",
      "      - -199439.69963374652\n",
      "      - -201359.43133197643\n",
      "      - -199154.2269607721\n",
      "      - -201798.9987536597\n",
      "      - -200840.0252838792\n",
      "      - -204615.51198837164\n",
      "      - -201353.66302160127\n",
      "      - -204397.01773789778\n",
      "      - -201060.94103819286\n",
      "      - -203529.6106503585\n",
      "      - -199679.5725352432\n",
      "      - -199828.01134029258\n",
      "      - -203339.0409827058\n",
      "      - -202376.18052713264\n",
      "      - -203324.16460168688\n",
      "      - -202800.47514621844\n",
      "      - -205331.87898368866\n",
      "      - -199920.11296225584\n",
      "      - -202708.84589912219\n",
      "      - -201490.8571434371\n",
      "      - -198093.1034612144\n",
      "      - -199947.82389641393\n",
      "      - -199178.50286941475\n",
      "      - -203458.05785426399\n",
      "      - -204256.52354841607\n",
      "      - -199584.95398441586\n",
      "      - -202726.97160034586\n",
      "      - -199070.24619741205\n",
      "      - -201266.82032216838\n",
      "      - -204725.68842169602\n",
      "      - -204800.3104464372\n",
      "      - -201878.11115433354\n",
      "      - -201487.72516891037\n",
      "      - -201999.80247189116\n",
      "      - -202644.88853859348\n",
      "      - -202029.6031510315\n",
      "      - -198962.7191603813\n",
      "      - -204227.01750940326\n",
      "      - -200326.85553814727\n",
      "      - -207894.76134957568\n",
      "      - -203469.54047364357\n",
      "      - -203549.1333125505\n",
      "      - -203191.22101922135\n",
      "      - -206677.00596444597\n",
      "      - -202679.0690687587\n",
      "      - -200905.64740951805\n",
      "      - -202320.8035846136\n",
      "      - -201337.5955774717\n",
      "      - -198056.6743522135\n",
      "      - -202973.52100715978\n",
      "      - -203138.17921886343\n",
      "      - -202860.84454596642\n",
      "      - -203596.4542885599\n",
      "      - -201407.55281037363\n",
      "      - -203759.16712817282\n",
      "      - -200119.57163338878\n",
      "      - -204418.99713966736\n",
      "      - -200777.84585904787\n",
      "      - -199490.986704705\n",
      "      - -202737.22181304995\n",
      "      - -201612.0707205523\n",
      "      - -203112.98004602315\n",
      "      - -201854.1976305056\n",
      "      - -200815.18703964466\n",
      "      - -200961.20285469154\n",
      "      - -202849.2994622929\n",
      "      - -200120.69367578582\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09514716541137577\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4699959937778971\n",
      "      mean_inference_ms: 0.9686559188681556\n",
      "      mean_raw_obs_processing_ms: 0.1351201861246714\n",
      "  time_since_restore: 1180.2406299114227\n",
      "  time_this_iter_s: 10.159645080566406\n",
      "  time_total_s: 1180.2406299114227\n",
      "  timers:\n",
      "    learn_throughput: 132327.297\n",
      "    learn_time_ms: 483.528\n",
      "    load_throughput: 22612769.391\n",
      "    load_time_ms: 2.83\n",
      "    training_iteration_time_ms: 9654.742\n",
      "    update_time_ms: 3.77\n",
      "  timestamp: 1665849927\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7870032\n",
      "  training_iteration: 123\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:05:33 (running for 00:20:07.40)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   123</td><td style=\"text-align: right;\">         1180.24</td><td style=\"text-align: right;\">7870032</td><td style=\"text-align: right;\"> -201718</td><td style=\"text-align: right;\">             -197892</td><td style=\"text-align: right;\">             -207895</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 7934016\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 7934016\n",
      "    num_agent_steps_trained: 7934016\n",
      "    num_env_steps_sampled: 7934016\n",
      "    num_env_steps_trained: 7934016\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-05-37\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -196770.71465957697\n",
      "  episode_reward_mean: -201837.39054080713\n",
      "  episode_reward_min: -207894.76134957568\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 7932\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1577701568603516\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0004839367466047406\n",
      "          model: {}\n",
      "          policy_loss: 0.0028922853525727987\n",
      "          total_loss: 10.00267219543457\n",
      "          vf_explained_var: -5.108969602929392e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 7934016\n",
      "    num_agent_steps_trained: 7934016\n",
      "    num_env_steps_sampled: 7934016\n",
      "    num_env_steps_trained: 7934016\n",
      "  iterations_since_restore: 124\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 7934016\n",
      "  num_agent_steps_trained: 7934016\n",
      "  num_env_steps_sampled: 7934016\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 7934016\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 85.26153846153845\n",
      "    ram_util_percent: 86.98461538461538\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09511483250189301\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46983569981019485\n",
      "    mean_inference_ms: 0.9690882702022359\n",
      "    mean_raw_obs_processing_ms: 0.13496965996979973\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -196770.71465957697\n",
      "    episode_reward_mean: -201837.39054080713\n",
      "    episode_reward_min: -207894.76134957568\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -207894.76134957568\n",
      "      - -203469.54047364357\n",
      "      - -203549.1333125505\n",
      "      - -203191.22101922135\n",
      "      - -206677.00596444597\n",
      "      - -202679.0690687587\n",
      "      - -200905.64740951805\n",
      "      - -202320.8035846136\n",
      "      - -201337.5955774717\n",
      "      - -198056.6743522135\n",
      "      - -202973.52100715978\n",
      "      - -203138.17921886343\n",
      "      - -202860.84454596642\n",
      "      - -203596.4542885599\n",
      "      - -201407.55281037363\n",
      "      - -203759.16712817282\n",
      "      - -200119.57163338878\n",
      "      - -204418.99713966736\n",
      "      - -200777.84585904787\n",
      "      - -199490.986704705\n",
      "      - -202737.22181304995\n",
      "      - -201612.0707205523\n",
      "      - -203112.98004602315\n",
      "      - -201854.1976305056\n",
      "      - -200815.18703964466\n",
      "      - -200961.20285469154\n",
      "      - -202849.2994622929\n",
      "      - -200120.69367578582\n",
      "      - -204813.86371584644\n",
      "      - -200143.3285785548\n",
      "      - -202024.8703790141\n",
      "      - -201764.08739840108\n",
      "      - -198502.4297008699\n",
      "      - -200778.97386041668\n",
      "      - -199710.02781940738\n",
      "      - -203213.3856770507\n",
      "      - -199468.6381675009\n",
      "      - -199561.35704452667\n",
      "      - -204028.2566689559\n",
      "      - -196770.71465957697\n",
      "      - -201005.33989710998\n",
      "      - -201953.7405443226\n",
      "      - -202598.08605792696\n",
      "      - -203715.17773998098\n",
      "      - -200714.3975114554\n",
      "      - -204984.8725084199\n",
      "      - -203160.66732735006\n",
      "      - -200038.06503925327\n",
      "      - -200838.52303660696\n",
      "      - -198674.18738463384\n",
      "      - -205019.66049772385\n",
      "      - -199321.97848622515\n",
      "      - -201828.28034884826\n",
      "      - -205948.9920211459\n",
      "      - -202122.47758449143\n",
      "      - -201413.9996461677\n",
      "      - -203013.8793643025\n",
      "      - -200451.33294781\n",
      "      - -199908.89745402295\n",
      "      - -201656.76647909448\n",
      "      - -203786.7647330395\n",
      "      - -202661.33185007877\n",
      "      - -198547.23637823728\n",
      "      - -199448.23498001773\n",
      "      - -203707.0209295405\n",
      "      - -203151.84509586342\n",
      "      - -197668.17337755326\n",
      "      - -201287.68586895932\n",
      "      - -203145.74987472355\n",
      "      - -205088.5384820211\n",
      "      - -201175.61144905313\n",
      "      - -202247.59318654952\n",
      "      - -199384.70966586666\n",
      "      - -201839.87382850546\n",
      "      - -202825.96926349966\n",
      "      - -202478.30129011004\n",
      "      - -201962.5217035511\n",
      "      - -201152.313083427\n",
      "      - -203758.14928677471\n",
      "      - -202821.1654618322\n",
      "      - -199713.84562664258\n",
      "      - -201723.81606545762\n",
      "      - -205641.01641294654\n",
      "      - -202044.21181333964\n",
      "      - -201012.66524002783\n",
      "      - -197837.29936447888\n",
      "      - -200475.79458227765\n",
      "      - -201546.30851543174\n",
      "      - -205208.56399930213\n",
      "      - -204060.58919282214\n",
      "      - -201869.67482582564\n",
      "      - -199615.77647189764\n",
      "      - -199911.10833273444\n",
      "      - -200872.7486912621\n",
      "      - -205278.42447092815\n",
      "      - -201205.83617693532\n",
      "      - -201214.69193208127\n",
      "      - -198836.66626223314\n",
      "      - -201870.97738012258\n",
      "      - -199823.56769728748\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09511483250189301\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46983569981019485\n",
      "      mean_inference_ms: 0.9690882702022359\n",
      "      mean_raw_obs_processing_ms: 0.13496965996979973\n",
      "  time_since_restore: 1189.8032855987549\n",
      "  time_this_iter_s: 9.562655687332153\n",
      "  time_total_s: 1189.8032855987549\n",
      "  timers:\n",
      "    learn_throughput: 132022.633\n",
      "    learn_time_ms: 484.644\n",
      "    load_throughput: 22525650.47\n",
      "    load_time_ms: 2.84\n",
      "    training_iteration_time_ms: 9673.765\n",
      "    update_time_ms: 3.809\n",
      "  timestamp: 1665849937\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7934016\n",
      "  training_iteration: 124\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:05:42 (running for 00:20:17.13)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   124</td><td style=\"text-align: right;\">          1189.8</td><td style=\"text-align: right;\">7934016</td><td style=\"text-align: right;\"> -201837</td><td style=\"text-align: right;\">             -196771</td><td style=\"text-align: right;\">             -207895</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 7998000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 7998000\n",
      "    num_agent_steps_trained: 7998000\n",
      "    num_env_steps_sampled: 7998000\n",
      "    num_env_steps_trained: 7998000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-05-47\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -197518.11951609034\n",
      "  episode_reward_mean: -201793.3957909703\n",
      "  episode_reward_min: -205641.01641294654\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 7992\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1551811695098877\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0004603054258041084\n",
      "          model: {}\n",
      "          policy_loss: 0.006309158634394407\n",
      "          total_loss: 10.006086349487305\n",
      "          vf_explained_var: -7.285012060265217e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 7998000\n",
      "    num_agent_steps_trained: 7998000\n",
      "    num_env_steps_sampled: 7998000\n",
      "    num_env_steps_trained: 7998000\n",
      "  iterations_since_restore: 125\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 7998000\n",
      "  num_agent_steps_trained: 7998000\n",
      "  num_env_steps_sampled: 7998000\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 7998000\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.13076923076922\n",
      "    ram_util_percent: 87.0\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09515800424265397\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4696981621662836\n",
      "    mean_inference_ms: 0.9688456529148243\n",
      "    mean_raw_obs_processing_ms: 0.1351088056241129\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -197518.11951609034\n",
      "    episode_reward_mean: -201793.3957909703\n",
      "    episode_reward_min: -205641.01641294654\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -203786.7647330395\n",
      "      - -202661.33185007877\n",
      "      - -198547.23637823728\n",
      "      - -199448.23498001773\n",
      "      - -203707.0209295405\n",
      "      - -203151.84509586342\n",
      "      - -197668.17337755326\n",
      "      - -201287.68586895932\n",
      "      - -203145.74987472355\n",
      "      - -205088.5384820211\n",
      "      - -201175.61144905313\n",
      "      - -202247.59318654952\n",
      "      - -199384.70966586666\n",
      "      - -201839.87382850546\n",
      "      - -202825.96926349966\n",
      "      - -202478.30129011004\n",
      "      - -201962.5217035511\n",
      "      - -201152.313083427\n",
      "      - -203758.14928677471\n",
      "      - -202821.1654618322\n",
      "      - -199713.84562664258\n",
      "      - -201723.81606545762\n",
      "      - -205641.01641294654\n",
      "      - -202044.21181333964\n",
      "      - -201012.66524002783\n",
      "      - -197837.29936447888\n",
      "      - -200475.79458227765\n",
      "      - -201546.30851543174\n",
      "      - -205208.56399930213\n",
      "      - -204060.58919282214\n",
      "      - -201869.67482582564\n",
      "      - -199615.77647189764\n",
      "      - -199911.10833273444\n",
      "      - -200872.7486912621\n",
      "      - -205278.42447092815\n",
      "      - -201205.83617693532\n",
      "      - -201214.69193208127\n",
      "      - -198836.66626223314\n",
      "      - -201870.97738012258\n",
      "      - -199823.56769728748\n",
      "      - -202091.66073478124\n",
      "      - -202375.83296269592\n",
      "      - -205399.5344824861\n",
      "      - -200823.39916926855\n",
      "      - -202312.38143699119\n",
      "      - -201896.6075240004\n",
      "      - -199234.14216932768\n",
      "      - -201676.01159852135\n",
      "      - -201502.3954815801\n",
      "      - -200306.03308623662\n",
      "      - -199950.91532519434\n",
      "      - -202657.5271650216\n",
      "      - -198746.835148118\n",
      "      - -199949.75963769795\n",
      "      - -202987.04091758098\n",
      "      - -199633.49656869788\n",
      "      - -200059.53139403032\n",
      "      - -203148.1045374209\n",
      "      - -201201.30950260867\n",
      "      - -201446.9932158716\n",
      "      - -202510.50340743773\n",
      "      - -201599.8415873556\n",
      "      - -203132.04024799378\n",
      "      - -203166.41700681136\n",
      "      - -202450.44314182707\n",
      "      - -205248.56465815764\n",
      "      - -197601.42159181228\n",
      "      - -203788.3256684414\n",
      "      - -203164.12063183004\n",
      "      - -204105.70015485949\n",
      "      - -202905.57500913923\n",
      "      - -199924.30391903242\n",
      "      - -203433.47439632672\n",
      "      - -198840.18272224284\n",
      "      - -199411.0871421727\n",
      "      - -202722.9990128912\n",
      "      - -201272.73731423393\n",
      "      - -202094.956832647\n",
      "      - -201269.2731199336\n",
      "      - -204107.19009652975\n",
      "      - -200585.7354605322\n",
      "      - -205086.11601306754\n",
      "      - -203231.08196977098\n",
      "      - -204238.8366377386\n",
      "      - -201935.51306495417\n",
      "      - -202674.79518413582\n",
      "      - -201218.31455784763\n",
      "      - -204449.91561437788\n",
      "      - -202484.6884732108\n",
      "      - -201741.7859797332\n",
      "      - -202017.18059738705\n",
      "      - -200675.99137971536\n",
      "      - -204567.36088642155\n",
      "      - -203085.42059077628\n",
      "      - -202982.19271767378\n",
      "      - -199763.70186501095\n",
      "      - -200397.71548231007\n",
      "      - -201163.27157832668\n",
      "      - -197518.11951609034\n",
      "      - -201470.79896490712\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09515800424265397\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4696981621662836\n",
      "      mean_inference_ms: 0.9688456529148243\n",
      "      mean_raw_obs_processing_ms: 0.1351088056241129\n",
      "  time_since_restore: 1199.286673784256\n",
      "  time_this_iter_s: 9.483388185501099\n",
      "  time_total_s: 1199.286673784256\n",
      "  timers:\n",
      "    learn_throughput: 132695.548\n",
      "    learn_time_ms: 482.186\n",
      "    load_throughput: 22432072.882\n",
      "    load_time_ms: 2.852\n",
      "    training_iteration_time_ms: 9681.329\n",
      "    update_time_ms: 3.807\n",
      "  timestamp: 1665849947\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7998000\n",
      "  training_iteration: 125\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:05:52 (running for 00:20:26.52)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   125</td><td style=\"text-align: right;\">         1199.29</td><td style=\"text-align: right;\">7998000</td><td style=\"text-align: right;\"> -201793</td><td style=\"text-align: right;\">             -197518</td><td style=\"text-align: right;\">             -205641</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 8061984\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 8061984\n",
      "    num_agent_steps_trained: 8061984\n",
      "    num_env_steps_sampled: 8061984\n",
      "    num_env_steps_trained: 8061984\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-05-55\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -197518.11951609034\n",
      "  episode_reward_mean: -201881.72241288738\n",
      "  episode_reward_min: -209381.8054393454\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 8052\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1540634632110596\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00033239819458685815\n",
      "          model: {}\n",
      "          policy_loss: 0.0030983430333435535\n",
      "          total_loss: 10.002850532531738\n",
      "          vf_explained_var: -4.352085269943018e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 8061984\n",
      "    num_agent_steps_trained: 8061984\n",
      "    num_env_steps_sampled: 8061984\n",
      "    num_env_steps_trained: 8061984\n",
      "  iterations_since_restore: 126\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 8061984\n",
      "  num_agent_steps_trained: 8061984\n",
      "  num_env_steps_sampled: 8061984\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 8061984\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.41538461538462\n",
      "    ram_util_percent: 86.9923076923077\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09507509665621786\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46975626682675325\n",
      "    mean_inference_ms: 0.9680122292425994\n",
      "    mean_raw_obs_processing_ms: 0.1350530750854361\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -197518.11951609034\n",
      "    episode_reward_mean: -201881.72241288738\n",
      "    episode_reward_min: -209381.8054393454\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -202510.50340743773\n",
      "      - -201599.8415873556\n",
      "      - -203132.04024799378\n",
      "      - -203166.41700681136\n",
      "      - -202450.44314182707\n",
      "      - -205248.56465815764\n",
      "      - -197601.42159181228\n",
      "      - -203788.3256684414\n",
      "      - -203164.12063183004\n",
      "      - -204105.70015485949\n",
      "      - -202905.57500913923\n",
      "      - -199924.30391903242\n",
      "      - -203433.47439632672\n",
      "      - -198840.18272224284\n",
      "      - -199411.0871421727\n",
      "      - -202722.9990128912\n",
      "      - -201272.73731423393\n",
      "      - -202094.956832647\n",
      "      - -201269.2731199336\n",
      "      - -204107.19009652975\n",
      "      - -200585.7354605322\n",
      "      - -205086.11601306754\n",
      "      - -203231.08196977098\n",
      "      - -204238.8366377386\n",
      "      - -201935.51306495417\n",
      "      - -202674.79518413582\n",
      "      - -201218.31455784763\n",
      "      - -204449.91561437788\n",
      "      - -202484.6884732108\n",
      "      - -201741.7859797332\n",
      "      - -202017.18059738705\n",
      "      - -200675.99137971536\n",
      "      - -204567.36088642155\n",
      "      - -203085.42059077628\n",
      "      - -202982.19271767378\n",
      "      - -199763.70186501095\n",
      "      - -200397.71548231007\n",
      "      - -201163.27157832668\n",
      "      - -197518.11951609034\n",
      "      - -201470.79896490712\n",
      "      - -199541.1726777618\n",
      "      - -203340.68021619195\n",
      "      - -203295.2621270611\n",
      "      - -201337.2278694337\n",
      "      - -200866.64005146694\n",
      "      - -202170.01864784042\n",
      "      - -202356.21461864078\n",
      "      - -202922.40533302815\n",
      "      - -198103.69169740102\n",
      "      - -202567.95726491892\n",
      "      - -203021.3272272642\n",
      "      - -200855.23404206935\n",
      "      - -203649.5782486738\n",
      "      - -199716.2158696111\n",
      "      - -202308.28387887904\n",
      "      - -200995.75190695326\n",
      "      - -199733.69019358893\n",
      "      - -200617.54067764827\n",
      "      - -205197.43040076457\n",
      "      - -198995.5805897755\n",
      "      - -202254.1701235303\n",
      "      - -199913.66560577333\n",
      "      - -198914.69190672386\n",
      "      - -200964.27310299955\n",
      "      - -200249.64446837013\n",
      "      - -209381.8054393454\n",
      "      - -201393.27127723972\n",
      "      - -203858.96144015403\n",
      "      - -201153.58650960433\n",
      "      - -200634.3245605655\n",
      "      - -202979.5536212745\n",
      "      - -203430.57739931476\n",
      "      - -199602.5847520435\n",
      "      - -202280.9654864769\n",
      "      - -201942.4549210325\n",
      "      - -200423.12082403613\n",
      "      - -204420.62094358596\n",
      "      - -201630.46543773302\n",
      "      - -199509.18664583453\n",
      "      - -199744.42987653034\n",
      "      - -199086.05421097184\n",
      "      - -203215.92130980478\n",
      "      - -203508.01139721886\n",
      "      - -199877.8686824178\n",
      "      - -202147.87941481033\n",
      "      - -201214.55694171606\n",
      "      - -203572.36450762284\n",
      "      - -201318.366200026\n",
      "      - -199119.30884392155\n",
      "      - -200359.23102051724\n",
      "      - -205485.84027614875\n",
      "      - -201137.04122917523\n",
      "      - -200513.88537858828\n",
      "      - -200920.46115188143\n",
      "      - -204440.21012588797\n",
      "      - -199950.7866710725\n",
      "      - -202162.9000545562\n",
      "      - -204702.90388967344\n",
      "      - -201131.06352826688\n",
      "      - -203995.6343776528\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09507509665621786\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46975626682675325\n",
      "      mean_inference_ms: 0.9680122292425994\n",
      "      mean_raw_obs_processing_ms: 0.1350530750854361\n",
      "  time_since_restore: 1208.1308312416077\n",
      "  time_this_iter_s: 8.844157457351685\n",
      "  time_total_s: 1208.1308312416077\n",
      "  timers:\n",
      "    learn_throughput: 130115.11\n",
      "    learn_time_ms: 491.749\n",
      "    load_throughput: 22446332.146\n",
      "    load_time_ms: 2.851\n",
      "    training_iteration_time_ms: 9633.652\n",
      "    update_time_ms: 3.813\n",
      "  timestamp: 1665849955\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8061984\n",
      "  training_iteration: 126\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:06:01 (running for 00:20:35.54)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   126</td><td style=\"text-align: right;\">         1208.13</td><td style=\"text-align: right;\">8061984</td><td style=\"text-align: right;\"> -201882</td><td style=\"text-align: right;\">             -197518</td><td style=\"text-align: right;\">             -209382</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 8125968\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 8125968\n",
      "    num_agent_steps_trained: 8125968\n",
      "    num_env_steps_sampled: 8125968\n",
      "    num_env_steps_trained: 8125968\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-06-05\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -196127.48871397975\n",
      "  episode_reward_mean: -201536.36601125833\n",
      "  episode_reward_min: -206925.53649977734\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 8124\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1569316387176514\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0006503960466943681\n",
      "          model: {}\n",
      "          policy_loss: 0.002944611944258213\n",
      "          total_loss: 10.002758026123047\n",
      "          vf_explained_var: -4.257474728319721e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 8125968\n",
      "    num_agent_steps_trained: 8125968\n",
      "    num_env_steps_sampled: 8125968\n",
      "    num_env_steps_trained: 8125968\n",
      "  iterations_since_restore: 127\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 8125968\n",
      "  num_agent_steps_trained: 8125968\n",
      "  num_env_steps_sampled: 8125968\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 8125968\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.06153846153846\n",
      "    ram_util_percent: 87.0\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09500779007516645\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46945134209244216\n",
      "    mean_inference_ms: 0.9675520191483368\n",
      "    mean_raw_obs_processing_ms: 0.13485303121343495\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -196127.48871397975\n",
      "    episode_reward_mean: -201536.36601125833\n",
      "    episode_reward_min: -206925.53649977734\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -199602.5847520435\n",
      "      - -202280.9654864769\n",
      "      - -201942.4549210325\n",
      "      - -200423.12082403613\n",
      "      - -204420.62094358596\n",
      "      - -201630.46543773302\n",
      "      - -199509.18664583453\n",
      "      - -199744.42987653034\n",
      "      - -199086.05421097184\n",
      "      - -203215.92130980478\n",
      "      - -203508.01139721886\n",
      "      - -199877.8686824178\n",
      "      - -202147.87941481033\n",
      "      - -201214.55694171606\n",
      "      - -203572.36450762284\n",
      "      - -201318.366200026\n",
      "      - -199119.30884392155\n",
      "      - -200359.23102051724\n",
      "      - -205485.84027614875\n",
      "      - -201137.04122917523\n",
      "      - -200513.88537858828\n",
      "      - -200920.46115188143\n",
      "      - -204440.21012588797\n",
      "      - -199950.7866710725\n",
      "      - -202162.9000545562\n",
      "      - -204702.90388967344\n",
      "      - -201131.06352826688\n",
      "      - -203995.6343776528\n",
      "      - -203899.1222428632\n",
      "      - -200346.40799190133\n",
      "      - -198380.66895556744\n",
      "      - -202620.2875590559\n",
      "      - -203664.20811843718\n",
      "      - -203219.4542951141\n",
      "      - -203438.34975946663\n",
      "      - -203717.90515908884\n",
      "      - -201454.88468749437\n",
      "      - -200883.37139867846\n",
      "      - -198144.07054610347\n",
      "      - -202016.1131151142\n",
      "      - -203135.43510914376\n",
      "      - -203707.72858537294\n",
      "      - -199823.89187661212\n",
      "      - -196127.48871397975\n",
      "      - -202435.05146495585\n",
      "      - -200398.6619278813\n",
      "      - -203751.22290302382\n",
      "      - -204814.68033013688\n",
      "      - -200599.1976172212\n",
      "      - -201888.10597891\n",
      "      - -201480.23836084985\n",
      "      - -204559.9866258393\n",
      "      - -201648.90962689178\n",
      "      - -199952.36373058608\n",
      "      - -204174.189976046\n",
      "      - -201219.66236429935\n",
      "      - -201449.82009146846\n",
      "      - -200935.31634853763\n",
      "      - -202407.4431441632\n",
      "      - -198930.52292158297\n",
      "      - -201285.61865896106\n",
      "      - -198955.87531709872\n",
      "      - -200642.94958515858\n",
      "      - -201967.86744535321\n",
      "      - -201430.97302674945\n",
      "      - -204136.62917695582\n",
      "      - -204212.8814017848\n",
      "      - -203478.8863361807\n",
      "      - -201572.19036332896\n",
      "      - -197757.694407787\n",
      "      - -199226.73075567433\n",
      "      - -201380.92337847722\n",
      "      - -206925.53649977734\n",
      "      - -199039.5546749822\n",
      "      - -199098.34030034038\n",
      "      - -199321.22100749792\n",
      "      - -201054.5806742514\n",
      "      - -203924.69699870844\n",
      "      - -204932.34341031304\n",
      "      - -202188.55293444652\n",
      "      - -202246.2207535125\n",
      "      - -199347.58363362748\n",
      "      - -204421.47911473445\n",
      "      - -200478.99291882387\n",
      "      - -200261.3234174892\n",
      "      - -199072.26965733845\n",
      "      - -202163.0913369128\n",
      "      - -200712.11050148174\n",
      "      - -198471.3904755251\n",
      "      - -201175.5572792315\n",
      "      - -202716.8112055235\n",
      "      - -205319.96811976976\n",
      "      - -200755.9752836847\n",
      "      - -200817.72017299014\n",
      "      - -201627.1870982858\n",
      "      - -199497.60418789383\n",
      "      - -200369.28898112944\n",
      "      - -201073.77004000085\n",
      "      - -198785.3742968819\n",
      "      - -199149.95667157735\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09500779007516645\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46945134209244216\n",
      "      mean_inference_ms: 0.9675520191483368\n",
      "      mean_raw_obs_processing_ms: 0.13485303121343495\n",
      "  time_since_restore: 1217.3647816181183\n",
      "  time_this_iter_s: 9.23395037651062\n",
      "  time_total_s: 1217.3647816181183\n",
      "  timers:\n",
      "    learn_throughput: 130490.129\n",
      "    learn_time_ms: 490.336\n",
      "    load_throughput: 22439200.249\n",
      "    load_time_ms: 2.851\n",
      "    training_iteration_time_ms: 9593.489\n",
      "    update_time_ms: 3.945\n",
      "  timestamp: 1665849965\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8125968\n",
      "  training_iteration: 127\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:06:10 (running for 00:20:44.80)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   127</td><td style=\"text-align: right;\">         1217.36</td><td style=\"text-align: right;\">8125968</td><td style=\"text-align: right;\"> -201536</td><td style=\"text-align: right;\">             -196127</td><td style=\"text-align: right;\">             -206926</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 8189952\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 8189952\n",
      "    num_agent_steps_trained: 8189952\n",
      "    num_env_steps_sampled: 8189952\n",
      "    num_env_steps_trained: 8189952\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-06-14\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -197607.6536389721\n",
      "  episode_reward_mean: -201100.70945111747\n",
      "  episode_reward_min: -211511.51083855476\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 8184\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.155449151992798\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0005070922779850662\n",
      "          model: {}\n",
      "          policy_loss: 0.006142523605376482\n",
      "          total_loss: 10.005928039550781\n",
      "          vf_explained_var: -5.392801227799282e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 8189952\n",
      "    num_agent_steps_trained: 8189952\n",
      "    num_env_steps_sampled: 8189952\n",
      "    num_env_steps_trained: 8189952\n",
      "  iterations_since_restore: 128\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 8189952\n",
      "  num_agent_steps_trained: 8189952\n",
      "  num_env_steps_sampled: 8189952\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 8189952\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 80.56153846153848\n",
      "    ram_util_percent: 87.0\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09503354919524995\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46925244676418315\n",
      "    mean_inference_ms: 0.9674901046951717\n",
      "    mean_raw_obs_processing_ms: 0.13497882533884936\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -197607.6536389721\n",
      "    episode_reward_mean: -201100.70945111747\n",
      "    episode_reward_min: -211511.51083855476\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -201285.61865896106\n",
      "      - -198955.87531709872\n",
      "      - -200642.94958515858\n",
      "      - -201967.86744535321\n",
      "      - -201430.97302674945\n",
      "      - -204136.62917695582\n",
      "      - -204212.8814017848\n",
      "      - -203478.8863361807\n",
      "      - -201572.19036332896\n",
      "      - -197757.694407787\n",
      "      - -199226.73075567433\n",
      "      - -201380.92337847722\n",
      "      - -206925.53649977734\n",
      "      - -199039.5546749822\n",
      "      - -199098.34030034038\n",
      "      - -199321.22100749792\n",
      "      - -201054.5806742514\n",
      "      - -203924.69699870844\n",
      "      - -204932.34341031304\n",
      "      - -202188.55293444652\n",
      "      - -202246.2207535125\n",
      "      - -199347.58363362748\n",
      "      - -204421.47911473445\n",
      "      - -200478.99291882387\n",
      "      - -200261.3234174892\n",
      "      - -199072.26965733845\n",
      "      - -202163.0913369128\n",
      "      - -200712.11050148174\n",
      "      - -198471.3904755251\n",
      "      - -201175.5572792315\n",
      "      - -202716.8112055235\n",
      "      - -205319.96811976976\n",
      "      - -200755.9752836847\n",
      "      - -200817.72017299014\n",
      "      - -201627.1870982858\n",
      "      - -199497.60418789383\n",
      "      - -200369.28898112944\n",
      "      - -201073.77004000085\n",
      "      - -198785.3742968819\n",
      "      - -199149.95667157735\n",
      "      - -211511.51083855476\n",
      "      - -202692.76290667462\n",
      "      - -199454.39455669993\n",
      "      - -201255.6557926087\n",
      "      - -198859.16019691748\n",
      "      - -200133.86831532206\n",
      "      - -201846.78825776154\n",
      "      - -200564.8838187397\n",
      "      - -200869.34422238512\n",
      "      - -204388.9928813245\n",
      "      - -198430.80497837972\n",
      "      - -198107.46078811807\n",
      "      - -200236.49802149998\n",
      "      - -202642.62045669576\n",
      "      - -203277.35298781437\n",
      "      - -198618.08115941274\n",
      "      - -199161.57111126892\n",
      "      - -200252.5089955653\n",
      "      - -203257.90945107673\n",
      "      - -197607.6536389721\n",
      "      - -204924.0198171205\n",
      "      - -201262.01518271203\n",
      "      - -199561.97021619198\n",
      "      - -201681.4380716008\n",
      "      - -200519.87983750715\n",
      "      - -200679.0271619441\n",
      "      - -200278.08030293943\n",
      "      - -200526.32469745204\n",
      "      - -200928.54367879804\n",
      "      - -198756.33177795983\n",
      "      - -201947.1353437774\n",
      "      - -199221.7669407762\n",
      "      - -203014.87511560178\n",
      "      - -198289.18337235556\n",
      "      - -204236.23726985144\n",
      "      - -199082.4880778871\n",
      "      - -201590.3853765035\n",
      "      - -198938.74885546885\n",
      "      - -199710.9914856223\n",
      "      - -201489.98229468835\n",
      "      - -199330.77491855435\n",
      "      - -204542.34867196504\n",
      "      - -200142.66861421982\n",
      "      - -201467.17553825816\n",
      "      - -201235.85503775568\n",
      "      - -202778.80439170278\n",
      "      - -203062.4416513056\n",
      "      - -198784.57731721358\n",
      "      - -201144.99710767003\n",
      "      - -198576.0008799801\n",
      "      - -201273.11579282937\n",
      "      - -200816.31560072635\n",
      "      - -202455.98446258222\n",
      "      - -203960.64216194712\n",
      "      - -199063.59842588476\n",
      "      - -199964.38195006692\n",
      "      - -200290.20585459\n",
      "      - -200054.52595035493\n",
      "      - -199715.86287027088\n",
      "      - -200603.6981610782\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09503354919524995\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46925244676418315\n",
      "      mean_inference_ms: 0.9674901046951717\n",
      "      mean_raw_obs_processing_ms: 0.13497882533884936\n",
      "  time_since_restore: 1226.644146680832\n",
      "  time_this_iter_s: 9.279365062713623\n",
      "  time_total_s: 1226.644146680832\n",
      "  timers:\n",
      "    learn_throughput: 130623.329\n",
      "    learn_time_ms: 489.836\n",
      "    load_throughput: 22451965.794\n",
      "    load_time_ms: 2.85\n",
      "    training_iteration_time_ms: 9557.618\n",
      "    update_time_ms: 3.946\n",
      "  timestamp: 1665849974\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8189952\n",
      "  training_iteration: 128\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:06:19 (running for 00:20:53.97)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   128</td><td style=\"text-align: right;\">         1226.64</td><td style=\"text-align: right;\">8189952</td><td style=\"text-align: right;\"> -201101</td><td style=\"text-align: right;\">             -197608</td><td style=\"text-align: right;\">             -211512</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 8253936\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 8253936\n",
      "    num_agent_steps_trained: 8253936\n",
      "    num_env_steps_sampled: 8253936\n",
      "    num_env_steps_trained: 8253936\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-06-24\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -196137.00935382568\n",
      "  episode_reward_mean: -201100.4420721797\n",
      "  episode_reward_min: -209644.1315852862\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 8244\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1574246883392334\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0003572635177988559\n",
      "          model: {}\n",
      "          policy_loss: 0.003220645245164633\n",
      "          total_loss: 10.002976417541504\n",
      "          vf_explained_var: -4.1628641866964244e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 8253936\n",
      "    num_agent_steps_trained: 8253936\n",
      "    num_env_steps_sampled: 8253936\n",
      "    num_env_steps_trained: 8253936\n",
      "  iterations_since_restore: 129\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 8253936\n",
      "  num_agent_steps_trained: 8253936\n",
      "  num_env_steps_sampled: 8253936\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 8253936\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.66153846153847\n",
      "    ram_util_percent: 86.95384615384616\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09495606888607157\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4693491377545786\n",
      "    mean_inference_ms: 0.9672454022228678\n",
      "    mean_raw_obs_processing_ms: 0.13494426873653698\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -196137.00935382568\n",
      "    episode_reward_mean: -201100.4420721797\n",
      "    episode_reward_min: -209644.1315852862\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -204924.0198171205\n",
      "      - -201262.01518271203\n",
      "      - -199561.97021619198\n",
      "      - -201681.4380716008\n",
      "      - -200519.87983750715\n",
      "      - -200679.0271619441\n",
      "      - -200278.08030293943\n",
      "      - -200526.32469745204\n",
      "      - -200928.54367879804\n",
      "      - -198756.33177795983\n",
      "      - -201947.1353437774\n",
      "      - -199221.7669407762\n",
      "      - -203014.87511560178\n",
      "      - -198289.18337235556\n",
      "      - -204236.23726985144\n",
      "      - -199082.4880778871\n",
      "      - -201590.3853765035\n",
      "      - -198938.74885546885\n",
      "      - -199710.9914856223\n",
      "      - -201489.98229468835\n",
      "      - -199330.77491855435\n",
      "      - -204542.34867196504\n",
      "      - -200142.66861421982\n",
      "      - -201467.17553825816\n",
      "      - -201235.85503775568\n",
      "      - -202778.80439170278\n",
      "      - -203062.4416513056\n",
      "      - -198784.57731721358\n",
      "      - -201144.99710767003\n",
      "      - -198576.0008799801\n",
      "      - -201273.11579282937\n",
      "      - -200816.31560072635\n",
      "      - -202455.98446258222\n",
      "      - -203960.64216194712\n",
      "      - -199063.59842588476\n",
      "      - -199964.38195006692\n",
      "      - -200290.20585459\n",
      "      - -200054.52595035493\n",
      "      - -199715.86287027088\n",
      "      - -200603.6981610782\n",
      "      - -204732.58537390077\n",
      "      - -209644.1315852862\n",
      "      - -201318.87491352763\n",
      "      - -201090.6974951564\n",
      "      - -201342.35990426815\n",
      "      - -202559.2830568276\n",
      "      - -203616.2389912543\n",
      "      - -197806.6748758843\n",
      "      - -199606.14338552675\n",
      "      - -206169.31991883053\n",
      "      - -201085.21243484764\n",
      "      - -201891.8634633174\n",
      "      - -198954.39773263034\n",
      "      - -201628.43362826365\n",
      "      - -201103.00068669685\n",
      "      - -202994.76549802697\n",
      "      - -202357.5613236621\n",
      "      - -201702.1763982791\n",
      "      - -198862.23682540207\n",
      "      - -204092.99592148492\n",
      "      - -202754.56336003199\n",
      "      - -199281.45565778724\n",
      "      - -200410.73449371284\n",
      "      - -200310.0938944164\n",
      "      - -199348.27902406876\n",
      "      - -201854.87741075605\n",
      "      - -204346.89657921315\n",
      "      - -199942.03940891477\n",
      "      - -201156.5525195652\n",
      "      - -198102.59252039186\n",
      "      - -198869.07681250398\n",
      "      - -201567.3245501943\n",
      "      - -198900.58475516087\n",
      "      - -203003.39676064003\n",
      "      - -199440.1734151272\n",
      "      - -198175.22018653504\n",
      "      - -201082.66917689412\n",
      "      - -198442.75515006596\n",
      "      - -200666.0312403567\n",
      "      - -199267.20904360322\n",
      "      - -200639.59045904514\n",
      "      - -201128.2195285123\n",
      "      - -201859.36235871835\n",
      "      - -201695.64293168284\n",
      "      - -204048.74528317398\n",
      "      - -201913.38034952033\n",
      "      - -199311.92853442012\n",
      "      - -201275.12486230186\n",
      "      - -196137.00935382568\n",
      "      - -199128.56774092064\n",
      "      - -201899.43663742355\n",
      "      - -204068.81277447386\n",
      "      - -201199.1252273571\n",
      "      - -202647.3722802534\n",
      "      - -200467.98152080513\n",
      "      - -203939.95699097257\n",
      "      - -200315.14102746826\n",
      "      - -196989.28710629398\n",
      "      - -206627.73745826937\n",
      "      - -199366.90518380245\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09495606888607157\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4693491377545786\n",
      "      mean_inference_ms: 0.9672454022228678\n",
      "      mean_raw_obs_processing_ms: 0.13494426873653698\n",
      "  time_since_restore: 1236.0766129493713\n",
      "  time_this_iter_s: 9.432466268539429\n",
      "  time_total_s: 1236.0766129493713\n",
      "  timers:\n",
      "    learn_throughput: 130595.634\n",
      "    learn_time_ms: 489.94\n",
      "    load_throughput: 22113592.493\n",
      "    load_time_ms: 2.893\n",
      "    training_iteration_time_ms: 9455.577\n",
      "    update_time_ms: 4.131\n",
      "  timestamp: 1665849984\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8253936\n",
      "  training_iteration: 129\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:06:29 (running for 00:21:03.57)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   129</td><td style=\"text-align: right;\">         1236.08</td><td style=\"text-align: right;\">8253936</td><td style=\"text-align: right;\"> -201100</td><td style=\"text-align: right;\">             -196137</td><td style=\"text-align: right;\">             -209644</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 8317920\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 8317920\n",
      "    num_agent_steps_trained: 8317920\n",
      "    num_env_steps_sampled: 8317920\n",
      "    num_env_steps_trained: 8317920\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-06-33\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -196137.00935382568\n",
      "  episode_reward_mean: -201991.68347359347\n",
      "  episode_reward_min: -251793.0248700226\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 8316\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1550159454345703\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0007188533782027662\n",
      "          model: {}\n",
      "          policy_loss: 0.002761990064755082\n",
      "          total_loss: 10.002589225769043\n",
      "          vf_explained_var: -3.500590395333347e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 8317920\n",
      "    num_agent_steps_trained: 8317920\n",
      "    num_env_steps_sampled: 8317920\n",
      "    num_env_steps_trained: 8317920\n",
      "  iterations_since_restore: 130\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 8317920\n",
      "  num_agent_steps_trained: 8317920\n",
      "  num_env_steps_sampled: 8317920\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 8317920\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.32307692307691\n",
      "    ram_util_percent: 86.9923076923077\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09490514780236263\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46914224603028265\n",
      "    mean_inference_ms: 0.9670463107267082\n",
      "    mean_raw_obs_processing_ms: 0.13479655534056043\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -196137.00935382568\n",
      "    episode_reward_mean: -201991.68347359347\n",
      "    episode_reward_min: -251793.0248700226\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -198900.58475516087\n",
      "      - -203003.39676064003\n",
      "      - -199440.1734151272\n",
      "      - -198175.22018653504\n",
      "      - -201082.66917689412\n",
      "      - -198442.75515006596\n",
      "      - -200666.0312403567\n",
      "      - -199267.20904360322\n",
      "      - -200639.59045904514\n",
      "      - -201128.2195285123\n",
      "      - -201859.36235871835\n",
      "      - -201695.64293168284\n",
      "      - -204048.74528317398\n",
      "      - -201913.38034952033\n",
      "      - -199311.92853442012\n",
      "      - -201275.12486230186\n",
      "      - -196137.00935382568\n",
      "      - -199128.56774092064\n",
      "      - -201899.43663742355\n",
      "      - -204068.81277447386\n",
      "      - -201199.1252273571\n",
      "      - -202647.3722802534\n",
      "      - -200467.98152080513\n",
      "      - -203939.95699097257\n",
      "      - -200315.14102746826\n",
      "      - -196989.28710629398\n",
      "      - -206627.73745826937\n",
      "      - -199366.90518380245\n",
      "      - -200896.9632349482\n",
      "      - -204877.0321519037\n",
      "      - -200961.62849123424\n",
      "      - -200626.71884985728\n",
      "      - -203894.36021561277\n",
      "      - -200237.14043023833\n",
      "      - -199426.02082116835\n",
      "      - -232841.9397113552\n",
      "      - -201792.4051079911\n",
      "      - -202689.5867358193\n",
      "      - -196455.4825441869\n",
      "      - -200159.5255589058\n",
      "      - -206422.95400875338\n",
      "      - -201532.05630823344\n",
      "      - -200377.3527814104\n",
      "      - -199377.89079651993\n",
      "      - -202643.83972726503\n",
      "      - -198015.46728653763\n",
      "      - -200746.4515295957\n",
      "      - -199691.02579410936\n",
      "      - -199279.7780193045\n",
      "      - -203378.4346228792\n",
      "      - -197455.32909972736\n",
      "      - -201293.64054889136\n",
      "      - -202169.8562300707\n",
      "      - -203297.9282892848\n",
      "      - -200292.07660950453\n",
      "      - -205641.5286646274\n",
      "      - -201393.7659915536\n",
      "      - -222652.20458905993\n",
      "      - -202366.32929135562\n",
      "      - -199667.3274817165\n",
      "      - -199801.13467473208\n",
      "      - -202562.2528904863\n",
      "      - -202950.21103297838\n",
      "      - -199850.5559276778\n",
      "      - -200903.06190299828\n",
      "      - -198508.33669207687\n",
      "      - -200407.53836572942\n",
      "      - -251793.0248700226\n",
      "      - -200624.54551624562\n",
      "      - -202898.84428866056\n",
      "      - -200517.6544038023\n",
      "      - -204348.73908285037\n",
      "      - -204497.025975455\n",
      "      - -198561.925288638\n",
      "      - -201223.53305392945\n",
      "      - -202400.04475774543\n",
      "      - -199179.6150508946\n",
      "      - -202248.03111528422\n",
      "      - -202133.06187176437\n",
      "      - -199619.95284973644\n",
      "      - -197852.5826592934\n",
      "      - -199050.78750707558\n",
      "      - -200950.69375349733\n",
      "      - -200706.3819879219\n",
      "      - -200341.96337138207\n",
      "      - -199010.56005880306\n",
      "      - -198461.7454101689\n",
      "      - -201669.38144397107\n",
      "      - -201785.4490800061\n",
      "      - -197827.76283584768\n",
      "      - -200206.8635132635\n",
      "      - -199619.26748272794\n",
      "      - -199706.08655870723\n",
      "      - -204408.87187255095\n",
      "      - -203248.76920398438\n",
      "      - -199698.0987783143\n",
      "      - -200399.73295743423\n",
      "      - -200834.7983338066\n",
      "      - -201524.10506260413\n",
      "      - -200643.9470150348\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09490514780236263\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46914224603028265\n",
      "      mean_inference_ms: 0.9670463107267082\n",
      "      mean_raw_obs_processing_ms: 0.13479655534056043\n",
      "  time_since_restore: 1245.3553094863892\n",
      "  time_this_iter_s: 9.278696537017822\n",
      "  time_total_s: 1245.3553094863892\n",
      "  timers:\n",
      "    learn_throughput: 130339.624\n",
      "    learn_time_ms: 490.902\n",
      "    load_throughput: 21887608.646\n",
      "    load_time_ms: 2.923\n",
      "    training_iteration_time_ms: 9464.76\n",
      "    update_time_ms: 4.108\n",
      "  timestamp: 1665849993\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8317920\n",
      "  training_iteration: 130\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:06:38 (running for 00:21:12.90)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   130</td><td style=\"text-align: right;\">         1245.36</td><td style=\"text-align: right;\">8317920</td><td style=\"text-align: right;\"> -201992</td><td style=\"text-align: right;\">             -196137</td><td style=\"text-align: right;\">             -251793</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 8381904\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 8381904\n",
      "    num_agent_steps_trained: 8381904\n",
      "    num_env_steps_sampled: 8381904\n",
      "    num_env_steps_trained: 8381904\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-06-42\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -195213.0257981498\n",
      "  episode_reward_mean: -200979.6229463314\n",
      "  episode_reward_min: -251793.0248700226\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 8376\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1514556407928467\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0007135669584386051\n",
      "          model: {}\n",
      "          policy_loss: 0.005752533674240112\n",
      "          total_loss: 10.00558090209961\n",
      "          vf_explained_var: -3.595200936956644e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 8381904\n",
      "    num_agent_steps_trained: 8381904\n",
      "    num_env_steps_sampled: 8381904\n",
      "    num_env_steps_trained: 8381904\n",
      "  iterations_since_restore: 131\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 8381904\n",
      "  num_agent_steps_trained: 8381904\n",
      "  num_env_steps_sampled: 8381904\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 8381904\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 78.55714285714285\n",
      "    ram_util_percent: 86.97857142857144\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09494724182978427\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46900516411802257\n",
      "    mean_inference_ms: 0.9670766666058421\n",
      "    mean_raw_obs_processing_ms: 0.13496596553954268\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -195213.0257981498\n",
      "    episode_reward_mean: -200979.6229463314\n",
      "    episode_reward_min: -251793.0248700226\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -199801.13467473208\n",
      "      - -202562.2528904863\n",
      "      - -202950.21103297838\n",
      "      - -199850.5559276778\n",
      "      - -200903.06190299828\n",
      "      - -198508.33669207687\n",
      "      - -200407.53836572942\n",
      "      - -251793.0248700226\n",
      "      - -200624.54551624562\n",
      "      - -202898.84428866056\n",
      "      - -200517.6544038023\n",
      "      - -204348.73908285037\n",
      "      - -204497.025975455\n",
      "      - -198561.925288638\n",
      "      - -201223.53305392945\n",
      "      - -202400.04475774543\n",
      "      - -199179.6150508946\n",
      "      - -202248.03111528422\n",
      "      - -202133.06187176437\n",
      "      - -199619.95284973644\n",
      "      - -197852.5826592934\n",
      "      - -199050.78750707558\n",
      "      - -200950.69375349733\n",
      "      - -200706.3819879219\n",
      "      - -200341.96337138207\n",
      "      - -199010.56005880306\n",
      "      - -198461.7454101689\n",
      "      - -201669.38144397107\n",
      "      - -201785.4490800061\n",
      "      - -197827.76283584768\n",
      "      - -200206.8635132635\n",
      "      - -199619.26748272794\n",
      "      - -199706.08655870723\n",
      "      - -204408.87187255095\n",
      "      - -203248.76920398438\n",
      "      - -199698.0987783143\n",
      "      - -200399.73295743423\n",
      "      - -200834.7983338066\n",
      "      - -201524.10506260413\n",
      "      - -200643.9470150348\n",
      "      - -199888.30802991867\n",
      "      - -198842.4695532645\n",
      "      - -202744.46498993653\n",
      "      - -200889.2110280103\n",
      "      - -198304.35308184545\n",
      "      - -203587.22850249623\n",
      "      - -200187.41045102858\n",
      "      - -200795.6074292154\n",
      "      - -201462.44420882475\n",
      "      - -199180.8777178673\n",
      "      - -198695.53793001288\n",
      "      - -195450.86466453486\n",
      "      - -198967.10373147647\n",
      "      - -203552.38001912195\n",
      "      - -200716.64400857524\n",
      "      - -199919.00182755542\n",
      "      - -196693.11542822688\n",
      "      - -198351.6797782935\n",
      "      - -200262.4364595327\n",
      "      - -202080.14416756298\n",
      "      - -200125.4422986445\n",
      "      - -196609.1667028259\n",
      "      - -198162.0949140493\n",
      "      - -203502.28407796868\n",
      "      - -201797.2229564183\n",
      "      - -197062.8164274826\n",
      "      - -198379.69891563465\n",
      "      - -200623.87196324917\n",
      "      - -195213.0257981498\n",
      "      - -203811.70176419793\n",
      "      - -205546.1207558037\n",
      "      - -201273.03347294425\n",
      "      - -199648.5096641516\n",
      "      - -202351.55802758253\n",
      "      - -196312.07887894163\n",
      "      - -201895.72504876336\n",
      "      - -203608.4874186956\n",
      "      - -200260.2121013019\n",
      "      - -201853.6116037246\n",
      "      - -199461.51060050927\n",
      "      - -204452.51730470944\n",
      "      - -202380.55327273207\n",
      "      - -198416.34363558106\n",
      "      - -205130.23341948894\n",
      "      - -200741.35815033352\n",
      "      - -196221.74135952935\n",
      "      - -197708.97462007916\n",
      "      - -200916.84918862482\n",
      "      - -201052.00946270226\n",
      "      - -198429.82007790374\n",
      "      - -198152.4507780356\n",
      "      - -198353.9072901706\n",
      "      - -199643.6641791181\n",
      "      - -201125.85849312332\n",
      "      - -201087.69284835886\n",
      "      - -197927.49926594493\n",
      "      - -197423.80989934102\n",
      "      - -202925.98150218758\n",
      "      - -204626.3091572106\n",
      "      - -200198.32583152145\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09494724182978427\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46900516411802257\n",
      "      mean_inference_ms: 0.9670766666058421\n",
      "      mean_raw_obs_processing_ms: 0.13496596553954268\n",
      "  time_since_restore: 1254.8384540081024\n",
      "  time_this_iter_s: 9.483144521713257\n",
      "  time_total_s: 1254.8384540081024\n",
      "  timers:\n",
      "    learn_throughput: 130771.584\n",
      "    learn_time_ms: 489.281\n",
      "    load_throughput: 22083567.619\n",
      "    load_time_ms: 2.897\n",
      "    training_iteration_time_ms: 9493.856\n",
      "    update_time_ms: 4.17\n",
      "  timestamp: 1665850002\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8381904\n",
      "  training_iteration: 131\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:06:47 (running for 00:21:22.39)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   131</td><td style=\"text-align: right;\">         1254.84</td><td style=\"text-align: right;\">8381904</td><td style=\"text-align: right;\"> -200980</td><td style=\"text-align: right;\">             -195213</td><td style=\"text-align: right;\">             -251793</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 8445888\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 8445888\n",
      "    num_agent_steps_trained: 8445888\n",
      "    num_env_steps_sampled: 8445888\n",
      "    num_env_steps_trained: 8445888\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-06-52\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -195213.0257981498\n",
      "  episode_reward_mean: -200745.9646095395\n",
      "  episode_reward_min: -205696.9862178534\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 8436\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1524641513824463\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00042273130384273827\n",
      "          model: {}\n",
      "          policy_loss: 0.003891976084560156\n",
      "          total_loss: 10.003662109375\n",
      "          vf_explained_var: -2.2706531765948057e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 8445888\n",
      "    num_agent_steps_trained: 8445888\n",
      "    num_env_steps_sampled: 8445888\n",
      "    num_env_steps_trained: 8445888\n",
      "  iterations_since_restore: 132\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 8445888\n",
      "  num_agent_steps_trained: 8445888\n",
      "  num_env_steps_sampled: 8445888\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 8445888\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.1846153846154\n",
      "    ram_util_percent: 86.96923076923078\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09487267656263804\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.469131328183223\n",
      "    mean_inference_ms: 0.9668402871785904\n",
      "    mean_raw_obs_processing_ms: 0.13492757167090028\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -195213.0257981498\n",
      "    episode_reward_mean: -200745.9646095395\n",
      "    episode_reward_min: -205696.9862178534\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -200125.4422986445\n",
      "      - -196609.1667028259\n",
      "      - -198162.0949140493\n",
      "      - -203502.28407796868\n",
      "      - -201797.2229564183\n",
      "      - -197062.8164274826\n",
      "      - -198379.69891563465\n",
      "      - -200623.87196324917\n",
      "      - -195213.0257981498\n",
      "      - -203811.70176419793\n",
      "      - -205546.1207558037\n",
      "      - -201273.03347294425\n",
      "      - -199648.5096641516\n",
      "      - -202351.55802758253\n",
      "      - -196312.07887894163\n",
      "      - -201895.72504876336\n",
      "      - -203608.4874186956\n",
      "      - -200260.2121013019\n",
      "      - -201853.6116037246\n",
      "      - -199461.51060050927\n",
      "      - -204452.51730470944\n",
      "      - -202380.55327273207\n",
      "      - -198416.34363558106\n",
      "      - -205130.23341948894\n",
      "      - -200741.35815033352\n",
      "      - -196221.74135952935\n",
      "      - -197708.97462007916\n",
      "      - -200916.84918862482\n",
      "      - -201052.00946270226\n",
      "      - -198429.82007790374\n",
      "      - -198152.4507780356\n",
      "      - -198353.9072901706\n",
      "      - -199643.6641791181\n",
      "      - -201125.85849312332\n",
      "      - -201087.69284835886\n",
      "      - -197927.49926594493\n",
      "      - -197423.80989934102\n",
      "      - -202925.98150218758\n",
      "      - -204626.3091572106\n",
      "      - -200198.32583152145\n",
      "      - -198384.73200086417\n",
      "      - -200889.37621016873\n",
      "      - -203102.1439137013\n",
      "      - -202089.2831322999\n",
      "      - -203852.45112374768\n",
      "      - -197145.67270601084\n",
      "      - -202977.50235391542\n",
      "      - -201549.87241416768\n",
      "      - -198057.2985197031\n",
      "      - -199461.16526697515\n",
      "      - -204351.4951208523\n",
      "      - -205696.9862178534\n",
      "      - -200083.90392440316\n",
      "      - -199708.87023884995\n",
      "      - -202803.19839014392\n",
      "      - -197600.540847662\n",
      "      - -200144.18272529743\n",
      "      - -201386.80002189917\n",
      "      - -200468.4574580582\n",
      "      - -200064.75416020915\n",
      "      - -204511.21943482786\n",
      "      - -201728.8132785602\n",
      "      - -199531.92491412617\n",
      "      - -203299.68236951937\n",
      "      - -202023.62688982437\n",
      "      - -201856.44946057495\n",
      "      - -201100.8194792398\n",
      "      - -198305.27615232609\n",
      "      - -195662.23861087032\n",
      "      - -204848.4816478931\n",
      "      - -200314.256764425\n",
      "      - -197750.114687908\n",
      "      - -198726.89360390208\n",
      "      - -200576.88630294724\n",
      "      - -201488.00999408506\n",
      "      - -201070.310892678\n",
      "      - -204501.93015190758\n",
      "      - -201515.03011493015\n",
      "      - -202225.9462673758\n",
      "      - -199521.86829957052\n",
      "      - -200545.9008745195\n",
      "      - -198619.24377535286\n",
      "      - -201807.0820788849\n",
      "      - -201242.6767995378\n",
      "      - -199734.13523962308\n",
      "      - -200432.14074054704\n",
      "      - -202195.44756448673\n",
      "      - -198698.8706047258\n",
      "      - -198853.90779262918\n",
      "      - -198028.53127101262\n",
      "      - -200748.41646065787\n",
      "      - -204327.06037819956\n",
      "      - -204271.82696106262\n",
      "      - -202099.9304436262\n",
      "      - -199280.8217161452\n",
      "      - -203512.99484756382\n",
      "      - -198991.4324961568\n",
      "      - -201906.45272635596\n",
      "      - -202616.0096090409\n",
      "      - -201891.0393818057\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09487267656263804\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.469131328183223\n",
      "      mean_inference_ms: 0.9668402871785904\n",
      "      mean_raw_obs_processing_ms: 0.13492757167090028\n",
      "  time_since_restore: 1264.1756489276886\n",
      "  time_this_iter_s: 9.337194919586182\n",
      "  time_total_s: 1264.1756489276886\n",
      "  timers:\n",
      "    learn_throughput: 129976.087\n",
      "    learn_time_ms: 492.275\n",
      "    load_throughput: 22011478.415\n",
      "    load_time_ms: 2.907\n",
      "    training_iteration_time_ms: 9402.881\n",
      "    update_time_ms: 4.105\n",
      "  timestamp: 1665850012\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8445888\n",
      "  training_iteration: 132\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:06:57 (running for 00:21:31.80)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   132</td><td style=\"text-align: right;\">         1264.18</td><td style=\"text-align: right;\">8445888</td><td style=\"text-align: right;\"> -200746</td><td style=\"text-align: right;\">             -195213</td><td style=\"text-align: right;\">             -205697</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 8509872\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 8509872\n",
      "    num_agent_steps_trained: 8509872\n",
      "    num_env_steps_sampled: 8509872\n",
      "    num_env_steps_trained: 8509872\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-07-01\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -197209.6642898574\n",
      "  episode_reward_mean: -200672.2312810637\n",
      "  episode_reward_min: -217947.42799727025\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 8508\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1527223587036133\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00038828811375424266\n",
      "          model: {}\n",
      "          policy_loss: 0.0029910423327237368\n",
      "          total_loss: 10.002753257751465\n",
      "          vf_explained_var: -2.7437058847112894e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 8509872\n",
      "    num_agent_steps_trained: 8509872\n",
      "    num_env_steps_sampled: 8509872\n",
      "    num_env_steps_trained: 8509872\n",
      "  iterations_since_restore: 133\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 8509872\n",
      "  num_agent_steps_trained: 8509872\n",
      "  num_env_steps_sampled: 8509872\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 8509872\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.72307692307692\n",
      "    ram_util_percent: 87.0\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.094831016099598\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4690532511762371\n",
      "    mean_inference_ms: 0.966713556377115\n",
      "    mean_raw_obs_processing_ms: 0.13475112519536384\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -197209.6642898574\n",
      "    episode_reward_mean: -200672.2312810637\n",
      "    episode_reward_min: -217947.42799727025\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -198726.89360390208\n",
      "      - -200576.88630294724\n",
      "      - -201488.00999408506\n",
      "      - -201070.310892678\n",
      "      - -204501.93015190758\n",
      "      - -201515.03011493015\n",
      "      - -202225.9462673758\n",
      "      - -199521.86829957052\n",
      "      - -200545.9008745195\n",
      "      - -198619.24377535286\n",
      "      - -201807.0820788849\n",
      "      - -201242.6767995378\n",
      "      - -199734.13523962308\n",
      "      - -200432.14074054704\n",
      "      - -202195.44756448673\n",
      "      - -198698.8706047258\n",
      "      - -198853.90779262918\n",
      "      - -198028.53127101262\n",
      "      - -200748.41646065787\n",
      "      - -204327.06037819956\n",
      "      - -204271.82696106262\n",
      "      - -202099.9304436262\n",
      "      - -199280.8217161452\n",
      "      - -203512.99484756382\n",
      "      - -198991.4324961568\n",
      "      - -201906.45272635596\n",
      "      - -202616.0096090409\n",
      "      - -201891.0393818057\n",
      "      - -202473.41170296553\n",
      "      - -200295.47285812563\n",
      "      - -198569.94015462033\n",
      "      - -199528.91126740677\n",
      "      - -199851.0624734121\n",
      "      - -197462.63520416495\n",
      "      - -200508.93328774505\n",
      "      - -200579.89602609133\n",
      "      - -200784.5691129339\n",
      "      - -199855.6155353679\n",
      "      - -199624.53389073652\n",
      "      - -198705.2062031034\n",
      "      - -198862.61231355162\n",
      "      - -198990.86849491225\n",
      "      - -203600.69049932162\n",
      "      - -202959.78395248673\n",
      "      - -200504.44141303052\n",
      "      - -199217.48925158515\n",
      "      - -200603.76954096026\n",
      "      - -200069.8316215295\n",
      "      - -200764.6887204434\n",
      "      - -201004.2714367545\n",
      "      - -198285.4625655841\n",
      "      - -204003.46593323923\n",
      "      - -198854.55139427102\n",
      "      - -202844.122138227\n",
      "      - -199807.10717789395\n",
      "      - -198358.3963115393\n",
      "      - -198835.77407003538\n",
      "      - -201623.93776719866\n",
      "      - -202816.78935240378\n",
      "      - -203091.4704428481\n",
      "      - -199887.79736937865\n",
      "      - -197223.00571799156\n",
      "      - -199906.32206432472\n",
      "      - -200110.47514482876\n",
      "      - -198020.57380454315\n",
      "      - -201534.35975159475\n",
      "      - -217947.42799727025\n",
      "      - -200226.0740268591\n",
      "      - -200195.28987742434\n",
      "      - -197490.62995470245\n",
      "      - -201442.87413702256\n",
      "      - -201825.33036030192\n",
      "      - -199912.64117062124\n",
      "      - -202360.69125080112\n",
      "      - -200540.86537512156\n",
      "      - -197912.39400718428\n",
      "      - -198014.6567777236\n",
      "      - -199877.4518681288\n",
      "      - -202783.26747806006\n",
      "      - -199371.8100203894\n",
      "      - -198119.4188268285\n",
      "      - -198844.0419205509\n",
      "      - -199224.4631313736\n",
      "      - -200159.3696997661\n",
      "      - -202026.81174298874\n",
      "      - -203354.59897993796\n",
      "      - -198860.4598772055\n",
      "      - -202562.6134875285\n",
      "      - -201154.38615731618\n",
      "      - -201116.0614265864\n",
      "      - -201302.26627304347\n",
      "      - -200915.5788336786\n",
      "      - -201195.00764503158\n",
      "      - -199816.9706730498\n",
      "      - -199491.72178320095\n",
      "      - -200406.59191485203\n",
      "      - -201095.03386461406\n",
      "      - -197209.6642898574\n",
      "      - -202823.61483949184\n",
      "      - -198190.0050813773\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.094831016099598\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4690532511762371\n",
      "      mean_inference_ms: 0.966713556377115\n",
      "      mean_raw_obs_processing_ms: 0.13475112519536384\n",
      "  time_since_restore: 1273.7128932476044\n",
      "  time_this_iter_s: 9.537244319915771\n",
      "  time_total_s: 1273.7128932476044\n",
      "  timers:\n",
      "    learn_throughput: 129933.119\n",
      "    learn_time_ms: 492.438\n",
      "    load_throughput: 21917997.675\n",
      "    load_time_ms: 2.919\n",
      "    training_iteration_time_ms: 9340.51\n",
      "    update_time_ms: 4.175\n",
      "  timestamp: 1665850021\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8509872\n",
      "  training_iteration: 133\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:07:06 (running for 00:21:41.36)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   133</td><td style=\"text-align: right;\">         1273.71</td><td style=\"text-align: right;\">8509872</td><td style=\"text-align: right;\"> -200672</td><td style=\"text-align: right;\">             -197210</td><td style=\"text-align: right;\">             -217947</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 8573856\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 8573856\n",
      "    num_agent_steps_trained: 8573856\n",
      "    num_env_steps_sampled: 8573856\n",
      "    num_env_steps_trained: 8573856\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-07-11\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -196616.44221502315\n",
      "  episode_reward_mean: -200597.50351694372\n",
      "  episode_reward_min: -217947.42799727025\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 8568\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.152390480041504\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0004828451492357999\n",
      "          model: {}\n",
      "          policy_loss: 0.006824715994298458\n",
      "          total_loss: 10.006606101989746\n",
      "          vf_explained_var: -5.487411769422579e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 8573856\n",
      "    num_agent_steps_trained: 8573856\n",
      "    num_env_steps_sampled: 8573856\n",
      "    num_env_steps_trained: 8573856\n",
      "  iterations_since_restore: 134\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 8573856\n",
      "  num_agent_steps_trained: 8573856\n",
      "  num_env_steps_sampled: 8573856\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 8573856\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.65384615384617\n",
      "    ram_util_percent: 87.0\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09486644637924367\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46892653944514984\n",
      "    mean_inference_ms: 0.9667259842065856\n",
      "    mean_raw_obs_processing_ms: 0.13489541073844824\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -196616.44221502315\n",
      "    episode_reward_mean: -200597.50351694372\n",
      "    episode_reward_min: -217947.42799727025\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -199887.79736937865\n",
      "      - -197223.00571799156\n",
      "      - -199906.32206432472\n",
      "      - -200110.47514482876\n",
      "      - -198020.57380454315\n",
      "      - -201534.35975159475\n",
      "      - -217947.42799727025\n",
      "      - -200226.0740268591\n",
      "      - -200195.28987742434\n",
      "      - -197490.62995470245\n",
      "      - -201442.87413702256\n",
      "      - -201825.33036030192\n",
      "      - -199912.64117062124\n",
      "      - -202360.69125080112\n",
      "      - -200540.86537512156\n",
      "      - -197912.39400718428\n",
      "      - -198014.6567777236\n",
      "      - -199877.4518681288\n",
      "      - -202783.26747806006\n",
      "      - -199371.8100203894\n",
      "      - -198119.4188268285\n",
      "      - -198844.0419205509\n",
      "      - -199224.4631313736\n",
      "      - -200159.3696997661\n",
      "      - -202026.81174298874\n",
      "      - -203354.59897993796\n",
      "      - -198860.4598772055\n",
      "      - -202562.6134875285\n",
      "      - -201154.38615731618\n",
      "      - -201116.0614265864\n",
      "      - -201302.26627304347\n",
      "      - -200915.5788336786\n",
      "      - -201195.00764503158\n",
      "      - -199816.9706730498\n",
      "      - -199491.72178320095\n",
      "      - -200406.59191485203\n",
      "      - -201095.03386461406\n",
      "      - -197209.6642898574\n",
      "      - -202823.61483949184\n",
      "      - -198190.0050813773\n",
      "      - -200231.90176611012\n",
      "      - -199414.07863090586\n",
      "      - -202458.9435398699\n",
      "      - -198801.07883596155\n",
      "      - -200436.11247822965\n",
      "      - -196921.49799889504\n",
      "      - -202006.3187540641\n",
      "      - -202064.61644345775\n",
      "      - -200709.85884797812\n",
      "      - -199961.6506543618\n",
      "      - -201208.51543388638\n",
      "      - -198446.04209045751\n",
      "      - -200750.15638974463\n",
      "      - -200737.0946062674\n",
      "      - -205237.66442237733\n",
      "      - -201359.10939662572\n",
      "      - -201840.4752858768\n",
      "      - -199133.04803199967\n",
      "      - -198451.18011739646\n",
      "      - -206262.60742482595\n",
      "      - -200769.49879547468\n",
      "      - -199463.7161599573\n",
      "      - -201678.43612001115\n",
      "      - -199066.34517766672\n",
      "      - -201140.8061726229\n",
      "      - -198747.93764704853\n",
      "      - -203629.4074689407\n",
      "      - -200785.89362172424\n",
      "      - -197154.37995079887\n",
      "      - -200150.92434730486\n",
      "      - -200809.12120650834\n",
      "      - -196616.44221502315\n",
      "      - -201554.1493658033\n",
      "      - -203777.5549913981\n",
      "      - -198848.32028590832\n",
      "      - -200727.84751943164\n",
      "      - -199868.4571698632\n",
      "      - -200015.73387400626\n",
      "      - -201442.75646109282\n",
      "      - -198973.31197901\n",
      "      - -200472.4955618608\n",
      "      - -203459.62743880978\n",
      "      - -200749.34993545787\n",
      "      - -199300.68326245234\n",
      "      - -201403.11870885937\n",
      "      - -201632.17761050366\n",
      "      - -200924.57948452278\n",
      "      - -202607.5477036784\n",
      "      - -200235.694083144\n",
      "      - -201446.6476387125\n",
      "      - -201923.76981176878\n",
      "      - -199272.4365128222\n",
      "      - -201845.73164218196\n",
      "      - -199435.05211879438\n",
      "      - -202321.76427922782\n",
      "      - -200201.77478957112\n",
      "      - -197510.8615995233\n",
      "      - -199704.09206580758\n",
      "      - -199779.92911564608\n",
      "      - -199417.40804958745\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09486644637924367\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46892653944514984\n",
      "      mean_inference_ms: 0.9667259842065856\n",
      "      mean_raw_obs_processing_ms: 0.13489541073844824\n",
      "  time_since_restore: 1283.086939573288\n",
      "  time_this_iter_s: 9.374046325683594\n",
      "  time_total_s: 1283.086939573288\n",
      "  timers:\n",
      "    learn_throughput: 128835.59\n",
      "    learn_time_ms: 496.633\n",
      "    load_throughput: 21992358.077\n",
      "    load_time_ms: 2.909\n",
      "    training_iteration_time_ms: 9321.579\n",
      "    update_time_ms: 4.087\n",
      "  timestamp: 1665850031\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8573856\n",
      "  training_iteration: 134\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:07:16 (running for 00:21:50.62)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   134</td><td style=\"text-align: right;\">         1283.09</td><td style=\"text-align: right;\">8573856</td><td style=\"text-align: right;\"> -200598</td><td style=\"text-align: right;\">             -196616</td><td style=\"text-align: right;\">             -217947</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 8637840\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 8637840\n",
      "    num_agent_steps_trained: 8637840\n",
      "    num_env_steps_sampled: 8637840\n",
      "    num_env_steps_trained: 8637840\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-07-20\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -196616.44221502315\n",
      "  episode_reward_mean: -200832.56751469194\n",
      "  episode_reward_min: -221895.3981939953\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 8628\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1501972675323486\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0007326400955207646\n",
      "          model: {}\n",
      "          policy_loss: 0.0037965287920087576\n",
      "          total_loss: 10.00362777709961\n",
      "          vf_explained_var: -3.879032561826534e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 8637840\n",
      "    num_agent_steps_trained: 8637840\n",
      "    num_env_steps_sampled: 8637840\n",
      "    num_env_steps_trained: 8637840\n",
      "  iterations_since_restore: 135\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 8637840\n",
      "  num_agent_steps_trained: 8637840\n",
      "  num_env_steps_sampled: 8637840\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 8637840\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.02307692307691\n",
      "    ram_util_percent: 87.0\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09478678271627868\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.468952752095691\n",
      "    mean_inference_ms: 0.9665394880653843\n",
      "    mean_raw_obs_processing_ms: 0.13485550580688357\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -196616.44221502315\n",
      "    episode_reward_mean: -200832.56751469194\n",
      "    episode_reward_min: -221895.3981939953\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -200769.49879547468\n",
      "      - -199463.7161599573\n",
      "      - -201678.43612001115\n",
      "      - -199066.34517766672\n",
      "      - -201140.8061726229\n",
      "      - -198747.93764704853\n",
      "      - -203629.4074689407\n",
      "      - -200785.89362172424\n",
      "      - -197154.37995079887\n",
      "      - -200150.92434730486\n",
      "      - -200809.12120650834\n",
      "      - -196616.44221502315\n",
      "      - -201554.1493658033\n",
      "      - -203777.5549913981\n",
      "      - -198848.32028590832\n",
      "      - -200727.84751943164\n",
      "      - -199868.4571698632\n",
      "      - -200015.73387400626\n",
      "      - -201442.75646109282\n",
      "      - -198973.31197901\n",
      "      - -200472.4955618608\n",
      "      - -203459.62743880978\n",
      "      - -200749.34993545787\n",
      "      - -199300.68326245234\n",
      "      - -201403.11870885937\n",
      "      - -201632.17761050366\n",
      "      - -200924.57948452278\n",
      "      - -202607.5477036784\n",
      "      - -200235.694083144\n",
      "      - -201446.6476387125\n",
      "      - -201923.76981176878\n",
      "      - -199272.4365128222\n",
      "      - -201845.73164218196\n",
      "      - -199435.05211879438\n",
      "      - -202321.76427922782\n",
      "      - -200201.77478957112\n",
      "      - -197510.8615995233\n",
      "      - -199704.09206580758\n",
      "      - -199779.92911564608\n",
      "      - -199417.40804958745\n",
      "      - -202800.8724414751\n",
      "      - -201276.75928205237\n",
      "      - -199079.31076439298\n",
      "      - -202101.92495066597\n",
      "      - -201338.40897718034\n",
      "      - -201123.4322756439\n",
      "      - -200751.10206254697\n",
      "      - -198906.1388884221\n",
      "      - -198509.39752187024\n",
      "      - -197856.62202491547\n",
      "      - -201222.6836099653\n",
      "      - -201862.5980809027\n",
      "      - -201355.8624811786\n",
      "      - -202952.90679837725\n",
      "      - -201232.25902210522\n",
      "      - -198794.29159335012\n",
      "      - -200693.98355910802\n",
      "      - -199179.01807277813\n",
      "      - -201353.3005704208\n",
      "      - -202395.54717671667\n",
      "      - -199278.12609882074\n",
      "      - -197861.68827288918\n",
      "      - -201372.2612097971\n",
      "      - -196856.40318410154\n",
      "      - -201715.6303272546\n",
      "      - -200842.10783231392\n",
      "      - -200860.12507546286\n",
      "      - -201731.25240092087\n",
      "      - -221895.3981939953\n",
      "      - -199786.08787874834\n",
      "      - -202304.40650959974\n",
      "      - -197569.45826508585\n",
      "      - -203186.65863910265\n",
      "      - -200730.8155385641\n",
      "      - -200668.87093575875\n",
      "      - -201192.59584461316\n",
      "      - -200489.59925776173\n",
      "      - -202618.20610677567\n",
      "      - -203270.56279967935\n",
      "      - -203267.45052690286\n",
      "      - -198039.79917397848\n",
      "      - -199797.76752719507\n",
      "      - -202075.72234852865\n",
      "      - -200620.23821086017\n",
      "      - -197058.4402011282\n",
      "      - -202019.23847403607\n",
      "      - -200760.8054982739\n",
      "      - -199025.36556939292\n",
      "      - -199364.3867849309\n",
      "      - -198282.88922428666\n",
      "      - -201238.28378456118\n",
      "      - -202845.59840242853\n",
      "      - -201883.61259104952\n",
      "      - -198811.73037676973\n",
      "      - -202203.56356277782\n",
      "      - -202238.52819236455\n",
      "      - -201535.62536927845\n",
      "      - -196880.42898973546\n",
      "      - -204769.69155375686\n",
      "      - -202655.12863912145\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09478678271627868\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.468952752095691\n",
      "      mean_inference_ms: 0.9665394880653843\n",
      "      mean_raw_obs_processing_ms: 0.13485550580688357\n",
      "  time_since_restore: 1292.451452255249\n",
      "  time_this_iter_s: 9.36451268196106\n",
      "  time_total_s: 1292.451452255249\n",
      "  timers:\n",
      "    learn_throughput: 128514.161\n",
      "    learn_time_ms: 497.875\n",
      "    load_throughput: 21593153.353\n",
      "    load_time_ms: 2.963\n",
      "    training_iteration_time_ms: 9309.922\n",
      "    update_time_ms: 4.115\n",
      "  timestamp: 1665850040\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8637840\n",
      "  training_iteration: 135\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:07:25 (running for 00:22:00.09)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   135</td><td style=\"text-align: right;\">         1292.45</td><td style=\"text-align: right;\">8637840</td><td style=\"text-align: right;\"> -200833</td><td style=\"text-align: right;\">             -196616</td><td style=\"text-align: right;\">             -221895</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:07:30 (running for 00:22:05.23)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   135</td><td style=\"text-align: right;\">         1292.45</td><td style=\"text-align: right;\">8637840</td><td style=\"text-align: right;\"> -200833</td><td style=\"text-align: right;\">             -196616</td><td style=\"text-align: right;\">             -221895</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 8701824\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 8701824\n",
      "    num_agent_steps_trained: 8701824\n",
      "    num_env_steps_sampled: 8701824\n",
      "    num_env_steps_trained: 8701824\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-07-31\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -195927.38547142365\n",
      "  episode_reward_mean: -200511.85513266985\n",
      "  episode_reward_min: -206413.76831491597\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 8700\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.147284507751465\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0004614510980900377\n",
      "          model: {}\n",
      "          policy_loss: 0.002076235366985202\n",
      "          total_loss: 10.001852035522461\n",
      "          vf_explained_var: -4.8251379780595016e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 8701824\n",
      "    num_agent_steps_trained: 8701824\n",
      "    num_env_steps_sampled: 8701824\n",
      "    num_env_steps_trained: 8701824\n",
      "  iterations_since_restore: 136\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 8701824\n",
      "  num_agent_steps_trained: 8701824\n",
      "  num_env_steps_sampled: 8701824\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 8701824\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 86.4357142857143\n",
      "    ram_util_percent: 87.00714285714285\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09484033079173787\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46897868085954875\n",
      "    mean_inference_ms: 0.9670248218617413\n",
      "    mean_raw_obs_processing_ms: 0.13470527560070183\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -195927.38547142365\n",
      "    episode_reward_mean: -200511.85513266985\n",
      "    episode_reward_min: -206413.76831491597\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -203186.65863910265\n",
      "      - -200730.8155385641\n",
      "      - -200668.87093575875\n",
      "      - -201192.59584461316\n",
      "      - -200489.59925776173\n",
      "      - -202618.20610677567\n",
      "      - -203270.56279967935\n",
      "      - -203267.45052690286\n",
      "      - -198039.79917397848\n",
      "      - -199797.76752719507\n",
      "      - -202075.72234852865\n",
      "      - -200620.23821086017\n",
      "      - -197058.4402011282\n",
      "      - -202019.23847403607\n",
      "      - -200760.8054982739\n",
      "      - -199025.36556939292\n",
      "      - -199364.3867849309\n",
      "      - -198282.88922428666\n",
      "      - -201238.28378456118\n",
      "      - -202845.59840242853\n",
      "      - -201883.61259104952\n",
      "      - -198811.73037676973\n",
      "      - -202203.56356277782\n",
      "      - -202238.52819236455\n",
      "      - -201535.62536927845\n",
      "      - -196880.42898973546\n",
      "      - -204769.69155375686\n",
      "      - -202655.12863912145\n",
      "      - -200316.92670430074\n",
      "      - -200523.77372197996\n",
      "      - -203110.86451812397\n",
      "      - -197163.61483425304\n",
      "      - -200119.41940554013\n",
      "      - -201982.93963423787\n",
      "      - -198200.9360960503\n",
      "      - -199297.83762981603\n",
      "      - -199252.34676829967\n",
      "      - -197505.9346495823\n",
      "      - -198276.5870732951\n",
      "      - -197320.8246715991\n",
      "      - -202922.55884809748\n",
      "      - -199703.40383623622\n",
      "      - -199292.99993764673\n",
      "      - -205077.05758653855\n",
      "      - -198998.0477032256\n",
      "      - -201242.43356395935\n",
      "      - -199859.85776566336\n",
      "      - -202312.86345408586\n",
      "      - -199534.68707025598\n",
      "      - -200079.7781610116\n",
      "      - -203991.755166539\n",
      "      - -202543.00917412178\n",
      "      - -201417.2790794458\n",
      "      - -205601.71753846208\n",
      "      - -198852.31511836124\n",
      "      - -202176.55356480443\n",
      "      - -200498.22404885234\n",
      "      - -202768.80251155715\n",
      "      - -201342.46428738954\n",
      "      - -202645.77321775712\n",
      "      - -197451.94590729772\n",
      "      - -200720.22274164375\n",
      "      - -199595.69631745276\n",
      "      - -197340.14934251233\n",
      "      - -200832.84107301346\n",
      "      - -200874.8474159313\n",
      "      - -201479.28902822133\n",
      "      - -200533.54154485304\n",
      "      - -198347.71511236666\n",
      "      - -200216.39884999185\n",
      "      - -200482.55146251695\n",
      "      - -201119.8200865465\n",
      "      - -199236.01167221917\n",
      "      - -198970.814640514\n",
      "      - -199122.64756746404\n",
      "      - -200132.00710979375\n",
      "      - -206413.76831491597\n",
      "      - -198968.99229395576\n",
      "      - -200191.80460019186\n",
      "      - -197685.1794517005\n",
      "      - -202352.73643627734\n",
      "      - -202110.11731560252\n",
      "      - -202245.42173571337\n",
      "      - -197151.59554408083\n",
      "      - -200281.6850013752\n",
      "      - -200282.05750787043\n",
      "      - -198901.4215205882\n",
      "      - -195927.38547142365\n",
      "      - -196849.79662202485\n",
      "      - -198489.2330696278\n",
      "      - -198868.40064655736\n",
      "      - -200828.8606434289\n",
      "      - -203545.07685260885\n",
      "      - -198645.2496616105\n",
      "      - -201562.50598614535\n",
      "      - -198288.1337845542\n",
      "      - -202408.40615568467\n",
      "      - -201466.29764641053\n",
      "      - -199236.50419933867\n",
      "      - -200563.19146826168\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09484033079173787\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46897868085954875\n",
      "      mean_inference_ms: 0.9670248218617413\n",
      "      mean_raw_obs_processing_ms: 0.13470527560070183\n",
      "  time_since_restore: 1302.8019802570343\n",
      "  time_this_iter_s: 10.350528001785278\n",
      "  time_total_s: 1302.8019802570343\n",
      "  timers:\n",
      "    learn_throughput: 129528.88\n",
      "    learn_time_ms: 493.975\n",
      "    load_throughput: 21598366.824\n",
      "    load_time_ms: 2.962\n",
      "    training_iteration_time_ms: 9460.486\n",
      "    update_time_ms: 4.185\n",
      "  timestamp: 1665850051\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8701824\n",
      "  training_iteration: 136\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:07:36 (running for 00:22:10.47)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   136</td><td style=\"text-align: right;\">          1302.8</td><td style=\"text-align: right;\">8701824</td><td style=\"text-align: right;\"> -200512</td><td style=\"text-align: right;\">             -195927</td><td style=\"text-align: right;\">             -206414</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 8765808\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 8765808\n",
      "    num_agent_steps_trained: 8765808\n",
      "    num_env_steps_sampled: 8765808\n",
      "    num_env_steps_trained: 8765808\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-07-40\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -195891.13432284424\n",
      "  episode_reward_mean: -200844.1473928474\n",
      "  episode_reward_min: -252776.90730740686\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 8760\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.14870548248291\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00043670920422300696\n",
      "          model: {}\n",
      "          policy_loss: 0.006132058799266815\n",
      "          total_loss: 10.005905151367188\n",
      "          vf_explained_var: -2.4598742598413992e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 8765808\n",
      "    num_agent_steps_trained: 8765808\n",
      "    num_env_steps_sampled: 8765808\n",
      "    num_env_steps_trained: 8765808\n",
      "  iterations_since_restore: 137\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 8765808\n",
      "  num_agent_steps_trained: 8765808\n",
      "  num_env_steps_sampled: 8765808\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 8765808\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.69999999999999\n",
      "    ram_util_percent: 87.18461538461537\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09489829035149064\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4688269337992296\n",
      "    mean_inference_ms: 0.9670451935044032\n",
      "    mean_raw_obs_processing_ms: 0.13487473367642921\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -195891.13432284424\n",
      "    episode_reward_mean: -200844.1473928474\n",
      "    episode_reward_min: -252776.90730740686\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -197451.94590729772\n",
      "      - -200720.22274164375\n",
      "      - -199595.69631745276\n",
      "      - -197340.14934251233\n",
      "      - -200832.84107301346\n",
      "      - -200874.8474159313\n",
      "      - -201479.28902822133\n",
      "      - -200533.54154485304\n",
      "      - -198347.71511236666\n",
      "      - -200216.39884999185\n",
      "      - -200482.55146251695\n",
      "      - -201119.8200865465\n",
      "      - -199236.01167221917\n",
      "      - -198970.814640514\n",
      "      - -199122.64756746404\n",
      "      - -200132.00710979375\n",
      "      - -206413.76831491597\n",
      "      - -198968.99229395576\n",
      "      - -200191.80460019186\n",
      "      - -197685.1794517005\n",
      "      - -202352.73643627734\n",
      "      - -202110.11731560252\n",
      "      - -202245.42173571337\n",
      "      - -197151.59554408083\n",
      "      - -200281.6850013752\n",
      "      - -200282.05750787043\n",
      "      - -198901.4215205882\n",
      "      - -195927.38547142365\n",
      "      - -196849.79662202485\n",
      "      - -198489.2330696278\n",
      "      - -198868.40064655736\n",
      "      - -200828.8606434289\n",
      "      - -203545.07685260885\n",
      "      - -198645.2496616105\n",
      "      - -201562.50598614535\n",
      "      - -198288.1337845542\n",
      "      - -202408.40615568467\n",
      "      - -201466.29764641053\n",
      "      - -199236.50419933867\n",
      "      - -200563.19146826168\n",
      "      - -198059.66308963674\n",
      "      - -202226.688729278\n",
      "      - -200487.99437816202\n",
      "      - -199858.242173847\n",
      "      - -203972.87006199732\n",
      "      - -200193.96147570977\n",
      "      - -196646.4710062743\n",
      "      - -197564.3026009965\n",
      "      - -200385.40136968778\n",
      "      - -205142.59818034046\n",
      "      - -200524.10809049214\n",
      "      - -201452.84660146417\n",
      "      - -200834.8123181564\n",
      "      - -199418.21908462222\n",
      "      - -201591.2349817493\n",
      "      - -198785.3384483956\n",
      "      - -198845.19317362798\n",
      "      - -202301.96911887344\n",
      "      - -197851.80819523984\n",
      "      - -198646.25653668543\n",
      "      - -201392.4693191632\n",
      "      - -199765.30193914092\n",
      "      - -197101.14633157116\n",
      "      - -200864.09827089694\n",
      "      - -204089.9349989653\n",
      "      - -200710.11518080736\n",
      "      - -201419.74474068012\n",
      "      - -200208.30509881637\n",
      "      - -199245.4411407835\n",
      "      - -252776.90730740686\n",
      "      - -197984.60747980623\n",
      "      - -197991.4138741121\n",
      "      - -199566.31935702375\n",
      "      - -205083.3316458899\n",
      "      - -195891.13432284424\n",
      "      - -201666.72634074735\n",
      "      - -199829.90264065462\n",
      "      - -198690.47549948873\n",
      "      - -199478.08455910094\n",
      "      - -199732.38131995875\n",
      "      - -197822.6327298584\n",
      "      - -200730.13179985053\n",
      "      - -197899.4473735889\n",
      "      - -202931.0787103633\n",
      "      - -207457.26180304718\n",
      "      - -202828.64872059994\n",
      "      - -204954.47981793535\n",
      "      - -200482.91090491347\n",
      "      - -199585.03795168083\n",
      "      - -200621.18858411588\n",
      "      - -200827.58752789185\n",
      "      - -198275.65723581196\n",
      "      - -199281.32592226262\n",
      "      - -199805.79717525895\n",
      "      - -200749.5718744397\n",
      "      - -198997.18885367183\n",
      "      - -204418.54560820595\n",
      "      - -203329.42420951684\n",
      "      - -200788.20187419906\n",
      "      - -204630.47782213995\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09489829035149064\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4688269337992296\n",
      "      mean_inference_ms: 0.9670451935044032\n",
      "      mean_raw_obs_processing_ms: 0.13487473367642921\n",
      "  time_since_restore: 1311.9804501533508\n",
      "  time_this_iter_s: 9.178469896316528\n",
      "  time_total_s: 1311.9804501533508\n",
      "  timers:\n",
      "    learn_throughput: 131043.57\n",
      "    learn_time_ms: 488.265\n",
      "    load_throughput: 21395354.264\n",
      "    load_time_ms: 2.991\n",
      "    training_iteration_time_ms: 9454.913\n",
      "    update_time_ms: 4.145\n",
      "  timestamp: 1665850060\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8765808\n",
      "  training_iteration: 137\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:07:45 (running for 00:22:19.83)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   137</td><td style=\"text-align: right;\">         1311.98</td><td style=\"text-align: right;\">8765808</td><td style=\"text-align: right;\"> -200844</td><td style=\"text-align: right;\">             -195891</td><td style=\"text-align: right;\">             -252777</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 8829792\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 8829792\n",
      "    num_agent_steps_trained: 8829792\n",
      "    num_env_steps_sampled: 8829792\n",
      "    num_env_steps_trained: 8829792\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-07-50\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -195891.13432284424\n",
      "  episode_reward_mean: -201134.1605345182\n",
      "  episode_reward_min: -252776.90730740686\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 8820\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1414031982421875\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0006363184656947851\n",
      "          model: {}\n",
      "          policy_loss: 0.003580055432394147\n",
      "          total_loss: 10.003393173217773\n",
      "          vf_explained_var: -1.8922110101016187e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 8829792\n",
      "    num_agent_steps_trained: 8829792\n",
      "    num_env_steps_sampled: 8829792\n",
      "    num_env_steps_trained: 8829792\n",
      "  iterations_since_restore: 138\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 8829792\n",
      "  num_agent_steps_trained: 8829792\n",
      "  num_env_steps_sampled: 8829792\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 8829792\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 86.66428571428573\n",
      "    ram_util_percent: 87.14285714285712\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09484565684614418\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46899554444894986\n",
      "    mean_inference_ms: 0.9671708603570249\n",
      "    mean_raw_obs_processing_ms: 0.13489547436685081\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -195891.13432284424\n",
      "    episode_reward_mean: -201134.1605345182\n",
      "    episode_reward_min: -252776.90730740686\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -201392.4693191632\n",
      "      - -199765.30193914092\n",
      "      - -197101.14633157116\n",
      "      - -200864.09827089694\n",
      "      - -204089.9349989653\n",
      "      - -200710.11518080736\n",
      "      - -201419.74474068012\n",
      "      - -200208.30509881637\n",
      "      - -199245.4411407835\n",
      "      - -252776.90730740686\n",
      "      - -197984.60747980623\n",
      "      - -197991.4138741121\n",
      "      - -199566.31935702375\n",
      "      - -205083.3316458899\n",
      "      - -195891.13432284424\n",
      "      - -201666.72634074735\n",
      "      - -199829.90264065462\n",
      "      - -198690.47549948873\n",
      "      - -199478.08455910094\n",
      "      - -199732.38131995875\n",
      "      - -197822.6327298584\n",
      "      - -200730.13179985053\n",
      "      - -197899.4473735889\n",
      "      - -202931.0787103633\n",
      "      - -207457.26180304718\n",
      "      - -202828.64872059994\n",
      "      - -204954.47981793535\n",
      "      - -200482.91090491347\n",
      "      - -199585.03795168083\n",
      "      - -200621.18858411588\n",
      "      - -200827.58752789185\n",
      "      - -198275.65723581196\n",
      "      - -199281.32592226262\n",
      "      - -199805.79717525895\n",
      "      - -200749.5718744397\n",
      "      - -198997.18885367183\n",
      "      - -204418.54560820595\n",
      "      - -203329.42420951684\n",
      "      - -200788.20187419906\n",
      "      - -204630.47782213995\n",
      "      - -197386.56484893314\n",
      "      - -197957.0938789142\n",
      "      - -197965.767011107\n",
      "      - -196828.09554602852\n",
      "      - -196963.8924192262\n",
      "      - -201394.15302558395\n",
      "      - -201926.28118632338\n",
      "      - -197994.74082269482\n",
      "      - -203956.48031714142\n",
      "      - -208583.65874104132\n",
      "      - -199059.5761470523\n",
      "      - -201024.00414994796\n",
      "      - -197966.6482479411\n",
      "      - -201860.50653606304\n",
      "      - -200222.24391828506\n",
      "      - -203163.78302221748\n",
      "      - -199219.0672865777\n",
      "      - -201871.6632309527\n",
      "      - -200822.05872441776\n",
      "      - -197919.99639229078\n",
      "      - -199151.44050774345\n",
      "      - -203312.01893615985\n",
      "      - -197152.24634243004\n",
      "      - -200518.35798227487\n",
      "      - -199798.21056150884\n",
      "      - -197780.09324078838\n",
      "      - -199785.5361374151\n",
      "      - -201265.6425498855\n",
      "      - -196405.71596222033\n",
      "      - -202227.8741680628\n",
      "      - -197391.4721036207\n",
      "      - -199056.85308468802\n",
      "      - -198334.8291986475\n",
      "      - -199030.89158051205\n",
      "      - -202521.19250882644\n",
      "      - -201992.1544989062\n",
      "      - -196599.26076491803\n",
      "      - -219225.0622931547\n",
      "      - -201970.40222198042\n",
      "      - -199450.52842853995\n",
      "      - -201553.66787589056\n",
      "      - -199452.43841954792\n",
      "      - -206228.3383501482\n",
      "      - -202394.814137251\n",
      "      - -203027.70896622163\n",
      "      - -205067.85039702174\n",
      "      - -208790.84598928146\n",
      "      - -199594.1571207933\n",
      "      - -197198.90821288797\n",
      "      - -200953.13670431232\n",
      "      - -196277.7257777654\n",
      "      - -197942.94949394563\n",
      "      - -199648.7212702966\n",
      "      - -199937.3795396039\n",
      "      - -197821.09962859\n",
      "      - -200366.76123039966\n",
      "      - -202796.91151743804\n",
      "      - -198042.80939185567\n",
      "      - -200591.32146294595\n",
      "      - -198768.01157339066\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09484565684614418\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46899554444894986\n",
      "      mean_inference_ms: 0.9671708603570249\n",
      "      mean_raw_obs_processing_ms: 0.13489547436685081\n",
      "  time_since_restore: 1322.219715833664\n",
      "  time_this_iter_s: 10.23926568031311\n",
      "  time_total_s: 1322.219715833664\n",
      "  timers:\n",
      "    learn_throughput: 130401.487\n",
      "    learn_time_ms: 490.669\n",
      "    load_throughput: 21463801.327\n",
      "    load_time_ms: 2.981\n",
      "    training_iteration_time_ms: 9550.772\n",
      "    update_time_ms: 4.119\n",
      "  timestamp: 1665850070\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8829792\n",
      "  training_iteration: 138\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:07:50 (running for 00:22:24.95)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   138</td><td style=\"text-align: right;\">         1322.22</td><td style=\"text-align: right;\">8829792</td><td style=\"text-align: right;\"> -201134</td><td style=\"text-align: right;\">             -195891</td><td style=\"text-align: right;\">             -252777</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:07:55 (running for 00:22:30.10)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   138</td><td style=\"text-align: right;\">         1322.22</td><td style=\"text-align: right;\">8829792</td><td style=\"text-align: right;\"> -201134</td><td style=\"text-align: right;\">             -195891</td><td style=\"text-align: right;\">             -252777</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 8893776\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 8893776\n",
      "    num_agent_steps_trained: 8893776\n",
      "    num_env_steps_sampled: 8893776\n",
      "    num_env_steps_trained: 8893776\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-08-00\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -196277.7257777654\n",
      "  episode_reward_mean: -200592.51555640966\n",
      "  episode_reward_min: -219225.0622931547\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 8892\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1418352127075195\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0005130615318194032\n",
      "          model: {}\n",
      "          policy_loss: 0.0025880271568894386\n",
      "          total_loss: 10.002375602722168\n",
      "          vf_explained_var: -5.298190686175985e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 8893776\n",
      "    num_agent_steps_trained: 8893776\n",
      "    num_env_steps_sampled: 8893776\n",
      "    num_env_steps_trained: 8893776\n",
      "  iterations_since_restore: 139\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 8893776\n",
      "  num_agent_steps_trained: 8893776\n",
      "  num_env_steps_sampled: 8893776\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 8893776\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.67857142857142\n",
      "    ram_util_percent: 87.04285714285716\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09486076021161034\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46894896948935316\n",
      "    mean_inference_ms: 0.9671764363643787\n",
      "    mean_raw_obs_processing_ms: 0.13477213799848647\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -196277.7257777654\n",
      "    episode_reward_mean: -200592.51555640966\n",
      "    episode_reward_min: -219225.0622931547\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -198334.8291986475\n",
      "      - -199030.89158051205\n",
      "      - -202521.19250882644\n",
      "      - -201992.1544989062\n",
      "      - -196599.26076491803\n",
      "      - -219225.0622931547\n",
      "      - -201970.40222198042\n",
      "      - -199450.52842853995\n",
      "      - -201553.66787589056\n",
      "      - -199452.43841954792\n",
      "      - -206228.3383501482\n",
      "      - -202394.814137251\n",
      "      - -203027.70896622163\n",
      "      - -205067.85039702174\n",
      "      - -208790.84598928146\n",
      "      - -199594.1571207933\n",
      "      - -197198.90821288797\n",
      "      - -200953.13670431232\n",
      "      - -196277.7257777654\n",
      "      - -197942.94949394563\n",
      "      - -199648.7212702966\n",
      "      - -199937.3795396039\n",
      "      - -197821.09962859\n",
      "      - -200366.76123039966\n",
      "      - -202796.91151743804\n",
      "      - -198042.80939185567\n",
      "      - -200591.32146294595\n",
      "      - -198768.01157339066\n",
      "      - -199310.9830381102\n",
      "      - -199049.9322079377\n",
      "      - -197629.481378104\n",
      "      - -199309.1752192957\n",
      "      - -201595.97696899655\n",
      "      - -199850.0972219985\n",
      "      - -198590.1714818418\n",
      "      - -201084.06510135136\n",
      "      - -202359.57175741898\n",
      "      - -199643.15794679784\n",
      "      - -201962.55124957048\n",
      "      - -200836.56023545173\n",
      "      - -198316.85690141408\n",
      "      - -203949.26034110147\n",
      "      - -199238.03844250328\n",
      "      - -198304.6373402633\n",
      "      - -198057.32511522123\n",
      "      - -201948.71928184232\n",
      "      - -197077.1249884288\n",
      "      - -201666.92232186813\n",
      "      - -200991.97017880355\n",
      "      - -201214.81689557194\n",
      "      - -198912.33725611432\n",
      "      - -201594.6143541448\n",
      "      - -201760.67436987144\n",
      "      - -201022.24114608517\n",
      "      - -200287.82702678672\n",
      "      - -199929.03180875338\n",
      "      - -198448.4402335664\n",
      "      - -202272.14520152585\n",
      "      - -200617.62496050805\n",
      "      - -198531.48614493976\n",
      "      - -200064.1134558428\n",
      "      - -203662.28052763906\n",
      "      - -200550.40575530677\n",
      "      - -199272.08152484696\n",
      "      - -201198.66055974798\n",
      "      - -198994.0115978578\n",
      "      - -198469.41756256815\n",
      "      - -199114.92410667922\n",
      "      - -201826.55798893914\n",
      "      - -200250.17775623835\n",
      "      - -201353.17480900828\n",
      "      - -197684.04658156692\n",
      "      - -200525.31945099196\n",
      "      - -201484.10867094033\n",
      "      - -202441.76097296752\n",
      "      - -200611.3813040713\n",
      "      - -202078.4417292904\n",
      "      - -205545.54049036646\n",
      "      - -200326.73667452735\n",
      "      - -199539.63410004726\n",
      "      - -200472.60043181604\n",
      "      - -199094.35849434856\n",
      "      - -199892.60439012162\n",
      "      - -201283.93175447694\n",
      "      - -201529.81724463496\n",
      "      - -200546.2557350294\n",
      "      - -200900.1170620894\n",
      "      - -201586.09110839272\n",
      "      - -199196.77230332352\n",
      "      - -199547.13163348055\n",
      "      - -197380.24793269747\n",
      "      - -200443.7431845981\n",
      "      - -199461.1286597295\n",
      "      - -201022.56397639704\n",
      "      - -201537.98404179537\n",
      "      - -200683.10355674996\n",
      "      - -201473.15927317506\n",
      "      - -199147.12190692982\n",
      "      - -198545.49684794628\n",
      "      - -199570.8538125311\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09486076021161034\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46894896948935316\n",
      "      mean_inference_ms: 0.9671764363643787\n",
      "      mean_raw_obs_processing_ms: 0.13477213799848647\n",
      "  time_since_restore: 1331.9206869602203\n",
      "  time_this_iter_s: 9.700971126556396\n",
      "  time_total_s: 1331.9206869602203\n",
      "  timers:\n",
      "    learn_throughput: 121228.151\n",
      "    learn_time_ms: 527.798\n",
      "    load_throughput: 21631095.315\n",
      "    load_time_ms: 2.958\n",
      "    training_iteration_time_ms: 9577.322\n",
      "    update_time_ms: 4.065\n",
      "  timestamp: 1665850080\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8893776\n",
      "  training_iteration: 139\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:08:05 (running for 00:22:39.68)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   139</td><td style=\"text-align: right;\">         1331.92</td><td style=\"text-align: right;\">8893776</td><td style=\"text-align: right;\"> -200593</td><td style=\"text-align: right;\">             -196278</td><td style=\"text-align: right;\">             -219225</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 8957760\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 8957760\n",
      "    num_agent_steps_trained: 8957760\n",
      "    num_env_steps_sampled: 8957760\n",
      "    num_env_steps_trained: 8957760\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-08-09\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -196558.92419581383\n",
      "  episode_reward_mean: -201331.9025039508\n",
      "  episode_reward_min: -249342.57784109356\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 8952\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.138327121734619\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0009994362480938435\n",
      "          model: {}\n",
      "          policy_loss: 0.0070093730464577675\n",
      "          total_loss: 10.006895065307617\n",
      "          vf_explained_var: -4.8251379780595016e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 8957760\n",
      "    num_agent_steps_trained: 8957760\n",
      "    num_env_steps_sampled: 8957760\n",
      "    num_env_steps_trained: 8957760\n",
      "  iterations_since_restore: 140\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 8957760\n",
      "  num_agent_steps_trained: 8957760\n",
      "  num_env_steps_sampled: 8957760\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 8957760\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.89230769230768\n",
      "    ram_util_percent: 87.0\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09489076207917031\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46879116662914677\n",
      "    mean_inference_ms: 0.9667832386432551\n",
      "    mean_raw_obs_processing_ms: 0.13491851411737346\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -196558.92419581383\n",
      "    episode_reward_mean: -201331.9025039508\n",
      "    episode_reward_min: -249342.57784109356\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -200064.1134558428\n",
      "      - -203662.28052763906\n",
      "      - -200550.40575530677\n",
      "      - -199272.08152484696\n",
      "      - -201198.66055974798\n",
      "      - -198994.0115978578\n",
      "      - -198469.41756256815\n",
      "      - -199114.92410667922\n",
      "      - -201826.55798893914\n",
      "      - -200250.17775623835\n",
      "      - -201353.17480900828\n",
      "      - -197684.04658156692\n",
      "      - -200525.31945099196\n",
      "      - -201484.10867094033\n",
      "      - -202441.76097296752\n",
      "      - -200611.3813040713\n",
      "      - -202078.4417292904\n",
      "      - -205545.54049036646\n",
      "      - -200326.73667452735\n",
      "      - -199539.63410004726\n",
      "      - -200472.60043181604\n",
      "      - -199094.35849434856\n",
      "      - -199892.60439012162\n",
      "      - -201283.93175447694\n",
      "      - -201529.81724463496\n",
      "      - -200546.2557350294\n",
      "      - -200900.1170620894\n",
      "      - -201586.09110839272\n",
      "      - -199196.77230332352\n",
      "      - -199547.13163348055\n",
      "      - -197380.24793269747\n",
      "      - -200443.7431845981\n",
      "      - -199461.1286597295\n",
      "      - -201022.56397639704\n",
      "      - -201537.98404179537\n",
      "      - -200683.10355674996\n",
      "      - -201473.15927317506\n",
      "      - -199147.12190692982\n",
      "      - -198545.49684794628\n",
      "      - -199570.8538125311\n",
      "      - -201235.64908631486\n",
      "      - -200754.68355244776\n",
      "      - -201104.70796612708\n",
      "      - -199430.19043116356\n",
      "      - -200270.26067039487\n",
      "      - -200929.0185824186\n",
      "      - -201342.67688731744\n",
      "      - -199129.19792056884\n",
      "      - -199793.89274518212\n",
      "      - -199363.42101359795\n",
      "      - -200331.76690197134\n",
      "      - -201103.18168109102\n",
      "      - -249342.57784109356\n",
      "      - -243717.58617609664\n",
      "      - -201348.05124209862\n",
      "      - -201972.6728704329\n",
      "      - -198623.65730491132\n",
      "      - -200070.80662650472\n",
      "      - -205263.02280231513\n",
      "      - -198854.6980860302\n",
      "      - -199159.47817476775\n",
      "      - -199257.5082045865\n",
      "      - -197723.37653745088\n",
      "      - -197981.52532534808\n",
      "      - -197004.4665460582\n",
      "      - -200769.52032384806\n",
      "      - -197709.7895596175\n",
      "      - -198879.1805118708\n",
      "      - -199903.3299075771\n",
      "      - -201663.0351974587\n",
      "      - -197418.2067190343\n",
      "      - -198928.24484572388\n",
      "      - -197782.9979672107\n",
      "      - -202603.1041148336\n",
      "      - -199080.29981949873\n",
      "      - -201972.2439773226\n",
      "      - -200587.2566045512\n",
      "      - -213006.4778113546\n",
      "      - -203396.03558337234\n",
      "      - -199745.3540769722\n",
      "      - -202890.34525617727\n",
      "      - -200404.0888215023\n",
      "      - -202148.9742361333\n",
      "      - -197876.57763120983\n",
      "      - -201892.62723982835\n",
      "      - -201474.61753470553\n",
      "      - -201783.32469204176\n",
      "      - -199609.1207955249\n",
      "      - -199122.1596250402\n",
      "      - -202619.3527261154\n",
      "      - -196558.92419581383\n",
      "      - -199705.9795659393\n",
      "      - -197593.81957630083\n",
      "      - -203618.36634544696\n",
      "      - -199052.76309888173\n",
      "      - -201810.27264600946\n",
      "      - -198294.2048070161\n",
      "      - -201385.95245695225\n",
      "      - -198862.1830664672\n",
      "      - -199625.584911732\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09489076207917031\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46879116662914677\n",
      "      mean_inference_ms: 0.9667832386432551\n",
      "      mean_raw_obs_processing_ms: 0.13491851411737346\n",
      "  time_since_restore: 1340.8028645515442\n",
      "  time_this_iter_s: 8.882177591323853\n",
      "  time_total_s: 1340.8028645515442\n",
      "  timers:\n",
      "    learn_throughput: 121923.902\n",
      "    learn_time_ms: 524.786\n",
      "    load_throughput: 21710014.734\n",
      "    load_time_ms: 2.947\n",
      "    training_iteration_time_ms: 9537.654\n",
      "    update_time_ms: 4.066\n",
      "  timestamp: 1665850089\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8957760\n",
      "  training_iteration: 140\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:08:14 (running for 00:22:48.68)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   140</td><td style=\"text-align: right;\">          1340.8</td><td style=\"text-align: right;\">8957760</td><td style=\"text-align: right;\"> -201332</td><td style=\"text-align: right;\">             -196559</td><td style=\"text-align: right;\">             -249343</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 9021744\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 9021744\n",
      "    num_agent_steps_trained: 9021744\n",
      "    num_env_steps_sampled: 9021744\n",
      "    num_env_steps_trained: 9021744\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-08-18\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -196558.92419581383\n",
      "  episode_reward_mean: -201068.03406029544\n",
      "  episode_reward_min: -253549.05869245704\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 9012\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1382198333740234\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0015086818020790815\n",
      "          model: {}\n",
      "          policy_loss: 0.003853869391605258\n",
      "          total_loss: 10.0038423538208\n",
      "          vf_explained_var: -3.500590395333347e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 9021744\n",
      "    num_agent_steps_trained: 9021744\n",
      "    num_env_steps_sampled: 9021744\n",
      "    num_env_steps_trained: 9021744\n",
      "  iterations_since_restore: 141\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 9021744\n",
      "  num_agent_steps_trained: 9021744\n",
      "  num_env_steps_sampled: 9021744\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 9021744\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 84.07692307692308\n",
      "    ram_util_percent: 87.0\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09480400099072131\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46880781157401485\n",
      "    mean_inference_ms: 0.966412033984252\n",
      "    mean_raw_obs_processing_ms: 0.13486664479446067\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -196558.92419581383\n",
      "    episode_reward_mean: -201068.03406029544\n",
      "    episode_reward_min: -253549.05869245704\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -199159.47817476775\n",
      "      - -199257.5082045865\n",
      "      - -197723.37653745088\n",
      "      - -197981.52532534808\n",
      "      - -197004.4665460582\n",
      "      - -200769.52032384806\n",
      "      - -197709.7895596175\n",
      "      - -198879.1805118708\n",
      "      - -199903.3299075771\n",
      "      - -201663.0351974587\n",
      "      - -197418.2067190343\n",
      "      - -198928.24484572388\n",
      "      - -197782.9979672107\n",
      "      - -202603.1041148336\n",
      "      - -199080.29981949873\n",
      "      - -201972.2439773226\n",
      "      - -200587.2566045512\n",
      "      - -213006.4778113546\n",
      "      - -203396.03558337234\n",
      "      - -199745.3540769722\n",
      "      - -202890.34525617727\n",
      "      - -200404.0888215023\n",
      "      - -202148.9742361333\n",
      "      - -197876.57763120983\n",
      "      - -201892.62723982835\n",
      "      - -201474.61753470553\n",
      "      - -201783.32469204176\n",
      "      - -199609.1207955249\n",
      "      - -199122.1596250402\n",
      "      - -202619.3527261154\n",
      "      - -196558.92419581383\n",
      "      - -199705.9795659393\n",
      "      - -197593.81957630083\n",
      "      - -203618.36634544696\n",
      "      - -199052.76309888173\n",
      "      - -201810.27264600946\n",
      "      - -198294.2048070161\n",
      "      - -201385.95245695225\n",
      "      - -198862.1830664672\n",
      "      - -199625.584911732\n",
      "      - -200282.74963147606\n",
      "      - -200711.98303569556\n",
      "      - -198235.82617296904\n",
      "      - -198587.18530073718\n",
      "      - -200850.12455556242\n",
      "      - -199836.55155594868\n",
      "      - -197987.40250886194\n",
      "      - -199616.45718116104\n",
      "      - -198651.92880595865\n",
      "      - -199965.57943470715\n",
      "      - -201756.30725974077\n",
      "      - -199416.81211283716\n",
      "      - -198343.04818992593\n",
      "      - -200400.25327442365\n",
      "      - -200011.05909776763\n",
      "      - -221834.3268980037\n",
      "      - -197579.46752592997\n",
      "      - -198755.14615529618\n",
      "      - -200257.2269278963\n",
      "      - -202901.3993651729\n",
      "      - -203552.51531918175\n",
      "      - -200647.85661987212\n",
      "      - -199855.74377880406\n",
      "      - -197690.04921251535\n",
      "      - -202721.48319860428\n",
      "      - -199976.7672412811\n",
      "      - -200868.39087422943\n",
      "      - -200673.96069732355\n",
      "      - -202951.88341190276\n",
      "      - -198233.10931221824\n",
      "      - -202644.88378941044\n",
      "      - -200044.97262272242\n",
      "      - -199782.2488470046\n",
      "      - -204029.57998645317\n",
      "      - -202062.7262062363\n",
      "      - -199438.3002834151\n",
      "      - -197285.851378794\n",
      "      - -200906.55963949827\n",
      "      - -196939.89218763242\n",
      "      - -217485.96117642344\n",
      "      - -199213.66980652654\n",
      "      - -199358.08511245647\n",
      "      - -200433.44623213555\n",
      "      - -203181.16492273047\n",
      "      - -200361.41116718945\n",
      "      - -200094.82612221668\n",
      "      - -202783.60282245447\n",
      "      - -202415.1758174451\n",
      "      - -198009.6039411321\n",
      "      - -199085.10552302183\n",
      "      - -199392.35027606538\n",
      "      - -197788.59228342102\n",
      "      - -197515.14444169935\n",
      "      - -200143.7984702702\n",
      "      - -198366.1108821943\n",
      "      - -200024.41025458006\n",
      "      - -253549.05869245704\n",
      "      - -201732.3419800906\n",
      "      - -198372.1364842079\n",
      "      - -200309.1289863597\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09480400099072131\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46880781157401485\n",
      "      mean_inference_ms: 0.966412033984252\n",
      "      mean_raw_obs_processing_ms: 0.13486664479446067\n",
      "  time_since_restore: 1350.1707808971405\n",
      "  time_this_iter_s: 9.367916345596313\n",
      "  time_total_s: 1350.1707808971405\n",
      "  timers:\n",
      "    learn_throughput: 120810.396\n",
      "    learn_time_ms: 529.623\n",
      "    load_throughput: 21549113.294\n",
      "    load_time_ms: 2.969\n",
      "    training_iteration_time_ms: 9526.093\n",
      "    update_time_ms: 4.149\n",
      "  timestamp: 1665850098\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 9021744\n",
      "  training_iteration: 141\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:08:23 (running for 00:22:58.23)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   141</td><td style=\"text-align: right;\">         1350.17</td><td style=\"text-align: right;\">9021744</td><td style=\"text-align: right;\"> -201068</td><td style=\"text-align: right;\">             -196559</td><td style=\"text-align: right;\">             -253549</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 9085728\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 9085728\n",
      "    num_agent_steps_trained: 9085728\n",
      "    num_env_steps_sampled: 9085728\n",
      "    num_env_steps_trained: 9085728\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-08-27\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -195825.43871789193\n",
      "  episode_reward_mean: -201197.22080513652\n",
      "  episode_reward_min: -253549.05869245704\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 9084\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.138425350189209\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0006485298508778214\n",
      "          model: {}\n",
      "          policy_loss: 0.0018385299481451511\n",
      "          total_loss: 10.001653671264648\n",
      "          vf_explained_var: -6.622738357719982e-09\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 9085728\n",
      "    num_agent_steps_trained: 9085728\n",
      "    num_env_steps_sampled: 9085728\n",
      "    num_env_steps_trained: 9085728\n",
      "  iterations_since_restore: 142\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 9085728\n",
      "  num_agent_steps_trained: 9085728\n",
      "  num_env_steps_sampled: 9085728\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 9085728\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.48461538461538\n",
      "    ram_util_percent: 87.0\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09475955475941518\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46855050880675336\n",
      "    mean_inference_ms: 0.966246826667832\n",
      "    mean_raw_obs_processing_ms: 0.13468058399778907\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -195825.43871789193\n",
      "    episode_reward_mean: -201197.22080513652\n",
      "    episode_reward_min: -253549.05869245704\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -199782.2488470046\n",
      "      - -204029.57998645317\n",
      "      - -202062.7262062363\n",
      "      - -199438.3002834151\n",
      "      - -197285.851378794\n",
      "      - -200906.55963949827\n",
      "      - -196939.89218763242\n",
      "      - -217485.96117642344\n",
      "      - -199213.66980652654\n",
      "      - -199358.08511245647\n",
      "      - -200433.44623213555\n",
      "      - -203181.16492273047\n",
      "      - -200361.41116718945\n",
      "      - -200094.82612221668\n",
      "      - -202783.60282245447\n",
      "      - -202415.1758174451\n",
      "      - -198009.6039411321\n",
      "      - -199085.10552302183\n",
      "      - -199392.35027606538\n",
      "      - -197788.59228342102\n",
      "      - -197515.14444169935\n",
      "      - -200143.7984702702\n",
      "      - -198366.1108821943\n",
      "      - -200024.41025458006\n",
      "      - -253549.05869245704\n",
      "      - -201732.3419800906\n",
      "      - -198372.1364842079\n",
      "      - -200309.1289863597\n",
      "      - -197099.68063019015\n",
      "      - -204752.72179591338\n",
      "      - -198904.178980435\n",
      "      - -201452.65408938515\n",
      "      - -213929.11133365807\n",
      "      - -200253.25600820387\n",
      "      - -203723.54562159054\n",
      "      - -199786.50926224646\n",
      "      - -198497.31975815955\n",
      "      - -198845.98622394822\n",
      "      - -198270.2494808259\n",
      "      - -200881.5266893388\n",
      "      - -198602.6469184265\n",
      "      - -199238.6583761123\n",
      "      - -197569.71269384463\n",
      "      - -198893.28985988483\n",
      "      - -201115.01065872473\n",
      "      - -201950.3368353019\n",
      "      - -225964.41250022405\n",
      "      - -196383.85237836005\n",
      "      - -195825.43871789193\n",
      "      - -200060.0872263024\n",
      "      - -198079.12365930944\n",
      "      - -203407.2253117879\n",
      "      - -200277.0480260613\n",
      "      - -198008.24901644982\n",
      "      - -199284.23367029487\n",
      "      - -201890.85693608443\n",
      "      - -203726.47358069487\n",
      "      - -202805.69691962563\n",
      "      - -197574.52784148278\n",
      "      - -197327.1075947131\n",
      "      - -200407.54207009284\n",
      "      - -199236.8969400814\n",
      "      - -197856.90773576067\n",
      "      - -200527.63196698946\n",
      "      - -205242.6508593693\n",
      "      - -202848.2769117112\n",
      "      - -233066.49587865098\n",
      "      - -199952.52035511986\n",
      "      - -201495.26430431305\n",
      "      - -198778.7214854076\n",
      "      - -199127.23196886087\n",
      "      - -198760.79736512847\n",
      "      - -196757.80669814345\n",
      "      - -198809.69837633442\n",
      "      - -198562.98333359126\n",
      "      - -197575.09530535727\n",
      "      - -197900.66939665578\n",
      "      - -197652.03112091235\n",
      "      - -200600.09929407976\n",
      "      - -200721.74342068788\n",
      "      - -202103.44477867504\n",
      "      - -198038.42754876497\n",
      "      - -198871.57414775732\n",
      "      - -200284.572797894\n",
      "      - -199539.10650593496\n",
      "      - -198773.39314203078\n",
      "      - -200663.5363904852\n",
      "      - -198244.72331771292\n",
      "      - -196903.22540691632\n",
      "      - -197354.74079919312\n",
      "      - -198131.21102997518\n",
      "      - -198952.73683278737\n",
      "      - -200237.7795130943\n",
      "      - -200231.7132554506\n",
      "      - -202060.31146092122\n",
      "      - -203656.09918022432\n",
      "      - -199610.59124621804\n",
      "      - -198136.71843128416\n",
      "      - -197778.15168546393\n",
      "      - -199827.94573603463\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09475955475941518\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46855050880675336\n",
      "      mean_inference_ms: 0.966246826667832\n",
      "      mean_raw_obs_processing_ms: 0.13468058399778907\n",
      "  time_since_restore: 1359.3768260478973\n",
      "  time_this_iter_s: 9.206045150756836\n",
      "  time_total_s: 1359.3768260478973\n",
      "  timers:\n",
      "    learn_throughput: 121372.944\n",
      "    learn_time_ms: 527.169\n",
      "    load_throughput: 21671970.665\n",
      "    load_time_ms: 2.952\n",
      "    training_iteration_time_ms: 9513.076\n",
      "    update_time_ms: 4.529\n",
      "  timestamp: 1665850107\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 9085728\n",
      "  training_iteration: 142\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:08:33 (running for 00:23:07.41)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   142</td><td style=\"text-align: right;\">         1359.38</td><td style=\"text-align: right;\">9085728</td><td style=\"text-align: right;\"> -201197</td><td style=\"text-align: right;\">             -195825</td><td style=\"text-align: right;\">             -253549</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 9149712\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 9149712\n",
      "    num_agent_steps_trained: 9149712\n",
      "    num_env_steps_sampled: 9149712\n",
      "    num_env_steps_trained: 9149712\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-08-37\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -195778.00558932457\n",
      "  episode_reward_mean: -200044.8223778415\n",
      "  episode_reward_min: -233066.49587865098\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 9144\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1347544193267822\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0014879789669066668\n",
      "          model: {}\n",
      "          policy_loss: 0.006259610410779715\n",
      "          total_loss: 10.006243705749512\n",
      "          vf_explained_var: -1.6083793852317285e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 9149712\n",
      "    num_agent_steps_trained: 9149712\n",
      "    num_env_steps_sampled: 9149712\n",
      "    num_env_steps_trained: 9149712\n",
      "  iterations_since_restore: 143\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 9149712\n",
      "  num_agent_steps_trained: 9149712\n",
      "  num_env_steps_sampled: 9149712\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 9149712\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.19285714285715\n",
      "    ram_util_percent: 87.0\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09477253286382449\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46836564399324376\n",
      "    mean_inference_ms: 0.9664658451533681\n",
      "    mean_raw_obs_processing_ms: 0.13480070423248905\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -195778.00558932457\n",
      "    episode_reward_mean: -200044.8223778415\n",
      "    episode_reward_min: -233066.49587865098\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -200407.54207009284\n",
      "      - -199236.8969400814\n",
      "      - -197856.90773576067\n",
      "      - -200527.63196698946\n",
      "      - -205242.6508593693\n",
      "      - -202848.2769117112\n",
      "      - -233066.49587865098\n",
      "      - -199952.52035511986\n",
      "      - -201495.26430431305\n",
      "      - -198778.7214854076\n",
      "      - -199127.23196886087\n",
      "      - -198760.79736512847\n",
      "      - -196757.80669814345\n",
      "      - -198809.69837633442\n",
      "      - -198562.98333359126\n",
      "      - -197575.09530535727\n",
      "      - -197900.66939665578\n",
      "      - -197652.03112091235\n",
      "      - -200600.09929407976\n",
      "      - -200721.74342068788\n",
      "      - -202103.44477867504\n",
      "      - -198038.42754876497\n",
      "      - -198871.57414775732\n",
      "      - -200284.572797894\n",
      "      - -199539.10650593496\n",
      "      - -198773.39314203078\n",
      "      - -200663.5363904852\n",
      "      - -198244.72331771292\n",
      "      - -196903.22540691632\n",
      "      - -197354.74079919312\n",
      "      - -198131.21102997518\n",
      "      - -198952.73683278737\n",
      "      - -200237.7795130943\n",
      "      - -200231.7132554506\n",
      "      - -202060.31146092122\n",
      "      - -203656.09918022432\n",
      "      - -199610.59124621804\n",
      "      - -198136.71843128416\n",
      "      - -197778.15168546393\n",
      "      - -199827.94573603463\n",
      "      - -196271.25974143122\n",
      "      - -198215.1393538511\n",
      "      - -197587.04407446002\n",
      "      - -198636.01581384422\n",
      "      - -198412.7860938381\n",
      "      - -198790.55078018326\n",
      "      - -199322.22490133753\n",
      "      - -200119.3970741058\n",
      "      - -202726.6563252297\n",
      "      - -198478.63919625775\n",
      "      - -201466.98354971615\n",
      "      - -201012.66279678667\n",
      "      - -199597.3011133628\n",
      "      - -198259.44709185066\n",
      "      - -202819.90206429604\n",
      "      - -198991.6795388555\n",
      "      - -198471.5412312009\n",
      "      - -204248.10488559067\n",
      "      - -197252.04020989008\n",
      "      - -202863.8577702275\n",
      "      - -201225.5322807202\n",
      "      - -199967.41650315715\n",
      "      - -201614.5779528183\n",
      "      - -198022.81238418297\n",
      "      - -199681.82428368123\n",
      "      - -203802.97958638423\n",
      "      - -202480.03303661154\n",
      "      - -201542.30488744332\n",
      "      - -197263.78779157356\n",
      "      - -200213.60572604864\n",
      "      - -198916.71312393047\n",
      "      - -199875.21679826276\n",
      "      - -200566.38346396538\n",
      "      - -201363.5404061465\n",
      "      - -200825.17372797034\n",
      "      - -199120.9730320476\n",
      "      - -200961.78032788704\n",
      "      - -198489.1605427135\n",
      "      - -198526.22643579514\n",
      "      - -201657.57814599446\n",
      "      - -199908.10362506474\n",
      "      - -199080.28366819324\n",
      "      - -199025.21981181132\n",
      "      - -205872.44510742553\n",
      "      - -199242.74601818764\n",
      "      - -196435.5683070429\n",
      "      - -195778.00558932457\n",
      "      - -196367.8412277506\n",
      "      - -200242.53240443981\n",
      "      - -197991.7404409614\n",
      "      - -202530.26697877384\n",
      "      - -199751.42087052402\n",
      "      - -203705.78094987932\n",
      "      - -199783.51975285067\n",
      "      - -197955.9051556725\n",
      "      - -199478.06245359973\n",
      "      - -201737.69783050867\n",
      "      - -198637.75796883018\n",
      "      - -197013.8375313758\n",
      "      - -199001.58005421414\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09477253286382449\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46836564399324376\n",
      "      mean_inference_ms: 0.9664658451533681\n",
      "      mean_raw_obs_processing_ms: 0.13480070423248905\n",
      "  time_since_restore: 1368.8837730884552\n",
      "  time_this_iter_s: 9.506947040557861\n",
      "  time_total_s: 1368.8837730884552\n",
      "  timers:\n",
      "    learn_throughput: 123327.709\n",
      "    learn_time_ms: 518.813\n",
      "    load_throughput: 21781023.531\n",
      "    load_time_ms: 2.938\n",
      "    training_iteration_time_ms: 9510.14\n",
      "    update_time_ms: 4.451\n",
      "  timestamp: 1665850117\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 9149712\n",
      "  training_iteration: 143\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:08:42 (running for 00:23:17.19)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   143</td><td style=\"text-align: right;\">         1368.88</td><td style=\"text-align: right;\">9149712</td><td style=\"text-align: right;\"> -200045</td><td style=\"text-align: right;\">             -195778</td><td style=\"text-align: right;\">             -233066</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 9213696\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 9213696\n",
      "    num_agent_steps_trained: 9213696\n",
      "    num_env_steps_sampled: 9213696\n",
      "    num_env_steps_trained: 9213696\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-08-46\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -195092.4990336426\n",
      "  episode_reward_mean: -200136.79119460727\n",
      "  episode_reward_min: -223726.89740539822\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 9204\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1345717906951904\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0005188697250559926\n",
      "          model: {}\n",
      "          policy_loss: 0.004527584183961153\n",
      "          total_loss: 10.004317283630371\n",
      "          vf_explained_var: -3.595200936956644e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 9213696\n",
      "    num_agent_steps_trained: 9213696\n",
      "    num_env_steps_sampled: 9213696\n",
      "    num_env_steps_trained: 9213696\n",
      "  iterations_since_restore: 144\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 9213696\n",
      "  num_agent_steps_trained: 9213696\n",
      "  num_env_steps_sampled: 9213696\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 9213696\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.43846153846154\n",
      "    ram_util_percent: 87.03076923076924\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09468043590527024\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4684459431415941\n",
      "    mean_inference_ms: 0.9663041990268623\n",
      "    mean_raw_obs_processing_ms: 0.13473322112910505\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -195092.4990336426\n",
      "    episode_reward_mean: -200136.79119460727\n",
      "    episode_reward_min: -223726.89740539822\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -201225.5322807202\n",
      "      - -199967.41650315715\n",
      "      - -201614.5779528183\n",
      "      - -198022.81238418297\n",
      "      - -199681.82428368123\n",
      "      - -203802.97958638423\n",
      "      - -202480.03303661154\n",
      "      - -201542.30488744332\n",
      "      - -197263.78779157356\n",
      "      - -200213.60572604864\n",
      "      - -198916.71312393047\n",
      "      - -199875.21679826276\n",
      "      - -200566.38346396538\n",
      "      - -201363.5404061465\n",
      "      - -200825.17372797034\n",
      "      - -199120.9730320476\n",
      "      - -200961.78032788704\n",
      "      - -198489.1605427135\n",
      "      - -198526.22643579514\n",
      "      - -201657.57814599446\n",
      "      - -199908.10362506474\n",
      "      - -199080.28366819324\n",
      "      - -199025.21981181132\n",
      "      - -205872.44510742553\n",
      "      - -199242.74601818764\n",
      "      - -196435.5683070429\n",
      "      - -195778.00558932457\n",
      "      - -196367.8412277506\n",
      "      - -200242.53240443981\n",
      "      - -197991.7404409614\n",
      "      - -202530.26697877384\n",
      "      - -199751.42087052402\n",
      "      - -203705.78094987932\n",
      "      - -199783.51975285067\n",
      "      - -197955.9051556725\n",
      "      - -199478.06245359973\n",
      "      - -201737.69783050867\n",
      "      - -198637.75796883018\n",
      "      - -197013.8375313758\n",
      "      - -199001.58005421414\n",
      "      - -205724.18328042407\n",
      "      - -201571.66690243347\n",
      "      - -199820.43025626626\n",
      "      - -201818.95463937795\n",
      "      - -199426.91474123858\n",
      "      - -196462.74070385974\n",
      "      - -198959.0493125962\n",
      "      - -200733.43330277412\n",
      "      - -202929.7366936145\n",
      "      - -197169.4202655951\n",
      "      - -200731.79988130642\n",
      "      - -200313.87012754014\n",
      "      - -197700.0738305456\n",
      "      - -200405.88525371475\n",
      "      - -200093.987907193\n",
      "      - -199231.30773571975\n",
      "      - -199990.1227195194\n",
      "      - -199730.20127589093\n",
      "      - -198416.43445308533\n",
      "      - -199721.71102612355\n",
      "      - -199983.94398798342\n",
      "      - -199052.33138986607\n",
      "      - -199922.36748321244\n",
      "      - -198892.91593284268\n",
      "      - -198368.66142179\n",
      "      - -200436.3032999524\n",
      "      - -200416.89327558092\n",
      "      - -202629.47766181585\n",
      "      - -199320.9901946586\n",
      "      - -198862.0758763526\n",
      "      - -204378.90401952548\n",
      "      - -201554.8034312882\n",
      "      - -223726.89740539822\n",
      "      - -198752.94961814702\n",
      "      - -196220.5766236434\n",
      "      - -196401.15296706615\n",
      "      - -201933.95720993413\n",
      "      - -199768.12175818384\n",
      "      - -199799.24149954243\n",
      "      - -196303.26155902492\n",
      "      - -197695.2888509999\n",
      "      - -200058.92202382835\n",
      "      - -201736.27207858814\n",
      "      - -198888.2649396171\n",
      "      - -199566.10808312232\n",
      "      - -201014.39727445258\n",
      "      - -199234.57875389382\n",
      "      - -199645.2404501852\n",
      "      - -198057.98415863694\n",
      "      - -195092.4990336426\n",
      "      - -200022.89317611625\n",
      "      - -203009.90351907356\n",
      "      - -200494.8078543514\n",
      "      - -198441.11946589258\n",
      "      - -200378.3069355228\n",
      "      - -199446.18676627113\n",
      "      - -201023.5212989125\n",
      "      - -200829.98354535946\n",
      "      - -202304.78273737067\n",
      "      - -203402.37140649994\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09468043590527024\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4684459431415941\n",
      "      mean_inference_ms: 0.9663041990268623\n",
      "      mean_raw_obs_processing_ms: 0.13473322112910505\n",
      "  time_since_restore: 1378.1213269233704\n",
      "  time_this_iter_s: 9.237553834915161\n",
      "  time_total_s: 1378.1213269233704\n",
      "  timers:\n",
      "    learn_throughput: 123831.615\n",
      "    learn_time_ms: 516.702\n",
      "    load_throughput: 21686506.326\n",
      "    load_time_ms: 2.95\n",
      "    training_iteration_time_ms: 9496.484\n",
      "    update_time_ms: 4.46\n",
      "  timestamp: 1665850126\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 9213696\n",
      "  training_iteration: 144\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:08:51 (running for 00:23:26.27)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   144</td><td style=\"text-align: right;\">         1378.12</td><td style=\"text-align: right;\">9213696</td><td style=\"text-align: right;\"> -200137</td><td style=\"text-align: right;\">             -195092</td><td style=\"text-align: right;\">             -223727</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 9277680\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 9277680\n",
      "    num_agent_steps_trained: 9277680\n",
      "    num_env_steps_sampled: 9277680\n",
      "    num_env_steps_trained: 9277680\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-08-56\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -195031.6818995292\n",
      "  episode_reward_mean: -200304.0961370686\n",
      "  episode_reward_min: -223726.89740539822\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 9276\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1340854167938232\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00030976824928075075\n",
      "          model: {}\n",
      "          policy_loss: 0.0025494080036878586\n",
      "          total_loss: 10.002298355102539\n",
      "          vf_explained_var: -3.7844220202032375e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 9277680\n",
      "    num_agent_steps_trained: 9277680\n",
      "    num_env_steps_sampled: 9277680\n",
      "    num_env_steps_trained: 9277680\n",
      "  iterations_since_restore: 145\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 9277680\n",
      "  num_agent_steps_trained: 9277680\n",
      "  num_env_steps_sampled: 9277680\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 9277680\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.34615384615384\n",
      "    ram_util_percent: 87.0\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09464609119367683\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4682935233419496\n",
      "    mean_inference_ms: 0.9660960957781825\n",
      "    mean_raw_obs_processing_ms: 0.13454443724435336\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -195031.6818995292\n",
      "    episode_reward_mean: -200304.0961370686\n",
      "    episode_reward_min: -223726.89740539822\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -223726.89740539822\n",
      "      - -198752.94961814702\n",
      "      - -196220.5766236434\n",
      "      - -196401.15296706615\n",
      "      - -201933.95720993413\n",
      "      - -199768.12175818384\n",
      "      - -199799.24149954243\n",
      "      - -196303.26155902492\n",
      "      - -197695.2888509999\n",
      "      - -200058.92202382835\n",
      "      - -201736.27207858814\n",
      "      - -198888.2649396171\n",
      "      - -199566.10808312232\n",
      "      - -201014.39727445258\n",
      "      - -199234.57875389382\n",
      "      - -199645.2404501852\n",
      "      - -198057.98415863694\n",
      "      - -195092.4990336426\n",
      "      - -200022.89317611625\n",
      "      - -203009.90351907356\n",
      "      - -200494.8078543514\n",
      "      - -198441.11946589258\n",
      "      - -200378.3069355228\n",
      "      - -199446.18676627113\n",
      "      - -201023.5212989125\n",
      "      - -200829.98354535946\n",
      "      - -202304.78273737067\n",
      "      - -203402.37140649994\n",
      "      - -197434.96352589288\n",
      "      - -198066.73933351514\n",
      "      - -200844.25117703318\n",
      "      - -197773.18466513391\n",
      "      - -199621.78263691673\n",
      "      - -200827.1757238337\n",
      "      - -199403.77310518452\n",
      "      - -199926.7547663656\n",
      "      - -201992.49523490775\n",
      "      - -200413.08170790484\n",
      "      - -203246.18408229013\n",
      "      - -201270.3155786577\n",
      "      - -199012.91183986282\n",
      "      - -200390.56532221395\n",
      "      - -202217.12949503542\n",
      "      - -199917.17009785125\n",
      "      - -200967.16102853854\n",
      "      - -201110.73297240149\n",
      "      - -211076.67890475874\n",
      "      - -197216.0550091063\n",
      "      - -201308.1695803026\n",
      "      - -202498.77433771713\n",
      "      - -200522.73520557227\n",
      "      - -200048.58888701943\n",
      "      - -199409.14688300947\n",
      "      - -200711.0527387255\n",
      "      - -203155.3431896797\n",
      "      - -197306.56012494914\n",
      "      - -199377.0039678883\n",
      "      - -199144.91009226665\n",
      "      - -203887.2696064978\n",
      "      - -201007.03235683238\n",
      "      - -200169.56438480536\n",
      "      - -202568.2708507666\n",
      "      - -201032.10212697397\n",
      "      - -198475.82334706903\n",
      "      - -199328.1366993157\n",
      "      - -201193.11030542888\n",
      "      - -205027.81757080604\n",
      "      - -200051.29432376192\n",
      "      - -201122.68903563617\n",
      "      - -198574.365604788\n",
      "      - -196707.77566273985\n",
      "      - -198476.1799306727\n",
      "      - -200778.9586532076\n",
      "      - -197369.62581166803\n",
      "      - -201028.23604911246\n",
      "      - -201477.18678785753\n",
      "      - -200511.9816876662\n",
      "      - -199316.82689379956\n",
      "      - -202920.12185930254\n",
      "      - -197440.17927281308\n",
      "      - -196561.3748706166\n",
      "      - -201602.1051117048\n",
      "      - -196384.69040564747\n",
      "      - -195031.6818995292\n",
      "      - -202352.62468261557\n",
      "      - -199078.00017921193\n",
      "      - -201028.0891090531\n",
      "      - -203706.04856969527\n",
      "      - -197433.27196807796\n",
      "      - -200760.70331707955\n",
      "      - -198546.80918548664\n",
      "      - -200188.7341660932\n",
      "      - -197612.6683378308\n",
      "      - -197709.54823454883\n",
      "      - -199944.98617747953\n",
      "      - -199963.89006404902\n",
      "      - -199017.42500924575\n",
      "      - -200631.37857553677\n",
      "      - -203444.01435394518\n",
      "      - -201486.03846007632\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09464609119367683\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4682935233419496\n",
      "      mean_inference_ms: 0.9660960957781825\n",
      "      mean_raw_obs_processing_ms: 0.13454443724435336\n",
      "  time_since_restore: 1387.4686093330383\n",
      "  time_this_iter_s: 9.347282409667969\n",
      "  time_total_s: 1387.4686093330383\n",
      "  timers:\n",
      "    learn_throughput: 123663.604\n",
      "    learn_time_ms: 517.404\n",
      "    load_throughput: 21928564.191\n",
      "    load_time_ms: 2.918\n",
      "    training_iteration_time_ms: 9494.625\n",
      "    update_time_ms: 4.536\n",
      "  timestamp: 1665850136\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 9277680\n",
      "  training_iteration: 145\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:09:01 (running for 00:23:35.59)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   145</td><td style=\"text-align: right;\">         1387.47</td><td style=\"text-align: right;\">9277680</td><td style=\"text-align: right;\"> -200304</td><td style=\"text-align: right;\">             -195032</td><td style=\"text-align: right;\">             -223727</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 9341664\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 9341664\n",
      "    num_agent_steps_trained: 9341664\n",
      "    num_env_steps_sampled: 9341664\n",
      "    num_env_steps_trained: 9341664\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-09-05\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -195031.6818995292\n",
      "  episode_reward_mean: -200014.8175162181\n",
      "  episode_reward_min: -210768.076152837\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 9336\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1281704902648926\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0003610054263845086\n",
      "          model: {}\n",
      "          policy_loss: 0.006445889826864004\n",
      "          total_loss: 10.006205558776855\n",
      "          vf_explained_var: -1.0407160466741061e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 9341664\n",
      "    num_agent_steps_trained: 9341664\n",
      "    num_env_steps_sampled: 9341664\n",
      "    num_env_steps_trained: 9341664\n",
      "  iterations_since_restore: 146\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 9341664\n",
      "  num_agent_steps_trained: 9341664\n",
      "  num_env_steps_sampled: 9341664\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 9341664\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 84.3846153846154\n",
      "    ram_util_percent: 87.0\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0946648185142731\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4681971258795113\n",
      "    mean_inference_ms: 0.9663362568762699\n",
      "    mean_raw_obs_processing_ms: 0.1346734794455012\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -195031.6818995292\n",
      "    episode_reward_mean: -200014.8175162181\n",
      "    episode_reward_min: -210768.076152837\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -200169.56438480536\n",
      "      - -202568.2708507666\n",
      "      - -201032.10212697397\n",
      "      - -198475.82334706903\n",
      "      - -199328.1366993157\n",
      "      - -201193.11030542888\n",
      "      - -205027.81757080604\n",
      "      - -200051.29432376192\n",
      "      - -201122.68903563617\n",
      "      - -198574.365604788\n",
      "      - -196707.77566273985\n",
      "      - -198476.1799306727\n",
      "      - -200778.9586532076\n",
      "      - -197369.62581166803\n",
      "      - -201028.23604911246\n",
      "      - -201477.18678785753\n",
      "      - -200511.9816876662\n",
      "      - -199316.82689379956\n",
      "      - -202920.12185930254\n",
      "      - -197440.17927281308\n",
      "      - -196561.3748706166\n",
      "      - -201602.1051117048\n",
      "      - -196384.69040564747\n",
      "      - -195031.6818995292\n",
      "      - -202352.62468261557\n",
      "      - -199078.00017921193\n",
      "      - -201028.0891090531\n",
      "      - -203706.04856969527\n",
      "      - -197433.27196807796\n",
      "      - -200760.70331707955\n",
      "      - -198546.80918548664\n",
      "      - -200188.7341660932\n",
      "      - -197612.6683378308\n",
      "      - -197709.54823454883\n",
      "      - -199944.98617747953\n",
      "      - -199963.89006404902\n",
      "      - -199017.42500924575\n",
      "      - -200631.37857553677\n",
      "      - -203444.01435394518\n",
      "      - -201486.03846007632\n",
      "      - -198184.60899048366\n",
      "      - -204315.19689132544\n",
      "      - -196087.51816083395\n",
      "      - -202423.04390145626\n",
      "      - -198495.74325367794\n",
      "      - -201251.04816469483\n",
      "      - -202859.03434938454\n",
      "      - -198600.58707453063\n",
      "      - -201960.78886664996\n",
      "      - -199925.8770887621\n",
      "      - -199777.17707262642\n",
      "      - -198280.79415194487\n",
      "      - -198619.51223840294\n",
      "      - -198025.7760833786\n",
      "      - -204508.4094963083\n",
      "      - -199572.86493514737\n",
      "      - -203558.74054376836\n",
      "      - -199425.25134538685\n",
      "      - -201494.08380055844\n",
      "      - -201117.34578000565\n",
      "      - -201098.0390395535\n",
      "      - -203528.4905049781\n",
      "      - -199799.67748037708\n",
      "      - -198639.3387948385\n",
      "      - -201221.06377405627\n",
      "      - -198414.53030754827\n",
      "      - -198354.73310656316\n",
      "      - -197201.3629849471\n",
      "      - -201731.23422037638\n",
      "      - -198382.64124634408\n",
      "      - -200865.81912435318\n",
      "      - -204570.5863786525\n",
      "      - -197751.23808542118\n",
      "      - -204039.58466479834\n",
      "      - -198240.0429740771\n",
      "      - -199107.7686303939\n",
      "      - -198637.22221201035\n",
      "      - -202854.72494719576\n",
      "      - -197641.42920640513\n",
      "      - -198350.79659939243\n",
      "      - -200818.15773325125\n",
      "      - -198834.66146448362\n",
      "      - -199653.39668041695\n",
      "      - -206158.40801123413\n",
      "      - -195304.71759447205\n",
      "      - -201065.69913128088\n",
      "      - -210768.076152837\n",
      "      - -201346.0490781532\n",
      "      - -197588.91445866754\n",
      "      - -196124.5278066006\n",
      "      - -200943.34275421148\n",
      "      - -197551.16449112425\n",
      "      - -198495.6347118797\n",
      "      - -199653.4298966295\n",
      "      - -200318.49739945147\n",
      "      - -197478.39729275144\n",
      "      - -197526.90972436665\n",
      "      - -199453.23370008275\n",
      "      - -199992.1794174566\n",
      "      - -197438.29811513622\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.0946648185142731\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4681971258795113\n",
      "      mean_inference_ms: 0.9663362568762699\n",
      "      mean_raw_obs_processing_ms: 0.1346734794455012\n",
      "  time_since_restore: 1397.137887954712\n",
      "  time_this_iter_s: 9.669278621673584\n",
      "  time_total_s: 1397.137887954712\n",
      "  timers:\n",
      "    learn_throughput: 122840.566\n",
      "    learn_time_ms: 520.87\n",
      "    load_throughput: 22024665.54\n",
      "    load_time_ms: 2.905\n",
      "    training_iteration_time_ms: 9426.647\n",
      "    update_time_ms: 4.47\n",
      "  timestamp: 1665850145\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 9341664\n",
      "  training_iteration: 146\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:09:10 (running for 00:23:45.37)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   146</td><td style=\"text-align: right;\">         1397.14</td><td style=\"text-align: right;\">9341664</td><td style=\"text-align: right;\"> -200015</td><td style=\"text-align: right;\">             -195032</td><td style=\"text-align: right;\">             -210768</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 9405648\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 9405648\n",
      "    num_agent_steps_trained: 9405648\n",
      "    num_env_steps_sampled: 9405648\n",
      "    num_env_steps_trained: 9405648\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-09-15\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -195304.71759447205\n",
      "  episode_reward_mean: -200034.0637120857\n",
      "  episode_reward_min: -210768.076152837\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 9396\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.126720428466797\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00029550702311098576\n",
      "          model: {}\n",
      "          policy_loss: 0.004208127968013287\n",
      "          total_loss: 10.003955841064453\n",
      "          vf_explained_var: -1.797600468478322e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 9405648\n",
      "    num_agent_steps_trained: 9405648\n",
      "    num_env_steps_sampled: 9405648\n",
      "    num_env_steps_trained: 9405648\n",
      "  iterations_since_restore: 147\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 9405648\n",
      "  num_agent_steps_trained: 9405648\n",
      "  num_env_steps_sampled: 9405648\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 9405648\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.71538461538461\n",
      "    ram_util_percent: 87.0\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09458002773034879\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.468242741705823\n",
      "    mean_inference_ms: 0.9663199070229638\n",
      "    mean_raw_obs_processing_ms: 0.13462160126116293\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -195304.71759447205\n",
      "    episode_reward_mean: -200034.0637120857\n",
      "    episode_reward_min: -210768.076152837\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -201098.0390395535\n",
      "      - -203528.4905049781\n",
      "      - -199799.67748037708\n",
      "      - -198639.3387948385\n",
      "      - -201221.06377405627\n",
      "      - -198414.53030754827\n",
      "      - -198354.73310656316\n",
      "      - -197201.3629849471\n",
      "      - -201731.23422037638\n",
      "      - -198382.64124634408\n",
      "      - -200865.81912435318\n",
      "      - -204570.5863786525\n",
      "      - -197751.23808542118\n",
      "      - -204039.58466479834\n",
      "      - -198240.0429740771\n",
      "      - -199107.7686303939\n",
      "      - -198637.22221201035\n",
      "      - -202854.72494719576\n",
      "      - -197641.42920640513\n",
      "      - -198350.79659939243\n",
      "      - -200818.15773325125\n",
      "      - -198834.66146448362\n",
      "      - -199653.39668041695\n",
      "      - -206158.40801123413\n",
      "      - -195304.71759447205\n",
      "      - -201065.69913128088\n",
      "      - -210768.076152837\n",
      "      - -201346.0490781532\n",
      "      - -197588.91445866754\n",
      "      - -196124.5278066006\n",
      "      - -200943.34275421148\n",
      "      - -197551.16449112425\n",
      "      - -198495.6347118797\n",
      "      - -199653.4298966295\n",
      "      - -200318.49739945147\n",
      "      - -197478.39729275144\n",
      "      - -197526.90972436665\n",
      "      - -199453.23370008275\n",
      "      - -199992.1794174566\n",
      "      - -197438.29811513622\n",
      "      - -200445.59760484807\n",
      "      - -201182.33279163722\n",
      "      - -197875.37586694016\n",
      "      - -200166.18590410732\n",
      "      - -204736.16913172038\n",
      "      - -198021.10055633323\n",
      "      - -199615.4288584922\n",
      "      - -198448.2878284968\n",
      "      - -200875.31969939612\n",
      "      - -199266.73983104582\n",
      "      - -199311.73303017826\n",
      "      - -197734.75752607215\n",
      "      - -199088.99985266812\n",
      "      - -200899.31056378043\n",
      "      - -201274.91965629935\n",
      "      - -200555.40672299513\n",
      "      - -201235.9590337135\n",
      "      - -201554.96135960368\n",
      "      - -200134.2170637846\n",
      "      - -198350.25569526159\n",
      "      - -197999.26133291857\n",
      "      - -202599.47168902677\n",
      "      - -198703.49438619317\n",
      "      - -197561.16251376734\n",
      "      - -200097.27453115137\n",
      "      - -202066.68915256285\n",
      "      - -201795.42856110513\n",
      "      - -205829.18234449843\n",
      "      - -200909.83165054477\n",
      "      - -201896.50473955643\n",
      "      - -201578.89753109036\n",
      "      - -199509.6215183569\n",
      "      - -202961.7895865039\n",
      "      - -198904.06492957895\n",
      "      - -199678.28998352936\n",
      "      - -198552.2676395447\n",
      "      - -201039.93822123902\n",
      "      - -202188.74703808036\n",
      "      - -199770.47057825146\n",
      "      - -200529.32783927541\n",
      "      - -199570.21949488606\n",
      "      - -198155.26361862835\n",
      "      - -202435.0419260528\n",
      "      - -198691.3641277316\n",
      "      - -198985.84026654856\n",
      "      - -198684.78488948982\n",
      "      - -197675.24447187508\n",
      "      - -202164.1233589679\n",
      "      - -197673.0986303751\n",
      "      - -199904.8581353143\n",
      "      - -200229.18317073458\n",
      "      - -204012.96428078713\n",
      "      - -195904.57990275125\n",
      "      - -198390.60114288435\n",
      "      - -197995.9741195308\n",
      "      - -199956.63039743764\n",
      "      - -199737.18203820067\n",
      "      - -201183.29697585345\n",
      "      - -199917.63279425926\n",
      "      - -200249.6932253441\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09458002773034879\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.468242741705823\n",
      "      mean_inference_ms: 0.9663199070229638\n",
      "      mean_raw_obs_processing_ms: 0.13462160126116293\n",
      "  time_since_restore: 1406.480574131012\n",
      "  time_this_iter_s: 9.342686176300049\n",
      "  time_total_s: 1406.480574131012\n",
      "  timers:\n",
      "    learn_throughput: 120683.769\n",
      "    learn_time_ms: 530.179\n",
      "    load_throughput: 22092657.452\n",
      "    load_time_ms: 2.896\n",
      "    training_iteration_time_ms: 9443.276\n",
      "    update_time_ms: 4.564\n",
      "  timestamp: 1665850155\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 9405648\n",
      "  training_iteration: 147\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:09:20 (running for 00:23:54.74)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   147</td><td style=\"text-align: right;\">         1406.48</td><td style=\"text-align: right;\">9405648</td><td style=\"text-align: right;\"> -200034</td><td style=\"text-align: right;\">             -195305</td><td style=\"text-align: right;\">             -210768</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 9469632\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 9469632\n",
      "    num_agent_steps_trained: 9469632\n",
      "    num_env_steps_sampled: 9469632\n",
      "    num_env_steps_trained: 9469632\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-09-24\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -195904.57990275125\n",
      "  episode_reward_mean: -200433.98657499204\n",
      "  episode_reward_min: -215439.3446295885\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 9468\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1226818561553955\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00038026730180718005\n",
      "          model: {}\n",
      "          policy_loss: 0.0011159214191138744\n",
      "          total_loss: 10.000880241394043\n",
      "          vf_explained_var: -3.500590395333347e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 9469632\n",
      "    num_agent_steps_trained: 9469632\n",
      "    num_env_steps_sampled: 9469632\n",
      "    num_env_steps_trained: 9469632\n",
      "  iterations_since_restore: 148\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 9469632\n",
      "  num_agent_steps_trained: 9469632\n",
      "  num_env_steps_sampled: 9469632\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 9469632\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.65384615384616\n",
      "    ram_util_percent: 87.0\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0945575954653708\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46810592521972666\n",
      "    mean_inference_ms: 0.9662285089824684\n",
      "    mean_raw_obs_processing_ms: 0.13445129887157992\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -195904.57990275125\n",
      "    episode_reward_mean: -200433.98657499204\n",
      "    episode_reward_min: -215439.3446295885\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -202961.7895865039\n",
      "      - -198904.06492957895\n",
      "      - -199678.28998352936\n",
      "      - -198552.2676395447\n",
      "      - -201039.93822123902\n",
      "      - -202188.74703808036\n",
      "      - -199770.47057825146\n",
      "      - -200529.32783927541\n",
      "      - -199570.21949488606\n",
      "      - -198155.26361862835\n",
      "      - -202435.0419260528\n",
      "      - -198691.3641277316\n",
      "      - -198985.84026654856\n",
      "      - -198684.78488948982\n",
      "      - -197675.24447187508\n",
      "      - -202164.1233589679\n",
      "      - -197673.0986303751\n",
      "      - -199904.8581353143\n",
      "      - -200229.18317073458\n",
      "      - -204012.96428078713\n",
      "      - -195904.57990275125\n",
      "      - -198390.60114288435\n",
      "      - -197995.9741195308\n",
      "      - -199956.63039743764\n",
      "      - -199737.18203820067\n",
      "      - -201183.29697585345\n",
      "      - -199917.63279425926\n",
      "      - -200249.6932253441\n",
      "      - -203544.08728543355\n",
      "      - -197603.9893335773\n",
      "      - -215439.3446295885\n",
      "      - -201849.04642588753\n",
      "      - -199433.79827212353\n",
      "      - -199519.09367339173\n",
      "      - -199051.82263846032\n",
      "      - -199916.3052002431\n",
      "      - -203540.6033986294\n",
      "      - -198844.0381041811\n",
      "      - -198257.00966300827\n",
      "      - -200404.77693528723\n",
      "      - -200809.84677096116\n",
      "      - -205298.82090768652\n",
      "      - -202011.33055545285\n",
      "      - -201174.02361312704\n",
      "      - -203141.88155729062\n",
      "      - -203719.82017920955\n",
      "      - -197348.67210532402\n",
      "      - -202201.28566835925\n",
      "      - -197548.18451027028\n",
      "      - -203013.7370441174\n",
      "      - -198337.38024674283\n",
      "      - -199740.7926897078\n",
      "      - -199624.81929066888\n",
      "      - -204525.62848012894\n",
      "      - -198909.0650737926\n",
      "      - -202541.26626985546\n",
      "      - -199908.92768356897\n",
      "      - -197985.60496369164\n",
      "      - -197939.77543595096\n",
      "      - -202386.3443257074\n",
      "      - -197265.20787827918\n",
      "      - -200358.02206573222\n",
      "      - -201918.8479282988\n",
      "      - -200297.56591516905\n",
      "      - -196787.22404036555\n",
      "      - -201639.20702519637\n",
      "      - -198077.13761087498\n",
      "      - -203699.07383106163\n",
      "      - -201362.9077391255\n",
      "      - -207661.32872055584\n",
      "      - -203028.33758496045\n",
      "      - -199450.02343341472\n",
      "      - -199734.97416760513\n",
      "      - -198612.85648589407\n",
      "      - -203974.72590029475\n",
      "      - -198514.9312891663\n",
      "      - -198838.45409341026\n",
      "      - -200182.0580655476\n",
      "      - -196183.11463375622\n",
      "      - -198052.1939328163\n",
      "      - -200064.16294021538\n",
      "      - -197567.84175498143\n",
      "      - -201184.8181279785\n",
      "      - -196836.45603466604\n",
      "      - -200075.33154933932\n",
      "      - -211781.96371532168\n",
      "      - -200702.82531162663\n",
      "      - -200031.72766277104\n",
      "      - -198876.4974043988\n",
      "      - -200042.76714150296\n",
      "      - -198405.07666477442\n",
      "      - -200115.76847436058\n",
      "      - -199094.69786189866\n",
      "      - -199081.92460445798\n",
      "      - -200591.50047425838\n",
      "      - -198100.57144123362\n",
      "      - -201412.49111512201\n",
      "      - -202115.85129033943\n",
      "      - -198336.30921452655\n",
      "      - -202628.28665882646\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.0945575954653708\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46810592521972666\n",
      "      mean_inference_ms: 0.9662285089824684\n",
      "      mean_raw_obs_processing_ms: 0.13445129887157992\n",
      "  time_since_restore: 1415.9302356243134\n",
      "  time_this_iter_s: 9.449661493301392\n",
      "  time_total_s: 1415.9302356243134\n",
      "  timers:\n",
      "    learn_throughput: 121644.438\n",
      "    learn_time_ms: 525.992\n",
      "    load_throughput: 21894572.796\n",
      "    load_time_ms: 2.922\n",
      "    training_iteration_time_ms: 9364.365\n",
      "    update_time_ms: 4.694\n",
      "  timestamp: 1665850164\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 9469632\n",
      "  training_iteration: 148\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:09:29 (running for 00:24:04.22)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   148</td><td style=\"text-align: right;\">         1415.93</td><td style=\"text-align: right;\">9469632</td><td style=\"text-align: right;\"> -200434</td><td style=\"text-align: right;\">             -195905</td><td style=\"text-align: right;\">             -215439</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 9533616\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 9533616\n",
      "    num_agent_steps_trained: 9533616\n",
      "    num_env_steps_sampled: 9533616\n",
      "    num_env_steps_trained: 9533616\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-09-34\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -196183.11463375622\n",
      "  episode_reward_mean: -200076.41838633074\n",
      "  episode_reward_min: -211781.96371532168\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 9528\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1254324913024902\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0008939740946516395\n",
      "          model: {}\n",
      "          policy_loss: 0.0062369294464588165\n",
      "          total_loss: 10.006103515625\n",
      "          vf_explained_var: -4.1628641866964244e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 9533616\n",
      "    num_agent_steps_trained: 9533616\n",
      "    num_env_steps_sampled: 9533616\n",
      "    num_env_steps_trained: 9533616\n",
      "  iterations_since_restore: 149\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 9533616\n",
      "  num_agent_steps_trained: 9533616\n",
      "  num_env_steps_sampled: 9533616\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 9533616\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.79285714285713\n",
      "    ram_util_percent: 87.0\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0946025005319089\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4680405353318923\n",
      "    mean_inference_ms: 0.9663553729809722\n",
      "    mean_raw_obs_processing_ms: 0.13461615583632563\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -196183.11463375622\n",
      "    episode_reward_mean: -200076.41838633074\n",
      "    episode_reward_min: -211781.96371532168\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -197265.20787827918\n",
      "      - -200358.02206573222\n",
      "      - -201918.8479282988\n",
      "      - -200297.56591516905\n",
      "      - -196787.22404036555\n",
      "      - -201639.20702519637\n",
      "      - -198077.13761087498\n",
      "      - -203699.07383106163\n",
      "      - -201362.9077391255\n",
      "      - -207661.32872055584\n",
      "      - -203028.33758496045\n",
      "      - -199450.02343341472\n",
      "      - -199734.97416760513\n",
      "      - -198612.85648589407\n",
      "      - -203974.72590029475\n",
      "      - -198514.9312891663\n",
      "      - -198838.45409341026\n",
      "      - -200182.0580655476\n",
      "      - -196183.11463375622\n",
      "      - -198052.1939328163\n",
      "      - -200064.16294021538\n",
      "      - -197567.84175498143\n",
      "      - -201184.8181279785\n",
      "      - -196836.45603466604\n",
      "      - -200075.33154933932\n",
      "      - -211781.96371532168\n",
      "      - -200702.82531162663\n",
      "      - -200031.72766277104\n",
      "      - -198876.4974043988\n",
      "      - -200042.76714150296\n",
      "      - -198405.07666477442\n",
      "      - -200115.76847436058\n",
      "      - -199094.69786189866\n",
      "      - -199081.92460445798\n",
      "      - -200591.50047425838\n",
      "      - -198100.57144123362\n",
      "      - -201412.49111512201\n",
      "      - -202115.85129033943\n",
      "      - -198336.30921452655\n",
      "      - -202628.28665882646\n",
      "      - -205345.60237049026\n",
      "      - -201378.18152033837\n",
      "      - -200661.08478967033\n",
      "      - -196849.741388099\n",
      "      - -200063.2668775766\n",
      "      - -201043.45386857764\n",
      "      - -202143.62825161734\n",
      "      - -200041.9914248026\n",
      "      - -201568.46511317446\n",
      "      - -203761.92984644242\n",
      "      - -198720.3269087223\n",
      "      - -200283.91862302256\n",
      "      - -200438.54704171602\n",
      "      - -199125.97148368153\n",
      "      - -199436.42284088492\n",
      "      - -198175.92689485892\n",
      "      - -199289.15082773296\n",
      "      - -199358.81496332752\n",
      "      - -200325.18075893298\n",
      "      - -199304.7623020211\n",
      "      - -197778.73876466227\n",
      "      - -198515.7521048693\n",
      "      - -197045.2934917004\n",
      "      - -199994.29432796975\n",
      "      - -201994.94098072866\n",
      "      - -197703.26701954188\n",
      "      - -201767.7222185596\n",
      "      - -198259.61850644686\n",
      "      - -203157.33486617162\n",
      "      - -200739.22157212763\n",
      "      - -199780.0838701319\n",
      "      - -203200.79227975238\n",
      "      - -206332.98449027186\n",
      "      - -199570.8009671224\n",
      "      - -198067.73787959677\n",
      "      - -198519.37906475502\n",
      "      - -201502.45668958093\n",
      "      - -199154.09799673158\n",
      "      - -199455.88965190225\n",
      "      - -205309.29144920158\n",
      "      - -197591.61602265478\n",
      "      - -199606.3734345331\n",
      "      - -200060.41315907607\n",
      "      - -199162.89260520364\n",
      "      - -197310.48399311784\n",
      "      - -200210.52916438412\n",
      "      - -197789.5094757007\n",
      "      - -199420.36637874687\n",
      "      - -199811.4348686207\n",
      "      - -198301.32731274277\n",
      "      - -199151.15408789067\n",
      "      - -197479.81489954406\n",
      "      - -203301.98647643946\n",
      "      - -197993.24475844597\n",
      "      - -198783.06074571618\n",
      "      - -197597.86229133498\n",
      "      - -196974.12848498853\n",
      "      - -196542.00272736832\n",
      "      - -201237.31860654108\n",
      "      - -201465.19106838832\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.0946025005319089\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4680405353318923\n",
      "      mean_inference_ms: 0.9663553729809722\n",
      "      mean_raw_obs_processing_ms: 0.13461615583632563\n",
      "  time_since_restore: 1425.5419342517853\n",
      "  time_this_iter_s: 9.611698627471924\n",
      "  time_total_s: 1425.5419342517853\n",
      "  timers:\n",
      "    learn_throughput: 131541.099\n",
      "    learn_time_ms: 486.418\n",
      "    load_throughput: 21789865.96\n",
      "    load_time_ms: 2.936\n",
      "    training_iteration_time_ms: 9355.475\n",
      "    update_time_ms: 4.666\n",
      "  timestamp: 1665850174\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 9533616\n",
      "  training_iteration: 149\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:09:39 (running for 00:24:13.86)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   149</td><td style=\"text-align: right;\">         1425.54</td><td style=\"text-align: right;\">9533616</td><td style=\"text-align: right;\"> -200076</td><td style=\"text-align: right;\">             -196183</td><td style=\"text-align: right;\">             -211782</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 9597600\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 9597600\n",
      "    num_agent_steps_trained: 9597600\n",
      "    num_env_steps_sampled: 9597600\n",
      "    num_env_steps_trained: 9597600\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-09-43\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -196124.0692157312\n",
      "  episode_reward_mean: -199594.9716953974\n",
      "  episode_reward_min: -206332.98449027186\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 9588\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.113942861557007\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0011205518385395408\n",
      "          model: {}\n",
      "          policy_loss: 0.003482159459963441\n",
      "          total_loss: 10.003395080566406\n",
      "          vf_explained_var: -9.461055272552699e-10\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 9597600\n",
      "    num_agent_steps_trained: 9597600\n",
      "    num_env_steps_sampled: 9597600\n",
      "    num_env_steps_trained: 9597600\n",
      "  iterations_since_restore: 150\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 9597600\n",
      "  num_agent_steps_trained: 9597600\n",
      "  num_env_steps_sampled: 9597600\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 9597600\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.92307692307692\n",
      "    ram_util_percent: 87.04615384615384\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09453847020319056\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4681529555327758\n",
      "    mean_inference_ms: 0.9662811523791598\n",
      "    mean_raw_obs_processing_ms: 0.13459110475357453\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -196124.0692157312\n",
      "    episode_reward_mean: -199594.9716953974\n",
      "    episode_reward_min: -206332.98449027186\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -197778.73876466227\n",
      "      - -198515.7521048693\n",
      "      - -197045.2934917004\n",
      "      - -199994.29432796975\n",
      "      - -201994.94098072866\n",
      "      - -197703.26701954188\n",
      "      - -201767.7222185596\n",
      "      - -198259.61850644686\n",
      "      - -203157.33486617162\n",
      "      - -200739.22157212763\n",
      "      - -199780.0838701319\n",
      "      - -203200.79227975238\n",
      "      - -206332.98449027186\n",
      "      - -199570.8009671224\n",
      "      - -198067.73787959677\n",
      "      - -198519.37906475502\n",
      "      - -201502.45668958093\n",
      "      - -199154.09799673158\n",
      "      - -199455.88965190225\n",
      "      - -205309.29144920158\n",
      "      - -197591.61602265478\n",
      "      - -199606.3734345331\n",
      "      - -200060.41315907607\n",
      "      - -199162.89260520364\n",
      "      - -197310.48399311784\n",
      "      - -200210.52916438412\n",
      "      - -197789.5094757007\n",
      "      - -199420.36637874687\n",
      "      - -199811.4348686207\n",
      "      - -198301.32731274277\n",
      "      - -199151.15408789067\n",
      "      - -197479.81489954406\n",
      "      - -203301.98647643946\n",
      "      - -197993.24475844597\n",
      "      - -198783.06074571618\n",
      "      - -197597.86229133498\n",
      "      - -196974.12848498853\n",
      "      - -196542.00272736832\n",
      "      - -201237.31860654108\n",
      "      - -201465.19106838832\n",
      "      - -196227.87415664172\n",
      "      - -199652.2482299397\n",
      "      - -200001.39052781262\n",
      "      - -201584.48265183828\n",
      "      - -197601.72580815715\n",
      "      - -202543.21596619362\n",
      "      - -198686.94550564242\n",
      "      - -196422.38092709362\n",
      "      - -198457.08406240944\n",
      "      - -201219.29937026917\n",
      "      - -197212.66328810313\n",
      "      - -200304.753048599\n",
      "      - -198152.4148961556\n",
      "      - -196124.0692157312\n",
      "      - -200028.43348274162\n",
      "      - -201192.57355801814\n",
      "      - -205197.88872955306\n",
      "      - -201757.0926972243\n",
      "      - -199031.37456535717\n",
      "      - -196852.64760855053\n",
      "      - -198571.41691027378\n",
      "      - -200691.50892998357\n",
      "      - -199010.5386853194\n",
      "      - -201364.62852714866\n",
      "      - -203107.7501522893\n",
      "      - -198800.70983558137\n",
      "      - -200797.45247208085\n",
      "      - -200580.746455558\n",
      "      - -200932.69629156054\n",
      "      - -197027.4045391129\n",
      "      - -201594.51361693395\n",
      "      - -198869.75706559623\n",
      "      - -199727.73286136167\n",
      "      - -196302.20551581698\n",
      "      - -200427.77647196714\n",
      "      - -197845.91969385417\n",
      "      - -197079.171215235\n",
      "      - -200579.01603740407\n",
      "      - -202739.0926307682\n",
      "      - -197937.01411462433\n",
      "      - -201072.09101345646\n",
      "      - -199035.4024139467\n",
      "      - -199271.15447277253\n",
      "      - -199672.37915090894\n",
      "      - -199852.3172584763\n",
      "      - -200047.30904931555\n",
      "      - -198687.5320426791\n",
      "      - -199676.74124855263\n",
      "      - -200511.1823818355\n",
      "      - -199265.35067134417\n",
      "      - -199067.3951199003\n",
      "      - -201215.7090004323\n",
      "      - -196460.28098430362\n",
      "      - -201011.7489307201\n",
      "      - -198764.08367964288\n",
      "      - -200450.75781491268\n",
      "      - -200177.42885564012\n",
      "      - -198408.36478776252\n",
      "      - -196546.92880109465\n",
      "      - -200424.99279028116\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09453847020319056\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4681529555327758\n",
      "      mean_inference_ms: 0.9662811523791598\n",
      "      mean_raw_obs_processing_ms: 0.13459110475357453\n",
      "  time_since_restore: 1435.0007560253143\n",
      "  time_this_iter_s: 9.458821773529053\n",
      "  time_total_s: 1435.0007560253143\n",
      "  timers:\n",
      "    learn_throughput: 131121.215\n",
      "    learn_time_ms: 487.976\n",
      "    load_throughput: 21794466.861\n",
      "    load_time_ms: 2.936\n",
      "    training_iteration_time_ms: 9413.16\n",
      "    update_time_ms: 4.648\n",
      "  timestamp: 1665850183\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 9597600\n",
      "  training_iteration: 150\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:09:48 (running for 00:24:23.37)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   150</td><td style=\"text-align: right;\">            1435</td><td style=\"text-align: right;\">9597600</td><td style=\"text-align: right;\"> -199595</td><td style=\"text-align: right;\">             -196124</td><td style=\"text-align: right;\">             -206333</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 9661584\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 9661584\n",
      "    num_agent_steps_trained: 9661584\n",
      "    num_env_steps_sampled: 9661584\n",
      "    num_env_steps_trained: 9661584\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-09-53\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -194545.11333435818\n",
      "  episode_reward_mean: -199465.18590590102\n",
      "  episode_reward_min: -204855.56312661574\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 9660\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.115866184234619\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0006824176525697112\n",
      "          model: {}\n",
      "          policy_loss: 0.0018298262730240822\n",
      "          total_loss: 10.001654624938965\n",
      "          vf_explained_var: 2.838316470743507e-09\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 9661584\n",
      "    num_agent_steps_trained: 9661584\n",
      "    num_env_steps_sampled: 9661584\n",
      "    num_env_steps_trained: 9661584\n",
      "  iterations_since_restore: 151\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 9661584\n",
      "  num_agent_steps_trained: 9661584\n",
      "  num_env_steps_sampled: 9661584\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 9661584\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.89230769230768\n",
      "    ram_util_percent: 87.1\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09452067226489737\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4681469017835937\n",
      "    mean_inference_ms: 0.9661231395394403\n",
      "    mean_raw_obs_processing_ms: 0.13442714328396024\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -194545.11333435818\n",
      "    episode_reward_mean: -199465.18590590102\n",
      "    episode_reward_min: -204855.56312661574\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -199727.73286136167\n",
      "      - -196302.20551581698\n",
      "      - -200427.77647196714\n",
      "      - -197845.91969385417\n",
      "      - -197079.171215235\n",
      "      - -200579.01603740407\n",
      "      - -202739.0926307682\n",
      "      - -197937.01411462433\n",
      "      - -201072.09101345646\n",
      "      - -199035.4024139467\n",
      "      - -199271.15447277253\n",
      "      - -199672.37915090894\n",
      "      - -199852.3172584763\n",
      "      - -200047.30904931555\n",
      "      - -198687.5320426791\n",
      "      - -199676.74124855263\n",
      "      - -200511.1823818355\n",
      "      - -199265.35067134417\n",
      "      - -199067.3951199003\n",
      "      - -201215.7090004323\n",
      "      - -196460.28098430362\n",
      "      - -201011.7489307201\n",
      "      - -198764.08367964288\n",
      "      - -200450.75781491268\n",
      "      - -200177.42885564012\n",
      "      - -198408.36478776252\n",
      "      - -196546.92880109465\n",
      "      - -200424.99279028116\n",
      "      - -197686.7477196579\n",
      "      - -198594.95014280366\n",
      "      - -201806.60268003322\n",
      "      - -196435.05741534164\n",
      "      - -197845.24801057248\n",
      "      - -198110.06480219227\n",
      "      - -196718.48143243784\n",
      "      - -200225.12916300146\n",
      "      - -198073.81761563238\n",
      "      - -199380.79630316966\n",
      "      - -201061.81051122624\n",
      "      - -197615.63146676985\n",
      "      - -201355.3536531127\n",
      "      - -194545.11333435818\n",
      "      - -200016.0414331039\n",
      "      - -198678.70938659846\n",
      "      - -198509.9019570986\n",
      "      - -197296.6502369003\n",
      "      - -196983.96226411802\n",
      "      - -200292.525135914\n",
      "      - -199839.99196345705\n",
      "      - -201637.65012446645\n",
      "      - -197478.36612332638\n",
      "      - -200184.16682958667\n",
      "      - -196883.26923216673\n",
      "      - -202993.90958814046\n",
      "      - -196927.41189567896\n",
      "      - -196910.06726687893\n",
      "      - -197175.6687784158\n",
      "      - -195694.1667475587\n",
      "      - -199903.28142339885\n",
      "      - -196715.23127346637\n",
      "      - -202228.9895407936\n",
      "      - -199635.7493155079\n",
      "      - -201666.11437598176\n",
      "      - -204604.9603570155\n",
      "      - -200548.71156448015\n",
      "      - -199204.59139910084\n",
      "      - -202265.56152825835\n",
      "      - -199388.64806872516\n",
      "      - -203301.8578065095\n",
      "      - -200997.26836920474\n",
      "      - -201242.37125272184\n",
      "      - -203593.41164045027\n",
      "      - -200132.19932141333\n",
      "      - -198968.4170127536\n",
      "      - -202774.80487508\n",
      "      - -199428.82969564205\n",
      "      - -198757.43767709553\n",
      "      - -199556.7190980985\n",
      "      - -199663.35965107594\n",
      "      - -196760.04513588568\n",
      "      - -199138.7648182929\n",
      "      - -200225.142263242\n",
      "      - -199254.59357963194\n",
      "      - -197681.11024585346\n",
      "      - -204855.56312661574\n",
      "      - -199424.9653582746\n",
      "      - -198959.49993593377\n",
      "      - -198519.14859620822\n",
      "      - -200006.93381814292\n",
      "      - -198891.25672677407\n",
      "      - -199553.34334469054\n",
      "      - -198995.22453621705\n",
      "      - -204062.91143196137\n",
      "      - -199247.24861873768\n",
      "      - -202094.53945480328\n",
      "      - -198957.76776800153\n",
      "      - -198701.607671366\n",
      "      - -200186.54743819233\n",
      "      - -200107.7036806917\n",
      "      - -197101.8155710823\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09452067226489737\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4681469017835937\n",
      "      mean_inference_ms: 0.9661231395394403\n",
      "      mean_raw_obs_processing_ms: 0.13442714328396024\n",
      "  time_since_restore: 1444.4438269138336\n",
      "  time_this_iter_s: 9.443070888519287\n",
      "  time_total_s: 1444.4438269138336\n",
      "  timers:\n",
      "    learn_throughput: 131433.282\n",
      "    learn_time_ms: 486.817\n",
      "    load_throughput: 21111916.355\n",
      "    load_time_ms: 3.031\n",
      "    training_iteration_time_ms: 9420.71\n",
      "    update_time_ms: 4.629\n",
      "  timestamp: 1665850193\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 9661584\n",
      "  training_iteration: 151\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:09:58 (running for 00:24:32.69)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   151</td><td style=\"text-align: right;\">         1444.44</td><td style=\"text-align: right;\">9661584</td><td style=\"text-align: right;\"> -199465</td><td style=\"text-align: right;\">             -194545</td><td style=\"text-align: right;\">             -204856</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 9725568\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 9725568\n",
      "    num_agent_steps_trained: 9725568\n",
      "    num_env_steps_sampled: 9725568\n",
      "    num_env_steps_trained: 9725568\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-10-02\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -194642.47309875194\n",
      "  episode_reward_mean: -199542.0358511512\n",
      "  episode_reward_min: -204855.56312661574\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 9720\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.128398895263672\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0007186588481999934\n",
      "          model: {}\n",
      "          policy_loss: 0.006383867468684912\n",
      "          total_loss: 10.00621509552002\n",
      "          vf_explained_var: -3.689811478579941e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 9725568\n",
      "    num_agent_steps_trained: 9725568\n",
      "    num_env_steps_sampled: 9725568\n",
      "    num_env_steps_trained: 9725568\n",
      "  iterations_since_restore: 152\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 9725568\n",
      "  num_agent_steps_trained: 9725568\n",
      "  num_env_steps_sampled: 9725568\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 9725568\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.1846153846154\n",
      "    ram_util_percent: 87.04615384615384\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09456738349652469\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4682021207270606\n",
      "    mean_inference_ms: 0.9658975004090464\n",
      "    mean_raw_obs_processing_ms: 0.13455810409543523\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -194642.47309875194\n",
      "    episode_reward_mean: -199542.0358511512\n",
      "    episode_reward_min: -204855.56312661574\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -202228.9895407936\n",
      "      - -199635.7493155079\n",
      "      - -201666.11437598176\n",
      "      - -204604.9603570155\n",
      "      - -200548.71156448015\n",
      "      - -199204.59139910084\n",
      "      - -202265.56152825835\n",
      "      - -199388.64806872516\n",
      "      - -203301.8578065095\n",
      "      - -200997.26836920474\n",
      "      - -201242.37125272184\n",
      "      - -203593.41164045027\n",
      "      - -200132.19932141333\n",
      "      - -198968.4170127536\n",
      "      - -202774.80487508\n",
      "      - -199428.82969564205\n",
      "      - -198757.43767709553\n",
      "      - -199556.7190980985\n",
      "      - -199663.35965107594\n",
      "      - -196760.04513588568\n",
      "      - -199138.7648182929\n",
      "      - -200225.142263242\n",
      "      - -199254.59357963194\n",
      "      - -197681.11024585346\n",
      "      - -204855.56312661574\n",
      "      - -199424.9653582746\n",
      "      - -198959.49993593377\n",
      "      - -198519.14859620822\n",
      "      - -200006.93381814292\n",
      "      - -198891.25672677407\n",
      "      - -199553.34334469054\n",
      "      - -198995.22453621705\n",
      "      - -204062.91143196137\n",
      "      - -199247.24861873768\n",
      "      - -202094.53945480328\n",
      "      - -198957.76776800153\n",
      "      - -198701.607671366\n",
      "      - -200186.54743819233\n",
      "      - -200107.7036806917\n",
      "      - -197101.8155710823\n",
      "      - -199610.27900042484\n",
      "      - -199487.99267226594\n",
      "      - -196151.0885112546\n",
      "      - -198933.42570276663\n",
      "      - -200063.51613683224\n",
      "      - -199639.27729988648\n",
      "      - -199560.96587795683\n",
      "      - -198789.07065814472\n",
      "      - -198426.93433187212\n",
      "      - -199826.42575259396\n",
      "      - -204177.77113502423\n",
      "      - -200414.3252743342\n",
      "      - -199939.70070897051\n",
      "      - -199630.8352987462\n",
      "      - -199508.8693084116\n",
      "      - -201606.38270572765\n",
      "      - -198710.35815089112\n",
      "      - -197118.57765452328\n",
      "      - -198606.44214241693\n",
      "      - -198199.8522139019\n",
      "      - -202966.41024292988\n",
      "      - -199247.39083185297\n",
      "      - -199709.39044165693\n",
      "      - -200366.61923174965\n",
      "      - -195859.60747237713\n",
      "      - -197525.37569517715\n",
      "      - -199412.67417266502\n",
      "      - -199591.45863991856\n",
      "      - -200499.26327442366\n",
      "      - -196933.44871745034\n",
      "      - -199870.17852153588\n",
      "      - -199334.37681728936\n",
      "      - -198718.40852425294\n",
      "      - -198776.58863229444\n",
      "      - -196475.48089173014\n",
      "      - -197262.53283974068\n",
      "      - -198822.87326751914\n",
      "      - -198843.33784570254\n",
      "      - -198329.8760875279\n",
      "      - -197447.33421031642\n",
      "      - -198684.463415955\n",
      "      - -198751.36765793094\n",
      "      - -194642.47309875194\n",
      "      - -200114.48989939928\n",
      "      - -197298.45247339233\n",
      "      - -197442.5547107682\n",
      "      - -199616.28487473045\n",
      "      - -198090.22912881707\n",
      "      - -197790.71293080054\n",
      "      - -200143.88795421214\n",
      "      - -199953.4773741468\n",
      "      - -203042.59694210644\n",
      "      - -200519.14441577715\n",
      "      - -199115.22394187146\n",
      "      - -198802.9078783117\n",
      "      - -199906.61769725746\n",
      "      - -200964.20696483614\n",
      "      - -197760.43218897854\n",
      "      - -196770.02180598926\n",
      "      - -199713.5871955207\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09456738349652469\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4682021207270606\n",
      "      mean_inference_ms: 0.9658975004090464\n",
      "      mean_raw_obs_processing_ms: 0.13455810409543523\n",
      "  time_since_restore: 1453.657964706421\n",
      "  time_this_iter_s: 9.21413779258728\n",
      "  time_total_s: 1453.657964706421\n",
      "  timers:\n",
      "    learn_throughput: 131034.376\n",
      "    learn_time_ms: 488.299\n",
      "    load_throughput: 21057251.025\n",
      "    load_time_ms: 3.039\n",
      "    training_iteration_time_ms: 9421.201\n",
      "    update_time_ms: 4.404\n",
      "  timestamp: 1665850202\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 9725568\n",
      "  training_iteration: 152\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:10:07 (running for 00:24:42.12)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   152</td><td style=\"text-align: right;\">         1453.66</td><td style=\"text-align: right;\">9725568</td><td style=\"text-align: right;\"> -199542</td><td style=\"text-align: right;\">             -194642</td><td style=\"text-align: right;\">             -204856</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 9789552\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 9789552\n",
      "    num_agent_steps_trained: 9789552\n",
      "    num_env_steps_sampled: 9789552\n",
      "    num_env_steps_trained: 9789552\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-10-11\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -194642.47309875194\n",
      "  episode_reward_mean: -199310.37365120318\n",
      "  episode_reward_min: -209482.83940226174\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 9780\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.128038167953491\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0005341186770237982\n",
      "          model: {}\n",
      "          policy_loss: 0.003935638815164566\n",
      "          total_loss: 10.003730773925781\n",
      "          vf_explained_var: -2.932926967957883e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 9789552\n",
      "    num_agent_steps_trained: 9789552\n",
      "    num_env_steps_sampled: 9789552\n",
      "    num_env_steps_trained: 9789552\n",
      "  iterations_since_restore: 153\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 9789552\n",
      "  num_agent_steps_trained: 9789552\n",
      "  num_env_steps_sampled: 9789552\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 9789552\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.88461538461539\n",
      "    ram_util_percent: 87.17692307692306\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09448415625124355\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4683317251947615\n",
      "    mean_inference_ms: 0.9655912751994612\n",
      "    mean_raw_obs_processing_ms: 0.13450710223336138\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -194642.47309875194\n",
      "    episode_reward_mean: -199310.37365120318\n",
      "    episode_reward_min: -209482.83940226174\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -202966.41024292988\n",
      "      - -199247.39083185297\n",
      "      - -199709.39044165693\n",
      "      - -200366.61923174965\n",
      "      - -195859.60747237713\n",
      "      - -197525.37569517715\n",
      "      - -199412.67417266502\n",
      "      - -199591.45863991856\n",
      "      - -200499.26327442366\n",
      "      - -196933.44871745034\n",
      "      - -199870.17852153588\n",
      "      - -199334.37681728936\n",
      "      - -198718.40852425294\n",
      "      - -198776.58863229444\n",
      "      - -196475.48089173014\n",
      "      - -197262.53283974068\n",
      "      - -198822.87326751914\n",
      "      - -198843.33784570254\n",
      "      - -198329.8760875279\n",
      "      - -197447.33421031642\n",
      "      - -198684.463415955\n",
      "      - -198751.36765793094\n",
      "      - -194642.47309875194\n",
      "      - -200114.48989939928\n",
      "      - -197298.45247339233\n",
      "      - -197442.5547107682\n",
      "      - -199616.28487473045\n",
      "      - -198090.22912881707\n",
      "      - -197790.71293080054\n",
      "      - -200143.88795421214\n",
      "      - -199953.4773741468\n",
      "      - -203042.59694210644\n",
      "      - -200519.14441577715\n",
      "      - -199115.22394187146\n",
      "      - -198802.9078783117\n",
      "      - -199906.61769725746\n",
      "      - -200964.20696483614\n",
      "      - -197760.43218897854\n",
      "      - -196770.02180598926\n",
      "      - -199713.5871955207\n",
      "      - -201137.1790124609\n",
      "      - -197666.51840951826\n",
      "      - -197440.14764390787\n",
      "      - -197091.57912324995\n",
      "      - -201065.41290471712\n",
      "      - -196658.17240289447\n",
      "      - -200997.16806978098\n",
      "      - -198271.82880704818\n",
      "      - -201405.3165483324\n",
      "      - -199034.86156051813\n",
      "      - -201010.5442660921\n",
      "      - -198434.20409032327\n",
      "      - -197205.9253052785\n",
      "      - -196522.83014084428\n",
      "      - -199390.5838741187\n",
      "      - -196849.28400918315\n",
      "      - -198071.965369163\n",
      "      - -197372.37062697517\n",
      "      - -200643.57703080855\n",
      "      - -203877.6232176354\n",
      "      - -197527.3089898713\n",
      "      - -196984.82918408338\n",
      "      - -199619.2958817903\n",
      "      - -199063.29567041053\n",
      "      - -200267.34195494096\n",
      "      - -202153.351608043\n",
      "      - -196114.09308215955\n",
      "      - -198055.54094939766\n",
      "      - -201242.83624396793\n",
      "      - -197747.4029521081\n",
      "      - -198452.688600929\n",
      "      - -199066.25626408544\n",
      "      - -202252.45492130838\n",
      "      - -200955.69246243886\n",
      "      - -200204.06561218473\n",
      "      - -204640.38108848402\n",
      "      - -202408.031551252\n",
      "      - -197174.7079661833\n",
      "      - -200207.94061863702\n",
      "      - -202007.73697054476\n",
      "      - -199592.47865174984\n",
      "      - -199558.36637621257\n",
      "      - -199493.54380519426\n",
      "      - -199854.78376644506\n",
      "      - -209482.83940226174\n",
      "      - -200954.3499904364\n",
      "      - -197330.5888777462\n",
      "      - -199349.20591927582\n",
      "      - -199856.0154846867\n",
      "      - -202041.82337966328\n",
      "      - -201393.0752697383\n",
      "      - -198868.67962187697\n",
      "      - -199933.88008792693\n",
      "      - -197911.97295747756\n",
      "      - -201529.09755343306\n",
      "      - -198828.64228317194\n",
      "      - -195714.19981674475\n",
      "      - -200238.55070240382\n",
      "      - -196890.46817162362\n",
      "      - -200806.69910891645\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09448415625124355\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4683317251947615\n",
      "      mean_inference_ms: 0.9655912751994612\n",
      "      mean_raw_obs_processing_ms: 0.13450710223336138\n",
      "  time_since_restore: 1463.0194685459137\n",
      "  time_this_iter_s: 9.361503839492798\n",
      "  time_total_s: 1463.0194685459137\n",
      "  timers:\n",
      "    learn_throughput: 129114.648\n",
      "    learn_time_ms: 495.56\n",
      "    load_throughput: 21055268.528\n",
      "    load_time_ms: 3.039\n",
      "    training_iteration_time_ms: 9406.588\n",
      "    update_time_ms: 4.525\n",
      "  timestamp: 1665850211\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 9789552\n",
      "  training_iteration: 153\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:10:17 (running for 00:24:51.49)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   153</td><td style=\"text-align: right;\">         1463.02</td><td style=\"text-align: right;\">9789552</td><td style=\"text-align: right;\"> -199310</td><td style=\"text-align: right;\">             -194642</td><td style=\"text-align: right;\">             -209483</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 9853536\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 9853536\n",
      "    num_agent_steps_trained: 9853536\n",
      "    num_env_steps_sampled: 9853536\n",
      "    num_env_steps_trained: 9853536\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-10-21\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -194233.58558442918\n",
      "  episode_reward_mean: -200056.7403624933\n",
      "  episode_reward_min: -209999.51884579286\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 9852\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.127915382385254\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0007267030887305737\n",
      "          model: {}\n",
      "          policy_loss: 0.002065693959593773\n",
      "          total_loss: 10.001895904541016\n",
      "          vf_explained_var: -1.9868215517249155e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 9853536\n",
      "    num_agent_steps_trained: 9853536\n",
      "    num_env_steps_sampled: 9853536\n",
      "    num_env_steps_trained: 9853536\n",
      "  iterations_since_restore: 154\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 9853536\n",
      "  num_agent_steps_trained: 9853536\n",
      "  num_env_steps_sampled: 9853536\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 9853536\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.12307692307692\n",
      "    ram_util_percent: 87.30769230769229\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09446513485741068\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46820883567087745\n",
      "    mean_inference_ms: 0.9653663960233518\n",
      "    mean_raw_obs_processing_ms: 0.13436023977324266\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -194233.58558442918\n",
      "    episode_reward_mean: -200056.7403624933\n",
      "    episode_reward_min: -209999.51884579286\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -202252.45492130838\n",
      "      - -200955.69246243886\n",
      "      - -200204.06561218473\n",
      "      - -204640.38108848402\n",
      "      - -202408.031551252\n",
      "      - -197174.7079661833\n",
      "      - -200207.94061863702\n",
      "      - -202007.73697054476\n",
      "      - -199592.47865174984\n",
      "      - -199558.36637621257\n",
      "      - -199493.54380519426\n",
      "      - -199854.78376644506\n",
      "      - -209482.83940226174\n",
      "      - -200954.3499904364\n",
      "      - -197330.5888777462\n",
      "      - -199349.20591927582\n",
      "      - -199856.0154846867\n",
      "      - -202041.82337966328\n",
      "      - -201393.0752697383\n",
      "      - -198868.67962187697\n",
      "      - -199933.88008792693\n",
      "      - -197911.97295747756\n",
      "      - -201529.09755343306\n",
      "      - -198828.64228317194\n",
      "      - -195714.19981674475\n",
      "      - -200238.55070240382\n",
      "      - -196890.46817162362\n",
      "      - -200806.69910891645\n",
      "      - -194233.58558442918\n",
      "      - -200605.38928001525\n",
      "      - -199861.35829873258\n",
      "      - -198602.40069553544\n",
      "      - -202489.32322785328\n",
      "      - -199942.2264953835\n",
      "      - -199016.839068155\n",
      "      - -203498.7729475538\n",
      "      - -197161.30541060335\n",
      "      - -198093.81872359046\n",
      "      - -200495.77060998362\n",
      "      - -199608.94107890877\n",
      "      - -198550.93054601064\n",
      "      - -203722.57642236628\n",
      "      - -202206.74483116777\n",
      "      - -199167.21839796298\n",
      "      - -200126.94823780263\n",
      "      - -201108.78644615505\n",
      "      - -199072.31107995418\n",
      "      - -198217.50943267412\n",
      "      - -199207.68533863366\n",
      "      - -200759.4705298628\n",
      "      - -200115.90424725818\n",
      "      - -198170.53766138572\n",
      "      - -195930.9405169544\n",
      "      - -199932.86677594416\n",
      "      - -198673.34053941086\n",
      "      - -209438.45567830306\n",
      "      - -195977.18268659603\n",
      "      - -203878.43550543507\n",
      "      - -199180.26960939844\n",
      "      - -197511.19025293624\n",
      "      - -201609.3596178634\n",
      "      - -201317.4728965207\n",
      "      - -198961.08631289683\n",
      "      - -203233.98156458067\n",
      "      - -201564.3651727859\n",
      "      - -199740.9855198283\n",
      "      - -199462.41949361356\n",
      "      - -197585.9730167055\n",
      "      - -197793.12308051236\n",
      "      - -204791.96638665785\n",
      "      - -199299.7575330658\n",
      "      - -200851.472732556\n",
      "      - -200350.59428643022\n",
      "      - -197295.1741754313\n",
      "      - -200392.84114298082\n",
      "      - -201164.6598350943\n",
      "      - -195828.46721948017\n",
      "      - -196790.31352501025\n",
      "      - -199633.55122896837\n",
      "      - -201453.14249945484\n",
      "      - -196756.13946321496\n",
      "      - -199527.12658817312\n",
      "      - -196449.9071932521\n",
      "      - -201471.41637855596\n",
      "      - -200313.32752690368\n",
      "      - -200214.95041486286\n",
      "      - -198151.6535996868\n",
      "      - -200444.10028071445\n",
      "      - -200593.60746649408\n",
      "      - -203051.39389098086\n",
      "      - -198972.1323347631\n",
      "      - -195894.36187554855\n",
      "      - -200089.18793409705\n",
      "      - -198117.59567156577\n",
      "      - -199669.77911435033\n",
      "      - -205025.24074047225\n",
      "      - -209999.51884579286\n",
      "      - -199752.3222408194\n",
      "      - -199039.5216891445\n",
      "      - -198980.7371845254\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09446513485741068\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46820883567087745\n",
      "      mean_inference_ms: 0.9653663960233518\n",
      "      mean_raw_obs_processing_ms: 0.13436023977324266\n",
      "  time_since_restore: 1472.3725609779358\n",
      "  time_this_iter_s: 9.353092432022095\n",
      "  time_total_s: 1472.3725609779358\n",
      "  timers:\n",
      "    learn_throughput: 129439.273\n",
      "    learn_time_ms: 494.317\n",
      "    load_throughput: 20849649.394\n",
      "    load_time_ms: 3.069\n",
      "    training_iteration_time_ms: 9418.119\n",
      "    update_time_ms: 4.516\n",
      "  timestamp: 1665850221\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 9853536\n",
      "  training_iteration: 154\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:10:26 (running for 00:25:00.71)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   154</td><td style=\"text-align: right;\">         1472.37</td><td style=\"text-align: right;\">9853536</td><td style=\"text-align: right;\"> -200057</td><td style=\"text-align: right;\">             -194234</td><td style=\"text-align: right;\">             -210000</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 9917520\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 9917520\n",
      "    num_agent_steps_trained: 9917520\n",
      "    num_env_steps_sampled: 9917520\n",
      "    num_env_steps_trained: 9917520\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-10-30\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -195438.5450448174\n",
      "  episode_reward_mean: -200010.12247205857\n",
      "  episode_reward_min: -209999.51884579286\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 9912\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.121026039123535\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0007987250573933125\n",
      "          model: {}\n",
      "          policy_loss: 0.00635549845173955\n",
      "          total_loss: 10.006202697753906\n",
      "          vf_explained_var: -4.8251379780595016e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 9917520\n",
      "    num_agent_steps_trained: 9917520\n",
      "    num_env_steps_sampled: 9917520\n",
      "    num_env_steps_trained: 9917520\n",
      "  iterations_since_restore: 155\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 9917520\n",
      "  num_agent_steps_trained: 9917520\n",
      "  num_env_steps_sampled: 9917520\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 9917520\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 80.6846153846154\n",
      "    ram_util_percent: 87.29999999999998\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0944817831124548\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4680917157699899\n",
      "    mean_inference_ms: 0.9650439568186419\n",
      "    mean_raw_obs_processing_ms: 0.13451211976066088\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -195438.5450448174\n",
      "    episode_reward_mean: -200010.12247205857\n",
      "    episode_reward_min: -209999.51884579286\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -201609.3596178634\n",
      "      - -201317.4728965207\n",
      "      - -198961.08631289683\n",
      "      - -203233.98156458067\n",
      "      - -201564.3651727859\n",
      "      - -199740.9855198283\n",
      "      - -199462.41949361356\n",
      "      - -197585.9730167055\n",
      "      - -197793.12308051236\n",
      "      - -204791.96638665785\n",
      "      - -199299.7575330658\n",
      "      - -200851.472732556\n",
      "      - -200350.59428643022\n",
      "      - -197295.1741754313\n",
      "      - -200392.84114298082\n",
      "      - -201164.6598350943\n",
      "      - -195828.46721948017\n",
      "      - -196790.31352501025\n",
      "      - -199633.55122896837\n",
      "      - -201453.14249945484\n",
      "      - -196756.13946321496\n",
      "      - -199527.12658817312\n",
      "      - -196449.9071932521\n",
      "      - -201471.41637855596\n",
      "      - -200313.32752690368\n",
      "      - -200214.95041486286\n",
      "      - -198151.6535996868\n",
      "      - -200444.10028071445\n",
      "      - -200593.60746649408\n",
      "      - -203051.39389098086\n",
      "      - -198972.1323347631\n",
      "      - -195894.36187554855\n",
      "      - -200089.18793409705\n",
      "      - -198117.59567156577\n",
      "      - -199669.77911435033\n",
      "      - -205025.24074047225\n",
      "      - -209999.51884579286\n",
      "      - -199752.3222408194\n",
      "      - -199039.5216891445\n",
      "      - -198980.7371845254\n",
      "      - -201430.7981333926\n",
      "      - -196350.4533018784\n",
      "      - -199433.3020955341\n",
      "      - -202718.3358970297\n",
      "      - -198477.24018959916\n",
      "      - -199674.78214962134\n",
      "      - -196819.91436489628\n",
      "      - -200264.50021849744\n",
      "      - -196475.20581969817\n",
      "      - -204276.4991681518\n",
      "      - -198501.10401821576\n",
      "      - -199994.25183492032\n",
      "      - -198055.85241899264\n",
      "      - -200889.30059833318\n",
      "      - -200715.6808614157\n",
      "      - -199808.4367026808\n",
      "      - -201881.70388809708\n",
      "      - -200027.84802556798\n",
      "      - -198119.09666629843\n",
      "      - -197409.46308079644\n",
      "      - -203521.64271874056\n",
      "      - -201125.59818064692\n",
      "      - -202764.05997214388\n",
      "      - -199307.58365007874\n",
      "      - -199779.3325486984\n",
      "      - -201012.67702986058\n",
      "      - -198644.7598230442\n",
      "      - -199193.92950375442\n",
      "      - -195438.5450448174\n",
      "      - -202768.58314518243\n",
      "      - -196785.14957739634\n",
      "      - -200693.83937506747\n",
      "      - -197469.37176478605\n",
      "      - -203331.25696231416\n",
      "      - -202052.3906380308\n",
      "      - -197174.26962960785\n",
      "      - -202508.61907124342\n",
      "      - -204252.12891650898\n",
      "      - -201115.30969131846\n",
      "      - -198529.04009242964\n",
      "      - -197908.0022710668\n",
      "      - -199782.97168469563\n",
      "      - -199093.16713425124\n",
      "      - -204606.1010120854\n",
      "      - -198108.52304062227\n",
      "      - -199220.22712008827\n",
      "      - -204181.3880785951\n",
      "      - -195900.33803127456\n",
      "      - -201395.34494259118\n",
      "      - -204979.68433976063\n",
      "      - -201250.7365316129\n",
      "      - -198800.74545441204\n",
      "      - -200713.7758282552\n",
      "      - -199411.1129716748\n",
      "      - -198205.3431721026\n",
      "      - -200224.17056915667\n",
      "      - -200642.99932982176\n",
      "      - -199217.31388424087\n",
      "      - -199186.0006917615\n",
      "      - -197757.7166741441\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.0944817831124548\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4680917157699899\n",
      "      mean_inference_ms: 0.9650439568186419\n",
      "      mean_raw_obs_processing_ms: 0.13451211976066088\n",
      "  time_since_restore: 1481.273342370987\n",
      "  time_this_iter_s: 8.900781393051147\n",
      "  time_total_s: 1481.273342370987\n",
      "  timers:\n",
      "    learn_throughput: 129282.941\n",
      "    learn_time_ms: 494.914\n",
      "    load_throughput: 21009938.398\n",
      "    load_time_ms: 3.045\n",
      "    training_iteration_time_ms: 9373.482\n",
      "    update_time_ms: 4.662\n",
      "  timestamp: 1665850230\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 9917520\n",
      "  training_iteration: 155\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:10:35 (running for 00:25:10.18)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   155</td><td style=\"text-align: right;\">         1481.27</td><td style=\"text-align: right;\">9917520</td><td style=\"text-align: right;\"> -200010</td><td style=\"text-align: right;\">             -195439</td><td style=\"text-align: right;\">             -210000</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 9981504\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 9981504\n",
      "    num_agent_steps_trained: 9981504\n",
      "    num_env_steps_sampled: 9981504\n",
      "    num_env_steps_trained: 9981504\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-10-39\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -195356.6640955735\n",
      "  episode_reward_mean: -199587.9754430106\n",
      "  episode_reward_min: -206523.86991858747\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 9972\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1175124645233154\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0005672713159583509\n",
      "          model: {}\n",
      "          policy_loss: 0.004035801161080599\n",
      "          total_loss: 10.003835678100586\n",
      "          vf_explained_var: -1.6083793852317285e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 9981504\n",
      "    num_agent_steps_trained: 9981504\n",
      "    num_env_steps_sampled: 9981504\n",
      "    num_env_steps_trained: 9981504\n",
      "  iterations_since_restore: 156\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 9981504\n",
      "  num_agent_steps_trained: 9981504\n",
      "  num_env_steps_sampled: 9981504\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 9981504\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.43076923076924\n",
      "    ram_util_percent: 87.36923076923077\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09438946604073102\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4680071983240813\n",
      "    mean_inference_ms: 0.9643959268590985\n",
      "    mean_raw_obs_processing_ms: 0.1344589796967534\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -195356.6640955735\n",
      "    episode_reward_mean: -199587.9754430106\n",
      "    episode_reward_min: -206523.86991858747\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -203521.64271874056\n",
      "      - -201125.59818064692\n",
      "      - -202764.05997214388\n",
      "      - -199307.58365007874\n",
      "      - -199779.3325486984\n",
      "      - -201012.67702986058\n",
      "      - -198644.7598230442\n",
      "      - -199193.92950375442\n",
      "      - -195438.5450448174\n",
      "      - -202768.58314518243\n",
      "      - -196785.14957739634\n",
      "      - -200693.83937506747\n",
      "      - -197469.37176478605\n",
      "      - -203331.25696231416\n",
      "      - -202052.3906380308\n",
      "      - -197174.26962960785\n",
      "      - -202508.61907124342\n",
      "      - -204252.12891650898\n",
      "      - -201115.30969131846\n",
      "      - -198529.04009242964\n",
      "      - -197908.0022710668\n",
      "      - -199782.97168469563\n",
      "      - -199093.16713425124\n",
      "      - -204606.1010120854\n",
      "      - -198108.52304062227\n",
      "      - -199220.22712008827\n",
      "      - -204181.3880785951\n",
      "      - -195900.33803127456\n",
      "      - -201395.34494259118\n",
      "      - -204979.68433976063\n",
      "      - -201250.7365316129\n",
      "      - -198800.74545441204\n",
      "      - -200713.7758282552\n",
      "      - -199411.1129716748\n",
      "      - -198205.3431721026\n",
      "      - -200224.17056915667\n",
      "      - -200642.99932982176\n",
      "      - -199217.31388424087\n",
      "      - -199186.0006917615\n",
      "      - -197757.7166741441\n",
      "      - -197433.46021568408\n",
      "      - -199929.96386108838\n",
      "      - -199829.3077033828\n",
      "      - -200453.6015941436\n",
      "      - -201170.8842508329\n",
      "      - -199847.9743257735\n",
      "      - -199129.46106723524\n",
      "      - -196994.13419812176\n",
      "      - -198946.8262538552\n",
      "      - -197866.47276149213\n",
      "      - -201345.470105002\n",
      "      - -206523.86991858747\n",
      "      - -199643.42667780115\n",
      "      - -203394.97173754353\n",
      "      - -196357.36951493367\n",
      "      - -201357.24983431873\n",
      "      - -195356.6640955735\n",
      "      - -198382.6583241058\n",
      "      - -199430.49637473826\n",
      "      - -198336.32865018846\n",
      "      - -197289.78393425271\n",
      "      - -199042.32188355425\n",
      "      - -198993.09610928316\n",
      "      - -197343.55639223094\n",
      "      - -197823.25453744282\n",
      "      - -201280.75497686936\n",
      "      - -201312.1089816594\n",
      "      - -199476.09974024797\n",
      "      - -197316.44839560168\n",
      "      - -198085.5088918709\n",
      "      - -197861.54754660462\n",
      "      - -198027.95917494202\n",
      "      - -199956.35471469339\n",
      "      - -199935.60898532867\n",
      "      - -204038.981765343\n",
      "      - -198917.56682191446\n",
      "      - -197014.31918987617\n",
      "      - -197424.0493865303\n",
      "      - -195750.42698343605\n",
      "      - -199070.36359235592\n",
      "      - -197029.7442629306\n",
      "      - -197717.00806643587\n",
      "      - -202859.79423355262\n",
      "      - -200898.94515087185\n",
      "      - -197167.94990929696\n",
      "      - -197857.62681324637\n",
      "      - -198230.27148655354\n",
      "      - -199999.41928945982\n",
      "      - -196429.0383667798\n",
      "      - -197560.55941559537\n",
      "      - -197925.168340766\n",
      "      - -195738.13533783014\n",
      "      - -201182.50753874675\n",
      "      - -199177.4625544663\n",
      "      - -204126.16212694248\n",
      "      - -198814.7538370287\n",
      "      - -199903.36530479035\n",
      "      - -201728.47192432237\n",
      "      - -198037.74264209138\n",
      "      - -200668.96413302675\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09438946604073102\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4680071983240813\n",
      "      mean_inference_ms: 0.9643959268590985\n",
      "      mean_raw_obs_processing_ms: 0.1344589796967534\n",
      "  time_since_restore: 1490.02312374115\n",
      "  time_this_iter_s: 8.749781370162964\n",
      "  time_total_s: 1490.02312374115\n",
      "  timers:\n",
      "    learn_throughput: 130390.843\n",
      "    learn_time_ms: 490.709\n",
      "    load_throughput: 20874949.217\n",
      "    load_time_ms: 3.065\n",
      "    training_iteration_time_ms: 9281.437\n",
      "    update_time_ms: 4.531\n",
      "  timestamp: 1665850239\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 9981504\n",
      "  training_iteration: 156\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:10:44 (running for 00:25:19.13)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   156</td><td style=\"text-align: right;\">         1490.02</td><td style=\"text-align: right;\">9981504</td><td style=\"text-align: right;\"> -199588</td><td style=\"text-align: right;\">             -195357</td><td style=\"text-align: right;\">             -206524</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 10045488\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 10045488\n",
      "    num_agent_steps_trained: 10045488\n",
      "    num_env_steps_sampled: 10045488\n",
      "    num_env_steps_trained: 10045488\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-10-49\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -195738.13533783014\n",
      "  episode_reward_mean: -199321.24375281387\n",
      "  episode_reward_min: -205525.17424476283\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 10044\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.116053342819214\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0003286139399278909\n",
      "          model: {}\n",
      "          policy_loss: 0.0017261338653042912\n",
      "          total_loss: 10.001482009887695\n",
      "          vf_explained_var: -3.595200936956644e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 10045488\n",
      "    num_agent_steps_trained: 10045488\n",
      "    num_env_steps_sampled: 10045488\n",
      "    num_env_steps_trained: 10045488\n",
      "  iterations_since_restore: 157\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 10045488\n",
      "  num_agent_steps_trained: 10045488\n",
      "  num_env_steps_sampled: 10045488\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 10045488\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 85.66428571428571\n",
      "    ram_util_percent: 87.45714285714284\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09439552862525055\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46795259910698417\n",
      "    mean_inference_ms: 0.9643392418053273\n",
      "    mean_raw_obs_processing_ms: 0.13429879191815067\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -195738.13533783014\n",
      "    episode_reward_mean: -199321.24375281387\n",
      "    episode_reward_min: -205525.17424476283\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -199956.35471469339\n",
      "      - -199935.60898532867\n",
      "      - -204038.981765343\n",
      "      - -198917.56682191446\n",
      "      - -197014.31918987617\n",
      "      - -197424.0493865303\n",
      "      - -195750.42698343605\n",
      "      - -199070.36359235592\n",
      "      - -197029.7442629306\n",
      "      - -197717.00806643587\n",
      "      - -202859.79423355262\n",
      "      - -200898.94515087185\n",
      "      - -197167.94990929696\n",
      "      - -197857.62681324637\n",
      "      - -198230.27148655354\n",
      "      - -199999.41928945982\n",
      "      - -196429.0383667798\n",
      "      - -197560.55941559537\n",
      "      - -197925.168340766\n",
      "      - -195738.13533783014\n",
      "      - -201182.50753874675\n",
      "      - -199177.4625544663\n",
      "      - -204126.16212694248\n",
      "      - -198814.7538370287\n",
      "      - -199903.36530479035\n",
      "      - -201728.47192432237\n",
      "      - -198037.74264209138\n",
      "      - -200668.96413302675\n",
      "      - -199807.79691611978\n",
      "      - -198069.48964552366\n",
      "      - -196847.51993636103\n",
      "      - -199705.8107877079\n",
      "      - -196118.19414316103\n",
      "      - -198290.49231667013\n",
      "      - -196899.84713337253\n",
      "      - -197895.74258201217\n",
      "      - -197755.7778727379\n",
      "      - -197109.3554338678\n",
      "      - -199400.56066461743\n",
      "      - -197849.84252506832\n",
      "      - -199314.0095640452\n",
      "      - -200878.1352596537\n",
      "      - -200631.89988299954\n",
      "      - -199054.9951709629\n",
      "      - -197559.88124442656\n",
      "      - -196804.64986947525\n",
      "      - -198633.6049550801\n",
      "      - -196384.1571085705\n",
      "      - -199256.56638233326\n",
      "      - -200480.7863078813\n",
      "      - -198174.14035879\n",
      "      - -197603.51207532312\n",
      "      - -201760.48087710518\n",
      "      - -197860.32595788004\n",
      "      - -199414.88555044876\n",
      "      - -200805.49589745604\n",
      "      - -198792.50665273372\n",
      "      - -199602.36396160125\n",
      "      - -200040.9518787725\n",
      "      - -204171.79015927823\n",
      "      - -199530.49554177304\n",
      "      - -196557.48168452937\n",
      "      - -202641.43270893814\n",
      "      - -198993.0070843948\n",
      "      - -201934.48406372787\n",
      "      - -197873.85094071744\n",
      "      - -200253.0327273772\n",
      "      - -200646.24839121397\n",
      "      - -199545.18482952905\n",
      "      - -199942.92488812617\n",
      "      - -200961.65716737407\n",
      "      - -200274.77875047844\n",
      "      - -199730.07438326057\n",
      "      - -197401.78399478144\n",
      "      - -197798.32533163586\n",
      "      - -201421.61083725543\n",
      "      - -203223.8500205202\n",
      "      - -199597.3935927904\n",
      "      - -200741.04033198074\n",
      "      - -198425.6649857112\n",
      "      - -199511.41305304426\n",
      "      - -202289.35044688138\n",
      "      - -199924.35083512918\n",
      "      - -198744.47394231556\n",
      "      - -197557.67912624375\n",
      "      - -197099.64363610416\n",
      "      - -202858.52558893326\n",
      "      - -196693.58489880923\n",
      "      - -197156.57145855052\n",
      "      - -205525.17424476283\n",
      "      - -200944.1255580039\n",
      "      - -199296.12089575143\n",
      "      - -199522.0214925589\n",
      "      - -200770.33944315807\n",
      "      - -200273.95987087037\n",
      "      - -199173.56388504966\n",
      "      - -202019.8167655452\n",
      "      - -197831.80972120946\n",
      "      - -200370.77338878266\n",
      "      - -198930.4235273145\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09439552862525055\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46795259910698417\n",
      "      mean_inference_ms: 0.9643392418053273\n",
      "      mean_raw_obs_processing_ms: 0.13429879191815067\n",
      "  time_since_restore: 1499.9946506023407\n",
      "  time_this_iter_s: 9.971526861190796\n",
      "  time_total_s: 1499.9946506023407\n",
      "  timers:\n",
      "    learn_throughput: 130803.39\n",
      "    learn_time_ms: 489.162\n",
      "    load_throughput: 20834434.216\n",
      "    load_time_ms: 3.071\n",
      "    training_iteration_time_ms: 9344.253\n",
      "    update_time_ms: 4.368\n",
      "  timestamp: 1665850249\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 10045488\n",
      "  training_iteration: 157\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:10:55 (running for 00:25:29.42)<br>Memory usage on this node: 13.6/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   157</td><td style=\"text-align: right;\">         1499.99</td><td style=\"text-align: right;\">10045488</td><td style=\"text-align: right;\"> -199321</td><td style=\"text-align: right;\">             -195738</td><td style=\"text-align: right;\">             -205525</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 10109472\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 10109472\n",
      "    num_agent_steps_trained: 10109472\n",
      "    num_env_steps_sampled: 10109472\n",
      "    num_env_steps_trained: 10109472\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-10-58\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -195208.8152929717\n",
      "  episode_reward_mean: -199284.96814004224\n",
      "  episode_reward_min: -205525.17424476283\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 10104\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1218769550323486\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0007208576425909996\n",
      "          model: {}\n",
      "          policy_loss: 0.0065614921040833\n",
      "          total_loss: 10.006392478942871\n",
      "          vf_explained_var: -3.7844220202032375e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 10109472\n",
      "    num_agent_steps_trained: 10109472\n",
      "    num_env_steps_sampled: 10109472\n",
      "    num_env_steps_trained: 10109472\n",
      "  iterations_since_restore: 158\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 10109472\n",
      "  num_agent_steps_trained: 10109472\n",
      "  num_env_steps_sampled: 10109472\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 10109472\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 80.85000000000001\n",
      "    ram_util_percent: 87.59285714285714\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0944130386249148\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46784423888580023\n",
      "    mean_inference_ms: 0.964645398798868\n",
      "    mean_raw_obs_processing_ms: 0.13445095897522708\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -195208.8152929717\n",
      "    episode_reward_mean: -199284.96814004224\n",
      "    episode_reward_min: -205525.17424476283\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -199530.49554177304\n",
      "      - -196557.48168452937\n",
      "      - -202641.43270893814\n",
      "      - -198993.0070843948\n",
      "      - -201934.48406372787\n",
      "      - -197873.85094071744\n",
      "      - -200253.0327273772\n",
      "      - -200646.24839121397\n",
      "      - -199545.18482952905\n",
      "      - -199942.92488812617\n",
      "      - -200961.65716737407\n",
      "      - -200274.77875047844\n",
      "      - -199730.07438326057\n",
      "      - -197401.78399478144\n",
      "      - -197798.32533163586\n",
      "      - -201421.61083725543\n",
      "      - -203223.8500205202\n",
      "      - -199597.3935927904\n",
      "      - -200741.04033198074\n",
      "      - -198425.6649857112\n",
      "      - -199511.41305304426\n",
      "      - -202289.35044688138\n",
      "      - -199924.35083512918\n",
      "      - -198744.47394231556\n",
      "      - -197557.67912624375\n",
      "      - -197099.64363610416\n",
      "      - -202858.52558893326\n",
      "      - -196693.58489880923\n",
      "      - -197156.57145855052\n",
      "      - -205525.17424476283\n",
      "      - -200944.1255580039\n",
      "      - -199296.12089575143\n",
      "      - -199522.0214925589\n",
      "      - -200770.33944315807\n",
      "      - -200273.95987087037\n",
      "      - -199173.56388504966\n",
      "      - -202019.8167655452\n",
      "      - -197831.80972120946\n",
      "      - -200370.77338878266\n",
      "      - -198930.4235273145\n",
      "      - -204547.45568398654\n",
      "      - -199792.2287200021\n",
      "      - -196623.51238348056\n",
      "      - -199222.34086634277\n",
      "      - -198769.56787659382\n",
      "      - -205208.1580355734\n",
      "      - -197068.71336729932\n",
      "      - -198832.7282850023\n",
      "      - -200923.60012804443\n",
      "      - -198655.50568389293\n",
      "      - -201314.28000125464\n",
      "      - -196647.87922547836\n",
      "      - -196865.1786039336\n",
      "      - -196658.01063042734\n",
      "      - -199201.10826991737\n",
      "      - -195208.8152929717\n",
      "      - -200447.5356789443\n",
      "      - -202320.65820974176\n",
      "      - -197741.63540353652\n",
      "      - -199584.7603673734\n",
      "      - -200140.72900957445\n",
      "      - -200694.04261439652\n",
      "      - -197901.12824401198\n",
      "      - -199961.48490812903\n",
      "      - -198165.1356923158\n",
      "      - -198126.91561910472\n",
      "      - -197722.04886216292\n",
      "      - -197954.174221404\n",
      "      - -196729.34813622743\n",
      "      - -197251.79064945437\n",
      "      - -197124.4602784134\n",
      "      - -199610.90588127857\n",
      "      - -198909.77094899665\n",
      "      - -199109.77246989412\n",
      "      - -200009.9926667418\n",
      "      - -198843.59567059003\n",
      "      - -196219.2028793581\n",
      "      - -201275.8942122886\n",
      "      - -198669.32282626553\n",
      "      - -200421.17891424647\n",
      "      - -202137.78967385067\n",
      "      - -203813.0539425451\n",
      "      - -198899.52831873824\n",
      "      - -199626.33429381513\n",
      "      - -196878.87046727652\n",
      "      - -195954.5117695235\n",
      "      - -197655.24837975547\n",
      "      - -196582.77032338816\n",
      "      - -198408.43589758992\n",
      "      - -199914.49295390304\n",
      "      - -197442.36808490503\n",
      "      - -196927.6777801249\n",
      "      - -195331.04145871103\n",
      "      - -196871.18961546163\n",
      "      - -198410.20260848143\n",
      "      - -201834.8709996329\n",
      "      - -198829.69159008743\n",
      "      - -201074.32994729\n",
      "      - -199700.2980596598\n",
      "      - -197741.49638569713\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.0944130386249148\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46784423888580023\n",
      "      mean_inference_ms: 0.964645398798868\n",
      "      mean_raw_obs_processing_ms: 0.13445095897522708\n",
      "  time_since_restore: 1509.4246590137482\n",
      "  time_this_iter_s: 9.43000841140747\n",
      "  time_total_s: 1509.4246590137482\n",
      "  timers:\n",
      "    learn_throughput: 131160.581\n",
      "    learn_time_ms: 487.829\n",
      "    load_throughput: 20803102.783\n",
      "    load_time_ms: 3.076\n",
      "    training_iteration_time_ms: 9342.184\n",
      "    update_time_ms: 4.288\n",
      "  timestamp: 1665850258\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 10109472\n",
      "  training_iteration: 158\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:11:04 (running for 00:25:38.42)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   158</td><td style=\"text-align: right;\">         1509.42</td><td style=\"text-align: right;\">10109472</td><td style=\"text-align: right;\"> -199285</td><td style=\"text-align: right;\">             -195209</td><td style=\"text-align: right;\">             -205525</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:11:09 (running for 00:25:43.52)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   158</td><td style=\"text-align: right;\">         1509.42</td><td style=\"text-align: right;\">10109472</td><td style=\"text-align: right;\"> -199285</td><td style=\"text-align: right;\">             -195209</td><td style=\"text-align: right;\">             -205525</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 10173456\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 10173456\n",
      "    num_agent_steps_trained: 10173456\n",
      "    num_env_steps_sampled: 10173456\n",
      "    num_env_steps_trained: 10173456\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-11-09\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -194155.09407436397\n",
      "  episode_reward_mean: -198858.55293734334\n",
      "  episode_reward_min: -242361.0525847031\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 10164\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.119784355163574\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0007980816881172359\n",
      "          model: {}\n",
      "          policy_loss: 0.00438212975859642\n",
      "          total_loss: 10.004228591918945\n",
      "          vf_explained_var: -3.973643103449831e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 10173456\n",
      "    num_agent_steps_trained: 10173456\n",
      "    num_env_steps_sampled: 10173456\n",
      "    num_env_steps_trained: 10173456\n",
      "  iterations_since_restore: 159\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 10173456\n",
      "  num_agent_steps_trained: 10173456\n",
      "  num_env_steps_sampled: 10173456\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 10173456\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 85.91428571428571\n",
      "    ram_util_percent: 87.53571428571429\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09437948429485866\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46793025967054797\n",
      "    mean_inference_ms: 0.9649719149033444\n",
      "    mean_raw_obs_processing_ms: 0.1344485015798961\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -194155.09407436397\n",
      "    episode_reward_mean: -198858.55293734334\n",
      "    episode_reward_min: -242361.0525847031\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -200140.72900957445\n",
      "      - -200694.04261439652\n",
      "      - -197901.12824401198\n",
      "      - -199961.48490812903\n",
      "      - -198165.1356923158\n",
      "      - -198126.91561910472\n",
      "      - -197722.04886216292\n",
      "      - -197954.174221404\n",
      "      - -196729.34813622743\n",
      "      - -197251.79064945437\n",
      "      - -197124.4602784134\n",
      "      - -199610.90588127857\n",
      "      - -198909.77094899665\n",
      "      - -199109.77246989412\n",
      "      - -200009.9926667418\n",
      "      - -198843.59567059003\n",
      "      - -196219.2028793581\n",
      "      - -201275.8942122886\n",
      "      - -198669.32282626553\n",
      "      - -200421.17891424647\n",
      "      - -202137.78967385067\n",
      "      - -203813.0539425451\n",
      "      - -198899.52831873824\n",
      "      - -199626.33429381513\n",
      "      - -196878.87046727652\n",
      "      - -195954.5117695235\n",
      "      - -197655.24837975547\n",
      "      - -196582.77032338816\n",
      "      - -198408.43589758992\n",
      "      - -199914.49295390304\n",
      "      - -197442.36808490503\n",
      "      - -196927.6777801249\n",
      "      - -195331.04145871103\n",
      "      - -196871.18961546163\n",
      "      - -198410.20260848143\n",
      "      - -201834.8709996329\n",
      "      - -198829.69159008743\n",
      "      - -201074.32994729\n",
      "      - -199700.2980596598\n",
      "      - -197741.49638569713\n",
      "      - -202145.12270071817\n",
      "      - -199222.00370279368\n",
      "      - -201708.09845960012\n",
      "      - -200739.9000217812\n",
      "      - -196721.52245514648\n",
      "      - -197261.09263510254\n",
      "      - -197865.00670516526\n",
      "      - -200244.98381750725\n",
      "      - -242361.0525847031\n",
      "      - -199060.41255695152\n",
      "      - -197696.21327055368\n",
      "      - -197590.03803062238\n",
      "      - -199527.86481238395\n",
      "      - -201471.55446559575\n",
      "      - -201297.3976552195\n",
      "      - -198189.5384976727\n",
      "      - -198646.05656183508\n",
      "      - -198838.0597210393\n",
      "      - -197606.0751129676\n",
      "      - -195129.65515451736\n",
      "      - -199576.69287982586\n",
      "      - -196535.6922884121\n",
      "      - -198918.71021425354\n",
      "      - -194155.09407436397\n",
      "      - -198339.37280996412\n",
      "      - -201319.86625974503\n",
      "      - -196958.99185697545\n",
      "      - -197142.670917138\n",
      "      - -197464.8270256696\n",
      "      - -198721.0156936728\n",
      "      - -197498.9053501171\n",
      "      - -195549.41233200475\n",
      "      - -197858.47467593703\n",
      "      - -197820.22327155175\n",
      "      - -197209.38805851387\n",
      "      - -199469.9798919964\n",
      "      - -196758.21598106957\n",
      "      - -197522.73876684823\n",
      "      - -195810.45508009533\n",
      "      - -198815.6320028074\n",
      "      - -199589.00532560874\n",
      "      - -197076.43726909385\n",
      "      - -198688.851530982\n",
      "      - -197135.136406883\n",
      "      - -198247.6397315311\n",
      "      - -196087.21276113563\n",
      "      - -196642.3175733322\n",
      "      - -198867.69069367842\n",
      "      - -197967.38818613708\n",
      "      - -195413.54959390286\n",
      "      - -199313.95797737862\n",
      "      - -198290.79068634618\n",
      "      - -200433.80142118307\n",
      "      - -196184.97344940776\n",
      "      - -198681.09823247668\n",
      "      - -200511.1410965822\n",
      "      - -197558.57418153842\n",
      "      - -198732.26425543972\n",
      "      - -194701.43674539978\n",
      "      - -200088.92100816482\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09437948429485866\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46793025967054797\n",
      "      mean_inference_ms: 0.9649719149033444\n",
      "      mean_raw_obs_processing_ms: 0.1344485015798961\n",
      "  time_since_restore: 1519.7056386470795\n",
      "  time_this_iter_s: 10.280979633331299\n",
      "  time_total_s: 1519.7056386470795\n",
      "  timers:\n",
      "    learn_throughput: 131691.193\n",
      "    learn_time_ms: 485.864\n",
      "    load_throughput: 20667725.368\n",
      "    load_time_ms: 3.096\n",
      "    training_iteration_time_ms: 9409.108\n",
      "    update_time_ms: 4.103\n",
      "  timestamp: 1665850269\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 10173456\n",
      "  training_iteration: 159\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:11:14 (running for 00:25:48.73)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   159</td><td style=\"text-align: right;\">         1519.71</td><td style=\"text-align: right;\">10173456</td><td style=\"text-align: right;\"> -198859</td><td style=\"text-align: right;\">             -194155</td><td style=\"text-align: right;\">             -242361</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 10237440\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 10237440\n",
      "    num_agent_steps_trained: 10237440\n",
      "    num_env_steps_sampled: 10237440\n",
      "    num_env_steps_trained: 10237440\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-11-18\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -194453.7405588477\n",
      "  episode_reward_mean: -198084.55429129858\n",
      "  episode_reward_min: -202092.78432049896\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 10236\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.115691900253296\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0008745538652874529\n",
      "          model: {}\n",
      "          policy_loss: 0.0009801475098356605\n",
      "          total_loss: 10.000845909118652\n",
      "          vf_explained_var: -3.500590395333347e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 10237440\n",
      "    num_agent_steps_trained: 10237440\n",
      "    num_env_steps_sampled: 10237440\n",
      "    num_env_steps_trained: 10237440\n",
      "  iterations_since_restore: 160\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 10237440\n",
      "  num_agent_steps_trained: 10237440\n",
      "  num_env_steps_sampled: 10237440\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 10237440\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 84.32307692307693\n",
      "    ram_util_percent: 87.45384615384616\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09439345846347895\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4680413619624393\n",
      "    mean_inference_ms: 0.9650399630160965\n",
      "    mean_raw_obs_processing_ms: 0.1343032290582799\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -194453.7405588477\n",
      "    episode_reward_mean: -198084.55429129858\n",
      "    episode_reward_min: -202092.78432049896\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -197858.47467593703\n",
      "      - -197820.22327155175\n",
      "      - -197209.38805851387\n",
      "      - -199469.9798919964\n",
      "      - -196758.21598106957\n",
      "      - -197522.73876684823\n",
      "      - -195810.45508009533\n",
      "      - -198815.6320028074\n",
      "      - -199589.00532560874\n",
      "      - -197076.43726909385\n",
      "      - -198688.851530982\n",
      "      - -197135.136406883\n",
      "      - -198247.6397315311\n",
      "      - -196087.21276113563\n",
      "      - -196642.3175733322\n",
      "      - -198867.69069367842\n",
      "      - -197967.38818613708\n",
      "      - -195413.54959390286\n",
      "      - -199313.95797737862\n",
      "      - -198290.79068634618\n",
      "      - -200433.80142118307\n",
      "      - -196184.97344940776\n",
      "      - -198681.09823247668\n",
      "      - -200511.1410965822\n",
      "      - -197558.57418153842\n",
      "      - -198732.26425543972\n",
      "      - -194701.43674539978\n",
      "      - -200088.92100816482\n",
      "      - -196590.80133447397\n",
      "      - -201768.68936123792\n",
      "      - -196496.76091273205\n",
      "      - -197496.81617589304\n",
      "      - -195780.9861525752\n",
      "      - -197064.70131363874\n",
      "      - -196355.5955585995\n",
      "      - -196736.7348999498\n",
      "      - -200843.7266867405\n",
      "      - -198273.87284998604\n",
      "      - -198598.8628456044\n",
      "      - -197382.78392162002\n",
      "      - -200381.8472840499\n",
      "      - -196879.89495659835\n",
      "      - -198958.72197404178\n",
      "      - -196052.59293761099\n",
      "      - -198393.0397090484\n",
      "      - -197737.91317994145\n",
      "      - -199098.6114820499\n",
      "      - -196085.65519692644\n",
      "      - -197457.43501847124\n",
      "      - -197291.14738366046\n",
      "      - -198502.31878337948\n",
      "      - -197266.1185389055\n",
      "      - -200885.2438932163\n",
      "      - -199250.60384315572\n",
      "      - -197636.83510247903\n",
      "      - -196547.17714823922\n",
      "      - -197781.89218735264\n",
      "      - -199162.17288412355\n",
      "      - -199464.16732228114\n",
      "      - -199736.58468310657\n",
      "      - -197828.3876695881\n",
      "      - -199248.1088617396\n",
      "      - -197554.22310320285\n",
      "      - -202092.78432049896\n",
      "      - -196100.21656273585\n",
      "      - -196404.96228086445\n",
      "      - -196195.44070362236\n",
      "      - -200003.54934347924\n",
      "      - -196632.22843083553\n",
      "      - -198713.44109671167\n",
      "      - -195622.2313373432\n",
      "      - -198625.45120029364\n",
      "      - -198081.54984023748\n",
      "      - -195477.8885458102\n",
      "      - -198807.6196088636\n",
      "      - -198328.6994502495\n",
      "      - -200063.79956894397\n",
      "      - -201466.72846553603\n",
      "      - -200484.11629159423\n",
      "      - -197858.1035030192\n",
      "      - -196892.83971014016\n",
      "      - -197025.64439628655\n",
      "      - -199843.33749191274\n",
      "      - -199720.48665042635\n",
      "      - -199317.03186885527\n",
      "      - -198831.91342292685\n",
      "      - -196120.77517526486\n",
      "      - -194453.7405588477\n",
      "      - -196219.82670093077\n",
      "      - -197463.28440653853\n",
      "      - -197131.64944090642\n",
      "      - -200470.56296391413\n",
      "      - -197533.88252878893\n",
      "      - -197271.25343601994\n",
      "      - -199029.1949764029\n",
      "      - -201289.18343609106\n",
      "      - -197075.49368982587\n",
      "      - -200139.7576419803\n",
      "      - -198108.59456453435\n",
      "      - -199489.8445073853\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09439345846347895\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4680413619624393\n",
      "      mean_inference_ms: 0.9650399630160965\n",
      "      mean_raw_obs_processing_ms: 0.1343032290582799\n",
      "  time_since_restore: 1529.2597575187683\n",
      "  time_this_iter_s: 9.554118871688843\n",
      "  time_total_s: 1529.2597575187683\n",
      "  timers:\n",
      "    learn_throughput: 132641.369\n",
      "    learn_time_ms: 482.383\n",
      "    load_throughput: 20617233.795\n",
      "    load_time_ms: 3.103\n",
      "    training_iteration_time_ms: 9418.711\n",
      "    update_time_ms: 4.268\n",
      "  timestamp: 1665850278\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 10237440\n",
      "  training_iteration: 160\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:11:24 (running for 00:25:58.50)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   160</td><td style=\"text-align: right;\">         1529.26</td><td style=\"text-align: right;\">10237440</td><td style=\"text-align: right;\"> -198085</td><td style=\"text-align: right;\">             -194454</td><td style=\"text-align: right;\">             -202093</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 10301424\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 10301424\n",
      "    num_agent_steps_trained: 10301424\n",
      "    num_env_steps_sampled: 10301424\n",
      "    num_env_steps_trained: 10301424\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-11-28\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -194453.7405588477\n",
      "  episode_reward_mean: -198250.99709146097\n",
      "  episode_reward_min: -202092.78432049896\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 10296\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.11318302154541\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0006486301426775753\n",
      "          model: {}\n",
      "          policy_loss: 0.006604866124689579\n",
      "          total_loss: 10.006421089172363\n",
      "          vf_explained_var: -3.0275376872168636e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 10301424\n",
      "    num_agent_steps_trained: 10301424\n",
      "    num_env_steps_sampled: 10301424\n",
      "    num_env_steps_trained: 10301424\n",
      "  iterations_since_restore: 161\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 10301424\n",
      "  num_agent_steps_trained: 10301424\n",
      "  num_env_steps_sampled: 10301424\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 10301424\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 80.37692307692308\n",
      "    ram_util_percent: 87.41538461538462\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09442606528533663\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4680797860324655\n",
      "    mean_inference_ms: 0.9648662278218636\n",
      "    mean_raw_obs_processing_ms: 0.13445585472398888\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -194453.7405588477\n",
      "    episode_reward_mean: -198250.99709146097\n",
      "    episode_reward_min: -202092.78432049896\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -197828.3876695881\n",
      "      - -199248.1088617396\n",
      "      - -197554.22310320285\n",
      "      - -202092.78432049896\n",
      "      - -196100.21656273585\n",
      "      - -196404.96228086445\n",
      "      - -196195.44070362236\n",
      "      - -200003.54934347924\n",
      "      - -196632.22843083553\n",
      "      - -198713.44109671167\n",
      "      - -195622.2313373432\n",
      "      - -198625.45120029364\n",
      "      - -198081.54984023748\n",
      "      - -195477.8885458102\n",
      "      - -198807.6196088636\n",
      "      - -198328.6994502495\n",
      "      - -200063.79956894397\n",
      "      - -201466.72846553603\n",
      "      - -200484.11629159423\n",
      "      - -197858.1035030192\n",
      "      - -196892.83971014016\n",
      "      - -197025.64439628655\n",
      "      - -199843.33749191274\n",
      "      - -199720.48665042635\n",
      "      - -199317.03186885527\n",
      "      - -198831.91342292685\n",
      "      - -196120.77517526486\n",
      "      - -194453.7405588477\n",
      "      - -196219.82670093077\n",
      "      - -197463.28440653853\n",
      "      - -197131.64944090642\n",
      "      - -200470.56296391413\n",
      "      - -197533.88252878893\n",
      "      - -197271.25343601994\n",
      "      - -199029.1949764029\n",
      "      - -201289.18343609106\n",
      "      - -197075.49368982587\n",
      "      - -200139.7576419803\n",
      "      - -198108.59456453435\n",
      "      - -199489.8445073853\n",
      "      - -196740.1482835068\n",
      "      - -199077.21787736344\n",
      "      - -197674.81286169708\n",
      "      - -196729.37867433226\n",
      "      - -195846.92081706604\n",
      "      - -197777.83628238912\n",
      "      - -196409.95085902343\n",
      "      - -197851.45559273486\n",
      "      - -198045.34814280368\n",
      "      - -198249.0698403484\n",
      "      - -197369.02303435872\n",
      "      - -198235.28508504693\n",
      "      - -197749.58760819797\n",
      "      - -199138.40861741608\n",
      "      - -198723.94111341416\n",
      "      - -199323.7333036163\n",
      "      - -196677.74025405012\n",
      "      - -200589.63353157163\n",
      "      - -196689.18935125932\n",
      "      - -199573.58661345753\n",
      "      - -200257.25775196136\n",
      "      - -196188.13953507107\n",
      "      - -201867.49058031468\n",
      "      - -198896.10951091093\n",
      "      - -197409.23922072252\n",
      "      - -197017.60886131917\n",
      "      - -197288.04025135373\n",
      "      - -200032.42086066992\n",
      "      - -198351.3594375999\n",
      "      - -199000.73901059318\n",
      "      - -197429.1843743678\n",
      "      - -199125.47423701774\n",
      "      - -197937.7892936261\n",
      "      - -199749.2771365654\n",
      "      - -198125.4845329751\n",
      "      - -199700.61032684252\n",
      "      - -200774.9536783949\n",
      "      - -198795.3598719495\n",
      "      - -199617.55757265093\n",
      "      - -195392.89593046886\n",
      "      - -201209.15960292306\n",
      "      - -196544.75289355993\n",
      "      - -195973.28687721136\n",
      "      - -197562.11411401365\n",
      "      - -199627.2048779104\n",
      "      - -197616.5872754834\n",
      "      - -201134.61172942456\n",
      "      - -197111.78835300074\n",
      "      - -195867.8872446266\n",
      "      - -197646.15254300562\n",
      "      - -199754.40217879848\n",
      "      - -197261.7055284842\n",
      "      - -199708.1596851217\n",
      "      - -199298.33412836771\n",
      "      - -198190.30139127516\n",
      "      - -196652.94034637848\n",
      "      - -196339.83609253002\n",
      "      - -198979.87049262028\n",
      "      - -200736.834236266\n",
      "      - -197436.69208292087\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09442606528533663\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4680797860324655\n",
      "      mean_inference_ms: 0.9648662278218636\n",
      "      mean_raw_obs_processing_ms: 0.13445585472398888\n",
      "  time_since_restore: 1538.4676666259766\n",
      "  time_this_iter_s: 9.207909107208252\n",
      "  time_total_s: 1538.4676666259766\n",
      "  timers:\n",
      "    learn_throughput: 132020.152\n",
      "    learn_time_ms: 484.653\n",
      "    load_throughput: 21405081.286\n",
      "    load_time_ms: 2.989\n",
      "    training_iteration_time_ms: 9395.335\n",
      "    update_time_ms: 4.534\n",
      "  timestamp: 1665850288\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 10301424\n",
      "  training_iteration: 161\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:11:33 (running for 00:26:07.57)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   161</td><td style=\"text-align: right;\">         1538.47</td><td style=\"text-align: right;\">10301424</td><td style=\"text-align: right;\"> -198251</td><td style=\"text-align: right;\">             -194454</td><td style=\"text-align: right;\">             -202093</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 10365408\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 10365408\n",
      "    num_agent_steps_trained: 10365408\n",
      "    num_env_steps_sampled: 10365408\n",
      "    num_env_steps_trained: 10365408\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-11-37\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -194890.70996811907\n",
      "  episode_reward_mean: -198246.60891001284\n",
      "  episode_reward_min: -202369.45779289262\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 10356\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1150782108306885\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0010350811062380672\n",
      "          model: {}\n",
      "          policy_loss: 0.004132954403758049\n",
      "          total_loss: 10.004027366638184\n",
      "          vf_explained_var: -3.689811478579941e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 10365408\n",
      "    num_agent_steps_trained: 10365408\n",
      "    num_env_steps_sampled: 10365408\n",
      "    num_env_steps_trained: 10365408\n",
      "  iterations_since_restore: 162\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 10365408\n",
      "  num_agent_steps_trained: 10365408\n",
      "  num_env_steps_sampled: 10365408\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 10365408\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.43846153846154\n",
      "    ram_util_percent: 87.45384615384616\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0943478220225348\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4680888653267567\n",
      "    mean_inference_ms: 0.9646936632727423\n",
      "    mean_raw_obs_processing_ms: 0.13442016970060583\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -194890.70996811907\n",
      "    episode_reward_mean: -198246.60891001284\n",
      "    episode_reward_min: -202369.45779289262\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -200257.25775196136\n",
      "      - -196188.13953507107\n",
      "      - -201867.49058031468\n",
      "      - -198896.10951091093\n",
      "      - -197409.23922072252\n",
      "      - -197017.60886131917\n",
      "      - -197288.04025135373\n",
      "      - -200032.42086066992\n",
      "      - -198351.3594375999\n",
      "      - -199000.73901059318\n",
      "      - -197429.1843743678\n",
      "      - -199125.47423701774\n",
      "      - -197937.7892936261\n",
      "      - -199749.2771365654\n",
      "      - -198125.4845329751\n",
      "      - -199700.61032684252\n",
      "      - -200774.9536783949\n",
      "      - -198795.3598719495\n",
      "      - -199617.55757265093\n",
      "      - -195392.89593046886\n",
      "      - -201209.15960292306\n",
      "      - -196544.75289355993\n",
      "      - -195973.28687721136\n",
      "      - -197562.11411401365\n",
      "      - -199627.2048779104\n",
      "      - -197616.5872754834\n",
      "      - -201134.61172942456\n",
      "      - -197111.78835300074\n",
      "      - -195867.8872446266\n",
      "      - -197646.15254300562\n",
      "      - -199754.40217879848\n",
      "      - -197261.7055284842\n",
      "      - -199708.1596851217\n",
      "      - -199298.33412836771\n",
      "      - -198190.30139127516\n",
      "      - -196652.94034637848\n",
      "      - -196339.83609253002\n",
      "      - -198979.87049262028\n",
      "      - -200736.834236266\n",
      "      - -197436.69208292087\n",
      "      - -196321.76575697522\n",
      "      - -196616.25470318363\n",
      "      - -201627.64541317103\n",
      "      - -199290.77381376695\n",
      "      - -198303.5325708096\n",
      "      - -197806.91273692125\n",
      "      - -200397.47675708696\n",
      "      - -198323.47635779635\n",
      "      - -198690.3833517298\n",
      "      - -198972.7515144256\n",
      "      - -198307.61917403867\n",
      "      - -197445.60436997676\n",
      "      - -200531.02985520425\n",
      "      - -198308.56975415527\n",
      "      - -200248.9507727891\n",
      "      - -198268.18151818187\n",
      "      - -196279.3303953737\n",
      "      - -199080.97271629566\n",
      "      - -201156.67387028402\n",
      "      - -194985.2031351791\n",
      "      - -196656.78012680958\n",
      "      - -195298.27502017136\n",
      "      - -196763.1227280767\n",
      "      - -198913.88208629293\n",
      "      - -197385.1393693097\n",
      "      - -199003.14432089656\n",
      "      - -195029.35982871364\n",
      "      - -196589.88546035776\n",
      "      - -196736.79409311654\n",
      "      - -194890.70996811907\n",
      "      - -197627.83380101202\n",
      "      - -198457.70343857308\n",
      "      - -202369.45779289262\n",
      "      - -195780.6927758706\n",
      "      - -198768.0965567709\n",
      "      - -196700.19414803167\n",
      "      - -198970.71777005686\n",
      "      - -199581.08953599396\n",
      "      - -198474.1542870049\n",
      "      - -197120.73214354287\n",
      "      - -196148.58908821276\n",
      "      - -196500.09281759415\n",
      "      - -200353.96623093347\n",
      "      - -198163.0524698946\n",
      "      - -198181.7583744628\n",
      "      - -199429.77442179533\n",
      "      - -197139.98811020076\n",
      "      - -198503.61238168567\n",
      "      - -199477.31352559116\n",
      "      - -197392.67677346827\n",
      "      - -198001.94031075155\n",
      "      - -197532.8918874282\n",
      "      - -198568.83360293586\n",
      "      - -198648.743684173\n",
      "      - -197162.82494298965\n",
      "      - -197173.37158317512\n",
      "      - -198506.8820263495\n",
      "      - -198872.21030282637\n",
      "      - -197631.2298539976\n",
      "      - -201580.65117455952\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.0943478220225348\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4680888653267567\n",
      "      mean_inference_ms: 0.9646936632727423\n",
      "      mean_raw_obs_processing_ms: 0.13442016970060583\n",
      "  time_since_restore: 1547.8157863616943\n",
      "  time_this_iter_s: 9.348119735717773\n",
      "  time_total_s: 1547.8157863616943\n",
      "  timers:\n",
      "    learn_throughput: 131942.108\n",
      "    learn_time_ms: 484.94\n",
      "    load_throughput: 21406617.941\n",
      "    load_time_ms: 2.989\n",
      "    training_iteration_time_ms: 9408.861\n",
      "    update_time_ms: 4.614\n",
      "  timestamp: 1665850297\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 10365408\n",
      "  training_iteration: 162\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:11:43 (running for 00:26:17.46)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   162</td><td style=\"text-align: right;\">         1547.82</td><td style=\"text-align: right;\">10365408</td><td style=\"text-align: right;\"> -198247</td><td style=\"text-align: right;\">             -194891</td><td style=\"text-align: right;\">             -202369</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 10429392\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 10429392\n",
      "    num_agent_steps_trained: 10429392\n",
      "    num_env_steps_sampled: 10429392\n",
      "    num_env_steps_trained: 10429392\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-11-46\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -193896.71237851284\n",
      "  episode_reward_mean: -198668.728497174\n",
      "  episode_reward_min: -248903.2964942603\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 10428\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.113553762435913\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0003499123267829418\n",
      "          model: {}\n",
      "          policy_loss: 0.0019027820089831948\n",
      "          total_loss: 10.00166130065918\n",
      "          vf_explained_var: -2.838316426334586e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 10429392\n",
      "    num_agent_steps_trained: 10429392\n",
      "    num_env_steps_sampled: 10429392\n",
      "    num_env_steps_trained: 10429392\n",
      "  iterations_since_restore: 163\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 10429392\n",
      "  num_agent_steps_trained: 10429392\n",
      "  num_env_steps_sampled: 10429392\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 10429392\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.99230769230768\n",
      "    ram_util_percent: 87.40769230769232\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09431359974132007\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4679981016492441\n",
      "    mean_inference_ms: 0.9645533200259897\n",
      "    mean_raw_obs_processing_ms: 0.13423776423044237\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -193896.71237851284\n",
      "    episode_reward_mean: -198668.728497174\n",
      "    episode_reward_min: -248903.2964942603\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -202369.45779289262\n",
      "      - -195780.6927758706\n",
      "      - -198768.0965567709\n",
      "      - -196700.19414803167\n",
      "      - -198970.71777005686\n",
      "      - -199581.08953599396\n",
      "      - -198474.1542870049\n",
      "      - -197120.73214354287\n",
      "      - -196148.58908821276\n",
      "      - -196500.09281759415\n",
      "      - -200353.96623093347\n",
      "      - -198163.0524698946\n",
      "      - -198181.7583744628\n",
      "      - -199429.77442179533\n",
      "      - -197139.98811020076\n",
      "      - -198503.61238168567\n",
      "      - -199477.31352559116\n",
      "      - -197392.67677346827\n",
      "      - -198001.94031075155\n",
      "      - -197532.8918874282\n",
      "      - -198568.83360293586\n",
      "      - -198648.743684173\n",
      "      - -197162.82494298965\n",
      "      - -197173.37158317512\n",
      "      - -198506.8820263495\n",
      "      - -198872.21030282637\n",
      "      - -197631.2298539976\n",
      "      - -201580.65117455952\n",
      "      - -201432.12969763306\n",
      "      - -195927.56478140032\n",
      "      - -200410.4815656014\n",
      "      - -197073.27567258888\n",
      "      - -200204.55164016096\n",
      "      - -198796.3910253216\n",
      "      - -199468.85430185983\n",
      "      - -198296.25071558164\n",
      "      - -196426.5972920791\n",
      "      - -203483.6474530592\n",
      "      - -196717.76321859646\n",
      "      - -198328.82065296485\n",
      "      - -199075.1078271841\n",
      "      - -200285.98271637975\n",
      "      - -199861.81647603275\n",
      "      - -196264.34830927374\n",
      "      - -196253.2011211417\n",
      "      - -198676.84654942705\n",
      "      - -199628.12374715146\n",
      "      - -197225.9579913774\n",
      "      - -196575.4949671501\n",
      "      - -197228.92027858703\n",
      "      - -195559.46275492368\n",
      "      - -194856.42541200772\n",
      "      - -199356.28407942405\n",
      "      - -197890.34890774835\n",
      "      - -196179.9486805\n",
      "      - -197357.76684488248\n",
      "      - -199600.79562838748\n",
      "      - -196559.6369638542\n",
      "      - -197414.1736918093\n",
      "      - -196808.04568623076\n",
      "      - -200090.89734377136\n",
      "      - -199159.21467092857\n",
      "      - -196858.757445574\n",
      "      - -199204.4555913313\n",
      "      - -196281.32900408265\n",
      "      - -199474.3079906775\n",
      "      - -199118.50468852642\n",
      "      - -197038.70144731438\n",
      "      - -193896.71237851284\n",
      "      - -197428.11332420784\n",
      "      - -197567.47707984678\n",
      "      - -199884.7119148848\n",
      "      - -196286.97637941508\n",
      "      - -201223.68282676823\n",
      "      - -197618.29382840815\n",
      "      - -199985.2003105121\n",
      "      - -196199.81566448478\n",
      "      - -197977.18081300572\n",
      "      - -248903.2964942603\n",
      "      - -199874.0013408472\n",
      "      - -197426.7225666234\n",
      "      - -197622.63068903823\n",
      "      - -197579.28530722493\n",
      "      - -197513.33284644852\n",
      "      - -196079.46750720462\n",
      "      - -196893.7148141376\n",
      "      - -197105.4415353894\n",
      "      - -196908.6602254674\n",
      "      - -199975.7385128082\n",
      "      - -198171.92327976838\n",
      "      - -199748.28819052395\n",
      "      - -197284.4771896745\n",
      "      - -198167.6076623196\n",
      "      - -197164.02616122822\n",
      "      - -199769.48782231967\n",
      "      - -195033.06740831013\n",
      "      - -202170.50053942145\n",
      "      - -201498.04690606458\n",
      "      - -196939.05575234286\n",
      "      - -197789.18904020847\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09431359974132007\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4679981016492441\n",
      "      mean_inference_ms: 0.9645533200259897\n",
      "      mean_raw_obs_processing_ms: 0.13423776423044237\n",
      "  time_since_restore: 1557.2187650203705\n",
      "  time_this_iter_s: 9.402978658676147\n",
      "  time_total_s: 1557.2187650203705\n",
      "  timers:\n",
      "    learn_throughput: 131924.92\n",
      "    learn_time_ms: 485.003\n",
      "    load_throughput: 21397913.149\n",
      "    load_time_ms: 2.99\n",
      "    training_iteration_time_ms: 9412.92\n",
      "    update_time_ms: 4.589\n",
      "  timestamp: 1665850306\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 10429392\n",
      "  training_iteration: 163\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:11:52 (running for 00:26:26.86)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   163</td><td style=\"text-align: right;\">         1557.22</td><td style=\"text-align: right;\">10429392</td><td style=\"text-align: right;\"> -198669</td><td style=\"text-align: right;\">             -193897</td><td style=\"text-align: right;\">             -248903</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 10493376\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 10493376\n",
      "    num_agent_steps_trained: 10493376\n",
      "    num_env_steps_sampled: 10493376\n",
      "    num_env_steps_trained: 10493376\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-11-56\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -193896.71237851284\n",
      "  episode_reward_mean: -198415.31761053362\n",
      "  episode_reward_min: -248903.2964942603\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 10488\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1123604774475098\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.000938701443374157\n",
      "          model: {}\n",
      "          policy_loss: 0.006767977494746447\n",
      "          total_loss: 10.006644248962402\n",
      "          vf_explained_var: -3.689811478579941e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 10493376\n",
      "    num_agent_steps_trained: 10493376\n",
      "    num_env_steps_sampled: 10493376\n",
      "    num_env_steps_trained: 10493376\n",
      "  iterations_since_restore: 164\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 10493376\n",
      "  num_agent_steps_trained: 10493376\n",
      "  num_env_steps_sampled: 10493376\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 10493376\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.57692307692308\n",
      "    ram_util_percent: 87.46153846153847\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09435193967928242\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46788262952137877\n",
      "    mean_inference_ms: 0.9645806455583036\n",
      "    mean_raw_obs_processing_ms: 0.13442049306165665\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -193896.71237851284\n",
      "    episode_reward_mean: -198415.31761053362\n",
      "    episode_reward_min: -248903.2964942603\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -200090.89734377136\n",
      "      - -199159.21467092857\n",
      "      - -196858.757445574\n",
      "      - -199204.4555913313\n",
      "      - -196281.32900408265\n",
      "      - -199474.3079906775\n",
      "      - -199118.50468852642\n",
      "      - -197038.70144731438\n",
      "      - -193896.71237851284\n",
      "      - -197428.11332420784\n",
      "      - -197567.47707984678\n",
      "      - -199884.7119148848\n",
      "      - -196286.97637941508\n",
      "      - -201223.68282676823\n",
      "      - -197618.29382840815\n",
      "      - -199985.2003105121\n",
      "      - -196199.81566448478\n",
      "      - -197977.18081300572\n",
      "      - -248903.2964942603\n",
      "      - -199874.0013408472\n",
      "      - -197426.7225666234\n",
      "      - -197622.63068903823\n",
      "      - -197579.28530722493\n",
      "      - -197513.33284644852\n",
      "      - -196079.46750720462\n",
      "      - -196893.7148141376\n",
      "      - -197105.4415353894\n",
      "      - -196908.6602254674\n",
      "      - -199975.7385128082\n",
      "      - -198171.92327976838\n",
      "      - -199748.28819052395\n",
      "      - -197284.4771896745\n",
      "      - -198167.6076623196\n",
      "      - -197164.02616122822\n",
      "      - -199769.48782231967\n",
      "      - -195033.06740831013\n",
      "      - -202170.50053942145\n",
      "      - -201498.04690606458\n",
      "      - -196939.05575234286\n",
      "      - -197789.18904020847\n",
      "      - -198043.45024939612\n",
      "      - -195742.97337685974\n",
      "      - -198100.46825965095\n",
      "      - -196300.592489091\n",
      "      - -198665.96390669624\n",
      "      - -198377.73567816094\n",
      "      - -197003.58671659767\n",
      "      - -197889.47156045027\n",
      "      - -197663.3935924093\n",
      "      - -194438.71115170952\n",
      "      - -197390.34021423128\n",
      "      - -196397.6901294743\n",
      "      - -199791.6006768644\n",
      "      - -199500.34295550635\n",
      "      - -198835.84597719507\n",
      "      - -196927.82519108607\n",
      "      - -196210.5632089364\n",
      "      - -201918.83522353592\n",
      "      - -196320.17501881692\n",
      "      - -197719.19143766118\n",
      "      - -195929.6380917483\n",
      "      - -197654.6439667159\n",
      "      - -198641.9446891213\n",
      "      - -197656.66410588156\n",
      "      - -198927.65936994733\n",
      "      - -196814.68327603673\n",
      "      - -197705.95333473838\n",
      "      - -197104.87679666842\n",
      "      - -197462.49309541658\n",
      "      - -197925.75345359766\n",
      "      - -198394.42602052164\n",
      "      - -200883.834658528\n",
      "      - -197933.48398229753\n",
      "      - -200305.99281052887\n",
      "      - -197535.08786066022\n",
      "      - -196528.71251916979\n",
      "      - -198241.41565359812\n",
      "      - -194591.21316618612\n",
      "      - -195603.51306072346\n",
      "      - -199572.12891178674\n",
      "      - -196981.07554805314\n",
      "      - -197455.7587907183\n",
      "      - -198488.8446539331\n",
      "      - -199137.33594757784\n",
      "      - -200596.4026257381\n",
      "      - -197358.20557306212\n",
      "      - -197955.03819203502\n",
      "      - -198638.15106756572\n",
      "      - -197382.49094765962\n",
      "      - -195967.81548997088\n",
      "      - -199062.26903514058\n",
      "      - -197972.32775449005\n",
      "      - -198549.25592258584\n",
      "      - -197899.31467403396\n",
      "      - -197731.51440674174\n",
      "      - -197403.65989375254\n",
      "      - -197755.36593722113\n",
      "      - -196834.1806439443\n",
      "      - -198939.00610082978\n",
      "      - -195858.57751621905\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09435193967928242\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46788262952137877\n",
      "      mean_inference_ms: 0.9645806455583036\n",
      "      mean_raw_obs_processing_ms: 0.13442049306165665\n",
      "  time_since_restore: 1566.6139430999756\n",
      "  time_this_iter_s: 9.395178079605103\n",
      "  time_total_s: 1566.6139430999756\n",
      "  timers:\n",
      "    learn_throughput: 131929.576\n",
      "    learn_time_ms: 484.986\n",
      "    load_throughput: 21856413.719\n",
      "    load_time_ms: 2.927\n",
      "    training_iteration_time_ms: 9417.096\n",
      "    update_time_ms: 4.625\n",
      "  timestamp: 1665850316\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 10493376\n",
      "  training_iteration: 164\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:12:01 (running for 00:26:36.09)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   164</td><td style=\"text-align: right;\">         1566.61</td><td style=\"text-align: right;\">10493376</td><td style=\"text-align: right;\"> -198415</td><td style=\"text-align: right;\">             -193897</td><td style=\"text-align: right;\">             -248903</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 10557360\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 10557360\n",
      "    num_agent_steps_trained: 10557360\n",
      "    num_env_steps_sampled: 10557360\n",
      "    num_env_steps_trained: 10557360\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-12-05\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -194021.80270128074\n",
      "  episode_reward_mean: -197753.8030649573\n",
      "  episode_reward_min: -202251.53184361034\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 10548\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1087310314178467\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0006352157215587795\n",
      "          model: {}\n",
      "          policy_loss: 0.004688762594014406\n",
      "          total_loss: 10.004504203796387\n",
      "          vf_explained_var: -8.514949634275126e-09\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 10557360\n",
      "    num_agent_steps_trained: 10557360\n",
      "    num_env_steps_sampled: 10557360\n",
      "    num_env_steps_trained: 10557360\n",
      "  iterations_since_restore: 165\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 10557360\n",
      "  num_agent_steps_trained: 10557360\n",
      "  num_env_steps_sampled: 10557360\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 10557360\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 85.13076923076923\n",
      "    ram_util_percent: 87.43846153846152\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09428810909734862\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4678611892684876\n",
      "    mean_inference_ms: 0.9645653945838905\n",
      "    mean_raw_obs_processing_ms: 0.13439763903035298\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -194021.80270128074\n",
      "    episode_reward_mean: -197753.8030649573\n",
      "    episode_reward_min: -202251.53184361034\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -195929.6380917483\n",
      "      - -197654.6439667159\n",
      "      - -198641.9446891213\n",
      "      - -197656.66410588156\n",
      "      - -198927.65936994733\n",
      "      - -196814.68327603673\n",
      "      - -197705.95333473838\n",
      "      - -197104.87679666842\n",
      "      - -197462.49309541658\n",
      "      - -197925.75345359766\n",
      "      - -198394.42602052164\n",
      "      - -200883.834658528\n",
      "      - -197933.48398229753\n",
      "      - -200305.99281052887\n",
      "      - -197535.08786066022\n",
      "      - -196528.71251916979\n",
      "      - -198241.41565359812\n",
      "      - -194591.21316618612\n",
      "      - -195603.51306072346\n",
      "      - -199572.12891178674\n",
      "      - -196981.07554805314\n",
      "      - -197455.7587907183\n",
      "      - -198488.8446539331\n",
      "      - -199137.33594757784\n",
      "      - -200596.4026257381\n",
      "      - -197358.20557306212\n",
      "      - -197955.03819203502\n",
      "      - -198638.15106756572\n",
      "      - -197382.49094765962\n",
      "      - -195967.81548997088\n",
      "      - -199062.26903514058\n",
      "      - -197972.32775449005\n",
      "      - -198549.25592258584\n",
      "      - -197899.31467403396\n",
      "      - -197731.51440674174\n",
      "      - -197403.65989375254\n",
      "      - -197755.36593722113\n",
      "      - -196834.1806439443\n",
      "      - -198939.00610082978\n",
      "      - -195858.57751621905\n",
      "      - -200017.3976239376\n",
      "      - -202251.53184361034\n",
      "      - -197408.70286847543\n",
      "      - -197587.0516682962\n",
      "      - -196806.13738740108\n",
      "      - -200343.30528667688\n",
      "      - -195643.00554600835\n",
      "      - -201789.5745280192\n",
      "      - -198921.47459133808\n",
      "      - -196883.56627617\n",
      "      - -199067.52729930566\n",
      "      - -196308.96523584303\n",
      "      - -198130.31097713835\n",
      "      - -196508.60956316406\n",
      "      - -197430.03035214718\n",
      "      - -198541.87970084912\n",
      "      - -196466.27395918587\n",
      "      - -198930.2535905287\n",
      "      - -195191.8967635427\n",
      "      - -198319.81422282904\n",
      "      - -199440.01841641197\n",
      "      - -200107.28272793003\n",
      "      - -196920.33932309804\n",
      "      - -198991.66663192163\n",
      "      - -197238.80905906358\n",
      "      - -197144.78148904478\n",
      "      - -199536.59653135075\n",
      "      - -196147.3633639396\n",
      "      - -197458.36578722927\n",
      "      - -195607.6042890187\n",
      "      - -195712.11048244414\n",
      "      - -196613.89786365672\n",
      "      - -199186.19223912928\n",
      "      - -195846.96154138594\n",
      "      - -197765.61346723643\n",
      "      - -194021.80270128074\n",
      "      - -197413.7491917193\n",
      "      - -199192.2010701986\n",
      "      - -196741.42341157512\n",
      "      - -196301.83352341453\n",
      "      - -198284.84002972362\n",
      "      - -197253.43370656276\n",
      "      - -197861.44131192344\n",
      "      - -197986.51039445077\n",
      "      - -197111.51369799342\n",
      "      - -200172.2788818753\n",
      "      - -197039.83163448764\n",
      "      - -198263.9400985979\n",
      "      - -197133.41602790618\n",
      "      - -196214.3533170807\n",
      "      - -195345.79033108987\n",
      "      - -198548.91625644863\n",
      "      - -196393.11072492978\n",
      "      - -200300.9793475852\n",
      "      - -199351.8003045837\n",
      "      - -196257.64183900156\n",
      "      - -195074.05252417724\n",
      "      - -198046.99459366695\n",
      "      - -196326.56439554304\n",
      "      - -199096.26513744323\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09428810909734862\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4678611892684876\n",
      "      mean_inference_ms: 0.9645653945838905\n",
      "      mean_raw_obs_processing_ms: 0.13439763903035298\n",
      "  time_since_restore: 1576.0380973815918\n",
      "  time_this_iter_s: 9.424154281616211\n",
      "  time_total_s: 1576.0380973815918\n",
      "  timers:\n",
      "    learn_throughput: 132353.944\n",
      "    learn_time_ms: 483.431\n",
      "    load_throughput: 21865673.78\n",
      "    load_time_ms: 2.926\n",
      "    training_iteration_time_ms: 9469.419\n",
      "    update_time_ms: 4.424\n",
      "  timestamp: 1665850325\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 10557360\n",
      "  training_iteration: 165\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:12:10 (running for 00:26:45.35)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   165</td><td style=\"text-align: right;\">         1576.04</td><td style=\"text-align: right;\">10557360</td><td style=\"text-align: right;\"> -197754</td><td style=\"text-align: right;\">             -194022</td><td style=\"text-align: right;\">             -202252</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 10621344\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 10621344\n",
      "    num_agent_steps_trained: 10621344\n",
      "    num_env_steps_sampled: 10621344\n",
      "    num_env_steps_trained: 10621344\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-12-15\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -194021.80270128074\n",
      "  episode_reward_mean: -197487.88401411052\n",
      "  episode_reward_min: -200786.876909628\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 10620\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1101484298706055\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0004835179715882987\n",
      "          model: {}\n",
      "          policy_loss: 0.0013674204237759113\n",
      "          total_loss: 10.001152992248535\n",
      "          vf_explained_var: -3.879032561826534e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 10621344\n",
      "    num_agent_steps_trained: 10621344\n",
      "    num_env_steps_sampled: 10621344\n",
      "    num_env_steps_trained: 10621344\n",
      "  iterations_since_restore: 166\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 10621344\n",
      "  num_agent_steps_trained: 10621344\n",
      "  num_env_steps_sampled: 10621344\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 10621344\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 78.69285714285715\n",
      "    ram_util_percent: 87.42857142857143\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09427169756669063\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4678803301779031\n",
      "    mean_inference_ms: 0.9644688771537365\n",
      "    mean_raw_obs_processing_ms: 0.13422832933589265\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -194021.80270128074\n",
      "    episode_reward_mean: -197487.88401411052\n",
      "    episode_reward_min: -200786.876909628\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -199186.19223912928\n",
      "      - -195846.96154138594\n",
      "      - -197765.61346723643\n",
      "      - -194021.80270128074\n",
      "      - -197413.7491917193\n",
      "      - -199192.2010701986\n",
      "      - -196741.42341157512\n",
      "      - -196301.83352341453\n",
      "      - -198284.84002972362\n",
      "      - -197253.43370656276\n",
      "      - -197861.44131192344\n",
      "      - -197986.51039445077\n",
      "      - -197111.51369799342\n",
      "      - -200172.2788818753\n",
      "      - -197039.83163448764\n",
      "      - -198263.9400985979\n",
      "      - -197133.41602790618\n",
      "      - -196214.3533170807\n",
      "      - -195345.79033108987\n",
      "      - -198548.91625644863\n",
      "      - -196393.11072492978\n",
      "      - -200300.9793475852\n",
      "      - -199351.8003045837\n",
      "      - -196257.64183900156\n",
      "      - -195074.05252417724\n",
      "      - -198046.99459366695\n",
      "      - -196326.56439554304\n",
      "      - -199096.26513744323\n",
      "      - -198477.76465564102\n",
      "      - -196507.182277374\n",
      "      - -195705.10242330047\n",
      "      - -195211.164315297\n",
      "      - -195971.55235160096\n",
      "      - -197109.02352234354\n",
      "      - -197171.04302280207\n",
      "      - -199594.92418580933\n",
      "      - -199762.95072721964\n",
      "      - -196938.6526473268\n",
      "      - -199030.38795705425\n",
      "      - -197556.02336235932\n",
      "      - -197928.14795581726\n",
      "      - -196133.36680355185\n",
      "      - -198411.33329839015\n",
      "      - -199237.62937262654\n",
      "      - -195236.24555128257\n",
      "      - -198584.35341327946\n",
      "      - -199452.7674725474\n",
      "      - -197904.1174649618\n",
      "      - -196612.64403960004\n",
      "      - -197673.2862062009\n",
      "      - -198497.7308124395\n",
      "      - -197906.0618495208\n",
      "      - -198765.73853219635\n",
      "      - -198085.68372304333\n",
      "      - -196195.89190415907\n",
      "      - -195157.02545543257\n",
      "      - -196590.0114271597\n",
      "      - -198688.2528047934\n",
      "      - -198149.29562636875\n",
      "      - -197886.60747956694\n",
      "      - -196837.717936338\n",
      "      - -197780.03942905882\n",
      "      - -196130.75698666062\n",
      "      - -197963.76475927385\n",
      "      - -199425.83455967155\n",
      "      - -199079.8956768381\n",
      "      - -195554.3571670147\n",
      "      - -196263.88858800818\n",
      "      - -195731.39322614245\n",
      "      - -196751.17245603955\n",
      "      - -199049.83375397557\n",
      "      - -197694.36482689882\n",
      "      - -197127.13877642356\n",
      "      - -198054.35049463643\n",
      "      - -198485.85643746136\n",
      "      - -198130.32775098106\n",
      "      - -196857.16337544977\n",
      "      - -198237.51111876348\n",
      "      - -194641.26019197438\n",
      "      - -197704.4713350644\n",
      "      - -197170.420179213\n",
      "      - -196961.81099636192\n",
      "      - -197415.4867257339\n",
      "      - -195501.41440464978\n",
      "      - -195844.1338537287\n",
      "      - -197445.74606748906\n",
      "      - -197227.4520534575\n",
      "      - -200591.24120715196\n",
      "      - -196999.10363528115\n",
      "      - -198111.58428081262\n",
      "      - -195013.85439928056\n",
      "      - -197710.1602894515\n",
      "      - -197774.12331915175\n",
      "      - -197838.1754577802\n",
      "      - -198811.5792470433\n",
      "      - -198202.88381588677\n",
      "      - -196710.1624000308\n",
      "      - -197395.56821517437\n",
      "      - -200786.876909628\n",
      "      - -197110.1107649966\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09427169756669063\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4678803301779031\n",
      "      mean_inference_ms: 0.9644688771537365\n",
      "      mean_raw_obs_processing_ms: 0.13422832933589265\n",
      "  time_since_restore: 1585.5342071056366\n",
      "  time_this_iter_s: 9.4961097240448\n",
      "  time_total_s: 1585.5342071056366\n",
      "  timers:\n",
      "    learn_throughput: 132474.563\n",
      "    learn_time_ms: 482.991\n",
      "    load_throughput: 21825840.088\n",
      "    load_time_ms: 2.932\n",
      "    training_iteration_time_ms: 9543.705\n",
      "    update_time_ms: 4.526\n",
      "  timestamp: 1665850335\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 10621344\n",
      "  training_iteration: 166\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:12:20 (running for 00:26:55.06)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   166</td><td style=\"text-align: right;\">         1585.53</td><td style=\"text-align: right;\">10621344</td><td style=\"text-align: right;\"> -197488</td><td style=\"text-align: right;\">             -194022</td><td style=\"text-align: right;\">             -200787</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 10685328\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 10685328\n",
      "    num_agent_steps_trained: 10685328\n",
      "    num_env_steps_sampled: 10685328\n",
      "    num_env_steps_trained: 10685328\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-12-24\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -194131.7308952869\n",
      "  episode_reward_mean: -197452.4135881642\n",
      "  episode_reward_min: -201855.51595320358\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 10680\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.106598138809204\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0008236956782639027\n",
      "          model: {}\n",
      "          policy_loss: 0.006949682254344225\n",
      "          total_loss: 10.006803512573242\n",
      "          vf_explained_var: -3.7844220202032375e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 10685328\n",
      "    num_agent_steps_trained: 10685328\n",
      "    num_env_steps_sampled: 10685328\n",
      "    num_env_steps_trained: 10685328\n",
      "  iterations_since_restore: 167\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 10685328\n",
      "  num_agent_steps_trained: 10685328\n",
      "  num_env_steps_sampled: 10685328\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 10685328\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.08461538461538\n",
      "    ram_util_percent: 87.4\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09431867734973219\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46783665268061386\n",
      "    mean_inference_ms: 0.964586825453408\n",
      "    mean_raw_obs_processing_ms: 0.134391607895564\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -194131.7308952869\n",
      "    episode_reward_mean: -197452.4135881642\n",
      "    episode_reward_min: -201855.51595320358\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -196837.717936338\n",
      "      - -197780.03942905882\n",
      "      - -196130.75698666062\n",
      "      - -197963.76475927385\n",
      "      - -199425.83455967155\n",
      "      - -199079.8956768381\n",
      "      - -195554.3571670147\n",
      "      - -196263.88858800818\n",
      "      - -195731.39322614245\n",
      "      - -196751.17245603955\n",
      "      - -199049.83375397557\n",
      "      - -197694.36482689882\n",
      "      - -197127.13877642356\n",
      "      - -198054.35049463643\n",
      "      - -198485.85643746136\n",
      "      - -198130.32775098106\n",
      "      - -196857.16337544977\n",
      "      - -198237.51111876348\n",
      "      - -194641.26019197438\n",
      "      - -197704.4713350644\n",
      "      - -197170.420179213\n",
      "      - -196961.81099636192\n",
      "      - -197415.4867257339\n",
      "      - -195501.41440464978\n",
      "      - -195844.1338537287\n",
      "      - -197445.74606748906\n",
      "      - -197227.4520534575\n",
      "      - -200591.24120715196\n",
      "      - -196999.10363528115\n",
      "      - -198111.58428081262\n",
      "      - -195013.85439928056\n",
      "      - -197710.1602894515\n",
      "      - -197774.12331915175\n",
      "      - -197838.1754577802\n",
      "      - -198811.5792470433\n",
      "      - -198202.88381588677\n",
      "      - -196710.1624000308\n",
      "      - -197395.56821517437\n",
      "      - -200786.876909628\n",
      "      - -197110.1107649966\n",
      "      - -200552.4338625176\n",
      "      - -199199.97749323343\n",
      "      - -194370.31139308983\n",
      "      - -196767.10034827417\n",
      "      - -197596.94609262477\n",
      "      - -196198.55922232772\n",
      "      - -201295.70577536878\n",
      "      - -196436.40946534136\n",
      "      - -197698.05694195718\n",
      "      - -195628.42079793205\n",
      "      - -198256.30656569047\n",
      "      - -196534.47890472348\n",
      "      - -198909.55587257503\n",
      "      - -198264.866985114\n",
      "      - -198027.07639059523\n",
      "      - -196021.5115287115\n",
      "      - -200456.93136583088\n",
      "      - -194131.7308952869\n",
      "      - -198429.14775594402\n",
      "      - -196344.27334390397\n",
      "      - -197926.68456791993\n",
      "      - -194836.3832789099\n",
      "      - -197128.44117833403\n",
      "      - -201855.51595320358\n",
      "      - -197347.11159886335\n",
      "      - -195812.63509104526\n",
      "      - -196453.8702851609\n",
      "      - -197247.6973046598\n",
      "      - -199716.96948476398\n",
      "      - -194365.740135973\n",
      "      - -198270.0733446235\n",
      "      - -196991.50414924757\n",
      "      - -197126.65636100536\n",
      "      - -198905.0515471265\n",
      "      - -195183.62858795273\n",
      "      - -197206.4626588635\n",
      "      - -198633.14381345213\n",
      "      - -196304.35333113724\n",
      "      - -195909.38816901646\n",
      "      - -197691.0381869938\n",
      "      - -199029.34315634213\n",
      "      - -197453.43553362865\n",
      "      - -197368.10744422875\n",
      "      - -198816.8088522825\n",
      "      - -198394.896254656\n",
      "      - -197651.2634635199\n",
      "      - -199338.68928385657\n",
      "      - -197677.41162541878\n",
      "      - -199357.27170104077\n",
      "      - -197410.85538531153\n",
      "      - -195195.99781817032\n",
      "      - -201580.64538787332\n",
      "      - -194753.07711105864\n",
      "      - -196946.53892070462\n",
      "      - -198322.38924639634\n",
      "      - -196899.05040865767\n",
      "      - -195922.45283879113\n",
      "      - -198386.7008857644\n",
      "      - -195061.505976523\n",
      "      - -195519.78042391886\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09431867734973219\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46783665268061386\n",
      "      mean_inference_ms: 0.964586825453408\n",
      "      mean_raw_obs_processing_ms: 0.134391607895564\n",
      "  time_since_restore: 1595.0537881851196\n",
      "  time_this_iter_s: 9.519581079483032\n",
      "  time_total_s: 1595.0537881851196\n",
      "  timers:\n",
      "    learn_throughput: 133373.098\n",
      "    learn_time_ms: 479.737\n",
      "    load_throughput: 21875476.617\n",
      "    load_time_ms: 2.925\n",
      "    training_iteration_time_ms: 9498.55\n",
      "    update_time_ms: 4.598\n",
      "  timestamp: 1665850344\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 10685328\n",
      "  training_iteration: 167\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:12:30 (running for 00:27:04.42)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   167</td><td style=\"text-align: right;\">         1595.05</td><td style=\"text-align: right;\">10685328</td><td style=\"text-align: right;\"> -197452</td><td style=\"text-align: right;\">             -194132</td><td style=\"text-align: right;\">             -201856</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 10749312\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 10749312\n",
      "    num_agent_steps_trained: 10749312\n",
      "    num_env_steps_sampled: 10749312\n",
      "    num_env_steps_trained: 10749312\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-12-34\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -194150.80209364172\n",
      "  episode_reward_mean: -197410.25051873512\n",
      "  episode_reward_min: -206428.70224828395\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 10740\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1059858798980713\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0005427315481938422\n",
      "          model: {}\n",
      "          policy_loss: 0.0049897003918886185\n",
      "          total_loss: 10.00478744506836\n",
      "          vf_explained_var: -1.8922110101016187e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 10749312\n",
      "    num_agent_steps_trained: 10749312\n",
      "    num_env_steps_sampled: 10749312\n",
      "    num_env_steps_trained: 10749312\n",
      "  iterations_since_restore: 168\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 10749312\n",
      "  num_agent_steps_trained: 10749312\n",
      "  num_env_steps_sampled: 10749312\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 10749312\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.35384615384615\n",
      "    ram_util_percent: 87.4\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09425736236616064\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4678166549572613\n",
      "    mean_inference_ms: 0.9645800695331894\n",
      "    mean_raw_obs_processing_ms: 0.1343699264588478\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -194150.80209364172\n",
      "    episode_reward_mean: -197410.25051873512\n",
      "    episode_reward_min: -206428.70224828395\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -197926.68456791993\n",
      "      - -194836.3832789099\n",
      "      - -197128.44117833403\n",
      "      - -201855.51595320358\n",
      "      - -197347.11159886335\n",
      "      - -195812.63509104526\n",
      "      - -196453.8702851609\n",
      "      - -197247.6973046598\n",
      "      - -199716.96948476398\n",
      "      - -194365.740135973\n",
      "      - -198270.0733446235\n",
      "      - -196991.50414924757\n",
      "      - -197126.65636100536\n",
      "      - -198905.0515471265\n",
      "      - -195183.62858795273\n",
      "      - -197206.4626588635\n",
      "      - -198633.14381345213\n",
      "      - -196304.35333113724\n",
      "      - -195909.38816901646\n",
      "      - -197691.0381869938\n",
      "      - -199029.34315634213\n",
      "      - -197453.43553362865\n",
      "      - -197368.10744422875\n",
      "      - -198816.8088522825\n",
      "      - -198394.896254656\n",
      "      - -197651.2634635199\n",
      "      - -199338.68928385657\n",
      "      - -197677.41162541878\n",
      "      - -199357.27170104077\n",
      "      - -197410.85538531153\n",
      "      - -195195.99781817032\n",
      "      - -201580.64538787332\n",
      "      - -194753.07711105864\n",
      "      - -196946.53892070462\n",
      "      - -198322.38924639634\n",
      "      - -196899.05040865767\n",
      "      - -195922.45283879113\n",
      "      - -198386.7008857644\n",
      "      - -195061.505976523\n",
      "      - -195519.78042391886\n",
      "      - -206428.70224828395\n",
      "      - -197859.47662823577\n",
      "      - -194245.59866751733\n",
      "      - -197406.8232975052\n",
      "      - -197790.19213373956\n",
      "      - -200002.82980814527\n",
      "      - -199327.29947097623\n",
      "      - -199270.81846478698\n",
      "      - -197739.7611052543\n",
      "      - -196641.67645368728\n",
      "      - -196211.8709890664\n",
      "      - -197694.71824422703\n",
      "      - -198872.2530045962\n",
      "      - -195619.38224058898\n",
      "      - -196116.44534556763\n",
      "      - -198867.37406072393\n",
      "      - -194384.53653354224\n",
      "      - -195633.3337584963\n",
      "      - -198690.25096186346\n",
      "      - -196506.3364306924\n",
      "      - -195882.67728089198\n",
      "      - -198069.65839311772\n",
      "      - -195971.99992646545\n",
      "      - -198380.95864391376\n",
      "      - -195623.10118253608\n",
      "      - -196910.76799197862\n",
      "      - -194150.80209364172\n",
      "      - -197131.667118312\n",
      "      - -198776.25065966713\n",
      "      - -196900.14718536264\n",
      "      - -198173.859486395\n",
      "      - -198820.67802054717\n",
      "      - -196824.80916971792\n",
      "      - -194916.20919578386\n",
      "      - -200516.58354838344\n",
      "      - -196967.08261053436\n",
      "      - -198284.21702277518\n",
      "      - -197656.5772386713\n",
      "      - -197873.86453787587\n",
      "      - -198760.42510898798\n",
      "      - -195898.77119741312\n",
      "      - -197094.06343367993\n",
      "      - -196730.4396820161\n",
      "      - -196891.0089400151\n",
      "      - -197111.746895636\n",
      "      - -197702.29835912434\n",
      "      - -196253.12991326812\n",
      "      - -197539.60776801276\n",
      "      - -197388.30684915188\n",
      "      - -197143.16428776245\n",
      "      - -195852.14594292274\n",
      "      - -199710.54565261304\n",
      "      - -196597.77758540428\n",
      "      - -199275.78753343422\n",
      "      - -197994.85240097283\n",
      "      - -197461.88988724074\n",
      "      - -197074.36290120587\n",
      "      - -197216.54130168\n",
      "      - -196219.3368158877\n",
      "      - -195968.68751662067\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09425736236616064\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4678166549572613\n",
      "      mean_inference_ms: 0.9645800695331894\n",
      "      mean_raw_obs_processing_ms: 0.1343699264588478\n",
      "  time_since_restore: 1604.3896267414093\n",
      "  time_this_iter_s: 9.335838556289673\n",
      "  time_total_s: 1604.3896267414093\n",
      "  timers:\n",
      "    learn_throughput: 133461.466\n",
      "    learn_time_ms: 479.419\n",
      "    load_throughput: 21931969.136\n",
      "    load_time_ms: 2.917\n",
      "    training_iteration_time_ms: 9489.127\n",
      "    update_time_ms: 4.663\n",
      "  timestamp: 1665850354\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 10749312\n",
      "  training_iteration: 168\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:12:39 (running for 00:27:13.96)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   168</td><td style=\"text-align: right;\">         1604.39</td><td style=\"text-align: right;\">10749312</td><td style=\"text-align: right;\"> -197410</td><td style=\"text-align: right;\">             -194151</td><td style=\"text-align: right;\">             -206429</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 10813296\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 10813296\n",
      "    num_agent_steps_trained: 10813296\n",
      "    num_env_steps_sampled: 10813296\n",
      "    num_env_steps_trained: 10813296\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-12-43\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -193717.56514046242\n",
      "  episode_reward_mean: -197450.33692488502\n",
      "  episode_reward_min: -204835.01006982411\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 10812\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.103146553039551\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0005081433337181807\n",
      "          model: {}\n",
      "          policy_loss: 0.0007324246107600629\n",
      "          total_loss: 10.000523567199707\n",
      "          vf_explained_var: -1.9868215517249155e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 10813296\n",
      "    num_agent_steps_trained: 10813296\n",
      "    num_env_steps_sampled: 10813296\n",
      "    num_env_steps_trained: 10813296\n",
      "  iterations_since_restore: 169\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 10813296\n",
      "  num_agent_steps_trained: 10813296\n",
      "  num_env_steps_sampled: 10813296\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 10813296\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 80.68461538461537\n",
      "    ram_util_percent: 87.41538461538462\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09422322470523473\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4678273676121066\n",
      "    mean_inference_ms: 0.9643234733189068\n",
      "    mean_raw_obs_processing_ms: 0.13418136618068346\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -193717.56514046242\n",
      "    episode_reward_mean: -197450.33692488502\n",
      "    episode_reward_min: -204835.01006982411\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -196824.80916971792\n",
      "      - -194916.20919578386\n",
      "      - -200516.58354838344\n",
      "      - -196967.08261053436\n",
      "      - -198284.21702277518\n",
      "      - -197656.5772386713\n",
      "      - -197873.86453787587\n",
      "      - -198760.42510898798\n",
      "      - -195898.77119741312\n",
      "      - -197094.06343367993\n",
      "      - -196730.4396820161\n",
      "      - -196891.0089400151\n",
      "      - -197111.746895636\n",
      "      - -197702.29835912434\n",
      "      - -196253.12991326812\n",
      "      - -197539.60776801276\n",
      "      - -197388.30684915188\n",
      "      - -197143.16428776245\n",
      "      - -195852.14594292274\n",
      "      - -199710.54565261304\n",
      "      - -196597.77758540428\n",
      "      - -199275.78753343422\n",
      "      - -197994.85240097283\n",
      "      - -197461.88988724074\n",
      "      - -197074.36290120587\n",
      "      - -197216.54130168\n",
      "      - -196219.3368158877\n",
      "      - -195968.68751662067\n",
      "      - -196249.22656592925\n",
      "      - -195108.1276678581\n",
      "      - -197681.43396896517\n",
      "      - -197128.39697814095\n",
      "      - -198223.23114711716\n",
      "      - -198003.487560107\n",
      "      - -196855.7393250334\n",
      "      - -196945.3853379853\n",
      "      - -196393.96613877013\n",
      "      - -196142.44598481103\n",
      "      - -200799.31051448733\n",
      "      - -196163.7221103513\n",
      "      - -195508.22509730046\n",
      "      - -198119.7347711686\n",
      "      - -197432.1936893405\n",
      "      - -198208.2263474166\n",
      "      - -198669.9412452716\n",
      "      - -197538.94893218705\n",
      "      - -197278.400975109\n",
      "      - -200493.9145477419\n",
      "      - -196621.57003018275\n",
      "      - -196041.92324199437\n",
      "      - -197879.98831061157\n",
      "      - -203768.54444804377\n",
      "      - -197633.56377603792\n",
      "      - -196291.2142634293\n",
      "      - -197068.85291523577\n",
      "      - -195987.99654920687\n",
      "      - -195961.9946343023\n",
      "      - -197067.63862495718\n",
      "      - -198132.12707327452\n",
      "      - -198045.28854490956\n",
      "      - -201450.89804176847\n",
      "      - -198654.58374161227\n",
      "      - -196512.39864034037\n",
      "      - -200085.31485982178\n",
      "      - -197550.65645218032\n",
      "      - -204835.01006982411\n",
      "      - -197172.95680865584\n",
      "      - -197248.39152620532\n",
      "      - -195685.29642932868\n",
      "      - -195348.82077347935\n",
      "      - -196607.1266245729\n",
      "      - -196565.75996532335\n",
      "      - -197590.71537559436\n",
      "      - -198104.7445693534\n",
      "      - -196064.04510565274\n",
      "      - -196700.77916208963\n",
      "      - -196628.95775950296\n",
      "      - -197600.15733549077\n",
      "      - -200289.35280192716\n",
      "      - -197261.6091220309\n",
      "      - -199060.90440950097\n",
      "      - -195909.82859283075\n",
      "      - -196313.03438710174\n",
      "      - -197637.50859978545\n",
      "      - -196204.42032123284\n",
      "      - -200405.24219581106\n",
      "      - -197965.428057018\n",
      "      - -199949.87004607118\n",
      "      - -194211.15250120749\n",
      "      - -197484.95475302357\n",
      "      - -195902.95646340883\n",
      "      - -195630.05489915403\n",
      "      - -198257.38768583408\n",
      "      - -200399.28728170667\n",
      "      - -194511.41655191348\n",
      "      - -193717.56514046242\n",
      "      - -196920.58001372125\n",
      "      - -194810.6863419696\n",
      "      - -196672.8859706362\n",
      "      - -200741.9584972825\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09422322470523473\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4678273676121066\n",
      "      mean_inference_ms: 0.9643234733189068\n",
      "      mean_raw_obs_processing_ms: 0.13418136618068346\n",
      "  time_since_restore: 1613.7137587070465\n",
      "  time_this_iter_s: 9.324131965637207\n",
      "  time_total_s: 1613.7137587070465\n",
      "  timers:\n",
      "    learn_throughput: 132793.638\n",
      "    learn_time_ms: 481.83\n",
      "    load_throughput: 21739207.862\n",
      "    load_time_ms: 2.943\n",
      "    training_iteration_time_ms: 9393.318\n",
      "    update_time_ms: 4.857\n",
      "  timestamp: 1665850363\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 10813296\n",
      "  training_iteration: 169\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:12:48 (running for 00:27:23.32)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   169</td><td style=\"text-align: right;\">         1613.71</td><td style=\"text-align: right;\">10813296</td><td style=\"text-align: right;\"> -197450</td><td style=\"text-align: right;\">             -193718</td><td style=\"text-align: right;\">             -204835</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 10877280\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 10877280\n",
      "    num_agent_steps_trained: 10877280\n",
      "    num_env_steps_sampled: 10877280\n",
      "    num_env_steps_trained: 10877280\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-12-53\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -193717.56514046242\n",
      "  episode_reward_mean: -197764.16786628985\n",
      "  episode_reward_min: -204835.01006982411\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 10872\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.102799892425537\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0007329023792408407\n",
      "          model: {}\n",
      "          policy_loss: 0.0053885700181126595\n",
      "          total_loss: 10.00522518157959\n",
      "          vf_explained_var: -2.7437058847112894e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 10877280\n",
      "    num_agent_steps_trained: 10877280\n",
      "    num_env_steps_sampled: 10877280\n",
      "    num_env_steps_trained: 10877280\n",
      "  iterations_since_restore: 170\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 10877280\n",
      "  num_agent_steps_trained: 10877280\n",
      "  num_env_steps_sampled: 10877280\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 10877280\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 84.36153846153844\n",
      "    ram_util_percent: 87.4\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09424690089998053\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.467765779646673\n",
      "    mean_inference_ms: 0.9644586821761911\n",
      "    mean_raw_obs_processing_ms: 0.13434504284926446\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -193717.56514046242\n",
      "    episode_reward_mean: -197764.16786628985\n",
      "    episode_reward_min: -204835.01006982411\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -201450.89804176847\n",
      "      - -198654.58374161227\n",
      "      - -196512.39864034037\n",
      "      - -200085.31485982178\n",
      "      - -197550.65645218032\n",
      "      - -204835.01006982411\n",
      "      - -197172.95680865584\n",
      "      - -197248.39152620532\n",
      "      - -195685.29642932868\n",
      "      - -195348.82077347935\n",
      "      - -196607.1266245729\n",
      "      - -196565.75996532335\n",
      "      - -197590.71537559436\n",
      "      - -198104.7445693534\n",
      "      - -196064.04510565274\n",
      "      - -196700.77916208963\n",
      "      - -196628.95775950296\n",
      "      - -197600.15733549077\n",
      "      - -200289.35280192716\n",
      "      - -197261.6091220309\n",
      "      - -199060.90440950097\n",
      "      - -195909.82859283075\n",
      "      - -196313.03438710174\n",
      "      - -197637.50859978545\n",
      "      - -196204.42032123284\n",
      "      - -200405.24219581106\n",
      "      - -197965.428057018\n",
      "      - -199949.87004607118\n",
      "      - -194211.15250120749\n",
      "      - -197484.95475302357\n",
      "      - -195902.95646340883\n",
      "      - -195630.05489915403\n",
      "      - -198257.38768583408\n",
      "      - -200399.28728170667\n",
      "      - -194511.41655191348\n",
      "      - -193717.56514046242\n",
      "      - -196920.58001372125\n",
      "      - -194810.6863419696\n",
      "      - -196672.8859706362\n",
      "      - -200741.9584972825\n",
      "      - -198211.5707919085\n",
      "      - -197935.41503944798\n",
      "      - -200627.7270188736\n",
      "      - -199323.64569149664\n",
      "      - -198442.05869320204\n",
      "      - -200653.92689840056\n",
      "      - -196545.53289675858\n",
      "      - -200685.37481249246\n",
      "      - -199993.2351062201\n",
      "      - -197232.32661555934\n",
      "      - -197374.46007423796\n",
      "      - -198069.29694146503\n",
      "      - -196750.4853522015\n",
      "      - -200552.09431998833\n",
      "      - -198285.5771080183\n",
      "      - -196323.8994302875\n",
      "      - -199255.24042546144\n",
      "      - -199967.95725526335\n",
      "      - -195956.77224014915\n",
      "      - -198846.95679797867\n",
      "      - -198532.16175855979\n",
      "      - -197610.82403988802\n",
      "      - -195769.10258856244\n",
      "      - -199192.15155461873\n",
      "      - -195870.30381329943\n",
      "      - -199020.15722559718\n",
      "      - -197094.95428239385\n",
      "      - -196983.3168674683\n",
      "      - -198622.92428251373\n",
      "      - -198477.26231817534\n",
      "      - -195734.262802329\n",
      "      - -197926.87521394648\n",
      "      - -198647.65398828714\n",
      "      - -195356.80350637686\n",
      "      - -198009.1629545809\n",
      "      - -194725.15723291278\n",
      "      - -198493.20383823517\n",
      "      - -198216.2326948089\n",
      "      - -196433.1509786754\n",
      "      - -197686.49281698195\n",
      "      - -198250.29858464285\n",
      "      - -194883.56284792695\n",
      "      - -197168.29363699612\n",
      "      - -196082.1398782925\n",
      "      - -199261.8317346845\n",
      "      - -195125.35037471473\n",
      "      - -199654.7397707868\n",
      "      - -198127.6615832347\n",
      "      - -195720.51045944158\n",
      "      - -200578.22282978284\n",
      "      - -201330.89310460977\n",
      "      - -198614.34377709954\n",
      "      - -195941.1228181265\n",
      "      - -196259.03221341153\n",
      "      - -197839.55065246645\n",
      "      - -197914.43155886236\n",
      "      - -200122.95449698696\n",
      "      - -197807.1429531597\n",
      "      - -195360.13611625144\n",
      "      - -200274.1610954561\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09424690089998053\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.467765779646673\n",
      "      mean_inference_ms: 0.9644586821761911\n",
      "      mean_raw_obs_processing_ms: 0.13434504284926446\n",
      "  time_since_restore: 1623.330900669098\n",
      "  time_this_iter_s: 9.617141962051392\n",
      "  time_total_s: 1623.330900669098\n",
      "  timers:\n",
      "    learn_throughput: 132656.357\n",
      "    learn_time_ms: 482.329\n",
      "    load_throughput: 21810053.567\n",
      "    load_time_ms: 2.934\n",
      "    training_iteration_time_ms: 9399.55\n",
      "    update_time_ms: 4.78\n",
      "  timestamp: 1665850373\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 10877280\n",
      "  training_iteration: 170\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:12:58 (running for 00:27:32.80)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   170</td><td style=\"text-align: right;\">         1623.33</td><td style=\"text-align: right;\">10877280</td><td style=\"text-align: right;\"> -197764</td><td style=\"text-align: right;\">             -193718</td><td style=\"text-align: right;\">             -204835</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 10941264\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 10941264\n",
      "    num_agent_steps_trained: 10941264\n",
      "    num_env_steps_sampled: 10941264\n",
      "    num_env_steps_trained: 10941264\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-13-03\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -194725.15723291278\n",
      "  episode_reward_mean: -197900.24714392747\n",
      "  episode_reward_min: -202509.79910044346\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 10932\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1075522899627686\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0008935497608035803\n",
      "          model: {}\n",
      "          policy_loss: 0.0045671965926885605\n",
      "          total_loss: 10.004434585571289\n",
      "          vf_explained_var: -8.514949634275126e-09\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 10941264\n",
      "    num_agent_steps_trained: 10941264\n",
      "    num_env_steps_sampled: 10941264\n",
      "    num_env_steps_trained: 10941264\n",
      "  iterations_since_restore: 171\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 10941264\n",
      "  num_agent_steps_trained: 10941264\n",
      "  num_env_steps_sampled: 10941264\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 10941264\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.12857142857145\n",
      "    ram_util_percent: 87.38571428571429\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09418602988037868\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4677299263692234\n",
      "    mean_inference_ms: 0.9646814227368523\n",
      "    mean_raw_obs_processing_ms: 0.1343525830307016\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -194725.15723291278\n",
      "    episode_reward_mean: -197900.24714392747\n",
      "    episode_reward_min: -202509.79910044346\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -198532.16175855979\n",
      "      - -197610.82403988802\n",
      "      - -195769.10258856244\n",
      "      - -199192.15155461873\n",
      "      - -195870.30381329943\n",
      "      - -199020.15722559718\n",
      "      - -197094.95428239385\n",
      "      - -196983.3168674683\n",
      "      - -198622.92428251373\n",
      "      - -198477.26231817534\n",
      "      - -195734.262802329\n",
      "      - -197926.87521394648\n",
      "      - -198647.65398828714\n",
      "      - -195356.80350637686\n",
      "      - -198009.1629545809\n",
      "      - -194725.15723291278\n",
      "      - -198493.20383823517\n",
      "      - -198216.2326948089\n",
      "      - -196433.1509786754\n",
      "      - -197686.49281698195\n",
      "      - -198250.29858464285\n",
      "      - -194883.56284792695\n",
      "      - -197168.29363699612\n",
      "      - -196082.1398782925\n",
      "      - -199261.8317346845\n",
      "      - -195125.35037471473\n",
      "      - -199654.7397707868\n",
      "      - -198127.6615832347\n",
      "      - -195720.51045944158\n",
      "      - -200578.22282978284\n",
      "      - -201330.89310460977\n",
      "      - -198614.34377709954\n",
      "      - -195941.1228181265\n",
      "      - -196259.03221341153\n",
      "      - -197839.55065246645\n",
      "      - -197914.43155886236\n",
      "      - -200122.95449698696\n",
      "      - -197807.1429531597\n",
      "      - -195360.13611625144\n",
      "      - -200274.1610954561\n",
      "      - -197659.2369506584\n",
      "      - -197766.88022250286\n",
      "      - -199000.97295601695\n",
      "      - -198311.69678053382\n",
      "      - -198459.8556598427\n",
      "      - -196758.16611745674\n",
      "      - -198107.31074881178\n",
      "      - -200492.0880675638\n",
      "      - -197694.45846894808\n",
      "      - -199463.8189573595\n",
      "      - -199373.21402513835\n",
      "      - -197116.1150469833\n",
      "      - -197843.55466936337\n",
      "      - -198643.856459302\n",
      "      - -196962.69462650976\n",
      "      - -202308.86217706598\n",
      "      - -199743.21036108516\n",
      "      - -199237.01727693353\n",
      "      - -198676.0314821069\n",
      "      - -197212.29143981932\n",
      "      - -196671.03776204496\n",
      "      - -198436.52040575293\n",
      "      - -195494.58970576499\n",
      "      - -195874.80030158823\n",
      "      - -197840.12119234484\n",
      "      - -200686.18821032738\n",
      "      - -198972.51530651396\n",
      "      - -196490.59963934906\n",
      "      - -198954.98415220788\n",
      "      - -197401.38150781894\n",
      "      - -197913.41364494307\n",
      "      - -196578.89627607082\n",
      "      - -197179.23978924064\n",
      "      - -197732.8086829102\n",
      "      - -197640.99794880775\n",
      "      - -197479.666877086\n",
      "      - -198223.2890161214\n",
      "      - -198796.21062655817\n",
      "      - -195930.39777292643\n",
      "      - -196698.83512160194\n",
      "      - -195677.74974873217\n",
      "      - -197060.467692493\n",
      "      - -197141.6221598771\n",
      "      - -195145.4541491628\n",
      "      - -197811.8026369077\n",
      "      - -198006.18326257306\n",
      "      - -198293.49633490935\n",
      "      - -199908.93890960183\n",
      "      - -196458.0508789119\n",
      "      - -202509.79910044346\n",
      "      - -198411.59215617366\n",
      "      - -198383.44946033324\n",
      "      - -199045.23564641096\n",
      "      - -198611.527470014\n",
      "      - -197570.03688403338\n",
      "      - -199029.41780356094\n",
      "      - -199935.6800076939\n",
      "      - -198833.4832557415\n",
      "      - -199299.6193922535\n",
      "      - -196344.74576379746\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09418602988037868\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4677299263692234\n",
      "      mean_inference_ms: 0.9646814227368523\n",
      "      mean_raw_obs_processing_ms: 0.1343525830307016\n",
      "  time_since_restore: 1632.9715330600739\n",
      "  time_this_iter_s: 9.640632390975952\n",
      "  time_total_s: 1632.9715330600739\n",
      "  timers:\n",
      "    learn_throughput: 132815.365\n",
      "    learn_time_ms: 481.751\n",
      "    load_throughput: 21399278.139\n",
      "    load_time_ms: 2.99\n",
      "    training_iteration_time_ms: 9442.582\n",
      "    update_time_ms: 4.443\n",
      "  timestamp: 1665850383\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 10941264\n",
      "  training_iteration: 171\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:13:08 (running for 00:27:42.66)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   171</td><td style=\"text-align: right;\">         1632.97</td><td style=\"text-align: right;\">10941264</td><td style=\"text-align: right;\"> -197900</td><td style=\"text-align: right;\">             -194725</td><td style=\"text-align: right;\">             -202510</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 11005248\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 11005248\n",
      "    num_agent_steps_trained: 11005248\n",
      "    num_env_steps_sampled: 11005248\n",
      "    num_env_steps_trained: 11005248\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-13-12\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -194140.19964143034\n",
      "  episode_reward_mean: -197449.77418709983\n",
      "  episode_reward_min: -202509.79910044346\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 11004\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.105109453201294\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0007301449659280479\n",
      "          model: {}\n",
      "          policy_loss: 0.0007539376383647323\n",
      "          total_loss: 10.000590324401855\n",
      "          vf_explained_var: -2.4598742598413992e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 11005248\n",
      "    num_agent_steps_trained: 11005248\n",
      "    num_env_steps_sampled: 11005248\n",
      "    num_env_steps_trained: 11005248\n",
      "  iterations_since_restore: 172\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 11005248\n",
      "  num_agent_steps_trained: 11005248\n",
      "  num_env_steps_sampled: 11005248\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 11005248\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 85.3076923076923\n",
      "    ram_util_percent: 87.4\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09416894333818894\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46773198495464824\n",
      "    mean_inference_ms: 0.9645807048986158\n",
      "    mean_raw_obs_processing_ms: 0.13418932577650053\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -194140.19964143034\n",
      "    episode_reward_mean: -197449.77418709983\n",
      "    episode_reward_min: -202509.79910044346\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -197179.23978924064\n",
      "      - -197732.8086829102\n",
      "      - -197640.99794880775\n",
      "      - -197479.666877086\n",
      "      - -198223.2890161214\n",
      "      - -198796.21062655817\n",
      "      - -195930.39777292643\n",
      "      - -196698.83512160194\n",
      "      - -195677.74974873217\n",
      "      - -197060.467692493\n",
      "      - -197141.6221598771\n",
      "      - -195145.4541491628\n",
      "      - -197811.8026369077\n",
      "      - -198006.18326257306\n",
      "      - -198293.49633490935\n",
      "      - -199908.93890960183\n",
      "      - -196458.0508789119\n",
      "      - -202509.79910044346\n",
      "      - -198411.59215617366\n",
      "      - -198383.44946033324\n",
      "      - -199045.23564641096\n",
      "      - -198611.527470014\n",
      "      - -197570.03688403338\n",
      "      - -199029.41780356094\n",
      "      - -199935.6800076939\n",
      "      - -198833.4832557415\n",
      "      - -199299.6193922535\n",
      "      - -196344.74576379746\n",
      "      - -195178.129264469\n",
      "      - -194771.1943221642\n",
      "      - -198374.6511748734\n",
      "      - -195213.93382830734\n",
      "      - -198142.7979276831\n",
      "      - -198336.9788025435\n",
      "      - -195687.25402026754\n",
      "      - -195553.99367482596\n",
      "      - -199512.20080719393\n",
      "      - -197815.00682032653\n",
      "      - -196797.5059431192\n",
      "      - -196162.98984283645\n",
      "      - -198741.65593076506\n",
      "      - -196896.88052461637\n",
      "      - -195395.2456956874\n",
      "      - -199805.4778243185\n",
      "      - -195973.63500522636\n",
      "      - -195939.0669448804\n",
      "      - -198004.87533568763\n",
      "      - -196905.3799933801\n",
      "      - -195468.11759950806\n",
      "      - -197244.87886201154\n",
      "      - -196393.9541840877\n",
      "      - -194140.19964143034\n",
      "      - -196993.53071580819\n",
      "      - -197171.1725976132\n",
      "      - -195439.6056978521\n",
      "      - -195931.77041339336\n",
      "      - -198141.87199443666\n",
      "      - -198627.10442789222\n",
      "      - -198226.28967485175\n",
      "      - -196370.70104010578\n",
      "      - -197237.30161645287\n",
      "      - -196354.29370169243\n",
      "      - -197984.26490769157\n",
      "      - -198747.50489783258\n",
      "      - -197562.35562044097\n",
      "      - -194651.48389508575\n",
      "      - -194294.07302109498\n",
      "      - -197469.2321779386\n",
      "      - -196928.33680379167\n",
      "      - -196282.353964007\n",
      "      - -196517.1599758685\n",
      "      - -198210.50327357274\n",
      "      - -196683.60797057586\n",
      "      - -197511.35802553766\n",
      "      - -197972.016020857\n",
      "      - -198840.18601597127\n",
      "      - -200662.00086132935\n",
      "      - -197295.97835093184\n",
      "      - -197033.8198884836\n",
      "      - -195599.40921534906\n",
      "      - -200396.45225773766\n",
      "      - -198431.33414325916\n",
      "      - -197317.170611043\n",
      "      - -199291.11593081595\n",
      "      - -196690.88322504383\n",
      "      - -196739.4448760414\n",
      "      - -198734.2480609159\n",
      "      - -195867.8459182126\n",
      "      - -198638.7551021148\n",
      "      - -196581.98832810015\n",
      "      - -196264.7570329543\n",
      "      - -198630.00328349677\n",
      "      - -199483.55963409285\n",
      "      - -195510.9657713006\n",
      "      - -201668.41962905345\n",
      "      - -198671.38497867\n",
      "      - -198168.02860069665\n",
      "      - -198281.2666109445\n",
      "      - -195724.12679953832\n",
      "      - -197530.57863040705\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09416894333818894\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46773198495464824\n",
      "      mean_inference_ms: 0.9645807048986158\n",
      "      mean_raw_obs_processing_ms: 0.13418932577650053\n",
      "  time_since_restore: 1642.4144921302795\n",
      "  time_this_iter_s: 9.442959070205688\n",
      "  time_total_s: 1642.4144921302795\n",
      "  timers:\n",
      "    learn_throughput: 133142.586\n",
      "    learn_time_ms: 480.568\n",
      "    load_throughput: 21297046.879\n",
      "    load_time_ms: 3.004\n",
      "    training_iteration_time_ms: 9452.146\n",
      "    update_time_ms: 4.339\n",
      "  timestamp: 1665850392\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 11005248\n",
      "  training_iteration: 172\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:13:17 (running for 00:27:52.13)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   172</td><td style=\"text-align: right;\">         1642.41</td><td style=\"text-align: right;\">11005248</td><td style=\"text-align: right;\"> -197450</td><td style=\"text-align: right;\">             -194140</td><td style=\"text-align: right;\">             -202510</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:13:22 (running for 00:27:57.18)<br>Memory usage on this node: 13.6/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   172</td><td style=\"text-align: right;\">         1642.41</td><td style=\"text-align: right;\">11005248</td><td style=\"text-align: right;\"> -197450</td><td style=\"text-align: right;\">             -194140</td><td style=\"text-align: right;\">             -202510</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 11069232\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 11069232\n",
      "    num_agent_steps_trained: 11069232\n",
      "    num_env_steps_sampled: 11069232\n",
      "    num_env_steps_trained: 11069232\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-13-23\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -194273.46175299367\n",
      "  episode_reward_mean: -197445.97492250375\n",
      "  episode_reward_min: -201668.41962905345\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 11064\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1091549396514893\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0013092680601403117\n",
      "          model: {}\n",
      "          policy_loss: 0.006540374364703894\n",
      "          total_loss: 10.006490707397461\n",
      "          vf_explained_var: -3.7844220202032375e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 11069232\n",
      "    num_agent_steps_trained: 11069232\n",
      "    num_env_steps_sampled: 11069232\n",
      "    num_env_steps_trained: 11069232\n",
      "  iterations_since_restore: 173\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 11069232\n",
      "  num_agent_steps_trained: 11069232\n",
      "  num_env_steps_sampled: 11069232\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 11069232\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.11333333333336\n",
      "    ram_util_percent: 87.49999999999999\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09423060199958717\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4677203975934394\n",
      "    mean_inference_ms: 0.9652154968152309\n",
      "    mean_raw_obs_processing_ms: 0.13438443766083974\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -194273.46175299367\n",
      "    episode_reward_mean: -197445.97492250375\n",
      "    episode_reward_min: -201668.41962905345\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -197237.30161645287\n",
      "      - -196354.29370169243\n",
      "      - -197984.26490769157\n",
      "      - -198747.50489783258\n",
      "      - -197562.35562044097\n",
      "      - -194651.48389508575\n",
      "      - -194294.07302109498\n",
      "      - -197469.2321779386\n",
      "      - -196928.33680379167\n",
      "      - -196282.353964007\n",
      "      - -196517.1599758685\n",
      "      - -198210.50327357274\n",
      "      - -196683.60797057586\n",
      "      - -197511.35802553766\n",
      "      - -197972.016020857\n",
      "      - -198840.18601597127\n",
      "      - -200662.00086132935\n",
      "      - -197295.97835093184\n",
      "      - -197033.8198884836\n",
      "      - -195599.40921534906\n",
      "      - -200396.45225773766\n",
      "      - -198431.33414325916\n",
      "      - -197317.170611043\n",
      "      - -199291.11593081595\n",
      "      - -196690.88322504383\n",
      "      - -196739.4448760414\n",
      "      - -198734.2480609159\n",
      "      - -195867.8459182126\n",
      "      - -198638.7551021148\n",
      "      - -196581.98832810015\n",
      "      - -196264.7570329543\n",
      "      - -198630.00328349677\n",
      "      - -199483.55963409285\n",
      "      - -195510.9657713006\n",
      "      - -201668.41962905345\n",
      "      - -198671.38497867\n",
      "      - -198168.02860069665\n",
      "      - -198281.2666109445\n",
      "      - -195724.12679953832\n",
      "      - -197530.57863040705\n",
      "      - -194553.81287708812\n",
      "      - -198475.44956436686\n",
      "      - -197204.89767548963\n",
      "      - -199539.41186382333\n",
      "      - -199447.11342139938\n",
      "      - -198417.31310576384\n",
      "      - -196353.8798694333\n",
      "      - -197131.4677860628\n",
      "      - -196634.10652148814\n",
      "      - -197176.80127754432\n",
      "      - -199919.72770693793\n",
      "      - -199724.24313069353\n",
      "      - -199139.6502046122\n",
      "      - -196110.56606008767\n",
      "      - -199376.05809923186\n",
      "      - -195265.37563713326\n",
      "      - -196615.7541947937\n",
      "      - -197866.35746056476\n",
      "      - -195435.27542673462\n",
      "      - -197890.2349101589\n",
      "      - -196155.74704338255\n",
      "      - -197975.75494490974\n",
      "      - -199464.5161146789\n",
      "      - -197857.9274436028\n",
      "      - -198603.29084961745\n",
      "      - -194273.46175299367\n",
      "      - -195740.05790793188\n",
      "      - -196688.35782825155\n",
      "      - -197186.00932092135\n",
      "      - -197169.71681502502\n",
      "      - -195680.4156756286\n",
      "      - -197625.47702485544\n",
      "      - -198288.76852474405\n",
      "      - -197401.2531587634\n",
      "      - -198174.3651265177\n",
      "      - -198669.7062222842\n",
      "      - -195181.79625543908\n",
      "      - -195949.6684831422\n",
      "      - -198497.72386699243\n",
      "      - -197136.0354290238\n",
      "      - -194859.1731749012\n",
      "      - -199494.13137537971\n",
      "      - -194629.2927015107\n",
      "      - -195679.24302573391\n",
      "      - -196630.60746593098\n",
      "      - -196635.58230976644\n",
      "      - -200751.70444111928\n",
      "      - -198248.0250969516\n",
      "      - -198086.0933806319\n",
      "      - -199431.6450256187\n",
      "      - -195430.05201507645\n",
      "      - -195923.15846647831\n",
      "      - -198065.39451195693\n",
      "      - -197841.89867125283\n",
      "      - -198741.58305805552\n",
      "      - -198998.50966607334\n",
      "      - -198050.5262839135\n",
      "      - -195880.32230444823\n",
      "      - -196425.8344725394\n",
      "      - -196337.5985919732\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09423060199958717\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4677203975934394\n",
      "      mean_inference_ms: 0.9652154968152309\n",
      "      mean_raw_obs_processing_ms: 0.13438443766083974\n",
      "  time_since_restore: 1652.9425148963928\n",
      "  time_this_iter_s: 10.528022766113281\n",
      "  time_total_s: 1652.9425148963928\n",
      "  timers:\n",
      "    learn_throughput: 134275.474\n",
      "    learn_time_ms: 476.513\n",
      "    load_throughput: 21190766.806\n",
      "    load_time_ms: 3.019\n",
      "    training_iteration_time_ms: 9564.683\n",
      "    update_time_ms: 4.152\n",
      "  timestamp: 1665850403\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 11069232\n",
      "  training_iteration: 173\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:13:28 (running for 00:28:02.69)<br>Memory usage on this node: 13.6/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   173</td><td style=\"text-align: right;\">         1652.94</td><td style=\"text-align: right;\">11069232</td><td style=\"text-align: right;\"> -197446</td><td style=\"text-align: right;\">             -194273</td><td style=\"text-align: right;\">             -201668</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 11133216\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 11133216\n",
      "    num_agent_steps_trained: 11133216\n",
      "    num_env_steps_sampled: 11133216\n",
      "    num_env_steps_trained: 11133216\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-13-32\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -194260.0265777544\n",
      "  episode_reward_mean: -197263.25287114803\n",
      "  episode_reward_min: -209722.713526288\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 11124\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1059610843658447\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00045544959721155465\n",
      "          model: {}\n",
      "          policy_loss: 0.004699958488345146\n",
      "          total_loss: 10.00447940826416\n",
      "          vf_explained_var: -2.4598742598413992e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 11133216\n",
      "    num_agent_steps_trained: 11133216\n",
      "    num_env_steps_sampled: 11133216\n",
      "    num_env_steps_trained: 11133216\n",
      "  iterations_since_restore: 174\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 11133216\n",
      "  num_agent_steps_trained: 11133216\n",
      "  num_env_steps_sampled: 11133216\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 11133216\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.07692307692308\n",
      "    ram_util_percent: 87.66923076923078\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09417692061122547\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46768804242135675\n",
      "    mean_inference_ms: 0.9655992736146024\n",
      "    mean_raw_obs_processing_ms: 0.1344014554615603\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -194260.0265777544\n",
      "    episode_reward_mean: -197263.25287114803\n",
      "    episode_reward_min: -209722.713526288\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -196155.74704338255\n",
      "      - -197975.75494490974\n",
      "      - -199464.5161146789\n",
      "      - -197857.9274436028\n",
      "      - -198603.29084961745\n",
      "      - -194273.46175299367\n",
      "      - -195740.05790793188\n",
      "      - -196688.35782825155\n",
      "      - -197186.00932092135\n",
      "      - -197169.71681502502\n",
      "      - -195680.4156756286\n",
      "      - -197625.47702485544\n",
      "      - -198288.76852474405\n",
      "      - -197401.2531587634\n",
      "      - -198174.3651265177\n",
      "      - -198669.7062222842\n",
      "      - -195181.79625543908\n",
      "      - -195949.6684831422\n",
      "      - -198497.72386699243\n",
      "      - -197136.0354290238\n",
      "      - -194859.1731749012\n",
      "      - -199494.13137537971\n",
      "      - -194629.2927015107\n",
      "      - -195679.24302573391\n",
      "      - -196630.60746593098\n",
      "      - -196635.58230976644\n",
      "      - -200751.70444111928\n",
      "      - -198248.0250969516\n",
      "      - -198086.0933806319\n",
      "      - -199431.6450256187\n",
      "      - -195430.05201507645\n",
      "      - -195923.15846647831\n",
      "      - -198065.39451195693\n",
      "      - -197841.89867125283\n",
      "      - -198741.58305805552\n",
      "      - -198998.50966607334\n",
      "      - -198050.5262839135\n",
      "      - -195880.32230444823\n",
      "      - -196425.8344725394\n",
      "      - -196337.5985919732\n",
      "      - -199476.41943621114\n",
      "      - -196750.20915110715\n",
      "      - -198319.19615577243\n",
      "      - -200129.2488401101\n",
      "      - -195339.41566320707\n",
      "      - -197869.45518248633\n",
      "      - -199411.53880232482\n",
      "      - -196958.90945630206\n",
      "      - -199723.93702190844\n",
      "      - -194260.0265777544\n",
      "      - -197885.3986329878\n",
      "      - -199966.99366301985\n",
      "      - -195810.57281889525\n",
      "      - -198208.543234963\n",
      "      - -197092.3626121511\n",
      "      - -196809.75085026663\n",
      "      - -196745.72665248724\n",
      "      - -194689.96479010378\n",
      "      - -197043.68022479757\n",
      "      - -197573.55355518556\n",
      "      - -196637.09759113917\n",
      "      - -197710.63261421878\n",
      "      - -196842.27674018563\n",
      "      - -195370.6630578129\n",
      "      - -197767.31988472477\n",
      "      - -196882.98285127024\n",
      "      - -195787.544715685\n",
      "      - -199248.4039064526\n",
      "      - -194606.30810412622\n",
      "      - -196692.677984287\n",
      "      - -196036.53831367788\n",
      "      - -194876.54784684835\n",
      "      - -195883.46785251648\n",
      "      - -196229.86059620127\n",
      "      - -196241.31034021784\n",
      "      - -197967.18846886346\n",
      "      - -194653.23135619675\n",
      "      - -196435.55475565125\n",
      "      - -196895.44963462252\n",
      "      - -196921.8336414936\n",
      "      - -197540.84806374283\n",
      "      - -196422.58287172043\n",
      "      - -198889.47520896306\n",
      "      - -198783.40140320556\n",
      "      - -196058.842466196\n",
      "      - -195954.70522308003\n",
      "      - -196571.12510987176\n",
      "      - -197149.2148072855\n",
      "      - -198423.2487133214\n",
      "      - -197049.98458144467\n",
      "      - -197348.98372445616\n",
      "      - -196806.78493946177\n",
      "      - -197028.93461559285\n",
      "      - -198235.72355010262\n",
      "      - -198641.0620848951\n",
      "      - -196604.0971983925\n",
      "      - -196974.3259369887\n",
      "      - -196834.26157160487\n",
      "      - -195672.75211194006\n",
      "      - -209722.713526288\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09417692061122547\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46768804242135675\n",
      "      mean_inference_ms: 0.9655992736146024\n",
      "      mean_raw_obs_processing_ms: 0.1344014554615603\n",
      "  time_since_restore: 1662.3356230258942\n",
      "  time_this_iter_s: 9.393108129501343\n",
      "  time_total_s: 1662.3356230258942\n",
      "  timers:\n",
      "    learn_throughput: 134858.107\n",
      "    learn_time_ms: 474.454\n",
      "    load_throughput: 21059068.641\n",
      "    load_time_ms: 3.038\n",
      "    training_iteration_time_ms: 9564.517\n",
      "    update_time_ms: 4.123\n",
      "  timestamp: 1665850412\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 11133216\n",
      "  training_iteration: 174\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:13:37 (running for 00:28:11.93)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   174</td><td style=\"text-align: right;\">         1662.34</td><td style=\"text-align: right;\">11133216</td><td style=\"text-align: right;\"> -197263</td><td style=\"text-align: right;\">             -194260</td><td style=\"text-align: right;\">             -209723</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 11197200\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 11197200\n",
      "    num_agent_steps_trained: 11197200\n",
      "    num_env_steps_sampled: 11197200\n",
      "    num_env_steps_trained: 11197200\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-13-42\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -193062.28838500215\n",
      "  episode_reward_mean: -197055.81652635394\n",
      "  episode_reward_min: -209722.713526288\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 11196\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.10555100440979\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0006951822433620691\n",
      "          model: {}\n",
      "          policy_loss: 0.0013905328232795\n",
      "          total_loss: 10.001218795776367\n",
      "          vf_explained_var: -5.676632852669172e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 11197200\n",
      "    num_agent_steps_trained: 11197200\n",
      "    num_env_steps_sampled: 11197200\n",
      "    num_env_steps_trained: 11197200\n",
      "  iterations_since_restore: 175\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 11197200\n",
      "  num_agent_steps_trained: 11197200\n",
      "  num_env_steps_sampled: 11197200\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 11197200\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 84.47692307692309\n",
      "    ram_util_percent: 87.54615384615384\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09415710239794006\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46766980801928176\n",
      "    mean_inference_ms: 0.9654984652772395\n",
      "    mean_raw_obs_processing_ms: 0.13424203685207997\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -193062.28838500215\n",
      "    episode_reward_mean: -197055.81652635394\n",
      "    episode_reward_min: -209722.713526288\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -195883.46785251648\n",
      "      - -196229.86059620127\n",
      "      - -196241.31034021784\n",
      "      - -197967.18846886346\n",
      "      - -194653.23135619675\n",
      "      - -196435.55475565125\n",
      "      - -196895.44963462252\n",
      "      - -196921.8336414936\n",
      "      - -197540.84806374283\n",
      "      - -196422.58287172043\n",
      "      - -198889.47520896306\n",
      "      - -198783.40140320556\n",
      "      - -196058.842466196\n",
      "      - -195954.70522308003\n",
      "      - -196571.12510987176\n",
      "      - -197149.2148072855\n",
      "      - -198423.2487133214\n",
      "      - -197049.98458144467\n",
      "      - -197348.98372445616\n",
      "      - -196806.78493946177\n",
      "      - -197028.93461559285\n",
      "      - -198235.72355010262\n",
      "      - -198641.0620848951\n",
      "      - -196604.0971983925\n",
      "      - -196974.3259369887\n",
      "      - -196834.26157160487\n",
      "      - -195672.75211194006\n",
      "      - -209722.713526288\n",
      "      - -199171.81326625607\n",
      "      - -196181.36594092523\n",
      "      - -205999.06002583556\n",
      "      - -198152.37999686933\n",
      "      - -196435.93889007514\n",
      "      - -197130.89072976675\n",
      "      - -195572.80065993618\n",
      "      - -196002.31558394636\n",
      "      - -197945.12370500749\n",
      "      - -195986.64542867942\n",
      "      - -195439.11358005507\n",
      "      - -195830.67592982494\n",
      "      - -196594.9868895649\n",
      "      - -196265.98873665917\n",
      "      - -196868.4339945564\n",
      "      - -196809.23670240343\n",
      "      - -193151.02713712346\n",
      "      - -196189.68232279923\n",
      "      - -197086.69869980428\n",
      "      - -195844.45549112672\n",
      "      - -197783.54219295684\n",
      "      - -197668.7362390292\n",
      "      - -199943.02098007093\n",
      "      - -194220.12545312577\n",
      "      - -195146.8891527179\n",
      "      - -193062.28838500215\n",
      "      - -194599.34885268228\n",
      "      - -207313.2573242209\n",
      "      - -195493.4815261732\n",
      "      - -198734.49460233306\n",
      "      - -201221.12492410847\n",
      "      - -196012.25717132378\n",
      "      - -194565.90314888232\n",
      "      - -194712.31415036635\n",
      "      - -197220.48313043406\n",
      "      - -196908.9088822463\n",
      "      - -197232.5945246595\n",
      "      - -198843.45887763173\n",
      "      - -195005.74256449507\n",
      "      - -195626.94909216647\n",
      "      - -198749.216522562\n",
      "      - -195085.30980741975\n",
      "      - -195906.74049752776\n",
      "      - -198551.84458966553\n",
      "      - -195470.4959559887\n",
      "      - -198582.2384271257\n",
      "      - -196129.9245958378\n",
      "      - -200836.82592196163\n",
      "      - -198072.68637434984\n",
      "      - -198342.4060809562\n",
      "      - -195085.13552584042\n",
      "      - -197816.66364344288\n",
      "      - -194098.36679288847\n",
      "      - -198570.48911504843\n",
      "      - -199262.66059167022\n",
      "      - -196771.82058583427\n",
      "      - -198194.31020319136\n",
      "      - -197445.39859111048\n",
      "      - -196086.97203148442\n",
      "      - -196389.81680401496\n",
      "      - -197080.59430649827\n",
      "      - -193958.8862794718\n",
      "      - -196164.744594357\n",
      "      - -195301.3775211577\n",
      "      - -195790.59131066749\n",
      "      - -196246.4268327936\n",
      "      - -196160.15421846218\n",
      "      - -197948.05237375374\n",
      "      - -194756.71158767698\n",
      "      - -197197.59123455442\n",
      "      - -195803.37729268818\n",
      "      - -195809.3031852306\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09415710239794006\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46766980801928176\n",
      "      mean_inference_ms: 0.9654984652772395\n",
      "      mean_raw_obs_processing_ms: 0.13424203685207997\n",
      "  time_since_restore: 1671.9608807563782\n",
      "  time_this_iter_s: 9.625257730484009\n",
      "  time_total_s: 1671.9608807563782\n",
      "  timers:\n",
      "    learn_throughput: 132932.969\n",
      "    learn_time_ms: 481.325\n",
      "    load_throughput: 21046021.812\n",
      "    load_time_ms: 3.04\n",
      "    training_iteration_time_ms: 9584.641\n",
      "    update_time_ms: 4.168\n",
      "  timestamp: 1665850422\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 11197200\n",
      "  training_iteration: 175\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:13:47 (running for 00:28:21.69)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   175</td><td style=\"text-align: right;\">         1671.96</td><td style=\"text-align: right;\">11197200</td><td style=\"text-align: right;\"> -197056</td><td style=\"text-align: right;\">             -193062</td><td style=\"text-align: right;\">             -209723</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 11261184\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 11261184\n",
      "    num_agent_steps_trained: 11261184\n",
      "    num_env_steps_sampled: 11261184\n",
      "    num_env_steps_trained: 11261184\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-13-51\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -193925.3823797375\n",
      "  episode_reward_mean: -196847.88838726503\n",
      "  episode_reward_min: -200836.82592196163\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 11256\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.109694004058838\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0007008120301179588\n",
      "          model: {}\n",
      "          policy_loss: 0.006145994644612074\n",
      "          total_loss: 10.005975723266602\n",
      "          vf_explained_var: -4.9197485196827984e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 11261184\n",
      "    num_agent_steps_trained: 11261184\n",
      "    num_env_steps_sampled: 11261184\n",
      "    num_env_steps_trained: 11261184\n",
      "  iterations_since_restore: 176\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 11261184\n",
      "  num_agent_steps_trained: 11261184\n",
      "  num_env_steps_sampled: 11261184\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 11261184\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.27692307692308\n",
      "    ram_util_percent: 87.5\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09421466680317163\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46758625870790516\n",
      "    mean_inference_ms: 0.9657288097295946\n",
      "    mean_raw_obs_processing_ms: 0.13440128020585698\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -193925.3823797375\n",
      "    episode_reward_mean: -196847.88838726503\n",
      "    episode_reward_min: -200836.82592196163\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -194565.90314888232\n",
      "      - -194712.31415036635\n",
      "      - -197220.48313043406\n",
      "      - -196908.9088822463\n",
      "      - -197232.5945246595\n",
      "      - -198843.45887763173\n",
      "      - -195005.74256449507\n",
      "      - -195626.94909216647\n",
      "      - -198749.216522562\n",
      "      - -195085.30980741975\n",
      "      - -195906.74049752776\n",
      "      - -198551.84458966553\n",
      "      - -195470.4959559887\n",
      "      - -198582.2384271257\n",
      "      - -196129.9245958378\n",
      "      - -200836.82592196163\n",
      "      - -198072.68637434984\n",
      "      - -198342.4060809562\n",
      "      - -195085.13552584042\n",
      "      - -197816.66364344288\n",
      "      - -194098.36679288847\n",
      "      - -198570.48911504843\n",
      "      - -199262.66059167022\n",
      "      - -196771.82058583427\n",
      "      - -198194.31020319136\n",
      "      - -197445.39859111048\n",
      "      - -196086.97203148442\n",
      "      - -196389.81680401496\n",
      "      - -197080.59430649827\n",
      "      - -193958.8862794718\n",
      "      - -196164.744594357\n",
      "      - -195301.3775211577\n",
      "      - -195790.59131066749\n",
      "      - -196246.4268327936\n",
      "      - -196160.15421846218\n",
      "      - -197948.05237375374\n",
      "      - -194756.71158767698\n",
      "      - -197197.59123455442\n",
      "      - -195803.37729268818\n",
      "      - -195809.3031852306\n",
      "      - -197526.30746803433\n",
      "      - -195439.22697562235\n",
      "      - -196160.04243597752\n",
      "      - -196230.78067904623\n",
      "      - -197586.28274260156\n",
      "      - -195772.01655981\n",
      "      - -194893.54811823828\n",
      "      - -196194.25272295356\n",
      "      - -196584.62731994616\n",
      "      - -194516.7956738935\n",
      "      - -198025.05467973324\n",
      "      - -196354.12473256644\n",
      "      - -197089.40703519917\n",
      "      - -194945.57030732356\n",
      "      - -198175.76636641042\n",
      "      - -198336.98024899268\n",
      "      - -196017.4188718507\n",
      "      - -197200.34047094162\n",
      "      - -196906.88040571805\n",
      "      - -195457.74794683343\n",
      "      - -197217.57127470008\n",
      "      - -200814.25172319912\n",
      "      - -196264.68236666027\n",
      "      - -196119.47718414842\n",
      "      - -200740.74761088405\n",
      "      - -198754.59510917644\n",
      "      - -196525.48105376327\n",
      "      - -195247.70238936954\n",
      "      - -197281.64986570043\n",
      "      - -199320.33145816068\n",
      "      - -197920.30398687677\n",
      "      - -198157.22398196565\n",
      "      - -197221.1027055978\n",
      "      - -197586.74490273264\n",
      "      - -197255.26612279643\n",
      "      - -195963.82204339997\n",
      "      - -196613.37438508702\n",
      "      - -195110.31538539933\n",
      "      - -197418.31239113727\n",
      "      - -198530.3046966088\n",
      "      - -197773.57948526344\n",
      "      - -196816.81896132673\n",
      "      - -193925.3823797375\n",
      "      - -198172.77628723733\n",
      "      - -199492.55126871174\n",
      "      - -197190.03824706777\n",
      "      - -195659.00004633292\n",
      "      - -196016.75806573324\n",
      "      - -195430.53330910346\n",
      "      - -195734.64825880635\n",
      "      - -196708.46594074072\n",
      "      - -198106.76887222825\n",
      "      - -196752.44355192228\n",
      "      - -198927.5637957287\n",
      "      - -194795.7732365946\n",
      "      - -196125.3152340425\n",
      "      - -198757.6782025381\n",
      "      - -196925.41754375433\n",
      "      - -196887.17101376725\n",
      "      - -197330.2348606878\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09421466680317163\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46758625870790516\n",
      "      mean_inference_ms: 0.9657288097295946\n",
      "      mean_raw_obs_processing_ms: 0.13440128020585698\n",
      "  time_since_restore: 1681.6409139633179\n",
      "  time_this_iter_s: 9.680033206939697\n",
      "  time_total_s: 1681.6409139633179\n",
      "  timers:\n",
      "    learn_throughput: 131574.337\n",
      "    learn_time_ms: 486.295\n",
      "    load_throughput: 21209188.608\n",
      "    load_time_ms: 3.017\n",
      "    training_iteration_time_ms: 9603.396\n",
      "    update_time_ms: 4.187\n",
      "  timestamp: 1665850431\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 11261184\n",
      "  training_iteration: 176\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:13:57 (running for 00:28:31.59)<br>Memory usage on this node: 13.6/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   176</td><td style=\"text-align: right;\">         1681.64</td><td style=\"text-align: right;\">11261184</td><td style=\"text-align: right;\"> -196848</td><td style=\"text-align: right;\">             -193925</td><td style=\"text-align: right;\">             -200837</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:14:02 (running for 00:28:36.60)<br>Memory usage on this node: 13.6/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   176</td><td style=\"text-align: right;\">         1681.64</td><td style=\"text-align: right;\">11261184</td><td style=\"text-align: right;\"> -196848</td><td style=\"text-align: right;\">             -193925</td><td style=\"text-align: right;\">             -200837</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 11325168\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 11325168\n",
      "    num_agent_steps_trained: 11325168\n",
      "    num_env_steps_sampled: 11325168\n",
      "    num_env_steps_trained: 11325168\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-14-02\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -193682.75115076028\n",
      "  episode_reward_mean: -196973.68639887086\n",
      "  episode_reward_min: -200814.25172319912\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 11316\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0979413986206055\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0006213672459125519\n",
      "          model: {}\n",
      "          policy_loss: 0.004271445330232382\n",
      "          total_loss: 10.004085540771484\n",
      "          vf_explained_var: -2.4598742598413992e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 11325168\n",
      "    num_agent_steps_trained: 11325168\n",
      "    num_env_steps_sampled: 11325168\n",
      "    num_env_steps_trained: 11325168\n",
      "  iterations_since_restore: 177\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 11325168\n",
      "  num_agent_steps_trained: 11325168\n",
      "  num_env_steps_sampled: 11325168\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 11325168\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.85\n",
      "    ram_util_percent: 87.6\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09421014186059853\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4677087259520684\n",
      "    mean_inference_ms: 0.966297551594429\n",
      "    mean_raw_obs_processing_ms: 0.13442845417923122\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -193682.75115076028\n",
      "    episode_reward_mean: -196973.68639887086\n",
      "    episode_reward_min: -200814.25172319912\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -197217.57127470008\n",
      "      - -200814.25172319912\n",
      "      - -196264.68236666027\n",
      "      - -196119.47718414842\n",
      "      - -200740.74761088405\n",
      "      - -198754.59510917644\n",
      "      - -196525.48105376327\n",
      "      - -195247.70238936954\n",
      "      - -197281.64986570043\n",
      "      - -199320.33145816068\n",
      "      - -197920.30398687677\n",
      "      - -198157.22398196565\n",
      "      - -197221.1027055978\n",
      "      - -197586.74490273264\n",
      "      - -197255.26612279643\n",
      "      - -195963.82204339997\n",
      "      - -196613.37438508702\n",
      "      - -195110.31538539933\n",
      "      - -197418.31239113727\n",
      "      - -198530.3046966088\n",
      "      - -197773.57948526344\n",
      "      - -196816.81896132673\n",
      "      - -193925.3823797375\n",
      "      - -198172.77628723733\n",
      "      - -199492.55126871174\n",
      "      - -197190.03824706777\n",
      "      - -195659.00004633292\n",
      "      - -196016.75806573324\n",
      "      - -195430.53330910346\n",
      "      - -195734.64825880635\n",
      "      - -196708.46594074072\n",
      "      - -198106.76887222825\n",
      "      - -196752.44355192228\n",
      "      - -198927.5637957287\n",
      "      - -194795.7732365946\n",
      "      - -196125.3152340425\n",
      "      - -198757.6782025381\n",
      "      - -196925.41754375433\n",
      "      - -196887.17101376725\n",
      "      - -197330.2348606878\n",
      "      - -195981.1220431839\n",
      "      - -200222.34802861002\n",
      "      - -197445.9712935508\n",
      "      - -195404.73739720663\n",
      "      - -197030.32813430676\n",
      "      - -198514.81994546024\n",
      "      - -194685.8993485943\n",
      "      - -198174.31767731847\n",
      "      - -195425.3602187681\n",
      "      - -195681.38342235168\n",
      "      - -197433.46937456809\n",
      "      - -196526.0599974423\n",
      "      - -196152.39048746953\n",
      "      - -195859.22411829102\n",
      "      - -196179.96485597995\n",
      "      - -195217.00406919536\n",
      "      - -197489.07210484854\n",
      "      - -196143.64817100033\n",
      "      - -197676.88644816936\n",
      "      - -194659.9182161978\n",
      "      - -198272.0044205607\n",
      "      - -196224.63223462098\n",
      "      - -198745.92484026667\n",
      "      - -198507.6084783717\n",
      "      - -198840.9064971187\n",
      "      - -196075.3075357945\n",
      "      - -197627.94290185312\n",
      "      - -199549.29299077\n",
      "      - -195436.35874077913\n",
      "      - -196465.5944787393\n",
      "      - -196662.7725720662\n",
      "      - -195923.42437257752\n",
      "      - -193682.75115076028\n",
      "      - -196779.11252362604\n",
      "      - -194838.18038131675\n",
      "      - -199215.17157961248\n",
      "      - -195639.88139282132\n",
      "      - -196340.44783766862\n",
      "      - -196686.7930567612\n",
      "      - -196426.5623517779\n",
      "      - -199529.77199698184\n",
      "      - -194160.90577626348\n",
      "      - -196500.4377480549\n",
      "      - -194753.09271445265\n",
      "      - -197333.09860419497\n",
      "      - -197221.74765168902\n",
      "      - -193928.30515262828\n",
      "      - -197746.580607469\n",
      "      - -198448.87596843863\n",
      "      - -196167.11875834086\n",
      "      - -197066.1127514396\n",
      "      - -197172.63292259348\n",
      "      - -195245.164562761\n",
      "      - -198087.39009323012\n",
      "      - -196289.59236873084\n",
      "      - -200658.68021374906\n",
      "      - -197118.26526109246\n",
      "      - -196312.1031523775\n",
      "      - -199945.9271203543\n",
      "      - -196246.0615731838\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09421014186059853\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4677087259520684\n",
      "      mean_inference_ms: 0.966297551594429\n",
      "      mean_raw_obs_processing_ms: 0.13442845417923122\n",
      "  time_since_restore: 1692.2436590194702\n",
      "  time_this_iter_s: 10.602745056152344\n",
      "  time_total_s: 1692.2436590194702\n",
      "  timers:\n",
      "    learn_throughput: 130977.657\n",
      "    learn_time_ms: 488.511\n",
      "    load_throughput: 21233352.887\n",
      "    load_time_ms: 3.013\n",
      "    training_iteration_time_ms: 9711.73\n",
      "    update_time_ms: 4.164\n",
      "  timestamp: 1665850442\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 11325168\n",
      "  training_iteration: 177\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:14:07 (running for 00:28:42.21)<br>Memory usage on this node: 13.6/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   177</td><td style=\"text-align: right;\">         1692.24</td><td style=\"text-align: right;\">11325168</td><td style=\"text-align: right;\"> -196974</td><td style=\"text-align: right;\">             -193683</td><td style=\"text-align: right;\">             -200814</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 11389152\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 11389152\n",
      "    num_agent_steps_trained: 11389152\n",
      "    num_env_steps_sampled: 11389152\n",
      "    num_env_steps_trained: 11389152\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-14-12\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -193682.75115076028\n",
      "  episode_reward_mean: -196590.54057402172\n",
      "  episode_reward_min: -200822.56710592276\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 11388\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0911412239074707\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.000571546726860106\n",
      "          model: {}\n",
      "          policy_loss: 0.001044401084072888\n",
      "          total_loss: 10.000849723815918\n",
      "          vf_explained_var: -1.797600468478322e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 11389152\n",
      "    num_agent_steps_trained: 11389152\n",
      "    num_env_steps_sampled: 11389152\n",
      "    num_env_steps_trained: 11389152\n",
      "  iterations_since_restore: 178\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 11389152\n",
      "  num_agent_steps_trained: 11389152\n",
      "  num_env_steps_sampled: 11389152\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 11389152\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 84.16428571428574\n",
      "    ram_util_percent: 87.59285714285713\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09420975100624235\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46785628768922577\n",
      "    mean_inference_ms: 0.9666721622704812\n",
      "    mean_raw_obs_processing_ms: 0.1342978745780784\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -193682.75115076028\n",
      "    episode_reward_mean: -196590.54057402172\n",
      "    episode_reward_min: -200822.56710592276\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -193682.75115076028\n",
      "      - -196779.11252362604\n",
      "      - -194838.18038131675\n",
      "      - -199215.17157961248\n",
      "      - -195639.88139282132\n",
      "      - -196340.44783766862\n",
      "      - -196686.7930567612\n",
      "      - -196426.5623517779\n",
      "      - -199529.77199698184\n",
      "      - -194160.90577626348\n",
      "      - -196500.4377480549\n",
      "      - -194753.09271445265\n",
      "      - -197333.09860419497\n",
      "      - -197221.74765168902\n",
      "      - -193928.30515262828\n",
      "      - -197746.580607469\n",
      "      - -198448.87596843863\n",
      "      - -196167.11875834086\n",
      "      - -197066.1127514396\n",
      "      - -197172.63292259348\n",
      "      - -195245.164562761\n",
      "      - -198087.39009323012\n",
      "      - -196289.59236873084\n",
      "      - -200658.68021374906\n",
      "      - -197118.26526109246\n",
      "      - -196312.1031523775\n",
      "      - -199945.9271203543\n",
      "      - -196246.0615731838\n",
      "      - -195318.04851169785\n",
      "      - -194482.49964493758\n",
      "      - -197867.708745383\n",
      "      - -196898.36509254162\n",
      "      - -195847.55304344196\n",
      "      - -197336.42563545133\n",
      "      - -197147.5915686849\n",
      "      - -197787.077078843\n",
      "      - -194009.67739068222\n",
      "      - -194072.508166239\n",
      "      - -197808.56194698272\n",
      "      - -195827.66187265582\n",
      "      - -197443.4662471637\n",
      "      - -196905.22051195242\n",
      "      - -200822.56710592276\n",
      "      - -195904.3866739953\n",
      "      - -194387.12815438394\n",
      "      - -195418.25411409413\n",
      "      - -197755.36950601402\n",
      "      - -195662.5217502008\n",
      "      - -196013.65592989107\n",
      "      - -199336.6070754625\n",
      "      - -195494.61615967363\n",
      "      - -195321.00793568714\n",
      "      - -196927.38712540563\n",
      "      - -194163.61930183298\n",
      "      - -196416.18257900732\n",
      "      - -195995.74387641472\n",
      "      - -195471.46256560966\n",
      "      - -199340.33248639898\n",
      "      - -196917.21085112548\n",
      "      - -197008.87104160903\n",
      "      - -194325.10776570067\n",
      "      - -198221.47224063711\n",
      "      - -196067.14150310974\n",
      "      - -195230.69914472074\n",
      "      - -197132.08403995566\n",
      "      - -195794.37959777523\n",
      "      - -197966.56129090537\n",
      "      - -196731.13423214218\n",
      "      - -196450.55615190545\n",
      "      - -198289.05337820936\n",
      "      - -195539.34411255622\n",
      "      - -198447.9831686787\n",
      "      - -194566.78788857767\n",
      "      - -195996.34638824675\n",
      "      - -199701.46203393125\n",
      "      - -196163.9739185075\n",
      "      - -195757.41321598526\n",
      "      - -195416.08768121692\n",
      "      - -195427.43623508606\n",
      "      - -194098.5921051032\n",
      "      - -194398.34429239715\n",
      "      - -196520.94203991524\n",
      "      - -196432.21114897868\n",
      "      - -197057.6622144418\n",
      "      - -197795.2724111344\n",
      "      - -194890.83452892644\n",
      "      - -198722.96367667196\n",
      "      - -197182.81184044955\n",
      "      - -196403.40144148766\n",
      "      - -197709.99375666355\n",
      "      - -197171.69188171538\n",
      "      - -194360.96732890935\n",
      "      - -196708.2973209857\n",
      "      - -196800.1632004673\n",
      "      - -199710.9587213777\n",
      "      - -194599.99716378414\n",
      "      - -196527.6024168685\n",
      "      - -198135.40531636242\n",
      "      - -197832.0192064691\n",
      "      - -196118.8464394584\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09420975100624235\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46785628768922577\n",
      "      mean_inference_ms: 0.9666721622704812\n",
      "      mean_raw_obs_processing_ms: 0.1342978745780784\n",
      "  time_since_restore: 1702.0324306488037\n",
      "  time_this_iter_s: 9.788771629333496\n",
      "  time_total_s: 1702.0324306488037\n",
      "  timers:\n",
      "    learn_throughput: 129782.584\n",
      "    learn_time_ms: 493.009\n",
      "    load_throughput: 21403544.853\n",
      "    load_time_ms: 2.989\n",
      "    training_iteration_time_ms: 9757.173\n",
      "    update_time_ms: 4.096\n",
      "  timestamp: 1665850452\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 11389152\n",
      "  training_iteration: 178\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:14:17 (running for 00:28:51.85)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   178</td><td style=\"text-align: right;\">         1702.03</td><td style=\"text-align: right;\">11389152</td><td style=\"text-align: right;\"> -196591</td><td style=\"text-align: right;\">             -193683</td><td style=\"text-align: right;\">             -200823</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 11453136\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 11453136\n",
      "    num_agent_steps_trained: 11453136\n",
      "    num_env_steps_sampled: 11453136\n",
      "    num_env_steps_trained: 11453136\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-14-21\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -192613.42333202687\n",
      "  episode_reward_mean: -196470.23687269428\n",
      "  episode_reward_min: -204229.84357989574\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 11448\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0953805446624756\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.000500973837915808\n",
      "          model: {}\n",
      "          policy_loss: 0.0060297721065580845\n",
      "          total_loss: 10.005819320678711\n",
      "          vf_explained_var: -2.2706531765948057e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 11453136\n",
      "    num_agent_steps_trained: 11453136\n",
      "    num_env_steps_sampled: 11453136\n",
      "    num_env_steps_trained: 11453136\n",
      "  iterations_since_restore: 179\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 11453136\n",
      "  num_agent_steps_trained: 11453136\n",
      "  num_env_steps_sampled: 11453136\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 11453136\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.3307692307692\n",
      "    ram_util_percent: 87.4923076923077\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09426191164549504\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46780952965738964\n",
      "    mean_inference_ms: 0.9666977778811416\n",
      "    mean_raw_obs_processing_ms: 0.13446512684589326\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -192613.42333202687\n",
      "    episode_reward_mean: -196470.23687269428\n",
      "    episode_reward_min: -204229.84357989574\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -194325.10776570067\n",
      "      - -198221.47224063711\n",
      "      - -196067.14150310974\n",
      "      - -195230.69914472074\n",
      "      - -197132.08403995566\n",
      "      - -195794.37959777523\n",
      "      - -197966.56129090537\n",
      "      - -196731.13423214218\n",
      "      - -196450.55615190545\n",
      "      - -198289.05337820936\n",
      "      - -195539.34411255622\n",
      "      - -198447.9831686787\n",
      "      - -194566.78788857767\n",
      "      - -195996.34638824675\n",
      "      - -199701.46203393125\n",
      "      - -196163.9739185075\n",
      "      - -195757.41321598526\n",
      "      - -195416.08768121692\n",
      "      - -195427.43623508606\n",
      "      - -194098.5921051032\n",
      "      - -194398.34429239715\n",
      "      - -196520.94203991524\n",
      "      - -196432.21114897868\n",
      "      - -197057.6622144418\n",
      "      - -197795.2724111344\n",
      "      - -194890.83452892644\n",
      "      - -198722.96367667196\n",
      "      - -197182.81184044955\n",
      "      - -196403.40144148766\n",
      "      - -197709.99375666355\n",
      "      - -197171.69188171538\n",
      "      - -194360.96732890935\n",
      "      - -196708.2973209857\n",
      "      - -196800.1632004673\n",
      "      - -199710.9587213777\n",
      "      - -194599.99716378414\n",
      "      - -196527.6024168685\n",
      "      - -198135.40531636242\n",
      "      - -197832.0192064691\n",
      "      - -196118.8464394584\n",
      "      - -194943.52946317696\n",
      "      - -195853.75696450623\n",
      "      - -196333.0256426088\n",
      "      - -198620.6237363087\n",
      "      - -197467.27837153047\n",
      "      - -194530.45152728306\n",
      "      - -196402.4751266242\n",
      "      - -204229.84357989574\n",
      "      - -197563.6876262942\n",
      "      - -197446.70493916783\n",
      "      - -196691.4970591229\n",
      "      - -197275.31540080567\n",
      "      - -197974.88695040342\n",
      "      - -195629.59987617398\n",
      "      - -195214.05891816661\n",
      "      - -194643.35836424783\n",
      "      - -195262.11101705054\n",
      "      - -196499.40135338347\n",
      "      - -197403.15365986456\n",
      "      - -193949.79264248826\n",
      "      - -196204.25923551622\n",
      "      - -193696.60386138104\n",
      "      - -196202.39439311257\n",
      "      - -197080.20975360138\n",
      "      - -195057.67760227562\n",
      "      - -197076.22371714606\n",
      "      - -196029.20569857644\n",
      "      - -192613.42333202687\n",
      "      - -195499.63302838436\n",
      "      - -197988.25691685468\n",
      "      - -196205.50599615183\n",
      "      - -196851.16057787254\n",
      "      - -198046.10388969627\n",
      "      - -194878.37906915756\n",
      "      - -197482.01147624626\n",
      "      - -195235.0021581521\n",
      "      - -195744.45937577324\n",
      "      - -196025.453887712\n",
      "      - -199968.89854593686\n",
      "      - -195401.0070022018\n",
      "      - -196934.19213238455\n",
      "      - -195421.941890881\n",
      "      - -195952.76515412715\n",
      "      - -195543.7246715698\n",
      "      - -194790.7749649088\n",
      "      - -195699.83722132465\n",
      "      - -196516.98074238322\n",
      "      - -197073.85232678716\n",
      "      - -195199.88210170952\n",
      "      - -193718.310418983\n",
      "      - -197779.86969519086\n",
      "      - -196968.35060075452\n",
      "      - -195972.59199707038\n",
      "      - -197904.3575571152\n",
      "      - -196700.17697196157\n",
      "      - -197892.21310043626\n",
      "      - -196546.2714165066\n",
      "      - -196589.97473840488\n",
      "      - -197507.72250981303\n",
      "      - -196685.47287981963\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09426191164549504\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46780952965738964\n",
      "      mean_inference_ms: 0.9666977778811416\n",
      "      mean_raw_obs_processing_ms: 0.13446512684589326\n",
      "  time_since_restore: 1711.3293342590332\n",
      "  time_this_iter_s: 9.296903610229492\n",
      "  time_total_s: 1711.3293342590332\n",
      "  timers:\n",
      "    learn_throughput: 129533.087\n",
      "    learn_time_ms: 493.959\n",
      "    load_throughput: 21764419.18\n",
      "    load_time_ms: 2.94\n",
      "    training_iteration_time_ms: 9754.636\n",
      "    update_time_ms: 4.02\n",
      "  timestamp: 1665850461\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 11453136\n",
      "  training_iteration: 179\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:14:26 (running for 00:29:01.36)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   179</td><td style=\"text-align: right;\">         1711.33</td><td style=\"text-align: right;\">11453136</td><td style=\"text-align: right;\"> -196470</td><td style=\"text-align: right;\">             -192613</td><td style=\"text-align: right;\">             -204230</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 11517120\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 11517120\n",
      "    num_agent_steps_trained: 11517120\n",
      "    num_env_steps_sampled: 11517120\n",
      "    num_env_steps_trained: 11517120\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-14-31\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -192613.42333202687\n",
      "  episode_reward_mean: -196274.04277243617\n",
      "  episode_reward_min: -201209.0676735488\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 11508\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.096754312515259\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0006385674932971597\n",
      "          model: {}\n",
      "          policy_loss: 0.0052358671091496944\n",
      "          total_loss: 10.005053520202637\n",
      "          vf_explained_var: -5.108969602929392e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 11517120\n",
      "    num_agent_steps_trained: 11517120\n",
      "    num_env_steps_sampled: 11517120\n",
      "    num_env_steps_trained: 11517120\n",
      "  iterations_since_restore: 180\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 11517120\n",
      "  num_agent_steps_trained: 11517120\n",
      "  num_env_steps_sampled: 11517120\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 11517120\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.1923076923077\n",
      "    ram_util_percent: 87.47692307692309\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0941983783010659\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46771874191130686\n",
      "    mean_inference_ms: 0.9664034655022223\n",
      "    mean_raw_obs_processing_ms: 0.13443867223321995\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -192613.42333202687\n",
      "    episode_reward_mean: -196274.04277243617\n",
      "    episode_reward_min: -201209.0676735488\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -196204.25923551622\n",
      "      - -193696.60386138104\n",
      "      - -196202.39439311257\n",
      "      - -197080.20975360138\n",
      "      - -195057.67760227562\n",
      "      - -197076.22371714606\n",
      "      - -196029.20569857644\n",
      "      - -192613.42333202687\n",
      "      - -195499.63302838436\n",
      "      - -197988.25691685468\n",
      "      - -196205.50599615183\n",
      "      - -196851.16057787254\n",
      "      - -198046.10388969627\n",
      "      - -194878.37906915756\n",
      "      - -197482.01147624626\n",
      "      - -195235.0021581521\n",
      "      - -195744.45937577324\n",
      "      - -196025.453887712\n",
      "      - -199968.89854593686\n",
      "      - -195401.0070022018\n",
      "      - -196934.19213238455\n",
      "      - -195421.941890881\n",
      "      - -195952.76515412715\n",
      "      - -195543.7246715698\n",
      "      - -194790.7749649088\n",
      "      - -195699.83722132465\n",
      "      - -196516.98074238322\n",
      "      - -197073.85232678716\n",
      "      - -195199.88210170952\n",
      "      - -193718.310418983\n",
      "      - -197779.86969519086\n",
      "      - -196968.35060075452\n",
      "      - -195972.59199707038\n",
      "      - -197904.3575571152\n",
      "      - -196700.17697196157\n",
      "      - -197892.21310043626\n",
      "      - -196546.2714165066\n",
      "      - -196589.97473840488\n",
      "      - -197507.72250981303\n",
      "      - -196685.47287981963\n",
      "      - -195947.33565897017\n",
      "      - -195540.6302201611\n",
      "      - -195735.82021425318\n",
      "      - -198918.18314968667\n",
      "      - -196047.39904590475\n",
      "      - -194163.210578095\n",
      "      - -196521.88419862243\n",
      "      - -200985.59560026324\n",
      "      - -195205.18566380392\n",
      "      - -196644.3384096842\n",
      "      - -197633.84812344337\n",
      "      - -195488.0015215766\n",
      "      - -198253.9942472101\n",
      "      - -195774.86997093938\n",
      "      - -196296.0994281459\n",
      "      - -199819.35572284122\n",
      "      - -195169.07962305174\n",
      "      - -197984.13385792985\n",
      "      - -198227.40536658623\n",
      "      - -195576.2877252714\n",
      "      - -196602.16141231498\n",
      "      - -193038.61271318197\n",
      "      - -195712.45850908637\n",
      "      - -198044.93893628864\n",
      "      - -195176.13189360278\n",
      "      - -194479.05657302836\n",
      "      - -199807.21846967237\n",
      "      - -196842.36208262976\n",
      "      - -193925.50464032276\n",
      "      - -196189.8993601587\n",
      "      - -196558.36376735274\n",
      "      - -198430.79177910235\n",
      "      - -195137.2140470376\n",
      "      - -195310.68591207213\n",
      "      - -195576.88514009857\n",
      "      - -193912.72230941127\n",
      "      - -197186.52554365172\n",
      "      - -195428.89985821722\n",
      "      - -198538.22998170994\n",
      "      - -195206.9082614637\n",
      "      - -193511.75581507155\n",
      "      - -195844.84430882733\n",
      "      - -197474.74743134194\n",
      "      - -195091.88833460893\n",
      "      - -194692.41035053428\n",
      "      - -194990.4707909359\n",
      "      - -195485.49320010617\n",
      "      - -193020.05850400188\n",
      "      - -197150.2488300174\n",
      "      - -201209.0676735488\n",
      "      - -197026.46150193992\n",
      "      - -198316.90524961174\n",
      "      - -193349.83422238857\n",
      "      - -194919.94079877972\n",
      "      - -196369.0116118176\n",
      "      - -198234.14020662932\n",
      "      - -195668.13400219602\n",
      "      - -196567.26764467778\n",
      "      - -193917.69707401996\n",
      "      - -196840.53756581378\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.0941983783010659\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46771874191130686\n",
      "      mean_inference_ms: 0.9664034655022223\n",
      "      mean_raw_obs_processing_ms: 0.13443867223321995\n",
      "  time_since_restore: 1720.7059450149536\n",
      "  time_this_iter_s: 9.37661075592041\n",
      "  time_total_s: 1720.7059450149536\n",
      "  timers:\n",
      "    learn_throughput: 119328.312\n",
      "    learn_time_ms: 536.201\n",
      "    load_throughput: 21823355.3\n",
      "    load_time_ms: 2.932\n",
      "    training_iteration_time_ms: 9730.586\n",
      "    update_time_ms: 3.929\n",
      "  timestamp: 1665850471\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 11517120\n",
      "  training_iteration: 180\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:14:36 (running for 00:29:10.78)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   180</td><td style=\"text-align: right;\">         1720.71</td><td style=\"text-align: right;\">11517120</td><td style=\"text-align: right;\"> -196274</td><td style=\"text-align: right;\">             -192613</td><td style=\"text-align: right;\">             -201209</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 11581104\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 11581104\n",
      "    num_agent_steps_trained: 11581104\n",
      "    num_env_steps_sampled: 11581104\n",
      "    num_env_steps_trained: 11581104\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-14-40\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -192750.12789678227\n",
      "  episode_reward_mean: -196150.98039590026\n",
      "  episode_reward_min: -203916.93579836545\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 11580\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0952537059783936\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.001088618184439838\n",
      "          model: {}\n",
      "          policy_loss: 0.0007209588657133281\n",
      "          total_loss: 10.000630378723145\n",
      "          vf_explained_var: -4.068253645073128e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 11581104\n",
      "    num_agent_steps_trained: 11581104\n",
      "    num_env_steps_sampled: 11581104\n",
      "    num_env_steps_trained: 11581104\n",
      "  iterations_since_restore: 181\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 11581104\n",
      "  num_agent_steps_trained: 11581104\n",
      "  num_env_steps_sampled: 11581104\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 11581104\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.36923076923078\n",
      "    ram_util_percent: 87.4923076923077\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09415838011640153\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4676653783140044\n",
      "    mean_inference_ms: 0.9657916777611186\n",
      "    mean_raw_obs_processing_ms: 0.13425068815613586\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -192750.12789678227\n",
      "    episode_reward_mean: -196150.98039590026\n",
      "    episode_reward_min: -203916.93579836545\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -195137.2140470376\n",
      "      - -195310.68591207213\n",
      "      - -195576.88514009857\n",
      "      - -193912.72230941127\n",
      "      - -197186.52554365172\n",
      "      - -195428.89985821722\n",
      "      - -198538.22998170994\n",
      "      - -195206.9082614637\n",
      "      - -193511.75581507155\n",
      "      - -195844.84430882733\n",
      "      - -197474.74743134194\n",
      "      - -195091.88833460893\n",
      "      - -194692.41035053428\n",
      "      - -194990.4707909359\n",
      "      - -195485.49320010617\n",
      "      - -193020.05850400188\n",
      "      - -197150.2488300174\n",
      "      - -201209.0676735488\n",
      "      - -197026.46150193992\n",
      "      - -198316.90524961174\n",
      "      - -193349.83422238857\n",
      "      - -194919.94079877972\n",
      "      - -196369.0116118176\n",
      "      - -198234.14020662932\n",
      "      - -195668.13400219602\n",
      "      - -196567.26764467778\n",
      "      - -193917.69707401996\n",
      "      - -196840.53756581378\n",
      "      - -192750.12789678227\n",
      "      - -195659.37528954973\n",
      "      - -195947.60348663418\n",
      "      - -197969.49356068045\n",
      "      - -195579.58536841263\n",
      "      - -196862.02669017218\n",
      "      - -195245.71078086406\n",
      "      - -194918.9706052303\n",
      "      - -196417.23712096742\n",
      "      - -194892.780748543\n",
      "      - -197197.02990813812\n",
      "      - -194164.81401956553\n",
      "      - -197622.49532294823\n",
      "      - -194859.43992187508\n",
      "      - -196065.33018442537\n",
      "      - -195458.25088070784\n",
      "      - -196368.8218605829\n",
      "      - -194672.0936615628\n",
      "      - -196907.595197415\n",
      "      - -197242.43057320183\n",
      "      - -197632.77300679364\n",
      "      - -197517.0362983566\n",
      "      - -198826.9328023147\n",
      "      - -198065.8496719333\n",
      "      - -196169.27745873373\n",
      "      - -196231.1244048343\n",
      "      - -197533.4666650396\n",
      "      - -197794.18272827574\n",
      "      - -195401.26284237092\n",
      "      - -197849.71883797602\n",
      "      - -194007.0275670854\n",
      "      - -195699.42452839337\n",
      "      - -195366.2851764307\n",
      "      - -198991.85805897595\n",
      "      - -193641.48430696476\n",
      "      - -203916.93579836545\n",
      "      - -194033.12772992658\n",
      "      - -196885.38523145148\n",
      "      - -197788.24536565784\n",
      "      - -194252.57518293324\n",
      "      - -195660.3684221485\n",
      "      - -195840.31271195758\n",
      "      - -195674.26040306324\n",
      "      - -195786.37908234695\n",
      "      - -195684.09052157612\n",
      "      - -196246.16255228056\n",
      "      - -197028.06779664752\n",
      "      - -197693.392716395\n",
      "      - -197350.6379963541\n",
      "      - -195601.13007489362\n",
      "      - -196578.4399243474\n",
      "      - -196548.1444948024\n",
      "      - -197236.68487596617\n",
      "      - -195162.62862947077\n",
      "      - -197494.60837548226\n",
      "      - -196249.07009713864\n",
      "      - -195244.9411445795\n",
      "      - -195036.65340226528\n",
      "      - -196140.17499584527\n",
      "      - -197208.146390417\n",
      "      - -198246.91071023146\n",
      "      - -195072.76106449973\n",
      "      - -194894.63314167986\n",
      "      - -195502.1738876333\n",
      "      - -196159.3853705697\n",
      "      - -195190.05747034468\n",
      "      - -197239.07401720737\n",
      "      - -192852.7462736461\n",
      "      - -196021.2403871156\n",
      "      - -198469.51867681762\n",
      "      - -194446.3845009027\n",
      "      - -195154.6865697971\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09415838011640153\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4676653783140044\n",
      "      mean_inference_ms: 0.9657916777611186\n",
      "      mean_raw_obs_processing_ms: 0.13425068815613586\n",
      "  time_since_restore: 1729.737815618515\n",
      "  time_this_iter_s: 9.031870603561401\n",
      "  time_total_s: 1729.737815618515\n",
      "  timers:\n",
      "    learn_throughput: 119940.668\n",
      "    learn_time_ms: 533.464\n",
      "    load_throughput: 22196996.529\n",
      "    load_time_ms: 2.883\n",
      "    training_iteration_time_ms: 9669.729\n",
      "    update_time_ms: 3.922\n",
      "  timestamp: 1665850480\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 11581104\n",
      "  training_iteration: 181\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:14:45 (running for 00:29:19.65)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   181</td><td style=\"text-align: right;\">         1729.74</td><td style=\"text-align: right;\">11581104</td><td style=\"text-align: right;\"> -196151</td><td style=\"text-align: right;\">             -192750</td><td style=\"text-align: right;\">             -203917</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 11645088\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 11645088\n",
      "    num_agent_steps_trained: 11645088\n",
      "    num_env_steps_sampled: 11645088\n",
      "    num_env_steps_trained: 11645088\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-14-49\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -192217.07823663883\n",
      "  episode_reward_mean: -195762.70697559867\n",
      "  episode_reward_min: -203916.93579836545\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 11640\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0959699153900146\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0007323726895265281\n",
      "          model: {}\n",
      "          policy_loss: 0.006751253269612789\n",
      "          total_loss: 10.006587028503418\n",
      "          vf_explained_var: -4.8251379780595016e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 11645088\n",
      "    num_agent_steps_trained: 11645088\n",
      "    num_env_steps_sampled: 11645088\n",
      "    num_env_steps_trained: 11645088\n",
      "  iterations_since_restore: 182\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 11645088\n",
      "  num_agent_steps_trained: 11645088\n",
      "  num_env_steps_sampled: 11645088\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 11645088\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.13076923076923\n",
      "    ram_util_percent: 87.44615384615386\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09420231855090914\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46751073391033315\n",
      "    mean_inference_ms: 0.9656579118321238\n",
      "    mean_raw_obs_processing_ms: 0.13440691005345565\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -192217.07823663883\n",
      "    episode_reward_mean: -195762.70697559867\n",
      "    episode_reward_min: -203916.93579836545\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -195366.2851764307\n",
      "      - -198991.85805897595\n",
      "      - -193641.48430696476\n",
      "      - -203916.93579836545\n",
      "      - -194033.12772992658\n",
      "      - -196885.38523145148\n",
      "      - -197788.24536565784\n",
      "      - -194252.57518293324\n",
      "      - -195660.3684221485\n",
      "      - -195840.31271195758\n",
      "      - -195674.26040306324\n",
      "      - -195786.37908234695\n",
      "      - -195684.09052157612\n",
      "      - -196246.16255228056\n",
      "      - -197028.06779664752\n",
      "      - -197693.392716395\n",
      "      - -197350.6379963541\n",
      "      - -195601.13007489362\n",
      "      - -196578.4399243474\n",
      "      - -196548.1444948024\n",
      "      - -197236.68487596617\n",
      "      - -195162.62862947077\n",
      "      - -197494.60837548226\n",
      "      - -196249.07009713864\n",
      "      - -195244.9411445795\n",
      "      - -195036.65340226528\n",
      "      - -196140.17499584527\n",
      "      - -197208.146390417\n",
      "      - -198246.91071023146\n",
      "      - -195072.76106449973\n",
      "      - -194894.63314167986\n",
      "      - -195502.1738876333\n",
      "      - -196159.3853705697\n",
      "      - -195190.05747034468\n",
      "      - -197239.07401720737\n",
      "      - -192852.7462736461\n",
      "      - -196021.2403871156\n",
      "      - -198469.51867681762\n",
      "      - -194446.3845009027\n",
      "      - -195154.6865697971\n",
      "      - -195506.90980716058\n",
      "      - -195768.27159484432\n",
      "      - -195385.59022822254\n",
      "      - -195480.88099327605\n",
      "      - -195444.72342563517\n",
      "      - -198287.41765118236\n",
      "      - -195100.03812076198\n",
      "      - -196287.7474930758\n",
      "      - -194125.3190240792\n",
      "      - -196272.94526547677\n",
      "      - -194243.3494699585\n",
      "      - -194574.1791303435\n",
      "      - -195955.44529471727\n",
      "      - -193399.40328483123\n",
      "      - -194336.2662479257\n",
      "      - -193306.19601461384\n",
      "      - -195454.00805543357\n",
      "      - -196892.62460826375\n",
      "      - -194661.51875479432\n",
      "      - -194395.2421601924\n",
      "      - -192968.97412382346\n",
      "      - -197517.12694654436\n",
      "      - -193416.60370743147\n",
      "      - -192217.07823663883\n",
      "      - -196697.68032676412\n",
      "      - -195965.60041247643\n",
      "      - -198478.8531681596\n",
      "      - -194770.05720212858\n",
      "      - -200052.0279111262\n",
      "      - -192572.01713151697\n",
      "      - -197382.94244884877\n",
      "      - -194567.6002604956\n",
      "      - -194811.93575663277\n",
      "      - -196437.3702013644\n",
      "      - -192461.88723349877\n",
      "      - -192886.45066591096\n",
      "      - -198827.4668432775\n",
      "      - -193694.9813196788\n",
      "      - -194084.45501267532\n",
      "      - -193769.31589355168\n",
      "      - -196494.53937118102\n",
      "      - -195941.18092954578\n",
      "      - -195089.54057962674\n",
      "      - -194332.67976278107\n",
      "      - -195015.2561781587\n",
      "      - -196961.77781270051\n",
      "      - -195456.72293148123\n",
      "      - -197693.84466984568\n",
      "      - -197150.11426894934\n",
      "      - -195228.6407485671\n",
      "      - -194892.31895329527\n",
      "      - -197528.84417698672\n",
      "      - -194755.87873054363\n",
      "      - -195504.78681229387\n",
      "      - -194294.9881530675\n",
      "      - -196713.10487237072\n",
      "      - -197643.8625208519\n",
      "      - -195510.04839856483\n",
      "      - -197772.30891932\n",
      "      - -194241.99381327417\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09420231855090914\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46751073391033315\n",
      "      mean_inference_ms: 0.9656579118321238\n",
      "      mean_raw_obs_processing_ms: 0.13440691005345565\n",
      "  time_since_restore: 1738.8807437419891\n",
      "  time_this_iter_s: 9.142928123474121\n",
      "  time_total_s: 1738.8807437419891\n",
      "  timers:\n",
      "    learn_throughput: 119967.685\n",
      "    learn_time_ms: 533.344\n",
      "    load_throughput: 22211877.567\n",
      "    load_time_ms: 2.881\n",
      "    training_iteration_time_ms: 9639.738\n",
      "    update_time_ms: 3.956\n",
      "  timestamp: 1665850489\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 11645088\n",
      "  training_iteration: 182\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:14:50 (running for 00:29:24.95)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   182</td><td style=\"text-align: right;\">         1738.88</td><td style=\"text-align: right;\">11645088</td><td style=\"text-align: right;\"> -195763</td><td style=\"text-align: right;\">             -192217</td><td style=\"text-align: right;\">             -203917</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:14:55 (running for 00:29:29.96)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   182</td><td style=\"text-align: right;\">         1738.88</td><td style=\"text-align: right;\">11645088</td><td style=\"text-align: right;\"> -195763</td><td style=\"text-align: right;\">             -192217</td><td style=\"text-align: right;\">             -203917</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 11709072\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 11709072\n",
      "    num_agent_steps_trained: 11709072\n",
      "    num_env_steps_sampled: 11709072\n",
      "    num_env_steps_trained: 11709072\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-14-59\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -191972.55538363737\n",
      "  episode_reward_mean: -195418.95133892226\n",
      "  episode_reward_min: -200355.3907960356\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 11700\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0992510318756104\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.000387260370189324\n",
      "          model: {}\n",
      "          policy_loss: 0.0050446768291294575\n",
      "          total_loss: 10.00481128692627\n",
      "          vf_explained_var: -2.176042634971509e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 11709072\n",
      "    num_agent_steps_trained: 11709072\n",
      "    num_env_steps_sampled: 11709072\n",
      "    num_env_steps_trained: 11709072\n",
      "  iterations_since_restore: 183\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 11709072\n",
      "  num_agent_steps_trained: 11709072\n",
      "  num_env_steps_sampled: 11709072\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 11709072\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 85.16923076923078\n",
      "    ram_util_percent: 87.5\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09418294027021748\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.467456338708582\n",
      "    mean_inference_ms: 0.9658037219174638\n",
      "    mean_raw_obs_processing_ms: 0.1343754847665548\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -191972.55538363737\n",
      "    episode_reward_mean: -195418.95133892226\n",
      "    episode_reward_min: -200355.3907960356\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -192968.97412382346\n",
      "      - -197517.12694654436\n",
      "      - -193416.60370743147\n",
      "      - -192217.07823663883\n",
      "      - -196697.68032676412\n",
      "      - -195965.60041247643\n",
      "      - -198478.8531681596\n",
      "      - -194770.05720212858\n",
      "      - -200052.0279111262\n",
      "      - -192572.01713151697\n",
      "      - -197382.94244884877\n",
      "      - -194567.6002604956\n",
      "      - -194811.93575663277\n",
      "      - -196437.3702013644\n",
      "      - -192461.88723349877\n",
      "      - -192886.45066591096\n",
      "      - -198827.4668432775\n",
      "      - -193694.9813196788\n",
      "      - -194084.45501267532\n",
      "      - -193769.31589355168\n",
      "      - -196494.53937118102\n",
      "      - -195941.18092954578\n",
      "      - -195089.54057962674\n",
      "      - -194332.67976278107\n",
      "      - -195015.2561781587\n",
      "      - -196961.77781270051\n",
      "      - -195456.72293148123\n",
      "      - -197693.84466984568\n",
      "      - -197150.11426894934\n",
      "      - -195228.6407485671\n",
      "      - -194892.31895329527\n",
      "      - -197528.84417698672\n",
      "      - -194755.87873054363\n",
      "      - -195504.78681229387\n",
      "      - -194294.9881530675\n",
      "      - -196713.10487237072\n",
      "      - -197643.8625208519\n",
      "      - -195510.04839856483\n",
      "      - -197772.30891932\n",
      "      - -194241.99381327417\n",
      "      - -200355.3907960356\n",
      "      - -194040.9907891787\n",
      "      - -194437.9944652575\n",
      "      - -195403.98935054502\n",
      "      - -193177.0929191479\n",
      "      - -195768.233660397\n",
      "      - -196879.45787624153\n",
      "      - -195891.6303380943\n",
      "      - -196549.76563943157\n",
      "      - -193893.54482186362\n",
      "      - -193808.2000799615\n",
      "      - -195374.32631345876\n",
      "      - -197466.00209282522\n",
      "      - -195815.12230032362\n",
      "      - -197909.0896784137\n",
      "      - -194849.6475433389\n",
      "      - -196045.06994305\n",
      "      - -196026.98563785022\n",
      "      - -196077.04626936567\n",
      "      - -194547.66783189046\n",
      "      - -199054.2693004964\n",
      "      - -195941.53970419068\n",
      "      - -194592.10962550202\n",
      "      - -197377.6205752203\n",
      "      - -195567.68099120827\n",
      "      - -195398.000425933\n",
      "      - -192787.10702705922\n",
      "      - -196205.86158381257\n",
      "      - -192758.06309918268\n",
      "      - -194299.04677584345\n",
      "      - -193280.03252157566\n",
      "      - -193007.45493471215\n",
      "      - -194658.193100494\n",
      "      - -195165.59774842905\n",
      "      - -194951.7104228062\n",
      "      - -192650.58221625802\n",
      "      - -194353.63416970865\n",
      "      - -193460.4647581833\n",
      "      - -195228.2292083361\n",
      "      - -194787.01887369002\n",
      "      - -194344.55313053352\n",
      "      - -199785.33957093008\n",
      "      - -195619.0152909727\n",
      "      - -194855.59691034953\n",
      "      - -199261.87472088877\n",
      "      - -193475.93489644758\n",
      "      - -193230.29125856818\n",
      "      - -196494.1791174558\n",
      "      - -192622.93331658994\n",
      "      - -196774.88280370052\n",
      "      - -198596.62465794443\n",
      "      - -196437.7931155602\n",
      "      - -193549.10601914837\n",
      "      - -196280.14156085308\n",
      "      - -199045.77190565303\n",
      "      - -191972.55538363737\n",
      "      - -195813.27951879555\n",
      "      - -192238.05717299986\n",
      "      - -194436.30884800162\n",
      "      - -195416.57187793424\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09418294027021748\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.467456338708582\n",
      "      mean_inference_ms: 0.9658037219174638\n",
      "      mean_raw_obs_processing_ms: 0.1343754847665548\n",
      "  time_since_restore: 1748.7415707111359\n",
      "  time_this_iter_s: 9.860826969146729\n",
      "  time_total_s: 1748.7415707111359\n",
      "  timers:\n",
      "    learn_throughput: 119675.318\n",
      "    learn_time_ms: 534.647\n",
      "    load_throughput: 22466062.294\n",
      "    load_time_ms: 2.848\n",
      "    training_iteration_time_ms: 9573.116\n",
      "    update_time_ms: 4.122\n",
      "  timestamp: 1665850499\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 11709072\n",
      "  training_iteration: 183\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:15:04 (running for 00:29:38.72)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   183</td><td style=\"text-align: right;\">         1748.74</td><td style=\"text-align: right;\">11709072</td><td style=\"text-align: right;\"> -195419</td><td style=\"text-align: right;\">             -191973</td><td style=\"text-align: right;\">             -200355</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 11773056\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 11773056\n",
      "    num_agent_steps_trained: 11773056\n",
      "    num_env_steps_sampled: 11773056\n",
      "    num_env_steps_trained: 11773056\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-15-08\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -191839.6433560653\n",
      "  episode_reward_mean: -195639.26313421875\n",
      "  episode_reward_min: -205508.73034860074\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 11772\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.098249673843384\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.001190322102047503\n",
      "          model: {}\n",
      "          policy_loss: 0.00046215124893933535\n",
      "          total_loss: 10.000391006469727\n",
      "          vf_explained_var: -1.0407160466741061e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 11773056\n",
      "    num_agent_steps_trained: 11773056\n",
      "    num_env_steps_sampled: 11773056\n",
      "    num_env_steps_trained: 11773056\n",
      "  iterations_since_restore: 184\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 11773056\n",
      "  num_agent_steps_trained: 11773056\n",
      "  num_env_steps_sampled: 11773056\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 11773056\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 80.37857142857142\n",
      "    ram_util_percent: 87.5\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09415766308428271\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4675071471268306\n",
      "    mean_inference_ms: 0.9658139561401022\n",
      "    mean_raw_obs_processing_ms: 0.13418744445848255\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -191839.6433560653\n",
      "    episode_reward_mean: -195639.26313421875\n",
      "    episode_reward_min: -205508.73034860074\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -194658.193100494\n",
      "      - -195165.59774842905\n",
      "      - -194951.7104228062\n",
      "      - -192650.58221625802\n",
      "      - -194353.63416970865\n",
      "      - -193460.4647581833\n",
      "      - -195228.2292083361\n",
      "      - -194787.01887369002\n",
      "      - -194344.55313053352\n",
      "      - -199785.33957093008\n",
      "      - -195619.0152909727\n",
      "      - -194855.59691034953\n",
      "      - -199261.87472088877\n",
      "      - -193475.93489644758\n",
      "      - -193230.29125856818\n",
      "      - -196494.1791174558\n",
      "      - -192622.93331658994\n",
      "      - -196774.88280370052\n",
      "      - -198596.62465794443\n",
      "      - -196437.7931155602\n",
      "      - -193549.10601914837\n",
      "      - -196280.14156085308\n",
      "      - -199045.77190565303\n",
      "      - -191972.55538363737\n",
      "      - -195813.27951879555\n",
      "      - -192238.05717299986\n",
      "      - -194436.30884800162\n",
      "      - -195416.57187793424\n",
      "      - -195062.60805874615\n",
      "      - -193936.78711034305\n",
      "      - -194238.48850008482\n",
      "      - -194462.2469806628\n",
      "      - -196669.83114575595\n",
      "      - -193818.924369312\n",
      "      - -200152.85303240124\n",
      "      - -194261.91929581348\n",
      "      - -197094.1209857733\n",
      "      - -196313.53198812288\n",
      "      - -195402.92253476012\n",
      "      - -192153.80128955998\n",
      "      - -197809.1119858359\n",
      "      - -195481.73017701082\n",
      "      - -194562.49854646946\n",
      "      - -194592.48159526536\n",
      "      - -198209.84478159502\n",
      "      - -194424.72504637484\n",
      "      - -196336.8505233066\n",
      "      - -194761.54186770107\n",
      "      - -193231.4253247357\n",
      "      - -195143.20810769853\n",
      "      - -194796.1712886348\n",
      "      - -201331.57977543303\n",
      "      - -197816.83393553656\n",
      "      - -198336.36737485687\n",
      "      - -197761.34616944997\n",
      "      - -195152.82852679907\n",
      "      - -194667.74758200286\n",
      "      - -197419.3401411252\n",
      "      - -197942.5853300665\n",
      "      - -193219.46871669122\n",
      "      - -196846.17240961402\n",
      "      - -194271.4481452597\n",
      "      - -195107.3787994528\n",
      "      - -199539.1000159486\n",
      "      - -193531.819357378\n",
      "      - -195897.86442997147\n",
      "      - -196839.41028573623\n",
      "      - -197374.2345012928\n",
      "      - -197258.47451843138\n",
      "      - -194036.434695692\n",
      "      - -194396.15640997927\n",
      "      - -193743.4163304255\n",
      "      - -193619.32386031328\n",
      "      - -195432.20995956488\n",
      "      - -197738.553485513\n",
      "      - -205508.73034860074\n",
      "      - -196894.08272430222\n",
      "      - -204833.3555768217\n",
      "      - -195638.09366055098\n",
      "      - -196165.6349009393\n",
      "      - -192246.4916445201\n",
      "      - -195457.67801997348\n",
      "      - -192410.387329003\n",
      "      - -196090.29111635985\n",
      "      - -193306.58113954175\n",
      "      - -193949.1085452755\n",
      "      - -197770.69934192032\n",
      "      - -194619.1751254425\n",
      "      - -194139.3737709465\n",
      "      - -195005.68558669375\n",
      "      - -193834.7092460555\n",
      "      - -194720.14979160408\n",
      "      - -195528.23365248222\n",
      "      - -196545.26970362203\n",
      "      - -198382.8634024145\n",
      "      - -196013.9136798623\n",
      "      - -191839.6433560653\n",
      "      - -193973.86208679216\n",
      "      - -197325.72300106735\n",
      "      - -194022.61580364595\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09415766308428271\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4675071471268306\n",
      "      mean_inference_ms: 0.9658139561401022\n",
      "      mean_raw_obs_processing_ms: 0.13418744445848255\n",
      "  time_since_restore: 1758.2071828842163\n",
      "  time_this_iter_s: 9.465612173080444\n",
      "  time_total_s: 1758.2071828842163\n",
      "  timers:\n",
      "    learn_throughput: 119220.525\n",
      "    learn_time_ms: 536.686\n",
      "    load_throughput: 22334435.801\n",
      "    load_time_ms: 2.865\n",
      "    training_iteration_time_ms: 9580.24\n",
      "    update_time_ms: 4.205\n",
      "  timestamp: 1665850508\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 11773056\n",
      "  training_iteration: 184\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:15:14 (running for 00:29:48.50)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   184</td><td style=\"text-align: right;\">         1758.21</td><td style=\"text-align: right;\">11773056</td><td style=\"text-align: right;\"> -195639</td><td style=\"text-align: right;\">             -191840</td><td style=\"text-align: right;\">             -205509</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 11837040\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 11837040\n",
      "    num_agent_steps_trained: 11837040\n",
      "    num_env_steps_sampled: 11837040\n",
      "    num_env_steps_trained: 11837040\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-15-18\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -191839.6433560653\n",
      "  episode_reward_mean: -195791.26605380117\n",
      "  episode_reward_min: -205508.73034860074\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 11832\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1020355224609375\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0005152799421921372\n",
      "          model: {}\n",
      "          policy_loss: 0.005815837997943163\n",
      "          total_loss: 10.005608558654785\n",
      "          vf_explained_var: -3.0275376872168636e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 11837040\n",
      "    num_agent_steps_trained: 11837040\n",
      "    num_env_steps_sampled: 11837040\n",
      "    num_env_steps_trained: 11837040\n",
      "  iterations_since_restore: 185\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 11837040\n",
      "  num_agent_steps_trained: 11837040\n",
      "  num_env_steps_sampled: 11837040\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 11837040\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.70769230769231\n",
      "    ram_util_percent: 87.47692307692306\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09419762580918484\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4674084575404025\n",
      "    mean_inference_ms: 0.9658609174501926\n",
      "    mean_raw_obs_processing_ms: 0.13435104603926284\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -191839.6433560653\n",
      "    episode_reward_mean: -195791.26605380117\n",
      "    episode_reward_min: -205508.73034860074\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -196846.17240961402\n",
      "      - -194271.4481452597\n",
      "      - -195107.3787994528\n",
      "      - -199539.1000159486\n",
      "      - -193531.819357378\n",
      "      - -195897.86442997147\n",
      "      - -196839.41028573623\n",
      "      - -197374.2345012928\n",
      "      - -197258.47451843138\n",
      "      - -194036.434695692\n",
      "      - -194396.15640997927\n",
      "      - -193743.4163304255\n",
      "      - -193619.32386031328\n",
      "      - -195432.20995956488\n",
      "      - -197738.553485513\n",
      "      - -205508.73034860074\n",
      "      - -196894.08272430222\n",
      "      - -204833.3555768217\n",
      "      - -195638.09366055098\n",
      "      - -196165.6349009393\n",
      "      - -192246.4916445201\n",
      "      - -195457.67801997348\n",
      "      - -192410.387329003\n",
      "      - -196090.29111635985\n",
      "      - -193306.58113954175\n",
      "      - -193949.1085452755\n",
      "      - -197770.69934192032\n",
      "      - -194619.1751254425\n",
      "      - -194139.3737709465\n",
      "      - -195005.68558669375\n",
      "      - -193834.7092460555\n",
      "      - -194720.14979160408\n",
      "      - -195528.23365248222\n",
      "      - -196545.26970362203\n",
      "      - -198382.8634024145\n",
      "      - -196013.9136798623\n",
      "      - -191839.6433560653\n",
      "      - -193973.86208679216\n",
      "      - -197325.72300106735\n",
      "      - -194022.61580364595\n",
      "      - -195655.16973001233\n",
      "      - -195819.10357041354\n",
      "      - -197332.89506741182\n",
      "      - -197613.52347455028\n",
      "      - -195349.63949957525\n",
      "      - -194261.83165031072\n",
      "      - -193977.91486585967\n",
      "      - -196500.54500271598\n",
      "      - -194885.0832529576\n",
      "      - -193283.49760719796\n",
      "      - -196633.95765418588\n",
      "      - -193282.60033574776\n",
      "      - -194381.00469495487\n",
      "      - -196993.18737375824\n",
      "      - -195176.2436659862\n",
      "      - -202346.67538372008\n",
      "      - -194830.8762826472\n",
      "      - -193910.59758381665\n",
      "      - -199088.56648488998\n",
      "      - -197068.43910187765\n",
      "      - -196044.91811974443\n",
      "      - -196335.7733237026\n",
      "      - -202124.97283254043\n",
      "      - -194805.68910484106\n",
      "      - -194303.3846489781\n",
      "      - -195148.6018926648\n",
      "      - -196703.63414247966\n",
      "      - -197826.18602695502\n",
      "      - -193361.6997236891\n",
      "      - -196423.28805494882\n",
      "      - -197708.91688594245\n",
      "      - -194848.02211540655\n",
      "      - -197188.07585002776\n",
      "      - -194668.43069821005\n",
      "      - -195141.90076556802\n",
      "      - -194090.89582723426\n",
      "      - -197445.87993791848\n",
      "      - -194935.5281080771\n",
      "      - -194847.98024288216\n",
      "      - -192752.31177514553\n",
      "      - -197868.82332748434\n",
      "      - -196091.64332090196\n",
      "      - -195514.97297104524\n",
      "      - -192792.66441877786\n",
      "      - -195109.9634822168\n",
      "      - -197425.51820782686\n",
      "      - -195043.26284814382\n",
      "      - -195847.15189228844\n",
      "      - -195519.72974241688\n",
      "      - -195203.32097850056\n",
      "      - -196530.7998537734\n",
      "      - -194765.13487055062\n",
      "      - -196058.07013705635\n",
      "      - -197071.9787643301\n",
      "      - -194524.52663731016\n",
      "      - -198121.21059452675\n",
      "      - -192491.79495087755\n",
      "      - -193290.07705648785\n",
      "      - -194608.09629171534\n",
      "      - -198296.07291526816\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09419762580918484\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4674084575404025\n",
      "      mean_inference_ms: 0.9658609174501926\n",
      "      mean_raw_obs_processing_ms: 0.13435104603926284\n",
      "  time_since_restore: 1767.5789773464203\n",
      "  time_this_iter_s: 9.37179446220398\n",
      "  time_total_s: 1767.5789773464203\n",
      "  timers:\n",
      "    learn_throughput: 120150.053\n",
      "    learn_time_ms: 532.534\n",
      "    load_throughput: 22509024.561\n",
      "    load_time_ms: 2.843\n",
      "    training_iteration_time_ms: 9554.836\n",
      "    update_time_ms: 4.077\n",
      "  timestamp: 1665850518\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 11837040\n",
      "  training_iteration: 185\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:15:23 (running for 00:29:57.62)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   185</td><td style=\"text-align: right;\">         1767.58</td><td style=\"text-align: right;\">11837040</td><td style=\"text-align: right;\"> -195791</td><td style=\"text-align: right;\">             -191840</td><td style=\"text-align: right;\">             -205509</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 11901024\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 11901024\n",
      "    num_agent_steps_trained: 11901024\n",
      "    num_env_steps_sampled: 11901024\n",
      "    num_env_steps_trained: 11901024\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-15-28\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -192428.4950034164\n",
      "  episode_reward_mean: -195624.3645795123\n",
      "  episode_reward_min: -202124.97283254043\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 11892\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.11061692237854\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00042768733692355454\n",
      "          model: {}\n",
      "          policy_loss: 0.005958036985248327\n",
      "          total_loss: 10.005731582641602\n",
      "          vf_explained_var: -2.3652637182181024e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 11901024\n",
      "    num_agent_steps_trained: 11901024\n",
      "    num_env_steps_sampled: 11901024\n",
      "    num_env_steps_trained: 11901024\n",
      "  iterations_since_restore: 186\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 11901024\n",
      "  num_agent_steps_trained: 11901024\n",
      "  num_env_steps_sampled: 11901024\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 11901024\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.03571428571429\n",
      "    ram_util_percent: 87.4\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09416056567331993\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4673704636704674\n",
      "    mean_inference_ms: 0.9660253461990407\n",
      "    mean_raw_obs_processing_ms: 0.13432689596469868\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -192428.4950034164\n",
      "    episode_reward_mean: -195624.3645795123\n",
      "    episode_reward_min: -202124.97283254043\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -196044.91811974443\n",
      "      - -196335.7733237026\n",
      "      - -202124.97283254043\n",
      "      - -194805.68910484106\n",
      "      - -194303.3846489781\n",
      "      - -195148.6018926648\n",
      "      - -196703.63414247966\n",
      "      - -197826.18602695502\n",
      "      - -193361.6997236891\n",
      "      - -196423.28805494882\n",
      "      - -197708.91688594245\n",
      "      - -194848.02211540655\n",
      "      - -197188.07585002776\n",
      "      - -194668.43069821005\n",
      "      - -195141.90076556802\n",
      "      - -194090.89582723426\n",
      "      - -197445.87993791848\n",
      "      - -194935.5281080771\n",
      "      - -194847.98024288216\n",
      "      - -192752.31177514553\n",
      "      - -197868.82332748434\n",
      "      - -196091.64332090196\n",
      "      - -195514.97297104524\n",
      "      - -192792.66441877786\n",
      "      - -195109.9634822168\n",
      "      - -197425.51820782686\n",
      "      - -195043.26284814382\n",
      "      - -195847.15189228844\n",
      "      - -195519.72974241688\n",
      "      - -195203.32097850056\n",
      "      - -196530.7998537734\n",
      "      - -194765.13487055062\n",
      "      - -196058.07013705635\n",
      "      - -197071.9787643301\n",
      "      - -194524.52663731016\n",
      "      - -198121.21059452675\n",
      "      - -192491.79495087755\n",
      "      - -193290.07705648785\n",
      "      - -194608.09629171534\n",
      "      - -198296.07291526816\n",
      "      - -193256.87912058493\n",
      "      - -197206.6845439853\n",
      "      - -195245.87357316137\n",
      "      - -196225.7117396429\n",
      "      - -196140.57668277205\n",
      "      - -198531.77844340215\n",
      "      - -195830.39513997803\n",
      "      - -197190.21549616472\n",
      "      - -194413.24283004622\n",
      "      - -198124.81178283037\n",
      "      - -195085.14650525348\n",
      "      - -198609.52446348817\n",
      "      - -193778.79975977386\n",
      "      - -196400.6835729077\n",
      "      - -192428.4950034164\n",
      "      - -195001.34707159473\n",
      "      - -195768.34724013583\n",
      "      - -197066.39204243073\n",
      "      - -192465.76913463505\n",
      "      - -194596.13969254788\n",
      "      - -196040.30490204494\n",
      "      - -195070.56399890978\n",
      "      - -196893.33710531535\n",
      "      - -198339.75853597882\n",
      "      - -192897.03400836114\n",
      "      - -198143.60829584752\n",
      "      - -194659.67772941722\n",
      "      - -198334.50899870027\n",
      "      - -194230.7312144572\n",
      "      - -193888.31874738916\n",
      "      - -198445.5399814\n",
      "      - -196733.9450620924\n",
      "      - -195234.70390836758\n",
      "      - -196468.08134551975\n",
      "      - -196735.23441679543\n",
      "      - -194196.23945189084\n",
      "      - -196624.1157053579\n",
      "      - -195730.47664331296\n",
      "      - -194932.73328198426\n",
      "      - -194294.17440938513\n",
      "      - -193637.6317961572\n",
      "      - -197539.17880412698\n",
      "      - -195516.32459782282\n",
      "      - -192756.67402980872\n",
      "      - -193738.107063756\n",
      "      - -194012.9445069517\n",
      "      - -196786.8602368618\n",
      "      - -197146.90866110742\n",
      "      - -195007.757399821\n",
      "      - -196045.98601725037\n",
      "      - -193820.66754947617\n",
      "      - -194306.51198214153\n",
      "      - -195255.61542033404\n",
      "      - -193537.5502498074\n",
      "      - -195007.18841168095\n",
      "      - -195197.38294509647\n",
      "      - -195455.2153200693\n",
      "      - -195276.4258981346\n",
      "      - -196763.14079904603\n",
      "      - -195487.58134204027\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09416056567331993\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4673704636704674\n",
      "      mean_inference_ms: 0.9660253461990407\n",
      "      mean_raw_obs_processing_ms: 0.13432689596469868\n",
      "  time_since_restore: 1777.4401042461395\n",
      "  time_this_iter_s: 9.861126899719238\n",
      "  time_total_s: 1777.4401042461395\n",
      "  timers:\n",
      "    learn_throughput: 120380.038\n",
      "    learn_time_ms: 531.517\n",
      "    load_throughput: 22497136.989\n",
      "    load_time_ms: 2.844\n",
      "    training_iteration_time_ms: 9572.895\n",
      "    update_time_ms: 4.016\n",
      "  timestamp: 1665850528\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 11901024\n",
      "  training_iteration: 186\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:15:28 (running for 00:30:02.70)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   186</td><td style=\"text-align: right;\">         1777.44</td><td style=\"text-align: right;\">11901024</td><td style=\"text-align: right;\"> -195624</td><td style=\"text-align: right;\">             -192428</td><td style=\"text-align: right;\">             -202125</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:15:33 (running for 00:30:07.70)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   186</td><td style=\"text-align: right;\">         1777.44</td><td style=\"text-align: right;\">11901024</td><td style=\"text-align: right;\"> -195624</td><td style=\"text-align: right;\">             -192428</td><td style=\"text-align: right;\">             -202125</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 11965008\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 11965008\n",
      "    num_agent_steps_trained: 11965008\n",
      "    num_env_steps_sampled: 11965008\n",
      "    num_env_steps_trained: 11965008\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-15-37\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -192578.32378001034\n",
      "  episode_reward_mean: -195479.7483674796\n",
      "  episode_reward_min: -200035.92735656403\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 11964\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.111236333847046\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0006041722954250872\n",
      "          model: {}\n",
      "          policy_loss: 0.00038109306478872895\n",
      "          total_loss: 10.000189781188965\n",
      "          vf_explained_var: -1.419158213167293e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 11965008\n",
      "    num_agent_steps_trained: 11965008\n",
      "    num_env_steps_sampled: 11965008\n",
      "    num_env_steps_trained: 11965008\n",
      "  iterations_since_restore: 187\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 11965008\n",
      "  num_agent_steps_trained: 11965008\n",
      "  num_env_steps_sampled: 11965008\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 11965008\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.10714285714286\n",
      "    ram_util_percent: 87.5\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09414833114718084\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46739551136450763\n",
      "    mean_inference_ms: 0.9661818469616168\n",
      "    mean_raw_obs_processing_ms: 0.13415141626494356\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -192578.32378001034\n",
      "    episode_reward_mean: -195479.7483674796\n",
      "    episode_reward_min: -200035.92735656403\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -195234.70390836758\n",
      "      - -196468.08134551975\n",
      "      - -196735.23441679543\n",
      "      - -194196.23945189084\n",
      "      - -196624.1157053579\n",
      "      - -195730.47664331296\n",
      "      - -194932.73328198426\n",
      "      - -194294.17440938513\n",
      "      - -193637.6317961572\n",
      "      - -197539.17880412698\n",
      "      - -195516.32459782282\n",
      "      - -192756.67402980872\n",
      "      - -193738.107063756\n",
      "      - -194012.9445069517\n",
      "      - -196786.8602368618\n",
      "      - -197146.90866110742\n",
      "      - -195007.757399821\n",
      "      - -196045.98601725037\n",
      "      - -193820.66754947617\n",
      "      - -194306.51198214153\n",
      "      - -195255.61542033404\n",
      "      - -193537.5502498074\n",
      "      - -195007.18841168095\n",
      "      - -195197.38294509647\n",
      "      - -195455.2153200693\n",
      "      - -195276.4258981346\n",
      "      - -196763.14079904603\n",
      "      - -195487.58134204027\n",
      "      - -196355.42241293198\n",
      "      - -196108.3203411649\n",
      "      - -194914.73934016837\n",
      "      - -194835.7290544916\n",
      "      - -197457.28277516537\n",
      "      - -200035.92735656403\n",
      "      - -197012.58248021142\n",
      "      - -195867.33918576187\n",
      "      - -192630.5438608991\n",
      "      - -194845.78823075106\n",
      "      - -194919.29282570494\n",
      "      - -194366.21243385368\n",
      "      - -194541.797879565\n",
      "      - -196897.31137955768\n",
      "      - -196099.32106931807\n",
      "      - -195193.1845788696\n",
      "      - -195145.95461328357\n",
      "      - -196835.37977406796\n",
      "      - -194492.30701288304\n",
      "      - -195160.7309190161\n",
      "      - -194861.7114605873\n",
      "      - -193726.175791832\n",
      "      - -198363.00715795255\n",
      "      - -196450.4042343508\n",
      "      - -195778.18602545373\n",
      "      - -195056.66289572025\n",
      "      - -196108.37121759864\n",
      "      - -194067.35518697996\n",
      "      - -192578.32378001034\n",
      "      - -195749.5668596895\n",
      "      - -195583.20365057176\n",
      "      - -195749.87383800713\n",
      "      - -196737.68584339353\n",
      "      - -195498.58212792914\n",
      "      - -195570.2919828068\n",
      "      - -195185.9343372874\n",
      "      - -196562.57403560687\n",
      "      - -194405.14563208914\n",
      "      - -195321.7899354556\n",
      "      - -196303.3053193295\n",
      "      - -195710.39375102945\n",
      "      - -193168.93458322037\n",
      "      - -195411.03289513895\n",
      "      - -196824.92442038868\n",
      "      - -196373.6567056568\n",
      "      - -196444.1810928573\n",
      "      - -195239.8237668916\n",
      "      - -197399.6340618133\n",
      "      - -197564.11090784948\n",
      "      - -196920.39110594228\n",
      "      - -194891.409392122\n",
      "      - -195853.2900482885\n",
      "      - -198045.424066477\n",
      "      - -195600.6017562574\n",
      "      - -198795.30534521837\n",
      "      - -193447.62755180892\n",
      "      - -194905.7684551335\n",
      "      - -195320.83540040188\n",
      "      - -193928.35449532128\n",
      "      - -195533.08125769696\n",
      "      - -195520.81056120418\n",
      "      - -197362.77005256797\n",
      "      - -195950.1118413927\n",
      "      - -193449.92005921985\n",
      "      - -194990.095066851\n",
      "      - -198180.99384476058\n",
      "      - -195100.0111345671\n",
      "      - -193683.05573251675\n",
      "      - -195335.8602186603\n",
      "      - -192920.71150080342\n",
      "      - -193615.27377838164\n",
      "      - -194601.71086653313\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09414833114718084\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46739551136450763\n",
      "      mean_inference_ms: 0.9661818469616168\n",
      "      mean_raw_obs_processing_ms: 0.13415141626494356\n",
      "  time_since_restore: 1787.1604313850403\n",
      "  time_this_iter_s: 9.720327138900757\n",
      "  time_total_s: 1787.1604313850403\n",
      "  timers:\n",
      "    learn_throughput: 120654.589\n",
      "    learn_time_ms: 530.307\n",
      "    load_throughput: 22341129.27\n",
      "    load_time_ms: 2.864\n",
      "    training_iteration_time_ms: 9484.583\n",
      "    update_time_ms: 4.09\n",
      "  timestamp: 1665850537\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 11965008\n",
      "  training_iteration: 187\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:15:43 (running for 00:30:17.45)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   187</td><td style=\"text-align: right;\">         1787.16</td><td style=\"text-align: right;\">11965008</td><td style=\"text-align: right;\"> -195480</td><td style=\"text-align: right;\">             -192578</td><td style=\"text-align: right;\">             -200036</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 12028992\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 12028992\n",
      "    num_agent_steps_trained: 12028992\n",
      "    num_env_steps_sampled: 12028992\n",
      "    num_env_steps_trained: 12028992\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-15-47\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -191305.83809018278\n",
      "  episode_reward_mean: -195497.742720241\n",
      "  episode_reward_min: -199664.38028437362\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 12024\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1203598976135254\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0010935441823676229\n",
      "          model: {}\n",
      "          policy_loss: 0.006155891343951225\n",
      "          total_loss: 10.006062507629395\n",
      "          vf_explained_var: -2.7437058847112894e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 12028992\n",
      "    num_agent_steps_trained: 12028992\n",
      "    num_env_steps_sampled: 12028992\n",
      "    num_env_steps_trained: 12028992\n",
      "  iterations_since_restore: 188\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 12028992\n",
      "  num_agent_steps_trained: 12028992\n",
      "  num_env_steps_sampled: 12028992\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 12028992\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.70769230769231\n",
      "    ram_util_percent: 87.4923076923077\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09418475496402616\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46731449981731915\n",
      "    mean_inference_ms: 0.9662897464523615\n",
      "    mean_raw_obs_processing_ms: 0.1343162244586436\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -191305.83809018278\n",
      "    episode_reward_mean: -195497.742720241\n",
      "    episode_reward_min: -199664.38028437362\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -196737.68584339353\n",
      "      - -195498.58212792914\n",
      "      - -195570.2919828068\n",
      "      - -195185.9343372874\n",
      "      - -196562.57403560687\n",
      "      - -194405.14563208914\n",
      "      - -195321.7899354556\n",
      "      - -196303.3053193295\n",
      "      - -195710.39375102945\n",
      "      - -193168.93458322037\n",
      "      - -195411.03289513895\n",
      "      - -196824.92442038868\n",
      "      - -196373.6567056568\n",
      "      - -196444.1810928573\n",
      "      - -195239.8237668916\n",
      "      - -197399.6340618133\n",
      "      - -197564.11090784948\n",
      "      - -196920.39110594228\n",
      "      - -194891.409392122\n",
      "      - -195853.2900482885\n",
      "      - -198045.424066477\n",
      "      - -195600.6017562574\n",
      "      - -198795.30534521837\n",
      "      - -193447.62755180892\n",
      "      - -194905.7684551335\n",
      "      - -195320.83540040188\n",
      "      - -193928.35449532128\n",
      "      - -195533.08125769696\n",
      "      - -195520.81056120418\n",
      "      - -197362.77005256797\n",
      "      - -195950.1118413927\n",
      "      - -193449.92005921985\n",
      "      - -194990.095066851\n",
      "      - -198180.99384476058\n",
      "      - -195100.0111345671\n",
      "      - -193683.05573251675\n",
      "      - -195335.8602186603\n",
      "      - -192920.71150080342\n",
      "      - -193615.27377838164\n",
      "      - -194601.71086653313\n",
      "      - -194723.57723931625\n",
      "      - -194637.8407058467\n",
      "      - -194319.74196258836\n",
      "      - -194045.03990712218\n",
      "      - -194292.9215795537\n",
      "      - -196513.90205874864\n",
      "      - -191305.83809018278\n",
      "      - -193605.75931356903\n",
      "      - -194366.98471751786\n",
      "      - -196325.6137922187\n",
      "      - -194335.9475485106\n",
      "      - -196080.6572095385\n",
      "      - -194119.2666522582\n",
      "      - -195327.3116274882\n",
      "      - -195160.85965212926\n",
      "      - -194213.23626234097\n",
      "      - -195071.7275152905\n",
      "      - -198066.22233938792\n",
      "      - -194936.13367318505\n",
      "      - -196659.7556483499\n",
      "      - -198205.6214856561\n",
      "      - -193156.70186362014\n",
      "      - -195745.84599404386\n",
      "      - -194107.60335336247\n",
      "      - -194325.11213403486\n",
      "      - -195913.78922679412\n",
      "      - -195710.51999891488\n",
      "      - -195132.12727251902\n",
      "      - -196068.70295436875\n",
      "      - -195967.416100534\n",
      "      - -193747.50765546432\n",
      "      - -193950.53922734587\n",
      "      - -196691.6182081676\n",
      "      - -199181.99613701526\n",
      "      - -198146.41971045418\n",
      "      - -198010.56689275405\n",
      "      - -194384.35720671408\n",
      "      - -195095.04647347453\n",
      "      - -194317.79696192575\n",
      "      - -194368.1548029113\n",
      "      - -197621.56547242418\n",
      "      - -197167.48656583007\n",
      "      - -195506.41961110468\n",
      "      - -195804.22563546826\n",
      "      - -194623.23427918073\n",
      "      - -194606.39324939842\n",
      "      - -195151.31063503507\n",
      "      - -193469.78784397987\n",
      "      - -194977.7557173317\n",
      "      - -194924.54381644604\n",
      "      - -199664.38028437362\n",
      "      - -196370.14945669653\n",
      "      - -196190.151265558\n",
      "      - -194423.7467819902\n",
      "      - -195513.0688284806\n",
      "      - -194562.9953833169\n",
      "      - -197882.74597288543\n",
      "      - -195478.3717424308\n",
      "      - -195473.6149990769\n",
      "      - -196351.12839699726\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09418475496402616\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46731449981731915\n",
      "      mean_inference_ms: 0.9662897464523615\n",
      "      mean_raw_obs_processing_ms: 0.1343162244586436\n",
      "  time_since_restore: 1796.488534450531\n",
      "  time_this_iter_s: 9.328103065490723\n",
      "  time_total_s: 1796.488534450531\n",
      "  timers:\n",
      "    learn_throughput: 120807.373\n",
      "    learn_time_ms: 529.637\n",
      "    load_throughput: 22292136.787\n",
      "    load_time_ms: 2.87\n",
      "    training_iteration_time_ms: 9438.658\n",
      "    update_time_ms: 4.059\n",
      "  timestamp: 1665850547\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 12028992\n",
      "  training_iteration: 188\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:15:52 (running for 00:30:26.81)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   188</td><td style=\"text-align: right;\">         1796.49</td><td style=\"text-align: right;\">12028992</td><td style=\"text-align: right;\"> -195498</td><td style=\"text-align: right;\">             -191306</td><td style=\"text-align: right;\">             -199664</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 12092976\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 12092976\n",
      "    num_agent_steps_trained: 12092976\n",
      "    num_env_steps_sampled: 12092976\n",
      "    num_env_steps_trained: 12092976\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-15-56\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -191711.63431438943\n",
      "  episode_reward_mean: -195313.52547201983\n",
      "  episode_reward_min: -200347.96663832798\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 12084\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1197309494018555\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0004982019308954477\n",
      "          model: {}\n",
      "          policy_loss: 0.005256341770291328\n",
      "          total_loss: 10.005043983459473\n",
      "          vf_explained_var: -1.9868215517249155e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 12092976\n",
      "    num_agent_steps_trained: 12092976\n",
      "    num_env_steps_sampled: 12092976\n",
      "    num_env_steps_trained: 12092976\n",
      "  iterations_since_restore: 189\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 12092976\n",
      "  num_agent_steps_trained: 12092976\n",
      "  num_env_steps_sampled: 12092976\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 12092976\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.06153846153846\n",
      "    ram_util_percent: 87.5\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09412013286305979\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4673060613606906\n",
      "    mean_inference_ms: 0.9661282706254543\n",
      "    mean_raw_obs_processing_ms: 0.13428810174531966\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -191711.63431438943\n",
      "    episode_reward_mean: -195313.52547201983\n",
      "    episode_reward_min: -200347.96663832798\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -198205.6214856561\n",
      "      - -193156.70186362014\n",
      "      - -195745.84599404386\n",
      "      - -194107.60335336247\n",
      "      - -194325.11213403486\n",
      "      - -195913.78922679412\n",
      "      - -195710.51999891488\n",
      "      - -195132.12727251902\n",
      "      - -196068.70295436875\n",
      "      - -195967.416100534\n",
      "      - -193747.50765546432\n",
      "      - -193950.53922734587\n",
      "      - -196691.6182081676\n",
      "      - -199181.99613701526\n",
      "      - -198146.41971045418\n",
      "      - -198010.56689275405\n",
      "      - -194384.35720671408\n",
      "      - -195095.04647347453\n",
      "      - -194317.79696192575\n",
      "      - -194368.1548029113\n",
      "      - -197621.56547242418\n",
      "      - -197167.48656583007\n",
      "      - -195506.41961110468\n",
      "      - -195804.22563546826\n",
      "      - -194623.23427918073\n",
      "      - -194606.39324939842\n",
      "      - -195151.31063503507\n",
      "      - -193469.78784397987\n",
      "      - -194977.7557173317\n",
      "      - -194924.54381644604\n",
      "      - -199664.38028437362\n",
      "      - -196370.14945669653\n",
      "      - -196190.151265558\n",
      "      - -194423.7467819902\n",
      "      - -195513.0688284806\n",
      "      - -194562.9953833169\n",
      "      - -197882.74597288543\n",
      "      - -195478.3717424308\n",
      "      - -195473.6149990769\n",
      "      - -196351.12839699726\n",
      "      - -194084.24278759054\n",
      "      - -194100.89638886697\n",
      "      - -191711.63431438943\n",
      "      - -195920.29959059265\n",
      "      - -197292.55529008596\n",
      "      - -197209.2230329703\n",
      "      - -194456.26747767648\n",
      "      - -194369.60531508224\n",
      "      - -195126.47388138712\n",
      "      - -192712.72761462998\n",
      "      - -194441.77838226134\n",
      "      - -193258.14274443456\n",
      "      - -195346.6396495125\n",
      "      - -197209.63369419472\n",
      "      - -196890.10387938502\n",
      "      - -194235.54399462888\n",
      "      - -195320.411239662\n",
      "      - -195429.57036852252\n",
      "      - -196753.8759620013\n",
      "      - -194378.64329793592\n",
      "      - -200347.96663832798\n",
      "      - -195030.8994148691\n",
      "      - -197700.65787602315\n",
      "      - -194036.20647663967\n",
      "      - -192816.21171133668\n",
      "      - -196594.52340107766\n",
      "      - -195828.02883987196\n",
      "      - -194271.7046219365\n",
      "      - -192277.56467931264\n",
      "      - -197761.82340792136\n",
      "      - -196336.18809526457\n",
      "      - -194592.3881512176\n",
      "      - -192305.5907081211\n",
      "      - -193220.61962322998\n",
      "      - -195172.4457792187\n",
      "      - -197427.5175691826\n",
      "      - -194212.98870961793\n",
      "      - -196456.7905310046\n",
      "      - -194893.6598890483\n",
      "      - -194711.8586244776\n",
      "      - -194939.8200824617\n",
      "      - -192819.35765625123\n",
      "      - -193467.0434708987\n",
      "      - -195795.73262193246\n",
      "      - -194736.69612277346\n",
      "      - -195114.1230833874\n",
      "      - -196544.97930753767\n",
      "      - -196137.59360724041\n",
      "      - -195363.54214798255\n",
      "      - -192900.14643611998\n",
      "      - -195678.60709798735\n",
      "      - -194626.3141767782\n",
      "      - -195894.46265600313\n",
      "      - -193281.6277919358\n",
      "      - -193313.76585826228\n",
      "      - -194404.5728248399\n",
      "      - -197136.8322863781\n",
      "      - -194818.80364005535\n",
      "      - -195006.74828523968\n",
      "      - -195137.35479632716\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09412013286305979\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4673060613606906\n",
      "      mean_inference_ms: 0.9661282706254543\n",
      "      mean_raw_obs_processing_ms: 0.13428810174531966\n",
      "  time_since_restore: 1805.7390832901\n",
      "  time_this_iter_s: 9.250548839569092\n",
      "  time_total_s: 1805.7390832901\n",
      "  timers:\n",
      "    learn_throughput: 121180.637\n",
      "    learn_time_ms: 528.005\n",
      "    load_throughput: 22291025.818\n",
      "    load_time_ms: 2.87\n",
      "    training_iteration_time_ms: 9434.029\n",
      "    update_time_ms: 4.095\n",
      "  timestamp: 1665850556\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 12092976\n",
      "  training_iteration: 189\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:16:01 (running for 00:30:36.09)<br>Memory usage on this node: 13.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   189</td><td style=\"text-align: right;\">         1805.74</td><td style=\"text-align: right;\">12092976</td><td style=\"text-align: right;\"> -195314</td><td style=\"text-align: right;\">             -191712</td><td style=\"text-align: right;\">             -200348</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 12156960\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 12156960\n",
      "    num_agent_steps_trained: 12156960\n",
      "    num_env_steps_sampled: 12156960\n",
      "    num_env_steps_trained: 12156960\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-16-06\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -191513.55423829408\n",
      "  episode_reward_mean: -195271.95980850156\n",
      "  episode_reward_min: -207276.50190679237\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 12156\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.114741086959839\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00036535790422931314\n",
      "          model: {}\n",
      "          policy_loss: 0.0006613729055970907\n",
      "          total_loss: 10.000422477722168\n",
      "          vf_explained_var: -3.0275376872168636e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 12156960\n",
      "    num_agent_steps_trained: 12156960\n",
      "    num_env_steps_sampled: 12156960\n",
      "    num_env_steps_trained: 12156960\n",
      "  iterations_since_restore: 190\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 12156960\n",
      "  num_agent_steps_trained: 12156960\n",
      "  num_env_steps_sampled: 12156960\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 12156960\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 84.88461538461539\n",
      "    ram_util_percent: 87.61538461538461\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09409575715397828\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46730038100168103\n",
      "    mean_inference_ms: 0.9659884094311013\n",
      "    mean_raw_obs_processing_ms: 0.13410439101144814\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -191513.55423829408\n",
      "    episode_reward_mean: -195271.95980850156\n",
      "    episode_reward_min: -207276.50190679237\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -192305.5907081211\n",
      "      - -193220.61962322998\n",
      "      - -195172.4457792187\n",
      "      - -197427.5175691826\n",
      "      - -194212.98870961793\n",
      "      - -196456.7905310046\n",
      "      - -194893.6598890483\n",
      "      - -194711.8586244776\n",
      "      - -194939.8200824617\n",
      "      - -192819.35765625123\n",
      "      - -193467.0434708987\n",
      "      - -195795.73262193246\n",
      "      - -194736.69612277346\n",
      "      - -195114.1230833874\n",
      "      - -196544.97930753767\n",
      "      - -196137.59360724041\n",
      "      - -195363.54214798255\n",
      "      - -192900.14643611998\n",
      "      - -195678.60709798735\n",
      "      - -194626.3141767782\n",
      "      - -195894.46265600313\n",
      "      - -193281.6277919358\n",
      "      - -193313.76585826228\n",
      "      - -194404.5728248399\n",
      "      - -197136.8322863781\n",
      "      - -194818.80364005535\n",
      "      - -195006.74828523968\n",
      "      - -195137.35479632716\n",
      "      - -196769.03895542905\n",
      "      - -196537.49841589385\n",
      "      - -195367.4712269629\n",
      "      - -197595.47563924227\n",
      "      - -196065.39124909218\n",
      "      - -195062.95593796126\n",
      "      - -195626.9782616132\n",
      "      - -194411.7650107501\n",
      "      - -195091.48285765378\n",
      "      - -195753.61345184082\n",
      "      - -194085.0417932502\n",
      "      - -197815.57054016428\n",
      "      - -197680.6562493014\n",
      "      - -194096.32293233273\n",
      "      - -197221.60085846955\n",
      "      - -197312.99439451555\n",
      "      - -192921.13676362424\n",
      "      - -192672.31855987202\n",
      "      - -191513.55423829408\n",
      "      - -194895.68558399845\n",
      "      - -194817.4340719641\n",
      "      - -193659.63063128386\n",
      "      - -193825.427159056\n",
      "      - -194373.71009059355\n",
      "      - -193630.233757197\n",
      "      - -201276.08506048008\n",
      "      - -197375.7526316843\n",
      "      - -193802.36872494663\n",
      "      - -194904.57318890348\n",
      "      - -192668.84288448625\n",
      "      - -197799.57554877413\n",
      "      - -194695.28165412004\n",
      "      - -196747.56757595445\n",
      "      - -194194.99624642587\n",
      "      - -193954.33908464163\n",
      "      - -195768.98404799993\n",
      "      - -195171.0567601183\n",
      "      - -193902.65621811541\n",
      "      - -196906.55393123737\n",
      "      - -194077.9282607659\n",
      "      - -193722.73206406445\n",
      "      - -194986.91036474172\n",
      "      - -195892.54622317888\n",
      "      - -192913.85656739815\n",
      "      - -195159.8672217806\n",
      "      - -197014.01915632962\n",
      "      - -193530.11418384706\n",
      "      - -195615.6028344611\n",
      "      - -194415.86714977084\n",
      "      - -196856.9244564652\n",
      "      - -194615.4667029582\n",
      "      - -194654.9092253723\n",
      "      - -196301.27189361464\n",
      "      - -195088.62637214572\n",
      "      - -193994.25229445833\n",
      "      - -197421.41742345298\n",
      "      - -195233.21038138875\n",
      "      - -207276.50190679237\n",
      "      - -195742.19908191342\n",
      "      - -195721.98861243165\n",
      "      - -194190.05047493236\n",
      "      - -196080.52643463662\n",
      "      - -196185.56280077022\n",
      "      - -194167.20598801298\n",
      "      - -193916.74816142753\n",
      "      - -194575.20960771796\n",
      "      - -196122.23208333802\n",
      "      - -194329.2425617894\n",
      "      - -195061.8156419954\n",
      "      - -198309.71558177608\n",
      "      - -195832.1166808313\n",
      "      - -194698.1248830605\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09409575715397828\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46730038100168103\n",
      "      mean_inference_ms: 0.9659884094311013\n",
      "      mean_raw_obs_processing_ms: 0.13410439101144814\n",
      "  time_since_restore: 1815.3128082752228\n",
      "  time_this_iter_s: 9.57372498512268\n",
      "  time_total_s: 1815.3128082752228\n",
      "  timers:\n",
      "    learn_throughput: 131025.586\n",
      "    learn_time_ms: 488.332\n",
      "    load_throughput: 22371486.09\n",
      "    load_time_ms: 2.86\n",
      "    training_iteration_time_ms: 9453.881\n",
      "    update_time_ms: 4.272\n",
      "  timestamp: 1665850566\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 12156960\n",
      "  training_iteration: 190\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:16:11 (running for 00:30:46.06)<br>Memory usage on this node: 13.6/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   190</td><td style=\"text-align: right;\">         1815.31</td><td style=\"text-align: right;\">12156960</td><td style=\"text-align: right;\"> -195272</td><td style=\"text-align: right;\">             -191514</td><td style=\"text-align: right;\">             -207277</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 12220944\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 12220944\n",
      "    num_agent_steps_trained: 12220944\n",
      "    num_env_steps_sampled: 12220944\n",
      "    num_env_steps_trained: 12220944\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-16-15\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -192168.92027916832\n",
      "  episode_reward_mean: -195291.65853746873\n",
      "  episode_reward_min: -207276.50190679237\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 12216\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.115069627761841\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0004075949836988002\n",
      "          model: {}\n",
      "          policy_loss: 0.006521804258227348\n",
      "          total_loss: 10.006293296813965\n",
      "          vf_explained_var: -2.7437058847112894e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 12220944\n",
      "    num_agent_steps_trained: 12220944\n",
      "    num_env_steps_sampled: 12220944\n",
      "    num_env_steps_trained: 12220944\n",
      "  iterations_since_restore: 191\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 12220944\n",
      "  num_agent_steps_trained: 12220944\n",
      "  num_env_steps_sampled: 12220944\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 12220944\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.43846153846154\n",
      "    ram_util_percent: 87.79999999999998\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09414116270878967\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4672411453410824\n",
      "    mean_inference_ms: 0.9661096119270628\n",
      "    mean_raw_obs_processing_ms: 0.13428242469590596\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -192168.92027916832\n",
      "    episode_reward_mean: -195291.65853746873\n",
      "    episode_reward_min: -207276.50190679237\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -196747.56757595445\n",
      "      - -194194.99624642587\n",
      "      - -193954.33908464163\n",
      "      - -195768.98404799993\n",
      "      - -195171.0567601183\n",
      "      - -193902.65621811541\n",
      "      - -196906.55393123737\n",
      "      - -194077.9282607659\n",
      "      - -193722.73206406445\n",
      "      - -194986.91036474172\n",
      "      - -195892.54622317888\n",
      "      - -192913.85656739815\n",
      "      - -195159.8672217806\n",
      "      - -197014.01915632962\n",
      "      - -193530.11418384706\n",
      "      - -195615.6028344611\n",
      "      - -194415.86714977084\n",
      "      - -196856.9244564652\n",
      "      - -194615.4667029582\n",
      "      - -194654.9092253723\n",
      "      - -196301.27189361464\n",
      "      - -195088.62637214572\n",
      "      - -193994.25229445833\n",
      "      - -197421.41742345298\n",
      "      - -195233.21038138875\n",
      "      - -207276.50190679237\n",
      "      - -195742.19908191342\n",
      "      - -195721.98861243165\n",
      "      - -194190.05047493236\n",
      "      - -196080.52643463662\n",
      "      - -196185.56280077022\n",
      "      - -194167.20598801298\n",
      "      - -193916.74816142753\n",
      "      - -194575.20960771796\n",
      "      - -196122.23208333802\n",
      "      - -194329.2425617894\n",
      "      - -195061.8156419954\n",
      "      - -198309.71558177608\n",
      "      - -195832.1166808313\n",
      "      - -194698.1248830605\n",
      "      - -194556.92649981743\n",
      "      - -195313.16568604327\n",
      "      - -197109.78208397242\n",
      "      - -195267.25344564213\n",
      "      - -194170.02866599784\n",
      "      - -194300.35467686952\n",
      "      - -196874.77839981677\n",
      "      - -195620.31526432742\n",
      "      - -193929.59799056858\n",
      "      - -195794.29323011512\n",
      "      - -193260.442119542\n",
      "      - -194382.49058434926\n",
      "      - -195126.9260590565\n",
      "      - -192335.0818830148\n",
      "      - -195522.64437052968\n",
      "      - -193830.96753377584\n",
      "      - -196734.2717163038\n",
      "      - -196207.0569879089\n",
      "      - -196844.4759874509\n",
      "      - -196628.53949040867\n",
      "      - -196714.15027691794\n",
      "      - -195456.06806041158\n",
      "      - -197782.76425291196\n",
      "      - -195250.30386224852\n",
      "      - -196288.34112965435\n",
      "      - -194259.17973137117\n",
      "      - -194763.7155776759\n",
      "      - -193646.90643260503\n",
      "      - -193011.40966830737\n",
      "      - -194916.29896040936\n",
      "      - -196091.6870966229\n",
      "      - -193982.3291935499\n",
      "      - -192168.92027916832\n",
      "      - -193958.81780203688\n",
      "      - -194963.113812439\n",
      "      - -194439.38295444488\n",
      "      - -194226.25574132003\n",
      "      - -194883.10183414273\n",
      "      - -194396.00917369992\n",
      "      - -197096.05671545299\n",
      "      - -196600.93587178018\n",
      "      - -197114.29062355732\n",
      "      - -196095.6726486065\n",
      "      - -194263.98060825234\n",
      "      - -196265.25538714032\n",
      "      - -194720.84431671017\n",
      "      - -195425.367733387\n",
      "      - -194864.6716045966\n",
      "      - -195202.53661388438\n",
      "      - -193639.54508260946\n",
      "      - -192803.53362766723\n",
      "      - -195186.0627063535\n",
      "      - -194872.1066785236\n",
      "      - -194742.9608744676\n",
      "      - -198145.70351141918\n",
      "      - -193741.47677191536\n",
      "      - -195831.8474890072\n",
      "      - -196750.57722108418\n",
      "      - -194063.09057218127\n",
      "      - -196380.27143071126\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09414116270878967\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4672411453410824\n",
      "      mean_inference_ms: 0.9661096119270628\n",
      "      mean_raw_obs_processing_ms: 0.13428242469590596\n",
      "  time_since_restore: 1824.8088579177856\n",
      "  time_this_iter_s: 9.496049642562866\n",
      "  time_total_s: 1824.8088579177856\n",
      "  timers:\n",
      "    learn_throughput: 130784.974\n",
      "    learn_time_ms: 489.231\n",
      "    load_throughput: 22306589.46\n",
      "    load_time_ms: 2.868\n",
      "    training_iteration_time_ms: 9500.593\n",
      "    update_time_ms: 4.308\n",
      "  timestamp: 1665850575\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 12220944\n",
      "  training_iteration: 191\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:16:20 (running for 00:30:55.04)<br>Memory usage on this node: 13.6/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   191</td><td style=\"text-align: right;\">         1824.81</td><td style=\"text-align: right;\">12220944</td><td style=\"text-align: right;\"> -195292</td><td style=\"text-align: right;\">             -192169</td><td style=\"text-align: right;\">             -207277</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 12284928\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 12284928\n",
      "    num_agent_steps_trained: 12284928\n",
      "    num_env_steps_sampled: 12284928\n",
      "    num_env_steps_trained: 12284928\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-16-25\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -192168.92027916832\n",
      "  episode_reward_mean: -195292.23219260405\n",
      "  episode_reward_min: -200766.04636785347\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 12276\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1202070713043213\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0005249574896879494\n",
      "          model: {}\n",
      "          policy_loss: 0.005800292827188969\n",
      "          total_loss: 10.005593299865723\n",
      "          vf_explained_var: -3.4059798537100505e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 12284928\n",
      "    num_agent_steps_trained: 12284928\n",
      "    num_env_steps_sampled: 12284928\n",
      "    num_env_steps_trained: 12284928\n",
      "  iterations_since_restore: 192\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 12284928\n",
      "  num_agent_steps_trained: 12284928\n",
      "  num_env_steps_sampled: 12284928\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 12284928\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 84.9857142857143\n",
      "    ram_util_percent: 87.66428571428571\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0941092018619906\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46731726579505706\n",
      "    mean_inference_ms: 0.9662809771958336\n",
      "    mean_raw_obs_processing_ms: 0.13429256349266375\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -192168.92027916832\n",
      "    episode_reward_mean: -195292.23219260405\n",
      "    episode_reward_min: -200766.04636785347\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -196714.15027691794\n",
      "      - -195456.06806041158\n",
      "      - -197782.76425291196\n",
      "      - -195250.30386224852\n",
      "      - -196288.34112965435\n",
      "      - -194259.17973137117\n",
      "      - -194763.7155776759\n",
      "      - -193646.90643260503\n",
      "      - -193011.40966830737\n",
      "      - -194916.29896040936\n",
      "      - -196091.6870966229\n",
      "      - -193982.3291935499\n",
      "      - -192168.92027916832\n",
      "      - -193958.81780203688\n",
      "      - -194963.113812439\n",
      "      - -194439.38295444488\n",
      "      - -194226.25574132003\n",
      "      - -194883.10183414273\n",
      "      - -194396.00917369992\n",
      "      - -197096.05671545299\n",
      "      - -196600.93587178018\n",
      "      - -197114.29062355732\n",
      "      - -196095.6726486065\n",
      "      - -194263.98060825234\n",
      "      - -196265.25538714032\n",
      "      - -194720.84431671017\n",
      "      - -195425.367733387\n",
      "      - -194864.6716045966\n",
      "      - -195202.53661388438\n",
      "      - -193639.54508260946\n",
      "      - -192803.53362766723\n",
      "      - -195186.0627063535\n",
      "      - -194872.1066785236\n",
      "      - -194742.9608744676\n",
      "      - -198145.70351141918\n",
      "      - -193741.47677191536\n",
      "      - -195831.8474890072\n",
      "      - -196750.57722108418\n",
      "      - -194063.09057218127\n",
      "      - -196380.27143071126\n",
      "      - -197926.18333238197\n",
      "      - -194675.61945772625\n",
      "      - -196255.13114196804\n",
      "      - -197366.86962950559\n",
      "      - -194909.65763992482\n",
      "      - -194585.37475102305\n",
      "      - -193245.593152548\n",
      "      - -195382.90640028563\n",
      "      - -194106.92526023422\n",
      "      - -192631.40356511148\n",
      "      - -194124.60326342445\n",
      "      - -195948.12416679136\n",
      "      - -195007.3249582572\n",
      "      - -194168.2105740869\n",
      "      - -194192.7652065809\n",
      "      - -194416.18000664999\n",
      "      - -197956.60593679437\n",
      "      - -194021.66972650515\n",
      "      - -195487.98189430576\n",
      "      - -200766.04636785347\n",
      "      - -195446.35736522073\n",
      "      - -194334.94266351717\n",
      "      - -198126.59709317127\n",
      "      - -196361.96063446894\n",
      "      - -196133.0567113935\n",
      "      - -194998.14557605505\n",
      "      - -193551.11264896832\n",
      "      - -198877.90636300942\n",
      "      - -197160.79149095216\n",
      "      - -195407.81019444874\n",
      "      - -195036.30377721772\n",
      "      - -195975.07011787372\n",
      "      - -195258.42719169857\n",
      "      - -193806.8336053827\n",
      "      - -193087.24712261962\n",
      "      - -195111.66370006284\n",
      "      - -197677.48342954126\n",
      "      - -194267.6746476962\n",
      "      - -196821.55652349535\n",
      "      - -197278.3477849226\n",
      "      - -193533.8631437751\n",
      "      - -194901.3708465213\n",
      "      - -194029.5934811951\n",
      "      - -194738.4132085446\n",
      "      - -195451.80769083486\n",
      "      - -193522.58771488362\n",
      "      - -194530.26259316396\n",
      "      - -200422.40045512226\n",
      "      - -196219.26283188327\n",
      "      - -194987.93047881185\n",
      "      - -196931.71533909233\n",
      "      - -194251.9253508105\n",
      "      - -193991.34452955917\n",
      "      - -197160.18034194244\n",
      "      - -195993.18230491743\n",
      "      - -193480.62167757246\n",
      "      - -194673.90192061133\n",
      "      - -196143.5246202491\n",
      "      - -194031.31790192722\n",
      "      - -193328.00382606286\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.0941092018619906\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46731726579505706\n",
      "      mean_inference_ms: 0.9662809771958336\n",
      "      mean_raw_obs_processing_ms: 0.13429256349266375\n",
      "  time_since_restore: 1834.804268360138\n",
      "  time_this_iter_s: 9.995410442352295\n",
      "  time_total_s: 1834.804268360138\n",
      "  timers:\n",
      "    learn_throughput: 131036.596\n",
      "    learn_time_ms: 488.291\n",
      "    load_throughput: 22558596.826\n",
      "    load_time_ms: 2.836\n",
      "    training_iteration_time_ms: 9585.692\n",
      "    update_time_ms: 4.278\n",
      "  timestamp: 1665850585\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 12284928\n",
      "  training_iteration: 192\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:16:25 (running for 00:31:00.26)<br>Memory usage on this node: 13.6/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   192</td><td style=\"text-align: right;\">          1834.8</td><td style=\"text-align: right;\">12284928</td><td style=\"text-align: right;\"> -195292</td><td style=\"text-align: right;\">             -192169</td><td style=\"text-align: right;\">             -200766</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:16:30 (running for 00:31:05.27)<br>Memory usage on this node: 13.6/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   192</td><td style=\"text-align: right;\">          1834.8</td><td style=\"text-align: right;\">12284928</td><td style=\"text-align: right;\"> -195292</td><td style=\"text-align: right;\">             -192169</td><td style=\"text-align: right;\">             -200766</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 12348912\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 12348912\n",
      "    num_agent_steps_trained: 12348912\n",
      "    num_env_steps_sampled: 12348912\n",
      "    num_env_steps_trained: 12348912\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-16-35\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -193071.29924243595\n",
      "  episode_reward_mean: -195162.12683990842\n",
      "  episode_reward_min: -201898.77272890083\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 12348\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.117231845855713\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0004072028968948871\n",
      "          model: {}\n",
      "          policy_loss: 0.00034335468080826104\n",
      "          total_loss: 10.000113487243652\n",
      "          vf_explained_var: -2.838316426334586e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 12348912\n",
      "    num_agent_steps_trained: 12348912\n",
      "    num_env_steps_sampled: 12348912\n",
      "    num_env_steps_trained: 12348912\n",
      "  iterations_since_restore: 193\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 12348912\n",
      "  num_agent_steps_trained: 12348912\n",
      "  num_env_steps_sampled: 12348912\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 12348912\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 80.66428571428571\n",
      "    ram_util_percent: 87.53571428571426\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09410032224491442\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4673839872869942\n",
      "    mean_inference_ms: 0.9663460845488226\n",
      "    mean_raw_obs_processing_ms: 0.134125029256701\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -193071.29924243595\n",
      "    episode_reward_mean: -195162.12683990842\n",
      "    episode_reward_min: -201898.77272890083\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -195258.42719169857\n",
      "      - -193806.8336053827\n",
      "      - -193087.24712261962\n",
      "      - -195111.66370006284\n",
      "      - -197677.48342954126\n",
      "      - -194267.6746476962\n",
      "      - -196821.55652349535\n",
      "      - -197278.3477849226\n",
      "      - -193533.8631437751\n",
      "      - -194901.3708465213\n",
      "      - -194029.5934811951\n",
      "      - -194738.4132085446\n",
      "      - -195451.80769083486\n",
      "      - -193522.58771488362\n",
      "      - -194530.26259316396\n",
      "      - -200422.40045512226\n",
      "      - -196219.26283188327\n",
      "      - -194987.93047881185\n",
      "      - -196931.71533909233\n",
      "      - -194251.9253508105\n",
      "      - -193991.34452955917\n",
      "      - -197160.18034194244\n",
      "      - -195993.18230491743\n",
      "      - -193480.62167757246\n",
      "      - -194673.90192061133\n",
      "      - -196143.5246202491\n",
      "      - -194031.31790192722\n",
      "      - -193328.00382606286\n",
      "      - -194899.25239900395\n",
      "      - -193526.44269699702\n",
      "      - -194887.40201496967\n",
      "      - -194490.59096833775\n",
      "      - -195589.11043902853\n",
      "      - -195656.1984568478\n",
      "      - -201898.77272890083\n",
      "      - -193499.47404067506\n",
      "      - -193900.0206748071\n",
      "      - -198611.925056403\n",
      "      - -195380.7854321773\n",
      "      - -197425.69798703882\n",
      "      - -195298.66618399968\n",
      "      - -194975.74844947047\n",
      "      - -196186.79086595995\n",
      "      - -195202.3251713071\n",
      "      - -194659.3101889961\n",
      "      - -193715.99255360977\n",
      "      - -196630.37487333847\n",
      "      - -196525.2461599935\n",
      "      - -194585.77414115626\n",
      "      - -194544.02570165435\n",
      "      - -194559.4424033158\n",
      "      - -196133.63194980333\n",
      "      - -193750.21291281667\n",
      "      - -198383.20549628648\n",
      "      - -193071.29924243595\n",
      "      - -194816.3263859862\n",
      "      - -194635.50901079286\n",
      "      - -194763.58310885288\n",
      "      - -194049.15950640006\n",
      "      - -194736.46648739235\n",
      "      - -197507.54953555382\n",
      "      - -194613.19323302046\n",
      "      - -194499.6149791001\n",
      "      - -194005.54894143672\n",
      "      - -193373.05053790176\n",
      "      - -196478.01201567947\n",
      "      - -196337.0369494823\n",
      "      - -195939.39826507124\n",
      "      - -195853.11372592178\n",
      "      - -193610.5917686832\n",
      "      - -194842.21638489718\n",
      "      - -196621.37858872124\n",
      "      - -194860.17609409976\n",
      "      - -193741.12032296535\n",
      "      - -196246.17488412448\n",
      "      - -196858.00278622707\n",
      "      - -193724.93720096716\n",
      "      - -197162.8474038094\n",
      "      - -194692.07213441914\n",
      "      - -194307.88439627862\n",
      "      - -194264.9409342066\n",
      "      - -193331.51326020822\n",
      "      - -194595.7868124867\n",
      "      - -194316.49684351095\n",
      "      - -194323.1209049943\n",
      "      - -194458.11512095545\n",
      "      - -194584.7753013305\n",
      "      - -195342.2516091216\n",
      "      - -194370.93468654735\n",
      "      - -193911.05927694752\n",
      "      - -196481.61805190996\n",
      "      - -194934.74746993842\n",
      "      - -196331.3052171635\n",
      "      - -195120.01919601473\n",
      "      - -195709.46261589957\n",
      "      - -195118.23829171606\n",
      "      - -194572.1402075448\n",
      "      - -194677.45187628295\n",
      "      - -194257.25926308188\n",
      "      - -193616.31895096655\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09410032224491442\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4673839872869942\n",
      "      mean_inference_ms: 0.9663460845488226\n",
      "      mean_raw_obs_processing_ms: 0.134125029256701\n",
      "  time_since_restore: 1844.3894386291504\n",
      "  time_this_iter_s: 9.585170269012451\n",
      "  time_total_s: 1844.3894386291504\n",
      "  timers:\n",
      "    learn_throughput: 131297.416\n",
      "    learn_time_ms: 487.321\n",
      "    load_throughput: 22404543.811\n",
      "    load_time_ms: 2.856\n",
      "    training_iteration_time_ms: 9558.108\n",
      "    update_time_ms: 4.285\n",
      "  timestamp: 1665850595\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 12348912\n",
      "  training_iteration: 193\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:16:40 (running for 00:31:14.88)<br>Memory usage on this node: 13.6/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   193</td><td style=\"text-align: right;\">         1844.39</td><td style=\"text-align: right;\">12348912</td><td style=\"text-align: right;\"> -195162</td><td style=\"text-align: right;\">             -193071</td><td style=\"text-align: right;\">             -201899</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:16:45 (running for 00:31:19.88)<br>Memory usage on this node: 13.6/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   193</td><td style=\"text-align: right;\">         1844.39</td><td style=\"text-align: right;\">12348912</td><td style=\"text-align: right;\"> -195162</td><td style=\"text-align: right;\">             -193071</td><td style=\"text-align: right;\">             -201899</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 12412896\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 12412896\n",
      "    num_agent_steps_trained: 12412896\n",
      "    num_env_steps_sampled: 12412896\n",
      "    num_env_steps_trained: 12412896\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-16-45\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -191974.75191293945\n",
      "  episode_reward_mean: -194841.13265852406\n",
      "  episode_reward_min: -198389.49882416817\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 12408\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1146576404571533\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0004980836529284716\n",
      "          model: {}\n",
      "          policy_loss: 0.005655413493514061\n",
      "          total_loss: 10.00544261932373\n",
      "          vf_explained_var: -1.9868215517249155e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 12412896\n",
      "    num_agent_steps_trained: 12412896\n",
      "    num_env_steps_sampled: 12412896\n",
      "    num_env_steps_trained: 12412896\n",
      "  iterations_since_restore: 194\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 12412896\n",
      "  num_agent_steps_trained: 12412896\n",
      "  num_env_steps_sampled: 12412896\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 12412896\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 90.2142857142857\n",
      "    ram_util_percent: 87.70000000000002\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09416704517178115\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.467355965908657\n",
      "    mean_inference_ms: 0.9669461542190837\n",
      "    mean_raw_obs_processing_ms: 0.1343419558661576\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -191974.75191293945\n",
      "    episode_reward_mean: -194841.13265852406\n",
      "    episode_reward_min: -198389.49882416817\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -197507.54953555382\n",
      "      - -194613.19323302046\n",
      "      - -194499.6149791001\n",
      "      - -194005.54894143672\n",
      "      - -193373.05053790176\n",
      "      - -196478.01201567947\n",
      "      - -196337.0369494823\n",
      "      - -195939.39826507124\n",
      "      - -195853.11372592178\n",
      "      - -193610.5917686832\n",
      "      - -194842.21638489718\n",
      "      - -196621.37858872124\n",
      "      - -194860.17609409976\n",
      "      - -193741.12032296535\n",
      "      - -196246.17488412448\n",
      "      - -196858.00278622707\n",
      "      - -193724.93720096716\n",
      "      - -197162.8474038094\n",
      "      - -194692.07213441914\n",
      "      - -194307.88439627862\n",
      "      - -194264.9409342066\n",
      "      - -193331.51326020822\n",
      "      - -194595.7868124867\n",
      "      - -194316.49684351095\n",
      "      - -194323.1209049943\n",
      "      - -194458.11512095545\n",
      "      - -194584.7753013305\n",
      "      - -195342.2516091216\n",
      "      - -194370.93468654735\n",
      "      - -193911.05927694752\n",
      "      - -196481.61805190996\n",
      "      - -194934.74746993842\n",
      "      - -196331.3052171635\n",
      "      - -195120.01919601473\n",
      "      - -195709.46261589957\n",
      "      - -195118.23829171606\n",
      "      - -194572.1402075448\n",
      "      - -194677.45187628295\n",
      "      - -194257.25926308188\n",
      "      - -193616.31895096655\n",
      "      - -194913.711867853\n",
      "      - -197287.09362390987\n",
      "      - -193714.6909878213\n",
      "      - -195409.2896670151\n",
      "      - -195494.57793743684\n",
      "      - -196430.88156676062\n",
      "      - -193021.98947964396\n",
      "      - -194825.83296982595\n",
      "      - -194830.99272368135\n",
      "      - -192227.73233927443\n",
      "      - -194814.11497565848\n",
      "      - -193594.8159945028\n",
      "      - -192781.8716615837\n",
      "      - -196668.75666762964\n",
      "      - -195645.95566097036\n",
      "      - -193106.36501378706\n",
      "      - -196441.8662318724\n",
      "      - -195023.06747477577\n",
      "      - -193234.2531411245\n",
      "      - -192626.9079951713\n",
      "      - -192835.24437134253\n",
      "      - -195239.98209735233\n",
      "      - -195282.95501467487\n",
      "      - -196510.64972116178\n",
      "      - -194138.46634857895\n",
      "      - -195616.88157461822\n",
      "      - -193433.04161144307\n",
      "      - -193561.83702975407\n",
      "      - -194377.08447331106\n",
      "      - -194585.8243637483\n",
      "      - -197473.75856622294\n",
      "      - -195313.4178166232\n",
      "      - -194546.0424781449\n",
      "      - -193627.10252240708\n",
      "      - -196022.84415005933\n",
      "      - -193770.18680040672\n",
      "      - -195419.1735833312\n",
      "      - -194416.3801559395\n",
      "      - -194864.61113045382\n",
      "      - -193700.1700273038\n",
      "      - -197219.72785242394\n",
      "      - -195198.33881357755\n",
      "      - -196288.0340566262\n",
      "      - -192951.1132451008\n",
      "      - -194563.5620718433\n",
      "      - -196624.87741951825\n",
      "      - -198389.49882416817\n",
      "      - -195936.9250952982\n",
      "      - -193860.29077946933\n",
      "      - -191974.75191293945\n",
      "      - -194057.96654887928\n",
      "      - -193601.33421652587\n",
      "      - -192457.13127894714\n",
      "      - -193329.39083441492\n",
      "      - -194022.67336547287\n",
      "      - -195507.50771049055\n",
      "      - -194325.6015536773\n",
      "      - -195372.01513774678\n",
      "      - -196343.41492596452\n",
      "      - -195667.2123529594\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09416704517178115\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.467355965908657\n",
      "      mean_inference_ms: 0.9669461542190837\n",
      "      mean_raw_obs_processing_ms: 0.1343419558661576\n",
      "  time_since_restore: 1854.9398038387299\n",
      "  time_this_iter_s: 10.550365209579468\n",
      "  time_total_s: 1854.9398038387299\n",
      "  timers:\n",
      "    learn_throughput: 132473.615\n",
      "    learn_time_ms: 482.994\n",
      "    load_throughput: 22398186.162\n",
      "    load_time_ms: 2.857\n",
      "    training_iteration_time_ms: 9666.594\n",
      "    update_time_ms: 4.119\n",
      "  timestamp: 1665850605\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 12412896\n",
      "  training_iteration: 194\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:16:51 (running for 00:31:25.48)<br>Memory usage on this node: 13.4/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   194</td><td style=\"text-align: right;\">         1854.94</td><td style=\"text-align: right;\">12412896</td><td style=\"text-align: right;\"> -194841</td><td style=\"text-align: right;\">             -191975</td><td style=\"text-align: right;\">             -198389</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 12476880\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 12476880\n",
      "    num_agent_steps_trained: 12476880\n",
      "    num_env_steps_sampled: 12476880\n",
      "    num_env_steps_trained: 12476880\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-16-56\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -191974.75191293945\n",
      "  episode_reward_mean: -195088.25552743475\n",
      "  episode_reward_min: -198390.97836715638\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 12468\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1122734546661377\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0008813755121082067\n",
      "          model: {}\n",
      "          policy_loss: 0.005916025955229998\n",
      "          total_loss: 10.005781173706055\n",
      "          vf_explained_var: -1.797600468478322e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 12476880\n",
      "    num_agent_steps_trained: 12476880\n",
      "    num_env_steps_sampled: 12476880\n",
      "    num_env_steps_trained: 12476880\n",
      "  iterations_since_restore: 195\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 12476880\n",
      "  num_agent_steps_trained: 12476880\n",
      "  num_env_steps_sampled: 12476880\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 12476880\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 85.75333333333334\n",
      "    ram_util_percent: 87.00000000000001\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09416038999845097\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46747863924836236\n",
      "    mean_inference_ms: 0.9675487887256972\n",
      "    mean_raw_obs_processing_ms: 0.13439199061527785\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -191974.75191293945\n",
      "    episode_reward_mean: -195088.25552743475\n",
      "    episode_reward_min: -198390.97836715638\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -192835.24437134253\n",
      "      - -195239.98209735233\n",
      "      - -195282.95501467487\n",
      "      - -196510.64972116178\n",
      "      - -194138.46634857895\n",
      "      - -195616.88157461822\n",
      "      - -193433.04161144307\n",
      "      - -193561.83702975407\n",
      "      - -194377.08447331106\n",
      "      - -194585.8243637483\n",
      "      - -197473.75856622294\n",
      "      - -195313.4178166232\n",
      "      - -194546.0424781449\n",
      "      - -193627.10252240708\n",
      "      - -196022.84415005933\n",
      "      - -193770.18680040672\n",
      "      - -195419.1735833312\n",
      "      - -194416.3801559395\n",
      "      - -194864.61113045382\n",
      "      - -193700.1700273038\n",
      "      - -197219.72785242394\n",
      "      - -195198.33881357755\n",
      "      - -196288.0340566262\n",
      "      - -192951.1132451008\n",
      "      - -194563.5620718433\n",
      "      - -196624.87741951825\n",
      "      - -198389.49882416817\n",
      "      - -195936.9250952982\n",
      "      - -193860.29077946933\n",
      "      - -191974.75191293945\n",
      "      - -194057.96654887928\n",
      "      - -193601.33421652587\n",
      "      - -192457.13127894714\n",
      "      - -193329.39083441492\n",
      "      - -194022.67336547287\n",
      "      - -195507.50771049055\n",
      "      - -194325.6015536773\n",
      "      - -195372.01513774678\n",
      "      - -196343.41492596452\n",
      "      - -195667.2123529594\n",
      "      - -196336.9743761333\n",
      "      - -194614.2251621005\n",
      "      - -195200.24390365102\n",
      "      - -198390.97836715638\n",
      "      - -194733.4838993452\n",
      "      - -194839.02899340063\n",
      "      - -194331.86244198226\n",
      "      - -194738.43529509738\n",
      "      - -195446.14169857674\n",
      "      - -195461.19120287817\n",
      "      - -194281.36881192896\n",
      "      - -195520.6881409063\n",
      "      - -194239.99925722918\n",
      "      - -195250.62365835355\n",
      "      - -194749.57593374807\n",
      "      - -196271.1538419695\n",
      "      - -196595.8309950816\n",
      "      - -196690.44341931757\n",
      "      - -194094.24674521305\n",
      "      - -195257.83851872484\n",
      "      - -195375.28175778757\n",
      "      - -196493.67216577535\n",
      "      - -195639.24867857454\n",
      "      - -197180.7242520967\n",
      "      - -192869.7021518968\n",
      "      - -194058.77396408154\n",
      "      - -195296.14369767238\n",
      "      - -194632.28150082662\n",
      "      - -197719.30291865175\n",
      "      - -195502.94831530334\n",
      "      - -193752.65577200887\n",
      "      - -196080.09861721154\n",
      "      - -196662.0456204714\n",
      "      - -192253.92767543264\n",
      "      - -194864.07175659042\n",
      "      - -193147.1301313048\n",
      "      - -195646.18627597412\n",
      "      - -198033.31724461634\n",
      "      - -194853.2786147833\n",
      "      - -192560.1568841812\n",
      "      - -195567.7506065521\n",
      "      - -196582.66071032095\n",
      "      - -197080.89619667325\n",
      "      - -194443.13214725544\n",
      "      - -195347.56797499026\n",
      "      - -194890.31036634365\n",
      "      - -196408.2932707354\n",
      "      - -194529.72547831296\n",
      "      - -196224.7219907796\n",
      "      - -196734.8027689137\n",
      "      - -193810.7271437342\n",
      "      - -195363.4121528513\n",
      "      - -193808.40232342726\n",
      "      - -192507.67583938682\n",
      "      - -195775.4881033432\n",
      "      - -194974.40442011738\n",
      "      - -196610.41606525524\n",
      "      - -194211.68517497662\n",
      "      - -193959.82586954968\n",
      "      - -197901.3496490019\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09416038999845097\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46747863924836236\n",
      "      mean_inference_ms: 0.9675487887256972\n",
      "      mean_raw_obs_processing_ms: 0.13439199061527785\n",
      "  time_since_restore: 1865.2250463962555\n",
      "  time_this_iter_s: 10.285242557525635\n",
      "  time_total_s: 1865.2250463962555\n",
      "  timers:\n",
      "    learn_throughput: 134073.409\n",
      "    learn_time_ms: 477.231\n",
      "    load_throughput: 22242621.287\n",
      "    load_time_ms: 2.877\n",
      "    training_iteration_time_ms: 9757.891\n",
      "    update_time_ms: 4.199\n",
      "  timestamp: 1665850616\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 12476880\n",
      "  training_iteration: 195\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:16:56 (running for 00:31:30.58)<br>Memory usage on this node: 13.4/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   195</td><td style=\"text-align: right;\">         1865.23</td><td style=\"text-align: right;\">12476880</td><td style=\"text-align: right;\"> -195088</td><td style=\"text-align: right;\">             -191975</td><td style=\"text-align: right;\">             -198391</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:17:01 (running for 00:31:35.79)<br>Memory usage on this node: 13.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   195</td><td style=\"text-align: right;\">         1865.23</td><td style=\"text-align: right;\">12476880</td><td style=\"text-align: right;\"> -195088</td><td style=\"text-align: right;\">             -191975</td><td style=\"text-align: right;\">             -198391</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 12540864\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 12540864\n",
      "    num_agent_steps_trained: 12540864\n",
      "    num_env_steps_sampled: 12540864\n",
      "    num_env_steps_trained: 12540864\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-17-05\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -190672.81684305417\n",
      "  episode_reward_mean: -194839.94413951068\n",
      "  episode_reward_min: -204820.6393425539\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 12540\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1066508293151855\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00042972754454240203\n",
      "          model: {}\n",
      "          policy_loss: 0.000525987590663135\n",
      "          total_loss: 10.000300407409668\n",
      "          vf_explained_var: -1.419158213167293e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 12540864\n",
      "    num_agent_steps_trained: 12540864\n",
      "    num_env_steps_sampled: 12540864\n",
      "    num_env_steps_trained: 12540864\n",
      "  iterations_since_restore: 196\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 12540864\n",
      "  num_agent_steps_trained: 12540864\n",
      "  num_env_steps_sampled: 12540864\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 12540864\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.77142857142857\n",
      "    ram_util_percent: 86.15714285714284\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09416462695603825\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4675763173908237\n",
      "    mean_inference_ms: 0.9677371415732042\n",
      "    mean_raw_obs_processing_ms: 0.13424682690426307\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -190672.81684305417\n",
      "    episode_reward_mean: -194839.94413951068\n",
      "    episode_reward_min: -204820.6393425539\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -196662.0456204714\n",
      "      - -192253.92767543264\n",
      "      - -194864.07175659042\n",
      "      - -193147.1301313048\n",
      "      - -195646.18627597412\n",
      "      - -198033.31724461634\n",
      "      - -194853.2786147833\n",
      "      - -192560.1568841812\n",
      "      - -195567.7506065521\n",
      "      - -196582.66071032095\n",
      "      - -197080.89619667325\n",
      "      - -194443.13214725544\n",
      "      - -195347.56797499026\n",
      "      - -194890.31036634365\n",
      "      - -196408.2932707354\n",
      "      - -194529.72547831296\n",
      "      - -196224.7219907796\n",
      "      - -196734.8027689137\n",
      "      - -193810.7271437342\n",
      "      - -195363.4121528513\n",
      "      - -193808.40232342726\n",
      "      - -192507.67583938682\n",
      "      - -195775.4881033432\n",
      "      - -194974.40442011738\n",
      "      - -196610.41606525524\n",
      "      - -194211.68517497662\n",
      "      - -193959.82586954968\n",
      "      - -197901.3496490019\n",
      "      - -196027.46698006534\n",
      "      - -195962.82004531537\n",
      "      - -196685.17009038915\n",
      "      - -196102.28628376138\n",
      "      - -194682.06674840578\n",
      "      - -199439.46486358493\n",
      "      - -195076.23885648377\n",
      "      - -193380.37884567917\n",
      "      - -193490.08244130528\n",
      "      - -194687.16276368054\n",
      "      - -194754.8443055225\n",
      "      - -193686.8455775491\n",
      "      - -195527.4276386862\n",
      "      - -193490.2799963084\n",
      "      - -195175.26086192153\n",
      "      - -194856.69325399926\n",
      "      - -195400.9865371292\n",
      "      - -195438.76749536814\n",
      "      - -194265.76230440114\n",
      "      - -194845.30960396206\n",
      "      - -194597.7849206732\n",
      "      - -194876.14388417415\n",
      "      - -193753.65673787636\n",
      "      - -195597.92784450937\n",
      "      - -193819.78563791147\n",
      "      - -194599.73794649495\n",
      "      - -194522.20660795746\n",
      "      - -195892.17957419937\n",
      "      - -195542.75834838513\n",
      "      - -195917.21454762729\n",
      "      - -195759.58554352765\n",
      "      - -193984.18776734904\n",
      "      - -193017.70368081672\n",
      "      - -195085.26417819835\n",
      "      - -193476.55973798546\n",
      "      - -195169.9656896542\n",
      "      - -194390.46734909332\n",
      "      - -194265.06773867528\n",
      "      - -192739.05226186846\n",
      "      - -194134.39578277568\n",
      "      - -193435.7025343482\n",
      "      - -194164.46965520593\n",
      "      - -193466.87789552225\n",
      "      - -194813.22096442996\n",
      "      - -195502.54261938695\n",
      "      - -193999.64835229056\n",
      "      - -194093.3692594801\n",
      "      - -196186.18877003706\n",
      "      - -194070.77937682148\n",
      "      - -195255.44578497662\n",
      "      - -193733.43084760173\n",
      "      - -193474.96651181\n",
      "      - -193643.3331595395\n",
      "      - -191710.24970793643\n",
      "      - -204820.6393425539\n",
      "      - -195689.56711802786\n",
      "      - -195928.90129861573\n",
      "      - -193693.60074162888\n",
      "      - -190672.81684305417\n",
      "      - -193871.7303648496\n",
      "      - -192794.25177455705\n",
      "      - -196678.15784686353\n",
      "      - -191485.73186503744\n",
      "      - -194264.18212693057\n",
      "      - -193861.40332634767\n",
      "      - -195941.3967858526\n",
      "      - -194300.28165846565\n",
      "      - -197172.53482918636\n",
      "      - -193867.91493275246\n",
      "      - -196946.65821870216\n",
      "      - -193051.80264904443\n",
      "      - -192532.29306006973\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09416462695603825\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4675763173908237\n",
      "      mean_inference_ms: 0.9677371415732042\n",
      "      mean_raw_obs_processing_ms: 0.13424682690426307\n",
      "  time_since_restore: 1874.8393173217773\n",
      "  time_this_iter_s: 9.61427092552185\n",
      "  time_total_s: 1874.8393173217773\n",
      "  timers:\n",
      "    learn_throughput: 136059.13\n",
      "    learn_time_ms: 470.266\n",
      "    load_throughput: 22246493.288\n",
      "    load_time_ms: 2.876\n",
      "    training_iteration_time_ms: 9733.35\n",
      "    update_time_ms: 4.363\n",
      "  timestamp: 1665850625\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 12540864\n",
      "  training_iteration: 196\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:17:10 (running for 00:31:45.24)<br>Memory usage on this node: 13.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   196</td><td style=\"text-align: right;\">         1874.84</td><td style=\"text-align: right;\">12540864</td><td style=\"text-align: right;\"> -194840</td><td style=\"text-align: right;\">             -190673</td><td style=\"text-align: right;\">             -204821</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 12604848\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 12604848\n",
      "    num_agent_steps_trained: 12604848\n",
      "    num_env_steps_sampled: 12604848\n",
      "    num_env_steps_trained: 12604848\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-17-15\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -190672.81684305417\n",
      "  episode_reward_mean: -194743.52437988532\n",
      "  episode_reward_min: -204820.6393425539\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 12600\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.105902910232544\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0005130438366904855\n",
      "          model: {}\n",
      "          policy_loss: 0.005939910653978586\n",
      "          total_loss: 10.005731582641602\n",
      "          vf_explained_var: -3.12214822884016e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 12604848\n",
      "    num_agent_steps_trained: 12604848\n",
      "    num_env_steps_sampled: 12604848\n",
      "    num_env_steps_trained: 12604848\n",
      "  iterations_since_restore: 197\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 12604848\n",
      "  num_agent_steps_trained: 12604848\n",
      "  num_env_steps_sampled: 12604848\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 12604848\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.60000000000001\n",
      "    ram_util_percent: 86.0\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09419378466823186\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.467416752000598\n",
      "    mean_inference_ms: 0.9681171710796036\n",
      "    mean_raw_obs_processing_ms: 0.13440577243680932\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -190672.81684305417\n",
      "    episode_reward_mean: -194743.52437988532\n",
      "    episode_reward_min: -204820.6393425539\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -193017.70368081672\n",
      "      - -195085.26417819835\n",
      "      - -193476.55973798546\n",
      "      - -195169.9656896542\n",
      "      - -194390.46734909332\n",
      "      - -194265.06773867528\n",
      "      - -192739.05226186846\n",
      "      - -194134.39578277568\n",
      "      - -193435.7025343482\n",
      "      - -194164.46965520593\n",
      "      - -193466.87789552225\n",
      "      - -194813.22096442996\n",
      "      - -195502.54261938695\n",
      "      - -193999.64835229056\n",
      "      - -194093.3692594801\n",
      "      - -196186.18877003706\n",
      "      - -194070.77937682148\n",
      "      - -195255.44578497662\n",
      "      - -193733.43084760173\n",
      "      - -193474.96651181\n",
      "      - -193643.3331595395\n",
      "      - -191710.24970793643\n",
      "      - -204820.6393425539\n",
      "      - -195689.56711802786\n",
      "      - -195928.90129861573\n",
      "      - -193693.60074162888\n",
      "      - -190672.81684305417\n",
      "      - -193871.7303648496\n",
      "      - -192794.25177455705\n",
      "      - -196678.15784686353\n",
      "      - -191485.73186503744\n",
      "      - -194264.18212693057\n",
      "      - -193861.40332634767\n",
      "      - -195941.3967858526\n",
      "      - -194300.28165846565\n",
      "      - -197172.53482918636\n",
      "      - -193867.91493275246\n",
      "      - -196946.65821870216\n",
      "      - -193051.80264904443\n",
      "      - -192532.29306006973\n",
      "      - -196824.80366142388\n",
      "      - -193997.35446403638\n",
      "      - -194641.0312018506\n",
      "      - -196431.16335109627\n",
      "      - -195543.1506061113\n",
      "      - -194444.12683235758\n",
      "      - -194991.19764797445\n",
      "      - -195809.26143791125\n",
      "      - -194637.3555635867\n",
      "      - -195395.56509309006\n",
      "      - -195851.3581871024\n",
      "      - -196346.46154071257\n",
      "      - -196977.68812083034\n",
      "      - -194503.4871715841\n",
      "      - -193706.68391763826\n",
      "      - -194801.2667237862\n",
      "      - -195599.12351708132\n",
      "      - -193758.55253511242\n",
      "      - -194337.87970301235\n",
      "      - -193819.2013832923\n",
      "      - -194565.01719908134\n",
      "      - -195221.2645911173\n",
      "      - -196426.46586466694\n",
      "      - -196279.5513305811\n",
      "      - -193730.59605483766\n",
      "      - -194159.8881543295\n",
      "      - -195650.5023463521\n",
      "      - -194802.78186437758\n",
      "      - -195270.34268050294\n",
      "      - -193820.52151857602\n",
      "      - -195762.4516597027\n",
      "      - -195204.37473532622\n",
      "      - -195280.1328994213\n",
      "      - -196387.9610761843\n",
      "      - -194750.46990989835\n",
      "      - -194639.25794163733\n",
      "      - -193419.17151512406\n",
      "      - -193528.54665306423\n",
      "      - -194025.35342174664\n",
      "      - -196112.46375767168\n",
      "      - -193335.63898123958\n",
      "      - -196032.16185331676\n",
      "      - -193811.295403502\n",
      "      - -195081.62570282107\n",
      "      - -193331.23070543155\n",
      "      - -193083.29586614872\n",
      "      - -196017.0992240095\n",
      "      - -195307.44438301196\n",
      "      - -195119.37924118005\n",
      "      - -196533.3525318863\n",
      "      - -192585.1679720004\n",
      "      - -195246.55852541016\n",
      "      - -193788.7423492776\n",
      "      - -195253.2441547524\n",
      "      - -196111.99458317936\n",
      "      - -194236.65642069303\n",
      "      - -198737.84901758863\n",
      "      - -194260.43534274245\n",
      "      - -191515.8690416077\n",
      "      - -196107.00221394247\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09419378466823186\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.467416752000598\n",
      "      mean_inference_ms: 0.9681171710796036\n",
      "      mean_raw_obs_processing_ms: 0.13440577243680932\n",
      "  time_since_restore: 1884.5540597438812\n",
      "  time_this_iter_s: 9.714742422103882\n",
      "  time_total_s: 1884.5540597438812\n",
      "  timers:\n",
      "    learn_throughput: 135698.055\n",
      "    learn_time_ms: 471.517\n",
      "    load_throughput: 22389403.585\n",
      "    load_time_ms: 2.858\n",
      "    training_iteration_time_ms: 9732.724\n",
      "    update_time_ms: 4.211\n",
      "  timestamp: 1665850635\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 12604848\n",
      "  training_iteration: 197\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:17:20 (running for 00:31:55.20)<br>Memory usage on this node: 13.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   197</td><td style=\"text-align: right;\">         1884.55</td><td style=\"text-align: right;\">12604848</td><td style=\"text-align: right;\"> -194744</td><td style=\"text-align: right;\">             -190673</td><td style=\"text-align: right;\">             -204821</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 12668832\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 12668832\n",
      "    num_agent_steps_trained: 12668832\n",
      "    num_env_steps_sampled: 12668832\n",
      "    num_env_steps_trained: 12668832\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-17-24\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -191515.8690416077\n",
      "  episode_reward_mean: -194898.1995693789\n",
      "  episode_reward_min: -199049.4612761541\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 12660\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1080994606018066\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0006616516038775444\n",
      "          model: {}\n",
      "          policy_loss: 0.00533079681918025\n",
      "          total_loss: 10.00515079498291\n",
      "          vf_explained_var: -3.311369312086754e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 12668832\n",
      "    num_agent_steps_trained: 12668832\n",
      "    num_env_steps_sampled: 12668832\n",
      "    num_env_steps_trained: 12668832\n",
      "  iterations_since_restore: 198\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 12668832\n",
      "  num_agent_steps_trained: 12668832\n",
      "  num_env_steps_sampled: 12668832\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 12668832\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.30000000000001\n",
      "    ram_util_percent: 85.86153846153844\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09413396721131416\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46736987322562\n",
      "    mean_inference_ms: 0.9681825237163977\n",
      "    mean_raw_obs_processing_ms: 0.13437518416389715\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -191515.8690416077\n",
      "    episode_reward_mean: -194898.1995693789\n",
      "    episode_reward_min: -199049.4612761541\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -194565.01719908134\n",
      "      - -195221.2645911173\n",
      "      - -196426.46586466694\n",
      "      - -196279.5513305811\n",
      "      - -193730.59605483766\n",
      "      - -194159.8881543295\n",
      "      - -195650.5023463521\n",
      "      - -194802.78186437758\n",
      "      - -195270.34268050294\n",
      "      - -193820.52151857602\n",
      "      - -195762.4516597027\n",
      "      - -195204.37473532622\n",
      "      - -195280.1328994213\n",
      "      - -196387.9610761843\n",
      "      - -194750.46990989835\n",
      "      - -194639.25794163733\n",
      "      - -193419.17151512406\n",
      "      - -193528.54665306423\n",
      "      - -194025.35342174664\n",
      "      - -196112.46375767168\n",
      "      - -193335.63898123958\n",
      "      - -196032.16185331676\n",
      "      - -193811.295403502\n",
      "      - -195081.62570282107\n",
      "      - -193331.23070543155\n",
      "      - -193083.29586614872\n",
      "      - -196017.0992240095\n",
      "      - -195307.44438301196\n",
      "      - -195119.37924118005\n",
      "      - -196533.3525318863\n",
      "      - -192585.1679720004\n",
      "      - -195246.55852541016\n",
      "      - -193788.7423492776\n",
      "      - -195253.2441547524\n",
      "      - -196111.99458317936\n",
      "      - -194236.65642069303\n",
      "      - -198737.84901758863\n",
      "      - -194260.43534274245\n",
      "      - -191515.8690416077\n",
      "      - -196107.00221394247\n",
      "      - -193930.5596179523\n",
      "      - -195589.08200994064\n",
      "      - -194265.3235684733\n",
      "      - -195431.12484191934\n",
      "      - -193240.01206481524\n",
      "      - -194660.57088541848\n",
      "      - -199049.4612761541\n",
      "      - -196646.4563205177\n",
      "      - -194692.7670674979\n",
      "      - -194167.04217858\n",
      "      - -196329.81027376297\n",
      "      - -195276.48421102273\n",
      "      - -195525.48361265217\n",
      "      - -195973.09684270623\n",
      "      - -195239.01811696502\n",
      "      - -193625.35654089245\n",
      "      - -194358.67777919356\n",
      "      - -194046.20387253238\n",
      "      - -196289.29217630124\n",
      "      - -193195.33548112027\n",
      "      - -196211.45215472596\n",
      "      - -198660.75979720996\n",
      "      - -193979.310820125\n",
      "      - -193234.5579260534\n",
      "      - -194631.12458248396\n",
      "      - -193924.25819405945\n",
      "      - -195029.14734179326\n",
      "      - -195964.24986517854\n",
      "      - -194006.7928294106\n",
      "      - -193955.87431610192\n",
      "      - -193086.93445863298\n",
      "      - -196452.0323070677\n",
      "      - -194028.0567721204\n",
      "      - -196525.24823795678\n",
      "      - -197929.35309822648\n",
      "      - -193216.06877102685\n",
      "      - -194736.38708489676\n",
      "      - -196984.06800244437\n",
      "      - -193295.70478776455\n",
      "      - -194613.67499167076\n",
      "      - -193452.62487156878\n",
      "      - -197177.90575669796\n",
      "      - -193700.98684437302\n",
      "      - -193588.87479021578\n",
      "      - -194553.20953318212\n",
      "      - -194328.0681764195\n",
      "      - -193966.78304101233\n",
      "      - -195767.06722555618\n",
      "      - -195455.1017984869\n",
      "      - -194161.5709664011\n",
      "      - -193569.47548979847\n",
      "      - -193975.77185167075\n",
      "      - -194712.4789175746\n",
      "      - -194505.98689566227\n",
      "      - -195271.53754725808\n",
      "      - -194102.0535379552\n",
      "      - -195526.157872642\n",
      "      - -193797.96596642846\n",
      "      - -195753.668453998\n",
      "      - -195923.2936356782\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09413396721131416\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46736987322562\n",
      "      mean_inference_ms: 0.9681825237163977\n",
      "      mean_raw_obs_processing_ms: 0.13437518416389715\n",
      "  time_since_restore: 1893.9312632083893\n",
      "  time_this_iter_s: 9.377203464508057\n",
      "  time_total_s: 1893.9312632083893\n",
      "  timers:\n",
      "    learn_throughput: 135357.001\n",
      "    learn_time_ms: 472.706\n",
      "    load_throughput: 22227514.94\n",
      "    load_time_ms: 2.879\n",
      "    training_iteration_time_ms: 9737.439\n",
      "    update_time_ms: 4.315\n",
      "  timestamp: 1665850644\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 12668832\n",
      "  training_iteration: 198\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:17:30 (running for 00:32:04.60)<br>Memory usage on this node: 13.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   198</td><td style=\"text-align: right;\">         1893.93</td><td style=\"text-align: right;\">12668832</td><td style=\"text-align: right;\"> -194898</td><td style=\"text-align: right;\">             -191516</td><td style=\"text-align: right;\">             -199049</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 12732816\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 12732816\n",
      "    num_agent_steps_trained: 12732816\n",
      "    num_env_steps_sampled: 12732816\n",
      "    num_env_steps_trained: 12732816\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-17-35\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -191129.81385884332\n",
      "  episode_reward_mean: -194568.74090561387\n",
      "  episode_reward_min: -199424.82433262374\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 12732\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1053125858306885\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0007091911393217742\n",
      "          model: {}\n",
      "          policy_loss: -0.0004779269511345774\n",
      "          total_loss: 9.999351501464844\n",
      "          vf_explained_var: -4.9197485196827984e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 12732816\n",
      "    num_agent_steps_trained: 12732816\n",
      "    num_env_steps_sampled: 12732816\n",
      "    num_env_steps_trained: 12732816\n",
      "  iterations_since_restore: 199\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 12732816\n",
      "  num_agent_steps_trained: 12732816\n",
      "  num_env_steps_sampled: 12732816\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 12732816\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.54285714285716\n",
      "    ram_util_percent: 85.82142857142856\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.094162301532523\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4674848309242899\n",
      "    mean_inference_ms: 0.9682325826339384\n",
      "    mean_raw_obs_processing_ms: 0.13418876534612814\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -191129.81385884332\n",
      "    episode_reward_mean: -194568.74090561387\n",
      "    episode_reward_min: -199424.82433262374\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -194028.0567721204\n",
      "      - -196525.24823795678\n",
      "      - -197929.35309822648\n",
      "      - -193216.06877102685\n",
      "      - -194736.38708489676\n",
      "      - -196984.06800244437\n",
      "      - -193295.70478776455\n",
      "      - -194613.67499167076\n",
      "      - -193452.62487156878\n",
      "      - -197177.90575669796\n",
      "      - -193700.98684437302\n",
      "      - -193588.87479021578\n",
      "      - -194553.20953318212\n",
      "      - -194328.0681764195\n",
      "      - -193966.78304101233\n",
      "      - -195767.06722555618\n",
      "      - -195455.1017984869\n",
      "      - -194161.5709664011\n",
      "      - -193569.47548979847\n",
      "      - -193975.77185167075\n",
      "      - -194712.4789175746\n",
      "      - -194505.98689566227\n",
      "      - -195271.53754725808\n",
      "      - -194102.0535379552\n",
      "      - -195526.157872642\n",
      "      - -193797.96596642846\n",
      "      - -195753.668453998\n",
      "      - -195923.2936356782\n",
      "      - -194866.87184465965\n",
      "      - -196138.04002272774\n",
      "      - -192174.03695268292\n",
      "      - -196352.37336827617\n",
      "      - -196565.86157257934\n",
      "      - -194578.8168351332\n",
      "      - -194392.76029741153\n",
      "      - -191129.81385884332\n",
      "      - -193230.8100282184\n",
      "      - -192186.41322696744\n",
      "      - -195327.4080582309\n",
      "      - -196996.76628477316\n",
      "      - -193531.0223051914\n",
      "      - -195232.82164767652\n",
      "      - -194009.64764641505\n",
      "      - -194273.28985306624\n",
      "      - -192865.62628917833\n",
      "      - -193393.4727004014\n",
      "      - -195404.09310778277\n",
      "      - -192360.89585898397\n",
      "      - -194310.2495438949\n",
      "      - -195251.24593483962\n",
      "      - -193705.26075236005\n",
      "      - -194478.1999081462\n",
      "      - -195436.1248800473\n",
      "      - -194978.5586936498\n",
      "      - -193274.5749723408\n",
      "      - -196673.56991515742\n",
      "      - -194891.43452974592\n",
      "      - -194446.38949928698\n",
      "      - -192436.6243845225\n",
      "      - -196574.87445097658\n",
      "      - -196158.84340020694\n",
      "      - -196133.4307989565\n",
      "      - -193433.37402598478\n",
      "      - -194333.94786434146\n",
      "      - -193822.1641245866\n",
      "      - -193024.45458028093\n",
      "      - -191940.23841149316\n",
      "      - -193200.50659942982\n",
      "      - -197551.33548205087\n",
      "      - -191954.69322888096\n",
      "      - -193322.13599502476\n",
      "      - -194280.1082730867\n",
      "      - -195422.13874970475\n",
      "      - -193180.19439598115\n",
      "      - -194816.67741956192\n",
      "      - -195606.37812140567\n",
      "      - -193285.73514404442\n",
      "      - -196953.34077846643\n",
      "      - -198014.87799143436\n",
      "      - -195417.9294211347\n",
      "      - -194282.04218181755\n",
      "      - -192566.22772010474\n",
      "      - -196932.78081558755\n",
      "      - -193459.22065795725\n",
      "      - -193893.16048029246\n",
      "      - -193646.87255538188\n",
      "      - -197278.06367321388\n",
      "      - -194749.06014023174\n",
      "      - -191724.77057891784\n",
      "      - -199424.82433262374\n",
      "      - -192998.1724060697\n",
      "      - -192375.48916294874\n",
      "      - -196078.82722001767\n",
      "      - -194837.22064174505\n",
      "      - -193689.0301768324\n",
      "      - -194237.01021630966\n",
      "      - -193272.93398083674\n",
      "      - -194315.9519327417\n",
      "      - -194149.89238272927\n",
      "      - -195022.9403561148\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.094162301532523\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4674848309242899\n",
      "      mean_inference_ms: 0.9682325826339384\n",
      "      mean_raw_obs_processing_ms: 0.13418876534612814\n",
      "  time_since_restore: 1903.9906873703003\n",
      "  time_this_iter_s: 10.05942416191101\n",
      "  time_total_s: 1903.9906873703003\n",
      "  timers:\n",
      "    learn_throughput: 135215.687\n",
      "    learn_time_ms: 473.2\n",
      "    load_throughput: 22390524.382\n",
      "    load_time_ms: 2.858\n",
      "    training_iteration_time_ms: 9818.369\n",
      "    update_time_ms: 4.243\n",
      "  timestamp: 1665850655\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 12732816\n",
      "  training_iteration: 199\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:17:40 (running for 00:32:14.48)<br>Memory usage on this node: 13.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   199</td><td style=\"text-align: right;\">         1903.99</td><td style=\"text-align: right;\">12732816</td><td style=\"text-align: right;\"> -194569</td><td style=\"text-align: right;\">             -191130</td><td style=\"text-align: right;\">             -199425</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 12796800\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 12796800\n",
      "    num_agent_steps_trained: 12796800\n",
      "    num_env_steps_sampled: 12796800\n",
      "    num_env_steps_trained: 12796800\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-17-44\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -190358.31593205556\n",
      "  episode_reward_mean: -194343.25400471\n",
      "  episode_reward_min: -199424.82433262374\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 12792\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.098520040512085\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0006763115525245667\n",
      "          model: {}\n",
      "          policy_loss: 0.006477045826613903\n",
      "          total_loss: 10.006302833557129\n",
      "          vf_explained_var: -4.352085269943018e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 12796800\n",
      "    num_agent_steps_trained: 12796800\n",
      "    num_env_steps_sampled: 12796800\n",
      "    num_env_steps_trained: 12796800\n",
      "  iterations_since_restore: 200\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 12796800\n",
      "  num_agent_steps_trained: 12796800\n",
      "  num_env_steps_sampled: 12796800\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 12796800\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.08461538461539\n",
      "    ram_util_percent: 85.82307692307691\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09420860193378382\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4674389510767219\n",
      "    mean_inference_ms: 0.9683374841069952\n",
      "    mean_raw_obs_processing_ms: 0.13434822182141282\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -190358.31593205556\n",
      "    episode_reward_mean: -194343.25400471\n",
      "    episode_reward_min: -199424.82433262374\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -196158.84340020694\n",
      "      - -196133.4307989565\n",
      "      - -193433.37402598478\n",
      "      - -194333.94786434146\n",
      "      - -193822.1641245866\n",
      "      - -193024.45458028093\n",
      "      - -191940.23841149316\n",
      "      - -193200.50659942982\n",
      "      - -197551.33548205087\n",
      "      - -191954.69322888096\n",
      "      - -193322.13599502476\n",
      "      - -194280.1082730867\n",
      "      - -195422.13874970475\n",
      "      - -193180.19439598115\n",
      "      - -194816.67741956192\n",
      "      - -195606.37812140567\n",
      "      - -193285.73514404442\n",
      "      - -196953.34077846643\n",
      "      - -198014.87799143436\n",
      "      - -195417.9294211347\n",
      "      - -194282.04218181755\n",
      "      - -192566.22772010474\n",
      "      - -196932.78081558755\n",
      "      - -193459.22065795725\n",
      "      - -193893.16048029246\n",
      "      - -193646.87255538188\n",
      "      - -197278.06367321388\n",
      "      - -194749.06014023174\n",
      "      - -191724.77057891784\n",
      "      - -199424.82433262374\n",
      "      - -192998.1724060697\n",
      "      - -192375.48916294874\n",
      "      - -196078.82722001767\n",
      "      - -194837.22064174505\n",
      "      - -193689.0301768324\n",
      "      - -194237.01021630966\n",
      "      - -193272.93398083674\n",
      "      - -194315.9519327417\n",
      "      - -194149.89238272927\n",
      "      - -195022.9403561148\n",
      "      - -194836.19641911334\n",
      "      - -195334.49912781204\n",
      "      - -194528.46546131672\n",
      "      - -194439.86789042977\n",
      "      - -195797.65030864542\n",
      "      - -193198.25717614635\n",
      "      - -194286.69599414503\n",
      "      - -192850.55910454266\n",
      "      - -194190.92239996055\n",
      "      - -194416.47446815745\n",
      "      - -194767.44019101738\n",
      "      - -195417.58614511203\n",
      "      - -193295.63247481297\n",
      "      - -194726.73405907856\n",
      "      - -196149.22901166507\n",
      "      - -194736.174684839\n",
      "      - -195634.88393626155\n",
      "      - -195472.04256226195\n",
      "      - -193675.50043149779\n",
      "      - -195231.2476933321\n",
      "      - -197560.01132858676\n",
      "      - -195793.79609149674\n",
      "      - -192533.4534566543\n",
      "      - -195149.5383488832\n",
      "      - -194883.88492170346\n",
      "      - -192831.1962902598\n",
      "      - -190358.31593205556\n",
      "      - -196611.98433746074\n",
      "      - -193790.04730188573\n",
      "      - -195223.7840660813\n",
      "      - -193088.19479334736\n",
      "      - -192690.44923240432\n",
      "      - -194373.7911738197\n",
      "      - -195841.75566115844\n",
      "      - -193977.96329917104\n",
      "      - -193134.60944757095\n",
      "      - -195174.82259741076\n",
      "      - -194035.95636983847\n",
      "      - -195722.5061930402\n",
      "      - -192316.49392448924\n",
      "      - -194732.55459165585\n",
      "      - -192419.84847688663\n",
      "      - -191870.47243091394\n",
      "      - -193620.26621765152\n",
      "      - -195965.15441574663\n",
      "      - -194178.4926814528\n",
      "      - -195338.64947694665\n",
      "      - -192596.0499145473\n",
      "      - -195118.43192236172\n",
      "      - -194381.8000507128\n",
      "      - -194923.33673880674\n",
      "      - -192233.30970839426\n",
      "      - -193996.88427919886\n",
      "      - -192886.8706042454\n",
      "      - -193400.4833037496\n",
      "      - -194600.04789018218\n",
      "      - -191192.78173328648\n",
      "      - -196142.44008025093\n",
      "      - -192802.5613054748\n",
      "      - -193059.35392254326\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09420860193378382\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4674389510767219\n",
      "      mean_inference_ms: 0.9683374841069952\n",
      "      mean_raw_obs_processing_ms: 0.13434822182141282\n",
      "  time_since_restore: 1913.2933418750763\n",
      "  time_this_iter_s: 9.302654504776001\n",
      "  time_total_s: 1913.2933418750763\n",
      "  timers:\n",
      "    learn_throughput: 134604.922\n",
      "    learn_time_ms: 475.347\n",
      "    load_throughput: 21789335.212\n",
      "    load_time_ms: 2.936\n",
      "    training_iteration_time_ms: 9791.118\n",
      "    update_time_ms: 4.116\n",
      "  timestamp: 1665850664\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 12796800\n",
      "  training_iteration: 200\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:17:49 (running for 00:32:23.92)<br>Memory usage on this node: 13.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   200</td><td style=\"text-align: right;\">         1913.29</td><td style=\"text-align: right;\">12796800</td><td style=\"text-align: right;\"> -194343</td><td style=\"text-align: right;\">             -190358</td><td style=\"text-align: right;\">             -199425</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 12860784\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 12860784\n",
      "    num_agent_steps_trained: 12860784\n",
      "    num_env_steps_sampled: 12860784\n",
      "    num_env_steps_trained: 12860784\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-17-53\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -190358.31593205556\n",
      "  episode_reward_mean: -194390.67130051178\n",
      "  episode_reward_min: -197560.01132858676\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 12852\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0985288619995117\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0007683765725232661\n",
      "          model: {}\n",
      "          policy_loss: 0.005664716474711895\n",
      "          total_loss: 10.005508422851562\n",
      "          vf_explained_var: -2.176042634971509e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 12860784\n",
      "    num_agent_steps_trained: 12860784\n",
      "    num_env_steps_sampled: 12860784\n",
      "    num_env_steps_trained: 12860784\n",
      "  iterations_since_restore: 201\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 12860784\n",
      "  num_agent_steps_trained: 12860784\n",
      "  num_env_steps_sampled: 12860784\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 12860784\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.7076923076923\n",
      "    ram_util_percent: 85.83076923076922\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09415084325570428\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4674211667437179\n",
      "    mean_inference_ms: 0.9682032442621518\n",
      "    mean_raw_obs_processing_ms: 0.13432451510304733\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -190358.31593205556\n",
      "    episode_reward_mean: -194390.67130051178\n",
      "    episode_reward_min: -197560.01132858676\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -197560.01132858676\n",
      "      - -195793.79609149674\n",
      "      - -192533.4534566543\n",
      "      - -195149.5383488832\n",
      "      - -194883.88492170346\n",
      "      - -192831.1962902598\n",
      "      - -190358.31593205556\n",
      "      - -196611.98433746074\n",
      "      - -193790.04730188573\n",
      "      - -195223.7840660813\n",
      "      - -193088.19479334736\n",
      "      - -192690.44923240432\n",
      "      - -194373.7911738197\n",
      "      - -195841.75566115844\n",
      "      - -193977.96329917104\n",
      "      - -193134.60944757095\n",
      "      - -195174.82259741076\n",
      "      - -194035.95636983847\n",
      "      - -195722.5061930402\n",
      "      - -192316.49392448924\n",
      "      - -194732.55459165585\n",
      "      - -192419.84847688663\n",
      "      - -191870.47243091394\n",
      "      - -193620.26621765152\n",
      "      - -195965.15441574663\n",
      "      - -194178.4926814528\n",
      "      - -195338.64947694665\n",
      "      - -192596.0499145473\n",
      "      - -195118.43192236172\n",
      "      - -194381.8000507128\n",
      "      - -194923.33673880674\n",
      "      - -192233.30970839426\n",
      "      - -193996.88427919886\n",
      "      - -192886.8706042454\n",
      "      - -193400.4833037496\n",
      "      - -194600.04789018218\n",
      "      - -191192.78173328648\n",
      "      - -196142.44008025093\n",
      "      - -192802.5613054748\n",
      "      - -193059.35392254326\n",
      "      - -194589.639442474\n",
      "      - -194534.18600408593\n",
      "      - -193947.55364195755\n",
      "      - -193202.0982865812\n",
      "      - -194250.3950578685\n",
      "      - -197035.51142804796\n",
      "      - -194994.16664993227\n",
      "      - -193552.6956796365\n",
      "      - -193160.89789964588\n",
      "      - -195132.26595648934\n",
      "      - -196046.9963088154\n",
      "      - -195020.62694118096\n",
      "      - -195676.28363726675\n",
      "      - -194980.34630550275\n",
      "      - -194788.75269858117\n",
      "      - -193786.84038280277\n",
      "      - -195369.1248361331\n",
      "      - -195914.79565299948\n",
      "      - -196155.27244748102\n",
      "      - -193565.12334949456\n",
      "      - -191854.16991860853\n",
      "      - -193998.40708867682\n",
      "      - -191625.84858418134\n",
      "      - -196015.6315588446\n",
      "      - -192227.97076802282\n",
      "      - -196655.04097550706\n",
      "      - -194932.83277628763\n",
      "      - -194226.6589148015\n",
      "      - -193166.57355609295\n",
      "      - -195787.55367797345\n",
      "      - -196116.37810991157\n",
      "      - -193834.824374105\n",
      "      - -194789.2680873186\n",
      "      - -194877.19387569078\n",
      "      - -194378.6174197257\n",
      "      - -193107.98447932073\n",
      "      - -196081.10261115822\n",
      "      - -195023.31363427636\n",
      "      - -193423.20428196577\n",
      "      - -195407.33423824862\n",
      "      - -193327.09722003507\n",
      "      - -197406.7233829428\n",
      "      - -195881.391170183\n",
      "      - -193909.46031007657\n",
      "      - -196680.85231036815\n",
      "      - -194935.4928330662\n",
      "      - -193243.7950076638\n",
      "      - -192791.00390631202\n",
      "      - -195883.79151848055\n",
      "      - -196192.4710259837\n",
      "      - -196524.74646516598\n",
      "      - -193838.94633225183\n",
      "      - -194544.68066082554\n",
      "      - -196113.00977533657\n",
      "      - -195871.85310081497\n",
      "      - -192771.9239554566\n",
      "      - -194192.52738921402\n",
      "      - -192929.78403876536\n",
      "      - -192866.97944905353\n",
      "      - -195374.77414915757\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09415084325570428\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4674211667437179\n",
      "      mean_inference_ms: 0.9682032442621518\n",
      "      mean_raw_obs_processing_ms: 0.13432451510304733\n",
      "  time_since_restore: 1922.6517791748047\n",
      "  time_this_iter_s: 9.358437299728394\n",
      "  time_total_s: 1922.6517791748047\n",
      "  timers:\n",
      "    learn_throughput: 134199.016\n",
      "    learn_time_ms: 476.784\n",
      "    load_throughput: 21782614.639\n",
      "    load_time_ms: 2.937\n",
      "    training_iteration_time_ms: 9777.277\n",
      "    update_time_ms: 4.259\n",
      "  timestamp: 1665850673\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 12860784\n",
      "  training_iteration: 201\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:17:59 (running for 00:32:33.53)<br>Memory usage on this node: 13.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   201</td><td style=\"text-align: right;\">         1922.65</td><td style=\"text-align: right;\">12860784</td><td style=\"text-align: right;\"> -194391</td><td style=\"text-align: right;\">             -190358</td><td style=\"text-align: right;\">             -197560</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 12924768\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 12924768\n",
      "    num_agent_steps_trained: 12924768\n",
      "    num_env_steps_sampled: 12924768\n",
      "    num_env_steps_trained: 12924768\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-18-03\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -189790.51887089308\n",
      "  episode_reward_mean: -194330.68073344324\n",
      "  episode_reward_min: -197406.7233829428\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 12924\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.096658706665039\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0014591491781175137\n",
      "          model: {}\n",
      "          policy_loss: -0.000762587005738169\n",
      "          total_loss: 9.999220848083496\n",
      "          vf_explained_var: -3.12214822884016e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 12924768\n",
      "    num_agent_steps_trained: 12924768\n",
      "    num_env_steps_sampled: 12924768\n",
      "    num_env_steps_trained: 12924768\n",
      "  iterations_since_restore: 202\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 12924768\n",
      "  num_agent_steps_trained: 12924768\n",
      "  num_env_steps_sampled: 12924768\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 12924768\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.60769230769232\n",
      "    ram_util_percent: 85.80769230769229\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09413211649714459\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4673980588347398\n",
      "    mean_inference_ms: 0.9679915187095708\n",
      "    mean_raw_obs_processing_ms: 0.13412869197595031\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -189790.51887089308\n",
      "    episode_reward_mean: -194330.68073344324\n",
      "    episode_reward_min: -197406.7233829428\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -194789.2680873186\n",
      "      - -194877.19387569078\n",
      "      - -194378.6174197257\n",
      "      - -193107.98447932073\n",
      "      - -196081.10261115822\n",
      "      - -195023.31363427636\n",
      "      - -193423.20428196577\n",
      "      - -195407.33423824862\n",
      "      - -193327.09722003507\n",
      "      - -197406.7233829428\n",
      "      - -195881.391170183\n",
      "      - -193909.46031007657\n",
      "      - -196680.85231036815\n",
      "      - -194935.4928330662\n",
      "      - -193243.7950076638\n",
      "      - -192791.00390631202\n",
      "      - -195883.79151848055\n",
      "      - -196192.4710259837\n",
      "      - -196524.74646516598\n",
      "      - -193838.94633225183\n",
      "      - -194544.68066082554\n",
      "      - -196113.00977533657\n",
      "      - -195871.85310081497\n",
      "      - -192771.9239554566\n",
      "      - -194192.52738921402\n",
      "      - -192929.78403876536\n",
      "      - -192866.97944905353\n",
      "      - -195374.77414915757\n",
      "      - -195463.65033247223\n",
      "      - -193427.30107293237\n",
      "      - -193297.31640171754\n",
      "      - -194228.47103210387\n",
      "      - -192755.25936930507\n",
      "      - -194521.39769905145\n",
      "      - -195093.5323255054\n",
      "      - -195816.77455354162\n",
      "      - -194737.32410168275\n",
      "      - -196965.343393237\n",
      "      - -194631.89275519864\n",
      "      - -196770.75007195483\n",
      "      - -191236.10111309538\n",
      "      - -196026.74822574944\n",
      "      - -195845.3622956815\n",
      "      - -194497.73246109646\n",
      "      - -192434.95242984805\n",
      "      - -194053.7901391027\n",
      "      - -197292.12126531496\n",
      "      - -196322.14684099934\n",
      "      - -194595.40729846153\n",
      "      - -189790.51887089308\n",
      "      - -192776.6007872735\n",
      "      - -192526.13769984542\n",
      "      - -196015.942138225\n",
      "      - -193270.70454597942\n",
      "      - -193728.27980863722\n",
      "      - -193503.19856204523\n",
      "      - -192728.40793934575\n",
      "      - -195246.6505766108\n",
      "      - -192612.76737140724\n",
      "      - -193825.89032269336\n",
      "      - -194009.3753854995\n",
      "      - -197381.84203919704\n",
      "      - -194332.11841122224\n",
      "      - -193547.72000924693\n",
      "      - -194976.06203255005\n",
      "      - -194498.49859532836\n",
      "      - -192899.99766728113\n",
      "      - -193178.00365995258\n",
      "      - -194273.72982704913\n",
      "      - -192827.57784845983\n",
      "      - -192302.7449907964\n",
      "      - -195139.10226437353\n",
      "      - -192288.76978548476\n",
      "      - -196512.59984262037\n",
      "      - -194987.69886136538\n",
      "      - -194832.58469295842\n",
      "      - -194111.62355829435\n",
      "      - -194958.66917501122\n",
      "      - -193000.31075858144\n",
      "      - -195495.1773241935\n",
      "      - -193909.81173052726\n",
      "      - -193027.63959210197\n",
      "      - -193086.9829292227\n",
      "      - -196361.71179356187\n",
      "      - -191621.22851367184\n",
      "      - -192383.66059030098\n",
      "      - -195691.568819972\n",
      "      - -192947.84775974098\n",
      "      - -192332.7786433279\n",
      "      - -193348.18491351014\n",
      "      - -193105.32761953655\n",
      "      - -193195.16221231507\n",
      "      - -195656.84818435146\n",
      "      - -194045.79780554652\n",
      "      - -195725.57738853383\n",
      "      - -194388.13396823575\n",
      "      - -196264.29621866904\n",
      "      - -192681.738200725\n",
      "      - -195338.53219393277\n",
      "      - -193993.24110720344\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09413211649714459\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4673980588347398\n",
      "      mean_inference_ms: 0.9679915187095708\n",
      "      mean_raw_obs_processing_ms: 0.13412869197595031\n",
      "  time_since_restore: 1931.9498987197876\n",
      "  time_this_iter_s: 9.29811954498291\n",
      "  time_total_s: 1931.9498987197876\n",
      "  timers:\n",
      "    learn_throughput: 134581.013\n",
      "    learn_time_ms: 475.431\n",
      "    load_throughput: 21613674.205\n",
      "    load_time_ms: 2.96\n",
      "    training_iteration_time_ms: 9707.643\n",
      "    update_time_ms: 4.326\n",
      "  timestamp: 1665850683\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 12924768\n",
      "  training_iteration: 202\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:18:08 (running for 00:32:42.64)<br>Memory usage on this node: 13.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   202</td><td style=\"text-align: right;\">         1931.95</td><td style=\"text-align: right;\">12924768</td><td style=\"text-align: right;\"> -194331</td><td style=\"text-align: right;\">             -189791</td><td style=\"text-align: right;\">             -197407</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 12988752\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 12988752\n",
      "    num_agent_steps_trained: 12988752\n",
      "    num_env_steps_sampled: 12988752\n",
      "    num_env_steps_trained: 12988752\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-18-12\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -191330.4776732859\n",
      "  episode_reward_mean: -193999.67099924\n",
      "  episode_reward_min: -197381.84203919704\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 12984\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0964560508728027\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0004325784102547914\n",
      "          model: {}\n",
      "          policy_loss: 0.006012150086462498\n",
      "          total_loss: 10.005789756774902\n",
      "          vf_explained_var: -4.1628641866964244e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 12988752\n",
      "    num_agent_steps_trained: 12988752\n",
      "    num_env_steps_sampled: 12988752\n",
      "    num_env_steps_trained: 12988752\n",
      "  iterations_since_restore: 203\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 12988752\n",
      "  num_agent_steps_trained: 12988752\n",
      "  num_env_steps_sampled: 12988752\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 12988752\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 80.84615384615384\n",
      "    ram_util_percent: 85.79999999999998\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0941545129919647\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46732312318798336\n",
      "    mean_inference_ms: 0.9682270954128183\n",
      "    mean_raw_obs_processing_ms: 0.13428545968602051\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -191330.4776732859\n",
      "    episode_reward_mean: -193999.67099924\n",
      "    episode_reward_min: -197381.84203919704\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -194009.3753854995\n",
      "      - -197381.84203919704\n",
      "      - -194332.11841122224\n",
      "      - -193547.72000924693\n",
      "      - -194976.06203255005\n",
      "      - -194498.49859532836\n",
      "      - -192899.99766728113\n",
      "      - -193178.00365995258\n",
      "      - -194273.72982704913\n",
      "      - -192827.57784845983\n",
      "      - -192302.7449907964\n",
      "      - -195139.10226437353\n",
      "      - -192288.76978548476\n",
      "      - -196512.59984262037\n",
      "      - -194987.69886136538\n",
      "      - -194832.58469295842\n",
      "      - -194111.62355829435\n",
      "      - -194958.66917501122\n",
      "      - -193000.31075858144\n",
      "      - -195495.1773241935\n",
      "      - -193909.81173052726\n",
      "      - -193027.63959210197\n",
      "      - -193086.9829292227\n",
      "      - -196361.71179356187\n",
      "      - -191621.22851367184\n",
      "      - -192383.66059030098\n",
      "      - -195691.568819972\n",
      "      - -192947.84775974098\n",
      "      - -192332.7786433279\n",
      "      - -193348.18491351014\n",
      "      - -193105.32761953655\n",
      "      - -193195.16221231507\n",
      "      - -195656.84818435146\n",
      "      - -194045.79780554652\n",
      "      - -195725.57738853383\n",
      "      - -194388.13396823575\n",
      "      - -196264.29621866904\n",
      "      - -192681.738200725\n",
      "      - -195338.53219393277\n",
      "      - -193993.24110720344\n",
      "      - -194347.5805117009\n",
      "      - -193040.39417620897\n",
      "      - -195490.74665938024\n",
      "      - -193557.3867826476\n",
      "      - -194741.05385289865\n",
      "      - -192151.04238382156\n",
      "      - -193814.89208777077\n",
      "      - -194213.85447333968\n",
      "      - -195090.980192227\n",
      "      - -192436.74714810163\n",
      "      - -193905.64848713594\n",
      "      - -195596.32494438576\n",
      "      - -194477.02351580228\n",
      "      - -194886.69445630358\n",
      "      - -195720.25616798896\n",
      "      - -195032.1255513323\n",
      "      - -195063.37664764127\n",
      "      - -196600.58429517876\n",
      "      - -195034.016460318\n",
      "      - -192602.48316152193\n",
      "      - -195183.03909136154\n",
      "      - -192522.89693410828\n",
      "      - -196521.63202663735\n",
      "      - -192189.08265101016\n",
      "      - -191992.60458324463\n",
      "      - -191330.4776732859\n",
      "      - -192995.83502420815\n",
      "      - -193008.57682983548\n",
      "      - -192584.57456146556\n",
      "      - -195226.9313016159\n",
      "      - -192729.20981852876\n",
      "      - -192913.4296852708\n",
      "      - -193083.8172373859\n",
      "      - -191373.15415043305\n",
      "      - -194791.67036923228\n",
      "      - -196237.0678243579\n",
      "      - -192206.63376623695\n",
      "      - -194483.65078308244\n",
      "      - -194630.8471529892\n",
      "      - -194839.66912609307\n",
      "      - -192576.70423985767\n",
      "      - -193814.18636337572\n",
      "      - -192533.96273546747\n",
      "      - -195203.3410348906\n",
      "      - -193014.1175129999\n",
      "      - -192200.6251330579\n",
      "      - -194171.00479670562\n",
      "      - -192760.59302843414\n",
      "      - -197053.94084585842\n",
      "      - -194894.2181201978\n",
      "      - -195382.76656739376\n",
      "      - -194222.17335498097\n",
      "      - -191331.30915902968\n",
      "      - -194459.9199045623\n",
      "      - -193290.1998342937\n",
      "      - -193774.5220766413\n",
      "      - -195502.68429435883\n",
      "      - -194601.27386017537\n",
      "      - -192041.58750380547\n",
      "      - -193829.68009737134\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.0941545129919647\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46732312318798336\n",
      "      mean_inference_ms: 0.9682270954128183\n",
      "      mean_raw_obs_processing_ms: 0.13428545968602051\n",
      "  time_since_restore: 1941.6759722232819\n",
      "  time_this_iter_s: 9.726073503494263\n",
      "  time_total_s: 1941.6759722232819\n",
      "  timers:\n",
      "    learn_throughput: 133301.014\n",
      "    learn_time_ms: 479.996\n",
      "    load_throughput: 21509389.197\n",
      "    load_time_ms: 2.975\n",
      "    training_iteration_time_ms: 9721.906\n",
      "    update_time_ms: 4.365\n",
      "  timestamp: 1665850692\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 12988752\n",
      "  training_iteration: 203\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:18:18 (running for 00:32:52.61)<br>Memory usage on this node: 13.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   203</td><td style=\"text-align: right;\">         1941.68</td><td style=\"text-align: right;\">12988752</td><td style=\"text-align: right;\"> -194000</td><td style=\"text-align: right;\">             -191330</td><td style=\"text-align: right;\">             -197382</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 13052736\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 13052736\n",
      "    num_agent_steps_trained: 13052736\n",
      "    num_env_steps_sampled: 13052736\n",
      "    num_env_steps_trained: 13052736\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-18-22\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -190941.85988333327\n",
      "  episode_reward_mean: -194039.40694359396\n",
      "  episode_reward_min: -198338.3397430027\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 13044\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0980165004730225\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0007822811603546143\n",
      "          model: {}\n",
      "          policy_loss: 0.005262515041977167\n",
      "          total_loss: 10.005109786987305\n",
      "          vf_explained_var: -2.3652637182181024e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 13052736\n",
      "    num_agent_steps_trained: 13052736\n",
      "    num_env_steps_sampled: 13052736\n",
      "    num_env_steps_trained: 13052736\n",
      "  iterations_since_restore: 204\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 13052736\n",
      "  num_agent_steps_trained: 13052736\n",
      "  num_env_steps_sampled: 13052736\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 13052736\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 84.34615384615384\n",
      "    ram_util_percent: 85.8153846153846\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09411377046504078\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.467331841777441\n",
      "    mean_inference_ms: 0.9682488818060259\n",
      "    mean_raw_obs_processing_ms: 0.13426635221576194\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -190941.85988333327\n",
      "    episode_reward_mean: -194039.40694359396\n",
      "    episode_reward_min: -198338.3397430027\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -195183.03909136154\n",
      "      - -192522.89693410828\n",
      "      - -196521.63202663735\n",
      "      - -192189.08265101016\n",
      "      - -191992.60458324463\n",
      "      - -191330.4776732859\n",
      "      - -192995.83502420815\n",
      "      - -193008.57682983548\n",
      "      - -192584.57456146556\n",
      "      - -195226.9313016159\n",
      "      - -192729.20981852876\n",
      "      - -192913.4296852708\n",
      "      - -193083.8172373859\n",
      "      - -191373.15415043305\n",
      "      - -194791.67036923228\n",
      "      - -196237.0678243579\n",
      "      - -192206.63376623695\n",
      "      - -194483.65078308244\n",
      "      - -194630.8471529892\n",
      "      - -194839.66912609307\n",
      "      - -192576.70423985767\n",
      "      - -193814.18636337572\n",
      "      - -192533.96273546747\n",
      "      - -195203.3410348906\n",
      "      - -193014.1175129999\n",
      "      - -192200.6251330579\n",
      "      - -194171.00479670562\n",
      "      - -192760.59302843414\n",
      "      - -197053.94084585842\n",
      "      - -194894.2181201978\n",
      "      - -195382.76656739376\n",
      "      - -194222.17335498097\n",
      "      - -191331.30915902968\n",
      "      - -194459.9199045623\n",
      "      - -193290.1998342937\n",
      "      - -193774.5220766413\n",
      "      - -195502.68429435883\n",
      "      - -194601.27386017537\n",
      "      - -192041.58750380547\n",
      "      - -193829.68009737134\n",
      "      - -195193.45290589918\n",
      "      - -195321.6939043369\n",
      "      - -195548.75616241028\n",
      "      - -194665.94056432988\n",
      "      - -193616.16336331895\n",
      "      - -191662.9803062126\n",
      "      - -194744.09747559726\n",
      "      - -194007.15046245168\n",
      "      - -194049.48912242387\n",
      "      - -192589.35064648342\n",
      "      - -193232.57273320868\n",
      "      - -193507.38195795615\n",
      "      - -195738.37216835673\n",
      "      - -196715.89518171258\n",
      "      - -196007.03816254574\n",
      "      - -195021.90897804286\n",
      "      - -195415.85020097587\n",
      "      - -197427.7086616121\n",
      "      - -190953.57488733172\n",
      "      - -192729.56031389185\n",
      "      - -195081.86895791965\n",
      "      - -192975.35626511445\n",
      "      - -193080.4135979647\n",
      "      - -194182.2437627887\n",
      "      - -194488.7465602734\n",
      "      - -195782.71712988656\n",
      "      - -190941.85988333327\n",
      "      - -193865.94160473603\n",
      "      - -194359.90309374742\n",
      "      - -192498.64326569115\n",
      "      - -194108.49901818775\n",
      "      - -193464.6044923103\n",
      "      - -191504.6840682225\n",
      "      - -195493.9599681484\n",
      "      - -197909.6143970397\n",
      "      - -194011.30909086735\n",
      "      - -193703.62284954044\n",
      "      - -195754.06418251063\n",
      "      - -193078.81540663572\n",
      "      - -195291.44939399086\n",
      "      - -193842.0706276426\n",
      "      - -191549.6760157354\n",
      "      - -192148.60665456887\n",
      "      - -194821.45285687564\n",
      "      - -193706.5474679906\n",
      "      - -192818.41857216012\n",
      "      - -197331.7131847897\n",
      "      - -198338.3397430027\n",
      "      - -191613.47486404065\n",
      "      - -194872.60101757114\n",
      "      - -192500.45706744422\n",
      "      - -193586.05157856477\n",
      "      - -195257.47681847622\n",
      "      - -195305.73140684867\n",
      "      - -195914.80212659301\n",
      "      - -193822.64613533518\n",
      "      - -193574.57601010107\n",
      "      - -195846.99605473343\n",
      "      - -195959.72783905122\n",
      "      - -193898.46211601904\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09411377046504078\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.467331841777441\n",
      "      mean_inference_ms: 0.9682488818060259\n",
      "      mean_raw_obs_processing_ms: 0.13426635221576194\n",
      "  time_since_restore: 1951.119778394699\n",
      "  time_this_iter_s: 9.443806171417236\n",
      "  time_total_s: 1951.119778394699\n",
      "  timers:\n",
      "    learn_throughput: 132027.095\n",
      "    learn_time_ms: 484.628\n",
      "    load_throughput: 21653610.071\n",
      "    load_time_ms: 2.955\n",
      "    training_iteration_time_ms: 9611.361\n",
      "    update_time_ms: 4.556\n",
      "  timestamp: 1665850702\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 13052736\n",
      "  training_iteration: 204\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:18:27 (running for 00:33:02.18)<br>Memory usage on this node: 13.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   204</td><td style=\"text-align: right;\">         1951.12</td><td style=\"text-align: right;\">13052736</td><td style=\"text-align: right;\"> -194039</td><td style=\"text-align: right;\">             -190942</td><td style=\"text-align: right;\">             -198338</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:18:32 (running for 00:33:07.20)<br>Memory usage on this node: 13.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   204</td><td style=\"text-align: right;\">         1951.12</td><td style=\"text-align: right;\">13052736</td><td style=\"text-align: right;\"> -194039</td><td style=\"text-align: right;\">             -190942</td><td style=\"text-align: right;\">             -198338</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 13116720\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 13116720\n",
      "    num_agent_steps_trained: 13116720\n",
      "    num_env_steps_sampled: 13116720\n",
      "    num_env_steps_trained: 13116720\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-18-32\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -190339.3611579891\n",
      "  episode_reward_mean: -194393.8742494724\n",
      "  episode_reward_min: -200699.6974262095\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 13116\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.09889817237854\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0003223623789381236\n",
      "          model: {}\n",
      "          policy_loss: -0.00021210857084952295\n",
      "          total_loss: 9.999543190002441\n",
      "          vf_explained_var: -3.0275376872168636e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 13116720\n",
      "    num_agent_steps_trained: 13116720\n",
      "    num_env_steps_sampled: 13116720\n",
      "    num_env_steps_trained: 13116720\n",
      "  iterations_since_restore: 205\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 13116720\n",
      "  num_agent_steps_trained: 13116720\n",
      "  num_env_steps_sampled: 13116720\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 13116720\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 84.26\n",
      "    ram_util_percent: 85.97333333333331\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0941419803877179\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46741907946940714\n",
      "    mean_inference_ms: 0.9685080665018367\n",
      "    mean_raw_obs_processing_ms: 0.13412762271173917\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -190339.3611579891\n",
      "    episode_reward_mean: -194393.8742494724\n",
      "    episode_reward_min: -200699.6974262095\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -191504.6840682225\n",
      "      - -195493.9599681484\n",
      "      - -197909.6143970397\n",
      "      - -194011.30909086735\n",
      "      - -193703.62284954044\n",
      "      - -195754.06418251063\n",
      "      - -193078.81540663572\n",
      "      - -195291.44939399086\n",
      "      - -193842.0706276426\n",
      "      - -191549.6760157354\n",
      "      - -192148.60665456887\n",
      "      - -194821.45285687564\n",
      "      - -193706.5474679906\n",
      "      - -192818.41857216012\n",
      "      - -197331.7131847897\n",
      "      - -198338.3397430027\n",
      "      - -191613.47486404065\n",
      "      - -194872.60101757114\n",
      "      - -192500.45706744422\n",
      "      - -193586.05157856477\n",
      "      - -195257.47681847622\n",
      "      - -195305.73140684867\n",
      "      - -195914.80212659301\n",
      "      - -193822.64613533518\n",
      "      - -193574.57601010107\n",
      "      - -195846.99605473343\n",
      "      - -195959.72783905122\n",
      "      - -193898.46211601904\n",
      "      - -193047.1336945347\n",
      "      - -194230.58397768464\n",
      "      - -194639.96793911548\n",
      "      - -194746.012801246\n",
      "      - -196148.896166537\n",
      "      - -193544.44032102186\n",
      "      - -193847.52936006247\n",
      "      - -190339.3611579891\n",
      "      - -196548.88512681372\n",
      "      - -192355.16007885768\n",
      "      - -194646.80418673303\n",
      "      - -194421.50720073626\n",
      "      - -195559.1288089537\n",
      "      - -197019.21211915207\n",
      "      - -194788.14678024207\n",
      "      - -192466.85439964113\n",
      "      - -194483.30154372024\n",
      "      - -194283.3220471154\n",
      "      - -190638.9791424348\n",
      "      - -194111.9347038562\n",
      "      - -193399.68495188028\n",
      "      - -192818.33989150508\n",
      "      - -194512.3570457647\n",
      "      - -193543.7047094958\n",
      "      - -193815.5075052885\n",
      "      - -195724.11847179473\n",
      "      - -194542.7930097301\n",
      "      - -193181.05990691617\n",
      "      - -194072.77693997548\n",
      "      - -194227.93305983068\n",
      "      - -195867.6690201595\n",
      "      - -194866.36436547857\n",
      "      - -195213.4044229762\n",
      "      - -195264.25289042012\n",
      "      - -193073.3555285947\n",
      "      - -193974.04381469748\n",
      "      - -193293.76017091676\n",
      "      - -193745.08005543554\n",
      "      - -195231.6200662658\n",
      "      - -194156.1429008292\n",
      "      - -194482.16224728068\n",
      "      - -194893.5697176934\n",
      "      - -196258.76905238043\n",
      "      - -194654.99451299114\n",
      "      - -194155.71896229722\n",
      "      - -190817.50829317654\n",
      "      - -194822.1792930495\n",
      "      - -195430.66913141686\n",
      "      - -193992.4638805893\n",
      "      - -200699.6974262095\n",
      "      - -197139.94780522707\n",
      "      - -193574.4153760777\n",
      "      - -193655.84305470937\n",
      "      - -194076.88255640457\n",
      "      - -193747.60396776765\n",
      "      - -194231.4853355389\n",
      "      - -195039.65886260028\n",
      "      - -195978.48701039626\n",
      "      - -195311.4087912247\n",
      "      - -196878.89226039863\n",
      "      - -193713.1537282249\n",
      "      - -193512.64729906464\n",
      "      - -192914.5192914249\n",
      "      - -192491.74118314357\n",
      "      - -192250.01171635243\n",
      "      - -193606.67342975046\n",
      "      - -195835.27988455747\n",
      "      - -195460.78240100568\n",
      "      - -195420.64582471823\n",
      "      - -195172.73487848847\n",
      "      - -195460.33482954648\n",
      "      - -193858.06514463227\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.0941419803877179\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46741907946940714\n",
      "      mean_inference_ms: 0.9685080665018367\n",
      "      mean_raw_obs_processing_ms: 0.13412762271173917\n",
      "  time_since_restore: 1961.4922170639038\n",
      "  time_this_iter_s: 10.372438669204712\n",
      "  time_total_s: 1961.4922170639038\n",
      "  timers:\n",
      "    learn_throughput: 131351.532\n",
      "    learn_time_ms: 487.12\n",
      "    load_throughput: 21696675.355\n",
      "    load_time_ms: 2.949\n",
      "    training_iteration_time_ms: 9620.12\n",
      "    update_time_ms: 4.615\n",
      "  timestamp: 1665850712\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 13116720\n",
      "  training_iteration: 205\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:18:38 (running for 00:33:12.50)<br>Memory usage on this node: 13.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   205</td><td style=\"text-align: right;\">         1961.49</td><td style=\"text-align: right;\">13116720</td><td style=\"text-align: right;\"> -194394</td><td style=\"text-align: right;\">             -190339</td><td style=\"text-align: right;\">             -200700</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 13180704\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 13180704\n",
      "    num_agent_steps_trained: 13180704\n",
      "    num_env_steps_sampled: 13180704\n",
      "    num_env_steps_trained: 13180704\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-18-42\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -190817.50829317654\n",
      "  episode_reward_mean: -194546.60718744586\n",
      "  episode_reward_min: -200699.6974262095\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 13176\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.096421480178833\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0004822109476663172\n",
      "          model: {}\n",
      "          policy_loss: 0.00585835799574852\n",
      "          total_loss: 10.005646705627441\n",
      "          vf_explained_var: -3.595200936956644e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 13180704\n",
      "    num_agent_steps_trained: 13180704\n",
      "    num_env_steps_sampled: 13180704\n",
      "    num_env_steps_trained: 13180704\n",
      "  iterations_since_restore: 206\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 13180704\n",
      "  num_agent_steps_trained: 13180704\n",
      "  num_env_steps_sampled: 13180704\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 13180704\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 84.32857142857142\n",
      "    ram_util_percent: 86.0\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09418719169658717\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46733765366330926\n",
      "    mean_inference_ms: 0.969093747700891\n",
      "    mean_raw_obs_processing_ms: 0.13431479450956715\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -190817.50829317654\n",
      "    episode_reward_mean: -194546.60718744586\n",
      "    episode_reward_min: -200699.6974262095\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -195213.4044229762\n",
      "      - -195264.25289042012\n",
      "      - -193073.3555285947\n",
      "      - -193974.04381469748\n",
      "      - -193293.76017091676\n",
      "      - -193745.08005543554\n",
      "      - -195231.6200662658\n",
      "      - -194156.1429008292\n",
      "      - -194482.16224728068\n",
      "      - -194893.5697176934\n",
      "      - -196258.76905238043\n",
      "      - -194654.99451299114\n",
      "      - -194155.71896229722\n",
      "      - -190817.50829317654\n",
      "      - -194822.1792930495\n",
      "      - -195430.66913141686\n",
      "      - -193992.4638805893\n",
      "      - -200699.6974262095\n",
      "      - -197139.94780522707\n",
      "      - -193574.4153760777\n",
      "      - -193655.84305470937\n",
      "      - -194076.88255640457\n",
      "      - -193747.60396776765\n",
      "      - -194231.4853355389\n",
      "      - -195039.65886260028\n",
      "      - -195978.48701039626\n",
      "      - -195311.4087912247\n",
      "      - -196878.89226039863\n",
      "      - -193713.1537282249\n",
      "      - -193512.64729906464\n",
      "      - -192914.5192914249\n",
      "      - -192491.74118314357\n",
      "      - -192250.01171635243\n",
      "      - -193606.67342975046\n",
      "      - -195835.27988455747\n",
      "      - -195460.78240100568\n",
      "      - -195420.64582471823\n",
      "      - -195172.73487848847\n",
      "      - -195460.33482954648\n",
      "      - -193858.06514463227\n",
      "      - -192058.06978330336\n",
      "      - -194802.09159780404\n",
      "      - -191726.09331240982\n",
      "      - -193429.19597959996\n",
      "      - -193129.7831712957\n",
      "      - -194801.02380938068\n",
      "      - -193370.08345613597\n",
      "      - -195182.659376338\n",
      "      - -193449.6496807809\n",
      "      - -193678.32341888\n",
      "      - -197916.18411479273\n",
      "      - -194815.41730484462\n",
      "      - -194557.76332566873\n",
      "      - -193970.11381936667\n",
      "      - -198758.27244541163\n",
      "      - -195051.51615269668\n",
      "      - -193634.10212454674\n",
      "      - -194534.37940429698\n",
      "      - -195794.0998370918\n",
      "      - -195959.8487911565\n",
      "      - -195165.178509704\n",
      "      - -193111.52957044606\n",
      "      - -195285.1122719433\n",
      "      - -194610.92608704223\n",
      "      - -195525.00230600574\n",
      "      - -193251.22337541316\n",
      "      - -196817.2027239281\n",
      "      - -192382.48143319384\n",
      "      - -194597.13995946667\n",
      "      - -197110.96305541776\n",
      "      - -194432.9893958608\n",
      "      - -195181.57142354886\n",
      "      - -192283.52202906422\n",
      "      - -196043.873907215\n",
      "      - -193697.59794736118\n",
      "      - -197229.9504868288\n",
      "      - -195615.14333332988\n",
      "      - -194255.81487175298\n",
      "      - -192074.05425079804\n",
      "      - -196213.01438379823\n",
      "      - -195312.80209488384\n",
      "      - -193056.52891783803\n",
      "      - -196265.5759928002\n",
      "      - -195343.5830037482\n",
      "      - -193108.07008520555\n",
      "      - -192238.32202583266\n",
      "      - -192498.92557349554\n",
      "      - -194138.43550045532\n",
      "      - -194345.3163372703\n",
      "      - -194159.34434262905\n",
      "      - -195450.94528737874\n",
      "      - -193146.73193229298\n",
      "      - -194439.18691617638\n",
      "      - -195778.6498121651\n",
      "      - -193656.65280867467\n",
      "      - -194722.06315016976\n",
      "      - -194777.24406423184\n",
      "      - -192336.49560862177\n",
      "      - -195859.709120048\n",
      "      - -195032.5669442774\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09418719169658717\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46733765366330926\n",
      "      mean_inference_ms: 0.969093747700891\n",
      "      mean_raw_obs_processing_ms: 0.13431479450956715\n",
      "  time_since_restore: 1971.4921607971191\n",
      "  time_this_iter_s: 9.999943733215332\n",
      "  time_total_s: 1971.4921607971191\n",
      "  timers:\n",
      "    learn_throughput: 129936.957\n",
      "    learn_time_ms: 492.423\n",
      "    load_throughput: 21633710.904\n",
      "    load_time_ms: 2.958\n",
      "    training_iteration_time_ms: 9658.568\n",
      "    update_time_ms: 4.566\n",
      "  timestamp: 1665850722\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 13180704\n",
      "  training_iteration: 206\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:18:47 (running for 00:33:22.33)<br>Memory usage on this node: 13.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   206</td><td style=\"text-align: right;\">         1971.49</td><td style=\"text-align: right;\">13180704</td><td style=\"text-align: right;\"> -194547</td><td style=\"text-align: right;\">             -190818</td><td style=\"text-align: right;\">             -200700</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 13244688\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 13244688\n",
      "    num_agent_steps_trained: 13244688\n",
      "    num_env_steps_sampled: 13244688\n",
      "    num_env_steps_trained: 13244688\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-18-52\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -192074.05425079804\n",
      "  episode_reward_mean: -194808.85372547276\n",
      "  episode_reward_min: -199193.99489665977\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 13236\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.104572057723999\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0012397636892274022\n",
      "          model: {}\n",
      "          policy_loss: 0.006068488582968712\n",
      "          total_loss: 10.00600528717041\n",
      "          vf_explained_var: -2.932926967957883e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 13244688\n",
      "    num_agent_steps_trained: 13244688\n",
      "    num_env_steps_sampled: 13244688\n",
      "    num_env_steps_trained: 13244688\n",
      "  iterations_since_restore: 207\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 13244688\n",
      "  num_agent_steps_trained: 13244688\n",
      "  num_env_steps_sampled: 13244688\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 13244688\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.83846153846154\n",
      "    ram_util_percent: 85.99230769230772\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09413082059490537\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4673158991482211\n",
      "    mean_inference_ms: 0.9691993186585782\n",
      "    mean_raw_obs_processing_ms: 0.13429836633221698\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -192074.05425079804\n",
      "    episode_reward_mean: -194808.85372547276\n",
      "    episode_reward_min: -199193.99489665977\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -195165.178509704\n",
      "      - -193111.52957044606\n",
      "      - -195285.1122719433\n",
      "      - -194610.92608704223\n",
      "      - -195525.00230600574\n",
      "      - -193251.22337541316\n",
      "      - -196817.2027239281\n",
      "      - -192382.48143319384\n",
      "      - -194597.13995946667\n",
      "      - -197110.96305541776\n",
      "      - -194432.9893958608\n",
      "      - -195181.57142354886\n",
      "      - -192283.52202906422\n",
      "      - -196043.873907215\n",
      "      - -193697.59794736118\n",
      "      - -197229.9504868288\n",
      "      - -195615.14333332988\n",
      "      - -194255.81487175298\n",
      "      - -192074.05425079804\n",
      "      - -196213.01438379823\n",
      "      - -195312.80209488384\n",
      "      - -193056.52891783803\n",
      "      - -196265.5759928002\n",
      "      - -195343.5830037482\n",
      "      - -193108.07008520555\n",
      "      - -192238.32202583266\n",
      "      - -192498.92557349554\n",
      "      - -194138.43550045532\n",
      "      - -194345.3163372703\n",
      "      - -194159.34434262905\n",
      "      - -195450.94528737874\n",
      "      - -193146.73193229298\n",
      "      - -194439.18691617638\n",
      "      - -195778.6498121651\n",
      "      - -193656.65280867467\n",
      "      - -194722.06315016976\n",
      "      - -194777.24406423184\n",
      "      - -192336.49560862177\n",
      "      - -195859.709120048\n",
      "      - -195032.5669442774\n",
      "      - -196171.62247047786\n",
      "      - -194229.2911534713\n",
      "      - -195994.90627020443\n",
      "      - -194447.74610483414\n",
      "      - -195616.35946328827\n",
      "      - -196023.10477737055\n",
      "      - -196815.29299318616\n",
      "      - -194025.40852686844\n",
      "      - -192989.81615676967\n",
      "      - -195742.66519801613\n",
      "      - -196373.93442540048\n",
      "      - -194913.22196531537\n",
      "      - -196014.338203655\n",
      "      - -193812.93494228556\n",
      "      - -195189.15638496392\n",
      "      - -199193.99489665977\n",
      "      - -196653.9256338681\n",
      "      - -195080.31178352458\n",
      "      - -194217.17829480252\n",
      "      - -195376.77608434245\n",
      "      - -195892.47701977327\n",
      "      - -195124.3769911674\n",
      "      - -193964.5429211347\n",
      "      - -195291.1683379405\n",
      "      - -195562.91729799888\n",
      "      - -195479.71289999655\n",
      "      - -195212.16086435015\n",
      "      - -194928.46867864448\n",
      "      - -192605.93416427608\n",
      "      - -194978.66764326193\n",
      "      - -197680.1518757288\n",
      "      - -194646.5171022199\n",
      "      - -193503.3342609794\n",
      "      - -193610.2532062934\n",
      "      - -194957.97187336558\n",
      "      - -193461.56954218962\n",
      "      - -196864.27029413264\n",
      "      - -192528.56300078044\n",
      "      - -194221.44384694583\n",
      "      - -193672.96940734255\n",
      "      - -193985.9838590687\n",
      "      - -196225.36727011998\n",
      "      - -194801.42077773582\n",
      "      - -196486.06065275279\n",
      "      - -194911.2618070951\n",
      "      - -193533.3709747117\n",
      "      - -193572.21268825192\n",
      "      - -194196.28539987147\n",
      "      - -195073.13253102137\n",
      "      - -194693.12304197814\n",
      "      - -193350.5569191275\n",
      "      - -195323.56523398787\n",
      "      - -195469.17664121586\n",
      "      - -195572.06396808292\n",
      "      - -196417.20923155465\n",
      "      - -193033.90100413517\n",
      "      - -196123.67591311337\n",
      "      - -195134.1191087432\n",
      "      - -196777.35089796787\n",
      "      - -192584.63682859603\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09413082059490537\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4673158991482211\n",
      "      mean_inference_ms: 0.9691993186585782\n",
      "      mean_raw_obs_processing_ms: 0.13429836633221698\n",
      "  time_since_restore: 1980.7435245513916\n",
      "  time_this_iter_s: 9.251363754272461\n",
      "  time_total_s: 1980.7435245513916\n",
      "  timers:\n",
      "    learn_throughput: 131863.346\n",
      "    learn_time_ms: 485.23\n",
      "    load_throughput: 21749250.124\n",
      "    load_time_ms: 2.942\n",
      "    training_iteration_time_ms: 9612.259\n",
      "    update_time_ms: 4.607\n",
      "  timestamp: 1665850732\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 13244688\n",
      "  training_iteration: 207\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:18:57 (running for 00:33:31.81)<br>Memory usage on this node: 13.6/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   207</td><td style=\"text-align: right;\">         1980.74</td><td style=\"text-align: right;\">13244688</td><td style=\"text-align: right;\"> -194809</td><td style=\"text-align: right;\">             -192074</td><td style=\"text-align: right;\">             -199194</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 13308672\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 13308672\n",
      "    num_agent_steps_trained: 13308672\n",
      "    num_env_steps_sampled: 13308672\n",
      "    num_env_steps_trained: 13308672\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-19-02\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -191758.45154312026\n",
      "  episode_reward_mean: -194875.99233413607\n",
      "  episode_reward_min: -200892.29090575452\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 13308\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1097023487091064\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0010692079085856676\n",
      "          model: {}\n",
      "          policy_loss: -0.0007878641481511295\n",
      "          total_loss: 9.999115943908691\n",
      "          vf_explained_var: -3.595200936956644e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 13308672\n",
      "    num_agent_steps_trained: 13308672\n",
      "    num_env_steps_sampled: 13308672\n",
      "    num_env_steps_trained: 13308672\n",
      "  iterations_since_restore: 208\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 13308672\n",
      "  num_agent_steps_trained: 13308672\n",
      "  num_env_steps_sampled: 13308672\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 13308672\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 87.53999999999999\n",
      "    ram_util_percent: 87.93333333333335\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09415752908649705\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46754804596309996\n",
      "    mean_inference_ms: 0.9692745814959691\n",
      "    mean_raw_obs_processing_ms: 0.1341876504301252\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -191758.45154312026\n",
      "    episode_reward_mean: -194875.99233413607\n",
      "    episode_reward_min: -200892.29090575452\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -193503.3342609794\n",
      "      - -193610.2532062934\n",
      "      - -194957.97187336558\n",
      "      - -193461.56954218962\n",
      "      - -196864.27029413264\n",
      "      - -192528.56300078044\n",
      "      - -194221.44384694583\n",
      "      - -193672.96940734255\n",
      "      - -193985.9838590687\n",
      "      - -196225.36727011998\n",
      "      - -194801.42077773582\n",
      "      - -196486.06065275279\n",
      "      - -194911.2618070951\n",
      "      - -193533.3709747117\n",
      "      - -193572.21268825192\n",
      "      - -194196.28539987147\n",
      "      - -195073.13253102137\n",
      "      - -194693.12304197814\n",
      "      - -193350.5569191275\n",
      "      - -195323.56523398787\n",
      "      - -195469.17664121586\n",
      "      - -195572.06396808292\n",
      "      - -196417.20923155465\n",
      "      - -193033.90100413517\n",
      "      - -196123.67591311337\n",
      "      - -195134.1191087432\n",
      "      - -196777.35089796787\n",
      "      - -192584.63682859603\n",
      "      - -196778.99510545467\n",
      "      - -191758.45154312026\n",
      "      - -195862.3158654965\n",
      "      - -194548.0146356117\n",
      "      - -195159.2424370622\n",
      "      - -199057.88388628274\n",
      "      - -194966.88340451996\n",
      "      - -193132.6536738708\n",
      "      - -193247.8221467309\n",
      "      - -195396.59660897034\n",
      "      - -193017.95193657966\n",
      "      - -195277.50668328468\n",
      "      - -195350.0590614046\n",
      "      - -195096.82935330327\n",
      "      - -198193.7481272994\n",
      "      - -193028.93081519564\n",
      "      - -194220.65672825198\n",
      "      - -198245.07454019279\n",
      "      - -191971.9103473249\n",
      "      - -195896.25474519312\n",
      "      - -196973.8424965236\n",
      "      - -194429.0962017583\n",
      "      - -195600.82327018995\n",
      "      - -195088.6678800456\n",
      "      - -194277.45710331737\n",
      "      - -193059.87098931186\n",
      "      - -193446.53966625448\n",
      "      - -194079.57277954806\n",
      "      - -192954.59207698406\n",
      "      - -193704.08702984257\n",
      "      - -193325.10356663103\n",
      "      - -195722.05981462708\n",
      "      - -193564.80564404876\n",
      "      - -194696.5061631819\n",
      "      - -196533.7344034007\n",
      "      - -193277.86509278367\n",
      "      - -193259.05873481598\n",
      "      - -194082.87145769646\n",
      "      - -200892.29090575452\n",
      "      - -196817.21459353348\n",
      "      - -194897.10014211072\n",
      "      - -195236.19120409424\n",
      "      - -196418.89593850455\n",
      "      - -195859.59289979207\n",
      "      - -194219.6795826142\n",
      "      - -196701.62151330485\n",
      "      - -197904.79550731997\n",
      "      - -195931.22967030763\n",
      "      - -195009.58697018988\n",
      "      - -195428.31679450817\n",
      "      - -194810.71442956864\n",
      "      - -194556.06773012728\n",
      "      - -196973.54622236663\n",
      "      - -194130.30487983229\n",
      "      - -196728.53521914844\n",
      "      - -199502.89464128122\n",
      "      - -196404.76684686527\n",
      "      - -194249.35080147788\n",
      "      - -193821.0552300474\n",
      "      - -193705.02932277825\n",
      "      - -195598.36792940195\n",
      "      - -193694.66932956703\n",
      "      - -193870.92826105034\n",
      "      - -195280.69977093185\n",
      "      - -192249.50421061934\n",
      "      - -191994.92717541667\n",
      "      - -194171.7776834148\n",
      "      - -194867.9807722766\n",
      "      - -193493.4257640537\n",
      "      - -193494.59345424478\n",
      "      - -196303.9578353389\n",
      "      - -194010.43398448784\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09415752908649705\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46754804596309996\n",
      "      mean_inference_ms: 0.9692745814959691\n",
      "      mean_raw_obs_processing_ms: 0.1341876504301252\n",
      "  time_since_restore: 1991.018245458603\n",
      "  time_this_iter_s: 10.274720907211304\n",
      "  time_total_s: 1991.018245458603\n",
      "  timers:\n",
      "    learn_throughput: 136162.423\n",
      "    learn_time_ms: 469.909\n",
      "    load_throughput: 21736038.548\n",
      "    load_time_ms: 2.944\n",
      "    training_iteration_time_ms: 9702.048\n",
      "    update_time_ms: 4.511\n",
      "  timestamp: 1665850742\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 13308672\n",
      "  training_iteration: 208\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:19:02 (running for 00:33:37.13)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   208</td><td style=\"text-align: right;\">         1991.02</td><td style=\"text-align: right;\">13308672</td><td style=\"text-align: right;\"> -194876</td><td style=\"text-align: right;\">             -191758</td><td style=\"text-align: right;\">             -200892</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:19:07 (running for 00:33:42.14)<br>Memory usage on this node: 13.9/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   208</td><td style=\"text-align: right;\">         1991.02</td><td style=\"text-align: right;\">13308672</td><td style=\"text-align: right;\"> -194876</td><td style=\"text-align: right;\">             -191758</td><td style=\"text-align: right;\">             -200892</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:19:13 (running for 00:33:47.59)<br>Memory usage on this node: 14.0/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   208</td><td style=\"text-align: right;\">         1991.02</td><td style=\"text-align: right;\">13308672</td><td style=\"text-align: right;\"> -194876</td><td style=\"text-align: right;\">             -191758</td><td style=\"text-align: right;\">             -200892</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 13372656\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 13372656\n",
      "    num_agent_steps_trained: 13372656\n",
      "    num_env_steps_sampled: 13372656\n",
      "    num_env_steps_trained: 13372656\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-19-13\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -191274.76427217663\n",
      "  episode_reward_mean: -194560.06515234854\n",
      "  episode_reward_min: -200892.29090575452\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 13368\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.115571975708008\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0011492474004626274\n",
      "          model: {}\n",
      "          policy_loss: 0.005654740147292614\n",
      "          total_loss: 10.005571365356445\n",
      "          vf_explained_var: -5.108969602929392e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 13372656\n",
      "    num_agent_steps_trained: 13372656\n",
      "    num_env_steps_sampled: 13372656\n",
      "    num_env_steps_trained: 13372656\n",
      "  iterations_since_restore: 209\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 13372656\n",
      "  num_agent_steps_trained: 13372656\n",
      "  num_env_steps_sampled: 13372656\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 13372656\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 86.06666666666665\n",
      "    ram_util_percent: 90.05333333333331\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09422834296492594\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46768223260340236\n",
      "    mean_inference_ms: 0.9700166563576537\n",
      "    mean_raw_obs_processing_ms: 0.1344048917688147\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -191274.76427217663\n",
      "    episode_reward_mean: -194560.06515234854\n",
      "    episode_reward_min: -200892.29090575452\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -193564.80564404876\n",
      "      - -194696.5061631819\n",
      "      - -196533.7344034007\n",
      "      - -193277.86509278367\n",
      "      - -193259.05873481598\n",
      "      - -194082.87145769646\n",
      "      - -200892.29090575452\n",
      "      - -196817.21459353348\n",
      "      - -194897.10014211072\n",
      "      - -195236.19120409424\n",
      "      - -196418.89593850455\n",
      "      - -195859.59289979207\n",
      "      - -194219.6795826142\n",
      "      - -196701.62151330485\n",
      "      - -197904.79550731997\n",
      "      - -195931.22967030763\n",
      "      - -195009.58697018988\n",
      "      - -195428.31679450817\n",
      "      - -194810.71442956864\n",
      "      - -194556.06773012728\n",
      "      - -196973.54622236663\n",
      "      - -194130.30487983229\n",
      "      - -196728.53521914844\n",
      "      - -199502.89464128122\n",
      "      - -196404.76684686527\n",
      "      - -194249.35080147788\n",
      "      - -193821.0552300474\n",
      "      - -193705.02932277825\n",
      "      - -195598.36792940195\n",
      "      - -193694.66932956703\n",
      "      - -193870.92826105034\n",
      "      - -195280.69977093185\n",
      "      - -192249.50421061934\n",
      "      - -191994.92717541667\n",
      "      - -194171.7776834148\n",
      "      - -194867.9807722766\n",
      "      - -193493.4257640537\n",
      "      - -193494.59345424478\n",
      "      - -196303.9578353389\n",
      "      - -194010.43398448784\n",
      "      - -192420.72789549822\n",
      "      - -194188.42265358605\n",
      "      - -193374.19642417366\n",
      "      - -192873.54206165718\n",
      "      - -193567.93205782562\n",
      "      - -193325.45549370875\n",
      "      - -194100.0638743122\n",
      "      - -194035.51348320802\n",
      "      - -195979.2761450077\n",
      "      - -193569.02072020745\n",
      "      - -194224.37175798687\n",
      "      - -191274.76427217663\n",
      "      - -192819.8705356605\n",
      "      - -193394.96615710887\n",
      "      - -196862.19355241925\n",
      "      - -195547.97685306484\n",
      "      - -196492.82270169762\n",
      "      - -193602.1345218747\n",
      "      - -193935.0021717003\n",
      "      - -193875.22747355828\n",
      "      - -193512.76143643897\n",
      "      - -191648.9661299377\n",
      "      - -192638.34075702805\n",
      "      - -193629.2877359394\n",
      "      - -195422.6218127033\n",
      "      - -194080.4266286524\n",
      "      - -196372.88522848577\n",
      "      - -191579.11845482243\n",
      "      - -195950.04323293205\n",
      "      - -193463.7091517773\n",
      "      - -194922.39211835328\n",
      "      - -191805.24958376455\n",
      "      - -196088.74549212077\n",
      "      - -197066.21099861144\n",
      "      - -192652.74420816102\n",
      "      - -194936.31272573277\n",
      "      - -196141.18175076164\n",
      "      - -193348.00875240372\n",
      "      - -195256.1121588307\n",
      "      - -193779.0248360714\n",
      "      - -195098.88162162135\n",
      "      - -196014.26411424566\n",
      "      - -192858.65364648812\n",
      "      - -193815.09535426297\n",
      "      - -194676.05140665566\n",
      "      - -193499.48516580026\n",
      "      - -196270.20802676637\n",
      "      - -195096.86295713656\n",
      "      - -192856.52525001654\n",
      "      - -192025.6348167598\n",
      "      - -195297.34050331498\n",
      "      - -194610.76998761346\n",
      "      - -194199.02562971748\n",
      "      - -195823.78020669546\n",
      "      - -192661.2332736528\n",
      "      - -193518.89265038786\n",
      "      - -193598.62454303305\n",
      "      - -193615.77186887624\n",
      "      - -194816.1969171188\n",
      "      - -197250.70458246695\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09422834296492594\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46768223260340236\n",
      "      mean_inference_ms: 0.9700166563576537\n",
      "      mean_raw_obs_processing_ms: 0.1344048917688147\n",
      "  time_since_restore: 2001.8453035354614\n",
      "  time_this_iter_s: 10.82705807685852\n",
      "  time_total_s: 2001.8453035354614\n",
      "  timers:\n",
      "    learn_throughput: 136857.472\n",
      "    learn_time_ms: 467.523\n",
      "    load_throughput: 21712649.445\n",
      "    load_time_ms: 2.947\n",
      "    training_iteration_time_ms: 9778.691\n",
      "    update_time_ms: 4.716\n",
      "  timestamp: 1665850753\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 13372656\n",
      "  training_iteration: 209\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:19:18 (running for 00:33:52.77)<br>Memory usage on this node: 14.0/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   209</td><td style=\"text-align: right;\">         2001.85</td><td style=\"text-align: right;\">13372656</td><td style=\"text-align: right;\"> -194560</td><td style=\"text-align: right;\">             -191275</td><td style=\"text-align: right;\">             -200892</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 13436640\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 13436640\n",
      "    num_agent_steps_trained: 13436640\n",
      "    num_env_steps_sampled: 13436640\n",
      "    num_env_steps_trained: 13436640\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-19-23\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -189612.56883172152\n",
      "  episode_reward_mean: -193919.1258087778\n",
      "  episode_reward_min: -197372.98858889667\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 13428\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1090359687805176\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0007096562767401338\n",
      "          model: {}\n",
      "          policy_loss: 0.006337576545774937\n",
      "          total_loss: 10.006168365478516\n",
      "          vf_explained_var: -2.0814320933482122e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 13436640\n",
      "    num_agent_steps_trained: 13436640\n",
      "    num_env_steps_sampled: 13436640\n",
      "    num_env_steps_trained: 13436640\n",
      "  iterations_since_restore: 210\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 13436640\n",
      "  num_agent_steps_trained: 13436640\n",
      "  num_env_steps_sampled: 13436640\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 13436640\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 87.97692307692309\n",
      "    ram_util_percent: 90.55384615384615\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09419383769298566\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46791990691251284\n",
      "    mean_inference_ms: 0.9702287057466674\n",
      "    mean_raw_obs_processing_ms: 0.13441522111829932\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -189612.56883172152\n",
      "    episode_reward_mean: -193919.1258087778\n",
      "    episode_reward_min: -197372.98858889667\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -193512.76143643897\n",
      "      - -191648.9661299377\n",
      "      - -192638.34075702805\n",
      "      - -193629.2877359394\n",
      "      - -195422.6218127033\n",
      "      - -194080.4266286524\n",
      "      - -196372.88522848577\n",
      "      - -191579.11845482243\n",
      "      - -195950.04323293205\n",
      "      - -193463.7091517773\n",
      "      - -194922.39211835328\n",
      "      - -191805.24958376455\n",
      "      - -196088.74549212077\n",
      "      - -197066.21099861144\n",
      "      - -192652.74420816102\n",
      "      - -194936.31272573277\n",
      "      - -196141.18175076164\n",
      "      - -193348.00875240372\n",
      "      - -195256.1121588307\n",
      "      - -193779.0248360714\n",
      "      - -195098.88162162135\n",
      "      - -196014.26411424566\n",
      "      - -192858.65364648812\n",
      "      - -193815.09535426297\n",
      "      - -194676.05140665566\n",
      "      - -193499.48516580026\n",
      "      - -196270.20802676637\n",
      "      - -195096.86295713656\n",
      "      - -192856.52525001654\n",
      "      - -192025.6348167598\n",
      "      - -195297.34050331498\n",
      "      - -194610.76998761346\n",
      "      - -194199.02562971748\n",
      "      - -195823.78020669546\n",
      "      - -192661.2332736528\n",
      "      - -193518.89265038786\n",
      "      - -193598.62454303305\n",
      "      - -193615.77186887624\n",
      "      - -194816.1969171188\n",
      "      - -197250.70458246695\n",
      "      - -192710.94957386292\n",
      "      - -195523.85818236382\n",
      "      - -194177.9876797403\n",
      "      - -193051.425165208\n",
      "      - -192224.00634737764\n",
      "      - -194583.08966245595\n",
      "      - -191444.64763318008\n",
      "      - -193835.74695999853\n",
      "      - -193386.71766731274\n",
      "      - -191875.5426670253\n",
      "      - -195142.7719257194\n",
      "      - -191450.5049549812\n",
      "      - -194233.6126834881\n",
      "      - -193211.44109633798\n",
      "      - -192684.30410296097\n",
      "      - -193979.85257229555\n",
      "      - -195047.50612565133\n",
      "      - -194495.79763093914\n",
      "      - -192501.133743069\n",
      "      - -195164.5299260652\n",
      "      - -195191.64939410295\n",
      "      - -192697.86759949094\n",
      "      - -194818.6564085221\n",
      "      - -192477.67755430168\n",
      "      - -192649.25165987\n",
      "      - -194427.20744554754\n",
      "      - -194689.26441517172\n",
      "      - -195561.47140057213\n",
      "      - -194271.3860637467\n",
      "      - -193461.5015749482\n",
      "      - -194781.92256425426\n",
      "      - -192616.22683749322\n",
      "      - -192338.87661760562\n",
      "      - -189612.56883172152\n",
      "      - -191754.30814087484\n",
      "      - -191794.08216341573\n",
      "      - -197297.81696457576\n",
      "      - -192432.38870424166\n",
      "      - -194146.7492996379\n",
      "      - -191095.93496903914\n",
      "      - -192623.99501415188\n",
      "      - -193006.85192918373\n",
      "      - -193349.16482182007\n",
      "      - -192782.9026173194\n",
      "      - -194444.7777992665\n",
      "      - -194996.0730348644\n",
      "      - -196656.78998745166\n",
      "      - -197372.98858889667\n",
      "      - -195070.66328048953\n",
      "      - -193838.1467676419\n",
      "      - -194937.08291362578\n",
      "      - -192800.85293950725\n",
      "      - -193755.5876187205\n",
      "      - -194318.06477431994\n",
      "      - -194088.76918121622\n",
      "      - -192203.99839387342\n",
      "      - -193401.95792391573\n",
      "      - -194489.8926709151\n",
      "      - -191837.75082961572\n",
      "      - -195195.8891656618\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09419383769298566\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46791990691251284\n",
      "      mean_inference_ms: 0.9702287057466674\n",
      "      mean_raw_obs_processing_ms: 0.13441522111829932\n",
      "  time_since_restore: 2011.4912431240082\n",
      "  time_this_iter_s: 9.645939588546753\n",
      "  time_total_s: 2011.4912431240082\n",
      "  timers:\n",
      "    learn_throughput: 137365.173\n",
      "    learn_time_ms: 465.795\n",
      "    load_throughput: 22200669.005\n",
      "    load_time_ms: 2.882\n",
      "    training_iteration_time_ms: 9813.024\n",
      "    update_time_ms: 4.798\n",
      "  timestamp: 1665850763\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 13436640\n",
      "  training_iteration: 210\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:19:28 (running for 00:34:02.66)<br>Memory usage on this node: 14.0/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   210</td><td style=\"text-align: right;\">         2011.49</td><td style=\"text-align: right;\">13436640</td><td style=\"text-align: right;\"> -193919</td><td style=\"text-align: right;\">             -189613</td><td style=\"text-align: right;\">             -197373</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 13500624\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 13500624\n",
      "    num_agent_steps_trained: 13500624\n",
      "    num_env_steps_sampled: 13500624\n",
      "    num_env_steps_trained: 13500624\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-19-33\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -188959.25968225475\n",
      "  episode_reward_mean: -193384.33150006155\n",
      "  episode_reward_min: -209547.92768035337\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 13500\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1107521057128906\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.001654784195125103\n",
      "          model: {}\n",
      "          policy_loss: -0.0005165744223631918\n",
      "          total_loss: 9.999503135681152\n",
      "          vf_explained_var: -2.932926967957883e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 13500624\n",
      "    num_agent_steps_trained: 13500624\n",
      "    num_env_steps_sampled: 13500624\n",
      "    num_env_steps_trained: 13500624\n",
      "  iterations_since_restore: 211\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 13500624\n",
      "  num_agent_steps_trained: 13500624\n",
      "  num_env_steps_sampled: 13500624\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 13500624\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.7642857142857\n",
      "    ram_util_percent: 90.36428571428571\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09419163184449472\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4679716338522843\n",
      "    mean_inference_ms: 0.9703666437405795\n",
      "    mean_raw_obs_processing_ms: 0.1342367101597065\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -188959.25968225475\n",
      "    episode_reward_mean: -193384.33150006155\n",
      "    episode_reward_min: -209547.92768035337\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -192338.87661760562\n",
      "      - -189612.56883172152\n",
      "      - -191754.30814087484\n",
      "      - -191794.08216341573\n",
      "      - -197297.81696457576\n",
      "      - -192432.38870424166\n",
      "      - -194146.7492996379\n",
      "      - -191095.93496903914\n",
      "      - -192623.99501415188\n",
      "      - -193006.85192918373\n",
      "      - -193349.16482182007\n",
      "      - -192782.9026173194\n",
      "      - -194444.7777992665\n",
      "      - -194996.0730348644\n",
      "      - -196656.78998745166\n",
      "      - -197372.98858889667\n",
      "      - -195070.66328048953\n",
      "      - -193838.1467676419\n",
      "      - -194937.08291362578\n",
      "      - -192800.85293950725\n",
      "      - -193755.5876187205\n",
      "      - -194318.06477431994\n",
      "      - -194088.76918121622\n",
      "      - -192203.99839387342\n",
      "      - -193401.95792391573\n",
      "      - -194489.8926709151\n",
      "      - -191837.75082961572\n",
      "      - -195195.8891656618\n",
      "      - -192797.99474487113\n",
      "      - -191278.29238129544\n",
      "      - -192423.40857777448\n",
      "      - -191920.51864076196\n",
      "      - -191686.62373737438\n",
      "      - -192022.74950001115\n",
      "      - -190836.28045933385\n",
      "      - -195056.13340757912\n",
      "      - -195841.33335097446\n",
      "      - -192764.76019417436\n",
      "      - -193179.68108057935\n",
      "      - -194660.5068505166\n",
      "      - -194023.333340869\n",
      "      - -192661.6579725474\n",
      "      - -194613.92841059956\n",
      "      - -193257.47729640108\n",
      "      - -191785.12496116754\n",
      "      - -193133.3412667907\n",
      "      - -194785.09274992763\n",
      "      - -190813.08311745746\n",
      "      - -191639.02177396664\n",
      "      - -192884.3053443545\n",
      "      - -191173.40875589222\n",
      "      - -193195.31906512118\n",
      "      - -193508.35172715702\n",
      "      - -192942.62192058295\n",
      "      - -195573.22420693404\n",
      "      - -193032.37790193755\n",
      "      - -192724.20530726275\n",
      "      - -194460.33315976846\n",
      "      - -192177.21002040213\n",
      "      - -193615.3694475922\n",
      "      - -192976.0576414997\n",
      "      - -191960.76914373314\n",
      "      - -192404.70521751908\n",
      "      - -191925.07965848496\n",
      "      - -191282.9071809478\n",
      "      - -192088.12735445664\n",
      "      - -191124.65378631864\n",
      "      - -195138.08328818725\n",
      "      - -191668.7814846627\n",
      "      - -191406.47039448994\n",
      "      - -191699.91202676698\n",
      "      - -193475.11544561293\n",
      "      - -191641.84035096294\n",
      "      - -194194.46460557726\n",
      "      - -197298.09364846296\n",
      "      - -194937.60548732846\n",
      "      - -190787.70779145247\n",
      "      - -195014.86187201695\n",
      "      - -190201.62838940253\n",
      "      - -192727.99452185366\n",
      "      - -191141.27992005073\n",
      "      - -188959.25968225475\n",
      "      - -191886.60954450467\n",
      "      - -194466.83788151786\n",
      "      - -191405.85246887666\n",
      "      - -191075.63655031464\n",
      "      - -209547.92768035337\n",
      "      - -193251.2830716504\n",
      "      - -194320.89220947036\n",
      "      - -193379.63805813793\n",
      "      - -194377.6038376787\n",
      "      - -193815.78570866643\n",
      "      - -200482.73321723434\n",
      "      - -198057.59769799295\n",
      "      - -192484.64144152656\n",
      "      - -193748.43839997554\n",
      "      - -193688.78756815425\n",
      "      - -194415.38172567586\n",
      "      - -193950.97326820818\n",
      "      - -191909.13416862432\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09419163184449472\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4679716338522843\n",
      "      mean_inference_ms: 0.9703666437405795\n",
      "      mean_raw_obs_processing_ms: 0.1342367101597065\n",
      "  time_since_restore: 2021.5072948932648\n",
      "  time_this_iter_s: 10.016051769256592\n",
      "  time_total_s: 2021.5072948932648\n",
      "  timers:\n",
      "    learn_throughput: 137144.941\n",
      "    learn_time_ms: 466.543\n",
      "    load_throughput: 22381561.151\n",
      "    load_time_ms: 2.859\n",
      "    training_iteration_time_ms: 9878.67\n",
      "    update_time_ms: 4.883\n",
      "  timestamp: 1665850773\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 13500624\n",
      "  training_iteration: 211\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:19:38 (running for 00:34:12.51)<br>Memory usage on this node: 14.0/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   211</td><td style=\"text-align: right;\">         2021.51</td><td style=\"text-align: right;\">13500624</td><td style=\"text-align: right;\"> -193384</td><td style=\"text-align: right;\">             -188959</td><td style=\"text-align: right;\">             -209548</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 13564608\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 13564608\n",
      "    num_agent_steps_trained: 13564608\n",
      "    num_env_steps_sampled: 13564608\n",
      "    num_env_steps_trained: 13564608\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-19-42\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -188959.25968225475\n",
      "  episode_reward_mean: -193107.44597237566\n",
      "  episode_reward_min: -209547.92768035337\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 13560\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1143884658813477\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0005735938320867717\n",
      "          model: {}\n",
      "          policy_loss: 0.0056685153394937515\n",
      "          total_loss: 10.005472183227539\n",
      "          vf_explained_var: -5.298190686175985e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 13564608\n",
      "    num_agent_steps_trained: 13564608\n",
      "    num_env_steps_sampled: 13564608\n",
      "    num_env_steps_trained: 13564608\n",
      "  iterations_since_restore: 212\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 13564608\n",
      "  num_agent_steps_trained: 13564608\n",
      "  num_env_steps_sampled: 13564608\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 13564608\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 80.00714285714285\n",
      "    ram_util_percent: 90.09285714285713\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09421752272562983\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46787791277429397\n",
      "    mean_inference_ms: 0.9705418722705135\n",
      "    mean_raw_obs_processing_ms: 0.13445769573352276\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -188959.25968225475\n",
      "    episode_reward_mean: -193107.44597237566\n",
      "    episode_reward_min: -209547.92768035337\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -192976.0576414997\n",
      "      - -191960.76914373314\n",
      "      - -192404.70521751908\n",
      "      - -191925.07965848496\n",
      "      - -191282.9071809478\n",
      "      - -192088.12735445664\n",
      "      - -191124.65378631864\n",
      "      - -195138.08328818725\n",
      "      - -191668.7814846627\n",
      "      - -191406.47039448994\n",
      "      - -191699.91202676698\n",
      "      - -193475.11544561293\n",
      "      - -191641.84035096294\n",
      "      - -194194.46460557726\n",
      "      - -197298.09364846296\n",
      "      - -194937.60548732846\n",
      "      - -190787.70779145247\n",
      "      - -195014.86187201695\n",
      "      - -190201.62838940253\n",
      "      - -192727.99452185366\n",
      "      - -191141.27992005073\n",
      "      - -188959.25968225475\n",
      "      - -191886.60954450467\n",
      "      - -194466.83788151786\n",
      "      - -191405.85246887666\n",
      "      - -191075.63655031464\n",
      "      - -209547.92768035337\n",
      "      - -193251.2830716504\n",
      "      - -194320.89220947036\n",
      "      - -193379.63805813793\n",
      "      - -194377.6038376787\n",
      "      - -193815.78570866643\n",
      "      - -200482.73321723434\n",
      "      - -198057.59769799295\n",
      "      - -192484.64144152656\n",
      "      - -193748.43839997554\n",
      "      - -193688.78756815425\n",
      "      - -194415.38172567586\n",
      "      - -193950.97326820818\n",
      "      - -191909.13416862432\n",
      "      - -193698.38382469915\n",
      "      - -194857.35969677323\n",
      "      - -195173.37780347245\n",
      "      - -192185.63937712854\n",
      "      - -192633.44384909378\n",
      "      - -191394.13462757584\n",
      "      - -191944.65112945758\n",
      "      - -193013.49484201235\n",
      "      - -190591.92912571848\n",
      "      - -195199.15128110108\n",
      "      - -196209.23432145518\n",
      "      - -192482.09360049837\n",
      "      - -193078.2722660896\n",
      "      - -192675.20405607315\n",
      "      - -190982.4685228522\n",
      "      - -192532.86365946\n",
      "      - -197942.54443865598\n",
      "      - -191770.76194890033\n",
      "      - -194336.7314685082\n",
      "      - -191534.48405792273\n",
      "      - -189843.93153707555\n",
      "      - -190417.38745366942\n",
      "      - -193369.55697557205\n",
      "      - -192792.81438603238\n",
      "      - -191964.18028633329\n",
      "      - -189505.20723946433\n",
      "      - -195275.05298159667\n",
      "      - -193752.65709672784\n",
      "      - -192570.29035466982\n",
      "      - -192453.39059431307\n",
      "      - -193185.33091776172\n",
      "      - -192130.47667968343\n",
      "      - -196847.50877901362\n",
      "      - -192272.31141835471\n",
      "      - -192947.09837585548\n",
      "      - -190810.86759003016\n",
      "      - -191989.01420464247\n",
      "      - -191013.60330486583\n",
      "      - -189778.1913696332\n",
      "      - -190874.4893835662\n",
      "      - -193564.1928670626\n",
      "      - -192430.4582287836\n",
      "      - -194723.0697752014\n",
      "      - -191043.9425100865\n",
      "      - -194084.9689346947\n",
      "      - -193527.9263902232\n",
      "      - -191687.9649675981\n",
      "      - -191572.9793873917\n",
      "      - -190852.85268188932\n",
      "      - -193387.00265792935\n",
      "      - -193049.73771247215\n",
      "      - -192525.10106281805\n",
      "      - -197306.0601081914\n",
      "      - -193272.01162248562\n",
      "      - -189817.96401691964\n",
      "      - -196022.09812098581\n",
      "      - -192511.15889851618\n",
      "      - -194112.19679905075\n",
      "      - -193596.70667114801\n",
      "      - -193305.4656072009\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09421752272562983\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46787791277429397\n",
      "      mean_inference_ms: 0.9705418722705135\n",
      "      mean_raw_obs_processing_ms: 0.13445769573352276\n",
      "  time_since_restore: 2030.9689292907715\n",
      "  time_this_iter_s: 9.461634397506714\n",
      "  time_total_s: 2030.9689292907715\n",
      "  timers:\n",
      "    learn_throughput: 136043.087\n",
      "    learn_time_ms: 470.322\n",
      "    load_throughput: 22430947.923\n",
      "    load_time_ms: 2.852\n",
      "    training_iteration_time_ms: 9894.929\n",
      "    update_time_ms: 4.781\n",
      "  timestamp: 1665850782\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 13564608\n",
      "  training_iteration: 212\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:19:47 (running for 00:34:22.22)<br>Memory usage on this node: 13.7/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   212</td><td style=\"text-align: right;\">         2030.97</td><td style=\"text-align: right;\">13564608</td><td style=\"text-align: right;\"> -193107</td><td style=\"text-align: right;\">             -188959</td><td style=\"text-align: right;\">             -209548</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:19:52 (running for 00:34:27.24)<br>Memory usage on this node: 13.7/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   212</td><td style=\"text-align: right;\">         2030.97</td><td style=\"text-align: right;\">13564608</td><td style=\"text-align: right;\"> -193107</td><td style=\"text-align: right;\">             -188959</td><td style=\"text-align: right;\">             -209548</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 13628592\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 13628592\n",
      "    num_agent_steps_trained: 13628592\n",
      "    num_env_steps_sampled: 13628592\n",
      "    num_env_steps_trained: 13628592\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-19-53\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -189505.20723946433\n",
      "  episode_reward_mean: -192800.05024884464\n",
      "  episode_reward_min: -198132.63542563716\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 13620\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.112642765045166\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0009246742120012641\n",
      "          model: {}\n",
      "          policy_loss: 0.006743175443261862\n",
      "          total_loss: 10.006616592407227\n",
      "          vf_explained_var: -2.0814320933482122e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 13628592\n",
      "    num_agent_steps_trained: 13628592\n",
      "    num_env_steps_sampled: 13628592\n",
      "    num_env_steps_trained: 13628592\n",
      "  iterations_since_restore: 213\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 13628592\n",
      "  num_agent_steps_trained: 13628592\n",
      "  num_env_steps_sampled: 13628592\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 13628592\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 91.50000000000001\n",
      "    ram_util_percent: 88.62142857142858\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09420122805361969\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46801535872243155\n",
      "    mean_inference_ms: 0.9708958841331322\n",
      "    mean_raw_obs_processing_ms: 0.1345098753979304\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -189505.20723946433\n",
      "    episode_reward_mean: -192800.05024884464\n",
      "    episode_reward_min: -198132.63542563716\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -189843.93153707555\n",
      "      - -190417.38745366942\n",
      "      - -193369.55697557205\n",
      "      - -192792.81438603238\n",
      "      - -191964.18028633329\n",
      "      - -189505.20723946433\n",
      "      - -195275.05298159667\n",
      "      - -193752.65709672784\n",
      "      - -192570.29035466982\n",
      "      - -192453.39059431307\n",
      "      - -193185.33091776172\n",
      "      - -192130.47667968343\n",
      "      - -196847.50877901362\n",
      "      - -192272.31141835471\n",
      "      - -192947.09837585548\n",
      "      - -190810.86759003016\n",
      "      - -191989.01420464247\n",
      "      - -191013.60330486583\n",
      "      - -189778.1913696332\n",
      "      - -190874.4893835662\n",
      "      - -193564.1928670626\n",
      "      - -192430.4582287836\n",
      "      - -194723.0697752014\n",
      "      - -191043.9425100865\n",
      "      - -194084.9689346947\n",
      "      - -193527.9263902232\n",
      "      - -191687.9649675981\n",
      "      - -191572.9793873917\n",
      "      - -190852.85268188932\n",
      "      - -193387.00265792935\n",
      "      - -193049.73771247215\n",
      "      - -192525.10106281805\n",
      "      - -197306.0601081914\n",
      "      - -193272.01162248562\n",
      "      - -189817.96401691964\n",
      "      - -196022.09812098581\n",
      "      - -192511.15889851618\n",
      "      - -194112.19679905075\n",
      "      - -193596.70667114801\n",
      "      - -193305.4656072009\n",
      "      - -193699.05132222088\n",
      "      - -192349.2328230264\n",
      "      - -193518.5330766724\n",
      "      - -190426.10248889797\n",
      "      - -196893.13012365613\n",
      "      - -193437.35871251673\n",
      "      - -190560.9971850539\n",
      "      - -198132.63542563716\n",
      "      - -194877.6929326227\n",
      "      - -195564.36999374442\n",
      "      - -192322.99615527954\n",
      "      - -191364.09288291426\n",
      "      - -192386.9209984565\n",
      "      - -192003.33988867493\n",
      "      - -194039.64045509772\n",
      "      - -191691.3608864127\n",
      "      - -193541.2987055835\n",
      "      - -191883.7256660618\n",
      "      - -193384.12359381953\n",
      "      - -193314.41658393395\n",
      "      - -193155.35453250198\n",
      "      - -192706.99676292384\n",
      "      - -192705.73381591993\n",
      "      - -192415.06130765527\n",
      "      - -190189.98857564272\n",
      "      - -193189.69315285998\n",
      "      - -190354.49163169102\n",
      "      - -193716.60053735875\n",
      "      - -193513.95958269908\n",
      "      - -193065.0763942467\n",
      "      - -191531.40718083532\n",
      "      - -191675.90243254663\n",
      "      - -190696.61515981163\n",
      "      - -195928.13615056526\n",
      "      - -192904.71448114022\n",
      "      - -195582.11414419246\n",
      "      - -192616.20887400294\n",
      "      - -193888.04175539652\n",
      "      - -192064.7981031082\n",
      "      - -191664.96292887183\n",
      "      - -194337.23218913263\n",
      "      - -191959.82726956953\n",
      "      - -190276.4687105135\n",
      "      - -191827.49729177082\n",
      "      - -191347.6118333155\n",
      "      - -193096.38656813535\n",
      "      - -192247.52893849148\n",
      "      - -195612.66723164215\n",
      "      - -191143.88378175758\n",
      "      - -191213.53662929076\n",
      "      - -194381.25952479194\n",
      "      - -195126.0281389541\n",
      "      - -192453.61529263237\n",
      "      - -191754.09762808873\n",
      "      - -191111.08246205281\n",
      "      - -194619.03358614925\n",
      "      - -191966.950367392\n",
      "      - -194321.77848843843\n",
      "      - -192649.70433198268\n",
      "      - -193414.73726659783\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09420122805361969\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46801535872243155\n",
      "      mean_inference_ms: 0.9708958841331322\n",
      "      mean_raw_obs_processing_ms: 0.1345098753979304\n",
      "  time_since_restore: 2041.7264614105225\n",
      "  time_this_iter_s: 10.757532119750977\n",
      "  time_total_s: 2041.7264614105225\n",
      "  timers:\n",
      "    learn_throughput: 136311.152\n",
      "    learn_time_ms: 469.397\n",
      "    load_throughput: 22662800.177\n",
      "    load_time_ms: 2.823\n",
      "    training_iteration_time_ms: 9997.981\n",
      "    update_time_ms: 4.667\n",
      "  timestamp: 1665850793\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 13628592\n",
      "  training_iteration: 213\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:19:58 (running for 00:34:32.79)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   213</td><td style=\"text-align: right;\">         2041.73</td><td style=\"text-align: right;\">13628592</td><td style=\"text-align: right;\"> -192800</td><td style=\"text-align: right;\">             -189505</td><td style=\"text-align: right;\">             -198133</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 13692576\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 13692576\n",
      "    num_agent_steps_trained: 13692576\n",
      "    num_env_steps_sampled: 13692576\n",
      "    num_env_steps_trained: 13692576\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-20-02\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -189812.10295323376\n",
      "  episode_reward_mean: -192992.14647656822\n",
      "  episode_reward_min: -199423.32466750185\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 13692\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1160712242126465\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0012184720253571868\n",
      "          model: {}\n",
      "          policy_loss: -0.0009212022996507585\n",
      "          total_loss: 9.999011993408203\n",
      "          vf_explained_var: -3.311369312086754e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 13692576\n",
      "    num_agent_steps_trained: 13692576\n",
      "    num_env_steps_sampled: 13692576\n",
      "    num_env_steps_trained: 13692576\n",
      "  iterations_since_restore: 214\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 13692576\n",
      "  num_agent_steps_trained: 13692576\n",
      "  num_env_steps_sampled: 13692576\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 13692576\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 80.0642857142857\n",
      "    ram_util_percent: 88.88571428571431\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09421094515022661\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4680087438892121\n",
      "    mean_inference_ms: 0.9710835160619627\n",
      "    mean_raw_obs_processing_ms: 0.1343419631820229\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -189812.10295323376\n",
      "    episode_reward_mean: -192992.14647656822\n",
      "    episode_reward_min: -199423.32466750185\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -190696.61515981163\n",
      "      - -195928.13615056526\n",
      "      - -192904.71448114022\n",
      "      - -195582.11414419246\n",
      "      - -192616.20887400294\n",
      "      - -193888.04175539652\n",
      "      - -192064.7981031082\n",
      "      - -191664.96292887183\n",
      "      - -194337.23218913263\n",
      "      - -191959.82726956953\n",
      "      - -190276.4687105135\n",
      "      - -191827.49729177082\n",
      "      - -191347.6118333155\n",
      "      - -193096.38656813535\n",
      "      - -192247.52893849148\n",
      "      - -195612.66723164215\n",
      "      - -191143.88378175758\n",
      "      - -191213.53662929076\n",
      "      - -194381.25952479194\n",
      "      - -195126.0281389541\n",
      "      - -192453.61529263237\n",
      "      - -191754.09762808873\n",
      "      - -191111.08246205281\n",
      "      - -194619.03358614925\n",
      "      - -191966.950367392\n",
      "      - -194321.77848843843\n",
      "      - -192649.70433198268\n",
      "      - -193414.73726659783\n",
      "      - -192943.51315804836\n",
      "      - -192189.3310263922\n",
      "      - -194723.5639246605\n",
      "      - -192898.5216167753\n",
      "      - -194832.3897007738\n",
      "      - -194134.0796334546\n",
      "      - -191718.92889923253\n",
      "      - -189812.10295323376\n",
      "      - -192339.11862657682\n",
      "      - -193605.39083641372\n",
      "      - -193905.28310122347\n",
      "      - -191138.74172089418\n",
      "      - -190585.4086112536\n",
      "      - -196773.62170299335\n",
      "      - -193212.7713029395\n",
      "      - -193395.4273020677\n",
      "      - -192698.7295687929\n",
      "      - -192722.57405611206\n",
      "      - -195122.7492385652\n",
      "      - -191940.85516928986\n",
      "      - -194913.65238700437\n",
      "      - -190618.54297162857\n",
      "      - -194652.32429034755\n",
      "      - -193808.59088827326\n",
      "      - -199423.32466750185\n",
      "      - -194485.36456731104\n",
      "      - -195989.9119319057\n",
      "      - -191722.54319589902\n",
      "      - -194926.41549805942\n",
      "      - -193987.90801473678\n",
      "      - -192388.063621745\n",
      "      - -191909.91832707642\n",
      "      - -192365.35710560993\n",
      "      - -196378.2558667688\n",
      "      - -191734.7333926572\n",
      "      - -195468.17625014932\n",
      "      - -193823.0883067977\n",
      "      - -192011.03285358357\n",
      "      - -190106.6982004377\n",
      "      - -192378.7900085954\n",
      "      - -191910.68363418648\n",
      "      - -191537.0107106025\n",
      "      - -191454.93589678995\n",
      "      - -193340.6083302658\n",
      "      - -196412.4040902111\n",
      "      - -191770.10932346323\n",
      "      - -191397.6877699483\n",
      "      - -194260.77885930127\n",
      "      - -192249.5233275829\n",
      "      - -191706.5729975943\n",
      "      - -191546.1373462315\n",
      "      - -194076.48619589867\n",
      "      - -191362.2683927756\n",
      "      - -191999.32672513073\n",
      "      - -193072.02561778188\n",
      "      - -193194.08501887938\n",
      "      - -191636.07652400812\n",
      "      - -190198.42090591224\n",
      "      - -194273.38268611004\n",
      "      - -193775.03893545317\n",
      "      - -194313.38626490557\n",
      "      - -194039.6525768138\n",
      "      - -192534.9121490312\n",
      "      - -191661.93341447753\n",
      "      - -193218.69422344523\n",
      "      - -189981.04526945626\n",
      "      - -192348.6151401986\n",
      "      - -193803.26734650516\n",
      "      - -192637.17414487829\n",
      "      - -192552.84314948198\n",
      "      - -195343.91080815863\n",
      "      - -191613.33625776655\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09421094515022661\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4680087438892121\n",
      "      mean_inference_ms: 0.9710835160619627\n",
      "      mean_raw_obs_processing_ms: 0.1343419631820229\n",
      "  time_since_restore: 2051.085078716278\n",
      "  time_this_iter_s: 9.358617305755615\n",
      "  time_total_s: 2051.085078716278\n",
      "  timers:\n",
      "    learn_throughput: 136834.005\n",
      "    learn_time_ms: 467.603\n",
      "    load_throughput: 22221809.348\n",
      "    load_time_ms: 2.879\n",
      "    training_iteration_time_ms: 9989.486\n",
      "    update_time_ms: 4.498\n",
      "  timestamp: 1665850802\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 13692576\n",
      "  training_iteration: 214\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:20:07 (running for 00:34:42.39)<br>Memory usage on this node: 13.7/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   214</td><td style=\"text-align: right;\">         2051.09</td><td style=\"text-align: right;\">13692576</td><td style=\"text-align: right;\"> -192992</td><td style=\"text-align: right;\">             -189812</td><td style=\"text-align: right;\">             -199423</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 13756560\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 13756560\n",
      "    num_agent_steps_trained: 13756560\n",
      "    num_env_steps_sampled: 13756560\n",
      "    num_env_steps_trained: 13756560\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-20-11\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -189981.04526945626\n",
      "  episode_reward_mean: -192813.1057113224\n",
      "  episode_reward_min: -196412.4040902111\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 13752\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1162869930267334\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0005849587614648044\n",
      "          model: {}\n",
      "          policy_loss: 0.0063365246169269085\n",
      "          total_loss: 10.006143569946289\n",
      "          vf_explained_var: -4.730527525254047e-09\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 13756560\n",
      "    num_agent_steps_trained: 13756560\n",
      "    num_env_steps_sampled: 13756560\n",
      "    num_env_steps_trained: 13756560\n",
      "  iterations_since_restore: 215\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 13756560\n",
      "  num_agent_steps_trained: 13756560\n",
      "  num_env_steps_sampled: 13756560\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 13756560\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.39166666666667\n",
      "    ram_util_percent: 88.84166666666665\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09422005030345736\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46783652037591444\n",
      "    mean_inference_ms: 0.9708640426439268\n",
      "    mean_raw_obs_processing_ms: 0.1344874243922496\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -189981.04526945626\n",
      "    episode_reward_mean: -192813.1057113224\n",
      "    episode_reward_min: -196412.4040902111\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -192365.35710560993\n",
      "      - -196378.2558667688\n",
      "      - -191734.7333926572\n",
      "      - -195468.17625014932\n",
      "      - -193823.0883067977\n",
      "      - -192011.03285358357\n",
      "      - -190106.6982004377\n",
      "      - -192378.7900085954\n",
      "      - -191910.68363418648\n",
      "      - -191537.0107106025\n",
      "      - -191454.93589678995\n",
      "      - -193340.6083302658\n",
      "      - -196412.4040902111\n",
      "      - -191770.10932346323\n",
      "      - -191397.6877699483\n",
      "      - -194260.77885930127\n",
      "      - -192249.5233275829\n",
      "      - -191706.5729975943\n",
      "      - -191546.1373462315\n",
      "      - -194076.48619589867\n",
      "      - -191362.2683927756\n",
      "      - -191999.32672513073\n",
      "      - -193072.02561778188\n",
      "      - -193194.08501887938\n",
      "      - -191636.07652400812\n",
      "      - -190198.42090591224\n",
      "      - -194273.38268611004\n",
      "      - -193775.03893545317\n",
      "      - -194313.38626490557\n",
      "      - -194039.6525768138\n",
      "      - -192534.9121490312\n",
      "      - -191661.93341447753\n",
      "      - -193218.69422344523\n",
      "      - -189981.04526945626\n",
      "      - -192348.6151401986\n",
      "      - -193803.26734650516\n",
      "      - -192637.17414487829\n",
      "      - -192552.84314948198\n",
      "      - -195343.91080815863\n",
      "      - -191613.33625776655\n",
      "      - -191960.65387768252\n",
      "      - -193105.99558206965\n",
      "      - -192784.19827918053\n",
      "      - -195116.92965305856\n",
      "      - -194619.75734640192\n",
      "      - -193900.17088106455\n",
      "      - -192379.14779543557\n",
      "      - -191015.21025367413\n",
      "      - -191277.49977808038\n",
      "      - -194494.36137449899\n",
      "      - -191220.64508396763\n",
      "      - -191646.3685064775\n",
      "      - -195904.44419159318\n",
      "      - -192852.08622431933\n",
      "      - -194345.47420384083\n",
      "      - -193280.60733897222\n",
      "      - -195429.40337732184\n",
      "      - -191728.03867755612\n",
      "      - -190351.79066155662\n",
      "      - -194507.66482408752\n",
      "      - -192845.19760411337\n",
      "      - -194575.55982786126\n",
      "      - -193162.95843937373\n",
      "      - -190602.34518145403\n",
      "      - -191399.41075514906\n",
      "      - -194260.98587984784\n",
      "      - -193318.88658033955\n",
      "      - -192647.65775380842\n",
      "      - -192735.39286209835\n",
      "      - -192256.85725028333\n",
      "      - -191267.5371543101\n",
      "      - -193334.858688963\n",
      "      - -191081.75593399073\n",
      "      - -190081.52132532606\n",
      "      - -192277.2652321612\n",
      "      - -194001.9069011524\n",
      "      - -192507.92745708395\n",
      "      - -193461.02468010003\n",
      "      - -193295.8321633425\n",
      "      - -190298.25684045252\n",
      "      - -191913.17042016238\n",
      "      - -192612.44271605933\n",
      "      - -193506.0205147831\n",
      "      - -191602.1935921976\n",
      "      - -192405.59295852366\n",
      "      - -194890.64258537855\n",
      "      - -193391.14520891837\n",
      "      - -192072.12886146482\n",
      "      - -193448.10506377925\n",
      "      - -194166.4037318355\n",
      "      - -192749.49807950502\n",
      "      - -193929.22473216755\n",
      "      - -195930.83280592598\n",
      "      - -194035.88984584092\n",
      "      - -192603.26036516167\n",
      "      - -192164.44038877322\n",
      "      - -190764.2607753016\n",
      "      - -193429.05691457566\n",
      "      - -191760.66396535203\n",
      "      - -193113.54516663626\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09422005030345736\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46783652037591444\n",
      "      mean_inference_ms: 0.9708640426439268\n",
      "      mean_raw_obs_processing_ms: 0.1344874243922496\n",
      "  time_since_restore: 2059.7677743434906\n",
      "  time_this_iter_s: 8.682695627212524\n",
      "  time_total_s: 2059.7677743434906\n",
      "  timers:\n",
      "    learn_throughput: 136459.86\n",
      "    learn_time_ms: 468.885\n",
      "    load_throughput: 22355645.561\n",
      "    load_time_ms: 2.862\n",
      "    training_iteration_time_ms: 9820.406\n",
      "    update_time_ms: 4.426\n",
      "  timestamp: 1665850811\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 13756560\n",
      "  training_iteration: 215\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:20:16 (running for 00:34:51.23)<br>Memory usage on this node: 13.7/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   215</td><td style=\"text-align: right;\">         2059.77</td><td style=\"text-align: right;\">13756560</td><td style=\"text-align: right;\"> -192813</td><td style=\"text-align: right;\">             -189981</td><td style=\"text-align: right;\">             -196412</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 13820544\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 13820544\n",
      "    num_agent_steps_trained: 13820544\n",
      "    num_env_steps_sampled: 13820544\n",
      "    num_env_steps_trained: 13820544\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-20-20\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -190066.88790774657\n",
      "  episode_reward_mean: -192721.9346567685\n",
      "  episode_reward_min: -196279.73461513923\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 13812\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1158719062805176\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00031377977575175464\n",
      "          model: {}\n",
      "          policy_loss: 0.006389504764229059\n",
      "          total_loss: 10.00614070892334\n",
      "          vf_explained_var: -2.4598742598413992e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 13820544\n",
      "    num_agent_steps_trained: 13820544\n",
      "    num_env_steps_sampled: 13820544\n",
      "    num_env_steps_trained: 13820544\n",
      "  iterations_since_restore: 216\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 13820544\n",
      "  num_agent_steps_trained: 13820544\n",
      "  num_env_steps_sampled: 13820544\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 13820544\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 78.77142857142857\n",
      "    ram_util_percent: 88.76428571428572\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09415418964062158\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4678632548593771\n",
      "    mean_inference_ms: 0.9704306348985429\n",
      "    mean_raw_obs_processing_ms: 0.13448041608725272\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -190066.88790774657\n",
      "    episode_reward_mean: -192721.9346567685\n",
      "    episode_reward_min: -196279.73461513923\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -192845.19760411337\n",
      "      - -194575.55982786126\n",
      "      - -193162.95843937373\n",
      "      - -190602.34518145403\n",
      "      - -191399.41075514906\n",
      "      - -194260.98587984784\n",
      "      - -193318.88658033955\n",
      "      - -192647.65775380842\n",
      "      - -192735.39286209835\n",
      "      - -192256.85725028333\n",
      "      - -191267.5371543101\n",
      "      - -193334.858688963\n",
      "      - -191081.75593399073\n",
      "      - -190081.52132532606\n",
      "      - -192277.2652321612\n",
      "      - -194001.9069011524\n",
      "      - -192507.92745708395\n",
      "      - -193461.02468010003\n",
      "      - -193295.8321633425\n",
      "      - -190298.25684045252\n",
      "      - -191913.17042016238\n",
      "      - -192612.44271605933\n",
      "      - -193506.0205147831\n",
      "      - -191602.1935921976\n",
      "      - -192405.59295852366\n",
      "      - -194890.64258537855\n",
      "      - -193391.14520891837\n",
      "      - -192072.12886146482\n",
      "      - -193448.10506377925\n",
      "      - -194166.4037318355\n",
      "      - -192749.49807950502\n",
      "      - -193929.22473216755\n",
      "      - -195930.83280592598\n",
      "      - -194035.88984584092\n",
      "      - -192603.26036516167\n",
      "      - -192164.44038877322\n",
      "      - -190764.2607753016\n",
      "      - -193429.05691457566\n",
      "      - -191760.66396535203\n",
      "      - -193113.54516663626\n",
      "      - -190471.7346541504\n",
      "      - -192812.96633585496\n",
      "      - -192256.4025100815\n",
      "      - -192043.44941776278\n",
      "      - -193755.0420670651\n",
      "      - -195067.5743138458\n",
      "      - -192613.05483619188\n",
      "      - -192036.36887899254\n",
      "      - -194430.38017499208\n",
      "      - -191477.38021968637\n",
      "      - -194772.6753345191\n",
      "      - -193966.78130395024\n",
      "      - -192220.18171594242\n",
      "      - -195556.11771235577\n",
      "      - -191265.09452621298\n",
      "      - -192520.32546317801\n",
      "      - -190655.8814271813\n",
      "      - -191576.21958244423\n",
      "      - -193692.79886874885\n",
      "      - -192440.0504150783\n",
      "      - -192593.05035602176\n",
      "      - -192663.51712878587\n",
      "      - -194954.5816063935\n",
      "      - -191555.80116315797\n",
      "      - -190688.2221162379\n",
      "      - -192470.16637551034\n",
      "      - -193099.68247185193\n",
      "      - -192330.11093177\n",
      "      - -192403.09179051418\n",
      "      - -195455.58027396124\n",
      "      - -191668.196270756\n",
      "      - -192055.89118282823\n",
      "      - -190768.84023810556\n",
      "      - -195981.9657906615\n",
      "      - -193896.89058646114\n",
      "      - -193058.84927870854\n",
      "      - -190900.9178664018\n",
      "      - -192407.2349265399\n",
      "      - -192675.85441382797\n",
      "      - -193807.2723914577\n",
      "      - -193748.50684720904\n",
      "      - -192566.6533605622\n",
      "      - -192599.5568920498\n",
      "      - -190105.33827330638\n",
      "      - -193768.28475709714\n",
      "      - -192224.24691056574\n",
      "      - -190066.88790774657\n",
      "      - -192471.09686935565\n",
      "      - -194182.43723681982\n",
      "      - -193460.42188942814\n",
      "      - -193597.40839647336\n",
      "      - -192334.37360811062\n",
      "      - -194092.87211466118\n",
      "      - -190639.90069525005\n",
      "      - -196279.73461513923\n",
      "      - -191930.1168487794\n",
      "      - -193209.54428292997\n",
      "      - -191407.58948391263\n",
      "      - -191466.4057279693\n",
      "      - -191074.23483775236\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09415418964062158\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4678632548593771\n",
      "      mean_inference_ms: 0.9704306348985429\n",
      "      mean_raw_obs_processing_ms: 0.13448041608725272\n",
      "  time_since_restore: 2069.0403320789337\n",
      "  time_this_iter_s: 9.272557735443115\n",
      "  time_total_s: 2069.0403320789337\n",
      "  timers:\n",
      "    learn_throughput: 136498.186\n",
      "    learn_time_ms: 468.753\n",
      "    load_throughput: 22402112.519\n",
      "    load_time_ms: 2.856\n",
      "    training_iteration_time_ms: 9747.95\n",
      "    update_time_ms: 4.671\n",
      "  timestamp: 1665850820\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 13820544\n",
      "  training_iteration: 216\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:20:26 (running for 00:35:00.46)<br>Memory usage on this node: 13.7/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   216</td><td style=\"text-align: right;\">         2069.04</td><td style=\"text-align: right;\">13820544</td><td style=\"text-align: right;\"> -192722</td><td style=\"text-align: right;\">             -190067</td><td style=\"text-align: right;\">             -196280</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 13884528\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 13884528\n",
      "    num_agent_steps_trained: 13884528\n",
      "    num_env_steps_sampled: 13884528\n",
      "    num_env_steps_trained: 13884528\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-20-30\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -189533.27401744912\n",
      "  episode_reward_mean: -193103.7524107704\n",
      "  episode_reward_min: -198886.97311562867\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 13884\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1132659912109375\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0008624577312730253\n",
      "          model: {}\n",
      "          policy_loss: -0.0005876872455701232\n",
      "          total_loss: 9.999275207519531\n",
      "          vf_explained_var: -2.6490953430879927e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 13884528\n",
      "    num_agent_steps_trained: 13884528\n",
      "    num_env_steps_sampled: 13884528\n",
      "    num_env_steps_trained: 13884528\n",
      "  iterations_since_restore: 217\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 13884528\n",
      "  num_agent_steps_trained: 13884528\n",
      "  num_env_steps_sampled: 13884528\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 13884528\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 87.73846153846155\n",
      "    ram_util_percent: 88.96923076923076\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09416168733034411\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4678567112251704\n",
      "    mean_inference_ms: 0.9704252624614759\n",
      "    mean_raw_obs_processing_ms: 0.13431752158651025\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -189533.27401744912\n",
      "    episode_reward_mean: -193103.7524107704\n",
      "    episode_reward_min: -198886.97311562867\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -190768.84023810556\n",
      "      - -195981.9657906615\n",
      "      - -193896.89058646114\n",
      "      - -193058.84927870854\n",
      "      - -190900.9178664018\n",
      "      - -192407.2349265399\n",
      "      - -192675.85441382797\n",
      "      - -193807.2723914577\n",
      "      - -193748.50684720904\n",
      "      - -192566.6533605622\n",
      "      - -192599.5568920498\n",
      "      - -190105.33827330638\n",
      "      - -193768.28475709714\n",
      "      - -192224.24691056574\n",
      "      - -190066.88790774657\n",
      "      - -192471.09686935565\n",
      "      - -194182.43723681982\n",
      "      - -193460.42188942814\n",
      "      - -193597.40839647336\n",
      "      - -192334.37360811062\n",
      "      - -194092.87211466118\n",
      "      - -190639.90069525005\n",
      "      - -196279.73461513923\n",
      "      - -191930.1168487794\n",
      "      - -193209.54428292997\n",
      "      - -191407.58948391263\n",
      "      - -191466.4057279693\n",
      "      - -191074.23483775236\n",
      "      - -192339.36903817987\n",
      "      - -193855.0787030291\n",
      "      - -193884.24223135225\n",
      "      - -193098.3131912722\n",
      "      - -194555.6900730783\n",
      "      - -191935.34237278847\n",
      "      - -193547.46178746043\n",
      "      - -193657.99754299072\n",
      "      - -193360.1568615499\n",
      "      - -193839.526785533\n",
      "      - -191979.44595282595\n",
      "      - -192870.126907209\n",
      "      - -190721.00348181976\n",
      "      - -190207.9593716197\n",
      "      - -190874.61193693147\n",
      "      - -194467.1811233334\n",
      "      - -192782.1874251999\n",
      "      - -191927.58797983322\n",
      "      - -189533.27401744912\n",
      "      - -194452.39362307682\n",
      "      - -194038.82234260332\n",
      "      - -191325.81572048966\n",
      "      - -193915.37651145007\n",
      "      - -192046.3430305441\n",
      "      - -192776.00505390269\n",
      "      - -191698.3272563695\n",
      "      - -191407.53527776158\n",
      "      - -194707.68589293482\n",
      "      - -193323.3576567211\n",
      "      - -195732.04629155685\n",
      "      - -194940.64264465013\n",
      "      - -194805.38829940095\n",
      "      - -192621.99068437133\n",
      "      - -194583.71608052088\n",
      "      - -194856.38807586528\n",
      "      - -193559.48061789697\n",
      "      - -192218.30124781764\n",
      "      - -191500.27559844553\n",
      "      - -193229.48267816534\n",
      "      - -191496.76445712775\n",
      "      - -194969.1846738715\n",
      "      - -192889.96604376863\n",
      "      - -193243.2658337111\n",
      "      - -193089.52713100112\n",
      "      - -191441.20475474745\n",
      "      - -192198.54284511515\n",
      "      - -196444.48205246966\n",
      "      - -194983.69207422217\n",
      "      - -192493.6126933365\n",
      "      - -194212.85061206546\n",
      "      - -191780.26212310442\n",
      "      - -193129.26949122173\n",
      "      - -193729.7542547988\n",
      "      - -194566.246698063\n",
      "      - -194738.29563022286\n",
      "      - -193588.5996355235\n",
      "      - -196461.34561950745\n",
      "      - -192495.41012716264\n",
      "      - -192374.0297401054\n",
      "      - -194272.8496793667\n",
      "      - -193502.32617496364\n",
      "      - -191696.46573731402\n",
      "      - -190209.54458936295\n",
      "      - -192503.9657577773\n",
      "      - -193141.26175151864\n",
      "      - -198886.97311562867\n",
      "      - -193625.04791751437\n",
      "      - -195286.16636182342\n",
      "      - -193624.5311869313\n",
      "      - -194086.59148710436\n",
      "      - -195715.65923928787\n",
      "      - -191598.18317201218\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09416168733034411\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4678567112251704\n",
      "      mean_inference_ms: 0.9704252624614759\n",
      "      mean_raw_obs_processing_ms: 0.13431752158651025\n",
      "  time_since_restore: 2078.8459661006927\n",
      "  time_this_iter_s: 9.805634021759033\n",
      "  time_total_s: 2078.8459661006927\n",
      "  timers:\n",
      "    learn_throughput: 134578.671\n",
      "    learn_time_ms: 475.439\n",
      "    load_throughput: 22257748.18\n",
      "    load_time_ms: 2.875\n",
      "    training_iteration_time_ms: 9803.091\n",
      "    update_time_ms: 4.861\n",
      "  timestamp: 1665850830\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 13884528\n",
      "  training_iteration: 217\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:20:35 (running for 00:35:10.25)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   217</td><td style=\"text-align: right;\">         2078.85</td><td style=\"text-align: right;\">13884528</td><td style=\"text-align: right;\"> -193104</td><td style=\"text-align: right;\">             -189533</td><td style=\"text-align: right;\">             -198887</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 13948512\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 13948512\n",
      "    num_agent_steps_trained: 13948512\n",
      "    num_env_steps_sampled: 13948512\n",
      "    num_env_steps_trained: 13948512\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-20-39\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -187810.11831035864\n",
      "  episode_reward_mean: -193284.94011683497\n",
      "  episode_reward_min: -198886.97311562867\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 13944\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.107599973678589\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0008235009736381471\n",
      "          model: {}\n",
      "          policy_loss: 0.005540563724935055\n",
      "          total_loss: 10.005393981933594\n",
      "          vf_explained_var: -5.392801227799282e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 13948512\n",
      "    num_agent_steps_trained: 13948512\n",
      "    num_env_steps_sampled: 13948512\n",
      "    num_env_steps_trained: 13948512\n",
      "  iterations_since_restore: 218\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 13948512\n",
      "  num_agent_steps_trained: 13948512\n",
      "  num_env_steps_sampled: 13948512\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 13948512\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.83846153846154\n",
      "    ram_util_percent: 89.23076923076925\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09418187429567046\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46772048819322015\n",
      "    mean_inference_ms: 0.970518999699754\n",
      "    mean_raw_obs_processing_ms: 0.13447243839471287\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -187810.11831035864\n",
      "    episode_reward_mean: -193284.94011683497\n",
      "    episode_reward_min: -198886.97311562867\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -192621.99068437133\n",
      "      - -194583.71608052088\n",
      "      - -194856.38807586528\n",
      "      - -193559.48061789697\n",
      "      - -192218.30124781764\n",
      "      - -191500.27559844553\n",
      "      - -193229.48267816534\n",
      "      - -191496.76445712775\n",
      "      - -194969.1846738715\n",
      "      - -192889.96604376863\n",
      "      - -193243.2658337111\n",
      "      - -193089.52713100112\n",
      "      - -191441.20475474745\n",
      "      - -192198.54284511515\n",
      "      - -196444.48205246966\n",
      "      - -194983.69207422217\n",
      "      - -192493.6126933365\n",
      "      - -194212.85061206546\n",
      "      - -191780.26212310442\n",
      "      - -193129.26949122173\n",
      "      - -193729.7542547988\n",
      "      - -194566.246698063\n",
      "      - -194738.29563022286\n",
      "      - -193588.5996355235\n",
      "      - -196461.34561950745\n",
      "      - -192495.41012716264\n",
      "      - -192374.0297401054\n",
      "      - -194272.8496793667\n",
      "      - -193502.32617496364\n",
      "      - -191696.46573731402\n",
      "      - -190209.54458936295\n",
      "      - -192503.9657577773\n",
      "      - -193141.26175151864\n",
      "      - -198886.97311562867\n",
      "      - -193625.04791751437\n",
      "      - -195286.16636182342\n",
      "      - -193624.5311869313\n",
      "      - -194086.59148710436\n",
      "      - -195715.65923928787\n",
      "      - -191598.18317201218\n",
      "      - -194410.5205533686\n",
      "      - -192437.30822835735\n",
      "      - -190993.05935382785\n",
      "      - -193336.34633396153\n",
      "      - -191964.0111096424\n",
      "      - -194449.92438389748\n",
      "      - -193558.13719453328\n",
      "      - -191471.24862565906\n",
      "      - -192827.90496953353\n",
      "      - -193440.6858267568\n",
      "      - -193854.02967821798\n",
      "      - -194660.57477574472\n",
      "      - -193894.62076135448\n",
      "      - -192534.62970033285\n",
      "      - -191524.98544611657\n",
      "      - -190910.58283222912\n",
      "      - -193624.5630166754\n",
      "      - -191852.31837863819\n",
      "      - -194500.1976186348\n",
      "      - -191498.55397735836\n",
      "      - -191850.396068414\n",
      "      - -193459.52030016144\n",
      "      - -194501.84459549683\n",
      "      - -192120.778727811\n",
      "      - -195428.5779003578\n",
      "      - -192879.6756616709\n",
      "      - -193615.81011610274\n",
      "      - -193434.40680890353\n",
      "      - -192849.07794655563\n",
      "      - -193790.74907547413\n",
      "      - -187810.11831035864\n",
      "      - -194236.61014530453\n",
      "      - -192233.1847660785\n",
      "      - -191941.01934514174\n",
      "      - -192372.5747533099\n",
      "      - -193592.0801812387\n",
      "      - -192744.26166990396\n",
      "      - -192991.91782986396\n",
      "      - -195417.0680763187\n",
      "      - -194717.7294026578\n",
      "      - -191910.58174226288\n",
      "      - -190780.5827293494\n",
      "      - -194458.4836395433\n",
      "      - -192923.6639427388\n",
      "      - -193012.24463373004\n",
      "      - -192166.873644331\n",
      "      - -194900.69370202388\n",
      "      - -193398.3464453537\n",
      "      - -192410.20110948643\n",
      "      - -193816.23919843973\n",
      "      - -191547.53674352381\n",
      "      - -193066.02603774788\n",
      "      - -192158.92986671784\n",
      "      - -194907.30516301325\n",
      "      - -197100.6650988359\n",
      "      - -193120.4702385376\n",
      "      - -194829.11411137853\n",
      "      - -192615.45312671043\n",
      "      - -192960.38058129943\n",
      "      - -195633.10783767176\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09418187429567046\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46772048819322015\n",
      "      mean_inference_ms: 0.970518999699754\n",
      "      mean_raw_obs_processing_ms: 0.13447243839471287\n",
      "  time_since_restore: 2087.992999315262\n",
      "  time_this_iter_s: 9.147033214569092\n",
      "  time_total_s: 2087.992999315262\n",
      "  timers:\n",
      "    learn_throughput: 130260.816\n",
      "    learn_time_ms: 491.199\n",
      "    load_throughput: 22485827.158\n",
      "    load_time_ms: 2.846\n",
      "    training_iteration_time_ms: 9690.371\n",
      "    update_time_ms: 4.959\n",
      "  timestamp: 1665850839\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 13948512\n",
      "  training_iteration: 218\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:20:45 (running for 00:35:19.47)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   218</td><td style=\"text-align: right;\">         2087.99</td><td style=\"text-align: right;\">13948512</td><td style=\"text-align: right;\"> -193285</td><td style=\"text-align: right;\">             -187810</td><td style=\"text-align: right;\">             -198887</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 14012496\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 14012496\n",
      "    num_agent_steps_trained: 14012496\n",
      "    num_env_steps_sampled: 14012496\n",
      "    num_env_steps_trained: 14012496\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-20-49\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -187810.11831035864\n",
      "  episode_reward_mean: -192896.53981270164\n",
      "  episode_reward_min: -197233.62523603922\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 14004\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1078598499298096\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00033316065673716366\n",
      "          model: {}\n",
      "          policy_loss: 0.007274224888533354\n",
      "          total_loss: 10.007030487060547\n",
      "          vf_explained_var: -4.5413063531896114e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 14012496\n",
      "    num_agent_steps_trained: 14012496\n",
      "    num_env_steps_sampled: 14012496\n",
      "    num_env_steps_trained: 14012496\n",
      "  iterations_since_restore: 219\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 14012496\n",
      "  num_agent_steps_trained: 14012496\n",
      "  num_env_steps_sampled: 14012496\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 14012496\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.66428571428571\n",
      "    ram_util_percent: 89.3785714285714\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09411437024671067\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46770538281287855\n",
      "    mean_inference_ms: 0.970457578395635\n",
      "    mean_raw_obs_processing_ms: 0.13446258094194824\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -187810.11831035864\n",
      "    episode_reward_mean: -192896.53981270164\n",
      "    episode_reward_min: -197233.62523603922\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -191850.396068414\n",
      "      - -193459.52030016144\n",
      "      - -194501.84459549683\n",
      "      - -192120.778727811\n",
      "      - -195428.5779003578\n",
      "      - -192879.6756616709\n",
      "      - -193615.81011610274\n",
      "      - -193434.40680890353\n",
      "      - -192849.07794655563\n",
      "      - -193790.74907547413\n",
      "      - -187810.11831035864\n",
      "      - -194236.61014530453\n",
      "      - -192233.1847660785\n",
      "      - -191941.01934514174\n",
      "      - -192372.5747533099\n",
      "      - -193592.0801812387\n",
      "      - -192744.26166990396\n",
      "      - -192991.91782986396\n",
      "      - -195417.0680763187\n",
      "      - -194717.7294026578\n",
      "      - -191910.58174226288\n",
      "      - -190780.5827293494\n",
      "      - -194458.4836395433\n",
      "      - -192923.6639427388\n",
      "      - -193012.24463373004\n",
      "      - -192166.873644331\n",
      "      - -194900.69370202388\n",
      "      - -193398.3464453537\n",
      "      - -192410.20110948643\n",
      "      - -193816.23919843973\n",
      "      - -191547.53674352381\n",
      "      - -193066.02603774788\n",
      "      - -192158.92986671784\n",
      "      - -194907.30516301325\n",
      "      - -197100.6650988359\n",
      "      - -193120.4702385376\n",
      "      - -194829.11411137853\n",
      "      - -192615.45312671043\n",
      "      - -192960.38058129943\n",
      "      - -195633.10783767176\n",
      "      - -192915.10712659996\n",
      "      - -191413.47822774848\n",
      "      - -192158.00775848693\n",
      "      - -190890.3880844062\n",
      "      - -191842.54929802075\n",
      "      - -193642.3768971528\n",
      "      - -192535.73126618288\n",
      "      - -191711.75751480836\n",
      "      - -192097.8503780441\n",
      "      - -193638.2792942821\n",
      "      - -192894.33861217115\n",
      "      - -193496.67709634008\n",
      "      - -193022.91708287102\n",
      "      - -193394.31306251284\n",
      "      - -191894.88337123246\n",
      "      - -194663.7419301386\n",
      "      - -192076.87657513353\n",
      "      - -193231.11697315212\n",
      "      - -189753.8819358643\n",
      "      - -191786.99256098174\n",
      "      - -196404.77430940815\n",
      "      - -192442.4956902278\n",
      "      - -191782.48603647915\n",
      "      - -190298.49876389143\n",
      "      - -190670.70012162006\n",
      "      - -196104.3639187801\n",
      "      - -192262.38978700055\n",
      "      - -194307.4737551824\n",
      "      - -190890.26674783905\n",
      "      - -192595.87547727663\n",
      "      - -192785.10056506871\n",
      "      - -190834.363356016\n",
      "      - -192731.56320385894\n",
      "      - -194427.20551942513\n",
      "      - -192814.27157353374\n",
      "      - -192328.983415801\n",
      "      - -197233.62523603922\n",
      "      - -193075.75269959134\n",
      "      - -191931.67868196528\n",
      "      - -195327.14252996657\n",
      "      - -195774.63619170905\n",
      "      - -190097.39286116636\n",
      "      - -193231.45975791564\n",
      "      - -192022.85985013764\n",
      "      - -191642.72897274035\n",
      "      - -190652.9766017702\n",
      "      - -190211.03381297944\n",
      "      - -194226.82870259628\n",
      "      - -192430.06111652133\n",
      "      - -194878.13433868552\n",
      "      - -193996.23354696576\n",
      "      - -190328.03922241376\n",
      "      - -193448.39598537175\n",
      "      - -191483.0371597562\n",
      "      - -193865.70927789746\n",
      "      - -196289.11541911843\n",
      "      - -190089.41732025862\n",
      "      - -193484.63432232774\n",
      "      - -191744.71456618648\n",
      "      - -189741.99453472567\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09411437024671067\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46770538281287855\n",
      "      mean_inference_ms: 0.970457578395635\n",
      "      mean_raw_obs_processing_ms: 0.13446258094194824\n",
      "  time_since_restore: 2097.5953571796417\n",
      "  time_this_iter_s: 9.602357864379883\n",
      "  time_total_s: 2097.5953571796417\n",
      "  timers:\n",
      "    learn_throughput: 128754.191\n",
      "    learn_time_ms: 496.947\n",
      "    load_throughput: 22544005.236\n",
      "    load_time_ms: 2.838\n",
      "    training_iteration_time_ms: 9567.794\n",
      "    update_time_ms: 4.815\n",
      "  timestamp: 1665850849\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 14012496\n",
      "  training_iteration: 219\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:20:54 (running for 00:35:29.32)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   219</td><td style=\"text-align: right;\">          2097.6</td><td style=\"text-align: right;\">14012496</td><td style=\"text-align: right;\"> -192897</td><td style=\"text-align: right;\">             -187810</td><td style=\"text-align: right;\">             -197234</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 14076480\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 14076480\n",
      "    num_agent_steps_trained: 14076480\n",
      "    num_env_steps_sampled: 14076480\n",
      "    num_env_steps_trained: 14076480\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-20-58\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -189344.3800151262\n",
      "  episode_reward_mean: -192671.28523637506\n",
      "  episode_reward_min: -206262.92848289327\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 14076\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.106194019317627\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0008955756202340126\n",
      "          model: {}\n",
      "          policy_loss: -0.0013472585706040263\n",
      "          total_loss: 9.998520851135254\n",
      "          vf_explained_var: -2.838316426334586e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 14076480\n",
      "    num_agent_steps_trained: 14076480\n",
      "    num_env_steps_sampled: 14076480\n",
      "    num_env_steps_trained: 14076480\n",
      "  iterations_since_restore: 220\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 14076480\n",
      "  num_agent_steps_trained: 14076480\n",
      "  num_env_steps_sampled: 14076480\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 14076480\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 80.56153846153848\n",
      "    ram_util_percent: 89.25384615384615\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09408521136027477\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46761695137712456\n",
      "    mean_inference_ms: 0.9702641957022052\n",
      "    mean_raw_obs_processing_ms: 0.13423871670779974\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -189344.3800151262\n",
      "    episode_reward_mean: -192671.28523637506\n",
      "    episode_reward_min: -206262.92848289327\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -192731.56320385894\n",
      "      - -194427.20551942513\n",
      "      - -192814.27157353374\n",
      "      - -192328.983415801\n",
      "      - -197233.62523603922\n",
      "      - -193075.75269959134\n",
      "      - -191931.67868196528\n",
      "      - -195327.14252996657\n",
      "      - -195774.63619170905\n",
      "      - -190097.39286116636\n",
      "      - -193231.45975791564\n",
      "      - -192022.85985013764\n",
      "      - -191642.72897274035\n",
      "      - -190652.9766017702\n",
      "      - -190211.03381297944\n",
      "      - -194226.82870259628\n",
      "      - -192430.06111652133\n",
      "      - -194878.13433868552\n",
      "      - -193996.23354696576\n",
      "      - -190328.03922241376\n",
      "      - -193448.39598537175\n",
      "      - -191483.0371597562\n",
      "      - -193865.70927789746\n",
      "      - -196289.11541911843\n",
      "      - -190089.41732025862\n",
      "      - -193484.63432232774\n",
      "      - -191744.71456618648\n",
      "      - -189741.99453472567\n",
      "      - -206262.92848289327\n",
      "      - -191141.598140818\n",
      "      - -194823.86901402447\n",
      "      - -191256.9497395791\n",
      "      - -193763.6624746522\n",
      "      - -190521.62859567927\n",
      "      - -193125.99314805926\n",
      "      - -194229.2004102515\n",
      "      - -192838.0412080655\n",
      "      - -192034.79459491093\n",
      "      - -193385.04731932018\n",
      "      - -192579.07371592135\n",
      "      - -192830.15937951382\n",
      "      - -192711.87057159925\n",
      "      - -190195.91596835395\n",
      "      - -192742.646914398\n",
      "      - -193239.47537450274\n",
      "      - -191118.36597643324\n",
      "      - -192056.83614238192\n",
      "      - -193530.03141059246\n",
      "      - -191630.66569798382\n",
      "      - -190408.66480053417\n",
      "      - -192921.86295847542\n",
      "      - -192193.6618781642\n",
      "      - -196226.29139192402\n",
      "      - -192216.44406252648\n",
      "      - -193081.0622348766\n",
      "      - -191532.88402843822\n",
      "      - -192885.61940591346\n",
      "      - -192224.56462599811\n",
      "      - -194994.4450286134\n",
      "      - -192457.3729967351\n",
      "      - -190141.18576084674\n",
      "      - -194932.2086464814\n",
      "      - -193591.77384871617\n",
      "      - -190236.95652447725\n",
      "      - -192215.17186762887\n",
      "      - -191956.20277400708\n",
      "      - -190655.29270613554\n",
      "      - -191652.1164413302\n",
      "      - -191082.21759293455\n",
      "      - -192322.6381687147\n",
      "      - -193757.4919736207\n",
      "      - -191727.57132545626\n",
      "      - -190270.6343112661\n",
      "      - -190645.0066089114\n",
      "      - -192223.15584121732\n",
      "      - -194117.332654662\n",
      "      - -192342.28453145773\n",
      "      - -198423.19658113428\n",
      "      - -193386.43669694278\n",
      "      - -189344.3800151262\n",
      "      - -192162.07760722568\n",
      "      - -194042.54546083912\n",
      "      - -189926.9990505425\n",
      "      - -191201.66099411645\n",
      "      - -195163.16333047996\n",
      "      - -193408.0786069603\n",
      "      - -192783.85459823592\n",
      "      - -190682.8113238295\n",
      "      - -192402.90870517108\n",
      "      - -192508.22484489623\n",
      "      - -192666.57163896618\n",
      "      - -189930.11980601554\n",
      "      - -191294.2357849692\n",
      "      - -194293.38352135773\n",
      "      - -191555.01315047857\n",
      "      - -191115.38428728763\n",
      "      - -194846.14010693063\n",
      "      - -190667.68182995592\n",
      "      - -192515.1148253952\n",
      "      - -192268.0451792291\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09408521136027477\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46761695137712456\n",
      "      mean_inference_ms: 0.9702641957022052\n",
      "      mean_raw_obs_processing_ms: 0.13423871670779974\n",
      "  time_since_restore: 2106.6663677692413\n",
      "  time_this_iter_s: 9.07101058959961\n",
      "  time_total_s: 2106.6663677692413\n",
      "  timers:\n",
      "    learn_throughput: 128706.811\n",
      "    learn_time_ms: 497.13\n",
      "    load_throughput: 22580994.652\n",
      "    load_time_ms: 2.834\n",
      "    training_iteration_time_ms: 9510.242\n",
      "    update_time_ms: 4.727\n",
      "  timestamp: 1665850858\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 14076480\n",
      "  training_iteration: 220\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:21:04 (running for 00:35:38.61)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   220</td><td style=\"text-align: right;\">         2106.67</td><td style=\"text-align: right;\">14076480</td><td style=\"text-align: right;\"> -192671</td><td style=\"text-align: right;\">             -189344</td><td style=\"text-align: right;\">             -206263</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 14140464\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 14140464\n",
      "    num_agent_steps_trained: 14140464\n",
      "    num_env_steps_sampled: 14140464\n",
      "    num_env_steps_trained: 14140464\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-21-08\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -188818.7086978596\n",
      "  episode_reward_mean: -192510.74797347543\n",
      "  episode_reward_min: -198423.19658113428\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 14136\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1095130443573\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0003457639249972999\n",
      "          model: {}\n",
      "          policy_loss: 0.006373499985784292\n",
      "          total_loss: 10.00613021850586\n",
      "          vf_explained_var: -2.838316426334586e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 14140464\n",
      "    num_agent_steps_trained: 14140464\n",
      "    num_env_steps_sampled: 14140464\n",
      "    num_env_steps_trained: 14140464\n",
      "  iterations_since_restore: 221\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 14140464\n",
      "  num_agent_steps_trained: 14140464\n",
      "  num_env_steps_sampled: 14140464\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 14140464\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.90769230769232\n",
      "    ram_util_percent: 89.4\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09410590924279302\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46749074600526697\n",
      "    mean_inference_ms: 0.9702951847290915\n",
      "    mean_raw_obs_processing_ms: 0.13441229594797557\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -188818.7086978596\n",
      "    episode_reward_mean: -192510.74797347543\n",
      "    episode_reward_min: -198423.19658113428\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -190141.18576084674\n",
      "      - -194932.2086464814\n",
      "      - -193591.77384871617\n",
      "      - -190236.95652447725\n",
      "      - -192215.17186762887\n",
      "      - -191956.20277400708\n",
      "      - -190655.29270613554\n",
      "      - -191652.1164413302\n",
      "      - -191082.21759293455\n",
      "      - -192322.6381687147\n",
      "      - -193757.4919736207\n",
      "      - -191727.57132545626\n",
      "      - -190270.6343112661\n",
      "      - -190645.0066089114\n",
      "      - -192223.15584121732\n",
      "      - -194117.332654662\n",
      "      - -192342.28453145773\n",
      "      - -198423.19658113428\n",
      "      - -193386.43669694278\n",
      "      - -189344.3800151262\n",
      "      - -192162.07760722568\n",
      "      - -194042.54546083912\n",
      "      - -189926.9990505425\n",
      "      - -191201.66099411645\n",
      "      - -195163.16333047996\n",
      "      - -193408.0786069603\n",
      "      - -192783.85459823592\n",
      "      - -190682.8113238295\n",
      "      - -192402.90870517108\n",
      "      - -192508.22484489623\n",
      "      - -192666.57163896618\n",
      "      - -189930.11980601554\n",
      "      - -191294.2357849692\n",
      "      - -194293.38352135773\n",
      "      - -191555.01315047857\n",
      "      - -191115.38428728763\n",
      "      - -194846.14010693063\n",
      "      - -190667.68182995592\n",
      "      - -192515.1148253952\n",
      "      - -192268.0451792291\n",
      "      - -188818.7086978596\n",
      "      - -192688.5658089924\n",
      "      - -192541.69898024976\n",
      "      - -191514.17648799962\n",
      "      - -195631.99935934815\n",
      "      - -194408.68485543868\n",
      "      - -195177.44710761463\n",
      "      - -193635.94927453963\n",
      "      - -191542.6407872375\n",
      "      - -191816.41020687268\n",
      "      - -190883.20572692135\n",
      "      - -193259.1939708819\n",
      "      - -192600.06421905482\n",
      "      - -190346.3173012026\n",
      "      - -195390.35959849175\n",
      "      - -191362.56428135993\n",
      "      - -193168.50241085357\n",
      "      - -193412.8017887737\n",
      "      - -193739.1215231158\n",
      "      - -191201.70206495293\n",
      "      - -193470.05533200115\n",
      "      - -191367.2126569201\n",
      "      - -192421.07033964683\n",
      "      - -191343.8612058317\n",
      "      - -193302.96710300082\n",
      "      - -195552.35031393915\n",
      "      - -191383.98583720898\n",
      "      - -190834.29229292096\n",
      "      - -193160.5329260383\n",
      "      - -193343.4406958972\n",
      "      - -191842.57719155346\n",
      "      - -192266.03305442375\n",
      "      - -196245.88788381993\n",
      "      - -191660.98418343285\n",
      "      - -192689.86332059017\n",
      "      - -192203.28756277254\n",
      "      - -190495.60703747577\n",
      "      - -194827.96514782612\n",
      "      - -194162.8306684791\n",
      "      - -192137.68759396864\n",
      "      - -194510.2834446072\n",
      "      - -193735.3607982089\n",
      "      - -192386.13390127153\n",
      "      - -192509.3633520815\n",
      "      - -193321.0917818585\n",
      "      - -192036.42025893362\n",
      "      - -192027.19072071646\n",
      "      - -192934.1454349479\n",
      "      - -191360.1189734341\n",
      "      - -190672.8457668255\n",
      "      - -192666.9080434596\n",
      "      - -194005.5789254053\n",
      "      - -190712.2327053125\n",
      "      - -195133.50781394908\n",
      "      - -191033.05396758995\n",
      "      - -192670.71521882137\n",
      "      - -192380.79129444185\n",
      "      - -192733.24205512682\n",
      "      - -192565.34557938323\n",
      "      - -193370.590987712\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09410590924279302\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46749074600526697\n",
      "      mean_inference_ms: 0.9702951847290915\n",
      "      mean_raw_obs_processing_ms: 0.13441229594797557\n",
      "  time_since_restore: 2116.1457328796387\n",
      "  time_this_iter_s: 9.479365110397339\n",
      "  time_total_s: 2116.1457328796387\n",
      "  timers:\n",
      "    learn_throughput: 128946.496\n",
      "    learn_time_ms: 496.206\n",
      "    load_throughput: 22431322.897\n",
      "    load_time_ms: 2.852\n",
      "    training_iteration_time_ms: 9456.598\n",
      "    update_time_ms: 4.573\n",
      "  timestamp: 1665850868\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 14140464\n",
      "  training_iteration: 221\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:21:13 (running for 00:35:47.48)<br>Memory usage on this node: 13.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   221</td><td style=\"text-align: right;\">         2116.15</td><td style=\"text-align: right;\">14140464</td><td style=\"text-align: right;\"> -192511</td><td style=\"text-align: right;\">             -188819</td><td style=\"text-align: right;\">             -198423</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 14204448\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 14204448\n",
      "    num_agent_steps_trained: 14204448\n",
      "    num_env_steps_sampled: 14204448\n",
      "    num_env_steps_trained: 14204448\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-21-17\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -188731.97125522874\n",
      "  episode_reward_mean: -192718.42618555346\n",
      "  episode_reward_min: -196245.88788381993\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 14196\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.107048988342285\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0004341437597759068\n",
      "          model: {}\n",
      "          policy_loss: 0.005856323521584272\n",
      "          total_loss: 10.005632400512695\n",
      "          vf_explained_var: -3.311369312086754e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 14204448\n",
      "    num_agent_steps_trained: 14204448\n",
      "    num_env_steps_sampled: 14204448\n",
      "    num_env_steps_trained: 14204448\n",
      "  iterations_since_restore: 222\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 14204448\n",
      "  num_agent_steps_trained: 14204448\n",
      "  num_env_steps_sampled: 14204448\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 14204448\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 85.70000000000002\n",
      "    ram_util_percent: 89.73846153846154\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09406181890941219\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4675258671850349\n",
      "    mean_inference_ms: 0.9702111854975874\n",
      "    mean_raw_obs_processing_ms: 0.13445074718605846\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -188731.97125522874\n",
      "    episode_reward_mean: -192718.42618555346\n",
      "    episode_reward_min: -196245.88788381993\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -193470.05533200115\n",
      "      - -191367.2126569201\n",
      "      - -192421.07033964683\n",
      "      - -191343.8612058317\n",
      "      - -193302.96710300082\n",
      "      - -195552.35031393915\n",
      "      - -191383.98583720898\n",
      "      - -190834.29229292096\n",
      "      - -193160.5329260383\n",
      "      - -193343.4406958972\n",
      "      - -191842.57719155346\n",
      "      - -192266.03305442375\n",
      "      - -196245.88788381993\n",
      "      - -191660.98418343285\n",
      "      - -192689.86332059017\n",
      "      - -192203.28756277254\n",
      "      - -190495.60703747577\n",
      "      - -194827.96514782612\n",
      "      - -194162.8306684791\n",
      "      - -192137.68759396864\n",
      "      - -194510.2834446072\n",
      "      - -193735.3607982089\n",
      "      - -192386.13390127153\n",
      "      - -192509.3633520815\n",
      "      - -193321.0917818585\n",
      "      - -192036.42025893362\n",
      "      - -192027.19072071646\n",
      "      - -192934.1454349479\n",
      "      - -191360.1189734341\n",
      "      - -190672.8457668255\n",
      "      - -192666.9080434596\n",
      "      - -194005.5789254053\n",
      "      - -190712.2327053125\n",
      "      - -195133.50781394908\n",
      "      - -191033.05396758995\n",
      "      - -192670.71521882137\n",
      "      - -192380.79129444185\n",
      "      - -192733.24205512682\n",
      "      - -192565.34557938323\n",
      "      - -193370.590987712\n",
      "      - -190942.4710253976\n",
      "      - -190912.12424340792\n",
      "      - -193435.5987217045\n",
      "      - -190569.5064920855\n",
      "      - -191840.84620951084\n",
      "      - -192405.0574013941\n",
      "      - -193271.43811487537\n",
      "      - -193600.2255917757\n",
      "      - -191169.5973582698\n",
      "      - -191409.18072143453\n",
      "      - -192972.78710850593\n",
      "      - -193309.47161689986\n",
      "      - -193516.23701714535\n",
      "      - -194075.22619837226\n",
      "      - -193327.11883970836\n",
      "      - -192586.08742476854\n",
      "      - -194515.44119778412\n",
      "      - -193617.91284419067\n",
      "      - -192712.90495044139\n",
      "      - -193295.6699071471\n",
      "      - -195097.49784733405\n",
      "      - -192063.57477278626\n",
      "      - -192951.50343888067\n",
      "      - -194468.46115664623\n",
      "      - -194752.1899924855\n",
      "      - -193647.1202123633\n",
      "      - -193012.19359181068\n",
      "      - -194816.2811032607\n",
      "      - -191721.820008318\n",
      "      - -193304.06453555782\n",
      "      - -191338.9408385596\n",
      "      - -191116.32034078034\n",
      "      - -189544.9913915772\n",
      "      - -193340.0209940876\n",
      "      - -192264.72311369577\n",
      "      - -194090.1789029184\n",
      "      - -191169.3437546897\n",
      "      - -194406.2929720953\n",
      "      - -192611.85044025592\n",
      "      - -192275.10773422365\n",
      "      - -193007.19089754543\n",
      "      - -191219.44795463653\n",
      "      - -190926.2014671457\n",
      "      - -191781.9513269826\n",
      "      - -191080.03587560158\n",
      "      - -190508.24399240903\n",
      "      - -193716.46505429232\n",
      "      - -192470.05840890852\n",
      "      - -193218.64836955018\n",
      "      - -193584.43159837477\n",
      "      - -195842.42517297794\n",
      "      - -193792.99074503357\n",
      "      - -191023.84896824812\n",
      "      - -194435.35814549416\n",
      "      - -193378.0871455605\n",
      "      - -188731.97125522874\n",
      "      - -193084.6426128032\n",
      "      - -194149.6275787354\n",
      "      - -193648.86598416674\n",
      "      - -193287.332502666\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09406181890941219\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4675258671850349\n",
      "      mean_inference_ms: 0.9702111854975874\n",
      "      mean_raw_obs_processing_ms: 0.13445074718605846\n",
      "  time_since_restore: 2125.775055170059\n",
      "  time_this_iter_s: 9.629322290420532\n",
      "  time_total_s: 2125.775055170059\n",
      "  timers:\n",
      "    learn_throughput: 129497.628\n",
      "    learn_time_ms: 494.094\n",
      "    load_throughput: 22338525.778\n",
      "    load_time_ms: 2.864\n",
      "    training_iteration_time_ms: 9473.599\n",
      "    update_time_ms: 4.723\n",
      "  timestamp: 1665850877\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 14204448\n",
      "  training_iteration: 222\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:21:23 (running for 00:35:57.53)<br>Memory usage on this node: 13.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   222</td><td style=\"text-align: right;\">         2125.78</td><td style=\"text-align: right;\">14204448</td><td style=\"text-align: right;\"> -192718</td><td style=\"text-align: right;\">             -188732</td><td style=\"text-align: right;\">             -196246</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 14268432\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 14268432\n",
      "    num_agent_steps_trained: 14268432\n",
      "    num_env_steps_sampled: 14268432\n",
      "    num_env_steps_trained: 14268432\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-21-27\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -188731.97125522874\n",
      "  episode_reward_mean: -192703.32884790708\n",
      "  episode_reward_min: -198863.04719580786\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 14268\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1037654876708984\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0007657678215764463\n",
      "          model: {}\n",
      "          policy_loss: -0.0010821159230545163\n",
      "          total_loss: 9.998759269714355\n",
      "          vf_explained_var: -2.3652637182181024e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 14268432\n",
      "    num_agent_steps_trained: 14268432\n",
      "    num_env_steps_sampled: 14268432\n",
      "    num_env_steps_trained: 14268432\n",
      "  iterations_since_restore: 223\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 14268432\n",
      "  num_agent_steps_trained: 14268432\n",
      "  num_env_steps_sampled: 14268432\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 14268432\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.3923076923077\n",
      "    ram_util_percent: 89.60769230769232\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09407423462260348\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46746686495468687\n",
      "    mean_inference_ms: 0.9701563459008259\n",
      "    mean_raw_obs_processing_ms: 0.13425872855264043\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -188731.97125522874\n",
      "    episode_reward_mean: -192703.32884790708\n",
      "    episode_reward_min: -198863.04719580786\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -189544.9913915772\n",
      "      - -193340.0209940876\n",
      "      - -192264.72311369577\n",
      "      - -194090.1789029184\n",
      "      - -191169.3437546897\n",
      "      - -194406.2929720953\n",
      "      - -192611.85044025592\n",
      "      - -192275.10773422365\n",
      "      - -193007.19089754543\n",
      "      - -191219.44795463653\n",
      "      - -190926.2014671457\n",
      "      - -191781.9513269826\n",
      "      - -191080.03587560158\n",
      "      - -190508.24399240903\n",
      "      - -193716.46505429232\n",
      "      - -192470.05840890852\n",
      "      - -193218.64836955018\n",
      "      - -193584.43159837477\n",
      "      - -195842.42517297794\n",
      "      - -193792.99074503357\n",
      "      - -191023.84896824812\n",
      "      - -194435.35814549416\n",
      "      - -193378.0871455605\n",
      "      - -188731.97125522874\n",
      "      - -193084.6426128032\n",
      "      - -194149.6275787354\n",
      "      - -193648.86598416674\n",
      "      - -193287.332502666\n",
      "      - -192078.21451667458\n",
      "      - -193665.92087887521\n",
      "      - -191589.8265384314\n",
      "      - -191260.82178664656\n",
      "      - -194556.98661626875\n",
      "      - -191957.63989936025\n",
      "      - -191979.23804523802\n",
      "      - -190763.88079264716\n",
      "      - -198279.74877534105\n",
      "      - -192617.92818528638\n",
      "      - -195530.6534561028\n",
      "      - -192832.4022728603\n",
      "      - -193788.80176243366\n",
      "      - -198863.04719580786\n",
      "      - -192445.97778543824\n",
      "      - -192463.32003878453\n",
      "      - -192670.75129839175\n",
      "      - -190832.45734567408\n",
      "      - -192763.78112990546\n",
      "      - -194829.11875271992\n",
      "      - -192056.51921254973\n",
      "      - -191820.37952576525\n",
      "      - -189532.94823659596\n",
      "      - -191609.73025160297\n",
      "      - -194577.94493221192\n",
      "      - -194457.95363667607\n",
      "      - -193105.293582132\n",
      "      - -192158.42622646227\n",
      "      - -191892.81122876488\n",
      "      - -191895.5105804329\n",
      "      - -194409.7915551098\n",
      "      - -191369.39692835955\n",
      "      - -195086.3929360811\n",
      "      - -194309.9695145592\n",
      "      - -190325.65379904126\n",
      "      - -191844.41542227622\n",
      "      - -194298.06576376225\n",
      "      - -195030.4956255186\n",
      "      - -191955.5802513784\n",
      "      - -194364.21593354232\n",
      "      - -194331.5827740036\n",
      "      - -191414.86293217662\n",
      "      - -192762.1128789712\n",
      "      - -192502.31762970824\n",
      "      - -190505.0718235403\n",
      "      - -192249.18284090175\n",
      "      - -191798.30100912336\n",
      "      - -192986.41947008358\n",
      "      - -191845.49304520138\n",
      "      - -192430.60674223315\n",
      "      - -193441.40441702885\n",
      "      - -193483.64861449285\n",
      "      - -191279.81227521322\n",
      "      - -193597.26851096196\n",
      "      - -192547.6701908271\n",
      "      - -195161.47852260314\n",
      "      - -193613.45428562045\n",
      "      - -193635.62082851527\n",
      "      - -189838.4919177276\n",
      "      - -192298.0419491636\n",
      "      - -193008.94357838287\n",
      "      - -190583.0815978303\n",
      "      - -193344.4664719221\n",
      "      - -191755.88651482514\n",
      "      - -189456.58631024207\n",
      "      - -189623.18227766335\n",
      "      - -195610.44330528265\n",
      "      - -191109.4649138667\n",
      "      - -194148.19302596268\n",
      "      - -191576.76603556858\n",
      "      - -192699.67751417396\n",
      "      - -191231.00401127207\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09407423462260348\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46746686495468687\n",
      "      mean_inference_ms: 0.9701563459008259\n",
      "      mean_raw_obs_processing_ms: 0.13425872855264043\n",
      "  time_since_restore: 2135.253452062607\n",
      "  time_this_iter_s: 9.478396892547607\n",
      "  time_total_s: 2135.253452062607\n",
      "  timers:\n",
      "    learn_throughput: 128467.259\n",
      "    learn_time_ms: 498.057\n",
      "    load_throughput: 22174803.934\n",
      "    load_time_ms: 2.885\n",
      "    training_iteration_time_ms: 9345.609\n",
      "    update_time_ms: 4.729\n",
      "  timestamp: 1665850887\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 14268432\n",
      "  training_iteration: 223\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:21:32 (running for 00:36:06.89)<br>Memory usage on this node: 13.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   223</td><td style=\"text-align: right;\">         2135.25</td><td style=\"text-align: right;\">14268432</td><td style=\"text-align: right;\"> -192703</td><td style=\"text-align: right;\">             -188732</td><td style=\"text-align: right;\">             -198863</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 14332416\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 14332416\n",
      "    num_agent_steps_trained: 14332416\n",
      "    num_env_steps_sampled: 14332416\n",
      "    num_env_steps_trained: 14332416\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-21-37\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -188823.17489631218\n",
      "  episode_reward_mean: -192481.46958074343\n",
      "  episode_reward_min: -206697.28377211024\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 14328\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1077911853790283\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0011489372700452805\n",
      "          model: {}\n",
      "          policy_loss: 0.005456771235913038\n",
      "          total_loss: 10.005374908447266\n",
      "          vf_explained_var: -2.554484801464696e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 14332416\n",
      "    num_agent_steps_trained: 14332416\n",
      "    num_env_steps_sampled: 14332416\n",
      "    num_env_steps_trained: 14332416\n",
      "  iterations_since_restore: 224\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 14332416\n",
      "  num_agent_steps_trained: 14332416\n",
      "  num_env_steps_sampled: 14332416\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 14332416\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 84.3142857142857\n",
      "    ram_util_percent: 89.65714285714286\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09412996783599396\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46742840080400294\n",
      "    mean_inference_ms: 0.9703627227010548\n",
      "    mean_raw_obs_processing_ms: 0.13443277729935685\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -188823.17489631218\n",
      "    episode_reward_mean: -192481.46958074343\n",
      "    episode_reward_min: -206697.28377211024\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -195086.3929360811\n",
      "      - -194309.9695145592\n",
      "      - -190325.65379904126\n",
      "      - -191844.41542227622\n",
      "      - -194298.06576376225\n",
      "      - -195030.4956255186\n",
      "      - -191955.5802513784\n",
      "      - -194364.21593354232\n",
      "      - -194331.5827740036\n",
      "      - -191414.86293217662\n",
      "      - -192762.1128789712\n",
      "      - -192502.31762970824\n",
      "      - -190505.0718235403\n",
      "      - -192249.18284090175\n",
      "      - -191798.30100912336\n",
      "      - -192986.41947008358\n",
      "      - -191845.49304520138\n",
      "      - -192430.60674223315\n",
      "      - -193441.40441702885\n",
      "      - -193483.64861449285\n",
      "      - -191279.81227521322\n",
      "      - -193597.26851096196\n",
      "      - -192547.6701908271\n",
      "      - -195161.47852260314\n",
      "      - -193613.45428562045\n",
      "      - -193635.62082851527\n",
      "      - -189838.4919177276\n",
      "      - -192298.0419491636\n",
      "      - -193008.94357838287\n",
      "      - -190583.0815978303\n",
      "      - -193344.4664719221\n",
      "      - -191755.88651482514\n",
      "      - -189456.58631024207\n",
      "      - -189623.18227766335\n",
      "      - -195610.44330528265\n",
      "      - -191109.4649138667\n",
      "      - -194148.19302596268\n",
      "      - -191576.76603556858\n",
      "      - -192699.67751417396\n",
      "      - -191231.00401127207\n",
      "      - -194807.05788010926\n",
      "      - -191715.03976082994\n",
      "      - -192152.6302017285\n",
      "      - -192048.08341227204\n",
      "      - -190705.23661226942\n",
      "      - -189233.1843496014\n",
      "      - -191665.14985389193\n",
      "      - -193188.0239710592\n",
      "      - -193710.45018449338\n",
      "      - -195034.19994658304\n",
      "      - -191314.9832449298\n",
      "      - -192783.7107912355\n",
      "      - -193873.15462323965\n",
      "      - -192883.5313727042\n",
      "      - -195120.03440714354\n",
      "      - -191132.28403124944\n",
      "      - -194240.51777264941\n",
      "      - -192183.04224099082\n",
      "      - -192696.47417893267\n",
      "      - -189697.3296140406\n",
      "      - -192087.09584863033\n",
      "      - -189179.84369734678\n",
      "      - -194451.61572191867\n",
      "      - -193090.05938958406\n",
      "      - -193283.31233404056\n",
      "      - -190452.1442866123\n",
      "      - -191361.54845015387\n",
      "      - -190716.3723238813\n",
      "      - -190915.8858201876\n",
      "      - -191659.826646619\n",
      "      - -193244.8288886274\n",
      "      - -191987.74230372222\n",
      "      - -192480.18919263995\n",
      "      - -192254.43817670722\n",
      "      - -191758.90685873717\n",
      "      - -192163.6324880248\n",
      "      - -189379.60642864305\n",
      "      - -193500.03772590277\n",
      "      - -193300.5455466202\n",
      "      - -206697.28377211024\n",
      "      - -193223.05494837914\n",
      "      - -192790.61464777472\n",
      "      - -189765.5773712099\n",
      "      - -193991.99403697447\n",
      "      - -188823.17489631218\n",
      "      - -191553.2066789116\n",
      "      - -192193.72512224465\n",
      "      - -193250.06665141534\n",
      "      - -190798.09170157876\n",
      "      - -192263.75139727374\n",
      "      - -191938.2737734739\n",
      "      - -193960.0147814144\n",
      "      - -191475.00307802443\n",
      "      - -193199.38021293867\n",
      "      - -192709.31053638173\n",
      "      - -191021.6602142383\n",
      "      - -191057.34389097447\n",
      "      - -191798.31045103766\n",
      "      - -192460.9184033462\n",
      "      - -192639.12346852076\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09412996783599396\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46742840080400294\n",
      "      mean_inference_ms: 0.9703627227010548\n",
      "      mean_raw_obs_processing_ms: 0.13443277729935685\n",
      "  time_since_restore: 2145.101815700531\n",
      "  time_this_iter_s: 9.848363637924194\n",
      "  time_total_s: 2145.101815700531\n",
      "  timers:\n",
      "    learn_throughput: 128785.789\n",
      "    learn_time_ms: 496.825\n",
      "    load_throughput: 22751949.67\n",
      "    load_time_ms: 2.812\n",
      "    training_iteration_time_ms: 9394.598\n",
      "    update_time_ms: 4.793\n",
      "  timestamp: 1665850897\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 14332416\n",
      "  training_iteration: 224\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:21:42 (running for 00:36:16.52)<br>Memory usage on this node: 13.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   224</td><td style=\"text-align: right;\">          2145.1</td><td style=\"text-align: right;\">14332416</td><td style=\"text-align: right;\"> -192481</td><td style=\"text-align: right;\">             -188823</td><td style=\"text-align: right;\">             -206697</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 14396400\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 14396400\n",
      "    num_agent_steps_trained: 14396400\n",
      "    num_env_steps_sampled: 14396400\n",
      "    num_env_steps_trained: 14396400\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-21-46\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -188823.17489631218\n",
      "  episode_reward_mean: -192914.79786049933\n",
      "  episode_reward_min: -206697.28377211024\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 14388\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.106255054473877\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0009181093773804605\n",
      "          model: {}\n",
      "          policy_loss: 0.006457505747675896\n",
      "          total_loss: 10.006331443786621\n",
      "          vf_explained_var: -2.3652637182181024e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 14396400\n",
      "    num_agent_steps_trained: 14396400\n",
      "    num_env_steps_sampled: 14396400\n",
      "    num_env_steps_trained: 14396400\n",
      "  iterations_since_restore: 225\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 14396400\n",
      "  num_agent_steps_trained: 14396400\n",
      "  num_env_steps_sampled: 14396400\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 14396400\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.0\n",
      "    ram_util_percent: 89.73076923076923\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09407874184936876\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46749794808061246\n",
      "    mean_inference_ms: 0.970229865932138\n",
      "    mean_raw_obs_processing_ms: 0.13444008551576406\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -188823.17489631218\n",
      "    episode_reward_mean: -192914.79786049933\n",
      "    episode_reward_min: -206697.28377211024\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -192087.09584863033\n",
      "      - -189179.84369734678\n",
      "      - -194451.61572191867\n",
      "      - -193090.05938958406\n",
      "      - -193283.31233404056\n",
      "      - -190452.1442866123\n",
      "      - -191361.54845015387\n",
      "      - -190716.3723238813\n",
      "      - -190915.8858201876\n",
      "      - -191659.826646619\n",
      "      - -193244.8288886274\n",
      "      - -191987.74230372222\n",
      "      - -192480.18919263995\n",
      "      - -192254.43817670722\n",
      "      - -191758.90685873717\n",
      "      - -192163.6324880248\n",
      "      - -189379.60642864305\n",
      "      - -193500.03772590277\n",
      "      - -193300.5455466202\n",
      "      - -206697.28377211024\n",
      "      - -193223.05494837914\n",
      "      - -192790.61464777472\n",
      "      - -189765.5773712099\n",
      "      - -193991.99403697447\n",
      "      - -188823.17489631218\n",
      "      - -191553.2066789116\n",
      "      - -192193.72512224465\n",
      "      - -193250.06665141534\n",
      "      - -190798.09170157876\n",
      "      - -192263.75139727374\n",
      "      - -191938.2737734739\n",
      "      - -193960.0147814144\n",
      "      - -191475.00307802443\n",
      "      - -193199.38021293867\n",
      "      - -192709.31053638173\n",
      "      - -191021.6602142383\n",
      "      - -191057.34389097447\n",
      "      - -191798.31045103766\n",
      "      - -192460.9184033462\n",
      "      - -192639.12346852076\n",
      "      - -192139.7868782133\n",
      "      - -191910.1212623756\n",
      "      - -191912.4788444014\n",
      "      - -192418.52169117949\n",
      "      - -194084.84247072713\n",
      "      - -193977.9075788715\n",
      "      - -192776.64757725564\n",
      "      - -195389.5803291374\n",
      "      - -193918.5850849872\n",
      "      - -191955.01469602468\n",
      "      - -191823.79716524458\n",
      "      - -192065.40473186038\n",
      "      - -191946.6452602011\n",
      "      - -191962.98646157648\n",
      "      - -194180.1132973669\n",
      "      - -194470.23816640693\n",
      "      - -192957.23861480033\n",
      "      - -191029.7509361066\n",
      "      - -193223.80286229553\n",
      "      - -195292.0169810917\n",
      "      - -192438.9953809314\n",
      "      - -192560.95405403717\n",
      "      - -193587.2321797595\n",
      "      - -194950.2589524845\n",
      "      - -193050.87241108328\n",
      "      - -195388.21218668882\n",
      "      - -194243.99341994952\n",
      "      - -190302.8490651808\n",
      "      - -193053.8245258981\n",
      "      - -193107.0325905425\n",
      "      - -193666.06158497493\n",
      "      - -191552.10726991625\n",
      "      - -193665.96540024292\n",
      "      - -192199.8819882757\n",
      "      - -193582.15690500828\n",
      "      - -192177.9030238559\n",
      "      - -191696.1577838541\n",
      "      - -192877.89248547525\n",
      "      - -192667.8275746045\n",
      "      - -193352.44327338564\n",
      "      - -202055.79594248606\n",
      "      - -193142.15275393202\n",
      "      - -194514.1657430362\n",
      "      - -191003.34703279217\n",
      "      - -193599.57710861255\n",
      "      - -192681.6535376514\n",
      "      - -193845.49922740686\n",
      "      - -195611.05014158142\n",
      "      - -193488.41250444856\n",
      "      - -193050.53436032622\n",
      "      - -192134.41773725025\n",
      "      - -192953.5095595384\n",
      "      - -192563.47687370138\n",
      "      - -192137.74211955632\n",
      "      - -193460.85284824978\n",
      "      - -193486.63144473167\n",
      "      - -196045.76321011572\n",
      "      - -193010.7376096936\n",
      "      - -194718.08616472734\n",
      "      - -193540.76502068684\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09407874184936876\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46749794808061246\n",
      "      mean_inference_ms: 0.970229865932138\n",
      "      mean_raw_obs_processing_ms: 0.13444008551576406\n",
      "  time_since_restore: 2154.2597482204437\n",
      "  time_this_iter_s: 9.15793251991272\n",
      "  time_total_s: 2154.2597482204437\n",
      "  timers:\n",
      "    learn_throughput: 130528.761\n",
      "    learn_time_ms: 490.191\n",
      "    load_throughput: 22461173.503\n",
      "    load_time_ms: 2.849\n",
      "    training_iteration_time_ms: 9442.155\n",
      "    update_time_ms: 4.719\n",
      "  timestamp: 1665850906\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 14396400\n",
      "  training_iteration: 225\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:21:51 (running for 00:36:25.83)<br>Memory usage on this node: 13.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   225</td><td style=\"text-align: right;\">         2154.26</td><td style=\"text-align: right;\">14396400</td><td style=\"text-align: right;\"> -192915</td><td style=\"text-align: right;\">             -188823</td><td style=\"text-align: right;\">             -206697</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 14460384\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 14460384\n",
      "    num_agent_steps_trained: 14460384\n",
      "    num_env_steps_sampled: 14460384\n",
      "    num_env_steps_trained: 14460384\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-21-54\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -189187.5593235322\n",
      "  episode_reward_mean: -192972.50492044108\n",
      "  episode_reward_min: -203726.23515527378\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 14460\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1053807735443115\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0006671907030977309\n",
      "          model: {}\n",
      "          policy_loss: -0.001297987182624638\n",
      "          total_loss: 9.99852466583252\n",
      "          vf_explained_var: -2.554484801464696e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 14460384\n",
      "    num_agent_steps_trained: 14460384\n",
      "    num_env_steps_sampled: 14460384\n",
      "    num_env_steps_trained: 14460384\n",
      "  iterations_since_restore: 226\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 14460384\n",
      "  num_agent_steps_trained: 14460384\n",
      "  num_env_steps_sampled: 14460384\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 14460384\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.1846153846154\n",
      "    ram_util_percent: 89.6076923076923\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09404862745499265\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46736334034483645\n",
      "    mean_inference_ms: 0.9696513858009358\n",
      "    mean_raw_obs_processing_ms: 0.1342162641104188\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -189187.5593235322\n",
      "    episode_reward_mean: -192972.50492044108\n",
      "    episode_reward_min: -203726.23515527378\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -193665.96540024292\n",
      "      - -192199.8819882757\n",
      "      - -193582.15690500828\n",
      "      - -192177.9030238559\n",
      "      - -191696.1577838541\n",
      "      - -192877.89248547525\n",
      "      - -192667.8275746045\n",
      "      - -193352.44327338564\n",
      "      - -202055.79594248606\n",
      "      - -193142.15275393202\n",
      "      - -194514.1657430362\n",
      "      - -191003.34703279217\n",
      "      - -193599.57710861255\n",
      "      - -192681.6535376514\n",
      "      - -193845.49922740686\n",
      "      - -195611.05014158142\n",
      "      - -193488.41250444856\n",
      "      - -193050.53436032622\n",
      "      - -192134.41773725025\n",
      "      - -192953.5095595384\n",
      "      - -192563.47687370138\n",
      "      - -192137.74211955632\n",
      "      - -193460.85284824978\n",
      "      - -193486.63144473167\n",
      "      - -196045.76321011572\n",
      "      - -193010.7376096936\n",
      "      - -194718.08616472734\n",
      "      - -193540.76502068684\n",
      "      - -192811.4523644717\n",
      "      - -197351.3011106674\n",
      "      - -193092.2166988183\n",
      "      - -191580.60628672957\n",
      "      - -191599.30430003494\n",
      "      - -193302.91783816984\n",
      "      - -191407.09383859424\n",
      "      - -189187.5593235322\n",
      "      - -192898.345168993\n",
      "      - -189801.17703893434\n",
      "      - -191669.80281241782\n",
      "      - -192608.78005193133\n",
      "      - -193732.32155585298\n",
      "      - -190473.70746212394\n",
      "      - -190908.37778323135\n",
      "      - -189958.1269506158\n",
      "      - -194411.9030742904\n",
      "      - -195616.93458711688\n",
      "      - -191414.73908093173\n",
      "      - -191717.03241710216\n",
      "      - -203726.23515527378\n",
      "      - -193504.57397755497\n",
      "      - -192144.28495580328\n",
      "      - -194167.78878040303\n",
      "      - -192125.94197005735\n",
      "      - -192464.39693346946\n",
      "      - -193781.54430575017\n",
      "      - -194919.06684126967\n",
      "      - -193921.2307974314\n",
      "      - -194085.95759614388\n",
      "      - -191907.25402234457\n",
      "      - -193600.60797395837\n",
      "      - -191760.57104120395\n",
      "      - -199022.56676395136\n",
      "      - -191742.45579254426\n",
      "      - -191749.19187564193\n",
      "      - -192690.10574365297\n",
      "      - -191593.5135000157\n",
      "      - -193016.01968535432\n",
      "      - -189787.33310439615\n",
      "      - -192369.89488227596\n",
      "      - -192427.22711076957\n",
      "      - -190491.99736582223\n",
      "      - -194085.0013059128\n",
      "      - -192808.33304932088\n",
      "      - -192994.8142937613\n",
      "      - -191513.57728096683\n",
      "      - -193525.06037631928\n",
      "      - -192113.3804687874\n",
      "      - -191636.3163211734\n",
      "      - -195502.66256601168\n",
      "      - -193024.03714206596\n",
      "      - -190770.78746557736\n",
      "      - -193299.4766151861\n",
      "      - -191457.3042582645\n",
      "      - -191552.82844130925\n",
      "      - -193426.8800121962\n",
      "      - -192280.68357533985\n",
      "      - -192396.37735020526\n",
      "      - -190645.6360073698\n",
      "      - -193369.56531800338\n",
      "      - -191161.03912887265\n",
      "      - -192903.38876442492\n",
      "      - -192347.7809222049\n",
      "      - -194270.5683997134\n",
      "      - -192974.20797605565\n",
      "      - -192081.1798673688\n",
      "      - -191635.31997662626\n",
      "      - -193254.242206183\n",
      "      - -194315.8384680056\n",
      "      - -191793.64726033056\n",
      "      - -192302.69793167702\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09404862745499265\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46736334034483645\n",
      "      mean_inference_ms: 0.9696513858009358\n",
      "      mean_raw_obs_processing_ms: 0.1342162641104188\n",
      "  time_since_restore: 2162.815412759781\n",
      "  time_this_iter_s: 8.555664539337158\n",
      "  time_total_s: 2162.815412759781\n",
      "  timers:\n",
      "    learn_throughput: 129651.035\n",
      "    learn_time_ms: 493.509\n",
      "    load_throughput: 22319018.907\n",
      "    load_time_ms: 2.867\n",
      "    training_iteration_time_ms: 9370.245\n",
      "    update_time_ms: 4.49\n",
      "  timestamp: 1665850914\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 14460384\n",
      "  training_iteration: 226\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:22:00 (running for 00:36:34.64)<br>Memory usage on this node: 13.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   226</td><td style=\"text-align: right;\">         2162.82</td><td style=\"text-align: right;\">14460384</td><td style=\"text-align: right;\"> -192973</td><td style=\"text-align: right;\">             -189188</td><td style=\"text-align: right;\">             -203726</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 14524368\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 14524368\n",
      "    num_agent_steps_trained: 14524368\n",
      "    num_env_steps_sampled: 14524368\n",
      "    num_env_steps_trained: 14524368\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-22-04\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -189369.8331432017\n",
      "  episode_reward_mean: -192436.70253924755\n",
      "  episode_reward_min: -199022.56676395136\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 14520\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1030800342559814\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0009126872755587101\n",
      "          model: {}\n",
      "          policy_loss: 0.006187467370182276\n",
      "          total_loss: 10.006058692932129\n",
      "          vf_explained_var: -3.689811478579941e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 14524368\n",
      "    num_agent_steps_trained: 14524368\n",
      "    num_env_steps_sampled: 14524368\n",
      "    num_env_steps_trained: 14524368\n",
      "  iterations_since_restore: 227\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 14524368\n",
      "  num_agent_steps_trained: 14524368\n",
      "  num_env_steps_sampled: 14524368\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 14524368\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 84.53076923076922\n",
      "    ram_util_percent: 89.56923076923077\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09406021225541071\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46723758160349815\n",
      "    mean_inference_ms: 0.9693332982946649\n",
      "    mean_raw_obs_processing_ms: 0.13435363064553957\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -189369.8331432017\n",
      "    episode_reward_mean: -192436.70253924755\n",
      "    episode_reward_min: -199022.56676395136\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -191760.57104120395\n",
      "      - -199022.56676395136\n",
      "      - -191742.45579254426\n",
      "      - -191749.19187564193\n",
      "      - -192690.10574365297\n",
      "      - -191593.5135000157\n",
      "      - -193016.01968535432\n",
      "      - -189787.33310439615\n",
      "      - -192369.89488227596\n",
      "      - -192427.22711076957\n",
      "      - -190491.99736582223\n",
      "      - -194085.0013059128\n",
      "      - -192808.33304932088\n",
      "      - -192994.8142937613\n",
      "      - -191513.57728096683\n",
      "      - -193525.06037631928\n",
      "      - -192113.3804687874\n",
      "      - -191636.3163211734\n",
      "      - -195502.66256601168\n",
      "      - -193024.03714206596\n",
      "      - -190770.78746557736\n",
      "      - -193299.4766151861\n",
      "      - -191457.3042582645\n",
      "      - -191552.82844130925\n",
      "      - -193426.8800121962\n",
      "      - -192280.68357533985\n",
      "      - -192396.37735020526\n",
      "      - -190645.6360073698\n",
      "      - -193369.56531800338\n",
      "      - -191161.03912887265\n",
      "      - -192903.38876442492\n",
      "      - -192347.7809222049\n",
      "      - -194270.5683997134\n",
      "      - -192974.20797605565\n",
      "      - -192081.1798673688\n",
      "      - -191635.31997662626\n",
      "      - -193254.242206183\n",
      "      - -194315.8384680056\n",
      "      - -191793.64726033056\n",
      "      - -192302.69793167702\n",
      "      - -194041.80969987012\n",
      "      - -189890.04751991792\n",
      "      - -189709.11980737356\n",
      "      - -193261.93441562392\n",
      "      - -191932.1408118533\n",
      "      - -189456.77948849415\n",
      "      - -192814.47623235287\n",
      "      - -192677.49805512396\n",
      "      - -191564.06915822977\n",
      "      - -195568.39935267487\n",
      "      - -191292.18992259185\n",
      "      - -191385.6046128178\n",
      "      - -192657.0827029891\n",
      "      - -192531.72472854704\n",
      "      - -192770.45663341938\n",
      "      - -191712.54170441945\n",
      "      - -192900.7644897455\n",
      "      - -191066.24814459652\n",
      "      - -194510.05948021892\n",
      "      - -191173.37392648304\n",
      "      - -191066.50688652036\n",
      "      - -192857.82440168568\n",
      "      - -194599.8971177782\n",
      "      - -191655.5513863316\n",
      "      - -191198.98031017362\n",
      "      - -190290.79871827917\n",
      "      - -191429.05292871885\n",
      "      - -194538.74492035375\n",
      "      - -193666.6372305328\n",
      "      - -190534.87567592633\n",
      "      - -192553.20470400117\n",
      "      - -191298.8305242589\n",
      "      - -193951.9272214154\n",
      "      - -193364.8265643157\n",
      "      - -191648.92957889207\n",
      "      - -191733.95692304804\n",
      "      - -195347.84410453518\n",
      "      - -193137.1330499258\n",
      "      - -192277.67454864993\n",
      "      - -189369.8331432017\n",
      "      - -191902.02124288824\n",
      "      - -192021.1534988619\n",
      "      - -194039.53939478772\n",
      "      - -191846.72887464473\n",
      "      - -191674.95429695485\n",
      "      - -191743.91559832782\n",
      "      - -192549.44799424233\n",
      "      - -190847.34386236887\n",
      "      - -192897.8116233142\n",
      "      - -194970.99856578358\n",
      "      - -193110.05541929268\n",
      "      - -191724.42886434591\n",
      "      - -194247.3111256787\n",
      "      - -194106.6524206314\n",
      "      - -193745.79503347105\n",
      "      - -193322.93780809952\n",
      "      - -190375.66486761393\n",
      "      - -190082.44690233137\n",
      "      - -195502.05493740208\n",
      "      - -191426.13115296143\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09406021225541071\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46723758160349815\n",
      "      mean_inference_ms: 0.9693332982946649\n",
      "      mean_raw_obs_processing_ms: 0.13435363064553957\n",
      "  time_since_restore: 2171.714976787567\n",
      "  time_this_iter_s: 8.899564027786255\n",
      "  time_total_s: 2171.714976787567\n",
      "  timers:\n",
      "    learn_throughput: 129002.665\n",
      "    learn_time_ms: 495.99\n",
      "    load_throughput: 22422889.012\n",
      "    load_time_ms: 2.854\n",
      "    training_iteration_time_ms: 9279.833\n",
      "    update_time_ms: 4.315\n",
      "  timestamp: 1665850924\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 14524368\n",
      "  training_iteration: 227\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:22:10 (running for 00:36:44.42)<br>Memory usage on this node: 13.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   227</td><td style=\"text-align: right;\">         2171.71</td><td style=\"text-align: right;\">14524368</td><td style=\"text-align: right;\"> -192437</td><td style=\"text-align: right;\">             -189370</td><td style=\"text-align: right;\">             -199023</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 14588352\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 14588352\n",
      "    num_agent_steps_trained: 14588352\n",
      "    num_env_steps_sampled: 14588352\n",
      "    num_env_steps_trained: 14588352\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-22-14\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -189369.8331432017\n",
      "  episode_reward_mean: -192264.2466671214\n",
      "  episode_reward_min: -202898.54026271947\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 14580\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.103538990020752\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0008636124548502266\n",
      "          model: {}\n",
      "          policy_loss: 0.005975666455924511\n",
      "          total_loss: 10.005838394165039\n",
      "          vf_explained_var: -2.176042634971509e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 14588352\n",
      "    num_agent_steps_trained: 14588352\n",
      "    num_env_steps_sampled: 14588352\n",
      "    num_env_steps_trained: 14588352\n",
      "  iterations_since_restore: 228\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 14588352\n",
      "  num_agent_steps_trained: 14588352\n",
      "  num_env_steps_sampled: 14588352\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 14588352\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.86153846153846\n",
      "    ram_util_percent: 89.57692307692308\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09401954847760412\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46722462330409137\n",
      "    mean_inference_ms: 0.9690518267130992\n",
      "    mean_raw_obs_processing_ms: 0.1343291424691924\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -189369.8331432017\n",
      "    episode_reward_mean: -192264.2466671214\n",
      "    episode_reward_min: -202898.54026271947\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -191066.50688652036\n",
      "      - -192857.82440168568\n",
      "      - -194599.8971177782\n",
      "      - -191655.5513863316\n",
      "      - -191198.98031017362\n",
      "      - -190290.79871827917\n",
      "      - -191429.05292871885\n",
      "      - -194538.74492035375\n",
      "      - -193666.6372305328\n",
      "      - -190534.87567592633\n",
      "      - -192553.20470400117\n",
      "      - -191298.8305242589\n",
      "      - -193951.9272214154\n",
      "      - -193364.8265643157\n",
      "      - -191648.92957889207\n",
      "      - -191733.95692304804\n",
      "      - -195347.84410453518\n",
      "      - -193137.1330499258\n",
      "      - -192277.67454864993\n",
      "      - -189369.8331432017\n",
      "      - -191902.02124288824\n",
      "      - -192021.1534988619\n",
      "      - -194039.53939478772\n",
      "      - -191846.72887464473\n",
      "      - -191674.95429695485\n",
      "      - -191743.91559832782\n",
      "      - -192549.44799424233\n",
      "      - -190847.34386236887\n",
      "      - -192897.8116233142\n",
      "      - -194970.99856578358\n",
      "      - -193110.05541929268\n",
      "      - -191724.42886434591\n",
      "      - -194247.3111256787\n",
      "      - -194106.6524206314\n",
      "      - -193745.79503347105\n",
      "      - -193322.93780809952\n",
      "      - -190375.66486761393\n",
      "      - -190082.44690233137\n",
      "      - -195502.05493740208\n",
      "      - -191426.13115296143\n",
      "      - -192144.51692939186\n",
      "      - -189993.68131190183\n",
      "      - -191247.50537695808\n",
      "      - -194211.51209582193\n",
      "      - -191507.31868034508\n",
      "      - -193264.25887594878\n",
      "      - -192296.9315871932\n",
      "      - -194360.00504689707\n",
      "      - -192371.3245557857\n",
      "      - -191916.51946973172\n",
      "      - -193371.46739862103\n",
      "      - -192524.05055054597\n",
      "      - -191571.92012108437\n",
      "      - -191475.83558662247\n",
      "      - -191724.00940017568\n",
      "      - -189449.43656234082\n",
      "      - -191193.33401306008\n",
      "      - -192985.26903067928\n",
      "      - -192640.08392790836\n",
      "      - -192939.73994028388\n",
      "      - -191957.43525366028\n",
      "      - -192074.95696113413\n",
      "      - -192203.20628391806\n",
      "      - -193070.06127608198\n",
      "      - -190319.73874494282\n",
      "      - -191227.00536050493\n",
      "      - -192238.9559601932\n",
      "      - -190058.30840289625\n",
      "      - -192291.3197059729\n",
      "      - -191964.5131973984\n",
      "      - -192728.79368621073\n",
      "      - -191801.34362429281\n",
      "      - -194260.03426115535\n",
      "      - -190888.13171324178\n",
      "      - -193770.81606041067\n",
      "      - -190337.9627829311\n",
      "      - -191240.08916082198\n",
      "      - -191582.75695216452\n",
      "      - -190427.4566249784\n",
      "      - -194001.18328776959\n",
      "      - -192630.02883233872\n",
      "      - -192363.05030346755\n",
      "      - -192451.77381740636\n",
      "      - -194710.0988462228\n",
      "      - -191822.4594286189\n",
      "      - -192149.62904275244\n",
      "      - -191989.5631971654\n",
      "      - -190964.36642361304\n",
      "      - -193985.07198871532\n",
      "      - -202898.54026271947\n",
      "      - -189633.99527661267\n",
      "      - -190963.04512517867\n",
      "      - -192018.25624887762\n",
      "      - -190999.1096185654\n",
      "      - -192210.137933247\n",
      "      - -190086.39642945462\n",
      "      - -190883.81540379094\n",
      "      - -191837.05872986602\n",
      "      - -191078.66806510458\n",
      "      - -190456.38855390108\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09401954847760412\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46722462330409137\n",
      "      mean_inference_ms: 0.9690518267130992\n",
      "      mean_raw_obs_processing_ms: 0.1343291424691924\n",
      "  time_since_restore: 2181.0528316497803\n",
      "  time_this_iter_s: 9.337854862213135\n",
      "  time_total_s: 2181.0528316497803\n",
      "  timers:\n",
      "    learn_throughput: 128705.348\n",
      "    learn_time_ms: 497.136\n",
      "    load_throughput: 22311411.183\n",
      "    load_time_ms: 2.868\n",
      "    training_iteration_time_ms: 9298.399\n",
      "    update_time_ms: 4.419\n",
      "  timestamp: 1665850934\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 14588352\n",
      "  training_iteration: 228\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:22:19 (running for 00:36:53.85)<br>Memory usage on this node: 13.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   228</td><td style=\"text-align: right;\">         2181.05</td><td style=\"text-align: right;\">14588352</td><td style=\"text-align: right;\"> -192264</td><td style=\"text-align: right;\">             -189370</td><td style=\"text-align: right;\">             -202899</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 14652336\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 14652336\n",
      "    num_agent_steps_trained: 14652336\n",
      "    num_env_steps_sampled: 14652336\n",
      "    num_env_steps_trained: 14652336\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-22-23\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -189053.95255389292\n",
      "  episode_reward_mean: -192469.8876337903\n",
      "  episode_reward_min: -202898.54026271947\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 14652\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1015119552612305\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.000926572538446635\n",
      "          model: {}\n",
      "          policy_loss: -0.002419488737359643\n",
      "          total_loss: 9.997455596923828\n",
      "          vf_explained_var: -2.932926967957883e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 14652336\n",
      "    num_agent_steps_trained: 14652336\n",
      "    num_env_steps_sampled: 14652336\n",
      "    num_env_steps_trained: 14652336\n",
      "  iterations_since_restore: 229\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 14652336\n",
      "  num_agent_steps_trained: 14652336\n",
      "  num_env_steps_sampled: 14652336\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 14652336\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 80.73076923076921\n",
      "    ram_util_percent: 89.6\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09403273985912765\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46709922561121175\n",
      "    mean_inference_ms: 0.9688369680735122\n",
      "    mean_raw_obs_processing_ms: 0.13410914704295251\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -189053.95255389292\n",
      "    episode_reward_mean: -192469.8876337903\n",
      "    episode_reward_min: -202898.54026271947\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -194260.03426115535\n",
      "      - -190888.13171324178\n",
      "      - -193770.81606041067\n",
      "      - -190337.9627829311\n",
      "      - -191240.08916082198\n",
      "      - -191582.75695216452\n",
      "      - -190427.4566249784\n",
      "      - -194001.18328776959\n",
      "      - -192630.02883233872\n",
      "      - -192363.05030346755\n",
      "      - -192451.77381740636\n",
      "      - -194710.0988462228\n",
      "      - -191822.4594286189\n",
      "      - -192149.62904275244\n",
      "      - -191989.5631971654\n",
      "      - -190964.36642361304\n",
      "      - -193985.07198871532\n",
      "      - -202898.54026271947\n",
      "      - -189633.99527661267\n",
      "      - -190963.04512517867\n",
      "      - -192018.25624887762\n",
      "      - -190999.1096185654\n",
      "      - -192210.137933247\n",
      "      - -190086.39642945462\n",
      "      - -190883.81540379094\n",
      "      - -191837.05872986602\n",
      "      - -191078.66806510458\n",
      "      - -190456.38855390108\n",
      "      - -193288.62680727456\n",
      "      - -192952.6642354232\n",
      "      - -189053.95255389292\n",
      "      - -191009.8271479751\n",
      "      - -191458.7153582911\n",
      "      - -192330.4675030332\n",
      "      - -190932.89214021066\n",
      "      - -190429.34285409044\n",
      "      - -192913.48295006924\n",
      "      - -193422.24629899353\n",
      "      - -192185.96053275463\n",
      "      - -189917.73643597122\n",
      "      - -191938.23984263913\n",
      "      - -191819.04052558992\n",
      "      - -189288.3456964094\n",
      "      - -194038.6156851042\n",
      "      - -193943.43111680498\n",
      "      - -191898.4555272556\n",
      "      - -192059.09685553482\n",
      "      - -193674.75369115674\n",
      "      - -192672.07720921055\n",
      "      - -191824.38155656346\n",
      "      - -193420.44902375623\n",
      "      - -194568.48127194616\n",
      "      - -191290.9427366391\n",
      "      - -191466.21859215747\n",
      "      - -189338.32658346128\n",
      "      - -192691.13026969618\n",
      "      - -190381.73260093608\n",
      "      - -193078.8410189392\n",
      "      - -191545.80106190787\n",
      "      - -201142.661352824\n",
      "      - -193949.4976937795\n",
      "      - -194512.0300372033\n",
      "      - -193147.97782860653\n",
      "      - -193731.28954836863\n",
      "      - -192356.78965730916\n",
      "      - -194043.53339466444\n",
      "      - -190512.96786672706\n",
      "      - -193512.62337602893\n",
      "      - -191599.9651206926\n",
      "      - -190320.22700209115\n",
      "      - -191507.3784308252\n",
      "      - -192914.2398991994\n",
      "      - -192013.28910960088\n",
      "      - -193170.13668380617\n",
      "      - -192714.3003372018\n",
      "      - -194998.36633107616\n",
      "      - -191283.1825777378\n",
      "      - -195868.33650419046\n",
      "      - -193003.07703621738\n",
      "      - -191305.93452330143\n",
      "      - -192016.84174943718\n",
      "      - -190732.67911648963\n",
      "      - -193247.33823740852\n",
      "      - -193282.1751250724\n",
      "      - -192161.3787695001\n",
      "      - -190339.92532757722\n",
      "      - -193269.57466224802\n",
      "      - -194260.42308093875\n",
      "      - -193004.51520106554\n",
      "      - -192552.36591984492\n",
      "      - -192757.4680749782\n",
      "      - -196825.56842935827\n",
      "      - -192314.6892775436\n",
      "      - -193760.65709658622\n",
      "      - -194243.57454792294\n",
      "      - -191195.42295439146\n",
      "      - -191553.74570691842\n",
      "      - -190794.0649081783\n",
      "      - -192022.6849642417\n",
      "      - -195571.70586309492\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09403273985912765\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46709922561121175\n",
      "      mean_inference_ms: 0.9688369680735122\n",
      "      mean_raw_obs_processing_ms: 0.13410914704295251\n",
      "  time_since_restore: 2190.2105207443237\n",
      "  time_this_iter_s: 9.157689094543457\n",
      "  time_total_s: 2190.2105207443237\n",
      "  timers:\n",
      "    learn_throughput: 129357.608\n",
      "    learn_time_ms: 494.629\n",
      "    load_throughput: 22235986.705\n",
      "    load_time_ms: 2.877\n",
      "    training_iteration_time_ms: 9253.928\n",
      "    update_time_ms: 4.351\n",
      "  timestamp: 1665850943\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 14652336\n",
      "  training_iteration: 229\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:22:28 (running for 00:37:03.21)<br>Memory usage on this node: 13.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   229</td><td style=\"text-align: right;\">         2190.21</td><td style=\"text-align: right;\">14652336</td><td style=\"text-align: right;\"> -192470</td><td style=\"text-align: right;\">             -189054</td><td style=\"text-align: right;\">             -202899</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 14716320\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 14716320\n",
      "    num_agent_steps_trained: 14716320\n",
      "    num_env_steps_sampled: 14716320\n",
      "    num_env_steps_trained: 14716320\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-22-33\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -189252.35264222167\n",
      "  episode_reward_mean: -192544.73253258097\n",
      "  episode_reward_min: -196825.56842935827\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 14712\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0981693267822266\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0005401559756137431\n",
      "          model: {}\n",
      "          policy_loss: 0.00532532949000597\n",
      "          total_loss: 10.005125045776367\n",
      "          vf_explained_var: -3.311369312086754e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 14716320\n",
      "    num_agent_steps_trained: 14716320\n",
      "    num_env_steps_sampled: 14716320\n",
      "    num_env_steps_trained: 14716320\n",
      "  iterations_since_restore: 230\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 14716320\n",
      "  num_agent_steps_trained: 14716320\n",
      "  num_env_steps_sampled: 14716320\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 14716320\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 87.28571428571429\n",
      "    ram_util_percent: 89.5857142857143\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09409123157754713\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4670899269971725\n",
      "    mean_inference_ms: 0.9691057323169887\n",
      "    mean_raw_obs_processing_ms: 0.13428823958884908\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -189252.35264222167\n",
      "    episode_reward_mean: -192544.73253258097\n",
      "    episode_reward_min: -196825.56842935827\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -193949.4976937795\n",
      "      - -194512.0300372033\n",
      "      - -193147.97782860653\n",
      "      - -193731.28954836863\n",
      "      - -192356.78965730916\n",
      "      - -194043.53339466444\n",
      "      - -190512.96786672706\n",
      "      - -193512.62337602893\n",
      "      - -191599.9651206926\n",
      "      - -190320.22700209115\n",
      "      - -191507.3784308252\n",
      "      - -192914.2398991994\n",
      "      - -192013.28910960088\n",
      "      - -193170.13668380617\n",
      "      - -192714.3003372018\n",
      "      - -194998.36633107616\n",
      "      - -191283.1825777378\n",
      "      - -195868.33650419046\n",
      "      - -193003.07703621738\n",
      "      - -191305.93452330143\n",
      "      - -192016.84174943718\n",
      "      - -190732.67911648963\n",
      "      - -193247.33823740852\n",
      "      - -193282.1751250724\n",
      "      - -192161.3787695001\n",
      "      - -190339.92532757722\n",
      "      - -193269.57466224802\n",
      "      - -194260.42308093875\n",
      "      - -193004.51520106554\n",
      "      - -192552.36591984492\n",
      "      - -192757.4680749782\n",
      "      - -196825.56842935827\n",
      "      - -192314.6892775436\n",
      "      - -193760.65709658622\n",
      "      - -194243.57454792294\n",
      "      - -191195.42295439146\n",
      "      - -191553.74570691842\n",
      "      - -190794.0649081783\n",
      "      - -192022.6849642417\n",
      "      - -195571.70586309492\n",
      "      - -190465.99321646785\n",
      "      - -192779.02231058362\n",
      "      - -193807.8809704553\n",
      "      - -194572.80304042733\n",
      "      - -191450.3792834399\n",
      "      - -192461.50513374436\n",
      "      - -190451.721666598\n",
      "      - -193708.26441359703\n",
      "      - -192005.33708667816\n",
      "      - -190613.85039527516\n",
      "      - -191643.71394596164\n",
      "      - -194720.47730031834\n",
      "      - -192401.8168928595\n",
      "      - -192353.10568659517\n",
      "      - -191226.26700847739\n",
      "      - -192045.25057188072\n",
      "      - -192713.20591585533\n",
      "      - -191579.16286264427\n",
      "      - -195670.62932314162\n",
      "      - -191871.82889242322\n",
      "      - -193733.24298012067\n",
      "      - -190985.4476774653\n",
      "      - -192327.88131822014\n",
      "      - -192193.3712021648\n",
      "      - -193860.62863603453\n",
      "      - -192555.3087131132\n",
      "      - -192378.83922421138\n",
      "      - -191920.64221894107\n",
      "      - -191032.4647716463\n",
      "      - -192226.06310798484\n",
      "      - -193236.98474591356\n",
      "      - -189860.08574963274\n",
      "      - -193928.0521821897\n",
      "      - -192952.723533301\n",
      "      - -191421.86846618942\n",
      "      - -193485.10461208614\n",
      "      - -194705.30652786375\n",
      "      - -192147.70002802068\n",
      "      - -191193.45933160078\n",
      "      - -194201.12077048738\n",
      "      - -190699.95415495159\n",
      "      - -192037.6793103518\n",
      "      - -191140.58635555682\n",
      "      - -193800.7398042603\n",
      "      - -191609.07684795427\n",
      "      - -191845.1196898758\n",
      "      - -194593.84416474306\n",
      "      - -191915.71639312172\n",
      "      - -190618.83471569893\n",
      "      - -193170.01435744445\n",
      "      - -191562.69971962573\n",
      "      - -193129.71488533425\n",
      "      - -192915.38006157163\n",
      "      - -191577.148922735\n",
      "      - -191055.29360988742\n",
      "      - -193421.3900939454\n",
      "      - -191250.38216135086\n",
      "      - -193047.43119373865\n",
      "      - -189252.35264222167\n",
      "      - -194569.44048769327\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09409123157754713\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4670899269971725\n",
      "      mean_inference_ms: 0.9691057323169887\n",
      "      mean_raw_obs_processing_ms: 0.13428823958884908\n",
      "  time_since_restore: 2200.3406109809875\n",
      "  time_this_iter_s: 10.130090236663818\n",
      "  time_total_s: 2200.3406109809875\n",
      "  timers:\n",
      "    learn_throughput: 131150.934\n",
      "    learn_time_ms: 487.865\n",
      "    load_throughput: 22226410.404\n",
      "    load_time_ms: 2.879\n",
      "    training_iteration_time_ms: 9359.927\n",
      "    update_time_ms: 4.226\n",
      "  timestamp: 1665850953\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 14716320\n",
      "  training_iteration: 230\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:22:38 (running for 00:37:12.99)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   230</td><td style=\"text-align: right;\">         2200.34</td><td style=\"text-align: right;\">14716320</td><td style=\"text-align: right;\"> -192545</td><td style=\"text-align: right;\">             -189252</td><td style=\"text-align: right;\">             -196826</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 14780304\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 14780304\n",
      "    num_agent_steps_trained: 14780304\n",
      "    num_env_steps_sampled: 14780304\n",
      "    num_env_steps_trained: 14780304\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-22-43\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -189252.35264222167\n",
      "  episode_reward_mean: -192570.863228437\n",
      "  episode_reward_min: -197007.6983980954\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 14772\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0977134704589844\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0012515957932919264\n",
      "          model: {}\n",
      "          policy_loss: 0.006794318091124296\n",
      "          total_loss: 10.006735801696777\n",
      "          vf_explained_var: -2.2706531765948057e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 14780304\n",
      "    num_agent_steps_trained: 14780304\n",
      "    num_env_steps_sampled: 14780304\n",
      "    num_env_steps_trained: 14780304\n",
      "  iterations_since_restore: 231\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 14780304\n",
      "  num_agent_steps_trained: 14780304\n",
      "  num_env_steps_sampled: 14780304\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 14780304\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.87857142857142\n",
      "    ram_util_percent: 89.35714285714288\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09408389799760475\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4672227873892691\n",
      "    mean_inference_ms: 0.9691818271764693\n",
      "    mean_raw_obs_processing_ms: 0.13431362880421896\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -189252.35264222167\n",
      "    episode_reward_mean: -192570.863228437\n",
      "    episode_reward_min: -197007.6983980954\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -193733.24298012067\n",
      "      - -190985.4476774653\n",
      "      - -192327.88131822014\n",
      "      - -192193.3712021648\n",
      "      - -193860.62863603453\n",
      "      - -192555.3087131132\n",
      "      - -192378.83922421138\n",
      "      - -191920.64221894107\n",
      "      - -191032.4647716463\n",
      "      - -192226.06310798484\n",
      "      - -193236.98474591356\n",
      "      - -189860.08574963274\n",
      "      - -193928.0521821897\n",
      "      - -192952.723533301\n",
      "      - -191421.86846618942\n",
      "      - -193485.10461208614\n",
      "      - -194705.30652786375\n",
      "      - -192147.70002802068\n",
      "      - -191193.45933160078\n",
      "      - -194201.12077048738\n",
      "      - -190699.95415495159\n",
      "      - -192037.6793103518\n",
      "      - -191140.58635555682\n",
      "      - -193800.7398042603\n",
      "      - -191609.07684795427\n",
      "      - -191845.1196898758\n",
      "      - -194593.84416474306\n",
      "      - -191915.71639312172\n",
      "      - -190618.83471569893\n",
      "      - -193170.01435744445\n",
      "      - -191562.69971962573\n",
      "      - -193129.71488533425\n",
      "      - -192915.38006157163\n",
      "      - -191577.148922735\n",
      "      - -191055.29360988742\n",
      "      - -193421.3900939454\n",
      "      - -191250.38216135086\n",
      "      - -193047.43119373865\n",
      "      - -189252.35264222167\n",
      "      - -194569.44048769327\n",
      "      - -190713.0402220693\n",
      "      - -192969.90897505436\n",
      "      - -195466.5232484353\n",
      "      - -195098.30417510692\n",
      "      - -194105.1469180758\n",
      "      - -193741.22736143036\n",
      "      - -191434.32154863045\n",
      "      - -192388.24075718128\n",
      "      - -190398.5507842494\n",
      "      - -191997.59498963977\n",
      "      - -192008.92138730572\n",
      "      - -191427.53378767872\n",
      "      - -194410.9537312734\n",
      "      - -193762.50258904972\n",
      "      - -192452.2820566277\n",
      "      - -194115.24777351716\n",
      "      - -192809.38837584533\n",
      "      - -193445.5576780993\n",
      "      - -193318.32345730803\n",
      "      - -192771.64194118395\n",
      "      - -192672.67817548287\n",
      "      - -190236.8901927271\n",
      "      - -193236.15602324827\n",
      "      - -190920.82938853337\n",
      "      - -191298.51433463336\n",
      "      - -191805.2437830125\n",
      "      - -193684.94347223564\n",
      "      - -192933.34633390725\n",
      "      - -192257.6368613265\n",
      "      - -192724.7769567469\n",
      "      - -191609.3531550223\n",
      "      - -190280.65365827648\n",
      "      - -191871.57835302106\n",
      "      - -194096.5500345452\n",
      "      - -192775.21397389565\n",
      "      - -191626.16804223473\n",
      "      - -191690.02353732538\n",
      "      - -192897.27212952467\n",
      "      - -197007.6983980954\n",
      "      - -194828.6063218581\n",
      "      - -194098.61621002454\n",
      "      - -193588.05168136908\n",
      "      - -193124.60479260935\n",
      "      - -192550.45148743317\n",
      "      - -191931.02331851498\n",
      "      - -193105.30792238563\n",
      "      - -191614.3086979633\n",
      "      - -193680.75527212088\n",
      "      - -195386.15286821438\n",
      "      - -192597.49997421567\n",
      "      - -192553.03988676312\n",
      "      - -191311.01769586996\n",
      "      - -193301.81639359493\n",
      "      - -192339.37094548668\n",
      "      - -192214.97498902844\n",
      "      - -193205.2274287118\n",
      "      - -191016.09739308635\n",
      "      - -192459.44797424698\n",
      "      - -191866.45790034553\n",
      "      - -192293.6597590533\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09408389799760475\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4672227873892691\n",
      "      mean_inference_ms: 0.9691818271764693\n",
      "      mean_raw_obs_processing_ms: 0.13431362880421896\n",
      "  time_since_restore: 2210.053022146225\n",
      "  time_this_iter_s: 9.712411165237427\n",
      "  time_total_s: 2210.053022146225\n",
      "  timers:\n",
      "    learn_throughput: 130319.377\n",
      "    learn_time_ms: 490.978\n",
      "    load_throughput: 22052718.058\n",
      "    load_time_ms: 2.901\n",
      "    training_iteration_time_ms: 9383.243\n",
      "    update_time_ms: 4.173\n",
      "  timestamp: 1665850963\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 14780304\n",
      "  training_iteration: 231\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:22:48 (running for 00:37:22.97)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   231</td><td style=\"text-align: right;\">         2210.05</td><td style=\"text-align: right;\">14780304</td><td style=\"text-align: right;\"> -192571</td><td style=\"text-align: right;\">             -189252</td><td style=\"text-align: right;\">             -197008</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 14844288\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 14844288\n",
      "    num_agent_steps_trained: 14844288\n",
      "    num_env_steps_sampled: 14844288\n",
      "    num_env_steps_trained: 14844288\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-22-53\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -189865.4716155863\n",
      "  episode_reward_mean: -192671.23414440508\n",
      "  episode_reward_min: -206526.9693160583\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 14844\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.091932773590088\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0005954584339633584\n",
      "          model: {}\n",
      "          policy_loss: -0.0021823649294674397\n",
      "          total_loss: 9.997627258300781\n",
      "          vf_explained_var: -3.216758770463457e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 14844288\n",
      "    num_agent_steps_trained: 14844288\n",
      "    num_env_steps_sampled: 14844288\n",
      "    num_env_steps_trained: 14844288\n",
      "  iterations_since_restore: 232\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 14844288\n",
      "  num_agent_steps_trained: 14844288\n",
      "  num_env_steps_sampled: 14844288\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 14844288\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 80.88571428571429\n",
      "    ram_util_percent: 89.52142857142859\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09408584980149719\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4672473678300644\n",
      "    mean_inference_ms: 0.9691851020155252\n",
      "    mean_raw_obs_processing_ms: 0.13413901125233732\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -189865.4716155863\n",
      "    episode_reward_mean: -192671.23414440508\n",
      "    episode_reward_min: -206526.9693160583\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -191871.57835302106\n",
      "      - -194096.5500345452\n",
      "      - -192775.21397389565\n",
      "      - -191626.16804223473\n",
      "      - -191690.02353732538\n",
      "      - -192897.27212952467\n",
      "      - -197007.6983980954\n",
      "      - -194828.6063218581\n",
      "      - -194098.61621002454\n",
      "      - -193588.05168136908\n",
      "      - -193124.60479260935\n",
      "      - -192550.45148743317\n",
      "      - -191931.02331851498\n",
      "      - -193105.30792238563\n",
      "      - -191614.3086979633\n",
      "      - -193680.75527212088\n",
      "      - -195386.15286821438\n",
      "      - -192597.49997421567\n",
      "      - -192553.03988676312\n",
      "      - -191311.01769586996\n",
      "      - -193301.81639359493\n",
      "      - -192339.37094548668\n",
      "      - -192214.97498902844\n",
      "      - -193205.2274287118\n",
      "      - -191016.09739308635\n",
      "      - -192459.44797424698\n",
      "      - -191866.45790034553\n",
      "      - -192293.6597590533\n",
      "      - -194639.0052448034\n",
      "      - -191865.75280364428\n",
      "      - -191991.15912907867\n",
      "      - -191464.90896116963\n",
      "      - -193274.48960175822\n",
      "      - -192312.72274445984\n",
      "      - -193355.94654824198\n",
      "      - -192358.09693591655\n",
      "      - -190523.9947055349\n",
      "      - -192969.71501296086\n",
      "      - -190529.2097298781\n",
      "      - -191162.687533034\n",
      "      - -192403.34218358234\n",
      "      - -191559.75945283612\n",
      "      - -193721.36779178138\n",
      "      - -191016.8228684029\n",
      "      - -191999.23055154452\n",
      "      - -191768.36340045946\n",
      "      - -192231.79668418065\n",
      "      - -193088.62725556415\n",
      "      - -190582.28121648118\n",
      "      - -192769.88600608817\n",
      "      - -191942.76675166606\n",
      "      - -194256.798102497\n",
      "      - -194790.05646529896\n",
      "      - -192741.01110812117\n",
      "      - -192182.97900380503\n",
      "      - -192427.77572423685\n",
      "      - -192112.09979580593\n",
      "      - -190593.08337337588\n",
      "      - -193657.41624117902\n",
      "      - -192299.86934302494\n",
      "      - -194817.0493718718\n",
      "      - -191466.88324265863\n",
      "      - -191138.3250082757\n",
      "      - -189927.579519361\n",
      "      - -195163.89902789507\n",
      "      - -192536.37725240455\n",
      "      - -193427.03579776242\n",
      "      - -193005.23093168755\n",
      "      - -190890.26208113326\n",
      "      - -189973.05069776461\n",
      "      - -190576.62429520473\n",
      "      - -193468.10065935925\n",
      "      - -192227.2553379561\n",
      "      - -192726.9427332366\n",
      "      - -190206.89735547398\n",
      "      - -206526.9693160583\n",
      "      - -193282.70995778014\n",
      "      - -191783.28491360706\n",
      "      - -193512.81620518974\n",
      "      - -191641.6085596356\n",
      "      - -193425.92415432906\n",
      "      - -195328.58349449083\n",
      "      - -191829.69893410077\n",
      "      - -192657.4934405697\n",
      "      - -191934.44275041393\n",
      "      - -194992.25785009976\n",
      "      - -189873.90848548023\n",
      "      - -194073.64068318493\n",
      "      - -189865.4716155863\n",
      "      - -190027.65772007048\n",
      "      - -192873.9143122882\n",
      "      - -194182.19380695937\n",
      "      - -192108.9045695345\n",
      "      - -192718.40330544853\n",
      "      - -193955.96678485457\n",
      "      - -193855.772610185\n",
      "      - -192526.06542939768\n",
      "      - -191307.65680935423\n",
      "      - -191401.9242891264\n",
      "      - -194260.61547876385\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09408584980149719\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4672473678300644\n",
      "      mean_inference_ms: 0.9691851020155252\n",
      "      mean_raw_obs_processing_ms: 0.13413901125233732\n",
      "  time_since_restore: 2219.729290485382\n",
      "  time_this_iter_s: 9.676268339157104\n",
      "  time_total_s: 2219.729290485382\n",
      "  timers:\n",
      "    learn_throughput: 128734.47\n",
      "    learn_time_ms: 497.023\n",
      "    load_throughput: 22221257.35\n",
      "    load_time_ms: 2.879\n",
      "    training_iteration_time_ms: 9387.731\n",
      "    update_time_ms: 4.049\n",
      "  timestamp: 1665850973\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 14844288\n",
      "  training_iteration: 232\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:22:58 (running for 00:37:33.08)<br>Memory usage on this node: 13.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   232</td><td style=\"text-align: right;\">         2219.73</td><td style=\"text-align: right;\">14844288</td><td style=\"text-align: right;\"> -192671</td><td style=\"text-align: right;\">             -189865</td><td style=\"text-align: right;\">             -206527</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 14908272\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 14908272\n",
      "    num_agent_steps_trained: 14908272\n",
      "    num_env_steps_sampled: 14908272\n",
      "    num_env_steps_trained: 14908272\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-23-02\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -189622.32485737462\n",
      "  episode_reward_mean: -192817.64763421737\n",
      "  episode_reward_min: -206526.9693160583\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 14904\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0880234241485596\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0006712102331221104\n",
      "          model: {}\n",
      "          policy_loss: 0.005983317736536264\n",
      "          total_loss: 10.005807876586914\n",
      "          vf_explained_var: -1.9868215517249155e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 14908272\n",
      "    num_agent_steps_trained: 14908272\n",
      "    num_env_steps_sampled: 14908272\n",
      "    num_env_steps_trained: 14908272\n",
      "  iterations_since_restore: 233\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 14908272\n",
      "  num_agent_steps_trained: 14908272\n",
      "  num_env_steps_sampled: 14908272\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 14908272\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 80.64615384615385\n",
      "    ram_util_percent: 89.63076923076923\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09409429872620426\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.467171141646024\n",
      "    mean_inference_ms: 0.9693476933829956\n",
      "    mean_raw_obs_processing_ms: 0.13428528553937638\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -189622.32485737462\n",
      "    episode_reward_mean: -192817.64763421737\n",
      "    episode_reward_min: -206526.9693160583\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -194817.0493718718\n",
      "      - -191466.88324265863\n",
      "      - -191138.3250082757\n",
      "      - -189927.579519361\n",
      "      - -195163.89902789507\n",
      "      - -192536.37725240455\n",
      "      - -193427.03579776242\n",
      "      - -193005.23093168755\n",
      "      - -190890.26208113326\n",
      "      - -189973.05069776461\n",
      "      - -190576.62429520473\n",
      "      - -193468.10065935925\n",
      "      - -192227.2553379561\n",
      "      - -192726.9427332366\n",
      "      - -190206.89735547398\n",
      "      - -206526.9693160583\n",
      "      - -193282.70995778014\n",
      "      - -191783.28491360706\n",
      "      - -193512.81620518974\n",
      "      - -191641.6085596356\n",
      "      - -193425.92415432906\n",
      "      - -195328.58349449083\n",
      "      - -191829.69893410077\n",
      "      - -192657.4934405697\n",
      "      - -191934.44275041393\n",
      "      - -194992.25785009976\n",
      "      - -189873.90848548023\n",
      "      - -194073.64068318493\n",
      "      - -189865.4716155863\n",
      "      - -190027.65772007048\n",
      "      - -192873.9143122882\n",
      "      - -194182.19380695937\n",
      "      - -192108.9045695345\n",
      "      - -192718.40330544853\n",
      "      - -193955.96678485457\n",
      "      - -193855.772610185\n",
      "      - -192526.06542939768\n",
      "      - -191307.65680935423\n",
      "      - -191401.9242891264\n",
      "      - -194260.61547876385\n",
      "      - -191978.40365406772\n",
      "      - -192444.86033787119\n",
      "      - -191824.56027491714\n",
      "      - -191850.77993313968\n",
      "      - -194056.56946366845\n",
      "      - -190002.07907229528\n",
      "      - -191776.8299694091\n",
      "      - -191828.72975106444\n",
      "      - -195601.87482822308\n",
      "      - -191960.57969920573\n",
      "      - -193113.6939879223\n",
      "      - -191006.45901993717\n",
      "      - -189789.34344011184\n",
      "      - -191795.2310174082\n",
      "      - -191169.0631830207\n",
      "      - -191010.89191042903\n",
      "      - -190542.94946485956\n",
      "      - -193456.0204812705\n",
      "      - -193661.01649588044\n",
      "      - -191386.3423828673\n",
      "      - -191362.13381701458\n",
      "      - -191943.74621061928\n",
      "      - -193177.95215854616\n",
      "      - -190503.3822136875\n",
      "      - -192141.33403258648\n",
      "      - -195604.97582541546\n",
      "      - -192640.78246195635\n",
      "      - -191796.23361748504\n",
      "      - -192810.27409195423\n",
      "      - -191819.58432319525\n",
      "      - -193063.87516780038\n",
      "      - -195493.1434932886\n",
      "      - -191858.66979099475\n",
      "      - -190459.55745683465\n",
      "      - -193137.42123030702\n",
      "      - -203916.5080589911\n",
      "      - -193658.5297398689\n",
      "      - -192502.26483368108\n",
      "      - -195522.35272957775\n",
      "      - -194054.22212515946\n",
      "      - -194096.22940790563\n",
      "      - -193394.12343635855\n",
      "      - -191597.72497437138\n",
      "      - -194843.98689510315\n",
      "      - -192278.0345254489\n",
      "      - -191042.432375454\n",
      "      - -192778.0560993477\n",
      "      - -191138.4471076067\n",
      "      - -191106.33210497865\n",
      "      - -192479.3134311337\n",
      "      - -189622.32485737462\n",
      "      - -192894.7003030012\n",
      "      - -206477.6404241671\n",
      "      - -190689.8951902688\n",
      "      - -191563.53210898378\n",
      "      - -195351.87276494678\n",
      "      - -194272.5465748717\n",
      "      - -192125.30278432177\n",
      "      - -192301.69738809174\n",
      "      - -192487.9501329134\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09409429872620426\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.467171141646024\n",
      "      mean_inference_ms: 0.9693476933829956\n",
      "      mean_raw_obs_processing_ms: 0.13428528553937638\n",
      "  time_since_restore: 2229.1534507274628\n",
      "  time_this_iter_s: 9.424160242080688\n",
      "  time_total_s: 2229.1534507274628\n",
      "  timers:\n",
      "    learn_throughput: 130022.555\n",
      "    learn_time_ms: 492.099\n",
      "    load_throughput: 22173521.423\n",
      "    load_time_ms: 2.886\n",
      "    training_iteration_time_ms: 9382.189\n",
      "    update_time_ms: 4.123\n",
      "  timestamp: 1665850982\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 14908272\n",
      "  training_iteration: 233\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:23:07 (running for 00:37:42.00)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   233</td><td style=\"text-align: right;\">         2229.15</td><td style=\"text-align: right;\">14908272</td><td style=\"text-align: right;\"> -192818</td><td style=\"text-align: right;\">             -189622</td><td style=\"text-align: right;\">             -206527</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 14972256\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 14972256\n",
      "    num_agent_steps_trained: 14972256\n",
      "    num_env_steps_sampled: 14972256\n",
      "    num_env_steps_trained: 14972256\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-23-11\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -189622.32485737462\n",
      "  episode_reward_mean: -192658.83099376544\n",
      "  episode_reward_min: -206477.6404241671\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 14964\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.081996440887451\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0015067653730511665\n",
      "          model: {}\n",
      "          policy_loss: 0.006302772089838982\n",
      "          total_loss: 10.006296157836914\n",
      "          vf_explained_var: -2.2706531765948057e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 14972256\n",
      "    num_agent_steps_trained: 14972256\n",
      "    num_env_steps_sampled: 14972256\n",
      "    num_env_steps_trained: 14972256\n",
      "  iterations_since_restore: 234\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 14972256\n",
      "  num_agent_steps_trained: 14972256\n",
      "  num_env_steps_sampled: 14972256\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 14972256\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.1076923076923\n",
      "    ram_util_percent: 89.5769230769231\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09403678666288987\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46718540263853897\n",
      "    mean_inference_ms: 0.9691831583117844\n",
      "    mean_raw_obs_processing_ms: 0.13426875535726168\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -189622.32485737462\n",
      "    episode_reward_mean: -192658.83099376544\n",
      "    episode_reward_min: -206477.6404241671\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -191362.13381701458\n",
      "      - -191943.74621061928\n",
      "      - -193177.95215854616\n",
      "      - -190503.3822136875\n",
      "      - -192141.33403258648\n",
      "      - -195604.97582541546\n",
      "      - -192640.78246195635\n",
      "      - -191796.23361748504\n",
      "      - -192810.27409195423\n",
      "      - -191819.58432319525\n",
      "      - -193063.87516780038\n",
      "      - -195493.1434932886\n",
      "      - -191858.66979099475\n",
      "      - -190459.55745683465\n",
      "      - -193137.42123030702\n",
      "      - -203916.5080589911\n",
      "      - -193658.5297398689\n",
      "      - -192502.26483368108\n",
      "      - -195522.35272957775\n",
      "      - -194054.22212515946\n",
      "      - -194096.22940790563\n",
      "      - -193394.12343635855\n",
      "      - -191597.72497437138\n",
      "      - -194843.98689510315\n",
      "      - -192278.0345254489\n",
      "      - -191042.432375454\n",
      "      - -192778.0560993477\n",
      "      - -191138.4471076067\n",
      "      - -191106.33210497865\n",
      "      - -192479.3134311337\n",
      "      - -189622.32485737462\n",
      "      - -192894.7003030012\n",
      "      - -206477.6404241671\n",
      "      - -190689.8951902688\n",
      "      - -191563.53210898378\n",
      "      - -195351.87276494678\n",
      "      - -194272.5465748717\n",
      "      - -192125.30278432177\n",
      "      - -192301.69738809174\n",
      "      - -192487.9501329134\n",
      "      - -193072.89739129733\n",
      "      - -194270.2944961303\n",
      "      - -191624.96446965294\n",
      "      - -192426.29769984196\n",
      "      - -191740.4311201434\n",
      "      - -192644.96011373893\n",
      "      - -193443.9696600199\n",
      "      - -192676.37423591324\n",
      "      - -191223.86658746566\n",
      "      - -189806.45694008184\n",
      "      - -190322.49784875373\n",
      "      - -193475.95763425724\n",
      "      - -191358.2997611534\n",
      "      - -193331.96380397514\n",
      "      - -193377.16288075116\n",
      "      - -190887.97321132565\n",
      "      - -193461.85952727785\n",
      "      - -193528.7889829681\n",
      "      - -192183.73942545344\n",
      "      - -191722.4874539271\n",
      "      - -191344.32781557078\n",
      "      - -193408.75183163624\n",
      "      - -191018.35138220355\n",
      "      - -190995.19286572287\n",
      "      - -194981.8315749595\n",
      "      - -191634.59153940895\n",
      "      - -192432.40163710914\n",
      "      - -195649.98711556228\n",
      "      - -192071.59245235397\n",
      "      - -191353.7241970889\n",
      "      - -190531.0130398686\n",
      "      - -191898.8989190669\n",
      "      - -190812.26538996084\n",
      "      - -192304.93904917742\n",
      "      - -193660.28361461984\n",
      "      - -191514.25422035556\n",
      "      - -191188.6285318379\n",
      "      - -192546.09878528997\n",
      "      - -192224.25905162783\n",
      "      - -193878.8255634972\n",
      "      - -191619.7203846325\n",
      "      - -195069.67934442568\n",
      "      - -189761.47964358178\n",
      "      - -192065.28348225635\n",
      "      - -192230.68202824576\n",
      "      - -192176.6359022733\n",
      "      - -192459.868961538\n",
      "      - -190735.33160354168\n",
      "      - -193497.5484640789\n",
      "      - -193611.29003849224\n",
      "      - -193382.44581811538\n",
      "      - -191023.4474437544\n",
      "      - -192410.5485800794\n",
      "      - -190643.57038329335\n",
      "      - -192584.3110901315\n",
      "      - -193371.5141832788\n",
      "      - -191179.21977385035\n",
      "      - -191980.93760931166\n",
      "      - -192791.11790141976\n",
      "      - -191247.9186535818\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09403678666288987\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46718540263853897\n",
      "      mean_inference_ms: 0.9691831583117844\n",
      "      mean_raw_obs_processing_ms: 0.13426875535726168\n",
      "  time_since_restore: 2238.3887705802917\n",
      "  time_this_iter_s: 9.23531985282898\n",
      "  time_total_s: 2238.3887705802917\n",
      "  timers:\n",
      "    learn_throughput: 129089.942\n",
      "    learn_time_ms: 495.654\n",
      "    load_throughput: 21925339.428\n",
      "    load_time_ms: 2.918\n",
      "    training_iteration_time_ms: 9320.621\n",
      "    update_time_ms: 4.091\n",
      "  timestamp: 1665850991\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 14972256\n",
      "  training_iteration: 234\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:23:16 (running for 00:37:51.39)<br>Memory usage on this node: 13.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   234</td><td style=\"text-align: right;\">         2238.39</td><td style=\"text-align: right;\">14972256</td><td style=\"text-align: right;\"> -192659</td><td style=\"text-align: right;\">             -189622</td><td style=\"text-align: right;\">             -206478</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 15036240\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 15036240\n",
      "    num_agent_steps_trained: 15036240\n",
      "    num_env_steps_sampled: 15036240\n",
      "    num_env_steps_trained: 15036240\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-23-20\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -189013.85954612147\n",
      "  episode_reward_mean: -192261.91665790774\n",
      "  episode_reward_min: -195431.4039932223\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 15036\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.082390308380127\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0003391635837033391\n",
      "          model: {}\n",
      "          policy_loss: -0.0025860071182250977\n",
      "          total_loss: 9.997173309326172\n",
      "          vf_explained_var: -1.1353265882974029e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 15036240\n",
      "    num_agent_steps_trained: 15036240\n",
      "    num_env_steps_sampled: 15036240\n",
      "    num_env_steps_trained: 15036240\n",
      "  iterations_since_restore: 235\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 15036240\n",
      "  num_agent_steps_trained: 15036240\n",
      "  num_env_steps_sampled: 15036240\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 15036240\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 80.43846153846154\n",
      "    ram_util_percent: 89.92307692307692\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09401513631564296\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46713039157177555\n",
      "    mean_inference_ms: 0.9689464576069128\n",
      "    mean_raw_obs_processing_ms: 0.13406590858723016\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -189013.85954612147\n",
      "    episode_reward_mean: -192261.91665790774\n",
      "    episode_reward_min: -195431.4039932223\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -190812.26538996084\n",
      "      - -192304.93904917742\n",
      "      - -193660.28361461984\n",
      "      - -191514.25422035556\n",
      "      - -191188.6285318379\n",
      "      - -192546.09878528997\n",
      "      - -192224.25905162783\n",
      "      - -193878.8255634972\n",
      "      - -191619.7203846325\n",
      "      - -195069.67934442568\n",
      "      - -189761.47964358178\n",
      "      - -192065.28348225635\n",
      "      - -192230.68202824576\n",
      "      - -192176.6359022733\n",
      "      - -192459.868961538\n",
      "      - -190735.33160354168\n",
      "      - -193497.5484640789\n",
      "      - -193611.29003849224\n",
      "      - -193382.44581811538\n",
      "      - -191023.4474437544\n",
      "      - -192410.5485800794\n",
      "      - -190643.57038329335\n",
      "      - -192584.3110901315\n",
      "      - -193371.5141832788\n",
      "      - -191179.21977385035\n",
      "      - -191980.93760931166\n",
      "      - -192791.11790141976\n",
      "      - -191247.9186535818\n",
      "      - -191575.17214995105\n",
      "      - -192663.9034398498\n",
      "      - -192972.1482042352\n",
      "      - -192553.3171390686\n",
      "      - -190459.08574498037\n",
      "      - -191017.5879809822\n",
      "      - -191717.87080846116\n",
      "      - -192248.3809464673\n",
      "      - -192332.10075852124\n",
      "      - -192655.5144597911\n",
      "      - -192129.81209959812\n",
      "      - -189741.66469033345\n",
      "      - -195072.53096096686\n",
      "      - -194667.58788867126\n",
      "      - -192052.13519950453\n",
      "      - -192331.05544125382\n",
      "      - -189013.85954612147\n",
      "      - -194145.07630464266\n",
      "      - -189292.59504176013\n",
      "      - -193018.0441030213\n",
      "      - -193266.09961555892\n",
      "      - -190185.91725938467\n",
      "      - -189368.9937273229\n",
      "      - -193274.17445306497\n",
      "      - -192034.6293054603\n",
      "      - -192673.54493055335\n",
      "      - -193271.9655736097\n",
      "      - -193915.74124529667\n",
      "      - -191416.41592559117\n",
      "      - -191625.25354782597\n",
      "      - -193712.6071969796\n",
      "      - -195008.52951126543\n",
      "      - -194616.84071598295\n",
      "      - -192804.67421292316\n",
      "      - -191857.26224360088\n",
      "      - -193463.81694776798\n",
      "      - -191364.85499808064\n",
      "      - -191470.15852539646\n",
      "      - -190697.53058055876\n",
      "      - -193244.70456626845\n",
      "      - -191556.5167045163\n",
      "      - -194254.4818567281\n",
      "      - -193614.43480882698\n",
      "      - -191039.1861849339\n",
      "      - -190227.01372069496\n",
      "      - -191968.89284903687\n",
      "      - -191108.01299378963\n",
      "      - -192755.8328391433\n",
      "      - -189975.5128989538\n",
      "      - -192274.57461921495\n",
      "      - -190823.00702965137\n",
      "      - -192040.12071254032\n",
      "      - -193976.52241915587\n",
      "      - -190153.93410480733\n",
      "      - -191302.90052819095\n",
      "      - -193451.27013541677\n",
      "      - -193605.06235155082\n",
      "      - -192258.34392724073\n",
      "      - -192558.68658161187\n",
      "      - -192975.96274328904\n",
      "      - -191661.91960890597\n",
      "      - -192480.8577458801\n",
      "      - -193390.18251660618\n",
      "      - -192159.79776198848\n",
      "      - -190344.14471476455\n",
      "      - -192694.8466098524\n",
      "      - -193340.3241818592\n",
      "      - -192303.54808293722\n",
      "      - -193273.2180615109\n",
      "      - -191265.03259030648\n",
      "      - -193020.85642672452\n",
      "      - -195431.4039932223\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09401513631564296\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46713039157177555\n",
      "      mean_inference_ms: 0.9689464576069128\n",
      "      mean_raw_obs_processing_ms: 0.13406590858723016\n",
      "  time_since_restore: 2247.6103863716125\n",
      "  time_this_iter_s: 9.2216157913208\n",
      "  time_total_s: 2247.6103863716125\n",
      "  timers:\n",
      "    learn_throughput: 128230.747\n",
      "    learn_time_ms: 498.975\n",
      "    load_throughput: 22087566.224\n",
      "    load_time_ms: 2.897\n",
      "    training_iteration_time_ms: 9327.165\n",
      "    update_time_ms: 4.136\n",
      "  timestamp: 1665851000\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 15036240\n",
      "  training_iteration: 235\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:23:26 (running for 00:38:00.68)<br>Memory usage on this node: 14.0/15.5 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   235</td><td style=\"text-align: right;\">         2247.61</td><td style=\"text-align: right;\">15036240</td><td style=\"text-align: right;\"> -192262</td><td style=\"text-align: right;\">             -189014</td><td style=\"text-align: right;\">             -195431</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 15100224\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 15100224\n",
      "    num_agent_steps_trained: 15100224\n",
      "    num_env_steps_sampled: 15100224\n",
      "    num_env_steps_trained: 15100224\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-23-30\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -188293.3607726563\n",
      "  episode_reward_mean: -192077.73124517195\n",
      "  episode_reward_min: -202618.26805136085\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 15096\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.083049774169922\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00093724305042997\n",
      "          model: {}\n",
      "          policy_loss: 0.00584028847515583\n",
      "          total_loss: 10.005719184875488\n",
      "          vf_explained_var: -1.7029899268550253e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 15100224\n",
      "    num_agent_steps_trained: 15100224\n",
      "    num_env_steps_sampled: 15100224\n",
      "    num_env_steps_trained: 15100224\n",
      "  iterations_since_restore: 236\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 15100224\n",
      "  num_agent_steps_trained: 15100224\n",
      "  num_env_steps_sampled: 15100224\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 15100224\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 85.72307692307692\n",
      "    ram_util_percent: 90.10000000000001\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0940516448825386\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4670646204484998\n",
      "    mean_inference_ms: 0.9690508649928676\n",
      "    mean_raw_obs_processing_ms: 0.13422895667781193\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -188293.3607726563\n",
      "    episode_reward_mean: -192077.73124517195\n",
      "    episode_reward_min: -202618.26805136085\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -194616.84071598295\n",
      "      - -192804.67421292316\n",
      "      - -191857.26224360088\n",
      "      - -193463.81694776798\n",
      "      - -191364.85499808064\n",
      "      - -191470.15852539646\n",
      "      - -190697.53058055876\n",
      "      - -193244.70456626845\n",
      "      - -191556.5167045163\n",
      "      - -194254.4818567281\n",
      "      - -193614.43480882698\n",
      "      - -191039.1861849339\n",
      "      - -190227.01372069496\n",
      "      - -191968.89284903687\n",
      "      - -191108.01299378963\n",
      "      - -192755.8328391433\n",
      "      - -189975.5128989538\n",
      "      - -192274.57461921495\n",
      "      - -190823.00702965137\n",
      "      - -192040.12071254032\n",
      "      - -193976.52241915587\n",
      "      - -190153.93410480733\n",
      "      - -191302.90052819095\n",
      "      - -193451.27013541677\n",
      "      - -193605.06235155082\n",
      "      - -192258.34392724073\n",
      "      - -192558.68658161187\n",
      "      - -192975.96274328904\n",
      "      - -191661.91960890597\n",
      "      - -192480.8577458801\n",
      "      - -193390.18251660618\n",
      "      - -192159.79776198848\n",
      "      - -190344.14471476455\n",
      "      - -192694.8466098524\n",
      "      - -193340.3241818592\n",
      "      - -192303.54808293722\n",
      "      - -193273.2180615109\n",
      "      - -191265.03259030648\n",
      "      - -193020.85642672452\n",
      "      - -195431.4039932223\n",
      "      - -189790.42288337194\n",
      "      - -192394.7743030522\n",
      "      - -193293.40639165012\n",
      "      - -191456.7604071197\n",
      "      - -193365.5846683508\n",
      "      - -196985.26696714055\n",
      "      - -190472.52537126333\n",
      "      - -190175.62493539613\n",
      "      - -188831.87410815642\n",
      "      - -191452.84224128167\n",
      "      - -190181.26333704498\n",
      "      - -190471.44961805022\n",
      "      - -192828.67094895872\n",
      "      - -190636.29310830127\n",
      "      - -190947.88042293227\n",
      "      - -190798.5602392209\n",
      "      - -193320.47790543822\n",
      "      - -192243.53269059752\n",
      "      - -191409.946418593\n",
      "      - -190015.87552370233\n",
      "      - -193012.90648474396\n",
      "      - -191831.22056251834\n",
      "      - -198182.21559971326\n",
      "      - -192111.06939185227\n",
      "      - -190119.23377714536\n",
      "      - -192149.24322431162\n",
      "      - -190239.5750370281\n",
      "      - -190686.50934687824\n",
      "      - -191779.0709564038\n",
      "      - -194745.8897997881\n",
      "      - -191382.93081912905\n",
      "      - -193315.04368377413\n",
      "      - -191170.56910008626\n",
      "      - -190422.58610988187\n",
      "      - -202618.26805136085\n",
      "      - -194450.24160401244\n",
      "      - -194328.53708327396\n",
      "      - -193062.20008308088\n",
      "      - -191931.91530329603\n",
      "      - -192471.35435686598\n",
      "      - -193924.84490548857\n",
      "      - -190887.13163198967\n",
      "      - -191399.27628401856\n",
      "      - -192401.80846296274\n",
      "      - -190958.32965239245\n",
      "      - -188820.45493200788\n",
      "      - -191388.7906435682\n",
      "      - -190551.6417758999\n",
      "      - -188293.3607726563\n",
      "      - -192170.72462714495\n",
      "      - -193633.23694398516\n",
      "      - -190760.69343821163\n",
      "      - -190784.7954854188\n",
      "      - -190906.89493824315\n",
      "      - -190262.468597598\n",
      "      - -192026.24282058727\n",
      "      - -191183.35286117977\n",
      "      - -191404.14065035662\n",
      "      - -190700.54261787893\n",
      "      - -191424.53451640718\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.0940516448825386\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4670646204484998\n",
      "      mean_inference_ms: 0.9690508649928676\n",
      "      mean_raw_obs_processing_ms: 0.13422895667781193\n",
      "  time_since_restore: 2257.208945274353\n",
      "  time_this_iter_s: 9.598558902740479\n",
      "  time_total_s: 2257.208945274353\n",
      "  timers:\n",
      "    learn_throughput: 128957.333\n",
      "    learn_time_ms: 496.164\n",
      "    load_throughput: 22084294.531\n",
      "    load_time_ms: 2.897\n",
      "    training_iteration_time_ms: 9431.676\n",
      "    update_time_ms: 3.989\n",
      "  timestamp: 1665851010\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 15100224\n",
      "  training_iteration: 236\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:23:35 (running for 00:38:10.05)<br>Memory usage on this node: 13.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   236</td><td style=\"text-align: right;\">         2257.21</td><td style=\"text-align: right;\">15100224</td><td style=\"text-align: right;\"> -192078</td><td style=\"text-align: right;\">             -188293</td><td style=\"text-align: right;\">             -202618</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 15164208\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 15164208\n",
      "    num_agent_steps_trained: 15164208\n",
      "    num_env_steps_sampled: 15164208\n",
      "    num_env_steps_trained: 15164208\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-23-39\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -188293.3607726563\n",
      "  episode_reward_mean: -192180.75370381266\n",
      "  episode_reward_min: -202618.26805136085\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 15156\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0901057720184326\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.000539999979082495\n",
      "          model: {}\n",
      "          policy_loss: 0.007277295924723148\n",
      "          total_loss: 10.007076263427734\n",
      "          vf_explained_var: -1.797600468478322e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 15164208\n",
      "    num_agent_steps_trained: 15164208\n",
      "    num_env_steps_sampled: 15164208\n",
      "    num_env_steps_trained: 15164208\n",
      "  iterations_since_restore: 237\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 15164208\n",
      "  num_agent_steps_trained: 15164208\n",
      "  num_env_steps_sampled: 15164208\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 15164208\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.04615384615384\n",
      "    ram_util_percent: 89.75384615384617\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0940287915597067\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4671085331202174\n",
      "    mean_inference_ms: 0.9689125716592474\n",
      "    mean_raw_obs_processing_ms: 0.1342343337831778\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -188293.3607726563\n",
      "    episode_reward_mean: -192180.75370381266\n",
      "    episode_reward_min: -202618.26805136085\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -193012.90648474396\n",
      "      - -191831.22056251834\n",
      "      - -198182.21559971326\n",
      "      - -192111.06939185227\n",
      "      - -190119.23377714536\n",
      "      - -192149.24322431162\n",
      "      - -190239.5750370281\n",
      "      - -190686.50934687824\n",
      "      - -191779.0709564038\n",
      "      - -194745.8897997881\n",
      "      - -191382.93081912905\n",
      "      - -193315.04368377413\n",
      "      - -191170.56910008626\n",
      "      - -190422.58610988187\n",
      "      - -202618.26805136085\n",
      "      - -194450.24160401244\n",
      "      - -194328.53708327396\n",
      "      - -193062.20008308088\n",
      "      - -191931.91530329603\n",
      "      - -192471.35435686598\n",
      "      - -193924.84490548857\n",
      "      - -190887.13163198967\n",
      "      - -191399.27628401856\n",
      "      - -192401.80846296274\n",
      "      - -190958.32965239245\n",
      "      - -188820.45493200788\n",
      "      - -191388.7906435682\n",
      "      - -190551.6417758999\n",
      "      - -188293.3607726563\n",
      "      - -192170.72462714495\n",
      "      - -193633.23694398516\n",
      "      - -190760.69343821163\n",
      "      - -190784.7954854188\n",
      "      - -190906.89493824315\n",
      "      - -190262.468597598\n",
      "      - -192026.24282058727\n",
      "      - -191183.35286117977\n",
      "      - -191404.14065035662\n",
      "      - -190700.54261787893\n",
      "      - -191424.53451640718\n",
      "      - -192054.87425676372\n",
      "      - -192033.24652803093\n",
      "      - -191260.09704545583\n",
      "      - -191595.91556464817\n",
      "      - -194346.45761960046\n",
      "      - -191854.69385598373\n",
      "      - -191435.14421281556\n",
      "      - -191445.30051566774\n",
      "      - -192199.30185011736\n",
      "      - -193182.59635682328\n",
      "      - -191505.64938350263\n",
      "      - -194646.43684417507\n",
      "      - -192349.1333834606\n",
      "      - -190826.62301298606\n",
      "      - -192774.1061229376\n",
      "      - -191689.33221846086\n",
      "      - -193062.85432610134\n",
      "      - -189054.48852133402\n",
      "      - -192513.66665032788\n",
      "      - -192215.83293174347\n",
      "      - -189655.20067851114\n",
      "      - -193315.22627398177\n",
      "      - -193191.71768591643\n",
      "      - -192780.1257844403\n",
      "      - -191137.87572062245\n",
      "      - -191742.56938790707\n",
      "      - -191643.17691333705\n",
      "      - -190229.19632428777\n",
      "      - -191149.84330685565\n",
      "      - -188895.6053470703\n",
      "      - -193021.88893856917\n",
      "      - -192128.13743635442\n",
      "      - -192847.87822855808\n",
      "      - -192161.386441093\n",
      "      - -196765.8350388883\n",
      "      - -197948.1264386312\n",
      "      - -192937.59203665593\n",
      "      - -190978.98156810703\n",
      "      - -191896.489468121\n",
      "      - -190691.2667364947\n",
      "      - -191913.06640147817\n",
      "      - -189374.9036425284\n",
      "      - -193244.77096204154\n",
      "      - -192047.70800547005\n",
      "      - -192460.3033307471\n",
      "      - -194432.82679267993\n",
      "      - -191095.1295052481\n",
      "      - -195449.51771567782\n",
      "      - -193692.1700175419\n",
      "      - -191921.4377326177\n",
      "      - -192170.66051235385\n",
      "      - -194226.05514422027\n",
      "      - -192118.5912012429\n",
      "      - -191283.2710831797\n",
      "      - -191886.1317855204\n",
      "      - -189845.3013876207\n",
      "      - -192288.91283097403\n",
      "      - -192921.3433775753\n",
      "      - -193620.52818305165\n",
      "      - -191025.0228810191\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.0940287915597067\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4671085331202174\n",
      "      mean_inference_ms: 0.9689125716592474\n",
      "      mean_raw_obs_processing_ms: 0.1342343337831778\n",
      "  time_since_restore: 2266.5196080207825\n",
      "  time_this_iter_s: 9.310662746429443\n",
      "  time_total_s: 2266.5196080207825\n",
      "  timers:\n",
      "    learn_throughput: 129619.6\n",
      "    learn_time_ms: 493.629\n",
      "    load_throughput: 21986592.425\n",
      "    load_time_ms: 2.91\n",
      "    training_iteration_time_ms: 9473.081\n",
      "    update_time_ms: 4.019\n",
      "  timestamp: 1665851019\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 15164208\n",
      "  training_iteration: 237\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:23:45 (running for 00:38:19.63)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   237</td><td style=\"text-align: right;\">         2266.52</td><td style=\"text-align: right;\">15164208</td><td style=\"text-align: right;\"> -192181</td><td style=\"text-align: right;\">             -188293</td><td style=\"text-align: right;\">             -202618</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 15228192\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 15228192\n",
      "    num_agent_steps_trained: 15228192\n",
      "    num_env_steps_sampled: 15228192\n",
      "    num_env_steps_trained: 15228192\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-23-49\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -189374.9036425284\n",
      "  episode_reward_mean: -192983.8574584805\n",
      "  episode_reward_min: -202930.91272268034\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 15228\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.093052625656128\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0003109672397840768\n",
      "          model: {}\n",
      "          policy_loss: -0.0018308745929971337\n",
      "          total_loss: 9.997922897338867\n",
      "          vf_explained_var: -1.5137688436084318e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 15228192\n",
      "    num_agent_steps_trained: 15228192\n",
      "    num_env_steps_sampled: 15228192\n",
      "    num_env_steps_trained: 15228192\n",
      "  iterations_since_restore: 238\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 15228192\n",
      "  num_agent_steps_trained: 15228192\n",
      "  num_env_steps_sampled: 15228192\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 15228192\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 78.56153846153846\n",
      "    ram_util_percent: 89.31538461538459\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09400078359974788\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46709736290918585\n",
      "    mean_inference_ms: 0.968590462721441\n",
      "    mean_raw_obs_processing_ms: 0.13402392702762164\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -189374.9036425284\n",
      "    episode_reward_mean: -192983.8574584805\n",
      "    episode_reward_min: -202930.91272268034\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -192847.87822855808\n",
      "      - -192161.386441093\n",
      "      - -196765.8350388883\n",
      "      - -197948.1264386312\n",
      "      - -192937.59203665593\n",
      "      - -190978.98156810703\n",
      "      - -191896.489468121\n",
      "      - -190691.2667364947\n",
      "      - -191913.06640147817\n",
      "      - -189374.9036425284\n",
      "      - -193244.77096204154\n",
      "      - -192047.70800547005\n",
      "      - -192460.3033307471\n",
      "      - -194432.82679267993\n",
      "      - -191095.1295052481\n",
      "      - -195449.51771567782\n",
      "      - -193692.1700175419\n",
      "      - -191921.4377326177\n",
      "      - -192170.66051235385\n",
      "      - -194226.05514422027\n",
      "      - -192118.5912012429\n",
      "      - -191283.2710831797\n",
      "      - -191886.1317855204\n",
      "      - -189845.3013876207\n",
      "      - -192288.91283097403\n",
      "      - -192921.3433775753\n",
      "      - -193620.52818305165\n",
      "      - -191025.0228810191\n",
      "      - -191579.785373498\n",
      "      - -192756.42079297465\n",
      "      - -191522.18386427467\n",
      "      - -193638.4445409089\n",
      "      - -195217.09195602933\n",
      "      - -193546.03690052556\n",
      "      - -193186.50819647327\n",
      "      - -192070.9964023094\n",
      "      - -191094.1354218163\n",
      "      - -192468.5220132139\n",
      "      - -191841.0112107663\n",
      "      - -192186.6367286187\n",
      "      - -193241.2845939724\n",
      "      - -197157.58851411802\n",
      "      - -194890.00854003595\n",
      "      - -195339.13312989913\n",
      "      - -192112.5821830033\n",
      "      - -193524.9550439828\n",
      "      - -192227.10766885302\n",
      "      - -192603.17492948935\n",
      "      - -194881.97228423468\n",
      "      - -193847.6520370852\n",
      "      - -191053.05546460592\n",
      "      - -196561.87795961983\n",
      "      - -193126.8970384197\n",
      "      - -193548.40368998732\n",
      "      - -194845.38145483242\n",
      "      - -191807.38589852236\n",
      "      - -194955.42358324752\n",
      "      - -197385.1822407726\n",
      "      - -193759.86337017146\n",
      "      - -191588.5322454479\n",
      "      - -194049.709986134\n",
      "      - -196671.00708864437\n",
      "      - -192818.14412427242\n",
      "      - -192337.3984301069\n",
      "      - -191064.4378165185\n",
      "      - -191124.02450682747\n",
      "      - -194124.9090394962\n",
      "      - -193048.40176875997\n",
      "      - -191471.55972026027\n",
      "      - -191424.03464669504\n",
      "      - -195196.1109839063\n",
      "      - -193926.44226027804\n",
      "      - -191408.1121444011\n",
      "      - -190420.49580070146\n",
      "      - -192883.1865033096\n",
      "      - -190616.03933404616\n",
      "      - -193276.38904988996\n",
      "      - -192011.11051963476\n",
      "      - -191616.2685717809\n",
      "      - -192495.94964863904\n",
      "      - -190911.04591028867\n",
      "      - -192939.57682868678\n",
      "      - -193204.45962350772\n",
      "      - -192453.9619339848\n",
      "      - -193517.35979719897\n",
      "      - -194931.8296089575\n",
      "      - -193333.1556083865\n",
      "      - -202930.91272268034\n",
      "      - -191592.4074159133\n",
      "      - -190830.17859089622\n",
      "      - -194573.93639330685\n",
      "      - -192021.6537779508\n",
      "      - -195046.98527675873\n",
      "      - -193135.86034515136\n",
      "      - -191748.49165299203\n",
      "      - -192141.57065088587\n",
      "      - -193477.4692688906\n",
      "      - -191656.72688936288\n",
      "      - -190807.56772446338\n",
      "      - -192336.42016243204\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09400078359974788\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46709736290918585\n",
      "      mean_inference_ms: 0.968590462721441\n",
      "      mean_raw_obs_processing_ms: 0.13402392702762164\n",
      "  time_since_restore: 2275.5918476581573\n",
      "  time_this_iter_s: 9.072239637374878\n",
      "  time_total_s: 2275.5918476581573\n",
      "  timers:\n",
      "    learn_throughput: 130461.925\n",
      "    learn_time_ms: 490.442\n",
      "    load_throughput: 21366226.166\n",
      "    load_time_ms: 2.995\n",
      "    training_iteration_time_ms: 9446.835\n",
      "    update_time_ms: 3.836\n",
      "  timestamp: 1665851029\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 15228192\n",
      "  training_iteration: 238\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:23:54 (running for 00:38:28.73)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   238</td><td style=\"text-align: right;\">         2275.59</td><td style=\"text-align: right;\">15228192</td><td style=\"text-align: right;\"> -192984</td><td style=\"text-align: right;\">             -189375</td><td style=\"text-align: right;\">             -202931</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 15292176\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 15292176\n",
      "    num_agent_steps_trained: 15292176\n",
      "    num_env_steps_sampled: 15292176\n",
      "    num_env_steps_trained: 15292176\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-23-58\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -189532.6295005331\n",
      "  episode_reward_mean: -192872.162186988\n",
      "  episode_reward_min: -202930.91272268034\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 15288\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.093376636505127\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.000506012060213834\n",
      "          model: {}\n",
      "          policy_loss: 0.005773572251200676\n",
      "          total_loss: 10.00556468963623\n",
      "          vf_explained_var: -8.514949634275126e-09\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 15292176\n",
      "    num_agent_steps_trained: 15292176\n",
      "    num_env_steps_sampled: 15292176\n",
      "    num_env_steps_trained: 15292176\n",
      "  iterations_since_restore: 239\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 15292176\n",
      "  num_agent_steps_trained: 15292176\n",
      "  num_env_steps_sampled: 15292176\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 15292176\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 84.34166666666665\n",
      "    ram_util_percent: 89.15833333333335\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09401015501666775\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4670027806128506\n",
      "    mean_inference_ms: 0.968504333498601\n",
      "    mean_raw_obs_processing_ms: 0.13416160872099148\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -189532.6295005331\n",
      "    episode_reward_mean: -192872.162186988\n",
      "    episode_reward_min: -202930.91272268034\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -194049.709986134\n",
      "      - -196671.00708864437\n",
      "      - -192818.14412427242\n",
      "      - -192337.3984301069\n",
      "      - -191064.4378165185\n",
      "      - -191124.02450682747\n",
      "      - -194124.9090394962\n",
      "      - -193048.40176875997\n",
      "      - -191471.55972026027\n",
      "      - -191424.03464669504\n",
      "      - -195196.1109839063\n",
      "      - -193926.44226027804\n",
      "      - -191408.1121444011\n",
      "      - -190420.49580070146\n",
      "      - -192883.1865033096\n",
      "      - -190616.03933404616\n",
      "      - -193276.38904988996\n",
      "      - -192011.11051963476\n",
      "      - -191616.2685717809\n",
      "      - -192495.94964863904\n",
      "      - -190911.04591028867\n",
      "      - -192939.57682868678\n",
      "      - -193204.45962350772\n",
      "      - -192453.9619339848\n",
      "      - -193517.35979719897\n",
      "      - -194931.8296089575\n",
      "      - -193333.1556083865\n",
      "      - -202930.91272268034\n",
      "      - -191592.4074159133\n",
      "      - -190830.17859089622\n",
      "      - -194573.93639330685\n",
      "      - -192021.6537779508\n",
      "      - -195046.98527675873\n",
      "      - -193135.86034515136\n",
      "      - -191748.49165299203\n",
      "      - -192141.57065088587\n",
      "      - -193477.4692688906\n",
      "      - -191656.72688936288\n",
      "      - -190807.56772446338\n",
      "      - -192336.42016243204\n",
      "      - -194871.9134823546\n",
      "      - -194540.88311800038\n",
      "      - -193745.3584462126\n",
      "      - -194949.56916924613\n",
      "      - -190689.34018119265\n",
      "      - -191153.79489887142\n",
      "      - -195076.1945688424\n",
      "      - -190852.43214881432\n",
      "      - -195507.40354020306\n",
      "      - -193307.75937613225\n",
      "      - -191970.43004958236\n",
      "      - -192369.5167118533\n",
      "      - -192873.54231863533\n",
      "      - -192762.89792233394\n",
      "      - -192309.5258640045\n",
      "      - -193675.6067771919\n",
      "      - -193040.59571548476\n",
      "      - -191778.33852232274\n",
      "      - -192464.27326678435\n",
      "      - -191495.21264926746\n",
      "      - -194135.6642266471\n",
      "      - -190326.82358610685\n",
      "      - -191333.04090650947\n",
      "      - -190221.18506912212\n",
      "      - -195563.0115769124\n",
      "      - -192255.46032767964\n",
      "      - -195207.21374886125\n",
      "      - -190273.36396618103\n",
      "      - -192869.333846827\n",
      "      - -193532.44661081998\n",
      "      - -195115.25552324508\n",
      "      - -191847.57606018925\n",
      "      - -194498.0662836559\n",
      "      - -192401.81087610128\n",
      "      - -189532.6295005331\n",
      "      - -194514.75564423547\n",
      "      - -192726.14662442697\n",
      "      - -194883.16530424973\n",
      "      - -190958.62480772453\n",
      "      - -192646.67433700504\n",
      "      - -193880.1533716886\n",
      "      - -189957.27889060188\n",
      "      - -193801.80413433095\n",
      "      - -194469.6709613323\n",
      "      - -190108.5027024402\n",
      "      - -193231.12032899\n",
      "      - -196748.72887146784\n",
      "      - -191687.92253879813\n",
      "      - -193228.70040399028\n",
      "      - -192407.70642192138\n",
      "      - -191933.37340976912\n",
      "      - -193077.16627631552\n",
      "      - -191573.89655764416\n",
      "      - -192599.48899036206\n",
      "      - -195712.04130068803\n",
      "      - -191980.03096472545\n",
      "      - -193990.1169902476\n",
      "      - -190692.26330611118\n",
      "      - -194451.01531909223\n",
      "      - -191833.0972769215\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09401015501666775\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4670027806128506\n",
      "      mean_inference_ms: 0.968504333498601\n",
      "      mean_raw_obs_processing_ms: 0.13416160872099148\n",
      "  time_since_restore: 2284.6778190135956\n",
      "  time_this_iter_s: 9.085971355438232\n",
      "  time_total_s: 2284.6778190135956\n",
      "  timers:\n",
      "    learn_throughput: 130965.308\n",
      "    learn_time_ms: 488.557\n",
      "    load_throughput: 21250334.323\n",
      "    load_time_ms: 3.011\n",
      "    training_iteration_time_ms: 9439.785\n",
      "    update_time_ms: 3.744\n",
      "  timestamp: 1665851038\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 15292176\n",
      "  training_iteration: 239\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:24:03 (running for 00:38:37.61)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   239</td><td style=\"text-align: right;\">         2284.68</td><td style=\"text-align: right;\">15292176</td><td style=\"text-align: right;\"> -192872</td><td style=\"text-align: right;\">             -189533</td><td style=\"text-align: right;\">             -202931</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 15356160\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 15356160\n",
      "    num_agent_steps_trained: 15356160\n",
      "    num_env_steps_sampled: 15356160\n",
      "    num_env_steps_trained: 15356160\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-24-07\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -189532.6295005331\n",
      "  episode_reward_mean: -193239.71802578936\n",
      "  episode_reward_min: -213502.68881188537\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 15348\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0966298580169678\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0006053762626834214\n",
      "          model: {}\n",
      "          policy_loss: 0.007457571569830179\n",
      "          total_loss: 10.007267951965332\n",
      "          vf_explained_var: -2.838316426334586e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 15356160\n",
      "    num_agent_steps_trained: 15356160\n",
      "    num_env_steps_sampled: 15356160\n",
      "    num_env_steps_trained: 15356160\n",
      "  iterations_since_restore: 240\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 15356160\n",
      "  num_agent_steps_trained: 15356160\n",
      "  num_env_steps_sampled: 15356160\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 15356160\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 78.95714285714287\n",
      "    ram_util_percent: 89.07142857142857\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09396312645617735\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46696325028052277\n",
      "    mean_inference_ms: 0.9683984538576297\n",
      "    mean_raw_obs_processing_ms: 0.13413800552034322\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -189532.6295005331\n",
      "    episode_reward_mean: -193239.71802578936\n",
      "    episode_reward_min: -213502.68881188537\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -194135.6642266471\n",
      "      - -190326.82358610685\n",
      "      - -191333.04090650947\n",
      "      - -190221.18506912212\n",
      "      - -195563.0115769124\n",
      "      - -192255.46032767964\n",
      "      - -195207.21374886125\n",
      "      - -190273.36396618103\n",
      "      - -192869.333846827\n",
      "      - -193532.44661081998\n",
      "      - -195115.25552324508\n",
      "      - -191847.57606018925\n",
      "      - -194498.0662836559\n",
      "      - -192401.81087610128\n",
      "      - -189532.6295005331\n",
      "      - -194514.75564423547\n",
      "      - -192726.14662442697\n",
      "      - -194883.16530424973\n",
      "      - -190958.62480772453\n",
      "      - -192646.67433700504\n",
      "      - -193880.1533716886\n",
      "      - -189957.27889060188\n",
      "      - -193801.80413433095\n",
      "      - -194469.6709613323\n",
      "      - -190108.5027024402\n",
      "      - -193231.12032899\n",
      "      - -196748.72887146784\n",
      "      - -191687.92253879813\n",
      "      - -193228.70040399028\n",
      "      - -192407.70642192138\n",
      "      - -191933.37340976912\n",
      "      - -193077.16627631552\n",
      "      - -191573.89655764416\n",
      "      - -192599.48899036206\n",
      "      - -195712.04130068803\n",
      "      - -191980.03096472545\n",
      "      - -193990.1169902476\n",
      "      - -190692.26330611118\n",
      "      - -194451.01531909223\n",
      "      - -191833.0972769215\n",
      "      - -192177.26697221163\n",
      "      - -196840.943363371\n",
      "      - -193114.13021915682\n",
      "      - -192601.1401395957\n",
      "      - -191925.34678223185\n",
      "      - -192366.70946145794\n",
      "      - -190477.1338899318\n",
      "      - -195552.65802329459\n",
      "      - -213502.68881188537\n",
      "      - -194015.12666762865\n",
      "      - -191582.0702460626\n",
      "      - -193158.1999430219\n",
      "      - -192857.92406856662\n",
      "      - -190597.96629894656\n",
      "      - -191962.80511904438\n",
      "      - -193038.82733341143\n",
      "      - -192028.95356163304\n",
      "      - -195190.04465662912\n",
      "      - -192006.22700932005\n",
      "      - -191648.52984803283\n",
      "      - -192993.61891686608\n",
      "      - -192895.93677943602\n",
      "      - -194305.71350311482\n",
      "      - -194487.82033757263\n",
      "      - -192220.89603637691\n",
      "      - -190708.06184116934\n",
      "      - -192601.89553135188\n",
      "      - -195202.92190925303\n",
      "      - -194172.8781569711\n",
      "      - -193311.42098420984\n",
      "      - -190633.18471207516\n",
      "      - -192916.52529782467\n",
      "      - -192287.69270850948\n",
      "      - -193258.64132888126\n",
      "      - -193843.598697285\n",
      "      - -194072.1377384593\n",
      "      - -191724.32631905525\n",
      "      - -193509.84015642744\n",
      "      - -209951.13890434123\n",
      "      - -193075.3232129201\n",
      "      - -194698.65624843718\n",
      "      - -195097.422560135\n",
      "      - -194206.1389716924\n",
      "      - -191898.06530119703\n",
      "      - -192829.59753404788\n",
      "      - -193225.51191558957\n",
      "      - -192705.79763667713\n",
      "      - -190065.08591251558\n",
      "      - -191043.22187455848\n",
      "      - -191527.64211461964\n",
      "      - -191063.30685547652\n",
      "      - -200151.02602710496\n",
      "      - -193177.52045599304\n",
      "      - -191326.3316987582\n",
      "      - -191315.45219495933\n",
      "      - -193585.6830482321\n",
      "      - -192282.5389534143\n",
      "      - -191077.1761310125\n",
      "      - -191332.88301307877\n",
      "      - -194338.15079943257\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09396312645617735\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46696325028052277\n",
      "      mean_inference_ms: 0.9683984538576297\n",
      "      mean_raw_obs_processing_ms: 0.13413800552034322\n",
      "  time_since_restore: 2294.085343837738\n",
      "  time_this_iter_s: 9.407524824142456\n",
      "  time_total_s: 2294.085343837738\n",
      "  timers:\n",
      "    learn_throughput: 130101.485\n",
      "    learn_time_ms: 491.801\n",
      "    load_throughput: 21199973.705\n",
      "    load_time_ms: 3.018\n",
      "    training_iteration_time_ms: 9367.522\n",
      "    update_time_ms: 3.866\n",
      "  timestamp: 1665851047\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 15356160\n",
      "  training_iteration: 240\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:24:12 (running for 00:38:47.17)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   240</td><td style=\"text-align: right;\">         2294.09</td><td style=\"text-align: right;\">15356160</td><td style=\"text-align: right;\"> -193240</td><td style=\"text-align: right;\">             -189533</td><td style=\"text-align: right;\">             -213503</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 15420144\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 15420144\n",
      "    num_agent_steps_trained: 15420144\n",
      "    num_env_steps_sampled: 15420144\n",
      "    num_env_steps_trained: 15420144\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-24-16\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -189972.3279768097\n",
      "  episode_reward_mean: -193483.96363448908\n",
      "  episode_reward_min: -209951.13890434123\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 15420\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.095569372177124\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0007679268601350486\n",
      "          model: {}\n",
      "          policy_loss: -0.002130345441401005\n",
      "          total_loss: 9.997714042663574\n",
      "          vf_explained_var: -2.0814320933482122e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 15420144\n",
      "    num_agent_steps_trained: 15420144\n",
      "    num_env_steps_sampled: 15420144\n",
      "    num_env_steps_trained: 15420144\n",
      "  iterations_since_restore: 241\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 15420144\n",
      "  num_agent_steps_trained: 15420144\n",
      "  num_env_steps_sampled: 15420144\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 15420144\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.24166666666666\n",
      "    ram_util_percent: 89.10000000000001\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09392140669892896\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4668557725073479\n",
      "    mean_inference_ms: 0.9678851683307778\n",
      "    mean_raw_obs_processing_ms: 0.13390881857189452\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -189972.3279768097\n",
      "    episode_reward_mean: -193483.96363448908\n",
      "    episode_reward_min: -209951.13890434123\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -192287.69270850948\n",
      "      - -193258.64132888126\n",
      "      - -193843.598697285\n",
      "      - -194072.1377384593\n",
      "      - -191724.32631905525\n",
      "      - -193509.84015642744\n",
      "      - -209951.13890434123\n",
      "      - -193075.3232129201\n",
      "      - -194698.65624843718\n",
      "      - -195097.422560135\n",
      "      - -194206.1389716924\n",
      "      - -191898.06530119703\n",
      "      - -192829.59753404788\n",
      "      - -193225.51191558957\n",
      "      - -192705.79763667713\n",
      "      - -190065.08591251558\n",
      "      - -191043.22187455848\n",
      "      - -191527.64211461964\n",
      "      - -191063.30685547652\n",
      "      - -200151.02602710496\n",
      "      - -193177.52045599304\n",
      "      - -191326.3316987582\n",
      "      - -191315.45219495933\n",
      "      - -193585.6830482321\n",
      "      - -192282.5389534143\n",
      "      - -191077.1761310125\n",
      "      - -191332.88301307877\n",
      "      - -194338.15079943257\n",
      "      - -192575.0374029481\n",
      "      - -191072.7269997338\n",
      "      - -192089.361748977\n",
      "      - -192749.52771994812\n",
      "      - -192232.21352439324\n",
      "      - -193760.22549375994\n",
      "      - -190335.7917145011\n",
      "      - -195046.35761135604\n",
      "      - -199852.97900429033\n",
      "      - -194768.25357419322\n",
      "      - -195296.64640215805\n",
      "      - -203810.16755191653\n",
      "      - -194359.2150679368\n",
      "      - -191236.88913740177\n",
      "      - -193615.3147018394\n",
      "      - -195494.60969067484\n",
      "      - -190834.1545065982\n",
      "      - -191114.07502295403\n",
      "      - -193876.8922726942\n",
      "      - -193468.4765738111\n",
      "      - -197054.50362533337\n",
      "      - -195478.9391773015\n",
      "      - -192455.5669354461\n",
      "      - -195347.5437237925\n",
      "      - -194292.36594887482\n",
      "      - -192908.6782596774\n",
      "      - -192950.54391881457\n",
      "      - -193292.86539856828\n",
      "      - -190604.78805797873\n",
      "      - -191851.87068753058\n",
      "      - -193051.05311152077\n",
      "      - -190713.29054549633\n",
      "      - -192133.40590027775\n",
      "      - -192343.01111919188\n",
      "      - -191180.3499155138\n",
      "      - -194218.98148399487\n",
      "      - -195676.6480727203\n",
      "      - -191508.5757511896\n",
      "      - -194778.57770371376\n",
      "      - -194955.20093831953\n",
      "      - -192751.13617887354\n",
      "      - -195571.07563819265\n",
      "      - -191725.19469887085\n",
      "      - -195596.47228126187\n",
      "      - -193170.2401573782\n",
      "      - -192570.27975115573\n",
      "      - -192666.49266094348\n",
      "      - -192921.7139019539\n",
      "      - -190801.03499921024\n",
      "      - -191667.92658466884\n",
      "      - -191921.2995227501\n",
      "      - -193000.15747099995\n",
      "      - -190470.08440935085\n",
      "      - -191860.56625862626\n",
      "      - -191422.37650718316\n",
      "      - -193406.70536249946\n",
      "      - -193916.85829482504\n",
      "      - -194134.36408107018\n",
      "      - -193398.89335705372\n",
      "      - -198424.48428861995\n",
      "      - -194018.28986028314\n",
      "      - -194305.93644703526\n",
      "      - -189972.3279768097\n",
      "      - -196661.76620681232\n",
      "      - -195504.7879149412\n",
      "      - -192148.60618264115\n",
      "      - -192002.49805267452\n",
      "      - -195347.1992340159\n",
      "      - -193943.96901075292\n",
      "      - -195243.15759562814\n",
      "      - -192481.6324759334\n",
      "      - -192313.25177573826\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09392140669892896\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4668557725073479\n",
      "      mean_inference_ms: 0.9678851683307778\n",
      "      mean_raw_obs_processing_ms: 0.13390881857189452\n",
      "  time_since_restore: 2302.845134496689\n",
      "  time_this_iter_s: 8.759790658950806\n",
      "  time_total_s: 2302.845134496689\n",
      "  timers:\n",
      "    learn_throughput: 122794.122\n",
      "    learn_time_ms: 521.067\n",
      "    load_throughput: 21379502.823\n",
      "    load_time_ms: 2.993\n",
      "    training_iteration_time_ms: 9272.207\n",
      "    update_time_ms: 3.846\n",
      "  timestamp: 1665851056\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 15420144\n",
      "  training_iteration: 241\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:24:21 (running for 00:38:56.19)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   241</td><td style=\"text-align: right;\">         2302.85</td><td style=\"text-align: right;\">15420144</td><td style=\"text-align: right;\"> -193484</td><td style=\"text-align: right;\">             -189972</td><td style=\"text-align: right;\">             -209951</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 15484128\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 15484128\n",
      "    num_agent_steps_trained: 15484128\n",
      "    num_env_steps_sampled: 15484128\n",
      "    num_env_steps_trained: 15484128\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-24-24\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -188463.71212142735\n",
      "  episode_reward_mean: -192705.68110771247\n",
      "  episode_reward_min: -204000.17875187894\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 15480\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.097053050994873\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0007225694134831429\n",
      "          model: {}\n",
      "          policy_loss: 0.00527820223942399\n",
      "          total_loss: 10.005112648010254\n",
      "          vf_explained_var: -4.1628641866964244e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 15484128\n",
      "    num_agent_steps_trained: 15484128\n",
      "    num_env_steps_sampled: 15484128\n",
      "    num_env_steps_trained: 15484128\n",
      "  iterations_since_restore: 242\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 15484128\n",
      "  num_agent_steps_trained: 15484128\n",
      "  num_env_steps_sampled: 15484128\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 15484128\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.60833333333333\n",
      "    ram_util_percent: 89.06666666666666\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09391234789164994\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4666875385511776\n",
      "    mean_inference_ms: 0.9674432452293928\n",
      "    mean_raw_obs_processing_ms: 0.13402929012244966\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -188463.71212142735\n",
      "    episode_reward_mean: -192705.68110771247\n",
      "    episode_reward_min: -204000.17875187894\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -192133.40590027775\n",
      "      - -192343.01111919188\n",
      "      - -191180.3499155138\n",
      "      - -194218.98148399487\n",
      "      - -195676.6480727203\n",
      "      - -191508.5757511896\n",
      "      - -194778.57770371376\n",
      "      - -194955.20093831953\n",
      "      - -192751.13617887354\n",
      "      - -195571.07563819265\n",
      "      - -191725.19469887085\n",
      "      - -195596.47228126187\n",
      "      - -193170.2401573782\n",
      "      - -192570.27975115573\n",
      "      - -192666.49266094348\n",
      "      - -192921.7139019539\n",
      "      - -190801.03499921024\n",
      "      - -191667.92658466884\n",
      "      - -191921.2995227501\n",
      "      - -193000.15747099995\n",
      "      - -190470.08440935085\n",
      "      - -191860.56625862626\n",
      "      - -191422.37650718316\n",
      "      - -193406.70536249946\n",
      "      - -193916.85829482504\n",
      "      - -194134.36408107018\n",
      "      - -193398.89335705372\n",
      "      - -198424.48428861995\n",
      "      - -194018.28986028314\n",
      "      - -194305.93644703526\n",
      "      - -189972.3279768097\n",
      "      - -196661.76620681232\n",
      "      - -195504.7879149412\n",
      "      - -192148.60618264115\n",
      "      - -192002.49805267452\n",
      "      - -195347.1992340159\n",
      "      - -193943.96901075292\n",
      "      - -195243.15759562814\n",
      "      - -192481.6324759334\n",
      "      - -192313.25177573826\n",
      "      - -191058.19843764312\n",
      "      - -191474.00017616738\n",
      "      - -194238.206566223\n",
      "      - -192363.5432843394\n",
      "      - -192276.18182434177\n",
      "      - -192108.5447460991\n",
      "      - -190646.38120521756\n",
      "      - -192440.23142461697\n",
      "      - -193050.67875250668\n",
      "      - -194187.34931743031\n",
      "      - -190923.6430672877\n",
      "      - -192840.24609742544\n",
      "      - -192381.7454992501\n",
      "      - -190675.40624189624\n",
      "      - -192603.55544386964\n",
      "      - -189672.1253912712\n",
      "      - -192024.8031204186\n",
      "      - -192845.98740226898\n",
      "      - -191030.6688883134\n",
      "      - -190247.2850411266\n",
      "      - -196894.84476174277\n",
      "      - -191509.56331553322\n",
      "      - -192903.694989651\n",
      "      - -190931.02616397908\n",
      "      - -193922.30079335647\n",
      "      - -194361.0425365857\n",
      "      - -190473.9158554014\n",
      "      - -192458.8973385839\n",
      "      - -191902.4514322191\n",
      "      - -204000.17875187894\n",
      "      - -193667.2948319867\n",
      "      - -192699.349626862\n",
      "      - -191119.83732546872\n",
      "      - -192264.8521196959\n",
      "      - -191249.360604137\n",
      "      - -188463.71212142735\n",
      "      - -191315.5675485842\n",
      "      - -192093.3114439284\n",
      "      - -191737.59411933916\n",
      "      - -193684.2656031308\n",
      "      - -192587.087592726\n",
      "      - -188945.37164562644\n",
      "      - -192069.0694667858\n",
      "      - -191337.31786760103\n",
      "      - -192193.53282865713\n",
      "      - -193843.26732865185\n",
      "      - -191418.67190715673\n",
      "      - -190054.08274145756\n",
      "      - -192102.30068895844\n",
      "      - -192824.31061257762\n",
      "      - -191042.04179063643\n",
      "      - -192385.3276038119\n",
      "      - -197075.45086900637\n",
      "      - -193264.60557917017\n",
      "      - -190437.54759409832\n",
      "      - -190047.13541429845\n",
      "      - -191288.4286795809\n",
      "      - -193470.26521133227\n",
      "      - -191692.41256652446\n",
      "      - -193612.50954770803\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09391234789164994\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4666875385511776\n",
      "      mean_inference_ms: 0.9674432452293928\n",
      "      mean_raw_obs_processing_ms: 0.13402929012244966\n",
      "  time_since_restore: 2311.211190223694\n",
      "  time_this_iter_s: 8.366055727005005\n",
      "  time_total_s: 2311.211190223694\n",
      "  timers:\n",
      "    learn_throughput: 124660.012\n",
      "    learn_time_ms: 513.268\n",
      "    load_throughput: 21158855.768\n",
      "    load_time_ms: 3.024\n",
      "    training_iteration_time_ms: 9141.27\n",
      "    update_time_ms: 3.837\n",
      "  timestamp: 1665851064\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 15484128\n",
      "  training_iteration: 242\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:24:29 (running for 00:39:04.36)<br>Memory usage on this node: 13.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   242</td><td style=\"text-align: right;\">         2311.21</td><td style=\"text-align: right;\">15484128</td><td style=\"text-align: right;\"> -192706</td><td style=\"text-align: right;\">             -188464</td><td style=\"text-align: right;\">             -204000</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 15548112\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 15548112\n",
      "    num_agent_steps_trained: 15548112\n",
      "    num_env_steps_sampled: 15548112\n",
      "    num_env_steps_trained: 15548112\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-24-34\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -188463.71212142735\n",
      "  episode_reward_mean: -192358.66763395813\n",
      "  episode_reward_min: -210069.4859653056\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 15540\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.096004009246826\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0005404495750553906\n",
      "          model: {}\n",
      "          policy_loss: 0.006578435190021992\n",
      "          total_loss: 10.006376266479492\n",
      "          vf_explained_var: -3.500590395333347e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 15548112\n",
      "    num_agent_steps_trained: 15548112\n",
      "    num_env_steps_sampled: 15548112\n",
      "    num_env_steps_trained: 15548112\n",
      "  iterations_since_restore: 243\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 15548112\n",
      "  num_agent_steps_trained: 15548112\n",
      "  num_env_steps_sampled: 15548112\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 15548112\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.28571428571429\n",
      "    ram_util_percent: 89.25\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09387889288904308\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46664531463693776\n",
      "    mean_inference_ms: 0.9671578201585568\n",
      "    mean_raw_obs_processing_ms: 0.1340227272253422\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -188463.71212142735\n",
      "    episode_reward_mean: -192358.66763395813\n",
      "    episode_reward_min: -210069.4859653056\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -196894.84476174277\n",
      "      - -191509.56331553322\n",
      "      - -192903.694989651\n",
      "      - -190931.02616397908\n",
      "      - -193922.30079335647\n",
      "      - -194361.0425365857\n",
      "      - -190473.9158554014\n",
      "      - -192458.8973385839\n",
      "      - -191902.4514322191\n",
      "      - -204000.17875187894\n",
      "      - -193667.2948319867\n",
      "      - -192699.349626862\n",
      "      - -191119.83732546872\n",
      "      - -192264.8521196959\n",
      "      - -191249.360604137\n",
      "      - -188463.71212142735\n",
      "      - -191315.5675485842\n",
      "      - -192093.3114439284\n",
      "      - -191737.59411933916\n",
      "      - -193684.2656031308\n",
      "      - -192587.087592726\n",
      "      - -188945.37164562644\n",
      "      - -192069.0694667858\n",
      "      - -191337.31786760103\n",
      "      - -192193.53282865713\n",
      "      - -193843.26732865185\n",
      "      - -191418.67190715673\n",
      "      - -190054.08274145756\n",
      "      - -192102.30068895844\n",
      "      - -192824.31061257762\n",
      "      - -191042.04179063643\n",
      "      - -192385.3276038119\n",
      "      - -197075.45086900637\n",
      "      - -193264.60557917017\n",
      "      - -190437.54759409832\n",
      "      - -190047.13541429845\n",
      "      - -191288.4286795809\n",
      "      - -193470.26521133227\n",
      "      - -191692.41256652446\n",
      "      - -193612.50954770803\n",
      "      - -191088.3194191576\n",
      "      - -189740.83144273426\n",
      "      - -192190.84208942344\n",
      "      - -190624.01895546485\n",
      "      - -193033.85375078494\n",
      "      - -192706.5630765513\n",
      "      - -191676.8785550784\n",
      "      - -191171.11648901913\n",
      "      - -200577.37304143488\n",
      "      - -193304.18775084268\n",
      "      - -190718.93395011796\n",
      "      - -194396.80329044748\n",
      "      - -192304.43110385138\n",
      "      - -193710.28482157257\n",
      "      - -190926.10270473018\n",
      "      - -191281.1356226382\n",
      "      - -192176.0652532656\n",
      "      - -196273.05336031943\n",
      "      - -192607.13109131268\n",
      "      - -190922.00000695512\n",
      "      - -194391.0106543343\n",
      "      - -191116.2285197756\n",
      "      - -191783.19529594883\n",
      "      - -190774.43255648593\n",
      "      - -192379.56647631718\n",
      "      - -192150.92186008013\n",
      "      - -189353.0336378298\n",
      "      - -191870.11341697673\n",
      "      - -190142.84529132867\n",
      "      - -191448.52406254198\n",
      "      - -210069.4859653056\n",
      "      - -189037.09523042428\n",
      "      - -194182.96265017512\n",
      "      - -192163.51377453964\n",
      "      - -192125.89848704304\n",
      "      - -191469.893850756\n",
      "      - -193907.14824890526\n",
      "      - -190514.74847514738\n",
      "      - -193077.50686309548\n",
      "      - -193420.91853370148\n",
      "      - -192431.94560960558\n",
      "      - -193350.55463641466\n",
      "      - -192031.3079318696\n",
      "      - -190610.34975445474\n",
      "      - -193907.47006737313\n",
      "      - -191753.1155927334\n",
      "      - -189441.0574847475\n",
      "      - -192438.3931178091\n",
      "      - -191025.6550005764\n",
      "      - -191942.55267863016\n",
      "      - -190110.56526809564\n",
      "      - -189831.5972494053\n",
      "      - -190858.36470048086\n",
      "      - -190613.38885413416\n",
      "      - -191574.05254262802\n",
      "      - -191934.96368581714\n",
      "      - -189998.1365073742\n",
      "      - -192654.71113972622\n",
      "      - -190447.2298177297\n",
      "      - -192758.5833099325\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09387889288904308\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46664531463693776\n",
      "      mean_inference_ms: 0.9671578201585568\n",
      "      mean_raw_obs_processing_ms: 0.1340227272253422\n",
      "  time_since_restore: 2320.7745835781097\n",
      "  time_this_iter_s: 9.563393354415894\n",
      "  time_total_s: 2320.7745835781097\n",
      "  timers:\n",
      "    learn_throughput: 124500.28\n",
      "    learn_time_ms: 513.927\n",
      "    load_throughput: 21130034.89\n",
      "    load_time_ms: 3.028\n",
      "    training_iteration_time_ms: 9155.204\n",
      "    update_time_ms: 3.727\n",
      "  timestamp: 1665851074\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 15548112\n",
      "  training_iteration: 243\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:24:39 (running for 00:39:14.20)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   243</td><td style=\"text-align: right;\">         2320.77</td><td style=\"text-align: right;\">15548112</td><td style=\"text-align: right;\"> -192359</td><td style=\"text-align: right;\">             -188464</td><td style=\"text-align: right;\">             -210069</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 15612096\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 15612096\n",
      "    num_agent_steps_trained: 15612096\n",
      "    num_env_steps_sampled: 15612096\n",
      "    num_env_steps_trained: 15612096\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-24-43\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -188424.29088110686\n",
      "  episode_reward_mean: -191674.2251958378\n",
      "  episode_reward_min: -198485.97770636537\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 15612\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.096067190170288\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0009105291683226824\n",
      "          model: {}\n",
      "          policy_loss: -0.0020247576758265495\n",
      "          total_loss: 9.997847557067871\n",
      "          vf_explained_var: -4.1628641866964244e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 15612096\n",
      "    num_agent_steps_trained: 15612096\n",
      "    num_env_steps_sampled: 15612096\n",
      "    num_env_steps_trained: 15612096\n",
      "  iterations_since_restore: 244\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 15612096\n",
      "  num_agent_steps_trained: 15612096\n",
      "  num_env_steps_sampled: 15612096\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 15612096\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.57692307692308\n",
      "    ram_util_percent: 89.29999999999998\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09385672398570293\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4666491718684533\n",
      "    mean_inference_ms: 0.9670100824584463\n",
      "    mean_raw_obs_processing_ms: 0.1338354758182293\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -188424.29088110686\n",
      "    episode_reward_mean: -191674.2251958378\n",
      "    episode_reward_min: -198485.97770636537\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -194182.96265017512\n",
      "      - -192163.51377453964\n",
      "      - -192125.89848704304\n",
      "      - -191469.893850756\n",
      "      - -193907.14824890526\n",
      "      - -190514.74847514738\n",
      "      - -193077.50686309548\n",
      "      - -193420.91853370148\n",
      "      - -192431.94560960558\n",
      "      - -193350.55463641466\n",
      "      - -192031.3079318696\n",
      "      - -190610.34975445474\n",
      "      - -193907.47006737313\n",
      "      - -191753.1155927334\n",
      "      - -189441.0574847475\n",
      "      - -192438.3931178091\n",
      "      - -191025.6550005764\n",
      "      - -191942.55267863016\n",
      "      - -190110.56526809564\n",
      "      - -189831.5972494053\n",
      "      - -190858.36470048086\n",
      "      - -190613.38885413416\n",
      "      - -191574.05254262802\n",
      "      - -191934.96368581714\n",
      "      - -189998.1365073742\n",
      "      - -192654.71113972622\n",
      "      - -190447.2298177297\n",
      "      - -192758.5833099325\n",
      "      - -196342.1394662484\n",
      "      - -189224.06569750098\n",
      "      - -189586.2024958311\n",
      "      - -190014.73723707767\n",
      "      - -190656.44822105122\n",
      "      - -191177.74486642718\n",
      "      - -188794.31039643404\n",
      "      - -190483.60095810538\n",
      "      - -192959.21840316473\n",
      "      - -193039.3482327559\n",
      "      - -191097.7712777074\n",
      "      - -192871.37877353845\n",
      "      - -191783.16419738706\n",
      "      - -191085.99069188198\n",
      "      - -190986.4614406002\n",
      "      - -190644.44278771308\n",
      "      - -191673.42301641204\n",
      "      - -190484.29344391677\n",
      "      - -191898.66150675062\n",
      "      - -193172.64129998285\n",
      "      - -193213.60379348032\n",
      "      - -190346.33020062032\n",
      "      - -191658.78569954887\n",
      "      - -190129.89751475945\n",
      "      - -193921.75932555337\n",
      "      - -192522.17530503607\n",
      "      - -192932.43351329633\n",
      "      - -191505.04142250607\n",
      "      - -190670.6297319576\n",
      "      - -193027.42431672523\n",
      "      - -190890.39000677256\n",
      "      - -191690.39232285554\n",
      "      - -191801.45119688584\n",
      "      - -192209.79950587984\n",
      "      - -191977.45206073695\n",
      "      - -191744.58146788325\n",
      "      - -189191.57076616018\n",
      "      - -192307.85700259265\n",
      "      - -192272.75268035138\n",
      "      - -190979.00942059382\n",
      "      - -192472.0375594328\n",
      "      - -191616.25347774156\n",
      "      - -191513.7927508259\n",
      "      - -188424.29088110686\n",
      "      - -193305.48105076476\n",
      "      - -190082.49889764542\n",
      "      - -190325.8939151876\n",
      "      - -193929.24997548416\n",
      "      - -190615.8184978819\n",
      "      - -192156.74092071186\n",
      "      - -191464.63338183536\n",
      "      - -191853.37651719697\n",
      "      - -192440.20133574947\n",
      "      - -189479.34946940403\n",
      "      - -190110.22535816176\n",
      "      - -192844.81418486196\n",
      "      - -191829.1999667713\n",
      "      - -188681.25139339347\n",
      "      - -194292.8803330451\n",
      "      - -192189.54364467034\n",
      "      - -191280.68644891636\n",
      "      - -190655.541583657\n",
      "      - -191984.70711101772\n",
      "      - -190883.00697952902\n",
      "      - -191553.70675208652\n",
      "      - -193134.72358927483\n",
      "      - -192637.65253007464\n",
      "      - -191553.02904174363\n",
      "      - -192882.2432885001\n",
      "      - -198485.97770636537\n",
      "      - -189196.45540598093\n",
      "      - -190001.2881371832\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09385672398570293\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4666491718684533\n",
      "      mean_inference_ms: 0.9670100824584463\n",
      "      mean_raw_obs_processing_ms: 0.1338354758182293\n",
      "  time_since_restore: 2330.117052078247\n",
      "  time_this_iter_s: 9.342468500137329\n",
      "  time_total_s: 2330.117052078247\n",
      "  timers:\n",
      "    learn_throughput: 124180.87\n",
      "    learn_time_ms: 515.248\n",
      "    load_throughput: 21110421.718\n",
      "    load_time_ms: 3.031\n",
      "    training_iteration_time_ms: 9166.117\n",
      "    update_time_ms: 3.749\n",
      "  timestamp: 1665851083\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 15612096\n",
      "  training_iteration: 244\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:24:49 (running for 00:39:23.57)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   244</td><td style=\"text-align: right;\">         2330.12</td><td style=\"text-align: right;\">15612096</td><td style=\"text-align: right;\"> -191674</td><td style=\"text-align: right;\">             -188424</td><td style=\"text-align: right;\">             -198486</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 15676080\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 15676080\n",
      "    num_agent_steps_trained: 15676080\n",
      "    num_env_steps_sampled: 15676080\n",
      "    num_env_steps_trained: 15676080\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-24-53\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -187705.03523260445\n",
      "  episode_reward_mean: -191598.599337599\n",
      "  episode_reward_min: -200634.92864797765\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 15672\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.099968671798706\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00048700885963626206\n",
      "          model: {}\n",
      "          policy_loss: 0.0059179989621043205\n",
      "          total_loss: 10.005705833435059\n",
      "          vf_explained_var: -2.554484801464696e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 15676080\n",
      "    num_agent_steps_trained: 15676080\n",
      "    num_env_steps_sampled: 15676080\n",
      "    num_env_steps_trained: 15676080\n",
      "  iterations_since_restore: 245\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 15676080\n",
      "  num_agent_steps_trained: 15676080\n",
      "  num_env_steps_sampled: 15676080\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 15676080\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.5\n",
      "    ram_util_percent: 89.26153846153845\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09386593277935866\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46657543861286194\n",
      "    mean_inference_ms: 0.9669736209350808\n",
      "    mean_raw_obs_processing_ms: 0.13397820071482144\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -187705.03523260445\n",
      "    episode_reward_mean: -191598.599337599\n",
      "    episode_reward_min: -200634.92864797765\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -191801.45119688584\n",
      "      - -192209.79950587984\n",
      "      - -191977.45206073695\n",
      "      - -191744.58146788325\n",
      "      - -189191.57076616018\n",
      "      - -192307.85700259265\n",
      "      - -192272.75268035138\n",
      "      - -190979.00942059382\n",
      "      - -192472.0375594328\n",
      "      - -191616.25347774156\n",
      "      - -191513.7927508259\n",
      "      - -188424.29088110686\n",
      "      - -193305.48105076476\n",
      "      - -190082.49889764542\n",
      "      - -190325.8939151876\n",
      "      - -193929.24997548416\n",
      "      - -190615.8184978819\n",
      "      - -192156.74092071186\n",
      "      - -191464.63338183536\n",
      "      - -191853.37651719697\n",
      "      - -192440.20133574947\n",
      "      - -189479.34946940403\n",
      "      - -190110.22535816176\n",
      "      - -192844.81418486196\n",
      "      - -191829.1999667713\n",
      "      - -188681.25139339347\n",
      "      - -194292.8803330451\n",
      "      - -192189.54364467034\n",
      "      - -191280.68644891636\n",
      "      - -190655.541583657\n",
      "      - -191984.70711101772\n",
      "      - -190883.00697952902\n",
      "      - -191553.70675208652\n",
      "      - -193134.72358927483\n",
      "      - -192637.65253007464\n",
      "      - -191553.02904174363\n",
      "      - -192882.2432885001\n",
      "      - -198485.97770636537\n",
      "      - -189196.45540598093\n",
      "      - -190001.2881371832\n",
      "      - -194408.55471447215\n",
      "      - -194565.31987290285\n",
      "      - -190896.1083598997\n",
      "      - -189782.43559392137\n",
      "      - -190219.51466685327\n",
      "      - -190735.02535292177\n",
      "      - -191009.37359985447\n",
      "      - -190673.34246319067\n",
      "      - -191971.78371386643\n",
      "      - -190639.89003425502\n",
      "      - -191606.97437789576\n",
      "      - -190602.33056632656\n",
      "      - -193495.6409095939\n",
      "      - -200634.92864797765\n",
      "      - -192518.98657483349\n",
      "      - -191560.14994596192\n",
      "      - -192166.14821716835\n",
      "      - -191984.25005224007\n",
      "      - -190308.72770777016\n",
      "      - -191560.8883265433\n",
      "      - -194469.59384901286\n",
      "      - -192084.8430405047\n",
      "      - -189456.95293673762\n",
      "      - -190792.99182583438\n",
      "      - -194751.51068528258\n",
      "      - -190809.80138641794\n",
      "      - -189608.8835542304\n",
      "      - -191078.68573239667\n",
      "      - -190698.90718882647\n",
      "      - -191194.01040025544\n",
      "      - -189367.04588481743\n",
      "      - -190671.75400147526\n",
      "      - -191222.4077068643\n",
      "      - -189313.83949010927\n",
      "      - -191580.4514975851\n",
      "      - -191030.82652256882\n",
      "      - -190441.7712454947\n",
      "      - -191764.42031802252\n",
      "      - -192365.41333153553\n",
      "      - -187705.03523260445\n",
      "      - -188645.6397833582\n",
      "      - -189847.9941335915\n",
      "      - -192714.43281143106\n",
      "      - -191860.1608070979\n",
      "      - -195668.63710847747\n",
      "      - -190729.27657529135\n",
      "      - -191736.5227660796\n",
      "      - -190710.8884148267\n",
      "      - -190453.03635482548\n",
      "      - -191901.03739289992\n",
      "      - -193682.18582921536\n",
      "      - -191733.30012397215\n",
      "      - -191405.77203146016\n",
      "      - -191423.93711209184\n",
      "      - -189666.13037680188\n",
      "      - -195671.24892763453\n",
      "      - -192869.04226408014\n",
      "      - -191383.09498319813\n",
      "      - -189555.4871021661\n",
      "      - -190091.56314509033\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09386593277935866\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46657543861286194\n",
      "      mean_inference_ms: 0.9669736209350808\n",
      "      mean_raw_obs_processing_ms: 0.13397820071482144\n",
      "  time_since_restore: 2339.2643609046936\n",
      "  time_this_iter_s: 9.147308826446533\n",
      "  time_total_s: 2339.2643609046936\n",
      "  timers:\n",
      "    learn_throughput: 122958.617\n",
      "    learn_time_ms: 520.37\n",
      "    load_throughput: 20987592.644\n",
      "    load_time_ms: 3.049\n",
      "    training_iteration_time_ms: 9158.694\n",
      "    update_time_ms: 3.634\n",
      "  timestamp: 1665851093\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 15676080\n",
      "  training_iteration: 245\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:24:58 (running for 00:39:32.54)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   245</td><td style=\"text-align: right;\">         2339.26</td><td style=\"text-align: right;\">15676080</td><td style=\"text-align: right;\"> -191599</td><td style=\"text-align: right;\">             -187705</td><td style=\"text-align: right;\">             -200635</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 15740064\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 15740064\n",
      "    num_agent_steps_trained: 15740064\n",
      "    num_env_steps_sampled: 15740064\n",
      "    num_env_steps_trained: 15740064\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-25-02\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -187705.03523260445\n",
      "  episode_reward_mean: -191083.73689303015\n",
      "  episode_reward_min: -197892.99919845044\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 15732\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1021220684051514\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0007320968434214592\n",
      "          model: {}\n",
      "          policy_loss: 0.0071622831746935844\n",
      "          total_loss: 10.006999969482422\n",
      "          vf_explained_var: -2.0814320933482122e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 15740064\n",
      "    num_agent_steps_trained: 15740064\n",
      "    num_env_steps_sampled: 15740064\n",
      "    num_env_steps_trained: 15740064\n",
      "  iterations_since_restore: 246\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 15740064\n",
      "  num_agent_steps_trained: 15740064\n",
      "  num_env_steps_sampled: 15740064\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 15740064\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 84.06153846153848\n",
      "    ram_util_percent: 89.2153846153846\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0938313032127088\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4665159571051693\n",
      "    mean_inference_ms: 0.9670188845898031\n",
      "    mean_raw_obs_processing_ms: 0.1339699700632549\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -187705.03523260445\n",
      "    episode_reward_mean: -191083.73689303015\n",
      "    episode_reward_min: -197892.99919845044\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -194469.59384901286\n",
      "      - -192084.8430405047\n",
      "      - -189456.95293673762\n",
      "      - -190792.99182583438\n",
      "      - -194751.51068528258\n",
      "      - -190809.80138641794\n",
      "      - -189608.8835542304\n",
      "      - -191078.68573239667\n",
      "      - -190698.90718882647\n",
      "      - -191194.01040025544\n",
      "      - -189367.04588481743\n",
      "      - -190671.75400147526\n",
      "      - -191222.4077068643\n",
      "      - -189313.83949010927\n",
      "      - -191580.4514975851\n",
      "      - -191030.82652256882\n",
      "      - -190441.7712454947\n",
      "      - -191764.42031802252\n",
      "      - -192365.41333153553\n",
      "      - -187705.03523260445\n",
      "      - -188645.6397833582\n",
      "      - -189847.9941335915\n",
      "      - -192714.43281143106\n",
      "      - -191860.1608070979\n",
      "      - -195668.63710847747\n",
      "      - -190729.27657529135\n",
      "      - -191736.5227660796\n",
      "      - -190710.8884148267\n",
      "      - -190453.03635482548\n",
      "      - -191901.03739289992\n",
      "      - -193682.18582921536\n",
      "      - -191733.30012397215\n",
      "      - -191405.77203146016\n",
      "      - -191423.93711209184\n",
      "      - -189666.13037680188\n",
      "      - -195671.24892763453\n",
      "      - -192869.04226408014\n",
      "      - -191383.09498319813\n",
      "      - -189555.4871021661\n",
      "      - -190091.56314509033\n",
      "      - -191686.36390153092\n",
      "      - -192328.55513641273\n",
      "      - -191127.5699099922\n",
      "      - -189202.65757106512\n",
      "      - -191475.2239591666\n",
      "      - -189267.35109830796\n",
      "      - -191183.2370902031\n",
      "      - -190816.99209050316\n",
      "      - -196739.3646436318\n",
      "      - -191961.17326339893\n",
      "      - -190438.73224549083\n",
      "      - -193999.6710111715\n",
      "      - -191238.441459469\n",
      "      - -189157.42591895678\n",
      "      - -188347.58384767282\n",
      "      - -190362.12825442507\n",
      "      - -188585.607293128\n",
      "      - -189716.20164648237\n",
      "      - -193643.825838978\n",
      "      - -189661.45729908798\n",
      "      - -193171.6122640351\n",
      "      - -190138.06570329092\n",
      "      - -187995.98883224628\n",
      "      - -190155.75979294063\n",
      "      - -190999.03039709324\n",
      "      - -192447.72929664858\n",
      "      - -189548.14949433564\n",
      "      - -191228.8236769824\n",
      "      - -189146.30528069878\n",
      "      - -191603.1555101073\n",
      "      - -193159.46565079436\n",
      "      - -197892.99919845044\n",
      "      - -189312.05626564103\n",
      "      - -194204.09508039165\n",
      "      - -189712.33894316194\n",
      "      - -189420.3297615907\n",
      "      - -190824.2247652034\n",
      "      - -190359.59412699784\n",
      "      - -191303.62035749428\n",
      "      - -193389.75548491502\n",
      "      - -189729.20204268504\n",
      "      - -191019.3143906257\n",
      "      - -191085.19602575226\n",
      "      - -191074.64845803689\n",
      "      - -190865.53014404935\n",
      "      - -190279.10540968445\n",
      "      - -191984.5312192522\n",
      "      - -192423.3807729653\n",
      "      - -189812.67909266346\n",
      "      - -191093.4489248206\n",
      "      - -190305.67651631738\n",
      "      - -189150.0226423839\n",
      "      - -189509.78901169432\n",
      "      - -189775.11166463202\n",
      "      - -190566.71746566796\n",
      "      - -189975.64364681128\n",
      "      - -191417.79700035558\n",
      "      - -189072.99871830235\n",
      "      - -189671.68845323173\n",
      "      - -190450.0104668179\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.0938313032127088\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4665159571051693\n",
      "      mean_inference_ms: 0.9670188845898031\n",
      "      mean_raw_obs_processing_ms: 0.1339699700632549\n",
      "  time_since_restore: 2349.0496587753296\n",
      "  time_this_iter_s: 9.785297870635986\n",
      "  time_total_s: 2349.0496587753296\n",
      "  timers:\n",
      "    learn_throughput: 121344.818\n",
      "    learn_time_ms: 527.291\n",
      "    load_throughput: 21065350.095\n",
      "    load_time_ms: 3.037\n",
      "    training_iteration_time_ms: 9177.053\n",
      "    update_time_ms: 3.731\n",
      "  timestamp: 1665851102\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 15740064\n",
      "  training_iteration: 246\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:25:03 (running for 00:39:37.58)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   246</td><td style=\"text-align: right;\">         2349.05</td><td style=\"text-align: right;\">15740064</td><td style=\"text-align: right;\"> -191084</td><td style=\"text-align: right;\">             -187705</td><td style=\"text-align: right;\">             -197893</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:25:08 (running for 00:39:42.59)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   246</td><td style=\"text-align: right;\">         2349.05</td><td style=\"text-align: right;\">15740064</td><td style=\"text-align: right;\"> -191084</td><td style=\"text-align: right;\">             -187705</td><td style=\"text-align: right;\">             -197893</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 15804048\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 15804048\n",
      "    num_agent_steps_trained: 15804048\n",
      "    num_env_steps_sampled: 15804048\n",
      "    num_env_steps_trained: 15804048\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-25-12\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -187116.2527508529\n",
      "  episode_reward_mean: -191672.7193689028\n",
      "  episode_reward_min: -217065.1196443312\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 15804\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1026830673217773\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0003826653119176626\n",
      "          model: {}\n",
      "          policy_loss: -0.0028248976450413465\n",
      "          total_loss: 9.996941566467285\n",
      "          vf_explained_var: -1.9868215517249155e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 15804048\n",
      "    num_agent_steps_trained: 15804048\n",
      "    num_env_steps_sampled: 15804048\n",
      "    num_env_steps_trained: 15804048\n",
      "  iterations_since_restore: 247\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 15804048\n",
      "  num_agent_steps_trained: 15804048\n",
      "  num_env_steps_sampled: 15804048\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 15804048\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 80.57857142857144\n",
      "    ram_util_percent: 89.41428571428573\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09380574274250844\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4664864603457152\n",
      "    mean_inference_ms: 0.9670365361633952\n",
      "    mean_raw_obs_processing_ms: 0.13377985304442702\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -187116.2527508529\n",
      "    episode_reward_mean: -191672.7193689028\n",
      "    episode_reward_min: -217065.1196443312\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -189312.05626564103\n",
      "      - -194204.09508039165\n",
      "      - -189712.33894316194\n",
      "      - -189420.3297615907\n",
      "      - -190824.2247652034\n",
      "      - -190359.59412699784\n",
      "      - -191303.62035749428\n",
      "      - -193389.75548491502\n",
      "      - -189729.20204268504\n",
      "      - -191019.3143906257\n",
      "      - -191085.19602575226\n",
      "      - -191074.64845803689\n",
      "      - -190865.53014404935\n",
      "      - -190279.10540968445\n",
      "      - -191984.5312192522\n",
      "      - -192423.3807729653\n",
      "      - -189812.67909266346\n",
      "      - -191093.4489248206\n",
      "      - -190305.67651631738\n",
      "      - -189150.0226423839\n",
      "      - -189509.78901169432\n",
      "      - -189775.11166463202\n",
      "      - -190566.71746566796\n",
      "      - -189975.64364681128\n",
      "      - -191417.79700035558\n",
      "      - -189072.99871830235\n",
      "      - -189671.68845323173\n",
      "      - -190450.0104668179\n",
      "      - -193390.53144810407\n",
      "      - -192499.87390805883\n",
      "      - -187116.2527508529\n",
      "      - -192300.2927688395\n",
      "      - -189922.1590069935\n",
      "      - -190018.70550912732\n",
      "      - -191593.3429065038\n",
      "      - -190513.2162587012\n",
      "      - -189763.45291733122\n",
      "      - -192189.34041834786\n",
      "      - -188511.44325229694\n",
      "      - -193394.48531398052\n",
      "      - -192765.61944441008\n",
      "      - -190418.66832205854\n",
      "      - -189289.68250292173\n",
      "      - -193779.9997012108\n",
      "      - -188744.8514912632\n",
      "      - -189195.27515433147\n",
      "      - -190401.68138337962\n",
      "      - -190727.6142836537\n",
      "      - -191476.7601169157\n",
      "      - -190934.44109663955\n",
      "      - -193491.33433272704\n",
      "      - -190759.56796045956\n",
      "      - -192183.22182102353\n",
      "      - -191057.9773758503\n",
      "      - -193212.33059544672\n",
      "      - -188723.97263985913\n",
      "      - -198419.8855910571\n",
      "      - -191332.7414100542\n",
      "      - -188058.8920967456\n",
      "      - -216171.47758507993\n",
      "      - -189061.4257249377\n",
      "      - -217065.1196443312\n",
      "      - -191552.15621376713\n",
      "      - -190907.45236014712\n",
      "      - -198964.70270596095\n",
      "      - -193052.27878774024\n",
      "      - -191382.33928192616\n",
      "      - -193130.7872849478\n",
      "      - -189883.8518519979\n",
      "      - -190935.37822701226\n",
      "      - -189664.08970709043\n",
      "      - -189600.32914671573\n",
      "      - -192332.36029148145\n",
      "      - -190884.11913436756\n",
      "      - -189861.91968395317\n",
      "      - -191251.04588022252\n",
      "      - -191995.93713038656\n",
      "      - -192546.12273914966\n",
      "      - -189602.60111230967\n",
      "      - -191469.86551059643\n",
      "      - -191005.7619574584\n",
      "      - -191300.90139459813\n",
      "      - -191575.25703878186\n",
      "      - -191609.14341897043\n",
      "      - -189995.20350754622\n",
      "      - -190550.6466309403\n",
      "      - -192712.67197825143\n",
      "      - -192082.67119468172\n",
      "      - -190924.77914049884\n",
      "      - -193443.2162163666\n",
      "      - -190995.36347818282\n",
      "      - -191372.11532529985\n",
      "      - -192674.497136008\n",
      "      - -191789.1419010945\n",
      "      - -192411.03811653264\n",
      "      - -192259.2551538576\n",
      "      - -191005.0780083619\n",
      "      - -189296.65393418056\n",
      "      - -192270.4445462981\n",
      "      - -192706.61617695814\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09380574274250844\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4664864603457152\n",
      "      mean_inference_ms: 0.9670365361633952\n",
      "      mean_raw_obs_processing_ms: 0.13377985304442702\n",
      "  time_since_restore: 2358.4605350494385\n",
      "  time_this_iter_s: 9.410876274108887\n",
      "  time_total_s: 2358.4605350494385\n",
      "  timers:\n",
      "    learn_throughput: 121541.23\n",
      "    learn_time_ms: 526.439\n",
      "    load_throughput: 21122717.245\n",
      "    load_time_ms: 3.029\n",
      "    training_iteration_time_ms: 9186.858\n",
      "    update_time_ms: 3.831\n",
      "  timestamp: 1665851112\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 15804048\n",
      "  training_iteration: 247\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:25:18 (running for 00:39:52.43)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   247</td><td style=\"text-align: right;\">         2358.46</td><td style=\"text-align: right;\">15804048</td><td style=\"text-align: right;\"> -191673</td><td style=\"text-align: right;\">             -187116</td><td style=\"text-align: right;\">             -217065</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 15868032\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 15868032\n",
      "    num_agent_steps_trained: 15868032\n",
      "    num_env_steps_sampled: 15868032\n",
      "    num_env_steps_trained: 15868032\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-25-22\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -187867.36122460547\n",
      "  episode_reward_mean: -191599.72991320622\n",
      "  episode_reward_min: -217065.1196443312\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 15864\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.100210189819336\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0008237868314608932\n",
      "          model: {}\n",
      "          policy_loss: 0.005467996932566166\n",
      "          total_loss: 10.00532341003418\n",
      "          vf_explained_var: -1.9868215517249155e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 15868032\n",
      "    num_agent_steps_trained: 15868032\n",
      "    num_env_steps_sampled: 15868032\n",
      "    num_env_steps_trained: 15868032\n",
      "  iterations_since_restore: 248\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 15868032\n",
      "  num_agent_steps_trained: 15868032\n",
      "  num_env_steps_sampled: 15868032\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 15868032\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.37692307692306\n",
      "    ram_util_percent: 89.26923076923079\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09381809245584816\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46642888108845343\n",
      "    mean_inference_ms: 0.9672421477316274\n",
      "    mean_raw_obs_processing_ms: 0.13392815411201783\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -187867.36122460547\n",
      "    episode_reward_mean: -191599.72991320622\n",
      "    episode_reward_min: -217065.1196443312\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -189061.4257249377\n",
      "      - -217065.1196443312\n",
      "      - -191552.15621376713\n",
      "      - -190907.45236014712\n",
      "      - -198964.70270596095\n",
      "      - -193052.27878774024\n",
      "      - -191382.33928192616\n",
      "      - -193130.7872849478\n",
      "      - -189883.8518519979\n",
      "      - -190935.37822701226\n",
      "      - -189664.08970709043\n",
      "      - -189600.32914671573\n",
      "      - -192332.36029148145\n",
      "      - -190884.11913436756\n",
      "      - -189861.91968395317\n",
      "      - -191251.04588022252\n",
      "      - -191995.93713038656\n",
      "      - -192546.12273914966\n",
      "      - -189602.60111230967\n",
      "      - -191469.86551059643\n",
      "      - -191005.7619574584\n",
      "      - -191300.90139459813\n",
      "      - -191575.25703878186\n",
      "      - -191609.14341897043\n",
      "      - -189995.20350754622\n",
      "      - -190550.6466309403\n",
      "      - -192712.67197825143\n",
      "      - -192082.67119468172\n",
      "      - -190924.77914049884\n",
      "      - -193443.2162163666\n",
      "      - -190995.36347818282\n",
      "      - -191372.11532529985\n",
      "      - -192674.497136008\n",
      "      - -191789.1419010945\n",
      "      - -192411.03811653264\n",
      "      - -192259.2551538576\n",
      "      - -191005.0780083619\n",
      "      - -189296.65393418056\n",
      "      - -192270.4445462981\n",
      "      - -192706.61617695814\n",
      "      - -189750.93155473753\n",
      "      - -191068.8724000476\n",
      "      - -193828.89667633828\n",
      "      - -188509.37444636278\n",
      "      - -191729.3966419243\n",
      "      - -190776.82083664252\n",
      "      - -189441.39616649377\n",
      "      - -191450.7417032867\n",
      "      - -189714.9575192127\n",
      "      - -193141.63992913693\n",
      "      - -189504.93240126685\n",
      "      - -191475.87735143345\n",
      "      - -191085.54514107417\n",
      "      - -192681.18025339989\n",
      "      - -188874.01605075604\n",
      "      - -189341.21306881515\n",
      "      - -192205.0908801731\n",
      "      - -190677.0683093193\n",
      "      - -190206.21232798614\n",
      "      - -190422.94771944953\n",
      "      - -189850.82835604413\n",
      "      - -189128.5172939878\n",
      "      - -192033.8477000851\n",
      "      - -192344.1138154726\n",
      "      - -187867.36122460547\n",
      "      - -190573.96766412578\n",
      "      - -190587.9528171891\n",
      "      - -197930.21747834617\n",
      "      - -188374.65235907322\n",
      "      - -190525.2586119014\n",
      "      - -189299.39586761125\n",
      "      - -191409.39207622883\n",
      "      - -191340.63173100044\n",
      "      - -189614.45906263017\n",
      "      - -188172.97367802367\n",
      "      - -191527.49134415638\n",
      "      - -192195.6873359735\n",
      "      - -190848.7437166717\n",
      "      - -192127.61072657743\n",
      "      - -192847.7803061422\n",
      "      - -189492.35122700682\n",
      "      - -192183.1299248967\n",
      "      - -190241.27241651493\n",
      "      - -191587.66599537706\n",
      "      - -194493.01022664414\n",
      "      - -205921.64810717772\n",
      "      - -190456.89793493474\n",
      "      - -190824.03056322486\n",
      "      - -189676.9504093852\n",
      "      - -190289.8407305754\n",
      "      - -189043.13430538913\n",
      "      - -190625.40669342718\n",
      "      - -190779.24498623604\n",
      "      - -194209.02442041654\n",
      "      - -192038.70938315566\n",
      "      - -189292.9806341857\n",
      "      - -190029.5652490934\n",
      "      - -191542.43298300626\n",
      "      - -192889.92369589477\n",
      "      - -192743.43821646707\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09381809245584816\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46642888108845343\n",
      "      mean_inference_ms: 0.9672421477316274\n",
      "      mean_raw_obs_processing_ms: 0.13392815411201783\n",
      "  time_since_restore: 2368.111479997635\n",
      "  time_this_iter_s: 9.650944948196411\n",
      "  time_total_s: 2368.111479997635\n",
      "  timers:\n",
      "    learn_throughput: 121094.199\n",
      "    learn_time_ms: 528.382\n",
      "    load_throughput: 21541156.741\n",
      "    load_time_ms: 2.97\n",
      "    training_iteration_time_ms: 9244.829\n",
      "    update_time_ms: 3.897\n",
      "  timestamp: 1665851122\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 15868032\n",
      "  training_iteration: 248\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:25:27 (running for 00:40:01.46)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   248</td><td style=\"text-align: right;\">         2368.11</td><td style=\"text-align: right;\">15868032</td><td style=\"text-align: right;\"> -191600</td><td style=\"text-align: right;\">             -187867</td><td style=\"text-align: right;\">             -217065</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 15932016\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 15932016\n",
      "    num_agent_steps_trained: 15932016\n",
      "    num_env_steps_sampled: 15932016\n",
      "    num_env_steps_trained: 15932016\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-25-31\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -187867.36122460547\n",
      "  episode_reward_mean: -191806.64537870124\n",
      "  episode_reward_min: -214549.13058164722\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 15924\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.103611707687378\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00046999819460324943\n",
      "          model: {}\n",
      "          policy_loss: 0.007467182818800211\n",
      "          total_loss: 10.00725269317627\n",
      "          vf_explained_var: -2.932926967957883e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 15932016\n",
      "    num_agent_steps_trained: 15932016\n",
      "    num_env_steps_sampled: 15932016\n",
      "    num_env_steps_trained: 15932016\n",
      "  iterations_since_restore: 249\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 15932016\n",
      "  num_agent_steps_trained: 15932016\n",
      "  num_env_steps_sampled: 15932016\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 15932016\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 80.66153846153846\n",
      "    ram_util_percent: 89.12307692307692\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09378013322982635\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46641836685746085\n",
      "    mean_inference_ms: 0.9671349236299858\n",
      "    mean_raw_obs_processing_ms: 0.13391453965206498\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -187867.36122460547\n",
      "    episode_reward_mean: -191806.64537870124\n",
      "    episode_reward_min: -214549.13058164722\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -189850.82835604413\n",
      "      - -189128.5172939878\n",
      "      - -192033.8477000851\n",
      "      - -192344.1138154726\n",
      "      - -187867.36122460547\n",
      "      - -190573.96766412578\n",
      "      - -190587.9528171891\n",
      "      - -197930.21747834617\n",
      "      - -188374.65235907322\n",
      "      - -190525.2586119014\n",
      "      - -189299.39586761125\n",
      "      - -191409.39207622883\n",
      "      - -191340.63173100044\n",
      "      - -189614.45906263017\n",
      "      - -188172.97367802367\n",
      "      - -191527.49134415638\n",
      "      - -192195.6873359735\n",
      "      - -190848.7437166717\n",
      "      - -192127.61072657743\n",
      "      - -192847.7803061422\n",
      "      - -189492.35122700682\n",
      "      - -192183.1299248967\n",
      "      - -190241.27241651493\n",
      "      - -191587.66599537706\n",
      "      - -194493.01022664414\n",
      "      - -205921.64810717772\n",
      "      - -190456.89793493474\n",
      "      - -190824.03056322486\n",
      "      - -189676.9504093852\n",
      "      - -190289.8407305754\n",
      "      - -189043.13430538913\n",
      "      - -190625.40669342718\n",
      "      - -190779.24498623604\n",
      "      - -194209.02442041654\n",
      "      - -192038.70938315566\n",
      "      - -189292.9806341857\n",
      "      - -190029.5652490934\n",
      "      - -191542.43298300626\n",
      "      - -192889.92369589477\n",
      "      - -192743.43821646707\n",
      "      - -190684.26139725166\n",
      "      - -192968.423340568\n",
      "      - -191002.97053061187\n",
      "      - -191693.74696497293\n",
      "      - -192819.94736226668\n",
      "      - -190311.18233910797\n",
      "      - -192224.08239281643\n",
      "      - -192162.07113442742\n",
      "      - -191645.5009217359\n",
      "      - -192921.4427102534\n",
      "      - -190023.76278398052\n",
      "      - -190415.44620947316\n",
      "      - -188033.16278639788\n",
      "      - -191835.99642797717\n",
      "      - -190533.16229506474\n",
      "      - -193246.2125105276\n",
      "      - -193220.0638440107\n",
      "      - -192091.55687518482\n",
      "      - -192391.06173575396\n",
      "      - -193067.9637514811\n",
      "      - -189577.12107683564\n",
      "      - -192055.04242239366\n",
      "      - -190206.77258767773\n",
      "      - -191325.84663814108\n",
      "      - -192766.90904680837\n",
      "      - -191540.56754260208\n",
      "      - -194329.1714424805\n",
      "      - -189087.49871668097\n",
      "      - -189920.8033065904\n",
      "      - -190287.43269432746\n",
      "      - -189418.2797913257\n",
      "      - -192732.75944014528\n",
      "      - -190732.46923636217\n",
      "      - -190516.83988938195\n",
      "      - -193728.03457903917\n",
      "      - -190554.02908025784\n",
      "      - -189615.511176624\n",
      "      - -189933.0625033581\n",
      "      - -190270.34736624456\n",
      "      - -191356.11762500793\n",
      "      - -190761.85852131573\n",
      "      - -189999.24158532865\n",
      "      - -191816.47028302128\n",
      "      - -214549.13058164722\n",
      "      - -191248.58954001951\n",
      "      - -192566.3281062011\n",
      "      - -189567.9805149324\n",
      "      - -191500.53982019905\n",
      "      - -192252.77029187075\n",
      "      - -202486.3551852922\n",
      "      - -192102.96276233924\n",
      "      - -191606.09720242405\n",
      "      - -193235.45306323766\n",
      "      - -197170.85956040522\n",
      "      - -190926.61361996812\n",
      "      - -192406.05386380796\n",
      "      - -191819.1783237384\n",
      "      - -190673.06338628868\n",
      "      - -191850.47445960096\n",
      "      - -191916.34145348537\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09378013322982635\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46641836685746085\n",
      "      mean_inference_ms: 0.9671349236299858\n",
      "      mean_raw_obs_processing_ms: 0.13391453965206498\n",
      "  time_since_restore: 2377.319205760956\n",
      "  time_this_iter_s: 9.207725763320923\n",
      "  time_total_s: 2377.319205760956\n",
      "  timers:\n",
      "    learn_throughput: 119453.694\n",
      "    learn_time_ms: 535.639\n",
      "    load_throughput: 21414988.041\n",
      "    load_time_ms: 2.988\n",
      "    training_iteration_time_ms: 9256.71\n",
      "    update_time_ms: 3.987\n",
      "  timestamp: 1665851131\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 15932016\n",
      "  training_iteration: 249\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:25:36 (running for 00:40:10.95)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   249</td><td style=\"text-align: right;\">         2377.32</td><td style=\"text-align: right;\">15932016</td><td style=\"text-align: right;\"> -191807</td><td style=\"text-align: right;\">             -187867</td><td style=\"text-align: right;\">             -214549</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 15996000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 15996000\n",
      "    num_agent_steps_trained: 15996000\n",
      "    num_env_steps_sampled: 15996000\n",
      "    num_env_steps_trained: 15996000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-25-40\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -188516.8140987884\n",
      "  episode_reward_mean: -191868.9426431584\n",
      "  episode_reward_min: -214549.13058164722\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 15996\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.107570171356201\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0008016292122192681\n",
      "          model: {}\n",
      "          policy_loss: -0.0038058862555772066\n",
      "          total_loss: 9.996042251586914\n",
      "          vf_explained_var: -6.622738357719982e-09\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 15996000\n",
      "    num_agent_steps_trained: 15996000\n",
      "    num_env_steps_sampled: 15996000\n",
      "    num_env_steps_trained: 15996000\n",
      "  iterations_since_restore: 250\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 15996000\n",
      "  num_agent_steps_trained: 15996000\n",
      "  num_env_steps_sampled: 15996000\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 15996000\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 85.39230769230768\n",
      "    ram_util_percent: 89.16153846153846\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09375860133384745\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46648511601812415\n",
      "    mean_inference_ms: 0.9669436964688137\n",
      "    mean_raw_obs_processing_ms: 0.13373138884914115\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -188516.8140987884\n",
      "    episode_reward_mean: -191868.9426431584\n",
      "    episode_reward_min: -214549.13058164722\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -190732.46923636217\n",
      "      - -190516.83988938195\n",
      "      - -193728.03457903917\n",
      "      - -190554.02908025784\n",
      "      - -189615.511176624\n",
      "      - -189933.0625033581\n",
      "      - -190270.34736624456\n",
      "      - -191356.11762500793\n",
      "      - -190761.85852131573\n",
      "      - -189999.24158532865\n",
      "      - -191816.47028302128\n",
      "      - -214549.13058164722\n",
      "      - -191248.58954001951\n",
      "      - -192566.3281062011\n",
      "      - -189567.9805149324\n",
      "      - -191500.53982019905\n",
      "      - -192252.77029187075\n",
      "      - -202486.3551852922\n",
      "      - -192102.96276233924\n",
      "      - -191606.09720242405\n",
      "      - -193235.45306323766\n",
      "      - -197170.85956040522\n",
      "      - -190926.61361996812\n",
      "      - -192406.05386380796\n",
      "      - -191819.1783237384\n",
      "      - -190673.06338628868\n",
      "      - -191850.47445960096\n",
      "      - -191916.34145348537\n",
      "      - -190760.9694231899\n",
      "      - -192409.74029146563\n",
      "      - -191727.440040452\n",
      "      - -189246.99329462746\n",
      "      - -189697.0071824477\n",
      "      - -192626.2194809061\n",
      "      - -191782.17436196475\n",
      "      - -193188.3190376784\n",
      "      - -193440.37227491738\n",
      "      - -190322.68321787\n",
      "      - -188548.75261151383\n",
      "      - -189378.29178370474\n",
      "      - -194689.70622779598\n",
      "      - -190312.25314608205\n",
      "      - -190228.82618944225\n",
      "      - -190267.24332613923\n",
      "      - -193119.80643535918\n",
      "      - -191887.7518826423\n",
      "      - -189096.57225933383\n",
      "      - -191027.27750584306\n",
      "      - -191459.26616708114\n",
      "      - -189676.12038296077\n",
      "      - -189767.11974906406\n",
      "      - -194490.5249939479\n",
      "      - -191071.2414871339\n",
      "      - -192953.38451972068\n",
      "      - -190729.26227006034\n",
      "      - -192033.25269879296\n",
      "      - -191438.20047816154\n",
      "      - -202896.8240054821\n",
      "      - -190603.54253645995\n",
      "      - -191442.78892456964\n",
      "      - -197412.25873429741\n",
      "      - -191280.68655924633\n",
      "      - -190463.87344384432\n",
      "      - -193467.15709870178\n",
      "      - -193073.26257142698\n",
      "      - -190065.69234796398\n",
      "      - -191460.74875458633\n",
      "      - -190502.20837290894\n",
      "      - -190216.51375506737\n",
      "      - -189695.64289594442\n",
      "      - -194149.5002906215\n",
      "      - -190898.72762061688\n",
      "      - -190376.08788139175\n",
      "      - -191448.37670636238\n",
      "      - -192496.54028463614\n",
      "      - -192638.45488963756\n",
      "      - -191077.8251594348\n",
      "      - -195916.24767566868\n",
      "      - -188516.8140987884\n",
      "      - -191108.36319738976\n",
      "      - -190408.69536073558\n",
      "      - -188699.92796322124\n",
      "      - -191624.87999817482\n",
      "      - -191707.32271656973\n",
      "      - -194160.35221547552\n",
      "      - -191614.88299447353\n",
      "      - -190195.84167945382\n",
      "      - -188940.5909864695\n",
      "      - -192654.68799028726\n",
      "      - -189979.22961651778\n",
      "      - -191609.8475418461\n",
      "      - -190605.0341135069\n",
      "      - -189963.3910670852\n",
      "      - -191089.63834575942\n",
      "      - -192687.25100944962\n",
      "      - -190315.79595366743\n",
      "      - -190693.69685639528\n",
      "      - -188965.79420462067\n",
      "      - -192173.9020191034\n",
      "      - -193055.81757628295\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09375860133384745\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46648511601812415\n",
      "      mean_inference_ms: 0.9669436964688137\n",
      "      mean_raw_obs_processing_ms: 0.13373138884914115\n",
      "  time_since_restore: 2386.8634939193726\n",
      "  time_this_iter_s: 9.544288158416748\n",
      "  time_total_s: 2386.8634939193726\n",
      "  timers:\n",
      "    learn_throughput: 119070.094\n",
      "    learn_time_ms: 537.364\n",
      "    load_throughput: 21438596.192\n",
      "    load_time_ms: 2.985\n",
      "    training_iteration_time_ms: 9270.445\n",
      "    update_time_ms: 4.051\n",
      "  timestamp: 1665851140\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 15996000\n",
      "  training_iteration: 250\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:25:46 (running for 00:40:20.72)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   250</td><td style=\"text-align: right;\">         2386.86</td><td style=\"text-align: right;\">15996000</td><td style=\"text-align: right;\"> -191869</td><td style=\"text-align: right;\">             -188517</td><td style=\"text-align: right;\">             -214549</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 16059984\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 16059984\n",
      "    num_agent_steps_trained: 16059984\n",
      "    num_env_steps_sampled: 16059984\n",
      "    num_env_steps_trained: 16059984\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-25-50\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -187793.06285268904\n",
      "  episode_reward_mean: -191463.09912777078\n",
      "  episode_reward_min: -203542.1811713846\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 16056\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1066107749938965\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00038216603570617735\n",
      "          model: {}\n",
      "          policy_loss: 0.006209576036781073\n",
      "          total_loss: 10.005975723266602\n",
      "          vf_explained_var: -1.6083793852317285e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 16059984\n",
      "    num_agent_steps_trained: 16059984\n",
      "    num_env_steps_sampled: 16059984\n",
      "    num_env_steps_trained: 16059984\n",
      "  iterations_since_restore: 251\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 16059984\n",
      "  num_agent_steps_trained: 16059984\n",
      "  num_env_steps_sampled: 16059984\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 16059984\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 85.65384615384616\n",
      "    ram_util_percent: 89.03846153846153\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09378755704481043\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46648858469592397\n",
      "    mean_inference_ms: 0.9670923960222606\n",
      "    mean_raw_obs_processing_ms: 0.13390268890688434\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -187793.06285268904\n",
      "    episode_reward_mean: -191463.09912777078\n",
      "    episode_reward_min: -203542.1811713846\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -197412.25873429741\n",
      "      - -191280.68655924633\n",
      "      - -190463.87344384432\n",
      "      - -193467.15709870178\n",
      "      - -193073.26257142698\n",
      "      - -190065.69234796398\n",
      "      - -191460.74875458633\n",
      "      - -190502.20837290894\n",
      "      - -190216.51375506737\n",
      "      - -189695.64289594442\n",
      "      - -194149.5002906215\n",
      "      - -190898.72762061688\n",
      "      - -190376.08788139175\n",
      "      - -191448.37670636238\n",
      "      - -192496.54028463614\n",
      "      - -192638.45488963756\n",
      "      - -191077.8251594348\n",
      "      - -195916.24767566868\n",
      "      - -188516.8140987884\n",
      "      - -191108.36319738976\n",
      "      - -190408.69536073558\n",
      "      - -188699.92796322124\n",
      "      - -191624.87999817482\n",
      "      - -191707.32271656973\n",
      "      - -194160.35221547552\n",
      "      - -191614.88299447353\n",
      "      - -190195.84167945382\n",
      "      - -188940.5909864695\n",
      "      - -192654.68799028726\n",
      "      - -189979.22961651778\n",
      "      - -191609.8475418461\n",
      "      - -190605.0341135069\n",
      "      - -189963.3910670852\n",
      "      - -191089.63834575942\n",
      "      - -192687.25100944962\n",
      "      - -190315.79595366743\n",
      "      - -190693.69685639528\n",
      "      - -188965.79420462067\n",
      "      - -192173.9020191034\n",
      "      - -193055.81757628295\n",
      "      - -187793.06285268904\n",
      "      - -189763.7864305205\n",
      "      - -192553.2640027227\n",
      "      - -188663.319084862\n",
      "      - -189595.17786485952\n",
      "      - -192397.48865255373\n",
      "      - -191353.73147628712\n",
      "      - -190614.30391858536\n",
      "      - -189904.38041584234\n",
      "      - -191251.16261905275\n",
      "      - -190460.62513071104\n",
      "      - -191545.64177644497\n",
      "      - -189676.84575507182\n",
      "      - -192116.8198417198\n",
      "      - -203542.1811713846\n",
      "      - -190620.79043010887\n",
      "      - -191380.99569873686\n",
      "      - -191788.79602736165\n",
      "      - -193220.13031756558\n",
      "      - -190012.37452065793\n",
      "      - -188818.29099623475\n",
      "      - -190811.4174409757\n",
      "      - -190667.75225051006\n",
      "      - -192037.6944623889\n",
      "      - -189134.43563544014\n",
      "      - -191440.46860172928\n",
      "      - -191457.9444466307\n",
      "      - -192354.71591404412\n",
      "      - -191933.61025162326\n",
      "      - -190637.70662711718\n",
      "      - -191747.66858753096\n",
      "      - -190442.2512957223\n",
      "      - -189953.79003463345\n",
      "      - -197656.43154069176\n",
      "      - -189412.78580011535\n",
      "      - -190108.28172723984\n",
      "      - -197490.74219522084\n",
      "      - -191690.0120960544\n",
      "      - -191027.88106535652\n",
      "      - -192841.70137618456\n",
      "      - -191432.46615846382\n",
      "      - -191429.4410830941\n",
      "      - -190237.75967437503\n",
      "      - -192887.22342330284\n",
      "      - -191280.9850033056\n",
      "      - -193389.1993002828\n",
      "      - -190356.8369707424\n",
      "      - -192335.74465041724\n",
      "      - -189009.79951028578\n",
      "      - -191321.38831224066\n",
      "      - -189698.67575086595\n",
      "      - -190893.93555967018\n",
      "      - -195882.26925035648\n",
      "      - -191638.98894944479\n",
      "      - -191181.0689922086\n",
      "      - -190520.88899313583\n",
      "      - -191757.58753533725\n",
      "      - -191002.37865051738\n",
      "      - -190758.34959270892\n",
      "      - -191962.9025355103\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09378755704481043\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46648858469592397\n",
      "      mean_inference_ms: 0.9670923960222606\n",
      "      mean_raw_obs_processing_ms: 0.13390268890688434\n",
      "  time_since_restore: 2396.489212036133\n",
      "  time_this_iter_s: 9.625718116760254\n",
      "  time_total_s: 2396.489212036133\n",
      "  timers:\n",
      "    learn_throughput: 127959.452\n",
      "    learn_time_ms: 500.033\n",
      "    load_throughput: 21333784.899\n",
      "    load_time_ms: 2.999\n",
      "    training_iteration_time_ms: 9356.94\n",
      "    update_time_ms: 4.1\n",
      "  timestamp: 1665851150\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 16059984\n",
      "  training_iteration: 251\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:25:55 (running for 00:40:29.94)<br>Memory usage on this node: 13.7/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   251</td><td style=\"text-align: right;\">         2396.49</td><td style=\"text-align: right;\">16059984</td><td style=\"text-align: right;\"> -191463</td><td style=\"text-align: right;\">             -187793</td><td style=\"text-align: right;\">             -203542</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 16123968\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 16123968\n",
      "    num_agent_steps_trained: 16123968\n",
      "    num_env_steps_sampled: 16123968\n",
      "    num_env_steps_trained: 16123968\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-25-59\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -188009.04607286467\n",
      "  episode_reward_mean: -191603.4590843967\n",
      "  episode_reward_min: -201486.06732959877\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 16116\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.112828254699707\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0005847421707585454\n",
      "          model: {}\n",
      "          policy_loss: 0.007334425579756498\n",
      "          total_loss: 10.00714111328125\n",
      "          vf_explained_var: -1.9868215517249155e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 16123968\n",
      "    num_agent_steps_trained: 16123968\n",
      "    num_env_steps_sampled: 16123968\n",
      "    num_env_steps_trained: 16123968\n",
      "  iterations_since_restore: 252\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 16123968\n",
      "  num_agent_steps_trained: 16123968\n",
      "  num_env_steps_sampled: 16123968\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 16123968\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.69230769230768\n",
      "    ram_util_percent: 88.89230769230768\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09376388557201844\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.466476794708179\n",
      "    mean_inference_ms: 0.9670547712484219\n",
      "    mean_raw_obs_processing_ms: 0.1339081637387805\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -188009.04607286467\n",
      "    episode_reward_mean: -191603.4590843967\n",
      "    episode_reward_min: -201486.06732959877\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -188818.29099623475\n",
      "      - -190811.4174409757\n",
      "      - -190667.75225051006\n",
      "      - -192037.6944623889\n",
      "      - -189134.43563544014\n",
      "      - -191440.46860172928\n",
      "      - -191457.9444466307\n",
      "      - -192354.71591404412\n",
      "      - -191933.61025162326\n",
      "      - -190637.70662711718\n",
      "      - -191747.66858753096\n",
      "      - -190442.2512957223\n",
      "      - -189953.79003463345\n",
      "      - -197656.43154069176\n",
      "      - -189412.78580011535\n",
      "      - -190108.28172723984\n",
      "      - -197490.74219522084\n",
      "      - -191690.0120960544\n",
      "      - -191027.88106535652\n",
      "      - -192841.70137618456\n",
      "      - -191432.46615846382\n",
      "      - -191429.4410830941\n",
      "      - -190237.75967437503\n",
      "      - -192887.22342330284\n",
      "      - -191280.9850033056\n",
      "      - -193389.1993002828\n",
      "      - -190356.8369707424\n",
      "      - -192335.74465041724\n",
      "      - -189009.79951028578\n",
      "      - -191321.38831224066\n",
      "      - -189698.67575086595\n",
      "      - -190893.93555967018\n",
      "      - -195882.26925035648\n",
      "      - -191638.98894944479\n",
      "      - -191181.0689922086\n",
      "      - -190520.88899313583\n",
      "      - -191757.58753533725\n",
      "      - -191002.37865051738\n",
      "      - -190758.34959270892\n",
      "      - -191962.9025355103\n",
      "      - -188860.84886816988\n",
      "      - -192526.4124272066\n",
      "      - -192426.3104293833\n",
      "      - -191194.116911635\n",
      "      - -192610.83664301495\n",
      "      - -194996.00372734666\n",
      "      - -190441.39387008708\n",
      "      - -190380.50570650314\n",
      "      - -192127.9248640278\n",
      "      - -190896.5973010753\n",
      "      - -191845.24170372903\n",
      "      - -191833.593880755\n",
      "      - -189515.1370575762\n",
      "      - -190763.06373424362\n",
      "      - -190871.54021063328\n",
      "      - -193007.0206473936\n",
      "      - -201486.06732959877\n",
      "      - -190699.206896556\n",
      "      - -192104.82889815082\n",
      "      - -189925.78204871755\n",
      "      - -192523.7964658098\n",
      "      - -190857.707802591\n",
      "      - -192837.82726764848\n",
      "      - -191839.2781024689\n",
      "      - -190908.49888707834\n",
      "      - -191524.40785706296\n",
      "      - -193529.06165457875\n",
      "      - -192589.97979236252\n",
      "      - -190342.14769885747\n",
      "      - -189088.4573269833\n",
      "      - -191433.68177592198\n",
      "      - -189493.30662964605\n",
      "      - -191968.82682756078\n",
      "      - -192540.03496359158\n",
      "      - -190848.7287406492\n",
      "      - -188009.04607286467\n",
      "      - -193641.38295808394\n",
      "      - -193378.73481345584\n",
      "      - -192325.08862323727\n",
      "      - -190095.60506981792\n",
      "      - -191824.47903855433\n",
      "      - -189891.68011407027\n",
      "      - -190975.91954514195\n",
      "      - -195173.76138884437\n",
      "      - -190410.49009837647\n",
      "      - -190855.77233220532\n",
      "      - -191586.17429271087\n",
      "      - -189831.14192223336\n",
      "      - -188306.5989766684\n",
      "      - -192467.7603370506\n",
      "      - -189300.05247380724\n",
      "      - -191929.60167585473\n",
      "      - -192894.5862174831\n",
      "      - -194833.8090098001\n",
      "      - -192863.90048680478\n",
      "      - -189653.11276958144\n",
      "      - -189888.6867401717\n",
      "      - -192714.9525288242\n",
      "      - -192315.32903199442\n",
      "      - -193696.5947317105\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09376388557201844\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.466476794708179\n",
      "      mean_inference_ms: 0.9670547712484219\n",
      "      mean_raw_obs_processing_ms: 0.1339081637387805\n",
      "  time_since_restore: 2405.7085716724396\n",
      "  time_this_iter_s: 9.219359636306763\n",
      "  time_total_s: 2405.7085716724396\n",
      "  timers:\n",
      "    learn_throughput: 130921.39\n",
      "    learn_time_ms: 488.721\n",
      "    load_throughput: 21398595.622\n",
      "    load_time_ms: 2.99\n",
      "    training_iteration_time_ms: 9442.261\n",
      "    update_time_ms: 4.009\n",
      "  timestamp: 1665851159\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 16123968\n",
      "  training_iteration: 252\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:26:05 (running for 00:40:39.50)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   252</td><td style=\"text-align: right;\">         2405.71</td><td style=\"text-align: right;\">16123968</td><td style=\"text-align: right;\"> -191603</td><td style=\"text-align: right;\">             -188009</td><td style=\"text-align: right;\">             -201486</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 16187952\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 16187952\n",
      "    num_agent_steps_trained: 16187952\n",
      "    num_env_steps_sampled: 16187952\n",
      "    num_env_steps_trained: 16187952\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-26-09\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -187784.8818006754\n",
      "  episode_reward_mean: -191454.48837430333\n",
      "  episode_reward_min: -202895.1952958097\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 16176\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1097919940948486\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0005899094394408166\n",
      "          model: {}\n",
      "          policy_loss: -0.0019087294349446893\n",
      "          total_loss: 9.997897148132324\n",
      "          vf_explained_var: -2.838316426334586e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 16187952\n",
      "    num_agent_steps_trained: 16187952\n",
      "    num_env_steps_sampled: 16187952\n",
      "    num_env_steps_trained: 16187952\n",
      "  iterations_since_restore: 253\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 16187952\n",
      "  num_agent_steps_trained: 16187952\n",
      "  num_env_steps_sampled: 16187952\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 16187952\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.05714285714285\n",
      "    ram_util_percent: 88.91428571428571\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09376060833114075\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4664706622790537\n",
      "    mean_inference_ms: 0.9670731227181636\n",
      "    mean_raw_obs_processing_ms: 0.13390713771082388\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -187784.8818006754\n",
      "    episode_reward_mean: -191454.48837430333\n",
      "    episode_reward_min: -202895.1952958097\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -192523.7964658098\n",
      "      - -190857.707802591\n",
      "      - -192837.82726764848\n",
      "      - -191839.2781024689\n",
      "      - -190908.49888707834\n",
      "      - -191524.40785706296\n",
      "      - -193529.06165457875\n",
      "      - -192589.97979236252\n",
      "      - -190342.14769885747\n",
      "      - -189088.4573269833\n",
      "      - -191433.68177592198\n",
      "      - -189493.30662964605\n",
      "      - -191968.82682756078\n",
      "      - -192540.03496359158\n",
      "      - -190848.7287406492\n",
      "      - -188009.04607286467\n",
      "      - -193641.38295808394\n",
      "      - -193378.73481345584\n",
      "      - -192325.08862323727\n",
      "      - -190095.60506981792\n",
      "      - -191824.47903855433\n",
      "      - -189891.68011407027\n",
      "      - -190975.91954514195\n",
      "      - -195173.76138884437\n",
      "      - -190410.49009837647\n",
      "      - -190855.77233220532\n",
      "      - -191586.17429271087\n",
      "      - -189831.14192223336\n",
      "      - -188306.5989766684\n",
      "      - -192467.7603370506\n",
      "      - -189300.05247380724\n",
      "      - -191929.60167585473\n",
      "      - -192894.5862174831\n",
      "      - -194833.8090098001\n",
      "      - -192863.90048680478\n",
      "      - -189653.11276958144\n",
      "      - -189888.6867401717\n",
      "      - -192714.9525288242\n",
      "      - -192315.32903199442\n",
      "      - -193696.5947317105\n",
      "      - -190417.65800818973\n",
      "      - -192407.04382944386\n",
      "      - -191159.82354460034\n",
      "      - -192607.17015207594\n",
      "      - -194362.97554642323\n",
      "      - -191702.9975032154\n",
      "      - -190980.28380553308\n",
      "      - -189744.9235892386\n",
      "      - -190125.19723071763\n",
      "      - -189771.45435589767\n",
      "      - -191700.88155299495\n",
      "      - -191656.96993959002\n",
      "      - -192182.71260932385\n",
      "      - -189661.42761012155\n",
      "      - -191348.7368297038\n",
      "      - -196879.7889008054\n",
      "      - -193343.76301446708\n",
      "      - -191951.17166028847\n",
      "      - -190843.42866737407\n",
      "      - -188065.304646686\n",
      "      - -190516.166868407\n",
      "      - -191435.5456153139\n",
      "      - -191119.45961716864\n",
      "      - -191277.2868133681\n",
      "      - -190305.66212681073\n",
      "      - -192912.77486282156\n",
      "      - -192372.64833730532\n",
      "      - -202895.1952958097\n",
      "      - -190725.79014657636\n",
      "      - -191619.36999363275\n",
      "      - -196464.04841770828\n",
      "      - -191181.03460259255\n",
      "      - -189482.96059178875\n",
      "      - -193607.82147342252\n",
      "      - -190611.97440898084\n",
      "      - -190358.6979606652\n",
      "      - -191807.83563355546\n",
      "      - -192802.13244602017\n",
      "      - -190975.65313161834\n",
      "      - -189005.9108909185\n",
      "      - -190008.849012464\n",
      "      - -192404.33322734066\n",
      "      - -191930.04851395896\n",
      "      - -191426.7801656425\n",
      "      - -188587.8048509472\n",
      "      - -189095.78363441402\n",
      "      - -191535.75692318653\n",
      "      - -190768.09061927276\n",
      "      - -188969.69597231463\n",
      "      - -190500.3143359252\n",
      "      - -193107.88915392902\n",
      "      - -191839.5874801116\n",
      "      - -191687.77293659092\n",
      "      - -191747.4130045872\n",
      "      - -189683.27677823292\n",
      "      - -190828.34366824178\n",
      "      - -187784.8818006754\n",
      "      - -190653.22030185268\n",
      "      - -189404.58255333928\n",
      "      - -189902.72722397867\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09376060833114075\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4664706622790537\n",
      "      mean_inference_ms: 0.9670731227181636\n",
      "      mean_raw_obs_processing_ms: 0.13390713771082388\n",
      "  time_since_restore: 2415.283271074295\n",
      "  time_this_iter_s: 9.574699401855469\n",
      "  time_total_s: 2415.283271074295\n",
      "  timers:\n",
      "    learn_throughput: 133475.997\n",
      "    learn_time_ms: 479.367\n",
      "    load_throughput: 21499222.695\n",
      "    load_time_ms: 2.976\n",
      "    training_iteration_time_ms: 9443.518\n",
      "    update_time_ms: 4.127\n",
      "  timestamp: 1665851169\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 16187952\n",
      "  training_iteration: 253\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:26:14 (running for 00:40:49.10)<br>Memory usage on this node: 13.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   253</td><td style=\"text-align: right;\">         2415.28</td><td style=\"text-align: right;\">16187952</td><td style=\"text-align: right;\"> -191454</td><td style=\"text-align: right;\">             -187785</td><td style=\"text-align: right;\">             -202895</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 16251936\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 16251936\n",
      "    num_agent_steps_trained: 16251936\n",
      "    num_env_steps_sampled: 16251936\n",
      "    num_env_steps_trained: 16251936\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-26-19\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -187377.4362335157\n",
      "  episode_reward_mean: -190995.93676351573\n",
      "  episode_reward_min: -194695.5999316879\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 16248\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1023104190826416\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0008675282006151974\n",
      "          model: {}\n",
      "          policy_loss: 0.00583320576697588\n",
      "          total_loss: 10.005695343017578\n",
      "          vf_explained_var: -1.7029899268550253e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 16251936\n",
      "    num_agent_steps_trained: 16251936\n",
      "    num_env_steps_sampled: 16251936\n",
      "    num_env_steps_trained: 16251936\n",
      "  iterations_since_restore: 254\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 16251936\n",
      "  num_agent_steps_trained: 16251936\n",
      "  num_env_steps_sampled: 16251936\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 16251936\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 88.58461538461539\n",
      "    ram_util_percent: 89.54615384615386\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09377670418597427\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4665346384855604\n",
      "    mean_inference_ms: 0.9671265915154896\n",
      "    mean_raw_obs_processing_ms: 0.1337499475451547\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -187377.4362335157\n",
      "    episode_reward_mean: -190995.93676351573\n",
      "    episode_reward_min: -194695.5999316879\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -189482.96059178875\n",
      "      - -193607.82147342252\n",
      "      - -190611.97440898084\n",
      "      - -190358.6979606652\n",
      "      - -191807.83563355546\n",
      "      - -192802.13244602017\n",
      "      - -190975.65313161834\n",
      "      - -189005.9108909185\n",
      "      - -190008.849012464\n",
      "      - -192404.33322734066\n",
      "      - -191930.04851395896\n",
      "      - -191426.7801656425\n",
      "      - -188587.8048509472\n",
      "      - -189095.78363441402\n",
      "      - -191535.75692318653\n",
      "      - -190768.09061927276\n",
      "      - -188969.69597231463\n",
      "      - -190500.3143359252\n",
      "      - -193107.88915392902\n",
      "      - -191839.5874801116\n",
      "      - -191687.77293659092\n",
      "      - -191747.4130045872\n",
      "      - -189683.27677823292\n",
      "      - -190828.34366824178\n",
      "      - -187784.8818006754\n",
      "      - -190653.22030185268\n",
      "      - -189404.58255333928\n",
      "      - -189902.72722397867\n",
      "      - -192346.98969642262\n",
      "      - -191216.0616247481\n",
      "      - -194695.5999316879\n",
      "      - -190295.44054625268\n",
      "      - -190818.67938498227\n",
      "      - -191666.8976493856\n",
      "      - -189811.3016206502\n",
      "      - -192523.56780569704\n",
      "      - -191054.34904160275\n",
      "      - -194105.16024418228\n",
      "      - -192963.79473655683\n",
      "      - -191588.955871999\n",
      "      - -191365.63417062312\n",
      "      - -190833.32541420154\n",
      "      - -187377.4362335157\n",
      "      - -190628.98305434792\n",
      "      - -191695.82030938895\n",
      "      - -190520.20360780717\n",
      "      - -191116.4025007208\n",
      "      - -191147.09709464863\n",
      "      - -189343.7283130904\n",
      "      - -192126.44467295188\n",
      "      - -189373.39644995081\n",
      "      - -192203.52325440865\n",
      "      - -189231.62282171057\n",
      "      - -188918.3362011335\n",
      "      - -190581.32507199404\n",
      "      - -191070.5365085724\n",
      "      - -193259.5313412467\n",
      "      - -192243.14175766223\n",
      "      - -190527.86913681013\n",
      "      - -194281.61888752188\n",
      "      - -190437.40987200887\n",
      "      - -187632.988013471\n",
      "      - -190918.4455877739\n",
      "      - -190144.3809793866\n",
      "      - -191926.10304676075\n",
      "      - -189931.76336472292\n",
      "      - -191802.77477850742\n",
      "      - -188827.8545244619\n",
      "      - -193323.7258644884\n",
      "      - -191536.1027981929\n",
      "      - -190110.78157058684\n",
      "      - -190245.82342889934\n",
      "      - -193423.18856125325\n",
      "      - -191115.90197095307\n",
      "      - -191695.58685778014\n",
      "      - -191639.97675315375\n",
      "      - -192387.16625160686\n",
      "      - -188972.24970498108\n",
      "      - -191117.1894998354\n",
      "      - -191282.75147378512\n",
      "      - -191793.03053343392\n",
      "      - -188883.88273153498\n",
      "      - -192376.51181887556\n",
      "      - -190007.86657978842\n",
      "      - -190853.19340356323\n",
      "      - -191850.14469509435\n",
      "      - -189608.36452336627\n",
      "      - -189802.25551398864\n",
      "      - -190286.3521004707\n",
      "      - -193682.94119942348\n",
      "      - -191499.45945953557\n",
      "      - -191780.34270118165\n",
      "      - -190081.38957963718\n",
      "      - -189298.12440971695\n",
      "      - -188476.71917533237\n",
      "      - -191687.10944213968\n",
      "      - -192573.89277131663\n",
      "      - -193827.9922819985\n",
      "      - -189713.00882033393\n",
      "      - -191586.01605778656\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09377670418597427\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4665346384855604\n",
      "      mean_inference_ms: 0.9671265915154896\n",
      "      mean_raw_obs_processing_ms: 0.1337499475451547\n",
      "  time_since_restore: 2425.1648349761963\n",
      "  time_this_iter_s: 9.881563901901245\n",
      "  time_total_s: 2425.1648349761963\n",
      "  timers:\n",
      "    learn_throughput: 134338.636\n",
      "    learn_time_ms: 476.289\n",
      "    load_throughput: 21745196.867\n",
      "    load_time_ms: 2.942\n",
      "    training_iteration_time_ms: 9497.541\n",
      "    update_time_ms: 4.17\n",
      "  timestamp: 1665851179\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 16251936\n",
      "  training_iteration: 254\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:26:24 (running for 00:40:58.70)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   254</td><td style=\"text-align: right;\">         2425.16</td><td style=\"text-align: right;\">16251936</td><td style=\"text-align: right;\"> -190996</td><td style=\"text-align: right;\">             -187377</td><td style=\"text-align: right;\">             -194696</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 16315920\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 16315920\n",
      "    num_agent_steps_trained: 16315920\n",
      "    num_env_steps_sampled: 16315920\n",
      "    num_env_steps_trained: 16315920\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-26-28\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -187632.988013471\n",
      "  episode_reward_mean: -191269.42957787093\n",
      "  episode_reward_min: -195365.2912474732\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 16308\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0994551181793213\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00036119521246291697\n",
      "          model: {}\n",
      "          policy_loss: 0.008246379904448986\n",
      "          total_loss: 10.008008003234863\n",
      "          vf_explained_var: -4.5413063531896114e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 16315920\n",
      "    num_agent_steps_trained: 16315920\n",
      "    num_env_steps_sampled: 16315920\n",
      "    num_env_steps_trained: 16315920\n",
      "  iterations_since_restore: 255\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 16315920\n",
      "  num_agent_steps_trained: 16315920\n",
      "  num_env_steps_sampled: 16315920\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 16315920\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 80.6\n",
      "    ram_util_percent: 89.35384615384615\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09378711137025228\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46655372924435823\n",
      "    mean_inference_ms: 0.9671004369432896\n",
      "    mean_raw_obs_processing_ms: 0.13389461671130806\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -187632.988013471\n",
      "    episode_reward_mean: -191269.42957787093\n",
      "    episode_reward_min: -195365.2912474732\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -190437.40987200887\n",
      "      - -187632.988013471\n",
      "      - -190918.4455877739\n",
      "      - -190144.3809793866\n",
      "      - -191926.10304676075\n",
      "      - -189931.76336472292\n",
      "      - -191802.77477850742\n",
      "      - -188827.8545244619\n",
      "      - -193323.7258644884\n",
      "      - -191536.1027981929\n",
      "      - -190110.78157058684\n",
      "      - -190245.82342889934\n",
      "      - -193423.18856125325\n",
      "      - -191115.90197095307\n",
      "      - -191695.58685778014\n",
      "      - -191639.97675315375\n",
      "      - -192387.16625160686\n",
      "      - -188972.24970498108\n",
      "      - -191117.1894998354\n",
      "      - -191282.75147378512\n",
      "      - -191793.03053343392\n",
      "      - -188883.88273153498\n",
      "      - -192376.51181887556\n",
      "      - -190007.86657978842\n",
      "      - -190853.19340356323\n",
      "      - -191850.14469509435\n",
      "      - -189608.36452336627\n",
      "      - -189802.25551398864\n",
      "      - -190286.3521004707\n",
      "      - -193682.94119942348\n",
      "      - -191499.45945953557\n",
      "      - -191780.34270118165\n",
      "      - -190081.38957963718\n",
      "      - -189298.12440971695\n",
      "      - -188476.71917533237\n",
      "      - -191687.10944213968\n",
      "      - -192573.89277131663\n",
      "      - -193827.9922819985\n",
      "      - -189713.00882033393\n",
      "      - -191586.01605778656\n",
      "      - -195365.2912474732\n",
      "      - -193325.21792195237\n",
      "      - -190532.2762888619\n",
      "      - -191404.1684033166\n",
      "      - -191895.37218984787\n",
      "      - -191328.02138205958\n",
      "      - -189446.1151895162\n",
      "      - -190392.07757499037\n",
      "      - -191857.0520434741\n",
      "      - -191603.03779795932\n",
      "      - -189942.3223445838\n",
      "      - -191312.45848339336\n",
      "      - -191324.10335095972\n",
      "      - -189467.27282307486\n",
      "      - -191014.33788143386\n",
      "      - -192446.32401432766\n",
      "      - -190962.1660183472\n",
      "      - -191767.70240829524\n",
      "      - -191526.45160798746\n",
      "      - -191343.84652867637\n",
      "      - -191224.96002371717\n",
      "      - -190757.90389944258\n",
      "      - -191975.06186570745\n",
      "      - -191434.14841402735\n",
      "      - -190639.91705165675\n",
      "      - -192014.16095298374\n",
      "      - -192040.81282112468\n",
      "      - -191635.01378331956\n",
      "      - -192735.32250507764\n",
      "      - -191806.64215461045\n",
      "      - -193902.8503842618\n",
      "      - -193032.95422314876\n",
      "      - -189986.7867894615\n",
      "      - -188948.5807324142\n",
      "      - -192480.28088651004\n",
      "      - -192584.37296394323\n",
      "      - -190894.8569420209\n",
      "      - -188970.74341383576\n",
      "      - -189638.32615251752\n",
      "      - -192027.24897700455\n",
      "      - -191380.45627454764\n",
      "      - -191832.14809581987\n",
      "      - -193035.96225141216\n",
      "      - -189207.15867669357\n",
      "      - -190548.71197702826\n",
      "      - -191118.3865472791\n",
      "      - -192897.90781744805\n",
      "      - -191752.45270967955\n",
      "      - -191341.93493275132\n",
      "      - -192847.50335011174\n",
      "      - -190584.06107323722\n",
      "      - -193736.55840283216\n",
      "      - -190770.614532588\n",
      "      - -191270.0762659737\n",
      "      - -191096.68840707376\n",
      "      - -191427.08479280683\n",
      "      - -190667.1583666906\n",
      "      - -192321.55630068434\n",
      "      - -191302.1172077664\n",
      "      - -192677.09666622465\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09378711137025228\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46655372924435823\n",
      "      mean_inference_ms: 0.9671004369432896\n",
      "      mean_raw_obs_processing_ms: 0.13389461671130806\n",
      "  time_since_restore: 2434.183363676071\n",
      "  time_this_iter_s: 9.018528699874878\n",
      "  time_total_s: 2434.183363676071\n",
      "  timers:\n",
      "    learn_throughput: 136031.571\n",
      "    learn_time_ms: 470.361\n",
      "    load_throughput: 21874585.087\n",
      "    load_time_ms: 2.925\n",
      "    training_iteration_time_ms: 9484.488\n",
      "    update_time_ms: 4.353\n",
      "  timestamp: 1665851188\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 16315920\n",
      "  training_iteration: 255\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:26:33 (running for 00:41:07.88)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   255</td><td style=\"text-align: right;\">         2434.18</td><td style=\"text-align: right;\">16315920</td><td style=\"text-align: right;\"> -191269</td><td style=\"text-align: right;\">             -187633</td><td style=\"text-align: right;\">             -195365</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 16379904\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 16379904\n",
      "    num_agent_steps_trained: 16379904\n",
      "    num_env_steps_sampled: 16379904\n",
      "    num_env_steps_trained: 16379904\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-26-37\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -188658.389340284\n",
      "  episode_reward_mean: -191704.50145343563\n",
      "  episode_reward_min: -214803.66950031684\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 16368\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1011369228363037\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0005535752279683948\n",
      "          model: {}\n",
      "          policy_loss: -0.002943991683423519\n",
      "          total_loss: 9.996855735778809\n",
      "          vf_explained_var: -2.7437058847112894e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 16379904\n",
      "    num_agent_steps_trained: 16379904\n",
      "    num_env_steps_sampled: 16379904\n",
      "    num_env_steps_trained: 16379904\n",
      "  iterations_since_restore: 256\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 16379904\n",
      "  num_agent_steps_trained: 16379904\n",
      "  num_env_steps_sampled: 16379904\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 16379904\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.6076923076923\n",
      "    ram_util_percent: 89.32307692307694\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09373659800397341\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46655597364692336\n",
      "    mean_inference_ms: 0.9667141886279276\n",
      "    mean_raw_obs_processing_ms: 0.1338604907055372\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -188658.389340284\n",
      "    episode_reward_mean: -191704.50145343563\n",
      "    episode_reward_min: -214803.66950031684\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -191224.96002371717\n",
      "      - -190757.90389944258\n",
      "      - -191975.06186570745\n",
      "      - -191434.14841402735\n",
      "      - -190639.91705165675\n",
      "      - -192014.16095298374\n",
      "      - -192040.81282112468\n",
      "      - -191635.01378331956\n",
      "      - -192735.32250507764\n",
      "      - -191806.64215461045\n",
      "      - -193902.8503842618\n",
      "      - -193032.95422314876\n",
      "      - -189986.7867894615\n",
      "      - -188948.5807324142\n",
      "      - -192480.28088651004\n",
      "      - -192584.37296394323\n",
      "      - -190894.8569420209\n",
      "      - -188970.74341383576\n",
      "      - -189638.32615251752\n",
      "      - -192027.24897700455\n",
      "      - -191380.45627454764\n",
      "      - -191832.14809581987\n",
      "      - -193035.96225141216\n",
      "      - -189207.15867669357\n",
      "      - -190548.71197702826\n",
      "      - -191118.3865472791\n",
      "      - -192897.90781744805\n",
      "      - -191752.45270967955\n",
      "      - -191341.93493275132\n",
      "      - -192847.50335011174\n",
      "      - -190584.06107323722\n",
      "      - -193736.55840283216\n",
      "      - -190770.614532588\n",
      "      - -191270.0762659737\n",
      "      - -191096.68840707376\n",
      "      - -191427.08479280683\n",
      "      - -190667.1583666906\n",
      "      - -192321.55630068434\n",
      "      - -191302.1172077664\n",
      "      - -192677.09666622465\n",
      "      - -189862.1227977436\n",
      "      - -189253.72570285393\n",
      "      - -193540.52768196695\n",
      "      - -189759.10217630237\n",
      "      - -189893.1977407021\n",
      "      - -190527.76582541005\n",
      "      - -190337.80824606604\n",
      "      - -214803.66950031684\n",
      "      - -192937.46111151556\n",
      "      - -189646.50738907963\n",
      "      - -190996.15552696734\n",
      "      - -194728.93335291246\n",
      "      - -191855.5995322295\n",
      "      - -191262.71286248666\n",
      "      - -189331.50600319682\n",
      "      - -191898.93183817912\n",
      "      - -192210.87908142532\n",
      "      - -192359.96641452136\n",
      "      - -191559.62855231806\n",
      "      - -190183.570132658\n",
      "      - -191772.35421116723\n",
      "      - -190606.09113205087\n",
      "      - -189994.04336379186\n",
      "      - -191147.81290468154\n",
      "      - -192411.1163362544\n",
      "      - -191367.4137624378\n",
      "      - -193781.9670994063\n",
      "      - -188658.389340284\n",
      "      - -191628.3582577936\n",
      "      - -190310.00018557362\n",
      "      - -192571.26917290682\n",
      "      - -192360.07833428404\n",
      "      - -191623.02057126007\n",
      "      - -191461.84584059473\n",
      "      - -193419.50934221764\n",
      "      - -193790.03806230967\n",
      "      - -193203.80395470472\n",
      "      - -192095.6266707368\n",
      "      - -191679.86491990808\n",
      "      - -189804.95760540402\n",
      "      - -189546.6385707715\n",
      "      - -189415.3251856024\n",
      "      - -193348.97134577954\n",
      "      - -191388.50199940716\n",
      "      - -191585.6857796389\n",
      "      - -189706.75727556547\n",
      "      - -192671.52711281084\n",
      "      - -194135.80636954488\n",
      "      - -190424.07030533708\n",
      "      - -189495.37973122246\n",
      "      - -195160.1691572014\n",
      "      - -192295.13628642104\n",
      "      - -189419.7136430318\n",
      "      - -192154.4792252553\n",
      "      - -192941.45900943247\n",
      "      - -189386.49143623232\n",
      "      - -190553.97052902696\n",
      "      - -191404.9910012509\n",
      "      - -193161.30241724203\n",
      "      - -191069.8568407323\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09373659800397341\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46655597364692336\n",
      "      mean_inference_ms: 0.9667141886279276\n",
      "      mean_raw_obs_processing_ms: 0.1338604907055372\n",
      "  time_since_restore: 2443.0045721530914\n",
      "  time_this_iter_s: 8.821208477020264\n",
      "  time_total_s: 2443.0045721530914\n",
      "  timers:\n",
      "    learn_throughput: 137842.556\n",
      "    learn_time_ms: 464.182\n",
      "    load_throughput: 21947932.704\n",
      "    load_time_ms: 2.915\n",
      "    training_iteration_time_ms: 9388.16\n",
      "    update_time_ms: 4.351\n",
      "  timestamp: 1665851197\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 16379904\n",
      "  training_iteration: 256\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:26:42 (running for 00:41:16.98)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   256</td><td style=\"text-align: right;\">            2443</td><td style=\"text-align: right;\">16379904</td><td style=\"text-align: right;\"> -191705</td><td style=\"text-align: right;\">             -188658</td><td style=\"text-align: right;\">             -214804</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 16443888\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 16443888\n",
      "    num_agent_steps_trained: 16443888\n",
      "    num_env_steps_sampled: 16443888\n",
      "    num_env_steps_trained: 16443888\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-26-46\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -188379.64122692836\n",
      "  episode_reward_mean: -191570.6289785161\n",
      "  episode_reward_min: -196663.08085199093\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 16440\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.097628355026245\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0008482947014272213\n",
      "          model: {}\n",
      "          policy_loss: 0.005354011431336403\n",
      "          total_loss: 10.005212783813477\n",
      "          vf_explained_var: -4.9197485196827984e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 16443888\n",
      "    num_agent_steps_trained: 16443888\n",
      "    num_env_steps_sampled: 16443888\n",
      "    num_env_steps_trained: 16443888\n",
      "  iterations_since_restore: 257\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 16443888\n",
      "  num_agent_steps_trained: 16443888\n",
      "  num_env_steps_sampled: 16443888\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 16443888\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 78.54615384615384\n",
      "    ram_util_percent: 89.31538461538464\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09369292162989849\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46649320502277364\n",
      "    mean_inference_ms: 0.9661036476312713\n",
      "    mean_raw_obs_processing_ms: 0.1336400760166274\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -188379.64122692836\n",
      "    episode_reward_mean: -191570.6289785161\n",
      "    episode_reward_min: -196663.08085199093\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -191623.02057126007\n",
      "      - -191461.84584059473\n",
      "      - -193419.50934221764\n",
      "      - -193790.03806230967\n",
      "      - -193203.80395470472\n",
      "      - -192095.6266707368\n",
      "      - -191679.86491990808\n",
      "      - -189804.95760540402\n",
      "      - -189546.6385707715\n",
      "      - -189415.3251856024\n",
      "      - -193348.97134577954\n",
      "      - -191388.50199940716\n",
      "      - -191585.6857796389\n",
      "      - -189706.75727556547\n",
      "      - -192671.52711281084\n",
      "      - -194135.80636954488\n",
      "      - -190424.07030533708\n",
      "      - -189495.37973122246\n",
      "      - -195160.1691572014\n",
      "      - -192295.13628642104\n",
      "      - -189419.7136430318\n",
      "      - -192154.4792252553\n",
      "      - -192941.45900943247\n",
      "      - -189386.49143623232\n",
      "      - -190553.97052902696\n",
      "      - -191404.9910012509\n",
      "      - -193161.30241724203\n",
      "      - -191069.8568407323\n",
      "      - -191805.42141367187\n",
      "      - -192005.69662780152\n",
      "      - -191297.68327115994\n",
      "      - -192584.5252347941\n",
      "      - -190950.610506985\n",
      "      - -190796.75401160307\n",
      "      - -192001.59779785405\n",
      "      - -192512.34539693015\n",
      "      - -189804.5307424693\n",
      "      - -193397.79317435814\n",
      "      - -191982.3583609955\n",
      "      - -190796.11888297542\n",
      "      - -190426.11640271914\n",
      "      - -194031.10941326947\n",
      "      - -194137.84673245635\n",
      "      - -194339.68443521395\n",
      "      - -193011.72426752158\n",
      "      - -192485.95653652618\n",
      "      - -192903.55026215347\n",
      "      - -190997.6744879107\n",
      "      - -188518.1214086525\n",
      "      - -192605.01769374113\n",
      "      - -196663.08085199093\n",
      "      - -190084.97410622876\n",
      "      - -190532.98582965398\n",
      "      - -189295.73916750407\n",
      "      - -192532.64788654557\n",
      "      - -191721.75489706837\n",
      "      - -192240.37812270303\n",
      "      - -189384.711729805\n",
      "      - -188905.99353155468\n",
      "      - -192353.65868964445\n",
      "      - -190886.12055780776\n",
      "      - -191752.27472377784\n",
      "      - -191672.4590999632\n",
      "      - -189031.33012497527\n",
      "      - -188379.64122692836\n",
      "      - -190208.9240372429\n",
      "      - -189977.37819643892\n",
      "      - -190429.47184424617\n",
      "      - -191448.64987791894\n",
      "      - -190163.34578440516\n",
      "      - -192092.75302597854\n",
      "      - -191494.502841556\n",
      "      - -194060.96737342278\n",
      "      - -190599.9727000255\n",
      "      - -190181.87399202428\n",
      "      - -190703.81679798913\n",
      "      - -189736.18575449113\n",
      "      - -190787.81153816843\n",
      "      - -193642.67982886362\n",
      "      - -193733.99495821647\n",
      "      - -190427.53834032672\n",
      "      - -190529.14741791072\n",
      "      - -192260.227215716\n",
      "      - -192895.23764881294\n",
      "      - -191992.0530833434\n",
      "      - -192212.81850518016\n",
      "      - -192049.6912667555\n",
      "      - -190974.02412315513\n",
      "      - -194163.91115906322\n",
      "      - -190818.26740021637\n",
      "      - -192150.52907739196\n",
      "      - -193392.5668817702\n",
      "      - -191100.30612555065\n",
      "      - -191128.13031685993\n",
      "      - -190870.8593327645\n",
      "      - -191129.24361053394\n",
      "      - -191426.93405705466\n",
      "      - -192116.71521244204\n",
      "      - -190429.3441537361\n",
      "      - -190558.13657548223\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09369292162989849\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46649320502277364\n",
      "      mean_inference_ms: 0.9661036476312713\n",
      "      mean_raw_obs_processing_ms: 0.1336400760166274\n",
      "  time_since_restore: 2451.9237580299377\n",
      "  time_this_iter_s: 8.919185876846313\n",
      "  time_total_s: 2451.9237580299377\n",
      "  timers:\n",
      "    learn_throughput: 128320.283\n",
      "    learn_time_ms: 498.627\n",
      "    load_throughput: 21963560.017\n",
      "    load_time_ms: 2.913\n",
      "    training_iteration_time_ms: 9339.005\n",
      "    update_time_ms: 4.161\n",
      "  timestamp: 1665851206\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 16443888\n",
      "  training_iteration: 257\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:26:51 (running for 00:41:25.68)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   257</td><td style=\"text-align: right;\">         2451.92</td><td style=\"text-align: right;\">16443888</td><td style=\"text-align: right;\"> -191571</td><td style=\"text-align: right;\">             -188380</td><td style=\"text-align: right;\">             -196663</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 16507872\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 16507872\n",
      "    num_agent_steps_trained: 16507872\n",
      "    num_env_steps_sampled: 16507872\n",
      "    num_env_steps_trained: 16507872\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-26-54\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -187301.04551211922\n",
      "  episode_reward_mean: -191088.1992992248\n",
      "  episode_reward_min: -208373.06431044333\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 16500\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0961673259735107\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0006354321376420557\n",
      "          model: {}\n",
      "          policy_loss: 0.007147474214434624\n",
      "          total_loss: 10.006964683532715\n",
      "          vf_explained_var: -3.311369312086754e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 16507872\n",
      "    num_agent_steps_trained: 16507872\n",
      "    num_env_steps_sampled: 16507872\n",
      "    num_env_steps_trained: 16507872\n",
      "  iterations_since_restore: 258\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 16507872\n",
      "  num_agent_steps_trained: 16507872\n",
      "  num_env_steps_sampled: 16507872\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 16507872\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.88181818181819\n",
      "    ram_util_percent: 89.30909090909091\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09368111409608762\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4663754022146549\n",
      "    mean_inference_ms: 0.9656812010549948\n",
      "    mean_raw_obs_processing_ms: 0.13375712023980552\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -187301.04551211922\n",
      "    episode_reward_mean: -191088.1992992248\n",
      "    episode_reward_min: -208373.06431044333\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -190886.12055780776\n",
      "      - -191752.27472377784\n",
      "      - -191672.4590999632\n",
      "      - -189031.33012497527\n",
      "      - -188379.64122692836\n",
      "      - -190208.9240372429\n",
      "      - -189977.37819643892\n",
      "      - -190429.47184424617\n",
      "      - -191448.64987791894\n",
      "      - -190163.34578440516\n",
      "      - -192092.75302597854\n",
      "      - -191494.502841556\n",
      "      - -194060.96737342278\n",
      "      - -190599.9727000255\n",
      "      - -190181.87399202428\n",
      "      - -190703.81679798913\n",
      "      - -189736.18575449113\n",
      "      - -190787.81153816843\n",
      "      - -193642.67982886362\n",
      "      - -193733.99495821647\n",
      "      - -190427.53834032672\n",
      "      - -190529.14741791072\n",
      "      - -192260.227215716\n",
      "      - -192895.23764881294\n",
      "      - -191992.0530833434\n",
      "      - -192212.81850518016\n",
      "      - -192049.6912667555\n",
      "      - -190974.02412315513\n",
      "      - -194163.91115906322\n",
      "      - -190818.26740021637\n",
      "      - -192150.52907739196\n",
      "      - -193392.5668817702\n",
      "      - -191100.30612555065\n",
      "      - -191128.13031685993\n",
      "      - -190870.8593327645\n",
      "      - -191129.24361053394\n",
      "      - -191426.93405705466\n",
      "      - -192116.71521244204\n",
      "      - -190429.3441537361\n",
      "      - -190558.13657548223\n",
      "      - -192086.5480214752\n",
      "      - -189949.51523390395\n",
      "      - -189263.45828041146\n",
      "      - -191037.30894477345\n",
      "      - -188652.53353045395\n",
      "      - -191291.15527846277\n",
      "      - -190548.14408179434\n",
      "      - -190559.72998407338\n",
      "      - -194765.99273865076\n",
      "      - -190245.79104763115\n",
      "      - -190755.47600731938\n",
      "      - -191721.8338771876\n",
      "      - -187992.90585010985\n",
      "      - -190205.82455403797\n",
      "      - -190252.74628206034\n",
      "      - -190327.34929217794\n",
      "      - -189562.12657128274\n",
      "      - -190438.81270296732\n",
      "      - -191875.46674829835\n",
      "      - -189507.9265436341\n",
      "      - -190940.9029197112\n",
      "      - -187301.04551211922\n",
      "      - -190156.01559061502\n",
      "      - -190249.60968942288\n",
      "      - -192709.10313871945\n",
      "      - -191815.8811695717\n",
      "      - -190349.8338933694\n",
      "      - -190900.21224595327\n",
      "      - -190117.48102061485\n",
      "      - -190643.10717457288\n",
      "      - -188395.35766132953\n",
      "      - -189791.2197369675\n",
      "      - -189436.47562446978\n",
      "      - -193773.7034754756\n",
      "      - -193348.28506698395\n",
      "      - -191741.69043025034\n",
      "      - -191319.33452689543\n",
      "      - -190369.44976213828\n",
      "      - -193065.41174920098\n",
      "      - -191096.78500577604\n",
      "      - -188757.32286498806\n",
      "      - -189940.3800439435\n",
      "      - -189846.50520715432\n",
      "      - -192087.70495512974\n",
      "      - -190683.21678181228\n",
      "      - -191680.21419794083\n",
      "      - -193390.32113535143\n",
      "      - -191498.0947209909\n",
      "      - -208373.06431044333\n",
      "      - -189432.9548693019\n",
      "      - -191627.0450071678\n",
      "      - -189350.73019929987\n",
      "      - -188350.29865409588\n",
      "      - -190556.83442336044\n",
      "      - -188805.04210148516\n",
      "      - -191226.64444898948\n",
      "      - -190712.68482119992\n",
      "      - -190283.4062302427\n",
      "      - -189376.02221921322\n",
      "      - -190670.0559769966\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09368111409608762\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4663754022146549\n",
      "      mean_inference_ms: 0.9656812010549948\n",
      "      mean_raw_obs_processing_ms: 0.13375712023980552\n",
      "  time_since_restore: 2460.219831943512\n",
      "  time_this_iter_s: 8.296073913574219\n",
      "  time_total_s: 2460.219831943512\n",
      "  timers:\n",
      "    learn_throughput: 128597.808\n",
      "    learn_time_ms: 497.551\n",
      "    load_throughput: 21848406.534\n",
      "    load_time_ms: 2.929\n",
      "    training_iteration_time_ms: 9203.636\n",
      "    update_time_ms: 4.233\n",
      "  timestamp: 1665851214\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 16507872\n",
      "  training_iteration: 258\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:27:00 (running for 00:41:34.64)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   258</td><td style=\"text-align: right;\">         2460.22</td><td style=\"text-align: right;\">16507872</td><td style=\"text-align: right;\"> -191088</td><td style=\"text-align: right;\">             -187301</td><td style=\"text-align: right;\">             -208373</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 16571856\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 16571856\n",
      "    num_agent_steps_trained: 16571856\n",
      "    num_env_steps_sampled: 16571856\n",
      "    num_env_steps_trained: 16571856\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-27-03\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -187301.04551211922\n",
      "  episode_reward_mean: -190875.5485910245\n",
      "  episode_reward_min: -208373.06431044333\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 16560\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0956180095672607\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0012653011362999678\n",
      "          model: {}\n",
      "          policy_loss: -0.003222078550606966\n",
      "          total_loss: 9.996719360351562\n",
      "          vf_explained_var: -4.5413063531896114e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 16571856\n",
      "    num_agent_steps_trained: 16571856\n",
      "    num_env_steps_sampled: 16571856\n",
      "    num_env_steps_trained: 16571856\n",
      "  iterations_since_restore: 259\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 16571856\n",
      "  num_agent_steps_trained: 16571856\n",
      "  num_env_steps_sampled: 16571856\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 16571856\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.95384615384616\n",
      "    ram_util_percent: 89.32307692307693\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09362439397642291\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4662380257205319\n",
      "    mean_inference_ms: 0.9652576711910633\n",
      "    mean_raw_obs_processing_ms: 0.13372132572811013\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -187301.04551211922\n",
      "    episode_reward_mean: -190875.5485910245\n",
      "    episode_reward_min: -208373.06431044333\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -190940.9029197112\n",
      "      - -187301.04551211922\n",
      "      - -190156.01559061502\n",
      "      - -190249.60968942288\n",
      "      - -192709.10313871945\n",
      "      - -191815.8811695717\n",
      "      - -190349.8338933694\n",
      "      - -190900.21224595327\n",
      "      - -190117.48102061485\n",
      "      - -190643.10717457288\n",
      "      - -188395.35766132953\n",
      "      - -189791.2197369675\n",
      "      - -189436.47562446978\n",
      "      - -193773.7034754756\n",
      "      - -193348.28506698395\n",
      "      - -191741.69043025034\n",
      "      - -191319.33452689543\n",
      "      - -190369.44976213828\n",
      "      - -193065.41174920098\n",
      "      - -191096.78500577604\n",
      "      - -188757.32286498806\n",
      "      - -189940.3800439435\n",
      "      - -189846.50520715432\n",
      "      - -192087.70495512974\n",
      "      - -190683.21678181228\n",
      "      - -191680.21419794083\n",
      "      - -193390.32113535143\n",
      "      - -191498.0947209909\n",
      "      - -208373.06431044333\n",
      "      - -189432.9548693019\n",
      "      - -191627.0450071678\n",
      "      - -189350.73019929987\n",
      "      - -188350.29865409588\n",
      "      - -190556.83442336044\n",
      "      - -188805.04210148516\n",
      "      - -191226.64444898948\n",
      "      - -190712.68482119992\n",
      "      - -190283.4062302427\n",
      "      - -189376.02221921322\n",
      "      - -190670.0559769966\n",
      "      - -192334.27805977044\n",
      "      - -188968.30363486137\n",
      "      - -190327.74608847682\n",
      "      - -192053.89783074052\n",
      "      - -190669.05960896946\n",
      "      - -191774.5242065967\n",
      "      - -192885.84816268523\n",
      "      - -189912.1555263692\n",
      "      - -190134.34828100962\n",
      "      - -191693.54944965488\n",
      "      - -192162.7024039186\n",
      "      - -189890.49254836197\n",
      "      - -189279.19191484337\n",
      "      - -191414.51517867533\n",
      "      - -191987.62787419432\n",
      "      - -190015.57942577967\n",
      "      - -191639.6873821744\n",
      "      - -190411.43982859817\n",
      "      - -191790.19201484654\n",
      "      - -191557.6036439931\n",
      "      - -190309.42561270943\n",
      "      - -192731.55158983782\n",
      "      - -191658.78475005622\n",
      "      - -192781.18048259665\n",
      "      - -189635.69641202482\n",
      "      - -189858.02403030152\n",
      "      - -188645.1622662227\n",
      "      - -189885.8215256887\n",
      "      - -189182.76606099046\n",
      "      - -189067.3274814891\n",
      "      - -193191.22235636282\n",
      "      - -189707.75119744378\n",
      "      - -189856.1620339889\n",
      "      - -189630.1402468988\n",
      "      - -191085.5231172645\n",
      "      - -190376.8116278164\n",
      "      - -193225.91287710812\n",
      "      - -189645.9967604446\n",
      "      - -188260.14604115183\n",
      "      - -192087.98815157416\n",
      "      - -192060.14239542175\n",
      "      - -189084.3178481347\n",
      "      - -190499.67840420298\n",
      "      - -192588.23574867568\n",
      "      - -189571.1454578259\n",
      "      - -191480.25096212752\n",
      "      - -190777.32208437513\n",
      "      - -190901.62124586033\n",
      "      - -189915.22321689327\n",
      "      - -188487.70087279167\n",
      "      - -188902.93196205\n",
      "      - -189665.33057371882\n",
      "      - -191894.86486366056\n",
      "      - -190189.09622563762\n",
      "      - -190202.2816719567\n",
      "      - -192272.9620964696\n",
      "      - -190805.79286389874\n",
      "      - -190536.33216632705\n",
      "      - -190440.30158892288\n",
      "      - -191383.74060374685\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09362439397642291\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4662380257205319\n",
      "      mean_inference_ms: 0.9652576711910633\n",
      "      mean_raw_obs_processing_ms: 0.13372132572811013\n",
      "  time_since_restore: 2469.0944328308105\n",
      "  time_this_iter_s: 8.874600887298584\n",
      "  time_total_s: 2469.0944328308105\n",
      "  timers:\n",
      "    learn_throughput: 130095.014\n",
      "    learn_time_ms: 491.825\n",
      "    load_throughput: 22000471.142\n",
      "    load_time_ms: 2.908\n",
      "    training_iteration_time_ms: 9170.698\n",
      "    update_time_ms: 4.369\n",
      "  timestamp: 1665851223\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 16571856\n",
      "  training_iteration: 259\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:27:09 (running for 00:41:43.41)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   259</td><td style=\"text-align: right;\">         2469.09</td><td style=\"text-align: right;\">16571856</td><td style=\"text-align: right;\"> -190876</td><td style=\"text-align: right;\">             -187301</td><td style=\"text-align: right;\">             -208373</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 16635840\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 16635840\n",
      "    num_agent_steps_trained: 16635840\n",
      "    num_env_steps_sampled: 16635840\n",
      "    num_env_steps_trained: 16635840\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-27-12\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -188260.14604115183\n",
      "  episode_reward_mean: -190969.57313141134\n",
      "  episode_reward_min: -194987.90972264652\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 16632\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0987935066223145\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0006070888484828174\n",
      "          model: {}\n",
      "          policy_loss: 0.005722902715206146\n",
      "          total_loss: 10.005536079406738\n",
      "          vf_explained_var: -3.0275376872168636e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 16635840\n",
      "    num_agent_steps_trained: 16635840\n",
      "    num_env_steps_sampled: 16635840\n",
      "    num_env_steps_trained: 16635840\n",
      "  iterations_since_restore: 260\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 16635840\n",
      "  num_agent_steps_trained: 16635840\n",
      "  num_env_steps_sampled: 16635840\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 16635840\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.85000000000001\n",
      "    ram_util_percent: 89.31666666666666\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09357700130012565\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46614386157831506\n",
      "    mean_inference_ms: 0.9648438816395242\n",
      "    mean_raw_obs_processing_ms: 0.13350206730858102\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -188260.14604115183\n",
      "    episode_reward_mean: -190969.57313141134\n",
      "    episode_reward_min: -194987.90972264652\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -189856.1620339889\n",
      "      - -189630.1402468988\n",
      "      - -191085.5231172645\n",
      "      - -190376.8116278164\n",
      "      - -193225.91287710812\n",
      "      - -189645.9967604446\n",
      "      - -188260.14604115183\n",
      "      - -192087.98815157416\n",
      "      - -192060.14239542175\n",
      "      - -189084.3178481347\n",
      "      - -190499.67840420298\n",
      "      - -192588.23574867568\n",
      "      - -189571.1454578259\n",
      "      - -191480.25096212752\n",
      "      - -190777.32208437513\n",
      "      - -190901.62124586033\n",
      "      - -189915.22321689327\n",
      "      - -188487.70087279167\n",
      "      - -188902.93196205\n",
      "      - -189665.33057371882\n",
      "      - -191894.86486366056\n",
      "      - -190189.09622563762\n",
      "      - -190202.2816719567\n",
      "      - -192272.9620964696\n",
      "      - -190805.79286389874\n",
      "      - -190536.33216632705\n",
      "      - -190440.30158892288\n",
      "      - -191383.74060374685\n",
      "      - -189772.65796485453\n",
      "      - -189784.5409725479\n",
      "      - -193733.99170391943\n",
      "      - -194783.73617259727\n",
      "      - -191812.7678635691\n",
      "      - -188959.63042856366\n",
      "      - -191540.45693403235\n",
      "      - -190198.57976667702\n",
      "      - -190872.51412401258\n",
      "      - -190399.77479651148\n",
      "      - -192000.33185613953\n",
      "      - -190295.22861237402\n",
      "      - -191437.73191338827\n",
      "      - -193604.15870339263\n",
      "      - -192049.77693484307\n",
      "      - -191307.4005237732\n",
      "      - -190994.97737075997\n",
      "      - -190792.02467802836\n",
      "      - -189187.46669127332\n",
      "      - -191852.571087171\n",
      "      - -189601.392732508\n",
      "      - -189173.42106128368\n",
      "      - -192248.93927729942\n",
      "      - -192132.19073432224\n",
      "      - -191780.09352208866\n",
      "      - -192290.17187698453\n",
      "      - -193084.96378828405\n",
      "      - -190086.40626948903\n",
      "      - -190813.34936027156\n",
      "      - -190505.69951557918\n",
      "      - -193507.13036336214\n",
      "      - -191202.79512864898\n",
      "      - -190225.91974719547\n",
      "      - -189819.5697946385\n",
      "      - -192127.2576036978\n",
      "      - -191662.58768488644\n",
      "      - -188969.83581832764\n",
      "      - -190100.93883364726\n",
      "      - -189131.68528126538\n",
      "      - -191234.2795882546\n",
      "      - -191598.07112389116\n",
      "      - -193041.92392922056\n",
      "      - -192805.82540325765\n",
      "      - -190645.79259452448\n",
      "      - -192016.63000121852\n",
      "      - -190157.97556022494\n",
      "      - -190954.03613649067\n",
      "      - -189560.25571901604\n",
      "      - -189389.5780657588\n",
      "      - -191484.3893269314\n",
      "      - -190752.9149064424\n",
      "      - -190768.72934882462\n",
      "      - -191820.4642933992\n",
      "      - -191452.39524930815\n",
      "      - -189237.5257346417\n",
      "      - -190283.41150358913\n",
      "      - -190327.8475466205\n",
      "      - -192573.3615661749\n",
      "      - -189195.5768059924\n",
      "      - -191831.94989146737\n",
      "      - -190568.94172191317\n",
      "      - -190720.72073773036\n",
      "      - -194987.90972264652\n",
      "      - -190183.65342242442\n",
      "      - -189558.59183454822\n",
      "      - -190418.5546997941\n",
      "      - -190335.7528350491\n",
      "      - -193609.58222780112\n",
      "      - -191413.67244542012\n",
      "      - -192857.77861449867\n",
      "      - -190472.8736257484\n",
      "      - -191023.72575716104\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09357700130012565\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46614386157831506\n",
      "      mean_inference_ms: 0.9648438816395242\n",
      "      mean_raw_obs_processing_ms: 0.13350206730858102\n",
      "  time_since_restore: 2477.862729072571\n",
      "  time_this_iter_s: 8.768296241760254\n",
      "  time_total_s: 2477.862729072571\n",
      "  timers:\n",
      "    learn_throughput: 130984.472\n",
      "    learn_time_ms: 488.485\n",
      "    load_throughput: 21804560.253\n",
      "    load_time_ms: 2.934\n",
      "    training_iteration_time_ms: 9093.044\n",
      "    update_time_ms: 4.373\n",
      "  timestamp: 1665851232\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 16635840\n",
      "  training_iteration: 260\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:27:17 (running for 00:41:51.96)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   260</td><td style=\"text-align: right;\">         2477.86</td><td style=\"text-align: right;\">16635840</td><td style=\"text-align: right;\"> -190970</td><td style=\"text-align: right;\">             -188260</td><td style=\"text-align: right;\">             -194988</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 16699824\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 16699824\n",
      "    num_agent_steps_trained: 16699824\n",
      "    num_env_steps_sampled: 16699824\n",
      "    num_env_steps_trained: 16699824\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-27-21\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -187920.04311409296\n",
      "  episode_reward_mean: -191089.04262701207\n",
      "  episode_reward_min: -194987.90972264652\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 16692\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.098416805267334\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.001287752646021545\n",
      "          model: {}\n",
      "          policy_loss: 0.007057718466967344\n",
      "          total_loss: 10.00700569152832\n",
      "          vf_explained_var: -3.879032561826534e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 16699824\n",
      "    num_agent_steps_trained: 16699824\n",
      "    num_env_steps_sampled: 16699824\n",
      "    num_env_steps_trained: 16699824\n",
      "  iterations_since_restore: 261\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 16699824\n",
      "  num_agent_steps_trained: 16699824\n",
      "  num_env_steps_sampled: 16699824\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 16699824\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 78.33846153846153\n",
      "    ram_util_percent: 89.17692307692309\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09357360590634083\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46609045750777583\n",
      "    mean_inference_ms: 0.9646935441826598\n",
      "    mean_raw_obs_processing_ms: 0.1336279810193797\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -187920.04311409296\n",
      "    episode_reward_mean: -191089.04262701207\n",
      "    episode_reward_min: -194987.90972264652\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -190225.91974719547\n",
      "      - -189819.5697946385\n",
      "      - -192127.2576036978\n",
      "      - -191662.58768488644\n",
      "      - -188969.83581832764\n",
      "      - -190100.93883364726\n",
      "      - -189131.68528126538\n",
      "      - -191234.2795882546\n",
      "      - -191598.07112389116\n",
      "      - -193041.92392922056\n",
      "      - -192805.82540325765\n",
      "      - -190645.79259452448\n",
      "      - -192016.63000121852\n",
      "      - -190157.97556022494\n",
      "      - -190954.03613649067\n",
      "      - -189560.25571901604\n",
      "      - -189389.5780657588\n",
      "      - -191484.3893269314\n",
      "      - -190752.9149064424\n",
      "      - -190768.72934882462\n",
      "      - -191820.4642933992\n",
      "      - -191452.39524930815\n",
      "      - -189237.5257346417\n",
      "      - -190283.41150358913\n",
      "      - -190327.8475466205\n",
      "      - -192573.3615661749\n",
      "      - -189195.5768059924\n",
      "      - -191831.94989146737\n",
      "      - -190568.94172191317\n",
      "      - -190720.72073773036\n",
      "      - -194987.90972264652\n",
      "      - -190183.65342242442\n",
      "      - -189558.59183454822\n",
      "      - -190418.5546997941\n",
      "      - -190335.7528350491\n",
      "      - -193609.58222780112\n",
      "      - -191413.67244542012\n",
      "      - -192857.77861449867\n",
      "      - -190472.8736257484\n",
      "      - -191023.72575716104\n",
      "      - -189358.26170986512\n",
      "      - -192015.7207918946\n",
      "      - -193479.25275349428\n",
      "      - -191379.08321518393\n",
      "      - -193466.14043551456\n",
      "      - -191349.20629383193\n",
      "      - -190540.00654791936\n",
      "      - -192893.18083848045\n",
      "      - -190067.6339348186\n",
      "      - -190586.76351472322\n",
      "      - -191478.99604316987\n",
      "      - -192913.48600612197\n",
      "      - -189661.95854711812\n",
      "      - -191068.3144716989\n",
      "      - -190186.17808725068\n",
      "      - -190065.16628713498\n",
      "      - -189456.59400761098\n",
      "      - -188915.64619493007\n",
      "      - -191111.91430898142\n",
      "      - -193972.2567010692\n",
      "      - -190494.43385193023\n",
      "      - -189467.89219956633\n",
      "      - -192952.01144895362\n",
      "      - -189883.3608320201\n",
      "      - -194961.41267160588\n",
      "      - -194084.86295731112\n",
      "      - -193459.44320462496\n",
      "      - -193266.41176390622\n",
      "      - -190786.0890133315\n",
      "      - -190971.05597488233\n",
      "      - -192308.9647834342\n",
      "      - -189846.19494885928\n",
      "      - -190047.74883133132\n",
      "      - -192967.23869991783\n",
      "      - -192573.52942181236\n",
      "      - -190775.80923041995\n",
      "      - -192588.45586690042\n",
      "      - -191003.2289274493\n",
      "      - -190093.7200878166\n",
      "      - -192604.02025089815\n",
      "      - -190654.63208576228\n",
      "      - -191711.16022070523\n",
      "      - -189912.10676772532\n",
      "      - -191320.07818512173\n",
      "      - -189128.10075062583\n",
      "      - -190966.66102558555\n",
      "      - -191695.03622419914\n",
      "      - -191138.6096444532\n",
      "      - -191450.848455193\n",
      "      - -189011.5334367943\n",
      "      - -190869.7169390731\n",
      "      - -189258.83444819695\n",
      "      - -190494.91304061326\n",
      "      - -192351.73280185275\n",
      "      - -189254.37366080796\n",
      "      - -191918.750435085\n",
      "      - -189922.3201203187\n",
      "      - -187920.04311409296\n",
      "      - -190920.5660030502\n",
      "      - -190580.11298052195\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09357360590634083\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46609045750777583\n",
      "      mean_inference_ms: 0.9646935441826598\n",
      "      mean_raw_obs_processing_ms: 0.1336279810193797\n",
      "  time_since_restore: 2486.8282918930054\n",
      "  time_this_iter_s: 8.96556282043457\n",
      "  time_total_s: 2486.8282918930054\n",
      "  timers:\n",
      "    learn_throughput: 130014.441\n",
      "    learn_time_ms: 492.13\n",
      "    load_throughput: 22062870.742\n",
      "    load_time_ms: 2.9\n",
      "    training_iteration_time_ms: 9027.002\n",
      "    update_time_ms: 4.304\n",
      "  timestamp: 1665851241\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 16699824\n",
      "  training_iteration: 261\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:27:26 (running for 00:42:01.17)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   261</td><td style=\"text-align: right;\">         2486.83</td><td style=\"text-align: right;\">16699824</td><td style=\"text-align: right;\"> -191089</td><td style=\"text-align: right;\">             -187920</td><td style=\"text-align: right;\">             -194988</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 16763808\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 16763808\n",
      "    num_agent_steps_trained: 16763808\n",
      "    num_env_steps_sampled: 16763808\n",
      "    num_env_steps_trained: 16763808\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-27-30\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -187920.04311409296\n",
      "  episode_reward_mean: -191283.85295161113\n",
      "  episode_reward_min: -194961.41267160588\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 16752\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.098369598388672\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00048196440911851823\n",
      "          model: {}\n",
      "          policy_loss: -0.0028006925713270903\n",
      "          total_loss: 9.996986389160156\n",
      "          vf_explained_var: -3.500590395333347e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 16763808\n",
      "    num_agent_steps_trained: 16763808\n",
      "    num_env_steps_sampled: 16763808\n",
      "    num_env_steps_trained: 16763808\n",
      "  iterations_since_restore: 262\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 16763808\n",
      "  num_agent_steps_trained: 16763808\n",
      "  num_env_steps_sampled: 16763808\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 16763808\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.76923076923077\n",
      "    ram_util_percent: 89.0923076923077\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09351866139819531\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46592875920756405\n",
      "    mean_inference_ms: 0.9645700736318207\n",
      "    mean_raw_obs_processing_ms: 0.13360369035985417\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -187920.04311409296\n",
      "    episode_reward_mean: -191283.85295161113\n",
      "    episode_reward_min: -194961.41267160588\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -190494.43385193023\n",
      "      - -189467.89219956633\n",
      "      - -192952.01144895362\n",
      "      - -189883.3608320201\n",
      "      - -194961.41267160588\n",
      "      - -194084.86295731112\n",
      "      - -193459.44320462496\n",
      "      - -193266.41176390622\n",
      "      - -190786.0890133315\n",
      "      - -190971.05597488233\n",
      "      - -192308.9647834342\n",
      "      - -189846.19494885928\n",
      "      - -190047.74883133132\n",
      "      - -192967.23869991783\n",
      "      - -192573.52942181236\n",
      "      - -190775.80923041995\n",
      "      - -192588.45586690042\n",
      "      - -191003.2289274493\n",
      "      - -190093.7200878166\n",
      "      - -192604.02025089815\n",
      "      - -190654.63208576228\n",
      "      - -191711.16022070523\n",
      "      - -189912.10676772532\n",
      "      - -191320.07818512173\n",
      "      - -189128.10075062583\n",
      "      - -190966.66102558555\n",
      "      - -191695.03622419914\n",
      "      - -191138.6096444532\n",
      "      - -191450.848455193\n",
      "      - -189011.5334367943\n",
      "      - -190869.7169390731\n",
      "      - -189258.83444819695\n",
      "      - -190494.91304061326\n",
      "      - -192351.73280185275\n",
      "      - -189254.37366080796\n",
      "      - -191918.750435085\n",
      "      - -189922.3201203187\n",
      "      - -187920.04311409296\n",
      "      - -190920.5660030502\n",
      "      - -190580.11298052195\n",
      "      - -193373.05428362393\n",
      "      - -191660.86946583688\n",
      "      - -191940.930640383\n",
      "      - -193491.72162649382\n",
      "      - -193913.59068869424\n",
      "      - -191411.8900652252\n",
      "      - -191739.6085140531\n",
      "      - -188626.07057310978\n",
      "      - -191702.76635863748\n",
      "      - -193978.3556066468\n",
      "      - -189605.92650083316\n",
      "      - -189661.59057279243\n",
      "      - -188901.62860935825\n",
      "      - -189826.8422020626\n",
      "      - -191290.7675701797\n",
      "      - -193483.38222809217\n",
      "      - -191015.87986373133\n",
      "      - -191134.2453175506\n",
      "      - -191202.20025968578\n",
      "      - -193262.59586948273\n",
      "      - -191024.57548453636\n",
      "      - -192570.6220696722\n",
      "      - -193664.1975580581\n",
      "      - -191844.75433619047\n",
      "      - -188779.61197249914\n",
      "      - -190244.89803943702\n",
      "      - -189586.98030423926\n",
      "      - -192741.75939468283\n",
      "      - -191870.44925861375\n",
      "      - -189953.70676866377\n",
      "      - -194813.92100244982\n",
      "      - -194419.29033072328\n",
      "      - -191735.9896952515\n",
      "      - -191170.9238289885\n",
      "      - -191676.65983892532\n",
      "      - -188655.82147117623\n",
      "      - -193555.53108599636\n",
      "      - -190249.9480064856\n",
      "      - -192275.15396587495\n",
      "      - -188910.82996957918\n",
      "      - -189900.36577140645\n",
      "      - -191685.34543191837\n",
      "      - -190265.23583794804\n",
      "      - -192469.4850358384\n",
      "      - -191551.55359482055\n",
      "      - -190382.51816606082\n",
      "      - -190079.55120538207\n",
      "      - -190375.37137596722\n",
      "      - -190457.37910089205\n",
      "      - -191199.42940990932\n",
      "      - -194873.8344055902\n",
      "      - -190304.84520079166\n",
      "      - -192029.58148845835\n",
      "      - -191330.0325073146\n",
      "      - -190055.36204059873\n",
      "      - -191301.16146468723\n",
      "      - -189651.5365061277\n",
      "      - -190239.90111816756\n",
      "      - -190224.07398649343\n",
      "      - -193423.17500747432\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09351866139819531\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46592875920756405\n",
      "      mean_inference_ms: 0.9645700736318207\n",
      "      mean_raw_obs_processing_ms: 0.13360369035985417\n",
      "  time_since_restore: 2495.8953824043274\n",
      "  time_this_iter_s: 9.067090511322021\n",
      "  time_total_s: 2495.8953824043274\n",
      "  timers:\n",
      "    learn_throughput: 126230.349\n",
      "    learn_time_ms: 506.883\n",
      "    load_throughput: 22250735.599\n",
      "    load_time_ms: 2.876\n",
      "    training_iteration_time_ms: 9011.913\n",
      "    update_time_ms: 4.318\n",
      "  timestamp: 1665851250\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 16763808\n",
      "  training_iteration: 262\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:27:35 (running for 00:42:10.06)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   262</td><td style=\"text-align: right;\">          2495.9</td><td style=\"text-align: right;\">16763808</td><td style=\"text-align: right;\"> -191284</td><td style=\"text-align: right;\">             -187920</td><td style=\"text-align: right;\">             -194961</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 16827792\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 16827792\n",
      "    num_agent_steps_trained: 16827792\n",
      "    num_env_steps_sampled: 16827792\n",
      "    num_env_steps_trained: 16827792\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-27-39\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -188307.6138222996\n",
      "  episode_reward_mean: -191039.45011342503\n",
      "  episode_reward_min: -194873.8344055902\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 16824\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.103433609008789\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0008090636692941189\n",
      "          model: {}\n",
      "          policy_loss: 0.005000079981982708\n",
      "          total_loss: 10.004853248596191\n",
      "          vf_explained_var: -3.689811478579941e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 16827792\n",
      "    num_agent_steps_trained: 16827792\n",
      "    num_env_steps_sampled: 16827792\n",
      "    num_env_steps_trained: 16827792\n",
      "  iterations_since_restore: 263\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 16827792\n",
      "  num_agent_steps_trained: 16827792\n",
      "  num_env_steps_sampled: 16827792\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 16827792\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.71666666666665\n",
      "    ram_util_percent: 89.10000000000001\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09346561258217763\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.465774772595005\n",
      "    mean_inference_ms: 0.9642665408163827\n",
      "    mean_raw_obs_processing_ms: 0.13339351554849016\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -188307.6138222996\n",
      "    episode_reward_mean: -191039.45011342503\n",
      "    episode_reward_min: -194873.8344055902\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -191735.9896952515\n",
      "      - -191170.9238289885\n",
      "      - -191676.65983892532\n",
      "      - -188655.82147117623\n",
      "      - -193555.53108599636\n",
      "      - -190249.9480064856\n",
      "      - -192275.15396587495\n",
      "      - -188910.82996957918\n",
      "      - -189900.36577140645\n",
      "      - -191685.34543191837\n",
      "      - -190265.23583794804\n",
      "      - -192469.4850358384\n",
      "      - -191551.55359482055\n",
      "      - -190382.51816606082\n",
      "      - -190079.55120538207\n",
      "      - -190375.37137596722\n",
      "      - -190457.37910089205\n",
      "      - -191199.42940990932\n",
      "      - -194873.8344055902\n",
      "      - -190304.84520079166\n",
      "      - -192029.58148845835\n",
      "      - -191330.0325073146\n",
      "      - -190055.36204059873\n",
      "      - -191301.16146468723\n",
      "      - -189651.5365061277\n",
      "      - -190239.90111816756\n",
      "      - -190224.07398649343\n",
      "      - -193423.17500747432\n",
      "      - -191249.20997818615\n",
      "      - -191749.870273378\n",
      "      - -191790.26401475337\n",
      "      - -190617.8651971016\n",
      "      - -192915.09718241682\n",
      "      - -193017.13120085027\n",
      "      - -191380.80362517983\n",
      "      - -191119.11406958153\n",
      "      - -194383.1441038893\n",
      "      - -191205.81060769066\n",
      "      - -191290.35280584396\n",
      "      - -190540.87422287164\n",
      "      - -194291.36231941506\n",
      "      - -190009.07643970038\n",
      "      - -192183.40207885002\n",
      "      - -191567.72222758038\n",
      "      - -191153.35360197016\n",
      "      - -191264.26904271363\n",
      "      - -192340.51597722317\n",
      "      - -189766.053844413\n",
      "      - -191562.90895708356\n",
      "      - -189525.65123639943\n",
      "      - -190071.28089692595\n",
      "      - -191043.4400839914\n",
      "      - -191248.41483342348\n",
      "      - -190237.57899854355\n",
      "      - -190293.76072726748\n",
      "      - -191028.63448382105\n",
      "      - -190625.2846085379\n",
      "      - -188998.79318317713\n",
      "      - -192967.93258822992\n",
      "      - -192311.75127809032\n",
      "      - -188480.19566525883\n",
      "      - -191800.5115334603\n",
      "      - -190817.17237076024\n",
      "      - -188607.77950790277\n",
      "      - -190498.54954092792\n",
      "      - -191946.91699054785\n",
      "      - -189532.5300769795\n",
      "      - -190954.16117565482\n",
      "      - -190138.043096113\n",
      "      - -190407.94331962877\n",
      "      - -192980.02675093437\n",
      "      - -191114.4078742976\n",
      "      - -192792.29665834896\n",
      "      - -190389.71811119677\n",
      "      - -190937.86257435248\n",
      "      - -190862.5179226605\n",
      "      - -192357.3597443391\n",
      "      - -189980.76529057237\n",
      "      - -190814.47773476827\n",
      "      - -190136.8683820289\n",
      "      - -191893.27319113706\n",
      "      - -189850.47028053383\n",
      "      - -191717.3633681062\n",
      "      - -191401.4502679023\n",
      "      - -191005.96397554665\n",
      "      - -190191.0737063289\n",
      "      - -188307.6138222996\n",
      "      - -189449.0198318713\n",
      "      - -189914.98645433504\n",
      "      - -191041.7142383213\n",
      "      - -190680.6127161871\n",
      "      - -191918.8431981804\n",
      "      - -191132.5275275665\n",
      "      - -191275.48586247282\n",
      "      - -191097.12418988132\n",
      "      - -191865.3345308775\n",
      "      - -190604.39247862986\n",
      "      - -190645.37574316273\n",
      "      - -190173.45177850057\n",
      "      - -190447.5086527008\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09346561258217763\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.465774772595005\n",
      "      mean_inference_ms: 0.9642665408163827\n",
      "      mean_raw_obs_processing_ms: 0.13339351554849016\n",
      "  time_since_restore: 2504.710873603821\n",
      "  time_this_iter_s: 8.815491199493408\n",
      "  time_total_s: 2504.710873603821\n",
      "  timers:\n",
      "    learn_throughput: 124009.332\n",
      "    learn_time_ms: 515.961\n",
      "    load_throughput: 22253318.668\n",
      "    load_time_ms: 2.875\n",
      "    training_iteration_time_ms: 8936.006\n",
      "    update_time_ms: 4.185\n",
      "  timestamp: 1665851259\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 16827792\n",
      "  training_iteration: 263\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:27:44 (running for 00:42:18.66)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   263</td><td style=\"text-align: right;\">         2504.71</td><td style=\"text-align: right;\">16827792</td><td style=\"text-align: right;\"> -191039</td><td style=\"text-align: right;\">             -188308</td><td style=\"text-align: right;\">             -194874</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 16891776\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 16891776\n",
      "    num_agent_steps_trained: 16891776\n",
      "    num_env_steps_sampled: 16891776\n",
      "    num_env_steps_trained: 16891776\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-27-48\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -187624.21260844558\n",
      "  episode_reward_mean: -190945.99149769588\n",
      "  episode_reward_min: -196282.30776097908\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 16884\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1100664138793945\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0004346906498540193\n",
      "          model: {}\n",
      "          policy_loss: 0.007517187390476465\n",
      "          total_loss: 10.007294654846191\n",
      "          vf_explained_var: -1.7029899268550253e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 16891776\n",
      "    num_agent_steps_trained: 16891776\n",
      "    num_env_steps_sampled: 16891776\n",
      "    num_env_steps_trained: 16891776\n",
      "  iterations_since_restore: 264\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 16891776\n",
      "  num_agent_steps_trained: 16891776\n",
      "  num_env_steps_sampled: 16891776\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 16891776\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.74615384615385\n",
      "    ram_util_percent: 89.13076923076922\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09345779888741639\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46567664105627665\n",
      "    mean_inference_ms: 0.9641330816826087\n",
      "    mean_raw_obs_processing_ms: 0.1335163273466466\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -187624.21260844558\n",
      "    episode_reward_mean: -190945.99149769588\n",
      "    episode_reward_min: -196282.30776097908\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -188480.19566525883\n",
      "      - -191800.5115334603\n",
      "      - -190817.17237076024\n",
      "      - -188607.77950790277\n",
      "      - -190498.54954092792\n",
      "      - -191946.91699054785\n",
      "      - -189532.5300769795\n",
      "      - -190954.16117565482\n",
      "      - -190138.043096113\n",
      "      - -190407.94331962877\n",
      "      - -192980.02675093437\n",
      "      - -191114.4078742976\n",
      "      - -192792.29665834896\n",
      "      - -190389.71811119677\n",
      "      - -190937.86257435248\n",
      "      - -190862.5179226605\n",
      "      - -192357.3597443391\n",
      "      - -189980.76529057237\n",
      "      - -190814.47773476827\n",
      "      - -190136.8683820289\n",
      "      - -191893.27319113706\n",
      "      - -189850.47028053383\n",
      "      - -191717.3633681062\n",
      "      - -191401.4502679023\n",
      "      - -191005.96397554665\n",
      "      - -190191.0737063289\n",
      "      - -188307.6138222996\n",
      "      - -189449.0198318713\n",
      "      - -189914.98645433504\n",
      "      - -191041.7142383213\n",
      "      - -190680.6127161871\n",
      "      - -191918.8431981804\n",
      "      - -191132.5275275665\n",
      "      - -191275.48586247282\n",
      "      - -191097.12418988132\n",
      "      - -191865.3345308775\n",
      "      - -190604.39247862986\n",
      "      - -190645.37574316273\n",
      "      - -190173.45177850057\n",
      "      - -190447.5086527008\n",
      "      - -189476.01041175216\n",
      "      - -190497.5203341873\n",
      "      - -192813.83467311627\n",
      "      - -189318.80020831307\n",
      "      - -190468.3112446556\n",
      "      - -191608.29104912817\n",
      "      - -189626.5152732065\n",
      "      - -191667.33924961096\n",
      "      - -190497.87427797148\n",
      "      - -190530.72766715632\n",
      "      - -190318.23649029667\n",
      "      - -191187.02954886263\n",
      "      - -193329.50755136638\n",
      "      - -191999.2988830053\n",
      "      - -190675.20987830494\n",
      "      - -189822.1397831021\n",
      "      - -193902.0114968638\n",
      "      - -196282.30776097908\n",
      "      - -190849.27641592044\n",
      "      - -195335.07181285231\n",
      "      - -191608.88720025402\n",
      "      - -190404.49258602547\n",
      "      - -190782.02706420407\n",
      "      - -190496.99251628315\n",
      "      - -187624.21260844558\n",
      "      - -189169.18678786233\n",
      "      - -191719.159113006\n",
      "      - -189544.79921731283\n",
      "      - -187838.74196859813\n",
      "      - -191897.1395117197\n",
      "      - -189721.96825082446\n",
      "      - -190661.3397511601\n",
      "      - -190123.15923167393\n",
      "      - -190911.47323556297\n",
      "      - -189717.25971785982\n",
      "      - -194051.35472015612\n",
      "      - -188495.13922387024\n",
      "      - -191293.42625391233\n",
      "      - -188833.99474562207\n",
      "      - -189458.31258712415\n",
      "      - -189956.4763274732\n",
      "      - -191507.07667657023\n",
      "      - -190100.53704347182\n",
      "      - -193182.67823746003\n",
      "      - -191814.4411275622\n",
      "      - -192251.4022821155\n",
      "      - -192831.1737602639\n",
      "      - -191032.7199491197\n",
      "      - -192879.8253367767\n",
      "      - -193321.18430494113\n",
      "      - -190791.75128461164\n",
      "      - -190453.41861699978\n",
      "      - -192171.92572420972\n",
      "      - -189693.09439581342\n",
      "      - -189318.101452878\n",
      "      - -194027.35833159322\n",
      "      - -192592.34100430226\n",
      "      - -189348.17483638227\n",
      "      - -190286.09965376533\n",
      "      - -192317.2989858758\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09345779888741639\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46567664105627665\n",
      "      mean_inference_ms: 0.9641330816826087\n",
      "      mean_raw_obs_processing_ms: 0.1335163273466466\n",
      "  time_since_restore: 2513.610610485077\n",
      "  time_this_iter_s: 8.899736881256104\n",
      "  time_total_s: 2513.610610485077\n",
      "  timers:\n",
      "    learn_throughput: 123857.144\n",
      "    learn_time_ms: 516.595\n",
      "    load_throughput: 22281217.071\n",
      "    load_time_ms: 2.872\n",
      "    training_iteration_time_ms: 8837.71\n",
      "    update_time_ms: 4.079\n",
      "  timestamp: 1665851268\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 16891776\n",
      "  training_iteration: 264\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:27:53 (running for 00:42:27.85)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   264</td><td style=\"text-align: right;\">         2513.61</td><td style=\"text-align: right;\">16891776</td><td style=\"text-align: right;\"> -190946</td><td style=\"text-align: right;\">             -187624</td><td style=\"text-align: right;\">             -196282</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 16955760\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 16955760\n",
      "    num_agent_steps_trained: 16955760\n",
      "    num_env_steps_sampled: 16955760\n",
      "    num_env_steps_trained: 16955760\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-27-57\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -186993.18522944787\n",
      "  episode_reward_mean: -191432.88737909627\n",
      "  episode_reward_min: -200979.12210712573\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 16944\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1105480194091797\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.001076370826922357\n",
      "          model: {}\n",
      "          policy_loss: -0.0028470042161643505\n",
      "          total_loss: 9.997057914733887\n",
      "          vf_explained_var: -3.0275376872168636e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 16955760\n",
      "    num_agent_steps_trained: 16955760\n",
      "    num_env_steps_sampled: 16955760\n",
      "    num_env_steps_trained: 16955760\n",
      "  iterations_since_restore: 265\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 16955760\n",
      "  num_agent_steps_trained: 16955760\n",
      "  num_env_steps_sampled: 16955760\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 16955760\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.80833333333335\n",
      "    ram_util_percent: 89.13333333333334\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09340981706680392\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4655430172703521\n",
      "    mean_inference_ms: 0.9637319125139373\n",
      "    mean_raw_obs_processing_ms: 0.13348329875182466\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -186993.18522944787\n",
      "    episode_reward_mean: -191432.88737909627\n",
      "    episode_reward_min: -200979.12210712573\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -191608.88720025402\n",
      "      - -190404.49258602547\n",
      "      - -190782.02706420407\n",
      "      - -190496.99251628315\n",
      "      - -187624.21260844558\n",
      "      - -189169.18678786233\n",
      "      - -191719.159113006\n",
      "      - -189544.79921731283\n",
      "      - -187838.74196859813\n",
      "      - -191897.1395117197\n",
      "      - -189721.96825082446\n",
      "      - -190661.3397511601\n",
      "      - -190123.15923167393\n",
      "      - -190911.47323556297\n",
      "      - -189717.25971785982\n",
      "      - -194051.35472015612\n",
      "      - -188495.13922387024\n",
      "      - -191293.42625391233\n",
      "      - -188833.99474562207\n",
      "      - -189458.31258712415\n",
      "      - -189956.4763274732\n",
      "      - -191507.07667657023\n",
      "      - -190100.53704347182\n",
      "      - -193182.67823746003\n",
      "      - -191814.4411275622\n",
      "      - -192251.4022821155\n",
      "      - -192831.1737602639\n",
      "      - -191032.7199491197\n",
      "      - -192879.8253367767\n",
      "      - -193321.18430494113\n",
      "      - -190791.75128461164\n",
      "      - -190453.41861699978\n",
      "      - -192171.92572420972\n",
      "      - -189693.09439581342\n",
      "      - -189318.101452878\n",
      "      - -194027.35833159322\n",
      "      - -192592.34100430226\n",
      "      - -189348.17483638227\n",
      "      - -190286.09965376533\n",
      "      - -192317.2989858758\n",
      "      - -190890.94784765298\n",
      "      - -191341.61585747567\n",
      "      - -189718.73712844972\n",
      "      - -193561.74152828206\n",
      "      - -189062.39805273726\n",
      "      - -194958.93855785913\n",
      "      - -192120.70031400854\n",
      "      - -192645.49244536244\n",
      "      - -194350.69054330696\n",
      "      - -191834.2810485011\n",
      "      - -191258.60889978425\n",
      "      - -189734.8128264089\n",
      "      - -189550.65193930038\n",
      "      - -188141.49181876722\n",
      "      - -191638.82721790756\n",
      "      - -189572.30670137572\n",
      "      - -190363.61133557235\n",
      "      - -189032.4182280337\n",
      "      - -192367.6461114018\n",
      "      - -190750.32096172246\n",
      "      - -192624.46236208646\n",
      "      - -193403.53285930547\n",
      "      - -191776.25131333078\n",
      "      - -192102.02054569797\n",
      "      - -195205.6326855285\n",
      "      - -192509.6176901055\n",
      "      - -191132.23514777047\n",
      "      - -190455.34448168156\n",
      "      - -191692.13699770835\n",
      "      - -186993.18522944787\n",
      "      - -190892.09158442102\n",
      "      - -200023.90631719516\n",
      "      - -191258.69569701893\n",
      "      - -189808.6871437525\n",
      "      - -193737.66262349027\n",
      "      - -191820.40159790407\n",
      "      - -190808.78905834875\n",
      "      - -191040.78965172113\n",
      "      - -192820.3233431432\n",
      "      - -190896.55343004054\n",
      "      - -200979.12210712573\n",
      "      - -193615.47466925392\n",
      "      - -193086.06904494375\n",
      "      - -192930.60564922803\n",
      "      - -194345.60627110515\n",
      "      - -191146.25434440604\n",
      "      - -193146.63093537677\n",
      "      - -192867.86871427431\n",
      "      - -193849.26205831164\n",
      "      - -191860.47100744792\n",
      "      - -189116.0189102336\n",
      "      - -190400.0120477056\n",
      "      - -190268.55482068934\n",
      "      - -192862.86966041627\n",
      "      - -189848.81988601887\n",
      "      - -191365.96985759464\n",
      "      - -190992.02228085382\n",
      "      - -192329.41147693686\n",
      "      - -190797.29628081716\n",
      "      - -189351.69313961695\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09340981706680392\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4655430172703521\n",
      "      mean_inference_ms: 0.9637319125139373\n",
      "      mean_raw_obs_processing_ms: 0.13348329875182466\n",
      "  time_since_restore: 2522.447945833206\n",
      "  time_this_iter_s: 8.837335348129272\n",
      "  time_total_s: 2522.447945833206\n",
      "  timers:\n",
      "    learn_throughput: 115265.448\n",
      "    learn_time_ms: 555.101\n",
      "    load_throughput: 22226042.249\n",
      "    load_time_ms: 2.879\n",
      "    training_iteration_time_ms: 8819.645\n",
      "    update_time_ms: 4.035\n",
      "  timestamp: 1665851277\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 16955760\n",
      "  training_iteration: 265\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:28:02 (running for 00:42:36.72)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   265</td><td style=\"text-align: right;\">         2522.45</td><td style=\"text-align: right;\">16955760</td><td style=\"text-align: right;\"> -191433</td><td style=\"text-align: right;\">             -186993</td><td style=\"text-align: right;\">             -200979</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 17019744\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 17019744\n",
      "    num_agent_steps_trained: 17019744\n",
      "    num_env_steps_sampled: 17019744\n",
      "    num_env_steps_trained: 17019744\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-28-05\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -187183.05105843776\n",
      "  episode_reward_mean: -191101.25061797816\n",
      "  episode_reward_min: -204842.10914266703\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 17016\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1081244945526123\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0004215535009279847\n",
      "          model: {}\n",
      "          policy_loss: 0.005701756104826927\n",
      "          total_loss: 10.005475044250488\n",
      "          vf_explained_var: -1.797600468478322e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 17019744\n",
      "    num_agent_steps_trained: 17019744\n",
      "    num_env_steps_sampled: 17019744\n",
      "    num_env_steps_trained: 17019744\n",
      "  iterations_since_restore: 266\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 17019744\n",
      "  num_agent_steps_trained: 17019744\n",
      "  num_env_steps_sampled: 17019744\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 17019744\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 78.04166666666667\n",
      "    ram_util_percent: 89.11666666666667\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09336224364666591\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46540283685349365\n",
      "    mean_inference_ms: 0.9630344111218341\n",
      "    mean_raw_obs_processing_ms: 0.13326620350593685\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -187183.05105843776\n",
      "    episode_reward_mean: -191101.25061797816\n",
      "    episode_reward_min: -204842.10914266703\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -191258.69569701893\n",
      "      - -189808.6871437525\n",
      "      - -193737.66262349027\n",
      "      - -191820.40159790407\n",
      "      - -190808.78905834875\n",
      "      - -191040.78965172113\n",
      "      - -192820.3233431432\n",
      "      - -190896.55343004054\n",
      "      - -200979.12210712573\n",
      "      - -193615.47466925392\n",
      "      - -193086.06904494375\n",
      "      - -192930.60564922803\n",
      "      - -194345.60627110515\n",
      "      - -191146.25434440604\n",
      "      - -193146.63093537677\n",
      "      - -192867.86871427431\n",
      "      - -193849.26205831164\n",
      "      - -191860.47100744792\n",
      "      - -189116.0189102336\n",
      "      - -190400.0120477056\n",
      "      - -190268.55482068934\n",
      "      - -192862.86966041627\n",
      "      - -189848.81988601887\n",
      "      - -191365.96985759464\n",
      "      - -190992.02228085382\n",
      "      - -192329.41147693686\n",
      "      - -190797.29628081716\n",
      "      - -189351.69313961695\n",
      "      - -191506.1891460069\n",
      "      - -189798.0958892097\n",
      "      - -191798.87400419574\n",
      "      - -192744.29039916315\n",
      "      - -187183.05105843776\n",
      "      - -189480.27218820303\n",
      "      - -190060.9932370094\n",
      "      - -191561.24666667674\n",
      "      - -189200.8007668307\n",
      "      - -189108.4381643378\n",
      "      - -188887.60503605736\n",
      "      - -190595.72469553695\n",
      "      - -189330.5603714627\n",
      "      - -188623.79802057278\n",
      "      - -188516.73633511772\n",
      "      - -188090.50156864876\n",
      "      - -189418.346478718\n",
      "      - -189279.02332006575\n",
      "      - -190579.85212686268\n",
      "      - -189673.16276541117\n",
      "      - -191564.914273757\n",
      "      - -191197.95655071386\n",
      "      - -189838.43731906742\n",
      "      - -189534.52755788877\n",
      "      - -193174.69160537896\n",
      "      - -190509.04637634073\n",
      "      - -190865.82506482166\n",
      "      - -188554.01734729827\n",
      "      - -190926.81467838713\n",
      "      - -189699.23882330395\n",
      "      - -191870.81516520015\n",
      "      - -190548.55960793467\n",
      "      - -191285.04171362982\n",
      "      - -189096.31057724543\n",
      "      - -190359.63481624602\n",
      "      - -189163.4345999456\n",
      "      - -191052.67700877224\n",
      "      - -192048.58469042042\n",
      "      - -192215.2925845535\n",
      "      - -190385.87642383153\n",
      "      - -190209.10993094867\n",
      "      - -188899.2336061636\n",
      "      - -192965.9584551222\n",
      "      - -204842.10914266703\n",
      "      - -194726.89571195332\n",
      "      - -189947.27020217534\n",
      "      - -190540.82859184584\n",
      "      - -191774.36564154614\n",
      "      - -190335.7881934467\n",
      "      - -193682.23900276073\n",
      "      - -192992.08274014664\n",
      "      - -191239.99836141287\n",
      "      - -191600.11367070558\n",
      "      - -191663.16065300468\n",
      "      - -190736.18269862386\n",
      "      - -191501.7288538035\n",
      "      - -189213.0365016467\n",
      "      - -189472.9567173437\n",
      "      - -189100.35571281952\n",
      "      - -189641.05572570534\n",
      "      - -191532.002610028\n",
      "      - -193902.2195093002\n",
      "      - -190474.6662118692\n",
      "      - -192556.39100442454\n",
      "      - -190530.79888847822\n",
      "      - -189497.7357007065\n",
      "      - -190938.12949378917\n",
      "      - -192204.62979497982\n",
      "      - -187906.7261178247\n",
      "      - -191714.46426322762\n",
      "      - -187555.56245429098\n",
      "      - -189546.07090402066\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09336224364666591\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46540283685349365\n",
      "      mean_inference_ms: 0.9630344111218341\n",
      "      mean_raw_obs_processing_ms: 0.13326620350593685\n",
      "  time_since_restore: 2530.7853367328644\n",
      "  time_this_iter_s: 8.337390899658203\n",
      "  time_total_s: 2530.7853367328644\n",
      "  timers:\n",
      "    learn_throughput: 115237.711\n",
      "    learn_time_ms: 555.235\n",
      "    load_throughput: 21856769.731\n",
      "    load_time_ms: 2.927\n",
      "    training_iteration_time_ms: 8771.238\n",
      "    update_time_ms: 4.009\n",
      "  timestamp: 1665851285\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 17019744\n",
      "  training_iteration: 266\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:28:10 (running for 00:42:45.01)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   266</td><td style=\"text-align: right;\">         2530.79</td><td style=\"text-align: right;\">17019744</td><td style=\"text-align: right;\"> -191101</td><td style=\"text-align: right;\">             -187183</td><td style=\"text-align: right;\">             -204842</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 17083728\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 17083728\n",
      "    num_agent_steps_trained: 17083728\n",
      "    num_env_steps_sampled: 17083728\n",
      "    num_env_steps_trained: 17083728\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-28-14\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -187555.56245429098\n",
      "  episode_reward_mean: -190924.98016516413\n",
      "  episode_reward_min: -204842.10914266703\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 17076\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1079256534576416\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0007845538784749806\n",
      "          model: {}\n",
      "          policy_loss: 0.007121074013411999\n",
      "          total_loss: 10.006967544555664\n",
      "          vf_explained_var: -3.7844221090210795e-09\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 17083728\n",
      "    num_agent_steps_trained: 17083728\n",
      "    num_env_steps_sampled: 17083728\n",
      "    num_env_steps_trained: 17083728\n",
      "  iterations_since_restore: 267\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 17083728\n",
      "  num_agent_steps_trained: 17083728\n",
      "  num_env_steps_sampled: 17083728\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 17083728\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.36923076923077\n",
      "    ram_util_percent: 89.12307692307694\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0933568453180354\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46534817641687654\n",
      "    mean_inference_ms: 0.9627671161763751\n",
      "    mean_raw_obs_processing_ms: 0.1333915871618837\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -187555.56245429098\n",
      "    episode_reward_mean: -190924.98016516413\n",
      "    episode_reward_min: -204842.10914266703\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -191285.04171362982\n",
      "      - -189096.31057724543\n",
      "      - -190359.63481624602\n",
      "      - -189163.4345999456\n",
      "      - -191052.67700877224\n",
      "      - -192048.58469042042\n",
      "      - -192215.2925845535\n",
      "      - -190385.87642383153\n",
      "      - -190209.10993094867\n",
      "      - -188899.2336061636\n",
      "      - -192965.9584551222\n",
      "      - -204842.10914266703\n",
      "      - -194726.89571195332\n",
      "      - -189947.27020217534\n",
      "      - -190540.82859184584\n",
      "      - -191774.36564154614\n",
      "      - -190335.7881934467\n",
      "      - -193682.23900276073\n",
      "      - -192992.08274014664\n",
      "      - -191239.99836141287\n",
      "      - -191600.11367070558\n",
      "      - -191663.16065300468\n",
      "      - -190736.18269862386\n",
      "      - -191501.7288538035\n",
      "      - -189213.0365016467\n",
      "      - -189472.9567173437\n",
      "      - -189100.35571281952\n",
      "      - -189641.05572570534\n",
      "      - -191532.002610028\n",
      "      - -193902.2195093002\n",
      "      - -190474.6662118692\n",
      "      - -192556.39100442454\n",
      "      - -190530.79888847822\n",
      "      - -189497.7357007065\n",
      "      - -190938.12949378917\n",
      "      - -192204.62979497982\n",
      "      - -187906.7261178247\n",
      "      - -191714.46426322762\n",
      "      - -187555.56245429098\n",
      "      - -189546.07090402066\n",
      "      - -193065.9048796452\n",
      "      - -189289.30331890195\n",
      "      - -193443.98360230366\n",
      "      - -190987.5092435395\n",
      "      - -191203.24444125642\n",
      "      - -190753.52057312833\n",
      "      - -191126.2607614362\n",
      "      - -191017.90868335194\n",
      "      - -191073.39394089146\n",
      "      - -190532.31442572142\n",
      "      - -190021.69092261308\n",
      "      - -188196.39704720155\n",
      "      - -191793.44528430692\n",
      "      - -189488.62064371645\n",
      "      - -190695.58317788265\n",
      "      - -189273.46668639805\n",
      "      - -192005.27266301253\n",
      "      - -189119.51233587353\n",
      "      - -193951.4631581758\n",
      "      - -189405.75829579902\n",
      "      - -191937.21479556325\n",
      "      - -189063.99863847924\n",
      "      - -191389.3377812338\n",
      "      - -189418.41891925628\n",
      "      - -190202.07454581963\n",
      "      - -191560.81604687197\n",
      "      - -191494.70031240213\n",
      "      - -190647.2385332577\n",
      "      - -189015.83347422513\n",
      "      - -188930.41255702655\n",
      "      - -194353.05671338527\n",
      "      - -191386.44833914872\n",
      "      - -191428.25924115122\n",
      "      - -190446.20083276718\n",
      "      - -189081.6893188608\n",
      "      - -189652.86096438405\n",
      "      - -191891.00485118185\n",
      "      - -190481.0250500152\n",
      "      - -190178.2766209377\n",
      "      - -192527.312309654\n",
      "      - -191009.5275626265\n",
      "      - -188191.05826064976\n",
      "      - -189613.3473982862\n",
      "      - -191174.82728866997\n",
      "      - -191550.54884641257\n",
      "      - -189250.7559989299\n",
      "      - -191227.2223838218\n",
      "      - -190922.43997827783\n",
      "      - -191055.59255298748\n",
      "      - -193324.87555258494\n",
      "      - -190486.46082061346\n",
      "      - -190264.30906234283\n",
      "      - -189037.86018899034\n",
      "      - -190217.5276295423\n",
      "      - -192329.85110623558\n",
      "      - -189294.91757351268\n",
      "      - -190585.272021501\n",
      "      - -191751.39770454195\n",
      "      - -191218.45269654138\n",
      "      - -189410.3184771404\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.0933568453180354\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46534817641687654\n",
      "      mean_inference_ms: 0.9627671161763751\n",
      "      mean_raw_obs_processing_ms: 0.1333915871618837\n",
      "  time_since_restore: 2539.6669902801514\n",
      "  time_this_iter_s: 8.881653547286987\n",
      "  time_total_s: 2539.6669902801514\n",
      "  timers:\n",
      "    learn_throughput: 122585.91\n",
      "    learn_time_ms: 521.952\n",
      "    load_throughput: 21914954.976\n",
      "    load_time_ms: 2.92\n",
      "    training_iteration_time_ms: 8767.532\n",
      "    update_time_ms: 4.054\n",
      "  timestamp: 1665851294\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 17083728\n",
      "  training_iteration: 267\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:28:19 (running for 00:42:54.04)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   267</td><td style=\"text-align: right;\">         2539.67</td><td style=\"text-align: right;\">17083728</td><td style=\"text-align: right;\"> -190925</td><td style=\"text-align: right;\">             -187556</td><td style=\"text-align: right;\">             -204842</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 17147712\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 17147712\n",
      "    num_agent_steps_trained: 17147712\n",
      "    num_env_steps_sampled: 17147712\n",
      "    num_env_steps_trained: 17147712\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-28-23\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -187604.66541026128\n",
      "  episode_reward_mean: -190518.41563898805\n",
      "  episode_reward_min: -195137.6115650324\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 17136\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.108135223388672\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0008501014672219753\n",
      "          model: {}\n",
      "          policy_loss: -0.0023941497784107924\n",
      "          total_loss: 9.997465133666992\n",
      "          vf_explained_var: -2.176042634971509e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 17147712\n",
      "    num_agent_steps_trained: 17147712\n",
      "    num_env_steps_sampled: 17147712\n",
      "    num_env_steps_trained: 17147712\n",
      "  iterations_since_restore: 268\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 17147712\n",
      "  num_agent_steps_trained: 17147712\n",
      "  num_env_steps_sampled: 17147712\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 17147712\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.2\n",
      "    ram_util_percent: 89.10000000000001\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09331248471051486\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4652890841472727\n",
      "    mean_inference_ms: 0.9624956588111092\n",
      "    mean_raw_obs_processing_ms: 0.13336617233676132\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -187604.66541026128\n",
      "    episode_reward_mean: -190518.41563898805\n",
      "    episode_reward_min: -195137.6115650324\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -191937.21479556325\n",
      "      - -189063.99863847924\n",
      "      - -191389.3377812338\n",
      "      - -189418.41891925628\n",
      "      - -190202.07454581963\n",
      "      - -191560.81604687197\n",
      "      - -191494.70031240213\n",
      "      - -190647.2385332577\n",
      "      - -189015.83347422513\n",
      "      - -188930.41255702655\n",
      "      - -194353.05671338527\n",
      "      - -191386.44833914872\n",
      "      - -191428.25924115122\n",
      "      - -190446.20083276718\n",
      "      - -189081.6893188608\n",
      "      - -189652.86096438405\n",
      "      - -191891.00485118185\n",
      "      - -190481.0250500152\n",
      "      - -190178.2766209377\n",
      "      - -192527.312309654\n",
      "      - -191009.5275626265\n",
      "      - -188191.05826064976\n",
      "      - -189613.3473982862\n",
      "      - -191174.82728866997\n",
      "      - -191550.54884641257\n",
      "      - -189250.7559989299\n",
      "      - -191227.2223838218\n",
      "      - -190922.43997827783\n",
      "      - -191055.59255298748\n",
      "      - -193324.87555258494\n",
      "      - -190486.46082061346\n",
      "      - -190264.30906234283\n",
      "      - -189037.86018899034\n",
      "      - -190217.5276295423\n",
      "      - -192329.85110623558\n",
      "      - -189294.91757351268\n",
      "      - -190585.272021501\n",
      "      - -191751.39770454195\n",
      "      - -191218.45269654138\n",
      "      - -189410.3184771404\n",
      "      - -188524.18203458787\n",
      "      - -191319.52280515488\n",
      "      - -189753.3456946461\n",
      "      - -189736.39601758664\n",
      "      - -189626.67097192054\n",
      "      - -189837.0837667843\n",
      "      - -188686.0453330863\n",
      "      - -192574.41346202575\n",
      "      - -190504.30711622612\n",
      "      - -188972.19521307416\n",
      "      - -190097.65248736207\n",
      "      - -191611.73994317267\n",
      "      - -191050.48352215905\n",
      "      - -191767.81785308445\n",
      "      - -190993.7206324739\n",
      "      - -195137.6115650324\n",
      "      - -189168.56468970707\n",
      "      - -190817.6271894573\n",
      "      - -192263.24804503322\n",
      "      - -190238.40157620545\n",
      "      - -190335.3805739016\n",
      "      - -191667.48601992088\n",
      "      - -189412.7252763411\n",
      "      - -187838.39982876924\n",
      "      - -188828.19764952417\n",
      "      - -191552.0392400462\n",
      "      - -188964.8443213173\n",
      "      - -189879.71732084552\n",
      "      - -191730.05315905923\n",
      "      - -189173.8523024401\n",
      "      - -191555.07148626057\n",
      "      - -189564.82759676638\n",
      "      - -190447.51369177247\n",
      "      - -189076.94677262244\n",
      "      - -189816.55528911288\n",
      "      - -193052.63314962553\n",
      "      - -190444.7895153005\n",
      "      - -187604.66541026128\n",
      "      - -190342.17034631304\n",
      "      - -188549.27852444458\n",
      "      - -190847.6316247285\n",
      "      - -189274.15919078406\n",
      "      - -189661.5127123175\n",
      "      - -190317.81777327284\n",
      "      - -193335.34539946806\n",
      "      - -189807.93600084443\n",
      "      - -191495.75822322792\n",
      "      - -192155.60363746987\n",
      "      - -189423.99630473755\n",
      "      - -189778.12793870628\n",
      "      - -189757.8699601395\n",
      "      - -192428.09671367673\n",
      "      - -190681.95511095366\n",
      "      - -189250.9619950111\n",
      "      - -188483.39157687046\n",
      "      - -191127.16064390168\n",
      "      - -188744.88582177224\n",
      "      - -191388.9183033822\n",
      "      - -194368.39783450667\n",
      "      - -189991.11678977957\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09331248471051486\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4652890841472727\n",
      "      mean_inference_ms: 0.9624956588111092\n",
      "      mean_raw_obs_processing_ms: 0.13336617233676132\n",
      "  time_since_restore: 2548.6741905212402\n",
      "  time_this_iter_s: 9.007200241088867\n",
      "  time_total_s: 2548.6741905212402\n",
      "  timers:\n",
      "    learn_throughput: 123106.762\n",
      "    learn_time_ms: 519.744\n",
      "    load_throughput: 22190756.107\n",
      "    load_time_ms: 2.883\n",
      "    training_iteration_time_ms: 8838.441\n",
      "    update_time_ms: 4.036\n",
      "  timestamp: 1665851303\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 17147712\n",
      "  training_iteration: 268\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:28:28 (running for 00:43:03.37)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   268</td><td style=\"text-align: right;\">         2548.67</td><td style=\"text-align: right;\">17147712</td><td style=\"text-align: right;\"> -190518</td><td style=\"text-align: right;\">             -187605</td><td style=\"text-align: right;\">             -195138</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 17211696\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 17211696\n",
      "    num_agent_steps_trained: 17211696\n",
      "    num_env_steps_sampled: 17211696\n",
      "    num_env_steps_trained: 17211696\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-28-32\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -186608.0089799702\n",
      "  episode_reward_mean: -190655.47337622524\n",
      "  episode_reward_min: -208064.88635224933\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 17208\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1050615310668945\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0016200905665755272\n",
      "          model: {}\n",
      "          policy_loss: 0.0052316621877253056\n",
      "          total_loss: 10.005244255065918\n",
      "          vf_explained_var: -3.0275376872168636e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 17211696\n",
      "    num_agent_steps_trained: 17211696\n",
      "    num_env_steps_sampled: 17211696\n",
      "    num_env_steps_trained: 17211696\n",
      "  iterations_since_restore: 269\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 17211696\n",
      "  num_agent_steps_trained: 17211696\n",
      "  num_env_steps_sampled: 17211696\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 17211696\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.75\n",
      "    ram_util_percent: 89.10000000000001\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09327848565238864\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.465264940841072\n",
      "    mean_inference_ms: 0.9621361366074876\n",
      "    mean_raw_obs_processing_ms: 0.13316764306062764\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -186608.0089799702\n",
      "    episode_reward_mean: -190655.47337622524\n",
      "    episode_reward_min: -208064.88635224933\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -190447.51369177247\n",
      "      - -189076.94677262244\n",
      "      - -189816.55528911288\n",
      "      - -193052.63314962553\n",
      "      - -190444.7895153005\n",
      "      - -187604.66541026128\n",
      "      - -190342.17034631304\n",
      "      - -188549.27852444458\n",
      "      - -190847.6316247285\n",
      "      - -189274.15919078406\n",
      "      - -189661.5127123175\n",
      "      - -190317.81777327284\n",
      "      - -193335.34539946806\n",
      "      - -189807.93600084443\n",
      "      - -191495.75822322792\n",
      "      - -192155.60363746987\n",
      "      - -189423.99630473755\n",
      "      - -189778.12793870628\n",
      "      - -189757.8699601395\n",
      "      - -192428.09671367673\n",
      "      - -190681.95511095366\n",
      "      - -189250.9619950111\n",
      "      - -188483.39157687046\n",
      "      - -191127.16064390168\n",
      "      - -188744.88582177224\n",
      "      - -191388.9183033822\n",
      "      - -194368.39783450667\n",
      "      - -189991.11678977957\n",
      "      - -188243.41331674243\n",
      "      - -188645.69679247928\n",
      "      - -190504.1226650419\n",
      "      - -192555.68822082295\n",
      "      - -192391.58436891309\n",
      "      - -192098.46016493565\n",
      "      - -188610.06621092127\n",
      "      - -199198.92791933526\n",
      "      - -190293.50948604327\n",
      "      - -191000.44685945156\n",
      "      - -191754.29370307602\n",
      "      - -188611.44944920027\n",
      "      - -190309.81994351128\n",
      "      - -192223.0447933664\n",
      "      - -190582.1029412258\n",
      "      - -189183.8629766246\n",
      "      - -191363.64758786454\n",
      "      - -189781.99787138822\n",
      "      - -189396.0946327206\n",
      "      - -193404.33665735315\n",
      "      - -208064.88635224933\n",
      "      - -188781.905282937\n",
      "      - -191413.81194481923\n",
      "      - -189818.98234783267\n",
      "      - -189157.34508785495\n",
      "      - -189125.48462324185\n",
      "      - -194181.21148815248\n",
      "      - -191668.21142177333\n",
      "      - -192415.96642554086\n",
      "      - -191844.77375934488\n",
      "      - -190531.22452222373\n",
      "      - -190541.6014687064\n",
      "      - -193407.28210760065\n",
      "      - -190174.3424992884\n",
      "      - -191734.156169547\n",
      "      - -191171.73558117385\n",
      "      - -188980.8731325577\n",
      "      - -194617.3324620935\n",
      "      - -190978.89156823276\n",
      "      - -189980.88575061597\n",
      "      - -192166.56435671553\n",
      "      - -188513.9326716185\n",
      "      - -189478.69114580713\n",
      "      - -189295.988624473\n",
      "      - -189052.6692799822\n",
      "      - -189443.25889762756\n",
      "      - -188153.52312871904\n",
      "      - -190201.6616209065\n",
      "      - -190401.46925533333\n",
      "      - -189678.71231442888\n",
      "      - -191416.19841869333\n",
      "      - -190774.06086311524\n",
      "      - -188139.24082128188\n",
      "      - -189238.34428482057\n",
      "      - -190343.50111343924\n",
      "      - -190591.52685644626\n",
      "      - -189667.33634456646\n",
      "      - -191168.41925654592\n",
      "      - -190020.66784880144\n",
      "      - -186608.0089799702\n",
      "      - -186997.48005329588\n",
      "      - -191352.8524070945\n",
      "      - -190033.73933352137\n",
      "      - -190679.21945002483\n",
      "      - -189842.70852635932\n",
      "      - -190051.90259143247\n",
      "      - -188820.03587733503\n",
      "      - -190628.7374823499\n",
      "      - -191223.56542906445\n",
      "      - -191736.55305949316\n",
      "      - -190401.6319915247\n",
      "      - -189026.46852592667\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09327848565238864\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.465264940841072\n",
      "      mean_inference_ms: 0.9621361366074876\n",
      "      mean_raw_obs_processing_ms: 0.13316764306062764\n",
      "  time_since_restore: 2557.587206363678\n",
      "  time_this_iter_s: 8.913015842437744\n",
      "  time_total_s: 2557.587206363678\n",
      "  timers:\n",
      "    learn_throughput: 124735.712\n",
      "    learn_time_ms: 512.957\n",
      "    load_throughput: 22177919.223\n",
      "    load_time_ms: 2.885\n",
      "    training_iteration_time_ms: 8842.265\n",
      "    update_time_ms: 3.833\n",
      "  timestamp: 1665851312\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 17211696\n",
      "  training_iteration: 269\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:28:37 (running for 00:43:11.73)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   269</td><td style=\"text-align: right;\">         2557.59</td><td style=\"text-align: right;\">17211696</td><td style=\"text-align: right;\"> -190655</td><td style=\"text-align: right;\">             -186608</td><td style=\"text-align: right;\">             -208065</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 17275680\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 17275680\n",
      "    num_agent_steps_trained: 17275680\n",
      "    num_env_steps_sampled: 17275680\n",
      "    num_env_steps_trained: 17275680\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-28-41\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -186608.0089799702\n",
      "  episode_reward_mean: -190508.9317946244\n",
      "  episode_reward_min: -197226.60882604675\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 17268\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1085751056671143\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0005310744745656848\n",
      "          model: {}\n",
      "          policy_loss: 0.007570182904601097\n",
      "          total_loss: 10.007365226745605\n",
      "          vf_explained_var: -2.3652637182181024e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 17275680\n",
      "    num_agent_steps_trained: 17275680\n",
      "    num_env_steps_sampled: 17275680\n",
      "    num_env_steps_trained: 17275680\n",
      "  iterations_since_restore: 270\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 17275680\n",
      "  num_agent_steps_trained: 17275680\n",
      "  num_env_steps_sampled: 17275680\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 17275680\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.87692307692308\n",
      "    ram_util_percent: 89.06153846153846\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0932688448715167\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46518324852055515\n",
      "    mean_inference_ms: 0.9619582295171198\n",
      "    mean_raw_obs_processing_ms: 0.1332880707735871\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -186608.0089799702\n",
      "    episode_reward_mean: -190508.9317946244\n",
      "    episode_reward_min: -197226.60882604675\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -193407.28210760065\n",
      "      - -190174.3424992884\n",
      "      - -191734.156169547\n",
      "      - -191171.73558117385\n",
      "      - -188980.8731325577\n",
      "      - -194617.3324620935\n",
      "      - -190978.89156823276\n",
      "      - -189980.88575061597\n",
      "      - -192166.56435671553\n",
      "      - -188513.9326716185\n",
      "      - -189478.69114580713\n",
      "      - -189295.988624473\n",
      "      - -189052.6692799822\n",
      "      - -189443.25889762756\n",
      "      - -188153.52312871904\n",
      "      - -190201.6616209065\n",
      "      - -190401.46925533333\n",
      "      - -189678.71231442888\n",
      "      - -191416.19841869333\n",
      "      - -190774.06086311524\n",
      "      - -188139.24082128188\n",
      "      - -189238.34428482057\n",
      "      - -190343.50111343924\n",
      "      - -190591.52685644626\n",
      "      - -189667.33634456646\n",
      "      - -191168.41925654592\n",
      "      - -190020.66784880144\n",
      "      - -186608.0089799702\n",
      "      - -186997.48005329588\n",
      "      - -191352.8524070945\n",
      "      - -190033.73933352137\n",
      "      - -190679.21945002483\n",
      "      - -189842.70852635932\n",
      "      - -190051.90259143247\n",
      "      - -188820.03587733503\n",
      "      - -190628.7374823499\n",
      "      - -191223.56542906445\n",
      "      - -191736.55305949316\n",
      "      - -190401.6319915247\n",
      "      - -189026.46852592667\n",
      "      - -191112.50388621222\n",
      "      - -191197.25210426023\n",
      "      - -190995.00301956217\n",
      "      - -189602.33970434326\n",
      "      - -197226.60882604675\n",
      "      - -190347.3003339367\n",
      "      - -188644.91358091382\n",
      "      - -189806.71540001468\n",
      "      - -191080.36497592277\n",
      "      - -189353.96818692077\n",
      "      - -190284.9299714653\n",
      "      - -191619.32959687032\n",
      "      - -191241.65296302817\n",
      "      - -191114.4576872344\n",
      "      - -190014.12209493658\n",
      "      - -191779.82761415903\n",
      "      - -189803.05065349187\n",
      "      - -190590.33163502585\n",
      "      - -190310.79021377806\n",
      "      - -191072.51351106583\n",
      "      - -191672.308409642\n",
      "      - -189958.0285968137\n",
      "      - -191776.22420504462\n",
      "      - -192115.0755419914\n",
      "      - -189313.12609402635\n",
      "      - -189666.41322839353\n",
      "      - -190242.89497802375\n",
      "      - -189740.62943118968\n",
      "      - -188905.5733117279\n",
      "      - -190470.1596623162\n",
      "      - -190229.92738808028\n",
      "      - -191266.67111498493\n",
      "      - -190202.37328962723\n",
      "      - -190312.08275847542\n",
      "      - -190096.47921442488\n",
      "      - -191719.07700984253\n",
      "      - -190398.7695843848\n",
      "      - -193038.4200628054\n",
      "      - -191223.90440095222\n",
      "      - -190178.46539671428\n",
      "      - -192315.64322265072\n",
      "      - -193214.24710946763\n",
      "      - -191560.61435070605\n",
      "      - -190488.79809836467\n",
      "      - -189631.54980156146\n",
      "      - -189781.67931095467\n",
      "      - -190979.04618921457\n",
      "      - -188863.74588771764\n",
      "      - -192355.2172908015\n",
      "      - -191912.50492422527\n",
      "      - -188802.9918694303\n",
      "      - -191439.37259610827\n",
      "      - -189292.9251145471\n",
      "      - -191324.72001953772\n",
      "      - -190340.28272446358\n",
      "      - -191083.35555876556\n",
      "      - -188807.71818888286\n",
      "      - -190224.68269106775\n",
      "      - -190206.18807521107\n",
      "      - -192349.1467182895\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.0932688448715167\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46518324852055515\n",
      "      mean_inference_ms: 0.9619582295171198\n",
      "      mean_raw_obs_processing_ms: 0.1332880707735871\n",
      "  time_since_restore: 2566.3019325733185\n",
      "  time_this_iter_s: 8.714726209640503\n",
      "  time_total_s: 2566.3019325733185\n",
      "  timers:\n",
      "    learn_throughput: 123561.22\n",
      "    learn_time_ms: 517.832\n",
      "    load_throughput: 22353969.642\n",
      "    load_time_ms: 2.862\n",
      "    training_iteration_time_ms: 8836.897\n",
      "    update_time_ms: 3.763\n",
      "  timestamp: 1665851321\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 17275680\n",
      "  training_iteration: 270\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:28:46 (running for 00:43:20.61)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   270</td><td style=\"text-align: right;\">          2566.3</td><td style=\"text-align: right;\">17275680</td><td style=\"text-align: right;\"> -190509</td><td style=\"text-align: right;\">             -186608</td><td style=\"text-align: right;\">             -197227</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 17339664\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 17339664\n",
      "    num_agent_steps_trained: 17339664\n",
      "    num_env_steps_sampled: 17339664\n",
      "    num_env_steps_trained: 17339664\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-28-50\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -187792.62821741228\n",
      "  episode_reward_mean: -190746.83532953187\n",
      "  episode_reward_min: -195409.21500153767\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 17328\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.105029344558716\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0009713497129268944\n",
      "          model: {}\n",
      "          policy_loss: -0.002143857069313526\n",
      "          total_loss: 9.997739791870117\n",
      "          vf_explained_var: -2.6490953430879927e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 17339664\n",
      "    num_agent_steps_trained: 17339664\n",
      "    num_env_steps_sampled: 17339664\n",
      "    num_env_steps_trained: 17339664\n",
      "  iterations_since_restore: 271\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 17339664\n",
      "  num_agent_steps_trained: 17339664\n",
      "  num_env_steps_sampled: 17339664\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 17339664\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 80.14615384615385\n",
      "    ram_util_percent: 89.0923076923077\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09322662763970609\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4650673766793348\n",
      "    mean_inference_ms: 0.961808942862265\n",
      "    mean_raw_obs_processing_ms: 0.13326344955057637\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -187792.62821741228\n",
      "    episode_reward_mean: -190746.83532953187\n",
      "    episode_reward_min: -195409.21500153767\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -191672.308409642\n",
      "      - -189958.0285968137\n",
      "      - -191776.22420504462\n",
      "      - -192115.0755419914\n",
      "      - -189313.12609402635\n",
      "      - -189666.41322839353\n",
      "      - -190242.89497802375\n",
      "      - -189740.62943118968\n",
      "      - -188905.5733117279\n",
      "      - -190470.1596623162\n",
      "      - -190229.92738808028\n",
      "      - -191266.67111498493\n",
      "      - -190202.37328962723\n",
      "      - -190312.08275847542\n",
      "      - -190096.47921442488\n",
      "      - -191719.07700984253\n",
      "      - -190398.7695843848\n",
      "      - -193038.4200628054\n",
      "      - -191223.90440095222\n",
      "      - -190178.46539671428\n",
      "      - -192315.64322265072\n",
      "      - -193214.24710946763\n",
      "      - -191560.61435070605\n",
      "      - -190488.79809836467\n",
      "      - -189631.54980156146\n",
      "      - -189781.67931095467\n",
      "      - -190979.04618921457\n",
      "      - -188863.74588771764\n",
      "      - -192355.2172908015\n",
      "      - -191912.50492422527\n",
      "      - -188802.9918694303\n",
      "      - -191439.37259610827\n",
      "      - -189292.9251145471\n",
      "      - -191324.72001953772\n",
      "      - -190340.28272446358\n",
      "      - -191083.35555876556\n",
      "      - -188807.71818888286\n",
      "      - -190224.68269106775\n",
      "      - -190206.18807521107\n",
      "      - -192349.1467182895\n",
      "      - -191047.5630979199\n",
      "      - -190860.6224561364\n",
      "      - -191596.62166174178\n",
      "      - -191322.28894406348\n",
      "      - -190174.95277465173\n",
      "      - -190809.91786529133\n",
      "      - -188655.64708590624\n",
      "      - -191619.35455683302\n",
      "      - -190783.26885573092\n",
      "      - -189939.41916523158\n",
      "      - -190346.2190703313\n",
      "      - -187792.62821741228\n",
      "      - -189417.74897281334\n",
      "      - -190922.74001572968\n",
      "      - -191391.3532166029\n",
      "      - -188826.57356855692\n",
      "      - -190499.629832284\n",
      "      - -188872.95824389026\n",
      "      - -190162.08415593446\n",
      "      - -192582.2404274275\n",
      "      - -190356.67928443442\n",
      "      - -189360.42236603054\n",
      "      - -191737.38756530127\n",
      "      - -192185.49140427043\n",
      "      - -195409.21500153767\n",
      "      - -190544.7003898632\n",
      "      - -193768.761384779\n",
      "      - -191204.93103786258\n",
      "      - -191162.39490218507\n",
      "      - -189077.18018854162\n",
      "      - -191068.57831961586\n",
      "      - -192314.34066802045\n",
      "      - -190356.75339863918\n",
      "      - -192152.65250963753\n",
      "      - -191978.8092615441\n",
      "      - -189951.89560198417\n",
      "      - -192188.33361944338\n",
      "      - -191274.45138902668\n",
      "      - -192363.7917445321\n",
      "      - -190426.18316461137\n",
      "      - -189859.28214046222\n",
      "      - -190253.84554738543\n",
      "      - -190133.00353580483\n",
      "      - -192254.10508548355\n",
      "      - -189059.27290416343\n",
      "      - -190806.93741186886\n",
      "      - -192849.662544981\n",
      "      - -189561.8886594566\n",
      "      - -190805.30531004447\n",
      "      - -188879.03010077713\n",
      "      - -190126.1242847831\n",
      "      - -191394.79293850402\n",
      "      - -190825.91985903835\n",
      "      - -191334.2871171444\n",
      "      - -190192.04965909215\n",
      "      - -190748.81013877664\n",
      "      - -190263.54032993168\n",
      "      - -188479.53112677098\n",
      "      - -192768.1486694308\n",
      "      - -190080.17678150814\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09322662763970609\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4650673766793348\n",
      "      mean_inference_ms: 0.961808942862265\n",
      "      mean_raw_obs_processing_ms: 0.13326344955057637\n",
      "  time_since_restore: 2575.6003675460815\n",
      "  time_this_iter_s: 9.298434972763062\n",
      "  time_total_s: 2575.6003675460815\n",
      "  timers:\n",
      "    learn_throughput: 122941.488\n",
      "    learn_time_ms: 520.443\n",
      "    load_throughput: 22292692.313\n",
      "    load_time_ms: 2.87\n",
      "    training_iteration_time_ms: 8870.277\n",
      "    update_time_ms: 3.691\n",
      "  timestamp: 1665851330\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 17339664\n",
      "  training_iteration: 271\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:28:55 (running for 00:43:30.23)<br>Memory usage on this node: 13.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   271</td><td style=\"text-align: right;\">          2575.6</td><td style=\"text-align: right;\">17339664</td><td style=\"text-align: right;\"> -190747</td><td style=\"text-align: right;\">             -187793</td><td style=\"text-align: right;\">             -195409</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 17403648\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 17403648\n",
      "    num_agent_steps_trained: 17403648\n",
      "    num_env_steps_sampled: 17403648\n",
      "    num_env_steps_trained: 17403648\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-29-00\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -188479.53112677098\n",
      "  episode_reward_mean: -190942.99225562255\n",
      "  episode_reward_min: -194712.9805543339\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 17400\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.103708028793335\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0005875796196050942\n",
      "          model: {}\n",
      "          policy_loss: 0.005207995884120464\n",
      "          total_loss: 10.005013465881348\n",
      "          vf_explained_var: -4.1628641866964244e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 17403648\n",
      "    num_agent_steps_trained: 17403648\n",
      "    num_env_steps_sampled: 17403648\n",
      "    num_env_steps_trained: 17403648\n",
      "  iterations_since_restore: 272\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 17403648\n",
      "  num_agent_steps_trained: 17403648\n",
      "  num_env_steps_sampled: 17403648\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 17403648\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 84.22307692307692\n",
      "    ram_util_percent: 89.56923076923076\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09321716237151868\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46506840598278965\n",
      "    mean_inference_ms: 0.9617175671133534\n",
      "    mean_raw_obs_processing_ms: 0.13311444838158434\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -188479.53112677098\n",
      "    episode_reward_mean: -190942.99225562255\n",
      "    episode_reward_min: -194712.9805543339\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -190356.75339863918\n",
      "      - -192152.65250963753\n",
      "      - -191978.8092615441\n",
      "      - -189951.89560198417\n",
      "      - -192188.33361944338\n",
      "      - -191274.45138902668\n",
      "      - -192363.7917445321\n",
      "      - -190426.18316461137\n",
      "      - -189859.28214046222\n",
      "      - -190253.84554738543\n",
      "      - -190133.00353580483\n",
      "      - -192254.10508548355\n",
      "      - -189059.27290416343\n",
      "      - -190806.93741186886\n",
      "      - -192849.662544981\n",
      "      - -189561.8886594566\n",
      "      - -190805.30531004447\n",
      "      - -188879.03010077713\n",
      "      - -190126.1242847831\n",
      "      - -191394.79293850402\n",
      "      - -190825.91985903835\n",
      "      - -191334.2871171444\n",
      "      - -190192.04965909215\n",
      "      - -190748.81013877664\n",
      "      - -190263.54032993168\n",
      "      - -188479.53112677098\n",
      "      - -192768.1486694308\n",
      "      - -190080.17678150814\n",
      "      - -189923.301969641\n",
      "      - -194205.4751142153\n",
      "      - -191246.04042950436\n",
      "      - -190707.88967356013\n",
      "      - -190468.63328494696\n",
      "      - -190655.39209677084\n",
      "      - -190855.3267049612\n",
      "      - -192148.62343614298\n",
      "      - -191895.10463576167\n",
      "      - -190705.84486070857\n",
      "      - -190060.01027955918\n",
      "      - -192936.66780416787\n",
      "      - -190494.01634591096\n",
      "      - -190977.8590271452\n",
      "      - -191304.00207401367\n",
      "      - -193646.22500853887\n",
      "      - -189865.88569282545\n",
      "      - -191543.59242567458\n",
      "      - -190806.6636514868\n",
      "      - -189815.3801658764\n",
      "      - -191434.37597799834\n",
      "      - -191628.2368964459\n",
      "      - -190758.78451120915\n",
      "      - -190058.1653139694\n",
      "      - -189394.29626447786\n",
      "      - -190303.3287122987\n",
      "      - -189460.73423783833\n",
      "      - -189829.34582000977\n",
      "      - -191215.58868454339\n",
      "      - -191164.43916646732\n",
      "      - -191702.81737306935\n",
      "      - -190063.44545396502\n",
      "      - -191591.59655550204\n",
      "      - -190876.25869842464\n",
      "      - -189160.35602841707\n",
      "      - -189988.13352183503\n",
      "      - -190070.65096870004\n",
      "      - -190893.18437164\n",
      "      - -192013.73216668548\n",
      "      - -191018.54375392516\n",
      "      - -190798.18188806323\n",
      "      - -191071.37165298834\n",
      "      - -192772.41300547344\n",
      "      - -189783.23825731812\n",
      "      - -191856.7117879304\n",
      "      - -190489.00573292354\n",
      "      - -190901.9092286557\n",
      "      - -190155.37593311514\n",
      "      - -190121.6846803754\n",
      "      - -190612.77770756392\n",
      "      - -191176.1000239615\n",
      "      - -190473.18214360205\n",
      "      - -192261.02385798297\n",
      "      - -190337.4096145849\n",
      "      - -190931.07555297745\n",
      "      - -190724.4056688363\n",
      "      - -190812.81335255274\n",
      "      - -190074.66295101494\n",
      "      - -191667.21186196504\n",
      "      - -191470.48317041917\n",
      "      - -191986.6909902651\n",
      "      - -190410.48951776727\n",
      "      - -192061.8531566505\n",
      "      - -189878.33791354467\n",
      "      - -190382.15620964053\n",
      "      - -190100.01022387433\n",
      "      - -190021.65146712292\n",
      "      - -190944.20964843617\n",
      "      - -193231.59373071365\n",
      "      - -192904.56964826354\n",
      "      - -194712.9805543339\n",
      "      - -190917.1104356798\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09321716237151868\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46506840598278965\n",
      "      mean_inference_ms: 0.9617175671133534\n",
      "      mean_raw_obs_processing_ms: 0.13311444838158434\n",
      "  time_since_restore: 2585.115175962448\n",
      "  time_this_iter_s: 9.514808416366577\n",
      "  time_total_s: 2585.115175962448\n",
      "  timers:\n",
      "    learn_throughput: 124365.165\n",
      "    learn_time_ms: 514.485\n",
      "    load_throughput: 22247415.392\n",
      "    load_time_ms: 2.876\n",
      "    training_iteration_time_ms: 8914.505\n",
      "    update_time_ms: 3.862\n",
      "  timestamp: 1665851340\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 17403648\n",
      "  training_iteration: 272\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:29:05 (running for 00:43:39.49)<br>Memory usage on this node: 13.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   272</td><td style=\"text-align: right;\">         2585.12</td><td style=\"text-align: right;\">17403648</td><td style=\"text-align: right;\"> -190943</td><td style=\"text-align: right;\">             -188480</td><td style=\"text-align: right;\">             -194713</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 17467632\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 17467632\n",
      "    num_agent_steps_trained: 17467632\n",
      "    num_env_steps_sampled: 17467632\n",
      "    num_env_steps_trained: 17467632\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-29-09\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -188783.08575760448\n",
      "  episode_reward_mean: -191017.53671293083\n",
      "  episode_reward_min: -194712.9805543339\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 17460\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.100745916366577\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0008187902858480811\n",
      "          model: {}\n",
      "          policy_loss: 0.007546423934400082\n",
      "          total_loss: 10.007401466369629\n",
      "          vf_explained_var: -3.7844220202032375e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 17467632\n",
      "    num_agent_steps_trained: 17467632\n",
      "    num_env_steps_sampled: 17467632\n",
      "    num_env_steps_trained: 17467632\n",
      "  iterations_since_restore: 273\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 17467632\n",
      "  num_agent_steps_trained: 17467632\n",
      "  num_env_steps_sampled: 17467632\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 17467632\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.10769230769232\n",
      "    ram_util_percent: 89.84615384615384\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0932326005011909\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4650480983225777\n",
      "    mean_inference_ms: 0.9617681972633133\n",
      "    mean_raw_obs_processing_ms: 0.13326209295175542\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -188783.08575760448\n",
      "    episode_reward_mean: -191017.53671293083\n",
      "    episode_reward_min: -194712.9805543339\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -191591.59655550204\n",
      "      - -190876.25869842464\n",
      "      - -189160.35602841707\n",
      "      - -189988.13352183503\n",
      "      - -190070.65096870004\n",
      "      - -190893.18437164\n",
      "      - -192013.73216668548\n",
      "      - -191018.54375392516\n",
      "      - -190798.18188806323\n",
      "      - -191071.37165298834\n",
      "      - -192772.41300547344\n",
      "      - -189783.23825731812\n",
      "      - -191856.7117879304\n",
      "      - -190489.00573292354\n",
      "      - -190901.9092286557\n",
      "      - -190155.37593311514\n",
      "      - -190121.6846803754\n",
      "      - -190612.77770756392\n",
      "      - -191176.1000239615\n",
      "      - -190473.18214360205\n",
      "      - -192261.02385798297\n",
      "      - -190337.4096145849\n",
      "      - -190931.07555297745\n",
      "      - -190724.4056688363\n",
      "      - -190812.81335255274\n",
      "      - -190074.66295101494\n",
      "      - -191667.21186196504\n",
      "      - -191470.48317041917\n",
      "      - -191986.6909902651\n",
      "      - -190410.48951776727\n",
      "      - -192061.8531566505\n",
      "      - -189878.33791354467\n",
      "      - -190382.15620964053\n",
      "      - -190100.01022387433\n",
      "      - -190021.65146712292\n",
      "      - -190944.20964843617\n",
      "      - -193231.59373071365\n",
      "      - -192904.56964826354\n",
      "      - -194712.9805543339\n",
      "      - -190917.1104356798\n",
      "      - -191299.68159733183\n",
      "      - -188783.08575760448\n",
      "      - -189086.53156734467\n",
      "      - -189781.46171294796\n",
      "      - -191058.55825748405\n",
      "      - -192796.73906239655\n",
      "      - -190999.66146700006\n",
      "      - -191614.65914509693\n",
      "      - -189684.34797183768\n",
      "      - -191988.31439383057\n",
      "      - -190275.10036640955\n",
      "      - -190510.80546923296\n",
      "      - -190433.33818210414\n",
      "      - -190657.16800868706\n",
      "      - -191277.74658802897\n",
      "      - -189644.47522534174\n",
      "      - -190550.58462968783\n",
      "      - -191319.98396369963\n",
      "      - -189706.5932799831\n",
      "      - -190779.6499100449\n",
      "      - -191159.71623403885\n",
      "      - -190487.06259538245\n",
      "      - -189653.27716005177\n",
      "      - -192496.59021279466\n",
      "      - -191345.41997124825\n",
      "      - -191522.86439469826\n",
      "      - -192430.8690699859\n",
      "      - -189563.45335498554\n",
      "      - -188881.6825951759\n",
      "      - -193136.86577208954\n",
      "      - -192891.23489942498\n",
      "      - -189441.51206401343\n",
      "      - -191473.0327265824\n",
      "      - -192899.41981949532\n",
      "      - -189447.45693225763\n",
      "      - -189126.01369521607\n",
      "      - -190669.3796827263\n",
      "      - -191139.24630019697\n",
      "      - -190869.73848452698\n",
      "      - -191891.56499500055\n",
      "      - -190947.38196144966\n",
      "      - -190288.24807466133\n",
      "      - -192739.17533230403\n",
      "      - -190496.53633262665\n",
      "      - -191583.95994508237\n",
      "      - -191319.54286056696\n",
      "      - -190198.68819819993\n",
      "      - -191852.50582924552\n",
      "      - -191772.92535805996\n",
      "      - -189425.55682953572\n",
      "      - -190595.66669965204\n",
      "      - -191636.4750866421\n",
      "      - -191571.07856351833\n",
      "      - -190617.693985714\n",
      "      - -193088.64117466888\n",
      "      - -192642.95642065347\n",
      "      - -192165.0364030169\n",
      "      - -191785.8340502035\n",
      "      - -191218.9520948097\n",
      "      - -191376.78094275887\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.0932326005011909\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4650480983225777\n",
      "      mean_inference_ms: 0.9617681972633133\n",
      "      mean_raw_obs_processing_ms: 0.13326209295175542\n",
      "  time_since_restore: 2594.3485822677612\n",
      "  time_this_iter_s: 9.23340630531311\n",
      "  time_total_s: 2594.3485822677612\n",
      "  timers:\n",
      "    learn_throughput: 124747.134\n",
      "    learn_time_ms: 512.91\n",
      "    load_throughput: 22237276.452\n",
      "    load_time_ms: 2.877\n",
      "    training_iteration_time_ms: 8956.11\n",
      "    update_time_ms: 3.915\n",
      "  timestamp: 1665851349\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 17467632\n",
      "  training_iteration: 273\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:29:14 (running for 00:43:49.01)<br>Memory usage on this node: 13.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   273</td><td style=\"text-align: right;\">         2594.35</td><td style=\"text-align: right;\">17467632</td><td style=\"text-align: right;\"> -191018</td><td style=\"text-align: right;\">             -188783</td><td style=\"text-align: right;\">             -194713</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 17531616\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 17531616\n",
      "    num_agent_steps_trained: 17531616\n",
      "    num_env_steps_sampled: 17531616\n",
      "    num_env_steps_trained: 17531616\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-29-18\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -188086.15994701872\n",
      "  episode_reward_mean: -190953.3909496395\n",
      "  episode_reward_min: -193610.4192624042\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 17520\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.102976083755493\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0007961284136399627\n",
      "          model: {}\n",
      "          policy_loss: -0.0018833065405488014\n",
      "          total_loss: 9.997965812683105\n",
      "          vf_explained_var: -4.068253645073128e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 17531616\n",
      "    num_agent_steps_trained: 17531616\n",
      "    num_env_steps_sampled: 17531616\n",
      "    num_env_steps_trained: 17531616\n",
      "  iterations_since_restore: 274\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 17531616\n",
      "  num_agent_steps_trained: 17531616\n",
      "  num_env_steps_sampled: 17531616\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 17531616\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.07692307692308\n",
      "    ram_util_percent: 89.63846153846154\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09319056112590551\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46492920785731157\n",
      "    mean_inference_ms: 0.9616311211353384\n",
      "    mean_raw_obs_processing_ms: 0.13323928954433006\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -188086.15994701872\n",
      "    episode_reward_mean: -190953.3909496395\n",
      "    episode_reward_min: -193610.4192624042\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -191159.71623403885\n",
      "      - -190487.06259538245\n",
      "      - -189653.27716005177\n",
      "      - -192496.59021279466\n",
      "      - -191345.41997124825\n",
      "      - -191522.86439469826\n",
      "      - -192430.8690699859\n",
      "      - -189563.45335498554\n",
      "      - -188881.6825951759\n",
      "      - -193136.86577208954\n",
      "      - -192891.23489942498\n",
      "      - -189441.51206401343\n",
      "      - -191473.0327265824\n",
      "      - -192899.41981949532\n",
      "      - -189447.45693225763\n",
      "      - -189126.01369521607\n",
      "      - -190669.3796827263\n",
      "      - -191139.24630019697\n",
      "      - -190869.73848452698\n",
      "      - -191891.56499500055\n",
      "      - -190947.38196144966\n",
      "      - -190288.24807466133\n",
      "      - -192739.17533230403\n",
      "      - -190496.53633262665\n",
      "      - -191583.95994508237\n",
      "      - -191319.54286056696\n",
      "      - -190198.68819819993\n",
      "      - -191852.50582924552\n",
      "      - -191772.92535805996\n",
      "      - -189425.55682953572\n",
      "      - -190595.66669965204\n",
      "      - -191636.4750866421\n",
      "      - -191571.07856351833\n",
      "      - -190617.693985714\n",
      "      - -193088.64117466888\n",
      "      - -192642.95642065347\n",
      "      - -192165.0364030169\n",
      "      - -191785.8340502035\n",
      "      - -191218.9520948097\n",
      "      - -191376.78094275887\n",
      "      - -190853.17012250226\n",
      "      - -192473.97420934137\n",
      "      - -190587.2590942064\n",
      "      - -189092.04130900433\n",
      "      - -193610.4192624042\n",
      "      - -192482.8100154442\n",
      "      - -191441.9716941678\n",
      "      - -190468.8228822445\n",
      "      - -191939.34857922804\n",
      "      - -190638.56945628484\n",
      "      - -191175.79298954637\n",
      "      - -190010.8259592701\n",
      "      - -189759.7149523096\n",
      "      - -192175.99598263932\n",
      "      - -191258.94368576756\n",
      "      - -193393.9476382284\n",
      "      - -191232.22543875262\n",
      "      - -189833.8646907807\n",
      "      - -190186.8541097277\n",
      "      - -191733.69709483217\n",
      "      - -191215.15644993613\n",
      "      - -192277.88639019095\n",
      "      - -190357.70793789535\n",
      "      - -191605.26662673143\n",
      "      - -189262.16653311742\n",
      "      - -190262.53261861525\n",
      "      - -189367.48523241622\n",
      "      - -189680.7541634802\n",
      "      - -189945.80037266907\n",
      "      - -191969.63576167607\n",
      "      - -189539.74643480702\n",
      "      - -190488.05464319623\n",
      "      - -192577.2321863937\n",
      "      - -190979.16847606385\n",
      "      - -189976.29890688928\n",
      "      - -191300.48474365266\n",
      "      - -190626.57892110042\n",
      "      - -191156.80223712575\n",
      "      - -190465.49495287356\n",
      "      - -191698.38824636515\n",
      "      - -190623.40887084778\n",
      "      - -190492.21378469525\n",
      "      - -191853.52817000996\n",
      "      - -189669.47753596312\n",
      "      - -188386.13541392685\n",
      "      - -189185.2308697342\n",
      "      - -191489.5714803394\n",
      "      - -189504.54857736095\n",
      "      - -190062.40772448227\n",
      "      - -192584.0267204373\n",
      "      - -191846.08105875112\n",
      "      - -189927.26015481554\n",
      "      - -191486.71317516197\n",
      "      - -191509.94284959688\n",
      "      - -189388.5732099621\n",
      "      - -188086.15994701872\n",
      "      - -190876.84813953278\n",
      "      - -191394.3184779574\n",
      "      - -189280.1244198149\n",
      "      - -190739.59627839742\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09319056112590551\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46492920785731157\n",
      "      mean_inference_ms: 0.9616311211353384\n",
      "      mean_raw_obs_processing_ms: 0.13323928954433006\n",
      "  time_since_restore: 2603.299924850464\n",
      "  time_this_iter_s: 8.951342582702637\n",
      "  time_total_s: 2603.299924850464\n",
      "  timers:\n",
      "    learn_throughput: 124725.265\n",
      "    learn_time_ms: 513.0\n",
      "    load_throughput: 22091929.99\n",
      "    load_time_ms: 2.896\n",
      "    training_iteration_time_ms: 8961.257\n",
      "    update_time_ms: 3.984\n",
      "  timestamp: 1665851358\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 17531616\n",
      "  training_iteration: 274\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:29:23 (running for 00:43:57.99)<br>Memory usage on this node: 13.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   274</td><td style=\"text-align: right;\">          2603.3</td><td style=\"text-align: right;\">17531616</td><td style=\"text-align: right;\"> -190953</td><td style=\"text-align: right;\">             -188086</td><td style=\"text-align: right;\">             -193610</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 17595600\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 17595600\n",
      "    num_agent_steps_trained: 17595600\n",
      "    num_env_steps_sampled: 17595600\n",
      "    num_env_steps_trained: 17595600\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-29-27\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -187812.64897462627\n",
      "  episode_reward_mean: -190880.98985500316\n",
      "  episode_reward_min: -196960.7974974207\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 17592\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1051998138427734\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0010022877249866724\n",
      "          model: {}\n",
      "          policy_loss: 0.005028248764574528\n",
      "          total_loss: 10.004919052124023\n",
      "          vf_explained_var: -2.7437058847112894e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 17595600\n",
      "    num_agent_steps_trained: 17595600\n",
      "    num_env_steps_sampled: 17595600\n",
      "    num_env_steps_trained: 17595600\n",
      "  iterations_since_restore: 275\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 17595600\n",
      "  num_agent_steps_trained: 17595600\n",
      "  num_env_steps_sampled: 17595600\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 17595600\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.56923076923076\n",
      "    ram_util_percent: 89.46923076923076\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09316007712891143\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46484471899400814\n",
      "    mean_inference_ms: 0.9611574479070752\n",
      "    mean_raw_obs_processing_ms: 0.13304792102563606\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -187812.64897462627\n",
      "    episode_reward_mean: -190880.98985500316\n",
      "    episode_reward_min: -196960.7974974207\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -192577.2321863937\n",
      "      - -190979.16847606385\n",
      "      - -189976.29890688928\n",
      "      - -191300.48474365266\n",
      "      - -190626.57892110042\n",
      "      - -191156.80223712575\n",
      "      - -190465.49495287356\n",
      "      - -191698.38824636515\n",
      "      - -190623.40887084778\n",
      "      - -190492.21378469525\n",
      "      - -191853.52817000996\n",
      "      - -189669.47753596312\n",
      "      - -188386.13541392685\n",
      "      - -189185.2308697342\n",
      "      - -191489.5714803394\n",
      "      - -189504.54857736095\n",
      "      - -190062.40772448227\n",
      "      - -192584.0267204373\n",
      "      - -191846.08105875112\n",
      "      - -189927.26015481554\n",
      "      - -191486.71317516197\n",
      "      - -191509.94284959688\n",
      "      - -189388.5732099621\n",
      "      - -188086.15994701872\n",
      "      - -190876.84813953278\n",
      "      - -191394.3184779574\n",
      "      - -189280.1244198149\n",
      "      - -190739.59627839742\n",
      "      - -191102.4450413023\n",
      "      - -190858.4227457784\n",
      "      - -191746.78927205582\n",
      "      - -191538.15328332255\n",
      "      - -189866.18153287433\n",
      "      - -192237.31141981366\n",
      "      - -189703.29223868108\n",
      "      - -189332.01960458432\n",
      "      - -189044.3507296207\n",
      "      - -190209.6108298275\n",
      "      - -192323.36331485191\n",
      "      - -190439.54291407592\n",
      "      - -189946.27599797933\n",
      "      - -189417.59488591863\n",
      "      - -196960.7974974207\n",
      "      - -191053.33234452215\n",
      "      - -191558.39439872533\n",
      "      - -192005.1402151616\n",
      "      - -190437.42063422984\n",
      "      - -191457.17964514712\n",
      "      - -188785.68105776364\n",
      "      - -191051.75217979253\n",
      "      - -193583.29675287753\n",
      "      - -191219.18404843737\n",
      "      - -189826.57533793277\n",
      "      - -191227.21871546414\n",
      "      - -190617.77553261747\n",
      "      - -192995.73332594507\n",
      "      - -190738.87083784302\n",
      "      - -190773.9216694373\n",
      "      - -191477.63291456513\n",
      "      - -194169.79166712033\n",
      "      - -190121.07472179426\n",
      "      - -191402.88244186723\n",
      "      - -187812.64897462627\n",
      "      - -189682.31792310116\n",
      "      - -192448.4708489157\n",
      "      - -189221.54929099124\n",
      "      - -191550.38806630307\n",
      "      - -190535.71825216184\n",
      "      - -191724.62655325147\n",
      "      - -190584.0710506467\n",
      "      - -193199.28436071237\n",
      "      - -191219.38542240654\n",
      "      - -190681.85548799398\n",
      "      - -191714.3577198026\n",
      "      - -189820.83000764807\n",
      "      - -190812.14864524012\n",
      "      - -190742.85744801245\n",
      "      - -189940.05982452765\n",
      "      - -191816.32813993492\n",
      "      - -193409.4597643117\n",
      "      - -191934.2563455603\n",
      "      - -189878.76912539682\n",
      "      - -190506.31737353397\n",
      "      - -190965.58361324095\n",
      "      - -191998.86230618617\n",
      "      - -189963.9384144662\n",
      "      - -189919.38400404775\n",
      "      - -191864.38981151802\n",
      "      - -189157.63842517565\n",
      "      - -192181.4116403158\n",
      "      - -189842.06189929487\n",
      "      - -190200.72199782782\n",
      "      - -191323.51047712832\n",
      "      - -190911.0480543966\n",
      "      - -191180.01941920098\n",
      "      - -192423.20800569613\n",
      "      - -189164.2647765702\n",
      "      - -189251.613031486\n",
      "      - -190801.5129342202\n",
      "      - -191318.490785847\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09316007712891143\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46484471899400814\n",
      "      mean_inference_ms: 0.9611574479070752\n",
      "      mean_raw_obs_processing_ms: 0.13304792102563606\n",
      "  time_since_restore: 2612.3298547267914\n",
      "  time_this_iter_s: 9.029929876327515\n",
      "  time_total_s: 2612.3298547267914\n",
      "  timers:\n",
      "    learn_throughput: 123887.305\n",
      "    learn_time_ms: 516.469\n",
      "    load_throughput: 22022677.428\n",
      "    load_time_ms: 2.905\n",
      "    training_iteration_time_ms: 8980.637\n",
      "    update_time_ms: 4.008\n",
      "  timestamp: 1665851367\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 17595600\n",
      "  training_iteration: 275\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:29:32 (running for 00:44:06.80)<br>Memory usage on this node: 13.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   275</td><td style=\"text-align: right;\">         2612.33</td><td style=\"text-align: right;\">17595600</td><td style=\"text-align: right;\"> -190881</td><td style=\"text-align: right;\">             -187813</td><td style=\"text-align: right;\">             -196961</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 17659584\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 17659584\n",
      "    num_agent_steps_trained: 17659584\n",
      "    num_env_steps_sampled: 17659584\n",
      "    num_env_steps_trained: 17659584\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-29-36\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -187812.64897462627\n",
      "  episode_reward_mean: -190537.29105994254\n",
      "  episode_reward_min: -193409.4597643117\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 17652\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.107006549835205\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0007081144722178578\n",
      "          model: {}\n",
      "          policy_loss: 0.006911231204867363\n",
      "          total_loss: 10.006742477416992\n",
      "          vf_explained_var: -2.932926967957883e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 17659584\n",
      "    num_agent_steps_trained: 17659584\n",
      "    num_env_steps_sampled: 17659584\n",
      "    num_env_steps_trained: 17659584\n",
      "  iterations_since_restore: 276\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 17659584\n",
      "  num_agent_steps_trained: 17659584\n",
      "  num_env_steps_sampled: 17659584\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 17659584\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.0923076923077\n",
      "    ram_util_percent: 89.5923076923077\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09317705543334887\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46481461227882165\n",
      "    mean_inference_ms: 0.9610047938908195\n",
      "    mean_raw_obs_processing_ms: 0.13319532451808885\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -187812.64897462627\n",
      "    episode_reward_mean: -190537.29105994254\n",
      "    episode_reward_min: -193409.4597643117\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -190121.07472179426\n",
      "      - -191402.88244186723\n",
      "      - -187812.64897462627\n",
      "      - -189682.31792310116\n",
      "      - -192448.4708489157\n",
      "      - -189221.54929099124\n",
      "      - -191550.38806630307\n",
      "      - -190535.71825216184\n",
      "      - -191724.62655325147\n",
      "      - -190584.0710506467\n",
      "      - -193199.28436071237\n",
      "      - -191219.38542240654\n",
      "      - -190681.85548799398\n",
      "      - -191714.3577198026\n",
      "      - -189820.83000764807\n",
      "      - -190812.14864524012\n",
      "      - -190742.85744801245\n",
      "      - -189940.05982452765\n",
      "      - -191816.32813993492\n",
      "      - -193409.4597643117\n",
      "      - -191934.2563455603\n",
      "      - -189878.76912539682\n",
      "      - -190506.31737353397\n",
      "      - -190965.58361324095\n",
      "      - -191998.86230618617\n",
      "      - -189963.9384144662\n",
      "      - -189919.38400404775\n",
      "      - -191864.38981151802\n",
      "      - -189157.63842517565\n",
      "      - -192181.4116403158\n",
      "      - -189842.06189929487\n",
      "      - -190200.72199782782\n",
      "      - -191323.51047712832\n",
      "      - -190911.0480543966\n",
      "      - -191180.01941920098\n",
      "      - -192423.20800569613\n",
      "      - -189164.2647765702\n",
      "      - -189251.613031486\n",
      "      - -190801.5129342202\n",
      "      - -191318.490785847\n",
      "      - -191465.64601509925\n",
      "      - -189637.6571567541\n",
      "      - -192203.25046612474\n",
      "      - -191597.204840416\n",
      "      - -190389.8625011334\n",
      "      - -190908.59495359723\n",
      "      - -189176.64239382895\n",
      "      - -190983.3257598629\n",
      "      - -190008.0171957838\n",
      "      - -191259.7286099087\n",
      "      - -188792.55435743218\n",
      "      - -188959.2090897557\n",
      "      - -189706.22908312158\n",
      "      - -191907.29820349984\n",
      "      - -191081.75430575604\n",
      "      - -190518.50342257423\n",
      "      - -191071.02602131272\n",
      "      - -189968.22505396762\n",
      "      - -190293.85057697076\n",
      "      - -188819.0999949745\n",
      "      - -189547.31658479106\n",
      "      - -190825.60428382174\n",
      "      - -192708.7474290705\n",
      "      - -188625.2191376006\n",
      "      - -190167.77789405483\n",
      "      - -188885.01522987374\n",
      "      - -191548.39111972819\n",
      "      - -190942.29036479062\n",
      "      - -190067.39816384716\n",
      "      - -190599.41234401378\n",
      "      - -189922.2480051973\n",
      "      - -189532.37928097116\n",
      "      - -190040.37000681376\n",
      "      - -190873.18123895096\n",
      "      - -192504.02108116614\n",
      "      - -189516.657961983\n",
      "      - -191500.79093699006\n",
      "      - -188947.8640835852\n",
      "      - -191167.83975743418\n",
      "      - -191614.97550875778\n",
      "      - -189891.07080898725\n",
      "      - -190546.74001425426\n",
      "      - -189756.90703772288\n",
      "      - -190405.1439037953\n",
      "      - -189676.0131924023\n",
      "      - -189373.49973913413\n",
      "      - -189868.7185395645\n",
      "      - -191835.27677048478\n",
      "      - -192029.4162015201\n",
      "      - -192237.6449101926\n",
      "      - -188672.96161741795\n",
      "      - -188432.47296147683\n",
      "      - -190138.10430462437\n",
      "      - -191049.74781981987\n",
      "      - -190423.2599269629\n",
      "      - -188990.77360835386\n",
      "      - -190069.09716510476\n",
      "      - -188478.24020176576\n",
      "      - -189382.19300898557\n",
      "      - -190959.32646101044\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09317705543334887\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46481461227882165\n",
      "      mean_inference_ms: 0.9610047938908195\n",
      "      mean_raw_obs_processing_ms: 0.13319532451808885\n",
      "  time_since_restore: 2621.490813732147\n",
      "  time_this_iter_s: 9.160959005355835\n",
      "  time_total_s: 2621.490813732147\n",
      "  timers:\n",
      "    learn_throughput: 124008.988\n",
      "    learn_time_ms: 515.963\n",
      "    load_throughput: 22500720.807\n",
      "    load_time_ms: 2.844\n",
      "    training_iteration_time_ms: 9063.144\n",
      "    update_time_ms: 4.051\n",
      "  timestamp: 1665851376\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 17659584\n",
      "  training_iteration: 276\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:29:41 (running for 00:44:16.26)<br>Memory usage on this node: 13.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   276</td><td style=\"text-align: right;\">         2621.49</td><td style=\"text-align: right;\">17659584</td><td style=\"text-align: right;\"> -190537</td><td style=\"text-align: right;\">             -187813</td><td style=\"text-align: right;\">             -193409</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 17723568\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 17723568\n",
      "    num_agent_steps_trained: 17723568\n",
      "    num_env_steps_sampled: 17723568\n",
      "    num_env_steps_trained: 17723568\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-29-45\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -187550.70043550374\n",
      "  episode_reward_mean: -190221.14319918252\n",
      "  episode_reward_min: -193520.36699446032\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 17712\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.109989643096924\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0006558825843967497\n",
      "          model: {}\n",
      "          policy_loss: -0.0016094360034912825\n",
      "          total_loss: 9.998211860656738\n",
      "          vf_explained_var: -2.2706531765948057e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 17723568\n",
      "    num_agent_steps_trained: 17723568\n",
      "    num_env_steps_sampled: 17723568\n",
      "    num_env_steps_trained: 17723568\n",
      "  iterations_since_restore: 277\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 17723568\n",
      "  num_agent_steps_trained: 17723568\n",
      "  num_env_steps_sampled: 17723568\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 17723568\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.93846153846152\n",
      "    ram_util_percent: 89.45384615384616\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09315371672892375\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46477237920032566\n",
      "    mean_inference_ms: 0.9608975695186983\n",
      "    mean_raw_obs_processing_ms: 0.13319347204895338\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -187550.70043550374\n",
      "    episode_reward_mean: -190221.14319918252\n",
      "    episode_reward_min: -193520.36699446032\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -189547.31658479106\n",
      "      - -190825.60428382174\n",
      "      - -192708.7474290705\n",
      "      - -188625.2191376006\n",
      "      - -190167.77789405483\n",
      "      - -188885.01522987374\n",
      "      - -191548.39111972819\n",
      "      - -190942.29036479062\n",
      "      - -190067.39816384716\n",
      "      - -190599.41234401378\n",
      "      - -189922.2480051973\n",
      "      - -189532.37928097116\n",
      "      - -190040.37000681376\n",
      "      - -190873.18123895096\n",
      "      - -192504.02108116614\n",
      "      - -189516.657961983\n",
      "      - -191500.79093699006\n",
      "      - -188947.8640835852\n",
      "      - -191167.83975743418\n",
      "      - -191614.97550875778\n",
      "      - -189891.07080898725\n",
      "      - -190546.74001425426\n",
      "      - -189756.90703772288\n",
      "      - -190405.1439037953\n",
      "      - -189676.0131924023\n",
      "      - -189373.49973913413\n",
      "      - -189868.7185395645\n",
      "      - -191835.27677048478\n",
      "      - -192029.4162015201\n",
      "      - -192237.6449101926\n",
      "      - -188672.96161741795\n",
      "      - -188432.47296147683\n",
      "      - -190138.10430462437\n",
      "      - -191049.74781981987\n",
      "      - -190423.2599269629\n",
      "      - -188990.77360835386\n",
      "      - -190069.09716510476\n",
      "      - -188478.24020176576\n",
      "      - -189382.19300898557\n",
      "      - -190959.32646101044\n",
      "      - -192587.58633231517\n",
      "      - -190852.99168790376\n",
      "      - -191329.57061094083\n",
      "      - -188503.6706869715\n",
      "      - -192080.55599616028\n",
      "      - -191062.3635674082\n",
      "      - -190766.07311479727\n",
      "      - -188021.73634115027\n",
      "      - -189312.4125268655\n",
      "      - -188311.93098604426\n",
      "      - -188274.23993414524\n",
      "      - -190693.38969458948\n",
      "      - -190584.13507434446\n",
      "      - -190394.15892879225\n",
      "      - -190496.31780824135\n",
      "      - -192008.88542616914\n",
      "      - -192001.0696127668\n",
      "      - -189126.66789412615\n",
      "      - -188997.75555839803\n",
      "      - -189363.97893681287\n",
      "      - -191642.30842393465\n",
      "      - -193195.11676451308\n",
      "      - -189878.59525194627\n",
      "      - -191317.0076036598\n",
      "      - -189994.59338988035\n",
      "      - -189016.78127584225\n",
      "      - -188344.5704640956\n",
      "      - -189079.2526425936\n",
      "      - -190801.60415949943\n",
      "      - -189181.60157061476\n",
      "      - -191685.76163609856\n",
      "      - -188482.12246840497\n",
      "      - -189025.0453566188\n",
      "      - -190350.0224159755\n",
      "      - -192178.57113652164\n",
      "      - -188957.7011813163\n",
      "      - -188725.08802042744\n",
      "      - -190712.09751956144\n",
      "      - -189348.52441532922\n",
      "      - -187550.70043550374\n",
      "      - -188391.4679901468\n",
      "      - -189957.21609275285\n",
      "      - -191061.75606146222\n",
      "      - -192501.38499923528\n",
      "      - -191012.3457591354\n",
      "      - -190452.99554741292\n",
      "      - -190258.7679052611\n",
      "      - -187792.88166156426\n",
      "      - -189607.69013161652\n",
      "      - -188619.9658522738\n",
      "      - -189916.13269556704\n",
      "      - -190324.2471220824\n",
      "      - -189518.05278039825\n",
      "      - -191334.48956973202\n",
      "      - -189708.16477105173\n",
      "      - -190196.23073528107\n",
      "      - -193520.36699446032\n",
      "      - -190905.3146368725\n",
      "      - -191448.41943684325\n",
      "      - -189595.7637168023\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09315371672892375\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46477237920032566\n",
      "      mean_inference_ms: 0.9608975695186983\n",
      "      mean_raw_obs_processing_ms: 0.13319347204895338\n",
      "  time_since_restore: 2630.7405531406403\n",
      "  time_this_iter_s: 9.249739408493042\n",
      "  time_total_s: 2630.7405531406403\n",
      "  timers:\n",
      "    learn_throughput: 127263.834\n",
      "    learn_time_ms: 502.767\n",
      "    load_throughput: 22384734.808\n",
      "    load_time_ms: 2.858\n",
      "    training_iteration_time_ms: 9100.101\n",
      "    update_time_ms: 4.027\n",
      "  timestamp: 1665851385\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 17723568\n",
      "  training_iteration: 277\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:29:51 (running for 00:44:25.77)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   277</td><td style=\"text-align: right;\">         2630.74</td><td style=\"text-align: right;\">17723568</td><td style=\"text-align: right;\"> -190221</td><td style=\"text-align: right;\">             -187551</td><td style=\"text-align: right;\">             -193520</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 17787552\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 17787552\n",
      "    num_agent_steps_trained: 17787552\n",
      "    num_env_steps_sampled: 17787552\n",
      "    num_env_steps_trained: 17787552\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-29-55\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -187550.70043550374\n",
      "  episode_reward_mean: -190258.85466934115\n",
      "  episode_reward_min: -193854.63117036398\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 17784\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.10483717918396\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.001078386907465756\n",
      "          model: {}\n",
      "          policy_loss: 0.00463333772495389\n",
      "          total_loss: 10.004537582397461\n",
      "          vf_explained_var: 3.7844221090210795e-09\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 17787552\n",
      "    num_agent_steps_trained: 17787552\n",
      "    num_env_steps_sampled: 17787552\n",
      "    num_env_steps_trained: 17787552\n",
      "  iterations_since_restore: 278\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 17787552\n",
      "  num_agent_steps_trained: 17787552\n",
      "  num_env_steps_sampled: 17787552\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 17787552\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 84.82857142857144\n",
      "    ram_util_percent: 89.46428571428571\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09315229329202537\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46483728019627885\n",
      "    mean_inference_ms: 0.9608717390624065\n",
      "    mean_raw_obs_processing_ms: 0.1330419491637948\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -187550.70043550374\n",
      "    episode_reward_mean: -190258.85466934115\n",
      "    episode_reward_min: -193854.63117036398\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -189025.0453566188\n",
      "      - -190350.0224159755\n",
      "      - -192178.57113652164\n",
      "      - -188957.7011813163\n",
      "      - -188725.08802042744\n",
      "      - -190712.09751956144\n",
      "      - -189348.52441532922\n",
      "      - -187550.70043550374\n",
      "      - -188391.4679901468\n",
      "      - -189957.21609275285\n",
      "      - -191061.75606146222\n",
      "      - -192501.38499923528\n",
      "      - -191012.3457591354\n",
      "      - -190452.99554741292\n",
      "      - -190258.7679052611\n",
      "      - -187792.88166156426\n",
      "      - -189607.69013161652\n",
      "      - -188619.9658522738\n",
      "      - -189916.13269556704\n",
      "      - -190324.2471220824\n",
      "      - -189518.05278039825\n",
      "      - -191334.48956973202\n",
      "      - -189708.16477105173\n",
      "      - -190196.23073528107\n",
      "      - -193520.36699446032\n",
      "      - -190905.3146368725\n",
      "      - -191448.41943684325\n",
      "      - -189595.7637168023\n",
      "      - -190724.304033302\n",
      "      - -192706.40431723962\n",
      "      - -188881.71947321526\n",
      "      - -189326.70300169234\n",
      "      - -189846.73575808326\n",
      "      - -188454.38497266633\n",
      "      - -189200.25399496767\n",
      "      - -190842.13125071014\n",
      "      - -188975.80895998908\n",
      "      - -189642.92397008536\n",
      "      - -188488.02452679147\n",
      "      - -189646.45072339638\n",
      "      - -191560.68012552892\n",
      "      - -189174.88919766175\n",
      "      - -190619.5454659631\n",
      "      - -189794.83985209034\n",
      "      - -188823.63481698633\n",
      "      - -190939.0860571289\n",
      "      - -189771.17349575585\n",
      "      - -192101.7893413043\n",
      "      - -191763.69014166357\n",
      "      - -191546.83846203785\n",
      "      - -191937.7101770664\n",
      "      - -190864.19398197555\n",
      "      - -192062.0017549814\n",
      "      - -190006.8951482874\n",
      "      - -188565.33049710144\n",
      "      - -193221.42525097946\n",
      "      - -189062.60140119307\n",
      "      - -190711.31319583644\n",
      "      - -190749.6329244501\n",
      "      - -188262.23983886815\n",
      "      - -189276.5515994072\n",
      "      - -191006.39090207947\n",
      "      - -190321.4281855335\n",
      "      - -188980.3364868223\n",
      "      - -189778.81817263542\n",
      "      - -190150.90626366079\n",
      "      - -190977.37628730826\n",
      "      - -190872.46502903767\n",
      "      - -190207.31951028164\n",
      "      - -193854.63117036398\n",
      "      - -190186.9901988051\n",
      "      - -189199.2499568296\n",
      "      - -191486.54618710623\n",
      "      - -191517.32254922602\n",
      "      - -189523.7104520717\n",
      "      - -190931.60394717535\n",
      "      - -191594.3378807909\n",
      "      - -190895.48687484942\n",
      "      - -189652.2338151988\n",
      "      - -191441.46779879797\n",
      "      - -188088.71315328078\n",
      "      - -189779.99581985397\n",
      "      - -190524.72569532157\n",
      "      - -190638.54911861612\n",
      "      - -192849.4567927946\n",
      "      - -191197.36546140737\n",
      "      - -189105.19302849847\n",
      "      - -190249.6675760905\n",
      "      - -189153.80163816232\n",
      "      - -191493.6774615294\n",
      "      - -189503.7094155688\n",
      "      - -190353.11298524908\n",
      "      - -189615.5482693779\n",
      "      - -188954.74238840732\n",
      "      - -189192.6047847473\n",
      "      - -190113.44843276136\n",
      "      - -191573.07191530667\n",
      "      - -190461.39466528085\n",
      "      - -189616.5223517057\n",
      "      - -190318.23166197172\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09315229329202537\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46483728019627885\n",
      "      mean_inference_ms: 0.9608717390624065\n",
      "      mean_raw_obs_processing_ms: 0.1330419491637948\n",
      "  time_since_restore: 2640.499784231186\n",
      "  time_this_iter_s: 9.759231090545654\n",
      "  time_total_s: 2640.499784231186\n",
      "  timers:\n",
      "    learn_throughput: 128199.8\n",
      "    learn_time_ms: 499.096\n",
      "    load_throughput: 22321617.854\n",
      "    load_time_ms: 2.866\n",
      "    training_iteration_time_ms: 9175.497\n",
      "    update_time_ms: 3.911\n",
      "  timestamp: 1665851395\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 17787552\n",
      "  training_iteration: 278\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:30:00 (running for 00:44:35.06)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   278</td><td style=\"text-align: right;\">          2640.5</td><td style=\"text-align: right;\">17787552</td><td style=\"text-align: right;\"> -190259</td><td style=\"text-align: right;\">             -187551</td><td style=\"text-align: right;\">             -193855</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 17851536\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 17851536\n",
      "    num_agent_steps_trained: 17851536\n",
      "    num_env_steps_sampled: 17851536\n",
      "    num_env_steps_trained: 17851536\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-30-05\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -187946.0234414324\n",
      "  episode_reward_mean: -190420.4017303911\n",
      "  episode_reward_min: -198084.70113748458\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 17844\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.103043794631958\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0009228751878254116\n",
      "          model: {}\n",
      "          policy_loss: 0.006628234405070543\n",
      "          total_loss: 10.006502151489258\n",
      "          vf_explained_var: -3.216758770463457e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 17851536\n",
      "    num_agent_steps_trained: 17851536\n",
      "    num_env_steps_sampled: 17851536\n",
      "    num_env_steps_trained: 17851536\n",
      "  iterations_since_restore: 279\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 17851536\n",
      "  num_agent_steps_trained: 17851536\n",
      "  num_env_steps_sampled: 17851536\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 17851536\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.94615384615385\n",
      "    ram_util_percent: 89.46923076923078\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09317782333014513\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46485074356811124\n",
      "    mean_inference_ms: 0.9610369991672598\n",
      "    mean_raw_obs_processing_ms: 0.13320490977063532\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -187946.0234414324\n",
      "    episode_reward_mean: -190420.4017303911\n",
      "    episode_reward_min: -198084.70113748458\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -189276.5515994072\n",
      "      - -191006.39090207947\n",
      "      - -190321.4281855335\n",
      "      - -188980.3364868223\n",
      "      - -189778.81817263542\n",
      "      - -190150.90626366079\n",
      "      - -190977.37628730826\n",
      "      - -190872.46502903767\n",
      "      - -190207.31951028164\n",
      "      - -193854.63117036398\n",
      "      - -190186.9901988051\n",
      "      - -189199.2499568296\n",
      "      - -191486.54618710623\n",
      "      - -191517.32254922602\n",
      "      - -189523.7104520717\n",
      "      - -190931.60394717535\n",
      "      - -191594.3378807909\n",
      "      - -190895.48687484942\n",
      "      - -189652.2338151988\n",
      "      - -191441.46779879797\n",
      "      - -188088.71315328078\n",
      "      - -189779.99581985397\n",
      "      - -190524.72569532157\n",
      "      - -190638.54911861612\n",
      "      - -192849.4567927946\n",
      "      - -191197.36546140737\n",
      "      - -189105.19302849847\n",
      "      - -190249.6675760905\n",
      "      - -189153.80163816232\n",
      "      - -191493.6774615294\n",
      "      - -189503.7094155688\n",
      "      - -190353.11298524908\n",
      "      - -189615.5482693779\n",
      "      - -188954.74238840732\n",
      "      - -189192.6047847473\n",
      "      - -190113.44843276136\n",
      "      - -191573.07191530667\n",
      "      - -190461.39466528085\n",
      "      - -189616.5223517057\n",
      "      - -190318.23166197172\n",
      "      - -190042.5464947461\n",
      "      - -189779.28331593532\n",
      "      - -190301.34611652247\n",
      "      - -191001.8426183955\n",
      "      - -190245.71110124578\n",
      "      - -191048.09571808556\n",
      "      - -190247.28075419695\n",
      "      - -190437.54161342166\n",
      "      - -189080.08182947076\n",
      "      - -189460.20158441737\n",
      "      - -189644.0628230903\n",
      "      - -192193.1736049767\n",
      "      - -188633.51407191742\n",
      "      - -191422.75522212198\n",
      "      - -191463.78112913956\n",
      "      - -188750.7565019345\n",
      "      - -189695.51725517825\n",
      "      - -192243.2893162468\n",
      "      - -190836.76211378464\n",
      "      - -190286.1836475876\n",
      "      - -190882.64557275546\n",
      "      - -190824.12468069282\n",
      "      - -189877.97009063975\n",
      "      - -187946.0234414324\n",
      "      - -190236.9633061963\n",
      "      - -188423.65451814668\n",
      "      - -189537.25486933618\n",
      "      - -194750.69137188958\n",
      "      - -190092.57037896948\n",
      "      - -190814.618876081\n",
      "      - -191645.35592943672\n",
      "      - -190571.9955600615\n",
      "      - -190932.10880674078\n",
      "      - -189870.98690669957\n",
      "      - -189967.51646057612\n",
      "      - -190525.97272454033\n",
      "      - -191254.96607941415\n",
      "      - -190546.19677432068\n",
      "      - -191990.13370516078\n",
      "      - -190048.0107758162\n",
      "      - -189699.23224304995\n",
      "      - -189836.67237593813\n",
      "      - -189430.460513507\n",
      "      - -191356.03652378084\n",
      "      - -191972.5133632071\n",
      "      - -191126.32379962728\n",
      "      - -189229.65140622426\n",
      "      - -189247.55422246552\n",
      "      - -198084.70113748458\n",
      "      - -190345.6626771277\n",
      "      - -189969.63008708804\n",
      "      - -189646.97661697667\n",
      "      - -190650.8269331808\n",
      "      - -188949.4183444474\n",
      "      - -190333.48146556228\n",
      "      - -188824.65327786005\n",
      "      - -191447.50472341242\n",
      "      - -190136.5058613055\n",
      "      - -188961.6215925879\n",
      "      - -190598.55232904508\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09317782333014513\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46485074356811124\n",
      "      mean_inference_ms: 0.9610369991672598\n",
      "      mean_raw_obs_processing_ms: 0.13320490977063532\n",
      "  time_since_restore: 2649.9571607112885\n",
      "  time_this_iter_s: 9.457376480102539\n",
      "  time_total_s: 2649.9571607112885\n",
      "  timers:\n",
      "    learn_throughput: 129305.453\n",
      "    learn_time_ms: 494.828\n",
      "    load_throughput: 22287693.577\n",
      "    load_time_ms: 2.871\n",
      "    training_iteration_time_ms: 9229.75\n",
      "    update_time_ms: 3.97\n",
      "  timestamp: 1665851405\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 17851536\n",
      "  training_iteration: 279\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:30:10 (running for 00:44:45.10)<br>Memory usage on this node: 13.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   279</td><td style=\"text-align: right;\">         2649.96</td><td style=\"text-align: right;\">17851536</td><td style=\"text-align: right;\"> -190420</td><td style=\"text-align: right;\">             -187946</td><td style=\"text-align: right;\">             -198085</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 17915520\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 17915520\n",
      "    num_agent_steps_trained: 17915520\n",
      "    num_env_steps_sampled: 17915520\n",
      "    num_env_steps_trained: 17915520\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-30-15\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -186216.06625641987\n",
      "  episode_reward_mean: -190458.6383742319\n",
      "  episode_reward_min: -198084.70113748458\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 17904\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1049790382385254\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0010849705431610346\n",
      "          model: {}\n",
      "          policy_loss: -0.0014879693044349551\n",
      "          total_loss: 9.998418807983398\n",
      "          vf_explained_var: -3.689811478579941e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 17915520\n",
      "    num_agent_steps_trained: 17915520\n",
      "    num_env_steps_sampled: 17915520\n",
      "    num_env_steps_trained: 17915520\n",
      "  iterations_since_restore: 280\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 17915520\n",
      "  num_agent_steps_trained: 17915520\n",
      "  num_env_steps_sampled: 17915520\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 17915520\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.31428571428572\n",
      "    ram_util_percent: 89.54999999999998\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09318040865041921\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.464834631506269\n",
      "    mean_inference_ms: 0.961159845108577\n",
      "    mean_raw_obs_processing_ms: 0.13322019624181525\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -186216.06625641987\n",
      "    episode_reward_mean: -190458.6383742319\n",
      "    episode_reward_min: -198084.70113748458\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -190882.64557275546\n",
      "      - -190824.12468069282\n",
      "      - -189877.97009063975\n",
      "      - -187946.0234414324\n",
      "      - -190236.9633061963\n",
      "      - -188423.65451814668\n",
      "      - -189537.25486933618\n",
      "      - -194750.69137188958\n",
      "      - -190092.57037896948\n",
      "      - -190814.618876081\n",
      "      - -191645.35592943672\n",
      "      - -190571.9955600615\n",
      "      - -190932.10880674078\n",
      "      - -189870.98690669957\n",
      "      - -189967.51646057612\n",
      "      - -190525.97272454033\n",
      "      - -191254.96607941415\n",
      "      - -190546.19677432068\n",
      "      - -191990.13370516078\n",
      "      - -190048.0107758162\n",
      "      - -189699.23224304995\n",
      "      - -189836.67237593813\n",
      "      - -189430.460513507\n",
      "      - -191356.03652378084\n",
      "      - -191972.5133632071\n",
      "      - -191126.32379962728\n",
      "      - -189229.65140622426\n",
      "      - -189247.55422246552\n",
      "      - -198084.70113748458\n",
      "      - -190345.6626771277\n",
      "      - -189969.63008708804\n",
      "      - -189646.97661697667\n",
      "      - -190650.8269331808\n",
      "      - -188949.4183444474\n",
      "      - -190333.48146556228\n",
      "      - -188824.65327786005\n",
      "      - -191447.50472341242\n",
      "      - -190136.5058613055\n",
      "      - -188961.6215925879\n",
      "      - -190598.55232904508\n",
      "      - -190011.99129891867\n",
      "      - -191151.70944741118\n",
      "      - -191177.29079245462\n",
      "      - -189934.51709738435\n",
      "      - -189430.26684403673\n",
      "      - -189462.29342661944\n",
      "      - -193330.27983977838\n",
      "      - -193020.74285979892\n",
      "      - -191440.89854930178\n",
      "      - -190655.25352766417\n",
      "      - -189711.9930215179\n",
      "      - -188852.166798053\n",
      "      - -190852.00869699288\n",
      "      - -190101.0517897221\n",
      "      - -191190.58937611748\n",
      "      - -189702.60894137793\n",
      "      - -191030.37963060863\n",
      "      - -190640.50823248771\n",
      "      - -189855.10975417233\n",
      "      - -189629.65165821154\n",
      "      - -190714.42486393076\n",
      "      - -190630.73352498285\n",
      "      - -189947.2837501576\n",
      "      - -190713.27404515195\n",
      "      - -190489.82199419226\n",
      "      - -191289.7877222283\n",
      "      - -190569.1850486452\n",
      "      - -190559.8493790622\n",
      "      - -191008.51514863252\n",
      "      - -188003.6834320599\n",
      "      - -189289.4953256589\n",
      "      - -191870.59167928324\n",
      "      - -187925.9052554404\n",
      "      - -190817.56831718553\n",
      "      - -187633.56530202978\n",
      "      - -192118.5636482705\n",
      "      - -190420.2661471698\n",
      "      - -186216.06625641987\n",
      "      - -189574.7328267761\n",
      "      - -191959.86567621477\n",
      "      - -189605.51321885077\n",
      "      - -190809.20881788223\n",
      "      - -189570.82183584847\n",
      "      - -189784.40402435904\n",
      "      - -192359.99595248688\n",
      "      - -191365.26985279802\n",
      "      - -189853.5296299585\n",
      "      - -191223.7948898211\n",
      "      - -190353.27113056692\n",
      "      - -189346.7879821892\n",
      "      - -191028.78302107824\n",
      "      - -188773.11705817023\n",
      "      - -191529.46004651266\n",
      "      - -191769.7510877115\n",
      "      - -188910.96752385024\n",
      "      - -192256.91735310553\n",
      "      - -190703.1864202182\n",
      "      - -191274.15841372515\n",
      "      - -190411.1693613518\n",
      "      - -191411.49855379591\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09318040865041921\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.464834631506269\n",
      "      mean_inference_ms: 0.961159845108577\n",
      "      mean_raw_obs_processing_ms: 0.13322019624181525\n",
      "  time_since_restore: 2659.8497262001038\n",
      "  time_this_iter_s: 9.892565488815308\n",
      "  time_total_s: 2659.8497262001038\n",
      "  timers:\n",
      "    learn_throughput: 129436.719\n",
      "    learn_time_ms: 494.326\n",
      "    load_throughput: 22242989.991\n",
      "    load_time_ms: 2.877\n",
      "    training_iteration_time_ms: 9347.671\n",
      "    update_time_ms: 4.092\n",
      "  timestamp: 1665851415\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 17915520\n",
      "  training_iteration: 280\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:30:20 (running for 00:44:54.75)<br>Memory usage on this node: 13.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   280</td><td style=\"text-align: right;\">         2659.85</td><td style=\"text-align: right;\">17915520</td><td style=\"text-align: right;\"> -190459</td><td style=\"text-align: right;\">             -186216</td><td style=\"text-align: right;\">             -198085</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 17979504\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 17979504\n",
      "    num_agent_steps_trained: 17979504\n",
      "    num_env_steps_sampled: 17979504\n",
      "    num_env_steps_trained: 17979504\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-30-24\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -186216.06625641987\n",
      "  episode_reward_mean: -190443.3978171198\n",
      "  episode_reward_min: -195000.95366231626\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 17976\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.109107255935669\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0008163059246726334\n",
      "          model: {}\n",
      "          policy_loss: 0.004658929537981749\n",
      "          total_loss: 10.004510879516602\n",
      "          vf_explained_var: 5.676632941487014e-09\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 17979504\n",
      "    num_agent_steps_trained: 17979504\n",
      "    num_env_steps_sampled: 17979504\n",
      "    num_env_steps_trained: 17979504\n",
      "  iterations_since_restore: 281\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 17979504\n",
      "  num_agent_steps_trained: 17979504\n",
      "  num_env_steps_sampled: 17979504\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 17979504\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 85.39999999999999\n",
      "    ram_util_percent: 89.62307692307694\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09319890127262535\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4648737891537855\n",
      "    mean_inference_ms: 0.9611824877156017\n",
      "    mean_raw_obs_processing_ms: 0.13307150718479643\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -186216.06625641987\n",
      "    episode_reward_mean: -190443.3978171198\n",
      "    episode_reward_min: -195000.95366231626\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -187925.9052554404\n",
      "      - -190817.56831718553\n",
      "      - -187633.56530202978\n",
      "      - -192118.5636482705\n",
      "      - -190420.2661471698\n",
      "      - -186216.06625641987\n",
      "      - -189574.7328267761\n",
      "      - -191959.86567621477\n",
      "      - -189605.51321885077\n",
      "      - -190809.20881788223\n",
      "      - -189570.82183584847\n",
      "      - -189784.40402435904\n",
      "      - -192359.99595248688\n",
      "      - -191365.26985279802\n",
      "      - -189853.5296299585\n",
      "      - -191223.7948898211\n",
      "      - -190353.27113056692\n",
      "      - -189346.7879821892\n",
      "      - -191028.78302107824\n",
      "      - -188773.11705817023\n",
      "      - -191529.46004651266\n",
      "      - -191769.7510877115\n",
      "      - -188910.96752385024\n",
      "      - -192256.91735310553\n",
      "      - -190703.1864202182\n",
      "      - -191274.15841372515\n",
      "      - -190411.1693613518\n",
      "      - -191411.49855379591\n",
      "      - -192064.06063586732\n",
      "      - -190162.33330112725\n",
      "      - -188787.31257891151\n",
      "      - -190850.6516173766\n",
      "      - -189242.7994523995\n",
      "      - -190359.85664118285\n",
      "      - -190972.6883874017\n",
      "      - -193088.73510391198\n",
      "      - -190335.80891223165\n",
      "      - -189198.8083183909\n",
      "      - -189312.36557748402\n",
      "      - -190913.6784970714\n",
      "      - -190792.82969859024\n",
      "      - -189412.2946636566\n",
      "      - -189128.3120314548\n",
      "      - -188787.53088182886\n",
      "      - -190216.3170440088\n",
      "      - -189612.2753575478\n",
      "      - -189563.3239863464\n",
      "      - -189876.07981170126\n",
      "      - -190608.23367836722\n",
      "      - -193455.8811644576\n",
      "      - -189878.3048307418\n",
      "      - -189550.81068741085\n",
      "      - -191995.92570999582\n",
      "      - -189084.04345205706\n",
      "      - -193162.85537085758\n",
      "      - -189166.09877869175\n",
      "      - -190035.3006342264\n",
      "      - -189653.33910445604\n",
      "      - -191670.22782329054\n",
      "      - -190474.38057475252\n",
      "      - -191314.41545088522\n",
      "      - -189838.6832059759\n",
      "      - -188074.07874139625\n",
      "      - -188204.2908738115\n",
      "      - -191032.4870988261\n",
      "      - -190198.15912014965\n",
      "      - -190191.87154374653\n",
      "      - -190671.48244215845\n",
      "      - -195000.95366231626\n",
      "      - -190079.2641574855\n",
      "      - -190181.2627950784\n",
      "      - -188795.5858202273\n",
      "      - -193308.01339937042\n",
      "      - -190489.33623201895\n",
      "      - -191600.3901245026\n",
      "      - -193549.95870841393\n",
      "      - -188569.64142397436\n",
      "      - -188502.08159853582\n",
      "      - -193083.58232308197\n",
      "      - -190240.82980383982\n",
      "      - -191535.21022150887\n",
      "      - -192257.2152359169\n",
      "      - -191308.66293763818\n",
      "      - -192447.53446360637\n",
      "      - -189550.91519465556\n",
      "      - -189683.03599605712\n",
      "      - -188574.1160922067\n",
      "      - -189331.97296612483\n",
      "      - -189336.82746819928\n",
      "      - -191372.12513778196\n",
      "      - -189767.94453083558\n",
      "      - -191606.1875969311\n",
      "      - -190325.0599920908\n",
      "      - -190784.75733407945\n",
      "      - -189189.95027391746\n",
      "      - -187791.5856851314\n",
      "      - -191074.41828968425\n",
      "      - -189930.8105189245\n",
      "      - -193565.16483482486\n",
      "      - -191558.31450449015\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09319890127262535\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4648737891537855\n",
      "      mean_inference_ms: 0.9611824877156017\n",
      "      mean_raw_obs_processing_ms: 0.13307150718479643\n",
      "  time_since_restore: 2669.4989850521088\n",
      "  time_this_iter_s: 9.649258852005005\n",
      "  time_total_s: 2669.4989850521088\n",
      "  timers:\n",
      "    learn_throughput: 129061.311\n",
      "    learn_time_ms: 495.764\n",
      "    load_throughput: 22185619.571\n",
      "    load_time_ms: 2.884\n",
      "    training_iteration_time_ms: 9382.767\n",
      "    update_time_ms: 4.196\n",
      "  timestamp: 1665851424\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 17979504\n",
      "  training_iteration: 281\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:30:29 (running for 00:45:04.17)<br>Memory usage on this node: 13.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   281</td><td style=\"text-align: right;\">          2669.5</td><td style=\"text-align: right;\">17979504</td><td style=\"text-align: right;\"> -190443</td><td style=\"text-align: right;\">             -186216</td><td style=\"text-align: right;\">             -195001</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 18043488\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 18043488\n",
      "    num_agent_steps_trained: 18043488\n",
      "    num_env_steps_sampled: 18043488\n",
      "    num_env_steps_trained: 18043488\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-30-34\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -187791.5856851314\n",
      "  episode_reward_mean: -191044.81886799642\n",
      "  episode_reward_min: -195000.95366231626\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 18036\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.109548568725586\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0010908659314736724\n",
      "          model: {}\n",
      "          policy_loss: 0.006644752807915211\n",
      "          total_loss: 10.006551742553711\n",
      "          vf_explained_var: -2.554484801464696e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 18043488\n",
      "    num_agent_steps_trained: 18043488\n",
      "    num_env_steps_sampled: 18043488\n",
      "    num_env_steps_trained: 18043488\n",
      "  iterations_since_restore: 282\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 18043488\n",
      "  num_agent_steps_trained: 18043488\n",
      "  num_env_steps_sampled: 18043488\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 18043488\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 83.3142857142857\n",
      "    ram_util_percent: 89.73571428571428\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09323009488343274\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46490513738863015\n",
      "    mean_inference_ms: 0.961388873335261\n",
      "    mean_raw_obs_processing_ms: 0.13325469712019478\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -187791.5856851314\n",
      "    episode_reward_mean: -191044.81886799642\n",
      "    episode_reward_min: -195000.95366231626\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -191314.41545088522\n",
      "      - -189838.6832059759\n",
      "      - -188074.07874139625\n",
      "      - -188204.2908738115\n",
      "      - -191032.4870988261\n",
      "      - -190198.15912014965\n",
      "      - -190191.87154374653\n",
      "      - -190671.48244215845\n",
      "      - -195000.95366231626\n",
      "      - -190079.2641574855\n",
      "      - -190181.2627950784\n",
      "      - -188795.5858202273\n",
      "      - -193308.01339937042\n",
      "      - -190489.33623201895\n",
      "      - -191600.3901245026\n",
      "      - -193549.95870841393\n",
      "      - -188569.64142397436\n",
      "      - -188502.08159853582\n",
      "      - -193083.58232308197\n",
      "      - -190240.82980383982\n",
      "      - -191535.21022150887\n",
      "      - -192257.2152359169\n",
      "      - -191308.66293763818\n",
      "      - -192447.53446360637\n",
      "      - -189550.91519465556\n",
      "      - -189683.03599605712\n",
      "      - -188574.1160922067\n",
      "      - -189331.97296612483\n",
      "      - -189336.82746819928\n",
      "      - -191372.12513778196\n",
      "      - -189767.94453083558\n",
      "      - -191606.1875969311\n",
      "      - -190325.0599920908\n",
      "      - -190784.75733407945\n",
      "      - -189189.95027391746\n",
      "      - -187791.5856851314\n",
      "      - -191074.41828968425\n",
      "      - -189930.8105189245\n",
      "      - -193565.16483482486\n",
      "      - -191558.31450449015\n",
      "      - -192580.12911946973\n",
      "      - -190634.55222672736\n",
      "      - -190252.80624426654\n",
      "      - -188886.66996895935\n",
      "      - -191104.31471266327\n",
      "      - -192021.36370547983\n",
      "      - -191420.1943916189\n",
      "      - -192388.92118233707\n",
      "      - -189550.26018919144\n",
      "      - -193199.75071387022\n",
      "      - -191560.81728698898\n",
      "      - -189306.71189890595\n",
      "      - -192016.39320422136\n",
      "      - -191626.2872680414\n",
      "      - -193150.90161760524\n",
      "      - -191323.74317086194\n",
      "      - -193966.19144493245\n",
      "      - -192768.37190101668\n",
      "      - -192193.4831249243\n",
      "      - -192625.63900966456\n",
      "      - -189034.62799925345\n",
      "      - -190293.0295001787\n",
      "      - -190201.3792606381\n",
      "      - -190883.03894286018\n",
      "      - -189068.8649351614\n",
      "      - -193679.0635173723\n",
      "      - -193207.58055138343\n",
      "      - -189880.14552611063\n",
      "      - -189502.31261774807\n",
      "      - -188981.72472237385\n",
      "      - -193715.6338056521\n",
      "      - -189766.8410159579\n",
      "      - -192540.75881482742\n",
      "      - -189495.9104883369\n",
      "      - -190982.59341614516\n",
      "      - -191468.0086389901\n",
      "      - -194016.1030075909\n",
      "      - -189663.0970786669\n",
      "      - -192828.00389193613\n",
      "      - -190854.1148157029\n",
      "      - -190030.81256120122\n",
      "      - -191002.21708650456\n",
      "      - -192836.47564691212\n",
      "      - -190117.71495499456\n",
      "      - -191270.9481053785\n",
      "      - -189732.0603758207\n",
      "      - -192994.51939160592\n",
      "      - -192688.08121773115\n",
      "      - -190835.77435417625\n",
      "      - -193437.15673558912\n",
      "      - -190726.61990111257\n",
      "      - -190186.98884136192\n",
      "      - -191206.95859030224\n",
      "      - -193533.55503973938\n",
      "      - -193074.21372247624\n",
      "      - -190643.8691178501\n",
      "      - -189885.82759390245\n",
      "      - -191874.18492816048\n",
      "      - -191612.85866514302\n",
      "      - -190232.53724064693\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09323009488343274\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46490513738863015\n",
      "      mean_inference_ms: 0.961388873335261\n",
      "      mean_raw_obs_processing_ms: 0.13325469712019478\n",
      "  time_since_restore: 2679.4528291225433\n",
      "  time_this_iter_s: 9.95384407043457\n",
      "  time_total_s: 2679.4528291225433\n",
      "  timers:\n",
      "    learn_throughput: 125820.489\n",
      "    learn_time_ms: 508.534\n",
      "    load_throughput: 22049456.679\n",
      "    load_time_ms: 2.902\n",
      "    training_iteration_time_ms: 9427.024\n",
      "    update_time_ms: 4.007\n",
      "  timestamp: 1665851434\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 18043488\n",
      "  training_iteration: 282\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:30:35 (running for 00:45:09.44)<br>Memory usage on this node: 13.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   282</td><td style=\"text-align: right;\">         2679.45</td><td style=\"text-align: right;\">18043488</td><td style=\"text-align: right;\"> -191045</td><td style=\"text-align: right;\">             -187792</td><td style=\"text-align: right;\">             -195001</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:30:40 (running for 00:45:14.44)<br>Memory usage on this node: 13.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   282</td><td style=\"text-align: right;\">         2679.45</td><td style=\"text-align: right;\">18043488</td><td style=\"text-align: right;\"> -191045</td><td style=\"text-align: right;\">             -187792</td><td style=\"text-align: right;\">             -195001</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 18107472\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 18107472\n",
      "    num_agent_steps_trained: 18107472\n",
      "    num_env_steps_sampled: 18107472\n",
      "    num_env_steps_trained: 18107472\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-30-44\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -187238.3418040868\n",
      "  episode_reward_mean: -191204.14101381126\n",
      "  episode_reward_min: -195155.0845863614\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 18096\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.107776403427124\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.000678788055665791\n",
      "          model: {}\n",
      "          policy_loss: -0.0009947724174708128\n",
      "          total_loss: 9.99882984161377\n",
      "          vf_explained_var: -4.352085269943018e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 18107472\n",
      "    num_agent_steps_trained: 18107472\n",
      "    num_env_steps_sampled: 18107472\n",
      "    num_env_steps_trained: 18107472\n",
      "  iterations_since_restore: 283\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 18107472\n",
      "  num_agent_steps_trained: 18107472\n",
      "  num_env_steps_sampled: 18107472\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 18107472\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 84.49999999999999\n",
      "    ram_util_percent: 89.69285714285715\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09322614830393061\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4649266340757332\n",
      "    mean_inference_ms: 0.9615930981573786\n",
      "    mean_raw_obs_processing_ms: 0.1332817425747855\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -187238.3418040868\n",
      "    episode_reward_mean: -191204.14101381126\n",
      "    episode_reward_min: -195155.0845863614\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -189034.62799925345\n",
      "      - -190293.0295001787\n",
      "      - -190201.3792606381\n",
      "      - -190883.03894286018\n",
      "      - -189068.8649351614\n",
      "      - -193679.0635173723\n",
      "      - -193207.58055138343\n",
      "      - -189880.14552611063\n",
      "      - -189502.31261774807\n",
      "      - -188981.72472237385\n",
      "      - -193715.6338056521\n",
      "      - -189766.8410159579\n",
      "      - -192540.75881482742\n",
      "      - -189495.9104883369\n",
      "      - -190982.59341614516\n",
      "      - -191468.0086389901\n",
      "      - -194016.1030075909\n",
      "      - -189663.0970786669\n",
      "      - -192828.00389193613\n",
      "      - -190854.1148157029\n",
      "      - -190030.81256120122\n",
      "      - -191002.21708650456\n",
      "      - -192836.47564691212\n",
      "      - -190117.71495499456\n",
      "      - -191270.9481053785\n",
      "      - -189732.0603758207\n",
      "      - -192994.51939160592\n",
      "      - -192688.08121773115\n",
      "      - -190835.77435417625\n",
      "      - -193437.15673558912\n",
      "      - -190726.61990111257\n",
      "      - -190186.98884136192\n",
      "      - -191206.95859030224\n",
      "      - -193533.55503973938\n",
      "      - -193074.21372247624\n",
      "      - -190643.8691178501\n",
      "      - -189885.82759390245\n",
      "      - -191874.18492816048\n",
      "      - -191612.85866514302\n",
      "      - -190232.53724064693\n",
      "      - -193400.51532567176\n",
      "      - -189804.43806474216\n",
      "      - -192844.15686692743\n",
      "      - -190133.09728719026\n",
      "      - -191208.09531563273\n",
      "      - -189999.74804694578\n",
      "      - -190072.161479225\n",
      "      - -193091.46814417318\n",
      "      - -192188.91754892352\n",
      "      - -191053.91963297446\n",
      "      - -190896.5721055365\n",
      "      - -192477.58124659833\n",
      "      - -188797.82230692363\n",
      "      - -193782.50267909284\n",
      "      - -191723.66892204332\n",
      "      - -188785.51701679354\n",
      "      - -191509.87133122046\n",
      "      - -191747.71341357921\n",
      "      - -190290.27557306061\n",
      "      - -192318.99126046197\n",
      "      - -190398.74715627794\n",
      "      - -190767.22369902194\n",
      "      - -190641.9259136809\n",
      "      - -190846.12558582355\n",
      "      - -191022.88036349806\n",
      "      - -192533.24474737115\n",
      "      - -189693.6082802183\n",
      "      - -190856.2806237401\n",
      "      - -190687.84013007424\n",
      "      - -193149.19107327904\n",
      "      - -194251.72913018902\n",
      "      - -189964.10605565488\n",
      "      - -191024.73158847194\n",
      "      - -191618.58912544826\n",
      "      - -189615.61411323803\n",
      "      - -193633.55772491387\n",
      "      - -191884.96751653668\n",
      "      - -187238.3418040868\n",
      "      - -189202.15162382027\n",
      "      - -191370.3277473069\n",
      "      - -191164.93052068635\n",
      "      - -191492.36652537418\n",
      "      - -190190.2000960723\n",
      "      - -194880.6267412834\n",
      "      - -193370.9242462862\n",
      "      - -190895.54828083527\n",
      "      - -190164.0801806204\n",
      "      - -192754.50247187936\n",
      "      - -189123.0325828033\n",
      "      - -189560.34398764002\n",
      "      - -189446.36011035804\n",
      "      - -190661.55897560238\n",
      "      - -191002.1713270639\n",
      "      - -190500.16586799736\n",
      "      - -190598.39652101093\n",
      "      - -195155.0845863614\n",
      "      - -194600.1864756904\n",
      "      - -188752.00075981856\n",
      "      - -191342.6293571013\n",
      "      - -190244.56757877755\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09322614830393061\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4649266340757332\n",
      "      mean_inference_ms: 0.9615930981573786\n",
      "      mean_raw_obs_processing_ms: 0.1332817425747855\n",
      "  time_since_restore: 2689.414471387863\n",
      "  time_this_iter_s: 9.961642265319824\n",
      "  time_total_s: 2689.414471387863\n",
      "  timers:\n",
      "    learn_throughput: 125351.341\n",
      "    learn_time_ms: 510.437\n",
      "    load_throughput: 22071943.542\n",
      "    load_time_ms: 2.899\n",
      "    training_iteration_time_ms: 9499.959\n",
      "    update_time_ms: 3.984\n",
      "  timestamp: 1665851444\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 18107472\n",
      "  training_iteration: 283\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:30:50 (running for 00:45:24.55)<br>Memory usage on this node: 13.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   283</td><td style=\"text-align: right;\">         2689.41</td><td style=\"text-align: right;\">18107472</td><td style=\"text-align: right;\"> -191204</td><td style=\"text-align: right;\">             -187238</td><td style=\"text-align: right;\">             -195155</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 18171456\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 18171456\n",
      "    num_agent_steps_trained: 18171456\n",
      "    num_env_steps_sampled: 18171456\n",
      "    num_env_steps_trained: 18171456\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-30-54\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -187238.3418040868\n",
      "  episode_reward_mean: -191016.98842234493\n",
      "  episode_reward_min: -202238.2891679721\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 18168\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1050024032592773\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00034358820994384587\n",
      "          model: {}\n",
      "          policy_loss: 0.005003764294087887\n",
      "          total_loss: 10.004762649536133\n",
      "          vf_explained_var: -2.176042634971509e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 18171456\n",
      "    num_agent_steps_trained: 18171456\n",
      "    num_env_steps_sampled: 18171456\n",
      "    num_env_steps_trained: 18171456\n",
      "  iterations_since_restore: 284\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 18171456\n",
      "  num_agent_steps_trained: 18171456\n",
      "  num_env_steps_sampled: 18171456\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 18171456\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 85.28461538461539\n",
      "    ram_util_percent: 89.66923076923078\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09328345113560596\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46501152518925265\n",
      "    mean_inference_ms: 0.9615480370177802\n",
      "    mean_raw_obs_processing_ms: 0.1331427550770337\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -187238.3418040868\n",
      "    episode_reward_mean: -191016.98842234493\n",
      "    episode_reward_min: -202238.2891679721\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -191024.73158847194\n",
      "      - -191618.58912544826\n",
      "      - -189615.61411323803\n",
      "      - -193633.55772491387\n",
      "      - -191884.96751653668\n",
      "      - -187238.3418040868\n",
      "      - -189202.15162382027\n",
      "      - -191370.3277473069\n",
      "      - -191164.93052068635\n",
      "      - -191492.36652537418\n",
      "      - -190190.2000960723\n",
      "      - -194880.6267412834\n",
      "      - -193370.9242462862\n",
      "      - -190895.54828083527\n",
      "      - -190164.0801806204\n",
      "      - -192754.50247187936\n",
      "      - -189123.0325828033\n",
      "      - -189560.34398764002\n",
      "      - -189446.36011035804\n",
      "      - -190661.55897560238\n",
      "      - -191002.1713270639\n",
      "      - -190500.16586799736\n",
      "      - -190598.39652101093\n",
      "      - -195155.0845863614\n",
      "      - -194600.1864756904\n",
      "      - -188752.00075981856\n",
      "      - -191342.6293571013\n",
      "      - -190244.56757877755\n",
      "      - -190443.60438142953\n",
      "      - -189392.70494542134\n",
      "      - -194768.68121566452\n",
      "      - -190533.20160639065\n",
      "      - -189777.39298395754\n",
      "      - -189060.14675277148\n",
      "      - -189285.40548034429\n",
      "      - -189224.8189483125\n",
      "      - -190864.80793000926\n",
      "      - -192926.84143581538\n",
      "      - -191659.36243205692\n",
      "      - -191705.0455522982\n",
      "      - -190855.38319448673\n",
      "      - -190105.65214539866\n",
      "      - -190421.4785832299\n",
      "      - -189395.02946374926\n",
      "      - -190611.8510476653\n",
      "      - -190111.78647785177\n",
      "      - -191001.55482796434\n",
      "      - -202238.2891679721\n",
      "      - -192615.96314193803\n",
      "      - -191780.61814651184\n",
      "      - -188800.83619258364\n",
      "      - -189809.11936252486\n",
      "      - -190129.43852120332\n",
      "      - -188145.2242532788\n",
      "      - -194105.82443881637\n",
      "      - -189196.92170066127\n",
      "      - -192008.29418161933\n",
      "      - -192099.62664489629\n",
      "      - -191421.55857062462\n",
      "      - -190806.3397682042\n",
      "      - -190559.11079979237\n",
      "      - -191975.0938810274\n",
      "      - -189419.71792308037\n",
      "      - -188720.41550809258\n",
      "      - -189432.4952392969\n",
      "      - -192749.84042085856\n",
      "      - -190212.30987606104\n",
      "      - -190353.8478743599\n",
      "      - -191941.91618474002\n",
      "      - -191310.2021706973\n",
      "      - -190281.57961321747\n",
      "      - -191541.18640447175\n",
      "      - -189105.09378021685\n",
      "      - -189797.36404727498\n",
      "      - -193768.3148944299\n",
      "      - -188357.22473505957\n",
      "      - -191374.28218680862\n",
      "      - -191210.11194624883\n",
      "      - -191577.54867391186\n",
      "      - -191548.86999954717\n",
      "      - -191843.906578091\n",
      "      - -189540.97345308628\n",
      "      - -190601.84042108024\n",
      "      - -198537.5711022306\n",
      "      - -189366.12946832695\n",
      "      - -190340.74907459528\n",
      "      - -190616.76478886345\n",
      "      - -189825.47856091996\n",
      "      - -190025.31065949093\n",
      "      - -191385.36689868348\n",
      "      - -193900.15133692915\n",
      "      - -189850.25191248464\n",
      "      - -190011.62525512694\n",
      "      - -191510.03438773158\n",
      "      - -189753.9594414974\n",
      "      - -190836.47872686145\n",
      "      - -189898.8459253971\n",
      "      - -190344.0427556785\n",
      "      - -190332.9017634396\n",
      "      - -191149.17163204448\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09328345113560596\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46501152518925265\n",
      "      mean_inference_ms: 0.9615480370177802\n",
      "      mean_raw_obs_processing_ms: 0.1331427550770337\n",
      "  time_since_restore: 2699.0223388671875\n",
      "  time_this_iter_s: 9.60786747932434\n",
      "  time_total_s: 2699.0223388671875\n",
      "  timers:\n",
      "    learn_throughput: 125391.982\n",
      "    learn_time_ms: 510.272\n",
      "    load_throughput: 22198281.758\n",
      "    load_time_ms: 2.882\n",
      "    training_iteration_time_ms: 9565.534\n",
      "    update_time_ms: 3.977\n",
      "  timestamp: 1665851454\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 18171456\n",
      "  training_iteration: 284\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:30:59 (running for 00:45:33.78)<br>Memory usage on this node: 13.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   284</td><td style=\"text-align: right;\">         2699.02</td><td style=\"text-align: right;\">18171456</td><td style=\"text-align: right;\"> -191017</td><td style=\"text-align: right;\">             -187238</td><td style=\"text-align: right;\">             -202238</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 18235440\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 18235440\n",
      "    num_agent_steps_trained: 18235440\n",
      "    num_env_steps_sampled: 18235440\n",
      "    num_env_steps_trained: 18235440\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-31-03\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -187256.28434776116\n",
      "  episode_reward_mean: -190892.93632320157\n",
      "  episode_reward_min: -198537.5711022306\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 18228\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.102843999862671\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0006825228338129818\n",
      "          model: {}\n",
      "          policy_loss: 0.007173463236540556\n",
      "          total_loss: 10.007000923156738\n",
      "          vf_explained_var: -2.176042634971509e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 18235440\n",
      "    num_agent_steps_trained: 18235440\n",
      "    num_env_steps_sampled: 18235440\n",
      "    num_env_steps_trained: 18235440\n",
      "  iterations_since_restore: 285\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 18235440\n",
      "  num_agent_steps_trained: 18235440\n",
      "  num_env_steps_sampled: 18235440\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 18235440\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.82142857142856\n",
      "    ram_util_percent: 89.58571428571427\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09332326516465374\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4650237010471476\n",
      "    mean_inference_ms: 0.9616521284663955\n",
      "    mean_raw_obs_processing_ms: 0.13329368634492053\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -187256.28434776116\n",
      "    episode_reward_mean: -190892.93632320157\n",
      "    episode_reward_min: -198537.5711022306\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -190559.11079979237\n",
      "      - -191975.0938810274\n",
      "      - -189419.71792308037\n",
      "      - -188720.41550809258\n",
      "      - -189432.4952392969\n",
      "      - -192749.84042085856\n",
      "      - -190212.30987606104\n",
      "      - -190353.8478743599\n",
      "      - -191941.91618474002\n",
      "      - -191310.2021706973\n",
      "      - -190281.57961321747\n",
      "      - -191541.18640447175\n",
      "      - -189105.09378021685\n",
      "      - -189797.36404727498\n",
      "      - -193768.3148944299\n",
      "      - -188357.22473505957\n",
      "      - -191374.28218680862\n",
      "      - -191210.11194624883\n",
      "      - -191577.54867391186\n",
      "      - -191548.86999954717\n",
      "      - -191843.906578091\n",
      "      - -189540.97345308628\n",
      "      - -190601.84042108024\n",
      "      - -198537.5711022306\n",
      "      - -189366.12946832695\n",
      "      - -190340.74907459528\n",
      "      - -190616.76478886345\n",
      "      - -189825.47856091996\n",
      "      - -190025.31065949093\n",
      "      - -191385.36689868348\n",
      "      - -193900.15133692915\n",
      "      - -189850.25191248464\n",
      "      - -190011.62525512694\n",
      "      - -191510.03438773158\n",
      "      - -189753.9594414974\n",
      "      - -190836.47872686145\n",
      "      - -189898.8459253971\n",
      "      - -190344.0427556785\n",
      "      - -190332.9017634396\n",
      "      - -191149.17163204448\n",
      "      - -190187.2431472979\n",
      "      - -190014.4551095681\n",
      "      - -193427.17735745502\n",
      "      - -191051.27432197868\n",
      "      - -192932.6770780029\n",
      "      - -192184.4840345419\n",
      "      - -190357.14737796565\n",
      "      - -191846.53765991313\n",
      "      - -187715.71797298925\n",
      "      - -190727.6812215213\n",
      "      - -190468.0589376561\n",
      "      - -188831.24974099873\n",
      "      - -191614.74809167147\n",
      "      - -189557.64195207987\n",
      "      - -189417.37402229334\n",
      "      - -191443.6985218444\n",
      "      - -193815.61711576587\n",
      "      - -190104.21906224164\n",
      "      - -191760.59356878084\n",
      "      - -190743.96647879994\n",
      "      - -192061.55259125933\n",
      "      - -189097.96335069748\n",
      "      - -188875.61088556782\n",
      "      - -189474.98755583525\n",
      "      - -189154.649498427\n",
      "      - -192915.77544216445\n",
      "      - -192074.05499244222\n",
      "      - -190848.44682792985\n",
      "      - -189571.49892281042\n",
      "      - -187551.0698152881\n",
      "      - -191000.8056052471\n",
      "      - -193074.36166710404\n",
      "      - -192333.00771432742\n",
      "      - -190297.19218225547\n",
      "      - -188626.55299975688\n",
      "      - -190339.09323550112\n",
      "      - -190939.1340374948\n",
      "      - -188533.07661226383\n",
      "      - -190490.77717766905\n",
      "      - -197454.13607089975\n",
      "      - -190168.31484500403\n",
      "      - -193326.6753721905\n",
      "      - -190303.95823175553\n",
      "      - -190491.2143879819\n",
      "      - -191258.8976352106\n",
      "      - -187256.28434776116\n",
      "      - -192485.1429156905\n",
      "      - -192513.69371261165\n",
      "      - -189595.11691324232\n",
      "      - -191617.41666673354\n",
      "      - -190394.34645692637\n",
      "      - -190341.7443469893\n",
      "      - -187508.7700249674\n",
      "      - -193413.6360528713\n",
      "      - -193516.32919390182\n",
      "      - -191054.1995372675\n",
      "      - -193675.46908642398\n",
      "      - -188559.1039761702\n",
      "      - -193011.86037260923\n",
      "      - -190978.06798378594\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09332326516465374\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4650237010471476\n",
      "      mean_inference_ms: 0.9616521284663955\n",
      "      mean_raw_obs_processing_ms: 0.13329368634492053\n",
      "  time_since_restore: 2708.4572474956512\n",
      "  time_this_iter_s: 9.434908628463745\n",
      "  time_total_s: 2708.4572474956512\n",
      "  timers:\n",
      "    learn_throughput: 137868.212\n",
      "    learn_time_ms: 464.095\n",
      "    load_throughput: 22229356.079\n",
      "    load_time_ms: 2.878\n",
      "    training_iteration_time_ms: 9606.038\n",
      "    update_time_ms: 3.847\n",
      "  timestamp: 1665851463\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 18235440\n",
      "  training_iteration: 285\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:31:09 (running for 00:45:43.75)<br>Memory usage on this node: 13.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   285</td><td style=\"text-align: right;\">         2708.46</td><td style=\"text-align: right;\">18235440</td><td style=\"text-align: right;\"> -190893</td><td style=\"text-align: right;\">             -187256</td><td style=\"text-align: right;\">             -198538</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 18299424\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 18299424\n",
      "    num_agent_steps_trained: 18299424\n",
      "    num_env_steps_sampled: 18299424\n",
      "    num_env_steps_trained: 18299424\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-31-13\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -187256.28434776116\n",
      "  episode_reward_mean: -190740.00314073593\n",
      "  episode_reward_min: -201771.0343365065\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 18288\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0986595153808594\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0005480574327521026\n",
      "          model: {}\n",
      "          policy_loss: -0.0015350134344771504\n",
      "          total_loss: 9.99826431274414\n",
      "          vf_explained_var: -1.419158213167293e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 18299424\n",
      "    num_agent_steps_trained: 18299424\n",
      "    num_env_steps_sampled: 18299424\n",
      "    num_env_steps_trained: 18299424\n",
      "  iterations_since_restore: 286\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 18299424\n",
      "  num_agent_steps_trained: 18299424\n",
      "  num_env_steps_sampled: 18299424\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 18299424\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 82.32142857142857\n",
      "    ram_util_percent: 89.66428571428571\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09329612107741853\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.46500682330286397\n",
      "    mean_inference_ms: 0.9618584098156662\n",
      "    mean_raw_obs_processing_ms: 0.13329040366251424\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -187256.28434776116\n",
      "    episode_reward_mean: -190740.00314073593\n",
      "    episode_reward_min: -201771.0343365065\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -192061.55259125933\n",
      "      - -189097.96335069748\n",
      "      - -188875.61088556782\n",
      "      - -189474.98755583525\n",
      "      - -189154.649498427\n",
      "      - -192915.77544216445\n",
      "      - -192074.05499244222\n",
      "      - -190848.44682792985\n",
      "      - -189571.49892281042\n",
      "      - -187551.0698152881\n",
      "      - -191000.8056052471\n",
      "      - -193074.36166710404\n",
      "      - -192333.00771432742\n",
      "      - -190297.19218225547\n",
      "      - -188626.55299975688\n",
      "      - -190339.09323550112\n",
      "      - -190939.1340374948\n",
      "      - -188533.07661226383\n",
      "      - -190490.77717766905\n",
      "      - -197454.13607089975\n",
      "      - -190168.31484500403\n",
      "      - -193326.6753721905\n",
      "      - -190303.95823175553\n",
      "      - -190491.2143879819\n",
      "      - -191258.8976352106\n",
      "      - -187256.28434776116\n",
      "      - -192485.1429156905\n",
      "      - -192513.69371261165\n",
      "      - -189595.11691324232\n",
      "      - -191617.41666673354\n",
      "      - -190394.34645692637\n",
      "      - -190341.7443469893\n",
      "      - -187508.7700249674\n",
      "      - -193413.6360528713\n",
      "      - -193516.32919390182\n",
      "      - -191054.1995372675\n",
      "      - -193675.46908642398\n",
      "      - -188559.1039761702\n",
      "      - -193011.86037260923\n",
      "      - -190978.06798378594\n",
      "      - -191989.1458836767\n",
      "      - -189814.28019772496\n",
      "      - -190284.8850037429\n",
      "      - -190813.50316553857\n",
      "      - -188449.52902136254\n",
      "      - -188698.43179243107\n",
      "      - -190809.22126185236\n",
      "      - -190953.23880563106\n",
      "      - -192591.9224113082\n",
      "      - -201771.0343365065\n",
      "      - -188174.5533714224\n",
      "      - -189660.64236771507\n",
      "      - -189129.22105907803\n",
      "      - -192156.59591835225\n",
      "      - -189378.0010389114\n",
      "      - -190362.36843299164\n",
      "      - -191319.77430305743\n",
      "      - -189468.01559385099\n",
      "      - -191178.39875027578\n",
      "      - -191535.421773241\n",
      "      - -191899.86045735792\n",
      "      - -192396.50729491853\n",
      "      - -192081.01386119722\n",
      "      - -191556.97856387417\n",
      "      - -190677.76979286276\n",
      "      - -190260.7480420764\n",
      "      - -189224.74997253175\n",
      "      - -192127.794677974\n",
      "      - -191325.35647918365\n",
      "      - -190813.27408838665\n",
      "      - -189347.9399964721\n",
      "      - -189061.76925662227\n",
      "      - -191555.46111423188\n",
      "      - -188181.29756376363\n",
      "      - -189847.90633248494\n",
      "      - -188508.21788655344\n",
      "      - -192266.4394542628\n",
      "      - -191324.29097563395\n",
      "      - -189035.9163665366\n",
      "      - -190532.53795801368\n",
      "      - -187472.85638936158\n",
      "      - -190559.12587850803\n",
      "      - -188776.71302090285\n",
      "      - -190050.92829248207\n",
      "      - -189385.69212959195\n",
      "      - -190755.90381790366\n",
      "      - -190277.46720863561\n",
      "      - -189932.70226311428\n",
      "      - -189778.10489249838\n",
      "      - -188082.55259292785\n",
      "      - -193361.90025093386\n",
      "      - -191535.3850677012\n",
      "      - -191689.52682789485\n",
      "      - -188548.03516608008\n",
      "      - -189110.38563472076\n",
      "      - -191030.68807906454\n",
      "      - -191667.00998260683\n",
      "      - -191833.86256957694\n",
      "      - -193108.01227328923\n",
      "      - -190295.45786715124\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09329612107741853\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.46500682330286397\n",
      "      mean_inference_ms: 0.9618584098156662\n",
      "      mean_raw_obs_processing_ms: 0.13329040366251424\n",
      "  time_since_restore: 2718.4397571086884\n",
      "  time_this_iter_s: 9.98250961303711\n",
      "  time_total_s: 2718.4397571086884\n",
      "  timers:\n",
      "    learn_throughput: 138613.599\n",
      "    learn_time_ms: 461.6\n",
      "    load_throughput: 22207466.291\n",
      "    load_time_ms: 2.881\n",
      "    training_iteration_time_ms: 9688.026\n",
      "    update_time_ms: 3.713\n",
      "  timestamp: 1665851473\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 18299424\n",
      "  training_iteration: 286\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:31:19 (running for 00:45:53.70)<br>Memory usage on this node: 13.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   286</td><td style=\"text-align: right;\">         2718.44</td><td style=\"text-align: right;\">18299424</td><td style=\"text-align: right;\"> -190740</td><td style=\"text-align: right;\">             -187256</td><td style=\"text-align: right;\">             -201771</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_62e25_00000:\n",
      "  agent_timesteps_total: 18363408\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 18363408\n",
      "    num_agent_steps_trained: 18363408\n",
      "    num_env_steps_sampled: 18363408\n",
      "    num_env_steps_trained: 18363408\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-15_18-31-23\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -186405.0224335903\n",
      "  episode_reward_mean: -190814.40596034896\n",
      "  episode_reward_min: -205528.119498394\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 18360\n",
      "  experiment_id: 416915bca0d6482fa48dbfee58d8681b\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0971672534942627\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0006344734574668109\n",
      "          model: {}\n",
      "          policy_loss: 0.005250617396086454\n",
      "          total_loss: 10.00506591796875\n",
      "          vf_explained_var: -2.932926967957883e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 18363408\n",
      "    num_agent_steps_trained: 18363408\n",
      "    num_env_steps_sampled: 18363408\n",
      "    num_env_steps_trained: 18363408\n",
      "  iterations_since_restore: 287\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 18363408\n",
      "  num_agent_steps_trained: 18363408\n",
      "  num_env_steps_sampled: 18363408\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 18363408\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 87.64615384615384\n",
      "    ram_util_percent: 89.82307692307691\n",
      "  pid: 18350\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0932882309116788\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.4650983741014798\n",
      "    mean_inference_ms: 0.9619066524958347\n",
      "    mean_raw_obs_processing_ms: 0.133137558441598\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -186405.0224335903\n",
      "    episode_reward_mean: -190814.40596034896\n",
      "    episode_reward_min: -205528.119498394\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -191555.46111423188\n",
      "      - -188181.29756376363\n",
      "      - -189847.90633248494\n",
      "      - -188508.21788655344\n",
      "      - -192266.4394542628\n",
      "      - -191324.29097563395\n",
      "      - -189035.9163665366\n",
      "      - -190532.53795801368\n",
      "      - -187472.85638936158\n",
      "      - -190559.12587850803\n",
      "      - -188776.71302090285\n",
      "      - -190050.92829248207\n",
      "      - -189385.69212959195\n",
      "      - -190755.90381790366\n",
      "      - -190277.46720863561\n",
      "      - -189932.70226311428\n",
      "      - -189778.10489249838\n",
      "      - -188082.55259292785\n",
      "      - -193361.90025093386\n",
      "      - -191535.3850677012\n",
      "      - -191689.52682789485\n",
      "      - -188548.03516608008\n",
      "      - -189110.38563472076\n",
      "      - -191030.68807906454\n",
      "      - -191667.00998260683\n",
      "      - -191833.86256957694\n",
      "      - -193108.01227328923\n",
      "      - -190295.45786715124\n",
      "      - -192420.25565336365\n",
      "      - -190706.85815886394\n",
      "      - -190737.5419499174\n",
      "      - -187934.6174838291\n",
      "      - -192860.55484640328\n",
      "      - -190581.42195935934\n",
      "      - -194895.3219698408\n",
      "      - -192114.410513622\n",
      "      - -192153.9226949472\n",
      "      - -190267.35735820682\n",
      "      - -190202.66493648844\n",
      "      - -191642.97449547716\n",
      "      - -191303.52536939413\n",
      "      - -191698.90835565075\n",
      "      - -190993.0102484874\n",
      "      - -189063.27873992382\n",
      "      - -191427.36122709187\n",
      "      - -191184.45812491974\n",
      "      - -192080.3951205801\n",
      "      - -193015.63552089257\n",
      "      - -191333.16140977928\n",
      "      - -194707.6571866768\n",
      "      - -205528.119498394\n",
      "      - -190783.43414398265\n",
      "      - -190611.18477718896\n",
      "      - -188223.54997939017\n",
      "      - -191174.63484134804\n",
      "      - -191108.98978160866\n",
      "      - -190416.58832313944\n",
      "      - -191140.04921925362\n",
      "      - -189543.5295999551\n",
      "      - -191144.3694071062\n",
      "      - -190062.73826795697\n",
      "      - -193835.8000857697\n",
      "      - -190238.7048600212\n",
      "      - -189566.2270901081\n",
      "      - -190532.00583626633\n",
      "      - -191361.19697300685\n",
      "      - -192043.10328359922\n",
      "      - -190229.02935179946\n",
      "      - -190208.62329063634\n",
      "      - -194282.88601001605\n",
      "      - -191954.46361887618\n",
      "      - -188632.73487076344\n",
      "      - -188383.8376698422\n",
      "      - -191545.19301581106\n",
      "      - -191159.9997125814\n",
      "      - -191691.6570661912\n",
      "      - -186939.5083852629\n",
      "      - -189433.39873100637\n",
      "      - -191447.19948441003\n",
      "      - -190451.48254328084\n",
      "      - -190846.43708589984\n",
      "      - -192378.13603150254\n",
      "      - -189921.0740022537\n",
      "      - -189649.21786167688\n",
      "      - -190127.81245427238\n",
      "      - -189738.71342742475\n",
      "      - -190569.47347893848\n",
      "      - -190029.3293337827\n",
      "      - -189972.20282197505\n",
      "      - -190428.91572883294\n",
      "      - -188015.7533032051\n",
      "      - -186405.0224335903\n",
      "      - -189578.34516472975\n",
      "      - -190920.11102415342\n",
      "      - -191834.23358147775\n",
      "      - -192146.38288187655\n",
      "      - -192598.91161879696\n",
      "      - -191790.80878956147\n",
      "      - -189908.40500156942\n",
      "      - -189077.39911066103\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.0932882309116788\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.4650983741014798\n",
      "      mean_inference_ms: 0.9619066524958347\n",
      "      mean_raw_obs_processing_ms: 0.133137558441598\n",
      "  time_since_restore: 2728.1007091999054\n",
      "  time_this_iter_s: 9.660952091217041\n",
      "  time_total_s: 2728.1007091999054\n",
      "  timers:\n",
      "    learn_throughput: 134094.806\n",
      "    learn_time_ms: 477.155\n",
      "    load_throughput: 22302881.86\n",
      "    load_time_ms: 2.869\n",
      "    training_iteration_time_ms: 9729.012\n",
      "    update_time_ms: 3.878\n",
      "  timestamp: 1665851483\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 18363408\n",
      "  training_iteration: 287\n",
      "  trial_id: 62e25_00000\n",
      "  warmup_time: 12.471279382705688\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-15 18:31:29 (running for 00:46:03.48)<br>Memory usage on this node: 13.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">      ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_62e25_00000</td><td>RUNNING </td><td>192.168.0.185:18350</td><td style=\"text-align: right;\">   287</td><td style=\"text-align: right;\">          2728.1</td><td style=\"text-align: right;\">18363408</td><td style=\"text-align: right;\"> -190814</td><td style=\"text-align: right;\">             -186405</td><td style=\"text-align: right;\">             -205528</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = tune.run(\n",
    "        PPOTrainer,\n",
    "        config=config,\n",
    "        name=\"industrial_benchmark\",\n",
    "        local_dir=\"tmp/ray_exp_logs\",\n",
    "        checkpoint_freq=5,\n",
    "        # stop={\"training_iteration\": 5},\n",
    "        sync_config=tune.SyncConfig(\n",
    "            syncer=None  # Disable syncing\n",
    "        )\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
