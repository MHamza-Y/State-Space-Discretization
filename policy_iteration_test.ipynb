{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from envs.IBGym_mod_envs import IBGymQ\n",
    "from dynamic_model.transforms import NormalizeTransform\n",
    "from dynamic_programming.mdp_model import Policy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001B[33mWARN: Box bound precision lowered by casting to float32\u001B[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "\n",
    "\n",
    "model_path = 'dynamic_model/model'\n",
    "\n",
    "model = torch.load(model_path).to(device)\n",
    "model.eval()\n",
    "model.look_ahead = 0\n",
    "\n",
    "normalize_dataset = NormalizeTransform.load('dynamic_model/NormalizeInputConfigs.pkl')\n",
    "normalize_dataset.to(device)\n",
    "\n",
    "env = IBGymQ(q_model=model,device=device, setpoint=70, reward_type='classic', action_type='discrete', observation_type='include_past',\n",
    "             reset_after_timesteps=1000, n_past_timesteps=model.seq_len, normalize_transformer=normalize_dataset)\n",
    "\n",
    "policy_save_path = 'dynamic_programming/ib_policy.pkl'\n",
    "policy = Policy.load(policy_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random action taken\n",
      "-530.2102529140392\n",
      "-471.263854917924\n",
      "random action taken\n",
      "-569.7239221671186\n",
      "random action taken\n",
      "-2180.013610890101\n",
      "random action taken\n",
      "-506.5863166855896\n",
      "-448.83579672322963\n",
      "random action taken\n",
      "-788.7215413489965\n",
      "random action taken\n",
      "-2319.300448328404\n",
      "-1752.0902113710622\n",
      "-2205.3190082704837\n",
      "-2235.581046806837\n",
      "random action taken\n",
      "-438.21025809640224\n",
      "random action taken\n",
      "-533.0978396707367\n",
      "random action taken\n",
      "-480.66889145173093\n",
      "random action taken\n",
      "-393.52701117486095\n",
      "random action taken\n",
      "-632.5829849700092\n",
      "-518.7529304456655\n",
      "random action taken\n",
      "-2326.023056263656\n",
      "-1903.5394349533312\n",
      "random action taken\n",
      "-649.4952958313693\n",
      "-881.1064024894706\n",
      "-2467.162667197834\n",
      "random action taken\n",
      "-738.1779984222684\n",
      "-462.74194103161904\n",
      "random action taken\n",
      "-508.3841996442079\n",
      "-2154.1141719582733\n",
      "-2495.605491433088\n",
      "-452.43663557763915\n",
      "-368.1401628561977\n",
      "-2398.877144836338\n",
      "random action taken\n",
      "-544.5360040756833\n",
      "-399.7041360859367\n",
      "-2315.3695278628356\n",
      "random action taken\n",
      "-2562.1335122962373\n",
      "random action taken\n",
      "-705.8528125208446\n",
      "random action taken\n",
      "-495.0760902886133\n",
      "random action taken\n",
      "-1830.7718939586562\n",
      "-1067.7804142308082\n",
      "-382.8753995076544\n",
      "-621.315638107095\n",
      "random action taken\n",
      "-925.8266520700498\n",
      "random action taken\n",
      "-1329.2336365391093\n",
      "random action taken\n",
      "-1987.178120073265\n",
      "-428.02816888982056\n",
      "random action taken\n",
      "-1646.700358366141\n",
      "random action taken\n",
      "-549.9753412565616\n",
      "-420.21880890975524\n",
      "random action taken\n",
      "-2209.8425180018357\n",
      "random action taken\n",
      "-774.8125354989535\n",
      "random action taken\n",
      "-2514.1414923228567\n",
      "-490.62041169544045\n",
      "random action taken\n",
      "-2267.5078441792716\n",
      "-461.7955333095146\n",
      "random action taken\n",
      "-1584.2414928973672\n",
      "-525.0785871133144\n",
      "-1592.6896459509003\n",
      "random action taken\n",
      "-519.3379360285161\n",
      "random action taken\n",
      "-522.1238839843909\n",
      "random action taken\n",
      "-483.22707266694545\n",
      "-1546.6784229824316\n",
      "-1743.366795845269\n",
      "-489.27816258015844\n",
      "-444.5243163866425\n",
      "-2310.6598072840497\n",
      "random action taken\n",
      "-852.8586986610827\n",
      "random action taken\n",
      "-622.0818924512673\n",
      "random action taken\n",
      "-630.2841074028885\n",
      "-2514.6894977714396\n",
      "random action taken\n",
      "-560.1883335384109\n",
      "-1604.3523409874472\n",
      "random action taken\n",
      "-511.5298518037809\n",
      "-494.3368901579277\n",
      "random action taken\n",
      "-498.8728870113245\n",
      "-1843.8514186901018\n",
      "-463.38465281432474\n",
      "-1708.494841308416\n",
      "random action taken\n",
      "-531.7474012991961\n",
      "-484.62314853905133\n",
      "random action taken\n",
      "-487.5978983745952\n",
      "random action taken\n",
      "-513.9499090370856\n",
      "random action taken\n",
      "-472.5874679982349\n",
      "random action taken\n",
      "-1297.0179381001208\n",
      "random action taken\n",
      "-1998.3532296040814\n",
      "-468.8864311385034\n",
      "random action taken\n",
      "-1957.5045421246682\n",
      "-454.61724241640235\n",
      "random action taken\n",
      "-1829.542938941465\n"
     ]
    }
   ],
   "source": [
    "total_epochs = 0\n",
    "episodes = 100\n",
    "avg_ep_reward = 0\n",
    "\n",
    "without_random_action_rewards = []\n",
    "with_random_action_rewards = []\n",
    "for _ in range(episodes):\n",
    "    state = env.reset()\n",
    "    epochs, penalties, reward = 0, 0, 0\n",
    "\n",
    "    done = False\n",
    "    total_rewards = 0\n",
    "    random_action = False\n",
    "    while not done:\n",
    "        if state in policy.state_to_index:\n",
    "            action = policy.get_action(state)\n",
    "        else:\n",
    "            action = env.action_space.sample()\n",
    "            random_action = True\n",
    "        state, reward, done, info = env.step(action)\n",
    "\n",
    "\n",
    "        epochs += 1\n",
    "\n",
    "        total_rewards += reward\n",
    "    if random_action:\n",
    "        with_random_action_rewards.append(total_rewards/env.reset_after_timesteps)\n",
    "        print('random action taken')\n",
    "    else:\n",
    "        without_random_action_rewards.append(total_rewards/env.reset_after_timesteps)\n",
    "    print((total_rewards/env.reset_after_timesteps))\n",
    "    avg_ep_reward += (total_rewards/env.reset_after_timesteps)\n",
    "    total_epochs += epochs\n",
    "\n",
    "print(f\"Results after {episodes} episodes:\")\n",
    "print(f\"Average timesteps per episode: {total_epochs / episodes}\")\n",
    "print(f\"Average Reward per episode: {avg_ep_reward / episodes}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Average Reward with random actions {sum(with_random_action_rewards)/len(with_random_action_rewards)}')\n",
    "print(f'Average Reward without random actions {sum(without_random_action_rewards)/len(without_random_action_rewards)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "without_random_action_rewards"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
