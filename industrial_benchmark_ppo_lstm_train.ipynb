{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ray.tune as tune\n",
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "from ray.tune import register_env\n",
    "from envs.env_creator import env_creator, ibgym_env_creator_rllib\n",
    "from envs.IBGym_mod_envs import IBGymModded\n",
    "from ppo.policy import LSTMPPOPolicy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Configure Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "register_env(\"IBGym-v1\", ibgym_env_creator_rllib)\n",
    "\n",
    "config = {\n",
    "    # Environment (RLlib understands openAI gym registered strings).\n",
    "    \"env\": \"IBGym-v1\",\n",
    "    # Use 2 environment workers (aka \"rollout workers\") that parallelly\n",
    "    # collect samples from their own environment clone(s).\n",
    "    \"num_workers\": 12,\n",
    "    \"num_gpus\": 1,\n",
    "\n",
    "    # Change this to \"framework: torch\", if you are using PyTorch.\n",
    "    # Also, use \"framework: tf2\" for tf2.x eager execution.\n",
    "    \"framework\": \"tf\",\n",
    "    \"entropy_coeff\": 0.0001,\n",
    "    # \"entropy_coeff_schedule\":PiecewiseSchedule(endpoints=[(0, 0.01), (143000, 0.00001)]),\n",
    "    \"lr\": 3e-5,\n",
    "    \"gamma\": 0.994,\n",
    "    \"clip_param\": 0.2,\n",
    "    \"seed\": 5321,\n",
    "    \"num_sgd_iter\": 2,\n",
    "    \"sgd_minibatch_size\": 1000,\n",
    "\n",
    "    # \"vf_loss_coeff\": 1e-9,\n",
    "    # \"vf_clip_param\": 1e7,\n",
    "    # Tweak the default model provided automatically by RLlib,\n",
    "    # given the environment's observation- and action spaces.\n",
    "    \"model\": {\n",
    "        # == LSTM ==\n",
    "        # Whether to wrap the model with an LSTM.\n",
    "        \"use_lstm\": True,\n",
    "        # Max seq len for training the LSTM, defaults to 20.\n",
    "        \"max_seq_len\": 30,\n",
    "        # Size of the LSTM cell.\n",
    "        \"lstm_cell_size\": 64,\n",
    "        # \"use_attention\": True,\n",
    "        # \"attention_num_transformer_units\": 2,\n",
    "        # \"attention_dim\": 128,\n",
    "        # \"vf_share_layers\": True,\n",
    "        # \"fcnet_hiddens\": [32, 32, 32],\n",
    "        # \"sgd_minibatch_size\": 1024,\n",
    "        \"vf_share_layers\": False,\n",
    "        # Whether to feed a_{t-1} to LSTM (one-hot encoded if discrete).\n",
    "        \"lstm_use_prev_action\": False,\n",
    "        # Whether to feed r_{t-1} to LSTM.\n",
    "        \"lstm_use_prev_reward\": False,\n",
    "        # Whether the LSTM is time-major (TxBx..) or batch-major (BxTx..).\n",
    "        \"_time_major\": False,\n",
    "    },\n",
    "    \"train_batch_size\": 32000,\n",
    "    \"timesteps_per_iteration\": 32000,\n",
    "    # \"output\": \"tmp/ib-out\",\n",
    "    # Set up a separate evaluation worker set for the\n",
    "    # `trainer.evaluate()` call after training (see below).\n",
    "    \"evaluation_num_workers\": 3,\n",
    "    # Only for evaluation runs, render the env.\n",
    "    \"evaluation_config\": {\n",
    "        \"render_env\": False,\n",
    "    },\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:13:56 (running for 00:03:58.30)<br>Memory usage on this node: 11.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         206.826</td><td style=\"text-align: right;\">831792</td><td style=\"text-align: right;\"> -230604</td><td style=\"text-align: right;\">             -212036</td><td style=\"text-align: right;\">             -263445</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 895776\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 895776\n",
      "    num_agent_steps_trained: 895776\n",
      "    num_env_steps_sampled: 895776\n",
      "    num_env_steps_trained: 895776\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-13-56\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -212035.63694766775\n",
      "  episode_reward_mean: -230745.94534207933\n",
      "  episode_reward_min: -303472.80645493016\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 888\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1898248195648193\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0020165974274277687\n",
      "          model: {}\n",
      "          policy_loss: -0.0016078799962997437\n",
      "          total_loss: 9.998476028442383\n",
      "          vf_explained_var: -5.683861672878265e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 895776\n",
      "    num_agent_steps_trained: 895776\n",
      "    num_env_steps_sampled: 895776\n",
      "    num_env_steps_trained: 895776\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 895776\n",
      "  num_agent_steps_trained: 895776\n",
      "  num_env_steps_sampled: 895776\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 895776\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.83181818181818\n",
      "    ram_util_percent: 76.30454545454545\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12072478369965761\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5218089074137272\n",
      "    mean_inference_ms: 1.6064918587425452\n",
      "    mean_raw_obs_processing_ms: 0.16764712869197843\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -212035.63694766775\n",
      "    episode_reward_mean: -230745.94534207933\n",
      "    episode_reward_min: -303472.80645493016\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -221976.74394918105\n",
      "      - -221747.67482973373\n",
      "      - -228058.53342971203\n",
      "      - -246030.26357082636\n",
      "      - -258706.48463346314\n",
      "      - -241500.41834597618\n",
      "      - -229582.92198738336\n",
      "      - -221050.00869447828\n",
      "      - -223657.30900475086\n",
      "      - -221195.07576146934\n",
      "      - -221523.4770851547\n",
      "      - -215782.01795757926\n",
      "      - -246843.05174775282\n",
      "      - -218648.7951022273\n",
      "      - -227116.1674551239\n",
      "      - -213682.82164207424\n",
      "      - -234848.8574217306\n",
      "      - -212035.63694766775\n",
      "      - -226332.2103652071\n",
      "      - -228095.0978603236\n",
      "      - -222144.7186409026\n",
      "      - -227662.5138419327\n",
      "      - -251761.41399469317\n",
      "      - -227109.68058618307\n",
      "      - -227976.00679081946\n",
      "      - -246726.71237029458\n",
      "      - -220332.75000551148\n",
      "      - -227691.50035213807\n",
      "      - -219561.19722360425\n",
      "      - -231887.0812953046\n",
      "      - -228574.39666519273\n",
      "      - -251459.4776185183\n",
      "      - -234195.62791639814\n",
      "      - -263444.65445658116\n",
      "      - -225914.62171783688\n",
      "      - -224735.5212427814\n",
      "      - -224968.20446696816\n",
      "      - -240208.73012546435\n",
      "      - -227060.74246488072\n",
      "      - -222018.0173157618\n",
      "      - -233439.2646652206\n",
      "      - -219293.1954816348\n",
      "      - -220536.30793986164\n",
      "      - -233059.0229539313\n",
      "      - -236657.75261622015\n",
      "      - -225468.3637758956\n",
      "      - -224758.6059116017\n",
      "      - -239626.21568274708\n",
      "      - -230181.00469998113\n",
      "      - -229139.21725570888\n",
      "      - -216482.11482417228\n",
      "      - -232780.83821636517\n",
      "      - -230518.73222596972\n",
      "      - -224716.14109274384\n",
      "      - -231049.1717397456\n",
      "      - -221286.10018580788\n",
      "      - -235172.4486244043\n",
      "      - -231262.57086934842\n",
      "      - -221328.3927012277\n",
      "      - -221017.14962099775\n",
      "      - -230675.62439715324\n",
      "      - -240102.15919872202\n",
      "      - -220578.29700422782\n",
      "      - -228822.60022870696\n",
      "      - -226844.65697570142\n",
      "      - -244998.21348982828\n",
      "      - -230967.2785037496\n",
      "      - -222091.9327489874\n",
      "      - -218683.716207327\n",
      "      - -303472.80645493016\n",
      "      - -226085.84760340996\n",
      "      - -258542.95884721287\n",
      "      - -221769.10779656656\n",
      "      - -231951.1044828991\n",
      "      - -233768.38846422522\n",
      "      - -229195.64897794375\n",
      "      - -254900.52267676854\n",
      "      - -232173.26462305262\n",
      "      - -225384.3578121388\n",
      "      - -249124.05768058795\n",
      "      - -214900.49350496687\n",
      "      - -227003.90697308283\n",
      "      - -222517.90879560355\n",
      "      - -235498.3604797991\n",
      "      - -228839.3732742142\n",
      "      - -229990.33360641508\n",
      "      - -232028.75779001304\n",
      "      - -233797.41569701582\n",
      "      - -241324.94312800502\n",
      "      - -235221.99112081734\n",
      "      - -257551.09269403495\n",
      "      - -232297.88869396804\n",
      "      - -215900.2178823036\n",
      "      - -221198.1672074163\n",
      "      - -213896.81338503739\n",
      "      - -222478.9093489877\n",
      "      - -236225.12149854834\n",
      "      - -219585.0296166905\n",
      "      - -245978.91360768524\n",
      "      - -216606.60376201457\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.12072478369965761\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5218089074137272\n",
      "      mean_inference_ms: 1.6064918587425452\n",
      "      mean_raw_obs_processing_ms: 0.16764712869197843\n",
      "  time_since_restore: 222.3333957195282\n",
      "  time_this_iter_s: 15.507290601730347\n",
      "  time_total_s: 222.3333957195282\n",
      "  timers:\n",
      "    learn_throughput: 25101.569\n",
      "    learn_time_ms: 2549.004\n",
      "    load_throughput: 393768.375\n",
      "    load_time_ms: 162.491\n",
      "    training_iteration_time_ms: 15815.258\n",
      "    update_time_ms: 5.144\n",
      "  timestamp: 1665742436\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 895776\n",
      "  training_iteration: 14\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:14:01 (running for 00:04:03.83)<br>Memory usage on this node: 11.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         222.333</td><td style=\"text-align: right;\">895776</td><td style=\"text-align: right;\"> -230746</td><td style=\"text-align: right;\">             -212036</td><td style=\"text-align: right;\">             -303473</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:14:06 (running for 00:04:08.84)<br>Memory usage on this node: 11.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         222.333</td><td style=\"text-align: right;\">895776</td><td style=\"text-align: right;\"> -230746</td><td style=\"text-align: right;\">             -212036</td><td style=\"text-align: right;\">             -303473</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:14:11 (running for 00:04:13.85)<br>Memory usage on this node: 11.8/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         222.333</td><td style=\"text-align: right;\">895776</td><td style=\"text-align: right;\"> -230746</td><td style=\"text-align: right;\">             -212036</td><td style=\"text-align: right;\">             -303473</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 959760\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 959760\n",
      "    num_agent_steps_trained: 959760\n",
      "    num_env_steps_sampled: 959760\n",
      "    num_env_steps_trained: 959760\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-14-12\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -213896.81338503739\n",
      "  episode_reward_mean: -230412.48026239523\n",
      "  episode_reward_min: -303472.80645493016\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 948\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1853694915771484\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0021077217534184456\n",
      "          model: {}\n",
      "          policy_loss: 0.00022972095757722855\n",
      "          total_loss: 10.00033187866211\n",
      "          vf_explained_var: -2.357177436351776e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 959760\n",
      "    num_agent_steps_trained: 959760\n",
      "    num_env_steps_sampled: 959760\n",
      "    num_env_steps_trained: 959760\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 959760\n",
      "  num_agent_steps_trained: 959760\n",
      "  num_env_steps_sampled: 959760\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 959760\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.92727272727272\n",
      "    ram_util_percent: 76.53181818181817\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12052543531934468\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5213512777691123\n",
      "    mean_inference_ms: 1.6077348626549763\n",
      "    mean_raw_obs_processing_ms: 0.167039775603222\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -213896.81338503739\n",
      "    episode_reward_mean: -230412.48026239523\n",
      "    episode_reward_min: -303472.80645493016\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -230675.62439715324\n",
      "      - -240102.15919872202\n",
      "      - -220578.29700422782\n",
      "      - -228822.60022870696\n",
      "      - -226844.65697570142\n",
      "      - -244998.21348982828\n",
      "      - -230967.2785037496\n",
      "      - -222091.9327489874\n",
      "      - -218683.716207327\n",
      "      - -303472.80645493016\n",
      "      - -226085.84760340996\n",
      "      - -258542.95884721287\n",
      "      - -221769.10779656656\n",
      "      - -231951.1044828991\n",
      "      - -233768.38846422522\n",
      "      - -229195.64897794375\n",
      "      - -254900.52267676854\n",
      "      - -232173.26462305262\n",
      "      - -225384.3578121388\n",
      "      - -249124.05768058795\n",
      "      - -214900.49350496687\n",
      "      - -227003.90697308283\n",
      "      - -222517.90879560355\n",
      "      - -235498.3604797991\n",
      "      - -228839.3732742142\n",
      "      - -229990.33360641508\n",
      "      - -232028.75779001304\n",
      "      - -233797.41569701582\n",
      "      - -241324.94312800502\n",
      "      - -235221.99112081734\n",
      "      - -257551.09269403495\n",
      "      - -232297.88869396804\n",
      "      - -215900.2178823036\n",
      "      - -221198.1672074163\n",
      "      - -213896.81338503739\n",
      "      - -222478.9093489877\n",
      "      - -236225.12149854834\n",
      "      - -219585.0296166905\n",
      "      - -245978.91360768524\n",
      "      - -216606.60376201457\n",
      "      - -220199.7257926631\n",
      "      - -235111.3832240891\n",
      "      - -229638.32523014696\n",
      "      - -237331.37859970858\n",
      "      - -221178.77609040946\n",
      "      - -222319.83173091104\n",
      "      - -223794.02792955562\n",
      "      - -226103.58312198607\n",
      "      - -222372.53245288174\n",
      "      - -224349.32062989497\n",
      "      - -222028.62351538418\n",
      "      - -240318.67075002127\n",
      "      - -233146.5973855053\n",
      "      - -221613.63737880552\n",
      "      - -220209.35526687812\n",
      "      - -228623.61675227754\n",
      "      - -222329.1663090611\n",
      "      - -222408.9223274196\n",
      "      - -228029.62884228042\n",
      "      - -214348.2125512299\n",
      "      - -254378.04126668762\n",
      "      - -230944.14180207576\n",
      "      - -223806.24136643726\n",
      "      - -225235.30114424034\n",
      "      - -228919.75719728417\n",
      "      - -217743.06885593597\n",
      "      - -222345.75916037968\n",
      "      - -219649.54262866313\n",
      "      - -231968.46050048174\n",
      "      - -219098.208828029\n",
      "      - -238792.88282051194\n",
      "      - -235457.5343532736\n",
      "      - -222537.97356644072\n",
      "      - -221412.2806473773\n",
      "      - -221235.9523204914\n",
      "      - -219530.47586878316\n",
      "      - -226690.41067778153\n",
      "      - -226697.46824750758\n",
      "      - -232808.39563576336\n",
      "      - -222665.2079334604\n",
      "      - -231457.29162509422\n",
      "      - -218753.27647631275\n",
      "      - -243914.33987309827\n",
      "      - -227549.7931304293\n",
      "      - -224558.78705773718\n",
      "      - -227624.5958246454\n",
      "      - -231058.7699669766\n",
      "      - -225599.684916324\n",
      "      - -225547.10879002386\n",
      "      - -223172.06268318932\n",
      "      - -224761.52071661683\n",
      "      - -231146.0819294143\n",
      "      - -231864.07870357131\n",
      "      - -230362.5825160037\n",
      "      - -222975.33971875635\n",
      "      - -295979.8174079158\n",
      "      - -221238.3804208291\n",
      "      - -226560.71495785727\n",
      "      - -292309.12676948\n",
      "      - -214467.4658117724\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.12052543531934468\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5213512777691123\n",
      "      mean_inference_ms: 1.6077348626549763\n",
      "      mean_raw_obs_processing_ms: 0.167039775603222\n",
      "  time_since_restore: 238.20126748085022\n",
      "  time_this_iter_s: 15.867871761322021\n",
      "  time_total_s: 238.20126748085022\n",
      "  timers:\n",
      "    learn_throughput: 25340.426\n",
      "    learn_time_ms: 2524.977\n",
      "    load_throughput: 393009.964\n",
      "    load_time_ms: 162.805\n",
      "    training_iteration_time_ms: 15737.225\n",
      "    update_time_ms: 5.256\n",
      "  timestamp: 1665742452\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 959760\n",
      "  training_iteration: 15\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:14:17 (running for 00:04:19.70)<br>Memory usage on this node: 11.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         238.201</td><td style=\"text-align: right;\">959760</td><td style=\"text-align: right;\"> -230412</td><td style=\"text-align: right;\">             -213897</td><td style=\"text-align: right;\">             -303473</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:14:22 (running for 00:04:25.02)<br>Memory usage on this node: 11.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         238.201</td><td style=\"text-align: right;\">959760</td><td style=\"text-align: right;\"> -230412</td><td style=\"text-align: right;\">             -213897</td><td style=\"text-align: right;\">             -303473</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:14:27 (running for 00:04:30.02)<br>Memory usage on this node: 11.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         238.201</td><td style=\"text-align: right;\">959760</td><td style=\"text-align: right;\"> -230412</td><td style=\"text-align: right;\">             -213897</td><td style=\"text-align: right;\">             -303473</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 1023744\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 1023744\n",
      "    num_agent_steps_trained: 1023744\n",
      "    num_env_steps_sampled: 1023744\n",
      "    num_env_steps_trained: 1023744\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-14-27\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -211455.83614863481\n",
      "  episode_reward_mean: -228762.98114044423\n",
      "  episode_reward_min: -295979.8174079158\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 1020\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.189800977706909\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00188849784899503\n",
      "          model: {}\n",
      "          policy_loss: 0.005997458007186651\n",
      "          total_loss: 10.00605583190918\n",
      "          vf_explained_var: -3.3910457659658277e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 1023744\n",
      "    num_agent_steps_trained: 1023744\n",
      "    num_env_steps_sampled: 1023744\n",
      "    num_env_steps_trained: 1023744\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 1023744\n",
      "  num_agent_steps_trained: 1023744\n",
      "  num_env_steps_sampled: 1023744\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 1023744\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.52380952380953\n",
      "    ram_util_percent: 76.74285714285713\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12058346487414216\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5212048865915542\n",
      "    mean_inference_ms: 1.6080155647780128\n",
      "    mean_raw_obs_processing_ms: 0.16707423879680633\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -211455.83614863481\n",
      "    episode_reward_mean: -228762.98114044423\n",
      "    episode_reward_min: -295979.8174079158\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -222537.97356644072\n",
      "      - -221412.2806473773\n",
      "      - -221235.9523204914\n",
      "      - -219530.47586878316\n",
      "      - -226690.41067778153\n",
      "      - -226697.46824750758\n",
      "      - -232808.39563576336\n",
      "      - -222665.2079334604\n",
      "      - -231457.29162509422\n",
      "      - -218753.27647631275\n",
      "      - -243914.33987309827\n",
      "      - -227549.7931304293\n",
      "      - -224558.78705773718\n",
      "      - -227624.5958246454\n",
      "      - -231058.7699669766\n",
      "      - -225599.684916324\n",
      "      - -225547.10879002386\n",
      "      - -223172.06268318932\n",
      "      - -224761.52071661683\n",
      "      - -231146.0819294143\n",
      "      - -231864.07870357131\n",
      "      - -230362.5825160037\n",
      "      - -222975.33971875635\n",
      "      - -295979.8174079158\n",
      "      - -221238.3804208291\n",
      "      - -226560.71495785727\n",
      "      - -292309.12676948\n",
      "      - -214467.4658117724\n",
      "      - -231792.6177794955\n",
      "      - -224779.73767158488\n",
      "      - -224284.11263309242\n",
      "      - -228122.7466183708\n",
      "      - -229579.4451391078\n",
      "      - -241080.6384280269\n",
      "      - -230793.14178809762\n",
      "      - -225248.8777892257\n",
      "      - -228723.94898217887\n",
      "      - -230560.4818059866\n",
      "      - -217823.43474853277\n",
      "      - -218300.2633480337\n",
      "      - -223940.92749394604\n",
      "      - -225192.84170576697\n",
      "      - -231609.92905174708\n",
      "      - -214768.41945879345\n",
      "      - -227765.92069389182\n",
      "      - -234257.0236312894\n",
      "      - -240014.39417442522\n",
      "      - -224751.20856215685\n",
      "      - -231175.68757012804\n",
      "      - -242910.05565242714\n",
      "      - -221828.68191737114\n",
      "      - -216381.06090001244\n",
      "      - -247953.69217792552\n",
      "      - -215766.578165718\n",
      "      - -221853.26532376706\n",
      "      - -225874.6893286188\n",
      "      - -247917.79810720423\n",
      "      - -240807.78093266155\n",
      "      - -224045.67608017076\n",
      "      - -223663.0446098431\n",
      "      - -225934.96074772978\n",
      "      - -225743.79086036823\n",
      "      - -217339.3298177952\n",
      "      - -233143.06289492437\n",
      "      - -220629.37645888075\n",
      "      - -220478.06512908367\n",
      "      - -218269.85584548162\n",
      "      - -211455.83614863481\n",
      "      - -228823.7848581262\n",
      "      - -220772.15489573978\n",
      "      - -224351.88870198457\n",
      "      - -217842.3277063334\n",
      "      - -226577.1738528846\n",
      "      - -244541.5968214662\n",
      "      - -290837.330195613\n",
      "      - -221001.63439844915\n",
      "      - -221429.63214797218\n",
      "      - -237378.2489549305\n",
      "      - -224853.71532331785\n",
      "      - -217693.35625588556\n",
      "      - -235595.353921697\n",
      "      - -225716.12324452313\n",
      "      - -237948.75624573274\n",
      "      - -227080.6866355254\n",
      "      - -228607.72591063427\n",
      "      - -233201.0732249558\n",
      "      - -219937.00712462745\n",
      "      - -233995.51674038902\n",
      "      - -238011.33781100457\n",
      "      - -222703.34657432162\n",
      "      - -218175.4806560293\n",
      "      - -218947.43106980168\n",
      "      - -233542.23460858222\n",
      "      - -234330.1330513963\n",
      "      - -222230.2752327131\n",
      "      - -225505.6658276443\n",
      "      - -221356.04525062983\n",
      "      - -228409.35816139996\n",
      "      - -225972.7721735709\n",
      "      - -217887.56210039466\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.12058346487414216\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5212048865915542\n",
      "      mean_inference_ms: 1.6080155647780128\n",
      "      mean_raw_obs_processing_ms: 0.16707423879680633\n",
      "  time_since_restore: 253.55240154266357\n",
      "  time_this_iter_s: 15.351134061813354\n",
      "  time_total_s: 253.55240154266357\n",
      "  timers:\n",
      "    learn_throughput: 25273.321\n",
      "    learn_time_ms: 2531.682\n",
      "    load_throughput: 393202.0\n",
      "    load_time_ms: 162.726\n",
      "    training_iteration_time_ms: 15669.301\n",
      "    update_time_ms: 5.298\n",
      "  timestamp: 1665742467\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1023744\n",
      "  training_iteration: 16\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:14:33 (running for 00:04:35.35)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         253.552</td><td style=\"text-align: right;\">1.02374e+06</td><td style=\"text-align: right;\"> -228763</td><td style=\"text-align: right;\">             -211456</td><td style=\"text-align: right;\">             -295980</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:14:38 (running for 00:04:40.35)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         253.552</td><td style=\"text-align: right;\">1.02374e+06</td><td style=\"text-align: right;\"> -228763</td><td style=\"text-align: right;\">             -211456</td><td style=\"text-align: right;\">             -295980</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:14:43 (running for 00:04:45.36)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         253.552</td><td style=\"text-align: right;\">1.02374e+06</td><td style=\"text-align: right;\"> -228763</td><td style=\"text-align: right;\">             -211456</td><td style=\"text-align: right;\">             -295980</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 1087728\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 1087728\n",
      "    num_agent_steps_trained: 1087728\n",
      "    num_env_steps_sampled: 1087728\n",
      "    num_env_steps_trained: 1087728\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-14-44\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -211455.83614863481\n",
      "  episode_reward_mean: -227065.8753183654\n",
      "  episode_reward_min: -290837.330195613\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 1080\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.186768054962158\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0020511276088654995\n",
      "          model: {}\n",
      "          policy_loss: 0.005901666358113289\n",
      "          total_loss: 10.005992889404297\n",
      "          vf_explained_var: -1.941341906785965e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 1087728\n",
      "    num_agent_steps_trained: 1087728\n",
      "    num_env_steps_sampled: 1087728\n",
      "    num_env_steps_trained: 1087728\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 1087728\n",
      "  num_agent_steps_trained: 1087728\n",
      "  num_env_steps_sampled: 1087728\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 1087728\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.49166666666666\n",
      "    ram_util_percent: 77.28333333333335\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.120499744576486\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.521583619868792\n",
      "    mean_inference_ms: 1.6093150528567333\n",
      "    mean_raw_obs_processing_ms: 0.1669152841992122\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -211455.83614863481\n",
      "    episode_reward_mean: -227065.8753183654\n",
      "    episode_reward_min: -290837.330195613\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -225934.96074772978\n",
      "      - -225743.79086036823\n",
      "      - -217339.3298177952\n",
      "      - -233143.06289492437\n",
      "      - -220629.37645888075\n",
      "      - -220478.06512908367\n",
      "      - -218269.85584548162\n",
      "      - -211455.83614863481\n",
      "      - -228823.7848581262\n",
      "      - -220772.15489573978\n",
      "      - -224351.88870198457\n",
      "      - -217842.3277063334\n",
      "      - -226577.1738528846\n",
      "      - -244541.5968214662\n",
      "      - -290837.330195613\n",
      "      - -221001.63439844915\n",
      "      - -221429.63214797218\n",
      "      - -237378.2489549305\n",
      "      - -224853.71532331785\n",
      "      - -217693.35625588556\n",
      "      - -235595.353921697\n",
      "      - -225716.12324452313\n",
      "      - -237948.75624573274\n",
      "      - -227080.6866355254\n",
      "      - -228607.72591063427\n",
      "      - -233201.0732249558\n",
      "      - -219937.00712462745\n",
      "      - -233995.51674038902\n",
      "      - -238011.33781100457\n",
      "      - -222703.34657432162\n",
      "      - -218175.4806560293\n",
      "      - -218947.43106980168\n",
      "      - -233542.23460858222\n",
      "      - -234330.1330513963\n",
      "      - -222230.2752327131\n",
      "      - -225505.6658276443\n",
      "      - -221356.04525062983\n",
      "      - -228409.35816139996\n",
      "      - -225972.7721735709\n",
      "      - -217887.56210039466\n",
      "      - -236139.6792814869\n",
      "      - -216962.4983878292\n",
      "      - -226077.9379577428\n",
      "      - -220902.28647207687\n",
      "      - -212942.48605670859\n",
      "      - -219970.90939114682\n",
      "      - -227358.81262588693\n",
      "      - -225791.07455850308\n",
      "      - -224293.18801177875\n",
      "      - -233378.104637538\n",
      "      - -229988.77620623005\n",
      "      - -220667.48900616498\n",
      "      - -219124.72149826013\n",
      "      - -223987.6996322301\n",
      "      - -218361.9555780689\n",
      "      - -223547.1389475514\n",
      "      - -225878.21949904377\n",
      "      - -216253.50939678884\n",
      "      - -221207.71291231774\n",
      "      - -220950.22969709936\n",
      "      - -219909.28480971776\n",
      "      - -217437.18797308314\n",
      "      - -224376.29811760047\n",
      "      - -224623.787665288\n",
      "      - -231414.13865305745\n",
      "      - -216587.17914303823\n",
      "      - -222993.3580331436\n",
      "      - -216078.62938207897\n",
      "      - -221572.06375264438\n",
      "      - -264304.22508796596\n",
      "      - -220845.75770617605\n",
      "      - -233960.11002668898\n",
      "      - -228106.1629001811\n",
      "      - -223077.44732374052\n",
      "      - -217608.80845893\n",
      "      - -216353.92093372854\n",
      "      - -250276.94980770742\n",
      "      - -219726.24010390928\n",
      "      - -239650.94530280895\n",
      "      - -250446.3997669394\n",
      "      - -217866.17799906989\n",
      "      - -222154.7994798567\n",
      "      - -216916.67685318645\n",
      "      - -223377.1645316938\n",
      "      - -253683.461324346\n",
      "      - -223574.7813592267\n",
      "      - -265924.86951028917\n",
      "      - -214662.37093128267\n",
      "      - -224092.71790124563\n",
      "      - -251821.4555127729\n",
      "      - -222974.26517508086\n",
      "      - -248287.0713793477\n",
      "      - -225915.91966161918\n",
      "      - -226724.81935038755\n",
      "      - -214536.5157657942\n",
      "      - -232527.1572758972\n",
      "      - -217144.16765112075\n",
      "      - -221806.11488848669\n",
      "      - -229581.7614938665\n",
      "      - -231630.9315079167\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.120499744576486\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.521583619868792\n",
      "      mean_inference_ms: 1.6093150528567333\n",
      "      mean_raw_obs_processing_ms: 0.1669152841992122\n",
      "  time_since_restore: 270.06014704704285\n",
      "  time_this_iter_s: 16.507745504379272\n",
      "  time_total_s: 270.06014704704285\n",
      "  timers:\n",
      "    learn_throughput: 25020.66\n",
      "    learn_time_ms: 2557.247\n",
      "    load_throughput: 382028.407\n",
      "    load_time_ms: 167.485\n",
      "    training_iteration_time_ms: 15766.265\n",
      "    update_time_ms: 5.427\n",
      "  timestamp: 1665742484\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1087728\n",
      "  training_iteration: 17\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:14:49 (running for 00:04:51.70)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">          270.06</td><td style=\"text-align: right;\">1.08773e+06</td><td style=\"text-align: right;\"> -227066</td><td style=\"text-align: right;\">             -211456</td><td style=\"text-align: right;\">             -290837</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:14:54 (running for 00:04:56.77)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">          270.06</td><td style=\"text-align: right;\">1.08773e+06</td><td style=\"text-align: right;\"> -227066</td><td style=\"text-align: right;\">             -211456</td><td style=\"text-align: right;\">             -290837</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:14:59 (running for 00:05:01.77)<br>Memory usage on this node: 11.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">          270.06</td><td style=\"text-align: right;\">1.08773e+06</td><td style=\"text-align: right;\"> -227066</td><td style=\"text-align: right;\">             -211456</td><td style=\"text-align: right;\">             -290837</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 1151712\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 1151712\n",
      "    num_agent_steps_trained: 1151712\n",
      "    num_env_steps_sampled: 1151712\n",
      "    num_env_steps_trained: 1151712\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-15-00\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -211427.20345332028\n",
      "  episode_reward_mean: -225834.4701837723\n",
      "  episode_reward_min: -265924.86951028917\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 1140\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.190392255783081\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.001882149837911129\n",
      "          model: {}\n",
      "          policy_loss: 0.0011186019983142614\n",
      "          total_loss: 10.001174926757812\n",
      "          vf_explained_var: -1.312699168920517e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 1151712\n",
      "    num_agent_steps_trained: 1151712\n",
      "    num_env_steps_sampled: 1151712\n",
      "    num_env_steps_trained: 1151712\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 1151712\n",
      "  num_agent_steps_trained: 1151712\n",
      "  num_env_steps_sampled: 1151712\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 1151712\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 78.79130434782608\n",
      "    ram_util_percent: 77.23913043478262\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12043347087489092\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5220495764000336\n",
      "    mean_inference_ms: 1.612874864935237\n",
      "    mean_raw_obs_processing_ms: 0.16652214543120392\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -211427.20345332028\n",
      "    episode_reward_mean: -225834.4701837723\n",
      "    episode_reward_min: -265924.86951028917\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -219909.28480971776\n",
      "      - -217437.18797308314\n",
      "      - -224376.29811760047\n",
      "      - -224623.787665288\n",
      "      - -231414.13865305745\n",
      "      - -216587.17914303823\n",
      "      - -222993.3580331436\n",
      "      - -216078.62938207897\n",
      "      - -221572.06375264438\n",
      "      - -264304.22508796596\n",
      "      - -220845.75770617605\n",
      "      - -233960.11002668898\n",
      "      - -228106.1629001811\n",
      "      - -223077.44732374052\n",
      "      - -217608.80845893\n",
      "      - -216353.92093372854\n",
      "      - -250276.94980770742\n",
      "      - -219726.24010390928\n",
      "      - -239650.94530280895\n",
      "      - -250446.3997669394\n",
      "      - -217866.17799906989\n",
      "      - -222154.7994798567\n",
      "      - -216916.67685318645\n",
      "      - -223377.1645316938\n",
      "      - -253683.461324346\n",
      "      - -223574.7813592267\n",
      "      - -265924.86951028917\n",
      "      - -214662.37093128267\n",
      "      - -224092.71790124563\n",
      "      - -251821.4555127729\n",
      "      - -222974.26517508086\n",
      "      - -248287.0713793477\n",
      "      - -225915.91966161918\n",
      "      - -226724.81935038755\n",
      "      - -214536.5157657942\n",
      "      - -232527.1572758972\n",
      "      - -217144.16765112075\n",
      "      - -221806.11488848669\n",
      "      - -229581.7614938665\n",
      "      - -231630.9315079167\n",
      "      - -229318.43260099576\n",
      "      - -214781.12755284976\n",
      "      - -217916.0624889101\n",
      "      - -221736.87286520636\n",
      "      - -228277.51171119325\n",
      "      - -228268.37542098272\n",
      "      - -217954.56801585952\n",
      "      - -217284.14151713025\n",
      "      - -215422.35929364158\n",
      "      - -228529.34203189702\n",
      "      - -214264.47371010162\n",
      "      - -219151.53999611567\n",
      "      - -242696.3209164919\n",
      "      - -215719.84009359116\n",
      "      - -233912.50948527132\n",
      "      - -222205.95925342708\n",
      "      - -234521.91390315676\n",
      "      - -233549.76571075432\n",
      "      - -216157.37065036208\n",
      "      - -215704.27056044654\n",
      "      - -218384.42000962005\n",
      "      - -220056.2585347081\n",
      "      - -220303.45143463122\n",
      "      - -228140.41166805758\n",
      "      - -239964.91825083914\n",
      "      - -224179.00618876168\n",
      "      - -211427.20345332028\n",
      "      - -225618.9035687965\n",
      "      - -220056.19423805247\n",
      "      - -218847.9733014266\n",
      "      - -214288.23128187083\n",
      "      - -231175.22564321375\n",
      "      - -231203.17812181663\n",
      "      - -262837.37349418446\n",
      "      - -218802.29884395073\n",
      "      - -222752.18871383756\n",
      "      - -237057.33363016346\n",
      "      - -216606.17665175837\n",
      "      - -226524.4468935298\n",
      "      - -220809.24738518798\n",
      "      - -227058.83785147298\n",
      "      - -223110.30294703008\n",
      "      - -224947.48790557892\n",
      "      - -221838.66596338997\n",
      "      - -218982.7816519406\n",
      "      - -229024.5777375917\n",
      "      - -227953.64233672156\n",
      "      - -224874.87100831958\n",
      "      - -220520.02550785756\n",
      "      - -216082.45586330188\n",
      "      - -240157.9399411381\n",
      "      - -214810.2290932899\n",
      "      - -223809.38664829897\n",
      "      - -225379.34800563648\n",
      "      - -217981.80504461567\n",
      "      - -216870.0576188968\n",
      "      - -216490.54201191734\n",
      "      - -233214.7688757984\n",
      "      - -216945.85112518707\n",
      "      - -222434.14765221617\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.12043347087489092\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5220495764000336\n",
      "      mean_inference_ms: 1.612874864935237\n",
      "      mean_raw_obs_processing_ms: 0.16652214543120392\n",
      "  time_since_restore: 286.42824244499207\n",
      "  time_this_iter_s: 16.36809539794922\n",
      "  time_total_s: 286.42824244499207\n",
      "  timers:\n",
      "    learn_throughput: 24664.538\n",
      "    learn_time_ms: 2594.17\n",
      "    load_throughput: 382710.93\n",
      "    load_time_ms: 167.186\n",
      "    training_iteration_time_ms: 15740.264\n",
      "    update_time_ms: 5.467\n",
      "  timestamp: 1665742500\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1151712\n",
      "  training_iteration: 18\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:15:05 (running for 00:05:08.08)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         286.428</td><td style=\"text-align: right;\">1.15171e+06</td><td style=\"text-align: right;\"> -225834</td><td style=\"text-align: right;\">             -211427</td><td style=\"text-align: right;\">             -265925</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:15:10 (running for 00:05:13.08)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         286.428</td><td style=\"text-align: right;\">1.15171e+06</td><td style=\"text-align: right;\"> -225834</td><td style=\"text-align: right;\">             -211427</td><td style=\"text-align: right;\">             -265925</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:15:15 (running for 00:05:18.09)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         286.428</td><td style=\"text-align: right;\">1.15171e+06</td><td style=\"text-align: right;\"> -225834</td><td style=\"text-align: right;\">             -211427</td><td style=\"text-align: right;\">             -265925</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 1215696\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 1215696\n",
      "    num_agent_steps_trained: 1215696\n",
      "    num_env_steps_sampled: 1215696\n",
      "    num_env_steps_trained: 1215696\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-15-15\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -210637.02773507687\n",
      "  episode_reward_mean: -223148.32382704868\n",
      "  episode_reward_min: -262837.37349418446\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 1212\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.197052478790283\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0012963061453774571\n",
      "          model: {}\n",
      "          policy_loss: 0.006734847091138363\n",
      "          total_loss: 10.006674766540527\n",
      "          vf_explained_var: 1.1265277635175153e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 1215696\n",
      "    num_agent_steps_trained: 1215696\n",
      "    num_env_steps_sampled: 1215696\n",
      "    num_env_steps_trained: 1215696\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 1215696\n",
      "  num_agent_steps_trained: 1215696\n",
      "  num_env_steps_sampled: 1215696\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 1215696\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.55238095238094\n",
      "    ram_util_percent: 77.24285714285715\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12055545028844643\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5220706517432236\n",
      "    mean_inference_ms: 1.6103356051708788\n",
      "    mean_raw_obs_processing_ms: 0.16638879488334413\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -210637.02773507687\n",
      "    episode_reward_mean: -223148.32382704868\n",
      "    episode_reward_min: -262837.37349418446\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -231203.17812181663\n",
      "      - -262837.37349418446\n",
      "      - -218802.29884395073\n",
      "      - -222752.18871383756\n",
      "      - -237057.33363016346\n",
      "      - -216606.17665175837\n",
      "      - -226524.4468935298\n",
      "      - -220809.24738518798\n",
      "      - -227058.83785147298\n",
      "      - -223110.30294703008\n",
      "      - -224947.48790557892\n",
      "      - -221838.66596338997\n",
      "      - -218982.7816519406\n",
      "      - -229024.5777375917\n",
      "      - -227953.64233672156\n",
      "      - -224874.87100831958\n",
      "      - -220520.02550785756\n",
      "      - -216082.45586330188\n",
      "      - -240157.9399411381\n",
      "      - -214810.2290932899\n",
      "      - -223809.38664829897\n",
      "      - -225379.34800563648\n",
      "      - -217981.80504461567\n",
      "      - -216870.0576188968\n",
      "      - -216490.54201191734\n",
      "      - -233214.7688757984\n",
      "      - -216945.85112518707\n",
      "      - -222434.14765221617\n",
      "      - -225287.20188372512\n",
      "      - -219102.843770089\n",
      "      - -216270.51469929592\n",
      "      - -219993.80651216596\n",
      "      - -222987.2096423589\n",
      "      - -230237.30874417798\n",
      "      - -225926.75746589704\n",
      "      - -215093.59756550196\n",
      "      - -230629.7247675828\n",
      "      - -219387.26883231202\n",
      "      - -228741.92599232148\n",
      "      - -213444.37362266608\n",
      "      - -219404.76532273414\n",
      "      - -222636.42678760676\n",
      "      - -216130.06687339913\n",
      "      - -219485.17801242493\n",
      "      - -218341.03968425546\n",
      "      - -216040.70268020616\n",
      "      - -213247.88251855306\n",
      "      - -222590.14034622654\n",
      "      - -219354.56470816804\n",
      "      - -211027.91535748058\n",
      "      - -224985.7890516859\n",
      "      - -222356.2850372082\n",
      "      - -222980.02321418587\n",
      "      - -215686.7692930665\n",
      "      - -215473.99275165232\n",
      "      - -222206.18734984237\n",
      "      - -217787.63597079634\n",
      "      - -220165.05775550334\n",
      "      - -231877.40658340233\n",
      "      - -224378.6774588814\n",
      "      - -232231.6009658099\n",
      "      - -225915.6250019571\n",
      "      - -219166.84648285905\n",
      "      - -228136.3162648505\n",
      "      - -216974.98051208013\n",
      "      - -218744.7418398235\n",
      "      - -218018.11601492445\n",
      "      - -218879.867110903\n",
      "      - -221073.99266693488\n",
      "      - -224484.0438996593\n",
      "      - -240224.48275483598\n",
      "      - -218661.19840399147\n",
      "      - -228050.5310308864\n",
      "      - -223868.8207178038\n",
      "      - -220157.4946118762\n",
      "      - -213899.08070353832\n",
      "      - -233022.65967728163\n",
      "      - -223833.05917240767\n",
      "      - -216952.89581691517\n",
      "      - -222086.91425455056\n",
      "      - -222674.2528827827\n",
      "      - -225696.00547378312\n",
      "      - -222226.01551251384\n",
      "      - -231039.03961477985\n",
      "      - -241779.53425617664\n",
      "      - -210637.02773507687\n",
      "      - -218581.92657154688\n",
      "      - -224907.21366821064\n",
      "      - -221540.369566765\n",
      "      - -240228.13951892342\n",
      "      - -221220.5624420774\n",
      "      - -225011.3976684097\n",
      "      - -212944.34268534768\n",
      "      - -220533.88224463904\n",
      "      - -215835.0074015492\n",
      "      - -212060.2523116284\n",
      "      - -224047.6624881274\n",
      "      - -225439.29566864984\n",
      "      - -240417.61213425893\n",
      "      - -231290.56617572778\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.12055545028844643\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5220706517432236\n",
      "      mean_inference_ms: 1.6103356051708788\n",
      "      mean_raw_obs_processing_ms: 0.16638879488334413\n",
      "  time_since_restore: 301.5238244533539\n",
      "  time_this_iter_s: 15.095582008361816\n",
      "  time_total_s: 301.5238244533539\n",
      "  timers:\n",
      "    learn_throughput: 24849.642\n",
      "    learn_time_ms: 2574.846\n",
      "    load_throughput: 381615.763\n",
      "    load_time_ms: 167.666\n",
      "    training_iteration_time_ms: 15703.303\n",
      "    update_time_ms: 5.245\n",
      "  timestamp: 1665742515\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1215696\n",
      "  training_iteration: 19\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:15:20 (running for 00:05:23.14)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         301.524</td><td style=\"text-align: right;\">1.2157e+06</td><td style=\"text-align: right;\"> -223148</td><td style=\"text-align: right;\">             -210637</td><td style=\"text-align: right;\">             -262837</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:15:25 (running for 00:05:28.21)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         301.524</td><td style=\"text-align: right;\">1.2157e+06</td><td style=\"text-align: right;\"> -223148</td><td style=\"text-align: right;\">             -210637</td><td style=\"text-align: right;\">             -262837</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:15:30 (running for 00:05:33.21)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         301.524</td><td style=\"text-align: right;\">1.2157e+06</td><td style=\"text-align: right;\"> -223148</td><td style=\"text-align: right;\">             -210637</td><td style=\"text-align: right;\">             -262837</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 1279680\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 1279680\n",
      "    num_agent_steps_trained: 1279680\n",
      "    num_env_steps_sampled: 1279680\n",
      "    num_env_steps_trained: 1279680\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-15-31\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -206864.16603588185\n",
      "  episode_reward_mean: -222091.1951210536\n",
      "  episode_reward_min: -253130.6172528566\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 1272\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.2016568183898926\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0019647504668682814\n",
      "          model: {}\n",
      "          policy_loss: 0.003713137935847044\n",
      "          total_loss: 10.003786087036133\n",
      "          vf_explained_var: 1.3938316669737105e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 1279680\n",
      "    num_agent_steps_trained: 1279680\n",
      "    num_env_steps_sampled: 1279680\n",
      "    num_env_steps_trained: 1279680\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 1279680\n",
      "  num_agent_steps_trained: 1279680\n",
      "  num_env_steps_sampled: 1279680\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 1279680\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.53636363636365\n",
      "    ram_util_percent: 77.25000000000001\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12040484598231252\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5213457200038344\n",
      "    mean_inference_ms: 1.6055037353737003\n",
      "    mean_raw_obs_processing_ms: 0.1660421546952625\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -206864.16603588185\n",
      "    episode_reward_mean: -222091.1951210536\n",
      "    episode_reward_min: -253130.6172528566\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -232231.6009658099\n",
      "      - -225915.6250019571\n",
      "      - -219166.84648285905\n",
      "      - -228136.3162648505\n",
      "      - -216974.98051208013\n",
      "      - -218744.7418398235\n",
      "      - -218018.11601492445\n",
      "      - -218879.867110903\n",
      "      - -221073.99266693488\n",
      "      - -224484.0438996593\n",
      "      - -240224.48275483598\n",
      "      - -218661.19840399147\n",
      "      - -228050.5310308864\n",
      "      - -223868.8207178038\n",
      "      - -220157.4946118762\n",
      "      - -213899.08070353832\n",
      "      - -233022.65967728163\n",
      "      - -223833.05917240767\n",
      "      - -216952.89581691517\n",
      "      - -222086.91425455056\n",
      "      - -222674.2528827827\n",
      "      - -225696.00547378312\n",
      "      - -222226.01551251384\n",
      "      - -231039.03961477985\n",
      "      - -241779.53425617664\n",
      "      - -210637.02773507687\n",
      "      - -218581.92657154688\n",
      "      - -224907.21366821064\n",
      "      - -221540.369566765\n",
      "      - -240228.13951892342\n",
      "      - -221220.5624420774\n",
      "      - -225011.3976684097\n",
      "      - -212944.34268534768\n",
      "      - -220533.88224463904\n",
      "      - -215835.0074015492\n",
      "      - -212060.2523116284\n",
      "      - -224047.6624881274\n",
      "      - -225439.29566864984\n",
      "      - -240417.61213425893\n",
      "      - -231290.56617572778\n",
      "      - -222080.61231494986\n",
      "      - -222345.53254417065\n",
      "      - -211848.47365110222\n",
      "      - -215734.4420359949\n",
      "      - -219376.53391360442\n",
      "      - -213280.07716029306\n",
      "      - -206864.16603588185\n",
      "      - -214284.50105182003\n",
      "      - -215797.77801440816\n",
      "      - -222854.81816804895\n",
      "      - -216151.47195477693\n",
      "      - -218390.46382381508\n",
      "      - -223286.37439691433\n",
      "      - -231283.31384075273\n",
      "      - -219161.6278015172\n",
      "      - -221670.37135218826\n",
      "      - -221862.53353497403\n",
      "      - -218307.49513885964\n",
      "      - -221685.17255462048\n",
      "      - -221710.41276128913\n",
      "      - -213267.76115707215\n",
      "      - -212926.6021329643\n",
      "      - -229431.8329346113\n",
      "      - -232681.95232554336\n",
      "      - -219700.46148263421\n",
      "      - -222514.37751293174\n",
      "      - -213289.9779379304\n",
      "      - -224011.87231809812\n",
      "      - -225276.22656705137\n",
      "      - -215436.06143477937\n",
      "      - -221246.27295756698\n",
      "      - -212294.55350603894\n",
      "      - -223207.87878450757\n",
      "      - -253130.6172528566\n",
      "      - -217332.32660313483\n",
      "      - -214580.41183035928\n",
      "      - -224094.24191350202\n",
      "      - -213816.91634863487\n",
      "      - -224853.96322073037\n",
      "      - -221676.63692687947\n",
      "      - -220475.90414313704\n",
      "      - -217122.77698769406\n",
      "      - -216038.9069003958\n",
      "      - -225234.25890254625\n",
      "      - -226294.80954842255\n",
      "      - -223134.4133464146\n",
      "      - -227533.50369826885\n",
      "      - -211220.03920052276\n",
      "      - -217321.89737380703\n",
      "      - -219983.4944711657\n",
      "      - -217917.26522517082\n",
      "      - -218861.2739606914\n",
      "      - -228963.88554138425\n",
      "      - -221716.9800881643\n",
      "      - -222629.8403474449\n",
      "      - -216507.70515484252\n",
      "      - -222388.7426996444\n",
      "      - -237242.2458806649\n",
      "      - -227442.38626646233\n",
      "      - -225848.6912458438\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.12040484598231252\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5213457200038344\n",
      "      mean_inference_ms: 1.6055037353737003\n",
      "      mean_raw_obs_processing_ms: 0.1660421546952625\n",
      "  time_since_restore: 316.94159603118896\n",
      "  time_this_iter_s: 15.417771577835083\n",
      "  time_total_s: 316.94159603118896\n",
      "  timers:\n",
      "    learn_throughput: 24532.902\n",
      "    learn_time_ms: 2608.089\n",
      "    load_throughput: 382035.749\n",
      "    load_time_ms: 167.482\n",
      "    training_iteration_time_ms: 15696.873\n",
      "    update_time_ms: 5.034\n",
      "  timestamp: 1665742531\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1279680\n",
      "  training_iteration: 20\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:15:36 (running for 00:05:38.65)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         316.942</td><td style=\"text-align: right;\">1.27968e+06</td><td style=\"text-align: right;\"> -222091</td><td style=\"text-align: right;\">             -206864</td><td style=\"text-align: right;\">             -253131</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:15:41 (running for 00:05:43.66)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         316.942</td><td style=\"text-align: right;\">1.27968e+06</td><td style=\"text-align: right;\"> -222091</td><td style=\"text-align: right;\">             -206864</td><td style=\"text-align: right;\">             -253131</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:15:46 (running for 00:05:48.67)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         316.942</td><td style=\"text-align: right;\">1.27968e+06</td><td style=\"text-align: right;\"> -222091</td><td style=\"text-align: right;\">             -206864</td><td style=\"text-align: right;\">             -253131</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 1343664\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 1343664\n",
      "    num_agent_steps_trained: 1343664\n",
      "    num_env_steps_sampled: 1343664\n",
      "    num_env_steps_trained: 1343664\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-15-46\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -206904.46788823238\n",
      "  episode_reward_mean: -220359.1268907074\n",
      "  episode_reward_min: -253130.6172528566\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 1332\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.191218852996826\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.001985028851777315\n",
      "          model: {}\n",
      "          policy_loss: 0.00015871570212766528\n",
      "          total_loss: 10.000236511230469\n",
      "          vf_explained_var: 2.243885546704405e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 1343664\n",
      "    num_agent_steps_trained: 1343664\n",
      "    num_env_steps_sampled: 1343664\n",
      "    num_env_steps_trained: 1343664\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 1343664\n",
      "  num_agent_steps_trained: 1343664\n",
      "  num_env_steps_sampled: 1343664\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 1343664\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.1952380952381\n",
      "    ram_util_percent: 77.21428571428572\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11995901178412392\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5204364267626334\n",
      "    mean_inference_ms: 1.6030162927559797\n",
      "    mean_raw_obs_processing_ms: 0.16533056994950016\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -206904.46788823238\n",
      "    episode_reward_mean: -220359.1268907074\n",
      "    episode_reward_min: -253130.6172528566\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -213267.76115707215\n",
      "      - -212926.6021329643\n",
      "      - -229431.8329346113\n",
      "      - -232681.95232554336\n",
      "      - -219700.46148263421\n",
      "      - -222514.37751293174\n",
      "      - -213289.9779379304\n",
      "      - -224011.87231809812\n",
      "      - -225276.22656705137\n",
      "      - -215436.06143477937\n",
      "      - -221246.27295756698\n",
      "      - -212294.55350603894\n",
      "      - -223207.87878450757\n",
      "      - -253130.6172528566\n",
      "      - -217332.32660313483\n",
      "      - -214580.41183035928\n",
      "      - -224094.24191350202\n",
      "      - -213816.91634863487\n",
      "      - -224853.96322073037\n",
      "      - -221676.63692687947\n",
      "      - -220475.90414313704\n",
      "      - -217122.77698769406\n",
      "      - -216038.9069003958\n",
      "      - -225234.25890254625\n",
      "      - -226294.80954842255\n",
      "      - -223134.4133464146\n",
      "      - -227533.50369826885\n",
      "      - -211220.03920052276\n",
      "      - -217321.89737380703\n",
      "      - -219983.4944711657\n",
      "      - -217917.26522517082\n",
      "      - -218861.2739606914\n",
      "      - -228963.88554138425\n",
      "      - -221716.9800881643\n",
      "      - -222629.8403474449\n",
      "      - -216507.70515484252\n",
      "      - -222388.7426996444\n",
      "      - -237242.2458806649\n",
      "      - -227442.38626646233\n",
      "      - -225848.6912458438\n",
      "      - -233200.2463920074\n",
      "      - -218507.68233982692\n",
      "      - -215223.7646101547\n",
      "      - -220355.14910350202\n",
      "      - -230466.99510085527\n",
      "      - -215271.22929006896\n",
      "      - -214455.6627128298\n",
      "      - -221714.20112636386\n",
      "      - -206904.46788823238\n",
      "      - -236623.4448234356\n",
      "      - -214281.40707967867\n",
      "      - -229176.6445961386\n",
      "      - -216337.8767944506\n",
      "      - -215750.78351248652\n",
      "      - -223889.90413710193\n",
      "      - -223226.56630658082\n",
      "      - -219058.97077658278\n",
      "      - -210745.4314670837\n",
      "      - -214792.99617577076\n",
      "      - -225012.02537199153\n",
      "      - -217131.30225673612\n",
      "      - -218275.9316314158\n",
      "      - -214351.75140810595\n",
      "      - -226690.18277314937\n",
      "      - -225127.67279855284\n",
      "      - -216104.88208864038\n",
      "      - -223279.79742759178\n",
      "      - -228111.0351975244\n",
      "      - -216855.89922677277\n",
      "      - -216240.53550591736\n",
      "      - -215029.1267332667\n",
      "      - -230010.9108504519\n",
      "      - -214493.35600660025\n",
      "      - -218836.46144574543\n",
      "      - -215696.57414672864\n",
      "      - -218659.942422621\n",
      "      - -217930.01249907207\n",
      "      - -214207.98845798936\n",
      "      - -223607.4581851123\n",
      "      - -217701.25010435088\n",
      "      - -216123.06490119264\n",
      "      - -213803.94008797203\n",
      "      - -230248.69525007656\n",
      "      - -213582.00822325647\n",
      "      - -212401.35478733655\n",
      "      - -222485.5383190883\n",
      "      - -209296.8796508208\n",
      "      - -222841.8181933942\n",
      "      - -221820.13894261315\n",
      "      - -222323.01147974774\n",
      "      - -219567.04964415796\n",
      "      - -219088.04979904921\n",
      "      - -221886.19375226038\n",
      "      - -212676.01397857632\n",
      "      - -212539.96179503232\n",
      "      - -208280.77079080415\n",
      "      - -226299.99035091413\n",
      "      - -220549.64893449197\n",
      "      - -220113.6862014853\n",
      "      - -217997.38708646933\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11995901178412392\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5204364267626334\n",
      "      mean_inference_ms: 1.6030162927559797\n",
      "      mean_raw_obs_processing_ms: 0.16533056994950016\n",
      "  time_since_restore: 332.21718192100525\n",
      "  time_this_iter_s: 15.275585889816284\n",
      "  time_total_s: 332.21718192100525\n",
      "  timers:\n",
      "    learn_throughput: 24948.973\n",
      "    learn_time_ms: 2564.595\n",
      "    load_throughput: 382286.083\n",
      "    load_time_ms: 167.372\n",
      "    training_iteration_time_ms: 15647.141\n",
      "    update_time_ms: 5.22\n",
      "  timestamp: 1665742546\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1343664\n",
      "  training_iteration: 21\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:15:51 (running for 00:05:53.90)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         332.217</td><td style=\"text-align: right;\">1.34366e+06</td><td style=\"text-align: right;\"> -220359</td><td style=\"text-align: right;\">             -206904</td><td style=\"text-align: right;\">             -253131</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:15:56 (running for 00:05:58.97)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         332.217</td><td style=\"text-align: right;\">1.34366e+06</td><td style=\"text-align: right;\"> -220359</td><td style=\"text-align: right;\">             -206904</td><td style=\"text-align: right;\">             -253131</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:16:01 (running for 00:06:03.97)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         332.217</td><td style=\"text-align: right;\">1.34366e+06</td><td style=\"text-align: right;\"> -220359</td><td style=\"text-align: right;\">             -206904</td><td style=\"text-align: right;\">             -253131</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 1407648\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 1407648\n",
      "    num_agent_steps_trained: 1407648\n",
      "    num_env_steps_sampled: 1407648\n",
      "    num_env_steps_trained: 1407648\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-16-02\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -208280.77079080415\n",
      "  episode_reward_mean: -217911.39226143697\n",
      "  episode_reward_min: -233746.30378946685\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 1404\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1845169067382812\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0017836472252383828\n",
      "          model: {}\n",
      "          policy_loss: 0.003890256630256772\n",
      "          total_loss: 10.003929138183594\n",
      "          vf_explained_var: 2.8922006549692014e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 1407648\n",
      "    num_agent_steps_trained: 1407648\n",
      "    num_env_steps_sampled: 1407648\n",
      "    num_env_steps_trained: 1407648\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 1407648\n",
      "  num_agent_steps_trained: 1407648\n",
      "  num_env_steps_sampled: 1407648\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 1407648\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.30909090909091\n",
      "    ram_util_percent: 77.20909090909093\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.119771255128219\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5201275524611875\n",
      "    mean_inference_ms: 1.6019334403637973\n",
      "    mean_raw_obs_processing_ms: 0.16528739921091037\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -208280.77079080415\n",
      "    episode_reward_mean: -217911.39226143697\n",
      "    episode_reward_min: -233746.30378946685\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -214493.35600660025\n",
      "      - -218836.46144574543\n",
      "      - -215696.57414672864\n",
      "      - -218659.942422621\n",
      "      - -217930.01249907207\n",
      "      - -214207.98845798936\n",
      "      - -223607.4581851123\n",
      "      - -217701.25010435088\n",
      "      - -216123.06490119264\n",
      "      - -213803.94008797203\n",
      "      - -230248.69525007656\n",
      "      - -213582.00822325647\n",
      "      - -212401.35478733655\n",
      "      - -222485.5383190883\n",
      "      - -209296.8796508208\n",
      "      - -222841.8181933942\n",
      "      - -221820.13894261315\n",
      "      - -222323.01147974774\n",
      "      - -219567.04964415796\n",
      "      - -219088.04979904921\n",
      "      - -221886.19375226038\n",
      "      - -212676.01397857632\n",
      "      - -212539.96179503232\n",
      "      - -208280.77079080415\n",
      "      - -226299.99035091413\n",
      "      - -220549.64893449197\n",
      "      - -220113.6862014853\n",
      "      - -217997.38708646933\n",
      "      - -215078.5266495405\n",
      "      - -227711.5940137244\n",
      "      - -219934.78556303456\n",
      "      - -214512.67611037777\n",
      "      - -222431.2112210134\n",
      "      - -209349.67601311998\n",
      "      - -218575.980170977\n",
      "      - -214330.75384204974\n",
      "      - -223517.20492935428\n",
      "      - -225061.2831513955\n",
      "      - -220248.33260731414\n",
      "      - -222509.97547801494\n",
      "      - -215111.0358630494\n",
      "      - -209417.26594470357\n",
      "      - -224017.17760467358\n",
      "      - -222460.8940499802\n",
      "      - -219845.63999784042\n",
      "      - -225816.74913740458\n",
      "      - -216502.57850253538\n",
      "      - -213083.81800274263\n",
      "      - -214137.3985924723\n",
      "      - -211283.1654935625\n",
      "      - -223434.7158637615\n",
      "      - -214486.74077601792\n",
      "      - -220895.35110844992\n",
      "      - -214554.3811615856\n",
      "      - -215639.13294739168\n",
      "      - -215331.10118403452\n",
      "      - -213222.44778953944\n",
      "      - -215603.4832773538\n",
      "      - -216018.00426076105\n",
      "      - -219248.72258654324\n",
      "      - -221061.86148665348\n",
      "      - -226939.32373709668\n",
      "      - -208937.38231716826\n",
      "      - -214045.28351131643\n",
      "      - -213746.2508786317\n",
      "      - -222196.22168498978\n",
      "      - -217852.24871638647\n",
      "      - -212056.8362953481\n",
      "      - -213691.55059998177\n",
      "      - -221660.24146731055\n",
      "      - -223478.47936357296\n",
      "      - -210024.4010956724\n",
      "      - -214129.42306270005\n",
      "      - -215205.9106548499\n",
      "      - -218461.69478961613\n",
      "      - -214409.4459651877\n",
      "      - -209129.32184159005\n",
      "      - -218285.24325818225\n",
      "      - -221398.07925010004\n",
      "      - -218879.2152112446\n",
      "      - -226948.22451314935\n",
      "      - -222138.92894602308\n",
      "      - -219125.12248798416\n",
      "      - -211257.54328397562\n",
      "      - -218010.05532555908\n",
      "      - -218522.45538686984\n",
      "      - -210803.94070671982\n",
      "      - -221701.95012157038\n",
      "      - -214506.1468167713\n",
      "      - -216624.4798877863\n",
      "      - -217682.62737396458\n",
      "      - -217850.80559907455\n",
      "      - -210807.07259770756\n",
      "      - -232748.10859023442\n",
      "      - -219247.8573540437\n",
      "      - -217392.13904317663\n",
      "      - -233746.30378946685\n",
      "      - -214619.42841327848\n",
      "      - -223455.7592904903\n",
      "      - -209931.81209697\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.119771255128219\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5201275524611875\n",
      "      mean_inference_ms: 1.6019334403637973\n",
      "      mean_raw_obs_processing_ms: 0.16528739921091037\n",
      "  time_since_restore: 348.03418040275574\n",
      "  time_this_iter_s: 15.816998481750488\n",
      "  time_total_s: 348.03418040275574\n",
      "  timers:\n",
      "    learn_throughput: 24409.696\n",
      "    learn_time_ms: 2621.253\n",
      "    load_throughput: 381183.814\n",
      "    load_time_ms: 167.856\n",
      "    training_iteration_time_ms: 15665.349\n",
      "    update_time_ms: 5.084\n",
      "  timestamp: 1665742562\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1407648\n",
      "  training_iteration: 22\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:16:07 (running for 00:06:09.81)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         348.034</td><td style=\"text-align: right;\">1.40765e+06</td><td style=\"text-align: right;\"> -217911</td><td style=\"text-align: right;\">             -208281</td><td style=\"text-align: right;\">             -233746</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:16:12 (running for 00:06:14.82)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         348.034</td><td style=\"text-align: right;\">1.40765e+06</td><td style=\"text-align: right;\"> -217911</td><td style=\"text-align: right;\">             -208281</td><td style=\"text-align: right;\">             -233746</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:16:17 (running for 00:06:19.83)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         348.034</td><td style=\"text-align: right;\">1.40765e+06</td><td style=\"text-align: right;\"> -217911</td><td style=\"text-align: right;\">             -208281</td><td style=\"text-align: right;\">             -233746</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 1471632\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 1471632\n",
      "    num_agent_steps_trained: 1471632\n",
      "    num_env_steps_sampled: 1471632\n",
      "    num_env_steps_trained: 1471632\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-16-18\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -203584.0717492047\n",
      "  episode_reward_mean: -218907.16813429154\n",
      "  episode_reward_min: -268617.8982193841\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 1464\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.181027889251709\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.001777302473783493\n",
      "          model: {}\n",
      "          policy_loss: 0.0027620696928352118\n",
      "          total_loss: 10.002799034118652\n",
      "          vf_explained_var: 4.693636583397165e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 1471632\n",
      "    num_agent_steps_trained: 1471632\n",
      "    num_env_steps_sampled: 1471632\n",
      "    num_env_steps_trained: 1471632\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 1471632\n",
      "  num_agent_steps_trained: 1471632\n",
      "  num_env_steps_sampled: 1471632\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 1471632\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.88181818181819\n",
      "    ram_util_percent: 77.2681818181818\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11961331009069034\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5201179550704871\n",
      "    mean_inference_ms: 1.600924724573738\n",
      "    mean_raw_obs_processing_ms: 0.16516850610975273\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -203584.0717492047\n",
      "    episode_reward_mean: -218907.16813429154\n",
      "    episode_reward_min: -268617.8982193841\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -221061.86148665348\n",
      "      - -226939.32373709668\n",
      "      - -208937.38231716826\n",
      "      - -214045.28351131643\n",
      "      - -213746.2508786317\n",
      "      - -222196.22168498978\n",
      "      - -217852.24871638647\n",
      "      - -212056.8362953481\n",
      "      - -213691.55059998177\n",
      "      - -221660.24146731055\n",
      "      - -223478.47936357296\n",
      "      - -210024.4010956724\n",
      "      - -214129.42306270005\n",
      "      - -215205.9106548499\n",
      "      - -218461.69478961613\n",
      "      - -214409.4459651877\n",
      "      - -209129.32184159005\n",
      "      - -218285.24325818225\n",
      "      - -221398.07925010004\n",
      "      - -218879.2152112446\n",
      "      - -226948.22451314935\n",
      "      - -222138.92894602308\n",
      "      - -219125.12248798416\n",
      "      - -211257.54328397562\n",
      "      - -218010.05532555908\n",
      "      - -218522.45538686984\n",
      "      - -210803.94070671982\n",
      "      - -221701.95012157038\n",
      "      - -214506.1468167713\n",
      "      - -216624.4798877863\n",
      "      - -217682.62737396458\n",
      "      - -217850.80559907455\n",
      "      - -210807.07259770756\n",
      "      - -232748.10859023442\n",
      "      - -219247.8573540437\n",
      "      - -217392.13904317663\n",
      "      - -233746.30378946685\n",
      "      - -214619.42841327848\n",
      "      - -223455.7592904903\n",
      "      - -209931.81209697\n",
      "      - -219647.7123025072\n",
      "      - -213598.48902206283\n",
      "      - -216298.3631571674\n",
      "      - -219126.8328659966\n",
      "      - -211182.58742512338\n",
      "      - -216191.5881617501\n",
      "      - -268617.8982193841\n",
      "      - -239004.7442296115\n",
      "      - -219045.29742232317\n",
      "      - -223139.033989738\n",
      "      - -228593.49851642136\n",
      "      - -215457.80016207547\n",
      "      - -216186.74390872646\n",
      "      - -221723.22373900196\n",
      "      - -217118.62196290676\n",
      "      - -215494.19139933103\n",
      "      - -213758.80398713224\n",
      "      - -218056.54939596774\n",
      "      - -216543.65962033393\n",
      "      - -209236.1110642386\n",
      "      - -266031.71247158945\n",
      "      - -216619.2204133445\n",
      "      - -219116.19364144537\n",
      "      - -221114.753295593\n",
      "      - -209945.90035069108\n",
      "      - -216662.31704453242\n",
      "      - -214926.01221428247\n",
      "      - -218324.75857233096\n",
      "      - -241673.7347381245\n",
      "      - -238218.40108830668\n",
      "      - -216704.62146928973\n",
      "      - -216852.47793499345\n",
      "      - -219966.24679260718\n",
      "      - -210377.8504874584\n",
      "      - -221845.59442468864\n",
      "      - -215592.7447948207\n",
      "      - -219464.49138410352\n",
      "      - -211494.47541386436\n",
      "      - -217608.1114013544\n",
      "      - -231529.0120776122\n",
      "      - -212483.58165403313\n",
      "      - -212958.60639151113\n",
      "      - -212585.28928401842\n",
      "      - -221979.706874079\n",
      "      - -213706.0816424681\n",
      "      - -215418.48800230818\n",
      "      - -203584.0717492047\n",
      "      - -212321.0350128504\n",
      "      - -221438.21258452124\n",
      "      - -214691.28903972972\n",
      "      - -219608.1354008179\n",
      "      - -230081.8931504508\n",
      "      - -216925.95571165826\n",
      "      - -219020.26349936295\n",
      "      - -214819.41813163954\n",
      "      - -210227.8594327366\n",
      "      - -207268.40697323644\n",
      "      - -222224.78463960477\n",
      "      - -222055.23459716933\n",
      "      - -212518.94228250821\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11961331009069034\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5201179550704871\n",
      "      mean_inference_ms: 1.600924724573738\n",
      "      mean_raw_obs_processing_ms: 0.16516850610975273\n",
      "  time_since_restore: 363.7175590991974\n",
      "  time_this_iter_s: 15.68337869644165\n",
      "  time_total_s: 363.7175590991974\n",
      "  timers:\n",
      "    learn_throughput: 24308.518\n",
      "    learn_time_ms: 2632.164\n",
      "    load_throughput: 514403.851\n",
      "    load_time_ms: 124.385\n",
      "    training_iteration_time_ms: 15682.863\n",
      "    update_time_ms: 5.01\n",
      "  timestamp: 1665742578\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1471632\n",
      "  training_iteration: 23\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:16:23 (running for 00:06:25.47)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         363.718</td><td style=\"text-align: right;\">1.47163e+06</td><td style=\"text-align: right;\"> -218907</td><td style=\"text-align: right;\">             -203584</td><td style=\"text-align: right;\">             -268618</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:16:28 (running for 00:06:30.54)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         363.718</td><td style=\"text-align: right;\">1.47163e+06</td><td style=\"text-align: right;\"> -218907</td><td style=\"text-align: right;\">             -203584</td><td style=\"text-align: right;\">             -268618</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 1535616\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 1535616\n",
      "    num_agent_steps_trained: 1535616\n",
      "    num_env_steps_sampled: 1535616\n",
      "    num_env_steps_trained: 1535616\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-16-33\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -203483.51135324533\n",
      "  episode_reward_mean: -217412.39564396403\n",
      "  episode_reward_min: -266031.71247158945\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 1524\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1794049739837646\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0017912257462739944\n",
      "          model: {}\n",
      "          policy_loss: -0.0065317098051309586\n",
      "          total_loss: 9.993507385253906\n",
      "          vf_explained_var: 4.256230113242054e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 1535616\n",
      "    num_agent_steps_trained: 1535616\n",
      "    num_env_steps_sampled: 1535616\n",
      "    num_env_steps_trained: 1535616\n",
      "  iterations_since_restore: 24\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 1535616\n",
      "  num_agent_steps_trained: 1535616\n",
      "  num_env_steps_sampled: 1535616\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 1535616\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.49047619047619\n",
      "    ram_util_percent: 77.29999999999998\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11935129408360817\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5193558379793874\n",
      "    mean_inference_ms: 1.5987259217797904\n",
      "    mean_raw_obs_processing_ms: 0.16468604851260832\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -203483.51135324533\n",
      "    episode_reward_mean: -217412.39564396403\n",
      "    episode_reward_min: -266031.71247158945\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -266031.71247158945\n",
      "      - -216619.2204133445\n",
      "      - -219116.19364144537\n",
      "      - -221114.753295593\n",
      "      - -209945.90035069108\n",
      "      - -216662.31704453242\n",
      "      - -214926.01221428247\n",
      "      - -218324.75857233096\n",
      "      - -241673.7347381245\n",
      "      - -238218.40108830668\n",
      "      - -216704.62146928973\n",
      "      - -216852.47793499345\n",
      "      - -219966.24679260718\n",
      "      - -210377.8504874584\n",
      "      - -221845.59442468864\n",
      "      - -215592.7447948207\n",
      "      - -219464.49138410352\n",
      "      - -211494.47541386436\n",
      "      - -217608.1114013544\n",
      "      - -231529.0120776122\n",
      "      - -212483.58165403313\n",
      "      - -212958.60639151113\n",
      "      - -212585.28928401842\n",
      "      - -221979.706874079\n",
      "      - -213706.0816424681\n",
      "      - -215418.48800230818\n",
      "      - -203584.0717492047\n",
      "      - -212321.0350128504\n",
      "      - -221438.21258452124\n",
      "      - -214691.28903972972\n",
      "      - -219608.1354008179\n",
      "      - -230081.8931504508\n",
      "      - -216925.95571165826\n",
      "      - -219020.26349936295\n",
      "      - -214819.41813163954\n",
      "      - -210227.8594327366\n",
      "      - -207268.40697323644\n",
      "      - -222224.78463960477\n",
      "      - -222055.23459716933\n",
      "      - -212518.94228250821\n",
      "      - -212105.02408068895\n",
      "      - -213043.27177290837\n",
      "      - -214492.1776462857\n",
      "      - -218192.16849039248\n",
      "      - -219372.67110337282\n",
      "      - -220883.08617202134\n",
      "      - -218147.42636004894\n",
      "      - -222357.14220015847\n",
      "      - -210468.35819318815\n",
      "      - -258517.76538975126\n",
      "      - -206592.03199706814\n",
      "      - -219931.6578561814\n",
      "      - -215917.79598011935\n",
      "      - -214120.47450365342\n",
      "      - -213605.1808998287\n",
      "      - -217037.71615893362\n",
      "      - -217565.24841445344\n",
      "      - -219030.70140888344\n",
      "      - -216185.23394609807\n",
      "      - -208834.65265034852\n",
      "      - -207933.14670817237\n",
      "      - -214660.06452087077\n",
      "      - -219194.3136038953\n",
      "      - -211819.4680006794\n",
      "      - -211728.34704016798\n",
      "      - -221161.6736415666\n",
      "      - -231441.86644911606\n",
      "      - -215846.86756810755\n",
      "      - -211603.82926289947\n",
      "      - -209005.0309689932\n",
      "      - -213094.0683651138\n",
      "      - -212960.3808776652\n",
      "      - -214687.79756216606\n",
      "      - -212627.7031080806\n",
      "      - -210571.25331407142\n",
      "      - -216364.47554822642\n",
      "      - -220095.4191440931\n",
      "      - -218269.70331271854\n",
      "      - -221161.58775237395\n",
      "      - -214445.14473430996\n",
      "      - -217270.16977547645\n",
      "      - -217858.04014761036\n",
      "      - -213759.08551828875\n",
      "      - -210762.097920555\n",
      "      - -226700.10240544818\n",
      "      - -212886.18558252597\n",
      "      - -219533.75141172996\n",
      "      - -203483.51135324533\n",
      "      - -216485.08766754688\n",
      "      - -219991.2659741376\n",
      "      - -209033.07288777657\n",
      "      - -220240.70120624074\n",
      "      - -218042.5226170489\n",
      "      - -220458.12804046366\n",
      "      - -220079.6224290561\n",
      "      - -213594.31913191918\n",
      "      - -213206.62073252484\n",
      "      - -206939.76951107624\n",
      "      - -212898.31655745598\n",
      "      - -222959.38075366348\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11935129408360817\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5193558379793874\n",
      "      mean_inference_ms: 1.5987259217797904\n",
      "      mean_raw_obs_processing_ms: 0.16468604851260832\n",
      "  time_since_restore: 378.58330154418945\n",
      "  time_this_iter_s: 14.865742444992065\n",
      "  time_total_s: 378.58330154418945\n",
      "  timers:\n",
      "    learn_throughput: 24554.922\n",
      "    learn_time_ms: 2605.75\n",
      "    load_throughput: 513726.868\n",
      "    load_time_ms: 124.549\n",
      "    training_iteration_time_ms: 15618.723\n",
      "    update_time_ms: 4.998\n",
      "  timestamp: 1665742593\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1535616\n",
      "  training_iteration: 24\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:16:38 (running for 00:06:40.46)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         378.583</td><td style=\"text-align: right;\">1.53562e+06</td><td style=\"text-align: right;\"> -217412</td><td style=\"text-align: right;\">             -203484</td><td style=\"text-align: right;\">             -266032</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:16:43 (running for 00:06:45.53)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         378.583</td><td style=\"text-align: right;\">1.53562e+06</td><td style=\"text-align: right;\"> -217412</td><td style=\"text-align: right;\">             -203484</td><td style=\"text-align: right;\">             -266032</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:16:48 (running for 00:06:50.53)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         378.583</td><td style=\"text-align: right;\">1.53562e+06</td><td style=\"text-align: right;\"> -217412</td><td style=\"text-align: right;\">             -203484</td><td style=\"text-align: right;\">             -266032</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 1599600\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 1599600\n",
      "    num_agent_steps_trained: 1599600\n",
      "    num_env_steps_sampled: 1599600\n",
      "    num_env_steps_trained: 1599600\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-16-48\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -203483.51135324533\n",
      "  episode_reward_mean: -215152.4350974754\n",
      "  episode_reward_min: -226700.10240544818\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 1596\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1799964904785156\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.002160376636311412\n",
      "          model: {}\n",
      "          policy_loss: 0.0023466835264116526\n",
      "          total_loss: 10.002461433410645\n",
      "          vf_explained_var: 6.755040431016823e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 1599600\n",
      "    num_agent_steps_trained: 1599600\n",
      "    num_env_steps_sampled: 1599600\n",
      "    num_env_steps_trained: 1599600\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 1599600\n",
      "  num_agent_steps_trained: 1599600\n",
      "  num_env_steps_sampled: 1599600\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 1599600\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.34285714285714\n",
      "    ram_util_percent: 77.29999999999998\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11922862967832401\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5186725263067072\n",
      "    mean_inference_ms: 1.59761635772056\n",
      "    mean_raw_obs_processing_ms: 0.16451047482682365\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -203483.51135324533\n",
      "    episode_reward_mean: -215152.4350974754\n",
      "    episode_reward_min: -226700.10240544818\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -214687.79756216606\n",
      "      - -212627.7031080806\n",
      "      - -210571.25331407142\n",
      "      - -216364.47554822642\n",
      "      - -220095.4191440931\n",
      "      - -218269.70331271854\n",
      "      - -221161.58775237395\n",
      "      - -214445.14473430996\n",
      "      - -217270.16977547645\n",
      "      - -217858.04014761036\n",
      "      - -213759.08551828875\n",
      "      - -210762.097920555\n",
      "      - -226700.10240544818\n",
      "      - -212886.18558252597\n",
      "      - -219533.75141172996\n",
      "      - -203483.51135324533\n",
      "      - -216485.08766754688\n",
      "      - -219991.2659741376\n",
      "      - -209033.07288777657\n",
      "      - -220240.70120624074\n",
      "      - -218042.5226170489\n",
      "      - -220458.12804046366\n",
      "      - -220079.6224290561\n",
      "      - -213594.31913191918\n",
      "      - -213206.62073252484\n",
      "      - -206939.76951107624\n",
      "      - -212898.31655745598\n",
      "      - -222959.38075366348\n",
      "      - -218610.97740707587\n",
      "      - -217716.77699884662\n",
      "      - -219879.4473151341\n",
      "      - -215229.37282938475\n",
      "      - -219747.80830021857\n",
      "      - -213800.92140521543\n",
      "      - -210285.02861781072\n",
      "      - -215300.420950738\n",
      "      - -212136.04743552647\n",
      "      - -218118.69732263562\n",
      "      - -216890.92776143362\n",
      "      - -225741.50997335804\n",
      "      - -212178.87446173135\n",
      "      - -226336.11689279333\n",
      "      - -211019.97335771334\n",
      "      - -209511.8456067302\n",
      "      - -217999.20100096866\n",
      "      - -214699.3650916054\n",
      "      - -208747.51185146495\n",
      "      - -217677.5906486647\n",
      "      - -210078.3082046997\n",
      "      - -212043.91641330885\n",
      "      - -206637.3417476551\n",
      "      - -211310.02531647202\n",
      "      - -219604.94907000227\n",
      "      - -221973.89213840503\n",
      "      - -214716.98080096027\n",
      "      - -211894.01609453658\n",
      "      - -207577.21410891289\n",
      "      - -221983.64779088076\n",
      "      - -219074.04750506583\n",
      "      - -216657.15320987251\n",
      "      - -207521.49186105537\n",
      "      - -214971.96358380318\n",
      "      - -223634.17114964555\n",
      "      - -213769.77778620197\n",
      "      - -224325.15597371993\n",
      "      - -211697.5839743585\n",
      "      - -214521.3476539993\n",
      "      - -222303.98449589245\n",
      "      - -211608.00874566444\n",
      "      - -220414.3959617477\n",
      "      - -211998.04711386043\n",
      "      - -210781.87459601945\n",
      "      - -211456.68947662003\n",
      "      - -213922.32839176222\n",
      "      - -215062.63697717545\n",
      "      - -217416.20276571\n",
      "      - -215801.07300702823\n",
      "      - -210868.7908874307\n",
      "      - -209146.39821161772\n",
      "      - -219132.0631712433\n",
      "      - -207656.11147059692\n",
      "      - -221671.82773925498\n",
      "      - -217128.20940220018\n",
      "      - -214179.85881783985\n",
      "      - -213241.2540799109\n",
      "      - -212539.7426313374\n",
      "      - -210934.9138612738\n",
      "      - -214598.4554761202\n",
      "      - -213252.52479468245\n",
      "      - -210889.27992497027\n",
      "      - -209039.58060005654\n",
      "      - -214847.0228013886\n",
      "      - -215654.1416160287\n",
      "      - -215845.1573105068\n",
      "      - -215697.4786361025\n",
      "      - -212127.57513835264\n",
      "      - -212509.59619203387\n",
      "      - -211963.7192882847\n",
      "      - -216573.74063057732\n",
      "      - -214954.5898218118\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11922862967832401\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5186725263067072\n",
      "      mean_inference_ms: 1.59761635772056\n",
      "      mean_raw_obs_processing_ms: 0.16451047482682365\n",
      "  time_since_restore: 393.9073386192322\n",
      "  time_this_iter_s: 15.324037075042725\n",
      "  time_total_s: 393.9073386192322\n",
      "  timers:\n",
      "    learn_throughput: 24488.394\n",
      "    learn_time_ms: 2612.83\n",
      "    load_throughput: 516183.903\n",
      "    load_time_ms: 123.956\n",
      "    training_iteration_time_ms: 15564.25\n",
      "    update_time_ms: 4.96\n",
      "  timestamp: 1665742608\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1599600\n",
      "  training_iteration: 25\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:16:53 (running for 00:06:55.80)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         393.907</td><td style=\"text-align: right;\">1.5996e+06</td><td style=\"text-align: right;\"> -215152</td><td style=\"text-align: right;\">             -203484</td><td style=\"text-align: right;\">             -226700</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:16:58 (running for 00:07:00.80)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         393.907</td><td style=\"text-align: right;\">1.5996e+06</td><td style=\"text-align: right;\"> -215152</td><td style=\"text-align: right;\">             -203484</td><td style=\"text-align: right;\">             -226700</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:17:03 (running for 00:07:05.81)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         393.907</td><td style=\"text-align: right;\">1.5996e+06</td><td style=\"text-align: right;\"> -215152</td><td style=\"text-align: right;\">             -203484</td><td style=\"text-align: right;\">             -226700</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 1663584\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 1663584\n",
      "    num_agent_steps_trained: 1663584\n",
      "    num_env_steps_sampled: 1663584\n",
      "    num_env_steps_trained: 1663584\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-17-03\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -204604.37498847177\n",
      "  episode_reward_mean: -213916.82170201716\n",
      "  episode_reward_min: -226295.83599401484\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 1656\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.175508499145508\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0018832115456461906\n",
      "          model: {}\n",
      "          policy_loss: 0.005672579165548086\n",
      "          total_loss: 10.005730628967285\n",
      "          vf_explained_var: 6.556969310622662e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 1663584\n",
      "    num_agent_steps_trained: 1663584\n",
      "    num_env_steps_sampled: 1663584\n",
      "    num_env_steps_trained: 1663584\n",
      "  iterations_since_restore: 26\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 1663584\n",
      "  num_agent_steps_trained: 1663584\n",
      "  num_env_steps_sampled: 1663584\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 1663584\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 73.0\n",
      "    ram_util_percent: 77.39545454545454\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11901406814203934\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5189153506297355\n",
      "    mean_inference_ms: 1.595058226975625\n",
      "    mean_raw_obs_processing_ms: 0.16434570568042559\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -204604.37498847177\n",
      "    episode_reward_mean: -213916.82170201716\n",
      "    episode_reward_min: -226295.83599401484\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -207521.49186105537\n",
      "      - -214971.96358380318\n",
      "      - -223634.17114964555\n",
      "      - -213769.77778620197\n",
      "      - -224325.15597371993\n",
      "      - -211697.5839743585\n",
      "      - -214521.3476539993\n",
      "      - -222303.98449589245\n",
      "      - -211608.00874566444\n",
      "      - -220414.3959617477\n",
      "      - -211998.04711386043\n",
      "      - -210781.87459601945\n",
      "      - -211456.68947662003\n",
      "      - -213922.32839176222\n",
      "      - -215062.63697717545\n",
      "      - -217416.20276571\n",
      "      - -215801.07300702823\n",
      "      - -210868.7908874307\n",
      "      - -209146.39821161772\n",
      "      - -219132.0631712433\n",
      "      - -207656.11147059692\n",
      "      - -221671.82773925498\n",
      "      - -217128.20940220018\n",
      "      - -214179.85881783985\n",
      "      - -213241.2540799109\n",
      "      - -212539.7426313374\n",
      "      - -210934.9138612738\n",
      "      - -214598.4554761202\n",
      "      - -213252.52479468245\n",
      "      - -210889.27992497027\n",
      "      - -209039.58060005654\n",
      "      - -214847.0228013886\n",
      "      - -215654.1416160287\n",
      "      - -215845.1573105068\n",
      "      - -215697.4786361025\n",
      "      - -212127.57513835264\n",
      "      - -212509.59619203387\n",
      "      - -211963.7192882847\n",
      "      - -216573.74063057732\n",
      "      - -214954.5898218118\n",
      "      - -209268.88518461073\n",
      "      - -217752.4859742901\n",
      "      - -210940.4197546843\n",
      "      - -222880.54526864606\n",
      "      - -211954.9052189541\n",
      "      - -210897.1410328496\n",
      "      - -208397.9621629215\n",
      "      - -211871.42244355468\n",
      "      - -216153.13634244225\n",
      "      - -212245.88233664885\n",
      "      - -218040.4980192735\n",
      "      - -204604.37498847177\n",
      "      - -210347.55633350677\n",
      "      - -210495.98603332086\n",
      "      - -210671.0550063903\n",
      "      - -219811.08208856577\n",
      "      - -208824.6973795376\n",
      "      - -225022.0857635766\n",
      "      - -208606.03613585536\n",
      "      - -208861.38618820647\n",
      "      - -216637.72349837513\n",
      "      - -216320.48360989205\n",
      "      - -212660.24332337576\n",
      "      - -210740.92099128556\n",
      "      - -225523.7827155925\n",
      "      - -222926.9360852994\n",
      "      - -212259.6163196225\n",
      "      - -212321.82145763995\n",
      "      - -212667.85126371754\n",
      "      - -205968.2765966493\n",
      "      - -219812.57408561226\n",
      "      - -213444.21459436914\n",
      "      - -210298.6725208166\n",
      "      - -213042.06645773823\n",
      "      - -215024.5869650615\n",
      "      - -214701.90986977943\n",
      "      - -216173.2913946746\n",
      "      - -211542.78099175985\n",
      "      - -206324.9418880955\n",
      "      - -215769.86460751784\n",
      "      - -207556.5757233963\n",
      "      - -209180.42317716015\n",
      "      - -210942.0264921306\n",
      "      - -223466.36525365562\n",
      "      - -207720.44483398748\n",
      "      - -217300.50829280182\n",
      "      - -207439.40394509715\n",
      "      - -210312.70200077386\n",
      "      - -212203.10194241244\n",
      "      - -210677.93065903563\n",
      "      - -223182.58547472453\n",
      "      - -226295.83599401484\n",
      "      - -209964.94633109355\n",
      "      - -205906.85797120314\n",
      "      - -212612.87318837395\n",
      "      - -217939.87545033242\n",
      "      - -215864.16942818384\n",
      "      - -211197.61339758214\n",
      "      - -220371.6433528145\n",
      "      - -214077.41838187128\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11901406814203934\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5189153506297355\n",
      "      mean_inference_ms: 1.595058226975625\n",
      "      mean_raw_obs_processing_ms: 0.16434570568042559\n",
      "  time_since_restore: 408.9782691001892\n",
      "  time_this_iter_s: 15.070930480957031\n",
      "  time_total_s: 408.9782691001892\n",
      "  timers:\n",
      "    learn_throughput: 24592.523\n",
      "    learn_time_ms: 2601.766\n",
      "    load_throughput: 515689.845\n",
      "    load_time_ms: 124.075\n",
      "    training_iteration_time_ms: 15535.955\n",
      "    update_time_ms: 4.841\n",
      "  timestamp: 1665742623\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1663584\n",
      "  training_iteration: 26\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:17:08 (running for 00:07:10.94)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         408.978</td><td style=\"text-align: right;\">1.66358e+06</td><td style=\"text-align: right;\"> -213917</td><td style=\"text-align: right;\">             -204604</td><td style=\"text-align: right;\">             -226296</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:17:13 (running for 00:07:16.01)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         408.978</td><td style=\"text-align: right;\">1.66358e+06</td><td style=\"text-align: right;\"> -213917</td><td style=\"text-align: right;\">             -204604</td><td style=\"text-align: right;\">             -226296</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:17:18 (running for 00:07:21.08)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         408.978</td><td style=\"text-align: right;\">1.66358e+06</td><td style=\"text-align: right;\"> -213917</td><td style=\"text-align: right;\">             -204604</td><td style=\"text-align: right;\">             -226296</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 1727568\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 1727568\n",
      "    num_agent_steps_trained: 1727568\n",
      "    num_env_steps_sampled: 1727568\n",
      "    num_env_steps_trained: 1727568\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-17-18\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -203508.7106639694\n",
      "  episode_reward_mean: -216235.70762756775\n",
      "  episode_reward_min: -288091.98887724103\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 1716\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.166250228881836\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0023053523618727922\n",
      "          model: {}\n",
      "          policy_loss: 0.0020070646423846483\n",
      "          total_loss: 10.002152442932129\n",
      "          vf_explained_var: 1.1710020544342115e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 1727568\n",
      "    num_agent_steps_trained: 1727568\n",
      "    num_env_steps_sampled: 1727568\n",
      "    num_env_steps_trained: 1727568\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 1727568\n",
      "  num_agent_steps_trained: 1727568\n",
      "  num_env_steps_sampled: 1727568\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 1727568\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.26666666666667\n",
      "    ram_util_percent: 77.43809523809526\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11874537601698062\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.518494956703223\n",
      "    mean_inference_ms: 1.5936753707219642\n",
      "    mean_raw_obs_processing_ms: 0.16388133215192696\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -203508.7106639694\n",
      "    episode_reward_mean: -216235.70762756775\n",
      "    episode_reward_min: -288091.98887724103\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -216637.72349837513\n",
      "      - -216320.48360989205\n",
      "      - -212660.24332337576\n",
      "      - -210740.92099128556\n",
      "      - -225523.7827155925\n",
      "      - -222926.9360852994\n",
      "      - -212259.6163196225\n",
      "      - -212321.82145763995\n",
      "      - -212667.85126371754\n",
      "      - -205968.2765966493\n",
      "      - -219812.57408561226\n",
      "      - -213444.21459436914\n",
      "      - -210298.6725208166\n",
      "      - -213042.06645773823\n",
      "      - -215024.5869650615\n",
      "      - -214701.90986977943\n",
      "      - -216173.2913946746\n",
      "      - -211542.78099175985\n",
      "      - -206324.9418880955\n",
      "      - -215769.86460751784\n",
      "      - -207556.5757233963\n",
      "      - -209180.42317716015\n",
      "      - -210942.0264921306\n",
      "      - -223466.36525365562\n",
      "      - -207720.44483398748\n",
      "      - -217300.50829280182\n",
      "      - -207439.40394509715\n",
      "      - -210312.70200077386\n",
      "      - -212203.10194241244\n",
      "      - -210677.93065903563\n",
      "      - -223182.58547472453\n",
      "      - -226295.83599401484\n",
      "      - -209964.94633109355\n",
      "      - -205906.85797120314\n",
      "      - -212612.87318837395\n",
      "      - -217939.87545033242\n",
      "      - -215864.16942818384\n",
      "      - -211197.61339758214\n",
      "      - -220371.6433528145\n",
      "      - -214077.41838187128\n",
      "      - -215007.52607220446\n",
      "      - -222011.9909075595\n",
      "      - -214587.74845989293\n",
      "      - -210419.2833754408\n",
      "      - -210760.40959131898\n",
      "      - -210552.54918068793\n",
      "      - -231741.56489898593\n",
      "      - -214788.39877362014\n",
      "      - -213665.1777307969\n",
      "      - -212464.76608183671\n",
      "      - -221406.75927225023\n",
      "      - -212469.57624239213\n",
      "      - -214081.12722853047\n",
      "      - -211316.3828958901\n",
      "      - -210499.04507707607\n",
      "      - -213341.70649667553\n",
      "      - -213840.8224337964\n",
      "      - -210373.46234219256\n",
      "      - -215123.49584247448\n",
      "      - -214313.68339832657\n",
      "      - -215537.8892213295\n",
      "      - -210473.01065418037\n",
      "      - -208350.83056954975\n",
      "      - -211223.51166403043\n",
      "      - -214366.0274724617\n",
      "      - -209225.57065614228\n",
      "      - -214697.1403714418\n",
      "      - -221772.28745485333\n",
      "      - -206934.86162030627\n",
      "      - -216710.27669551372\n",
      "      - -214481.86281558077\n",
      "      - -214616.41333977645\n",
      "      - -214035.2005808363\n",
      "      - -213775.91665801633\n",
      "      - -210493.67727465378\n",
      "      - -210863.70316682121\n",
      "      - -203508.7106639694\n",
      "      - -210583.78007692247\n",
      "      - -213164.1569168806\n",
      "      - -213641.4098387904\n",
      "      - -209176.66876234513\n",
      "      - -213464.0962341872\n",
      "      - -223925.72157773643\n",
      "      - -219894.23817027346\n",
      "      - -214245.11283209227\n",
      "      - -213594.86396660935\n",
      "      - -210883.26648926397\n",
      "      - -212164.75561149887\n",
      "      - -211243.22840809665\n",
      "      - -213078.05410526932\n",
      "      - -207621.30123013406\n",
      "      - -212286.12258962129\n",
      "      - -222914.02689970203\n",
      "      - -246549.9824197189\n",
      "      - -282639.4477168296\n",
      "      - -217494.19092753343\n",
      "      - -209400.56937449187\n",
      "      - -278074.9756337217\n",
      "      - -288091.98887724103\n",
      "      - -217230.57638888442\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11874537601698062\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.518494956703223\n",
      "      mean_inference_ms: 1.5936753707219642\n",
      "      mean_raw_obs_processing_ms: 0.16388133215192696\n",
      "  time_since_restore: 424.30951857566833\n",
      "  time_this_iter_s: 15.331249475479126\n",
      "  time_total_s: 424.30951857566833\n",
      "  timers:\n",
      "    learn_throughput: 24847.349\n",
      "    learn_time_ms: 2575.084\n",
      "    load_throughput: 536569.821\n",
      "    load_time_ms: 119.246\n",
      "    training_iteration_time_ms: 15418.366\n",
      "    update_time_ms: 4.686\n",
      "  timestamp: 1665742638\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1727568\n",
      "  training_iteration: 27\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:17:24 (running for 00:07:26.26)<br>Memory usage on this node: 12.1/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">          424.31</td><td style=\"text-align: right;\">1.72757e+06</td><td style=\"text-align: right;\"> -216236</td><td style=\"text-align: right;\">             -203509</td><td style=\"text-align: right;\">             -288092</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:17:29 (running for 00:07:31.27)<br>Memory usage on this node: 12.1/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">          424.31</td><td style=\"text-align: right;\">1.72757e+06</td><td style=\"text-align: right;\"> -216236</td><td style=\"text-align: right;\">             -203509</td><td style=\"text-align: right;\">             -288092</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:17:34 (running for 00:07:36.27)<br>Memory usage on this node: 12.1/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">          424.31</td><td style=\"text-align: right;\">1.72757e+06</td><td style=\"text-align: right;\"> -216236</td><td style=\"text-align: right;\">             -203509</td><td style=\"text-align: right;\">             -288092</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 1791552\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 1791552\n",
      "    num_agent_steps_trained: 1791552\n",
      "    num_env_steps_sampled: 1791552\n",
      "    num_env_steps_trained: 1791552\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-17-34\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -203508.7106639694\n",
      "  episode_reward_mean: -216603.72533681185\n",
      "  episode_reward_min: -288091.98887724103\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 1788\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.160926342010498\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0024710926227271557\n",
      "          model: {}\n",
      "          policy_loss: 0.00858118012547493\n",
      "          total_loss: 10.008758544921875\n",
      "          vf_explained_var: 4.560213710647076e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 1791552\n",
      "    num_agent_steps_trained: 1791552\n",
      "    num_env_steps_sampled: 1791552\n",
      "    num_env_steps_trained: 1791552\n",
      "  iterations_since_restore: 28\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 1791552\n",
      "  num_agent_steps_trained: 1791552\n",
      "  num_env_steps_sampled: 1791552\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 1791552\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.94545454545454\n",
      "    ram_util_percent: 78.16818181818184\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11886540532414822\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5183427761987922\n",
      "    mean_inference_ms: 1.5939493558582591\n",
      "    mean_raw_obs_processing_ms: 0.16394204403831605\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -203508.7106639694\n",
      "    episode_reward_mean: -216603.72533681185\n",
      "    episode_reward_min: -288091.98887724103\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -214035.2005808363\n",
      "      - -213775.91665801633\n",
      "      - -210493.67727465378\n",
      "      - -210863.70316682121\n",
      "      - -203508.7106639694\n",
      "      - -210583.78007692247\n",
      "      - -213164.1569168806\n",
      "      - -213641.4098387904\n",
      "      - -209176.66876234513\n",
      "      - -213464.0962341872\n",
      "      - -223925.72157773643\n",
      "      - -219894.23817027346\n",
      "      - -214245.11283209227\n",
      "      - -213594.86396660935\n",
      "      - -210883.26648926397\n",
      "      - -212164.75561149887\n",
      "      - -211243.22840809665\n",
      "      - -213078.05410526932\n",
      "      - -207621.30123013406\n",
      "      - -212286.12258962129\n",
      "      - -222914.02689970203\n",
      "      - -246549.9824197189\n",
      "      - -282639.4477168296\n",
      "      - -217494.19092753343\n",
      "      - -209400.56937449187\n",
      "      - -278074.9756337217\n",
      "      - -288091.98887724103\n",
      "      - -217230.57638888442\n",
      "      - -221826.45502756123\n",
      "      - -212346.852882214\n",
      "      - -213710.83908090458\n",
      "      - -211933.96081489255\n",
      "      - -215965.5360330228\n",
      "      - -214228.19905116165\n",
      "      - -219138.66529560043\n",
      "      - -211613.58966326172\n",
      "      - -214348.5772784681\n",
      "      - -209101.06026148383\n",
      "      - -212776.0889066857\n",
      "      - -209649.52262666935\n",
      "      - -224492.7007544749\n",
      "      - -218235.87020752387\n",
      "      - -207869.10075544243\n",
      "      - -218926.92167207165\n",
      "      - -207780.65584569072\n",
      "      - -217518.09713350947\n",
      "      - -220992.26832121602\n",
      "      - -216459.5539547955\n",
      "      - -213605.23893011856\n",
      "      - -211947.5995017951\n",
      "      - -217829.83920362892\n",
      "      - -212873.23737322172\n",
      "      - -210258.21544324874\n",
      "      - -213875.7420863589\n",
      "      - -210698.68503802916\n",
      "      - -215148.01367401896\n",
      "      - -216067.73806164777\n",
      "      - -213664.78408065968\n",
      "      - -207095.1318407395\n",
      "      - -213252.32280764298\n",
      "      - -211190.6959675236\n",
      "      - -208359.63322122738\n",
      "      - -232970.23646338037\n",
      "      - -210910.43737782227\n",
      "      - -216301.0608023576\n",
      "      - -214938.01668828606\n",
      "      - -211983.41648291575\n",
      "      - -215859.10548630022\n",
      "      - -215789.38157033006\n",
      "      - -212775.32643064647\n",
      "      - -219873.28861750007\n",
      "      - -216082.63267315752\n",
      "      - -211741.3319136276\n",
      "      - -227998.1816442838\n",
      "      - -214995.3857029086\n",
      "      - -218250.33710149158\n",
      "      - -213952.95683167898\n",
      "      - -214433.55570579885\n",
      "      - -217294.92390893737\n",
      "      - -208852.98501674592\n",
      "      - -218001.11635163383\n",
      "      - -214850.0617386168\n",
      "      - -215698.5289613927\n",
      "      - -215803.9501544498\n",
      "      - -219151.22172974766\n",
      "      - -213585.69561947955\n",
      "      - -216262.87860725893\n",
      "      - -207811.690487137\n",
      "      - -208688.23200900826\n",
      "      - -216236.36219376975\n",
      "      - -213864.98293731958\n",
      "      - -216178.47303386248\n",
      "      - -213204.98587923014\n",
      "      - -210659.69346456486\n",
      "      - -217573.6457216577\n",
      "      - -209183.18300113018\n",
      "      - -209542.08882376904\n",
      "      - -209309.497361267\n",
      "      - -214622.1528807803\n",
      "      - -216320.39611828458\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11886540532414822\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5183427761987922\n",
      "      mean_inference_ms: 1.5939493558582591\n",
      "      mean_raw_obs_processing_ms: 0.16394204403831605\n",
      "  time_since_restore: 439.7650122642517\n",
      "  time_this_iter_s: 15.455493688583374\n",
      "  time_total_s: 439.7650122642517\n",
      "  timers:\n",
      "    learn_throughput: 25173.504\n",
      "    learn_time_ms: 2541.72\n",
      "    load_throughput: 536259.959\n",
      "    load_time_ms: 119.315\n",
      "    training_iteration_time_ms: 15327.102\n",
      "    update_time_ms: 4.617\n",
      "  timestamp: 1665742654\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1791552\n",
      "  training_iteration: 28\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:17:39 (running for 00:07:41.68)<br>Memory usage on this node: 12.1/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         439.765</td><td style=\"text-align: right;\">1.79155e+06</td><td style=\"text-align: right;\"> -216604</td><td style=\"text-align: right;\">             -203509</td><td style=\"text-align: right;\">             -288092</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:17:44 (running for 00:07:46.75)<br>Memory usage on this node: 12.1/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         439.765</td><td style=\"text-align: right;\">1.79155e+06</td><td style=\"text-align: right;\"> -216604</td><td style=\"text-align: right;\">             -203509</td><td style=\"text-align: right;\">             -288092</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:17:49 (running for 00:07:51.75)<br>Memory usage on this node: 12.1/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         439.765</td><td style=\"text-align: right;\">1.79155e+06</td><td style=\"text-align: right;\"> -216604</td><td style=\"text-align: right;\">             -203509</td><td style=\"text-align: right;\">             -288092</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 1855536\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 1855536\n",
      "    num_agent_steps_trained: 1855536\n",
      "    num_env_steps_sampled: 1855536\n",
      "    num_env_steps_trained: 1855536\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-17-50\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -204964.31745586454\n",
      "  episode_reward_mean: -216106.61426056348\n",
      "  episode_reward_min: -273775.92469949025\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 1848\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1628544330596924\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0020686069037765265\n",
      "          model: {}\n",
      "          policy_loss: 0.004060119390487671\n",
      "          total_loss: 10.004158020019531\n",
      "          vf_explained_var: 3.895851477864198e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 1855536\n",
      "    num_agent_steps_trained: 1855536\n",
      "    num_env_steps_sampled: 1855536\n",
      "    num_env_steps_trained: 1855536\n",
      "  iterations_since_restore: 29\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 1855536\n",
      "  num_agent_steps_trained: 1855536\n",
      "  num_env_steps_sampled: 1855536\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 1855536\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.31739130434781\n",
      "    ram_util_percent: 78.20434782608697\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11886516505257654\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5186918948302462\n",
      "    mean_inference_ms: 1.5949456837426044\n",
      "    mean_raw_obs_processing_ms: 0.1641643580871823\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -204964.31745586454\n",
      "    episode_reward_mean: -216106.61426056348\n",
      "    episode_reward_min: -273775.92469949025\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -211190.6959675236\n",
      "      - -208359.63322122738\n",
      "      - -232970.23646338037\n",
      "      - -210910.43737782227\n",
      "      - -216301.0608023576\n",
      "      - -214938.01668828606\n",
      "      - -211983.41648291575\n",
      "      - -215859.10548630022\n",
      "      - -215789.38157033006\n",
      "      - -212775.32643064647\n",
      "      - -219873.28861750007\n",
      "      - -216082.63267315752\n",
      "      - -211741.3319136276\n",
      "      - -227998.1816442838\n",
      "      - -214995.3857029086\n",
      "      - -218250.33710149158\n",
      "      - -213952.95683167898\n",
      "      - -214433.55570579885\n",
      "      - -217294.92390893737\n",
      "      - -208852.98501674592\n",
      "      - -218001.11635163383\n",
      "      - -214850.0617386168\n",
      "      - -215698.5289613927\n",
      "      - -215803.9501544498\n",
      "      - -219151.22172974766\n",
      "      - -213585.69561947955\n",
      "      - -216262.87860725893\n",
      "      - -207811.690487137\n",
      "      - -208688.23200900826\n",
      "      - -216236.36219376975\n",
      "      - -213864.98293731958\n",
      "      - -216178.47303386248\n",
      "      - -213204.98587923014\n",
      "      - -210659.69346456486\n",
      "      - -217573.6457216577\n",
      "      - -209183.18300113018\n",
      "      - -209542.08882376904\n",
      "      - -209309.497361267\n",
      "      - -214622.1528807803\n",
      "      - -216320.39611828458\n",
      "      - -273775.92469949025\n",
      "      - -210702.07843103094\n",
      "      - -229155.3795585492\n",
      "      - -221631.07255476012\n",
      "      - -209238.8407751488\n",
      "      - -212156.48495937343\n",
      "      - -212754.29793590328\n",
      "      - -221667.9581259782\n",
      "      - -227114.43840035246\n",
      "      - -204964.31745586454\n",
      "      - -221577.03720208668\n",
      "      - -220139.01768788835\n",
      "      - -217370.50066827555\n",
      "      - -214152.85313822227\n",
      "      - -213918.83836022383\n",
      "      - -212013.11171134858\n",
      "      - -207853.0012644907\n",
      "      - -212230.16923799866\n",
      "      - -207786.6780698045\n",
      "      - -205030.95294025066\n",
      "      - -214384.96263035893\n",
      "      - -219598.83642799896\n",
      "      - -215242.02832204913\n",
      "      - -210912.91658083705\n",
      "      - -214850.00880722614\n",
      "      - -213860.48191073933\n",
      "      - -211473.39850941516\n",
      "      - -211053.9615879992\n",
      "      - -210226.13520787196\n",
      "      - -223973.79702043615\n",
      "      - -213233.38130073267\n",
      "      - -210045.07474465595\n",
      "      - -213880.64003226292\n",
      "      - -215484.7527028429\n",
      "      - -211801.0685155853\n",
      "      - -211203.63000349846\n",
      "      - -209906.7135979487\n",
      "      - -225651.67164421323\n",
      "      - -214274.9796605123\n",
      "      - -219991.93365667624\n",
      "      - -215046.70439003676\n",
      "      - -218089.2728973555\n",
      "      - -215309.08050862123\n",
      "      - -213734.20392313204\n",
      "      - -218152.1498706914\n",
      "      - -212286.04219241632\n",
      "      - -215682.0999003381\n",
      "      - -207438.14254992464\n",
      "      - -212404.3093326953\n",
      "      - -212755.51178955968\n",
      "      - -209581.50505948626\n",
      "      - -235803.2875026628\n",
      "      - -213405.34534986707\n",
      "      - -220841.29623793624\n",
      "      - -218883.46801132744\n",
      "      - -209524.39619109727\n",
      "      - -216096.1666875476\n",
      "      - -265787.0462484535\n",
      "      - -227422.6772438833\n",
      "      - -215033.66744713282\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11886516505257654\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5186918948302462\n",
      "      mean_inference_ms: 1.5949456837426044\n",
      "      mean_raw_obs_processing_ms: 0.1641643580871823\n",
      "  time_since_restore: 456.0115041732788\n",
      "  time_this_iter_s: 16.2464919090271\n",
      "  time_total_s: 456.0115041732788\n",
      "  timers:\n",
      "    learn_throughput: 25170.437\n",
      "    learn_time_ms: 2542.03\n",
      "    load_throughput: 539530.491\n",
      "    load_time_ms: 118.592\n",
      "    training_iteration_time_ms: 15442.098\n",
      "    update_time_ms: 4.788\n",
      "  timestamp: 1665742670\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1855536\n",
      "  training_iteration: 29\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:17:55 (running for 00:07:58.03)<br>Memory usage on this node: 12.1/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         456.012</td><td style=\"text-align: right;\">1.85554e+06</td><td style=\"text-align: right;\"> -216107</td><td style=\"text-align: right;\">             -204964</td><td style=\"text-align: right;\">             -273776</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:18:00 (running for 00:08:03.03)<br>Memory usage on this node: 12.1/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         456.012</td><td style=\"text-align: right;\">1.85554e+06</td><td style=\"text-align: right;\"> -216107</td><td style=\"text-align: right;\">             -204964</td><td style=\"text-align: right;\">             -273776</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:18:05 (running for 00:08:08.04)<br>Memory usage on this node: 12.1/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         456.012</td><td style=\"text-align: right;\">1.85554e+06</td><td style=\"text-align: right;\"> -216107</td><td style=\"text-align: right;\">             -204964</td><td style=\"text-align: right;\">             -273776</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 1919520\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 1919520\n",
      "    num_agent_steps_trained: 1919520\n",
      "    num_env_steps_sampled: 1919520\n",
      "    num_env_steps_trained: 1919520\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-18-05\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -204367.46261826897\n",
      "  episode_reward_mean: -214423.18969880533\n",
      "  episode_reward_min: -265787.0462484535\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 1908\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1571688652038574\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0020385703537613153\n",
      "          model: {}\n",
      "          policy_loss: 0.001669418066740036\n",
      "          total_loss: 10.001760482788086\n",
      "          vf_explained_var: 4.54392284154892e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 1919520\n",
      "    num_agent_steps_trained: 1919520\n",
      "    num_env_steps_sampled: 1919520\n",
      "    num_env_steps_trained: 1919520\n",
      "  iterations_since_restore: 30\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 1919520\n",
      "  num_agent_steps_trained: 1919520\n",
      "  num_env_steps_sampled: 1919520\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 1919520\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.58571428571427\n",
      "    ram_util_percent: 78.20000000000002\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11876953582677817\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5180290566208727\n",
      "    mean_inference_ms: 1.5954524754362616\n",
      "    mean_raw_obs_processing_ms: 0.16403420904164914\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -204367.46261826897\n",
      "    episode_reward_mean: -214423.18969880533\n",
      "    episode_reward_min: -265787.0462484535\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -214384.96263035893\n",
      "      - -219598.83642799896\n",
      "      - -215242.02832204913\n",
      "      - -210912.91658083705\n",
      "      - -214850.00880722614\n",
      "      - -213860.48191073933\n",
      "      - -211473.39850941516\n",
      "      - -211053.9615879992\n",
      "      - -210226.13520787196\n",
      "      - -223973.79702043615\n",
      "      - -213233.38130073267\n",
      "      - -210045.07474465595\n",
      "      - -213880.64003226292\n",
      "      - -215484.7527028429\n",
      "      - -211801.0685155853\n",
      "      - -211203.63000349846\n",
      "      - -209906.7135979487\n",
      "      - -225651.67164421323\n",
      "      - -214274.9796605123\n",
      "      - -219991.93365667624\n",
      "      - -215046.70439003676\n",
      "      - -218089.2728973555\n",
      "      - -215309.08050862123\n",
      "      - -213734.20392313204\n",
      "      - -218152.1498706914\n",
      "      - -212286.04219241632\n",
      "      - -215682.0999003381\n",
      "      - -207438.14254992464\n",
      "      - -212404.3093326953\n",
      "      - -212755.51178955968\n",
      "      - -209581.50505948626\n",
      "      - -235803.2875026628\n",
      "      - -213405.34534986707\n",
      "      - -220841.29623793624\n",
      "      - -218883.46801132744\n",
      "      - -209524.39619109727\n",
      "      - -216096.1666875476\n",
      "      - -265787.0462484535\n",
      "      - -227422.6772438833\n",
      "      - -215033.66744713282\n",
      "      - -210180.55317626882\n",
      "      - -220884.5566871136\n",
      "      - -213825.89988510453\n",
      "      - -210630.24818652988\n",
      "      - -214465.16371886598\n",
      "      - -213060.9476545351\n",
      "      - -204367.46261826897\n",
      "      - -216527.69238997274\n",
      "      - -204727.12686485104\n",
      "      - -212253.48953123347\n",
      "      - -214568.1224765908\n",
      "      - -212931.59091346542\n",
      "      - -208556.08927443216\n",
      "      - -209381.68422052948\n",
      "      - -216851.37332765595\n",
      "      - -223165.59291065016\n",
      "      - -212169.37886352435\n",
      "      - -213707.56210470657\n",
      "      - -205822.83174902044\n",
      "      - -205494.35098547363\n",
      "      - -211323.3104923467\n",
      "      - -209645.851979348\n",
      "      - -211156.42320005898\n",
      "      - -224819.95043153965\n",
      "      - -214903.0704153954\n",
      "      - -219842.15620077445\n",
      "      - -216289.6314097941\n",
      "      - -212555.69473577768\n",
      "      - -212472.85868201737\n",
      "      - -209693.33237978758\n",
      "      - -211801.67328638321\n",
      "      - -212856.93165127994\n",
      "      - -214790.130882955\n",
      "      - -218870.2334925961\n",
      "      - -209046.1216209669\n",
      "      - -220856.85328737166\n",
      "      - -209848.39907731782\n",
      "      - -210073.3073918814\n",
      "      - -208820.66860236638\n",
      "      - -209001.95207751205\n",
      "      - -225372.7581796472\n",
      "      - -210750.6909744597\n",
      "      - -212795.5880509675\n",
      "      - -216187.7796420633\n",
      "      - -211847.4245749858\n",
      "      - -208560.6345208857\n",
      "      - -226820.06823057125\n",
      "      - -212028.63168226604\n",
      "      - -214920.78300393766\n",
      "      - -212202.42947831398\n",
      "      - -205679.11864207787\n",
      "      - -207802.4914872955\n",
      "      - -208803.04234115497\n",
      "      - -214996.7845713937\n",
      "      - -211944.0851780567\n",
      "      - -214414.50833530116\n",
      "      - -206915.4173661531\n",
      "      - -211674.33952344835\n",
      "      - -211580.58941263575\n",
      "      - -220454.7896506244\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11876953582677817\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5180290566208727\n",
      "      mean_inference_ms: 1.5954524754362616\n",
      "      mean_raw_obs_processing_ms: 0.16403420904164914\n",
      "  time_since_restore: 471.2512454986572\n",
      "  time_this_iter_s: 15.239741325378418\n",
      "  time_total_s: 471.2512454986572\n",
      "  timers:\n",
      "    learn_throughput: 25569.29\n",
      "    learn_time_ms: 2502.377\n",
      "    load_throughput: 538854.608\n",
      "    load_time_ms: 118.741\n",
      "    training_iteration_time_ms: 15424.032\n",
      "    update_time_ms: 4.673\n",
      "  timestamp: 1665742685\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1919520\n",
      "  training_iteration: 30\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:18:11 (running for 00:08:13.24)<br>Memory usage on this node: 12.1/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         471.251</td><td style=\"text-align: right;\">1.91952e+06</td><td style=\"text-align: right;\"> -214423</td><td style=\"text-align: right;\">             -204367</td><td style=\"text-align: right;\">             -265787</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:18:16 (running for 00:08:18.74)<br>Memory usage on this node: 12.1/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         471.251</td><td style=\"text-align: right;\">1.91952e+06</td><td style=\"text-align: right;\"> -214423</td><td style=\"text-align: right;\">             -204367</td><td style=\"text-align: right;\">             -265787</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 1983504\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 1983504\n",
      "    num_agent_steps_trained: 1983504\n",
      "    num_env_steps_sampled: 1983504\n",
      "    num_env_steps_trained: 1983504\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-18-21\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -205447.43054673067\n",
      "  episode_reward_mean: -213882.716355698\n",
      "  episode_reward_min: -260976.56690828517\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 1980\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.157827377319336\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0022739574778825045\n",
      "          model: {}\n",
      "          policy_loss: 0.006677048280835152\n",
      "          total_loss: 10.006815910339355\n",
      "          vf_explained_var: 1.2622430176634225e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 1983504\n",
      "    num_agent_steps_trained: 1983504\n",
      "    num_env_steps_sampled: 1983504\n",
      "    num_env_steps_trained: 1983504\n",
      "  iterations_since_restore: 31\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 1983504\n",
      "  num_agent_steps_trained: 1983504\n",
      "  num_env_steps_sampled: 1983504\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 1983504\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.04761904761905\n",
      "    ram_util_percent: 78.20952380952383\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11877475530601657\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5176860387640402\n",
      "    mean_inference_ms: 1.5955152518648703\n",
      "    mean_raw_obs_processing_ms: 0.16402684791263827\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -205447.43054673067\n",
      "    episode_reward_mean: -213882.716355698\n",
      "    episode_reward_min: -260976.56690828517\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -214790.130882955\n",
      "      - -218870.2334925961\n",
      "      - -209046.1216209669\n",
      "      - -220856.85328737166\n",
      "      - -209848.39907731782\n",
      "      - -210073.3073918814\n",
      "      - -208820.66860236638\n",
      "      - -209001.95207751205\n",
      "      - -225372.7581796472\n",
      "      - -210750.6909744597\n",
      "      - -212795.5880509675\n",
      "      - -216187.7796420633\n",
      "      - -211847.4245749858\n",
      "      - -208560.6345208857\n",
      "      - -226820.06823057125\n",
      "      - -212028.63168226604\n",
      "      - -214920.78300393766\n",
      "      - -212202.42947831398\n",
      "      - -205679.11864207787\n",
      "      - -207802.4914872955\n",
      "      - -208803.04234115497\n",
      "      - -214996.7845713937\n",
      "      - -211944.0851780567\n",
      "      - -214414.50833530116\n",
      "      - -206915.4173661531\n",
      "      - -211674.33952344835\n",
      "      - -211580.58941263575\n",
      "      - -220454.7896506244\n",
      "      - -212679.53932105785\n",
      "      - -215131.00504255953\n",
      "      - -218929.55034203353\n",
      "      - -214558.76373758187\n",
      "      - -208114.89524088713\n",
      "      - -215033.91228580903\n",
      "      - -212433.70220126465\n",
      "      - -212256.202881979\n",
      "      - -223606.2866194461\n",
      "      - -213899.1838765789\n",
      "      - -217754.36629374907\n",
      "      - -206605.32125886448\n",
      "      - -211997.2845338077\n",
      "      - -235856.03282944046\n",
      "      - -207373.23739591407\n",
      "      - -217333.77236732084\n",
      "      - -211674.45035123496\n",
      "      - -214541.7735078221\n",
      "      - -215781.78587336122\n",
      "      - -208538.64295879123\n",
      "      - -217149.86614018335\n",
      "      - -210883.76729615076\n",
      "      - -219220.38591981545\n",
      "      - -210429.73913391403\n",
      "      - -214143.83291228706\n",
      "      - -228045.351739451\n",
      "      - -218909.56714097442\n",
      "      - -209707.29248906954\n",
      "      - -215574.39232559566\n",
      "      - -215025.57807583592\n",
      "      - -211433.4100291378\n",
      "      - -209318.04438082495\n",
      "      - -211793.06304912065\n",
      "      - -210566.17859773128\n",
      "      - -206898.98569200613\n",
      "      - -216307.10566237423\n",
      "      - -211060.63136012657\n",
      "      - -216344.20728657063\n",
      "      - -209436.1561312488\n",
      "      - -205447.43054673067\n",
      "      - -207218.72691068877\n",
      "      - -217916.4833471474\n",
      "      - -207501.7454947584\n",
      "      - -213510.60396973294\n",
      "      - -223009.95770405952\n",
      "      - -214647.7386605934\n",
      "      - -223166.40814764056\n",
      "      - -210831.79243225168\n",
      "      - -212042.24575314717\n",
      "      - -215156.5836221231\n",
      "      - -211902.80331455456\n",
      "      - -214709.42831422362\n",
      "      - -213091.326132643\n",
      "      - -210106.01361589815\n",
      "      - -214685.1798407733\n",
      "      - -207870.96316035884\n",
      "      - -207729.37570682022\n",
      "      - -209373.3454003821\n",
      "      - -216365.95035898493\n",
      "      - -206438.40101112556\n",
      "      - -214550.17283136796\n",
      "      - -215488.35564954334\n",
      "      - -209265.21718841442\n",
      "      - -216018.71935418007\n",
      "      - -220768.47256406752\n",
      "      - -208473.26288902227\n",
      "      - -209478.34251268208\n",
      "      - -260976.56690828517\n",
      "      - -209739.71684568087\n",
      "      - -211672.27651176226\n",
      "      - -211011.0698328523\n",
      "      - -214700.07347617473\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11877475530601657\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5176860387640402\n",
      "      mean_inference_ms: 1.5955152518648703\n",
      "      mean_raw_obs_processing_ms: 0.16402684791263827\n",
      "  time_since_restore: 486.564350605011\n",
      "  time_this_iter_s: 15.31310510635376\n",
      "  time_total_s: 486.564350605011\n",
      "  timers:\n",
      "    learn_throughput: 25572.98\n",
      "    learn_time_ms: 2502.016\n",
      "    load_throughput: 540005.347\n",
      "    load_time_ms: 118.488\n",
      "    training_iteration_time_ms: 15427.656\n",
      "    update_time_ms: 4.348\n",
      "  timestamp: 1665742701\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 1983504\n",
      "  training_iteration: 31\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:18:26 (running for 00:08:28.89)<br>Memory usage on this node: 12.1/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         486.564</td><td style=\"text-align: right;\">1.9835e+06</td><td style=\"text-align: right;\"> -213883</td><td style=\"text-align: right;\">             -205447</td><td style=\"text-align: right;\">             -260977</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:18:31 (running for 00:08:33.90)<br>Memory usage on this node: 12.1/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         486.564</td><td style=\"text-align: right;\">1.9835e+06</td><td style=\"text-align: right;\"> -213883</td><td style=\"text-align: right;\">             -205447</td><td style=\"text-align: right;\">             -260977</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:18:36 (running for 00:08:39.13)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         486.564</td><td style=\"text-align: right;\">1.9835e+06</td><td style=\"text-align: right;\"> -213883</td><td style=\"text-align: right;\">             -205447</td><td style=\"text-align: right;\">             -260977</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 2047488\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 2047488\n",
      "    num_agent_steps_trained: 2047488\n",
      "    num_env_steps_sampled: 2047488\n",
      "    num_env_steps_trained: 2047488\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-18-37\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -205447.43054673067\n",
      "  episode_reward_mean: -214549.1910200332\n",
      "  episode_reward_min: -260976.56690828517\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 2040\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1592791080474854\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0017458065412938595\n",
      "          model: {}\n",
      "          policy_loss: 0.006505824625492096\n",
      "          total_loss: 10.006538391113281\n",
      "          vf_explained_var: 3.2908283174037933e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 2047488\n",
      "    num_agent_steps_trained: 2047488\n",
      "    num_env_steps_sampled: 2047488\n",
      "    num_env_steps_trained: 2047488\n",
      "  iterations_since_restore: 32\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 2047488\n",
      "  num_agent_steps_trained: 2047488\n",
      "  num_env_steps_sampled: 2047488\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 2047488\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 78.14782608695653\n",
      "    ram_util_percent: 78.05652173913043\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1187269711813684\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5175517803169967\n",
      "    mean_inference_ms: 1.595360603953782\n",
      "    mean_raw_obs_processing_ms: 0.16409893618480628\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -205447.43054673067\n",
      "    episode_reward_mean: -214549.1910200332\n",
      "    episode_reward_min: -260976.56690828517\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -211793.06304912065\n",
      "      - -210566.17859773128\n",
      "      - -206898.98569200613\n",
      "      - -216307.10566237423\n",
      "      - -211060.63136012657\n",
      "      - -216344.20728657063\n",
      "      - -209436.1561312488\n",
      "      - -205447.43054673067\n",
      "      - -207218.72691068877\n",
      "      - -217916.4833471474\n",
      "      - -207501.7454947584\n",
      "      - -213510.60396973294\n",
      "      - -223009.95770405952\n",
      "      - -214647.7386605934\n",
      "      - -223166.40814764056\n",
      "      - -210831.79243225168\n",
      "      - -212042.24575314717\n",
      "      - -215156.5836221231\n",
      "      - -211902.80331455456\n",
      "      - -214709.42831422362\n",
      "      - -213091.326132643\n",
      "      - -210106.01361589815\n",
      "      - -214685.1798407733\n",
      "      - -207870.96316035884\n",
      "      - -207729.37570682022\n",
      "      - -209373.3454003821\n",
      "      - -216365.95035898493\n",
      "      - -206438.40101112556\n",
      "      - -214550.17283136796\n",
      "      - -215488.35564954334\n",
      "      - -209265.21718841442\n",
      "      - -216018.71935418007\n",
      "      - -220768.47256406752\n",
      "      - -208473.26288902227\n",
      "      - -209478.34251268208\n",
      "      - -260976.56690828517\n",
      "      - -209739.71684568087\n",
      "      - -211672.27651176226\n",
      "      - -211011.0698328523\n",
      "      - -214700.07347617473\n",
      "      - -205880.12823266909\n",
      "      - -213682.62550541357\n",
      "      - -225754.0523387292\n",
      "      - -224824.18334469807\n",
      "      - -221328.9062071813\n",
      "      - -210785.56136776385\n",
      "      - -215605.27250062465\n",
      "      - -217728.47926160504\n",
      "      - -209086.62744522735\n",
      "      - -212630.92912173658\n",
      "      - -213451.91100228953\n",
      "      - -213246.03132025164\n",
      "      - -210198.8007675742\n",
      "      - -207295.63678775134\n",
      "      - -238009.92592021954\n",
      "      - -235696.04474074976\n",
      "      - -213427.48704490706\n",
      "      - -215065.39693679533\n",
      "      - -215058.2820038833\n",
      "      - -221361.2578171532\n",
      "      - -211622.2401093913\n",
      "      - -207810.423749094\n",
      "      - -211056.54147703305\n",
      "      - -211642.80545467837\n",
      "      - -212636.55329368077\n",
      "      - -211240.49451274655\n",
      "      - -214821.35876881523\n",
      "      - -216069.1311139135\n",
      "      - -216406.6893225414\n",
      "      - -218874.26292383188\n",
      "      - -210580.9761167224\n",
      "      - -213504.6799205813\n",
      "      - -214391.8061297985\n",
      "      - -220620.18855947588\n",
      "      - -208800.85447731582\n",
      "      - -206023.73668683344\n",
      "      - -214942.911727967\n",
      "      - -212482.23705195132\n",
      "      - -218599.1852853816\n",
      "      - -216706.5308787068\n",
      "      - -217142.4151663921\n",
      "      - -210552.75886586425\n",
      "      - -212159.22958149642\n",
      "      - -211560.54004002232\n",
      "      - -222005.10810007877\n",
      "      - -216201.0323196543\n",
      "      - -207653.14802710846\n",
      "      - -218258.23832454154\n",
      "      - -213921.62548233944\n",
      "      - -209466.714147493\n",
      "      - -209760.40897851004\n",
      "      - -223655.30796155846\n",
      "      - -224641.67812231334\n",
      "      - -215016.1610748519\n",
      "      - -217635.19088514269\n",
      "      - -219083.35498501715\n",
      "      - -211890.2949931506\n",
      "      - -208339.95769852382\n",
      "      - -217552.3180558326\n",
      "      - -212201.3941778992\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1187269711813684\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5175517803169967\n",
      "      mean_inference_ms: 1.595360603953782\n",
      "      mean_raw_obs_processing_ms: 0.16409893618480628\n",
      "  time_since_restore: 503.0980384349823\n",
      "  time_this_iter_s: 16.533687829971313\n",
      "  time_total_s: 503.0980384349823\n",
      "  timers:\n",
      "    learn_throughput: 25242.255\n",
      "    learn_time_ms: 2534.797\n",
      "    load_throughput: 540680.635\n",
      "    load_time_ms: 118.34\n",
      "    training_iteration_time_ms: 15499.552\n",
      "    update_time_ms: 4.467\n",
      "  timestamp: 1665742717\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2047488\n",
      "  training_iteration: 32\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:18:42 (running for 00:08:45.15)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">         503.098</td><td style=\"text-align: right;\">2.04749e+06</td><td style=\"text-align: right;\"> -214549</td><td style=\"text-align: right;\">             -205447</td><td style=\"text-align: right;\">             -260977</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:18:47 (running for 00:08:50.23)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">         503.098</td><td style=\"text-align: right;\">2.04749e+06</td><td style=\"text-align: right;\"> -214549</td><td style=\"text-align: right;\">             -205447</td><td style=\"text-align: right;\">             -260977</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:18:52 (running for 00:08:55.23)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">         503.098</td><td style=\"text-align: right;\">2.04749e+06</td><td style=\"text-align: right;\"> -214549</td><td style=\"text-align: right;\">             -205447</td><td style=\"text-align: right;\">             -260977</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 2111472\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 2111472\n",
      "    num_agent_steps_trained: 2111472\n",
      "    num_env_steps_sampled: 2111472\n",
      "    num_env_steps_trained: 2111472\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-18-53\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -205979.76762272144\n",
      "  episode_reward_mean: -215278.62090900243\n",
      "  episode_reward_min: -237251.03903564156\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 2100\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1565890312194824\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0018260887591168284\n",
      "          model: {}\n",
      "          policy_loss: 8.033215999603271e-05\n",
      "          total_loss: 10.000129699707031\n",
      "          vf_explained_var: -1.6996636986732483e-07\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 2111472\n",
      "    num_agent_steps_trained: 2111472\n",
      "    num_env_steps_sampled: 2111472\n",
      "    num_env_steps_trained: 2111472\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 2111472\n",
      "  num_agent_steps_trained: 2111472\n",
      "  num_env_steps_sampled: 2111472\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 2111472\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.72380952380952\n",
      "    ram_util_percent: 77.76666666666668\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11878749753715052\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5171570687092337\n",
      "    mean_inference_ms: 1.594899252717629\n",
      "    mean_raw_obs_processing_ms: 0.1638639126423497\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -205979.76762272144\n",
      "    episode_reward_mean: -215278.62090900243\n",
      "    episode_reward_min: -237251.03903564156\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -211622.2401093913\n",
      "      - -207810.423749094\n",
      "      - -211056.54147703305\n",
      "      - -211642.80545467837\n",
      "      - -212636.55329368077\n",
      "      - -211240.49451274655\n",
      "      - -214821.35876881523\n",
      "      - -216069.1311139135\n",
      "      - -216406.6893225414\n",
      "      - -218874.26292383188\n",
      "      - -210580.9761167224\n",
      "      - -213504.6799205813\n",
      "      - -214391.8061297985\n",
      "      - -220620.18855947588\n",
      "      - -208800.85447731582\n",
      "      - -206023.73668683344\n",
      "      - -214942.911727967\n",
      "      - -212482.23705195132\n",
      "      - -218599.1852853816\n",
      "      - -216706.5308787068\n",
      "      - -217142.4151663921\n",
      "      - -210552.75886586425\n",
      "      - -212159.22958149642\n",
      "      - -211560.54004002232\n",
      "      - -222005.10810007877\n",
      "      - -216201.0323196543\n",
      "      - -207653.14802710846\n",
      "      - -218258.23832454154\n",
      "      - -213921.62548233944\n",
      "      - -209466.714147493\n",
      "      - -209760.40897851004\n",
      "      - -223655.30796155846\n",
      "      - -224641.67812231334\n",
      "      - -215016.1610748519\n",
      "      - -217635.19088514269\n",
      "      - -219083.35498501715\n",
      "      - -211890.2949931506\n",
      "      - -208339.95769852382\n",
      "      - -217552.3180558326\n",
      "      - -212201.3941778992\n",
      "      - -209560.9545603848\n",
      "      - -208577.1040208064\n",
      "      - -227411.92290245925\n",
      "      - -217943.4258491212\n",
      "      - -217334.01700359202\n",
      "      - -216894.89606381208\n",
      "      - -219665.5740317074\n",
      "      - -213605.81625250238\n",
      "      - -213017.10070663437\n",
      "      - -210183.08860951645\n",
      "      - -214325.60449101662\n",
      "      - -213327.4337777937\n",
      "      - -220720.77059044948\n",
      "      - -216912.4434095209\n",
      "      - -212290.5474193574\n",
      "      - -214029.2511716886\n",
      "      - -226237.4309418626\n",
      "      - -220783.6807887787\n",
      "      - -228298.6860921746\n",
      "      - -209267.06237905106\n",
      "      - -210137.4890102101\n",
      "      - -213110.33890573154\n",
      "      - -237251.03903564156\n",
      "      - -213367.7585162705\n",
      "      - -211796.30824002385\n",
      "      - -220783.30739214498\n",
      "      - -214156.16178821182\n",
      "      - -213132.51912767952\n",
      "      - -229045.71786139748\n",
      "      - -217064.26289340833\n",
      "      - -224154.41578399943\n",
      "      - -209023.83092947138\n",
      "      - -215884.19077808523\n",
      "      - -210850.16795013446\n",
      "      - -216789.93089059024\n",
      "      - -222850.50302329718\n",
      "      - -213078.03460723496\n",
      "      - -211166.85390626083\n",
      "      - -215443.4591576683\n",
      "      - -206940.13023633105\n",
      "      - -210587.34919770542\n",
      "      - -210591.4207861896\n",
      "      - -232571.28804571196\n",
      "      - -212258.50869253767\n",
      "      - -222115.66346310065\n",
      "      - -214418.1971154467\n",
      "      - -212902.1009299374\n",
      "      - -212462.8700085501\n",
      "      - -217018.5633173401\n",
      "      - -216330.51569564774\n",
      "      - -218796.10081547705\n",
      "      - -219310.90971306534\n",
      "      - -205979.76762272144\n",
      "      - -209654.28437687168\n",
      "      - -219498.68806964677\n",
      "      - -208117.5099199293\n",
      "      - -224944.62166704726\n",
      "      - -211546.51324385314\n",
      "      - -216387.78212838742\n",
      "      - -208425.72044680806\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11878749753715052\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5171570687092337\n",
      "      mean_inference_ms: 1.594899252717629\n",
      "      mean_raw_obs_processing_ms: 0.1638639126423497\n",
      "  time_since_restore: 518.3773727416992\n",
      "  time_this_iter_s: 15.279334306716919\n",
      "  time_total_s: 518.3773727416992\n",
      "  timers:\n",
      "    learn_throughput: 25379.74\n",
      "    learn_time_ms: 2521.066\n",
      "    load_throughput: 541706.745\n",
      "    load_time_ms: 118.116\n",
      "    training_iteration_time_ms: 15459.415\n",
      "    update_time_ms: 4.48\n",
      "  timestamp: 1665742733\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2111472\n",
      "  training_iteration: 33\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:18:58 (running for 00:09:00.53)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         518.377</td><td style=\"text-align: right;\">2.11147e+06</td><td style=\"text-align: right;\"> -215279</td><td style=\"text-align: right;\">             -205980</td><td style=\"text-align: right;\">             -237251</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:19:03 (running for 00:09:05.53)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         518.377</td><td style=\"text-align: right;\">2.11147e+06</td><td style=\"text-align: right;\"> -215279</td><td style=\"text-align: right;\">             -205980</td><td style=\"text-align: right;\">             -237251</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:19:08 (running for 00:09:10.58)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         518.377</td><td style=\"text-align: right;\">2.11147e+06</td><td style=\"text-align: right;\"> -215279</td><td style=\"text-align: right;\">             -205980</td><td style=\"text-align: right;\">             -237251</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 2175456\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 2175456\n",
      "    num_agent_steps_trained: 2175456\n",
      "    num_env_steps_sampled: 2175456\n",
      "    num_env_steps_trained: 2175456\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-19-08\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -205979.540833765\n",
      "  episode_reward_mean: -215019.55175908087\n",
      "  episode_reward_min: -232571.28804571196\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 2172\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.156897783279419\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0017313743010163307\n",
      "          model: {}\n",
      "          policy_loss: 0.00723530538380146\n",
      "          total_loss: 10.0072660446167\n",
      "          vf_explained_var: 3.2168168218049686e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 2175456\n",
      "    num_agent_steps_trained: 2175456\n",
      "    num_env_steps_sampled: 2175456\n",
      "    num_env_steps_trained: 2175456\n",
      "  iterations_since_restore: 34\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 2175456\n",
      "  num_agent_steps_trained: 2175456\n",
      "  num_env_steps_sampled: 2175456\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 2175456\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.92857142857142\n",
      "    ram_util_percent: 77.66190476190475\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11892782502533214\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5168581544249624\n",
      "    mean_inference_ms: 1.5965683560425032\n",
      "    mean_raw_obs_processing_ms: 0.16384340694677169\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -205979.540833765\n",
      "    episode_reward_mean: -215019.55175908087\n",
      "    episode_reward_min: -232571.28804571196\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -215884.19077808523\n",
      "      - -210850.16795013446\n",
      "      - -216789.93089059024\n",
      "      - -222850.50302329718\n",
      "      - -213078.03460723496\n",
      "      - -211166.85390626083\n",
      "      - -215443.4591576683\n",
      "      - -206940.13023633105\n",
      "      - -210587.34919770542\n",
      "      - -210591.4207861896\n",
      "      - -232571.28804571196\n",
      "      - -212258.50869253767\n",
      "      - -222115.66346310065\n",
      "      - -214418.1971154467\n",
      "      - -212902.1009299374\n",
      "      - -212462.8700085501\n",
      "      - -217018.5633173401\n",
      "      - -216330.51569564774\n",
      "      - -218796.10081547705\n",
      "      - -219310.90971306534\n",
      "      - -205979.76762272144\n",
      "      - -209654.28437687168\n",
      "      - -219498.68806964677\n",
      "      - -208117.5099199293\n",
      "      - -224944.62166704726\n",
      "      - -211546.51324385314\n",
      "      - -216387.78212838742\n",
      "      - -208425.72044680806\n",
      "      - -223494.28647010005\n",
      "      - -214132.58893657185\n",
      "      - -218811.4970645048\n",
      "      - -211962.8696852102\n",
      "      - -211636.7458932841\n",
      "      - -221572.87511085157\n",
      "      - -221612.41010097283\n",
      "      - -211857.2670766802\n",
      "      - -210186.64210165854\n",
      "      - -217560.84118782185\n",
      "      - -218646.03075696516\n",
      "      - -215777.14874042387\n",
      "      - -206003.99640019413\n",
      "      - -228157.4335000421\n",
      "      - -212179.80987024785\n",
      "      - -215152.20606532643\n",
      "      - -211700.42406296707\n",
      "      - -219397.29668042614\n",
      "      - -219866.74916541355\n",
      "      - -216727.01886039216\n",
      "      - -211201.04213280036\n",
      "      - -214762.0421776646\n",
      "      - -212325.5092362318\n",
      "      - -219157.70103401595\n",
      "      - -211059.3492033108\n",
      "      - -210093.43823005643\n",
      "      - -206762.97291163885\n",
      "      - -220637.67692171506\n",
      "      - -215714.19169321997\n",
      "      - -217565.09131935937\n",
      "      - -212328.2946530301\n",
      "      - -213628.68142779582\n",
      "      - -209108.23694924486\n",
      "      - -225059.97006005456\n",
      "      - -211286.16013165654\n",
      "      - -215064.8445064271\n",
      "      - -210177.32162329333\n",
      "      - -207696.4212342447\n",
      "      - -210648.10616601194\n",
      "      - -210854.27366122164\n",
      "      - -205979.540833765\n",
      "      - -213826.58712423578\n",
      "      - -211331.26183335093\n",
      "      - -212312.988997193\n",
      "      - -211003.7047935003\n",
      "      - -213659.85575652932\n",
      "      - -220685.74548389472\n",
      "      - -213209.25857384154\n",
      "      - -216299.35723549305\n",
      "      - -217782.77876477342\n",
      "      - -210736.7681424834\n",
      "      - -220407.85155941092\n",
      "      - -206379.15431871294\n",
      "      - -212586.2015531089\n",
      "      - -221892.37231814145\n",
      "      - -214656.75106017766\n",
      "      - -215719.92994913997\n",
      "      - -224255.59018687689\n",
      "      - -207961.9076569616\n",
      "      - -210252.1308664918\n",
      "      - -219209.9869528847\n",
      "      - -211199.99002819185\n",
      "      - -218595.1697286655\n",
      "      - -226271.59060176468\n",
      "      - -211362.7139403632\n",
      "      - -218837.9121611647\n",
      "      - -221867.70856777186\n",
      "      - -216288.507514798\n",
      "      - -212960.45272615837\n",
      "      - -214433.8816860604\n",
      "      - -224952.40796757748\n",
      "      - -216546.0082159742\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11892782502533214\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5168581544249624\n",
      "      mean_inference_ms: 1.5965683560425032\n",
      "      mean_raw_obs_processing_ms: 0.16384340694677169\n",
      "  time_since_restore: 534.063022851944\n",
      "  time_this_iter_s: 15.685650110244751\n",
      "  time_total_s: 534.063022851944\n",
      "  timers:\n",
      "    learn_throughput: 25317.841\n",
      "    learn_time_ms: 2527.23\n",
      "    load_throughput: 541850.572\n",
      "    load_time_ms: 118.084\n",
      "    training_iteration_time_ms: 15541.51\n",
      "    update_time_ms: 4.44\n",
      "  timestamp: 1665742748\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2175456\n",
      "  training_iteration: 34\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:19:13 (running for 00:09:16.18)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         534.063</td><td style=\"text-align: right;\">2.17546e+06</td><td style=\"text-align: right;\"> -215020</td><td style=\"text-align: right;\">             -205980</td><td style=\"text-align: right;\">             -232571</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:19:19 (running for 00:09:21.34)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         534.063</td><td style=\"text-align: right;\">2.17546e+06</td><td style=\"text-align: right;\"> -215020</td><td style=\"text-align: right;\">             -205980</td><td style=\"text-align: right;\">             -232571</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 2239440\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 2239440\n",
      "    num_agent_steps_trained: 2239440\n",
      "    num_env_steps_sampled: 2239440\n",
      "    num_env_steps_trained: 2239440\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-19-23\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -205630.09020700658\n",
      "  episode_reward_mean: -214334.83340572123\n",
      "  episode_reward_min: -226271.59060176468\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 2232\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.156545877456665\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0018354773055762053\n",
      "          model: {}\n",
      "          policy_loss: 0.00602150522172451\n",
      "          total_loss: 10.006072998046875\n",
      "          vf_explained_var: 1.567881554365158e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 2239440\n",
      "    num_agent_steps_trained: 2239440\n",
      "    num_env_steps_sampled: 2239440\n",
      "    num_env_steps_trained: 2239440\n",
      "  iterations_since_restore: 35\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 2239440\n",
      "  num_agent_steps_trained: 2239440\n",
      "  num_env_steps_sampled: 2239440\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 2239440\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 72.22272727272727\n",
      "    ram_util_percent: 77.59999999999997\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11869789917457191\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5163807461662198\n",
      "    mean_inference_ms: 1.5952003393315493\n",
      "    mean_raw_obs_processing_ms: 0.16372270276886217\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -205630.09020700658\n",
      "    episode_reward_mean: -214334.83340572123\n",
      "    episode_reward_min: -226271.59060176468\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -209108.23694924486\n",
      "      - -225059.97006005456\n",
      "      - -211286.16013165654\n",
      "      - -215064.8445064271\n",
      "      - -210177.32162329333\n",
      "      - -207696.4212342447\n",
      "      - -210648.10616601194\n",
      "      - -210854.27366122164\n",
      "      - -205979.540833765\n",
      "      - -213826.58712423578\n",
      "      - -211331.26183335093\n",
      "      - -212312.988997193\n",
      "      - -211003.7047935003\n",
      "      - -213659.85575652932\n",
      "      - -220685.74548389472\n",
      "      - -213209.25857384154\n",
      "      - -216299.35723549305\n",
      "      - -217782.77876477342\n",
      "      - -210736.7681424834\n",
      "      - -220407.85155941092\n",
      "      - -206379.15431871294\n",
      "      - -212586.2015531089\n",
      "      - -221892.37231814145\n",
      "      - -214656.75106017766\n",
      "      - -215719.92994913997\n",
      "      - -224255.59018687689\n",
      "      - -207961.9076569616\n",
      "      - -210252.1308664918\n",
      "      - -219209.9869528847\n",
      "      - -211199.99002819185\n",
      "      - -218595.1697286655\n",
      "      - -226271.59060176468\n",
      "      - -211362.7139403632\n",
      "      - -218837.9121611647\n",
      "      - -221867.70856777186\n",
      "      - -216288.507514798\n",
      "      - -212960.45272615837\n",
      "      - -214433.8816860604\n",
      "      - -224952.40796757748\n",
      "      - -216546.0082159742\n",
      "      - -210418.5466932069\n",
      "      - -210610.2050133033\n",
      "      - -213176.73440335845\n",
      "      - -211901.70321064212\n",
      "      - -207390.62324653845\n",
      "      - -214984.27652989404\n",
      "      - -217411.7589029027\n",
      "      - -213024.89380617836\n",
      "      - -224362.4520551568\n",
      "      - -216575.1771354548\n",
      "      - -206742.35786392132\n",
      "      - -215247.44706843744\n",
      "      - -223138.36013525916\n",
      "      - -216613.42114875864\n",
      "      - -207369.83164818006\n",
      "      - -214199.50020176594\n",
      "      - -217056.66019344266\n",
      "      - -208296.89717246566\n",
      "      - -213814.30139816782\n",
      "      - -213924.79273788354\n",
      "      - -212466.6441307684\n",
      "      - -224884.74597870518\n",
      "      - -205630.09020700658\n",
      "      - -217719.15236080324\n",
      "      - -214660.07316495938\n",
      "      - -216069.80135535734\n",
      "      - -221307.6893873683\n",
      "      - -209372.80331659748\n",
      "      - -213123.40693570639\n",
      "      - -219644.81257364887\n",
      "      - -209259.76651143134\n",
      "      - -219545.76136077565\n",
      "      - -215725.4774183059\n",
      "      - -210400.68140027268\n",
      "      - -214714.1404039808\n",
      "      - -209176.4376780181\n",
      "      - -215772.82968265776\n",
      "      - -221096.03582509788\n",
      "      - -209546.80387672444\n",
      "      - -211036.9222025118\n",
      "      - -214578.69815789908\n",
      "      - -210715.26003499542\n",
      "      - -222849.7280336114\n",
      "      - -211337.22626397212\n",
      "      - -206299.42049098146\n",
      "      - -218016.50822695188\n",
      "      - -219047.02055238525\n",
      "      - -218433.12182546838\n",
      "      - -214243.90037779024\n",
      "      - -213387.55837995544\n",
      "      - -222598.87936059016\n",
      "      - -207349.54843513865\n",
      "      - -211311.30079833782\n",
      "      - -211122.39759670434\n",
      "      - -208710.11100133305\n",
      "      - -213224.22590146353\n",
      "      - -210430.47021297418\n",
      "      - -207600.27091806682\n",
      "      - -220822.24885005635\n",
      "      - -210630.0273862191\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11869789917457191\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5163807461662198\n",
      "      mean_inference_ms: 1.5952003393315493\n",
      "      mean_raw_obs_processing_ms: 0.16372270276886217\n",
      "  time_since_restore: 548.896333694458\n",
      "  time_this_iter_s: 14.833310842514038\n",
      "  time_total_s: 548.896333694458\n",
      "  timers:\n",
      "    learn_throughput: 25398.449\n",
      "    learn_time_ms: 2519.209\n",
      "    load_throughput: 540473.855\n",
      "    load_time_ms: 118.385\n",
      "    training_iteration_time_ms: 15492.456\n",
      "    update_time_ms: 4.434\n",
      "  timestamp: 1665742763\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2239440\n",
      "  training_iteration: 35\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:19:29 (running for 00:09:31.30)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         548.896</td><td style=\"text-align: right;\">2.23944e+06</td><td style=\"text-align: right;\"> -214335</td><td style=\"text-align: right;\">             -205630</td><td style=\"text-align: right;\">             -226272</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:19:34 (running for 00:09:36.37)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         548.896</td><td style=\"text-align: right;\">2.23944e+06</td><td style=\"text-align: right;\"> -214335</td><td style=\"text-align: right;\">             -205630</td><td style=\"text-align: right;\">             -226272</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 2303424\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 2303424\n",
      "    num_agent_steps_trained: 2303424\n",
      "    num_env_steps_sampled: 2303424\n",
      "    num_env_steps_trained: 2303424\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-19-38\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -205477.26945502078\n",
      "  episode_reward_mean: -213228.92035652723\n",
      "  episode_reward_min: -224884.74597870518\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 2292\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1513824462890625\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.001969194272533059\n",
      "          model: {}\n",
      "          policy_loss: -0.0005196034908294678\n",
      "          total_loss: 9.999558448791504\n",
      "          vf_explained_var: 2.6016496121883392e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 2303424\n",
      "    num_agent_steps_trained: 2303424\n",
      "    num_env_steps_sampled: 2303424\n",
      "    num_env_steps_trained: 2303424\n",
      "  iterations_since_restore: 36\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 2303424\n",
      "  num_agent_steps_trained: 2303424\n",
      "  num_env_steps_sampled: 2303424\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 2303424\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.245\n",
      "    ram_util_percent: 77.59999999999998\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11841931697526441\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5158435657277392\n",
      "    mean_inference_ms: 1.5935555555022103\n",
      "    mean_raw_obs_processing_ms: 0.16336907139999293\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -205477.26945502078\n",
      "    episode_reward_mean: -213228.92035652723\n",
      "    episode_reward_min: -224884.74597870518\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -212466.6441307684\n",
      "      - -224884.74597870518\n",
      "      - -205630.09020700658\n",
      "      - -217719.15236080324\n",
      "      - -214660.07316495938\n",
      "      - -216069.80135535734\n",
      "      - -221307.6893873683\n",
      "      - -209372.80331659748\n",
      "      - -213123.40693570639\n",
      "      - -219644.81257364887\n",
      "      - -209259.76651143134\n",
      "      - -219545.76136077565\n",
      "      - -215725.4774183059\n",
      "      - -210400.68140027268\n",
      "      - -214714.1404039808\n",
      "      - -209176.4376780181\n",
      "      - -215772.82968265776\n",
      "      - -221096.03582509788\n",
      "      - -209546.80387672444\n",
      "      - -211036.9222025118\n",
      "      - -214578.69815789908\n",
      "      - -210715.26003499542\n",
      "      - -222849.7280336114\n",
      "      - -211337.22626397212\n",
      "      - -206299.42049098146\n",
      "      - -218016.50822695188\n",
      "      - -219047.02055238525\n",
      "      - -218433.12182546838\n",
      "      - -214243.90037779024\n",
      "      - -213387.55837995544\n",
      "      - -222598.87936059016\n",
      "      - -207349.54843513865\n",
      "      - -211311.30079833782\n",
      "      - -211122.39759670434\n",
      "      - -208710.11100133305\n",
      "      - -213224.22590146353\n",
      "      - -210430.47021297418\n",
      "      - -207600.27091806682\n",
      "      - -220822.24885005635\n",
      "      - -210630.0273862191\n",
      "      - -214938.77600518052\n",
      "      - -208037.68221134244\n",
      "      - -214526.86896925117\n",
      "      - -212514.58296914856\n",
      "      - -205477.26945502078\n",
      "      - -206408.37930557065\n",
      "      - -212870.7569525151\n",
      "      - -211753.27607266864\n",
      "      - -209941.02367658378\n",
      "      - -214206.34321139596\n",
      "      - -216142.25655944622\n",
      "      - -208944.79375895206\n",
      "      - -214787.02111460807\n",
      "      - -205772.0403208531\n",
      "      - -219227.5161156781\n",
      "      - -211427.13397773923\n",
      "      - -217665.34016645045\n",
      "      - -218423.301017663\n",
      "      - -218644.75855519797\n",
      "      - -213088.12390274153\n",
      "      - -210281.35533905943\n",
      "      - -218576.76714164406\n",
      "      - -211785.3188529851\n",
      "      - -208394.32033148388\n",
      "      - -216909.77684806706\n",
      "      - -215290.0271272584\n",
      "      - -211691.50264817313\n",
      "      - -208730.00621676733\n",
      "      - -217982.02922511857\n",
      "      - -206447.53724372745\n",
      "      - -210429.84525818483\n",
      "      - -215808.74356193305\n",
      "      - -212571.44324417828\n",
      "      - -212632.30564754203\n",
      "      - -210891.7973156057\n",
      "      - -212685.04954663725\n",
      "      - -210071.7254930033\n",
      "      - -209987.97219232304\n",
      "      - -208206.97874336562\n",
      "      - -208872.33489662845\n",
      "      - -221229.82779465022\n",
      "      - -212311.72721278004\n",
      "      - -210767.27618584488\n",
      "      - -213936.56937450753\n",
      "      - -208801.35704451211\n",
      "      - -213706.0952650036\n",
      "      - -214888.4060709691\n",
      "      - -215370.54776985748\n",
      "      - -209088.7002007586\n",
      "      - -211905.72960244693\n",
      "      - -212944.37224881072\n",
      "      - -213408.0327958079\n",
      "      - -210410.61821574942\n",
      "      - -216721.9039147493\n",
      "      - -213789.2446905234\n",
      "      - -214539.12945956466\n",
      "      - -218907.59881132568\n",
      "      - -213800.4578858503\n",
      "      - -211556.8087423376\n",
      "      - -207901.55259939237\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11841931697526441\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5158435657277392\n",
      "      mean_inference_ms: 1.5935555555022103\n",
      "      mean_raw_obs_processing_ms: 0.16336907139999293\n",
      "  time_since_restore: 564.0534851551056\n",
      "  time_this_iter_s: 15.157151460647583\n",
      "  time_total_s: 564.0534851551056\n",
      "  timers:\n",
      "    learn_throughput: 25459.75\n",
      "    learn_time_ms: 2513.143\n",
      "    load_throughput: 534674.135\n",
      "    load_time_ms: 119.669\n",
      "    training_iteration_time_ms: 15501.148\n",
      "    update_time_ms: 4.421\n",
      "  timestamp: 1665742778\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2303424\n",
      "  training_iteration: 36\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:19:44 (running for 00:09:46.24)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         564.053</td><td style=\"text-align: right;\">2.30342e+06</td><td style=\"text-align: right;\"> -213229</td><td style=\"text-align: right;\">             -205477</td><td style=\"text-align: right;\">             -224885</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:19:49 (running for 00:09:51.42)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         564.053</td><td style=\"text-align: right;\">2.30342e+06</td><td style=\"text-align: right;\"> -213229</td><td style=\"text-align: right;\">             -205477</td><td style=\"text-align: right;\">             -224885</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 2367408\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 2367408\n",
      "    num_agent_steps_trained: 2367408\n",
      "    num_env_steps_sampled: 2367408\n",
      "    num_env_steps_trained: 2367408\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-19-53\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -204282.02535206903\n",
      "  episode_reward_mean: -213243.30789859593\n",
      "  episode_reward_min: -224305.92978500525\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 2364\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1467208862304688\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0019365899497643113\n",
      "          model: {}\n",
      "          policy_loss: 0.007180704269558191\n",
      "          total_loss: 10.00725269317627\n",
      "          vf_explained_var: 1.7840128521129373e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 2367408\n",
      "    num_agent_steps_trained: 2367408\n",
      "    num_env_steps_sampled: 2367408\n",
      "    num_env_steps_trained: 2367408\n",
      "  iterations_since_restore: 37\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 2367408\n",
      "  num_agent_steps_trained: 2367408\n",
      "  num_env_steps_sampled: 2367408\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 2367408\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.41904761904762\n",
      "    ram_util_percent: 77.70952380952383\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11853846021121567\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.515564321775322\n",
      "    mean_inference_ms: 1.5921207879005894\n",
      "    mean_raw_obs_processing_ms: 0.16343076376593907\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -204282.02535206903\n",
      "    episode_reward_mean: -213243.30789859593\n",
      "    episode_reward_min: -224305.92978500525\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -212571.44324417828\n",
      "      - -212632.30564754203\n",
      "      - -210891.7973156057\n",
      "      - -212685.04954663725\n",
      "      - -210071.7254930033\n",
      "      - -209987.97219232304\n",
      "      - -208206.97874336562\n",
      "      - -208872.33489662845\n",
      "      - -221229.82779465022\n",
      "      - -212311.72721278004\n",
      "      - -210767.27618584488\n",
      "      - -213936.56937450753\n",
      "      - -208801.35704451211\n",
      "      - -213706.0952650036\n",
      "      - -214888.4060709691\n",
      "      - -215370.54776985748\n",
      "      - -209088.7002007586\n",
      "      - -211905.72960244693\n",
      "      - -212944.37224881072\n",
      "      - -213408.0327958079\n",
      "      - -210410.61821574942\n",
      "      - -216721.9039147493\n",
      "      - -213789.2446905234\n",
      "      - -214539.12945956466\n",
      "      - -218907.59881132568\n",
      "      - -213800.4578858503\n",
      "      - -211556.8087423376\n",
      "      - -207901.55259939237\n",
      "      - -208431.5183513584\n",
      "      - -210653.23174419726\n",
      "      - -219513.1762757925\n",
      "      - -209450.85505313423\n",
      "      - -215181.27294210278\n",
      "      - -213632.16218869106\n",
      "      - -224305.92978500525\n",
      "      - -214929.30785692038\n",
      "      - -221412.95927319114\n",
      "      - -211827.29544491944\n",
      "      - -209920.67328964808\n",
      "      - -208067.71798842488\n",
      "      - -207398.24695423085\n",
      "      - -216176.09303327213\n",
      "      - -215448.1797215696\n",
      "      - -217351.74263395322\n",
      "      - -215234.53777676835\n",
      "      - -216689.50007952296\n",
      "      - -216907.12845206945\n",
      "      - -217910.3900783529\n",
      "      - -223031.3954780946\n",
      "      - -212061.19547490816\n",
      "      - -210720.50091596314\n",
      "      - -211377.5939593616\n",
      "      - -215357.45429738887\n",
      "      - -211909.09637816835\n",
      "      - -216591.36440734356\n",
      "      - -213026.53027041972\n",
      "      - -214184.90351552196\n",
      "      - -208573.7516207638\n",
      "      - -210107.1934738493\n",
      "      - -206986.19906281072\n",
      "      - -212805.13125097207\n",
      "      - -216823.38321513621\n",
      "      - -217064.03626057063\n",
      "      - -211786.07423106505\n",
      "      - -212831.27402927997\n",
      "      - -213330.1671384508\n",
      "      - -212692.08213370005\n",
      "      - -213982.66084018163\n",
      "      - -214062.68220758246\n",
      "      - -210775.92933676092\n",
      "      - -209810.81792264758\n",
      "      - -208158.0088764847\n",
      "      - -217938.9235721966\n",
      "      - -215935.17573048983\n",
      "      - -208704.59765558268\n",
      "      - -206596.77494589562\n",
      "      - -208917.42913029934\n",
      "      - -214982.7278428986\n",
      "      - -217894.63011553805\n",
      "      - -214213.52940806514\n",
      "      - -214818.375905009\n",
      "      - -215005.01700520923\n",
      "      - -218258.05907727862\n",
      "      - -214984.66972718836\n",
      "      - -213103.3053287769\n",
      "      - -208302.48108223968\n",
      "      - -210997.6239442601\n",
      "      - -210266.6470406032\n",
      "      - -213939.7499897015\n",
      "      - -211274.54986881453\n",
      "      - -223941.4686455765\n",
      "      - -204979.1255198577\n",
      "      - -219903.4247598453\n",
      "      - -216861.58904485693\n",
      "      - -219830.15173267687\n",
      "      - -208421.37913858338\n",
      "      - -213856.18068432013\n",
      "      - -215512.4279934174\n",
      "      - -210211.84143306967\n",
      "      - -204282.02535206903\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11853846021121567\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.515564321775322\n",
      "      mean_inference_ms: 1.5921207879005894\n",
      "      mean_raw_obs_processing_ms: 0.16343076376593907\n",
      "  time_since_restore: 578.8514094352722\n",
      "  time_this_iter_s: 14.797924280166626\n",
      "  time_total_s: 578.8514094352722\n",
      "  timers:\n",
      "    learn_throughput: 25552.865\n",
      "    learn_time_ms: 2503.985\n",
      "    load_throughput: 538113.943\n",
      "    load_time_ms: 118.904\n",
      "    training_iteration_time_ms: 15447.781\n",
      "    update_time_ms: 4.406\n",
      "  timestamp: 1665742793\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2367408\n",
      "  training_iteration: 37\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:19:59 (running for 00:10:01.40)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         578.851</td><td style=\"text-align: right;\">2.36741e+06</td><td style=\"text-align: right;\"> -213243</td><td style=\"text-align: right;\">             -204282</td><td style=\"text-align: right;\">             -224306</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:20:04 (running for 00:10:06.48)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         578.851</td><td style=\"text-align: right;\">2.36741e+06</td><td style=\"text-align: right;\"> -213243</td><td style=\"text-align: right;\">             -204282</td><td style=\"text-align: right;\">             -224306</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 2431392\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 2431392\n",
      "    num_agent_steps_trained: 2431392\n",
      "    num_env_steps_sampled: 2431392\n",
      "    num_env_steps_trained: 2431392\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-20-09\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -203027.07746725224\n",
      "  episode_reward_mean: -213516.52507259604\n",
      "  episode_reward_min: -242226.89677700918\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 2424\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.140758991241455\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0019217245280742645\n",
      "          model: {}\n",
      "          policy_loss: 0.0057186828926205635\n",
      "          total_loss: 10.005788803100586\n",
      "          vf_explained_var: 1.977197825908661e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 2431392\n",
      "    num_agent_steps_trained: 2431392\n",
      "    num_env_steps_sampled: 2431392\n",
      "    num_env_steps_trained: 2431392\n",
      "  iterations_since_restore: 38\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 2431392\n",
      "  num_agent_steps_trained: 2431392\n",
      "  num_env_steps_sampled: 2431392\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 2431392\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.19047619047619\n",
      "    ram_util_percent: 77.70000000000002\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1184323014144466\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5150969100795971\n",
      "    mean_inference_ms: 1.5918840522932658\n",
      "    mean_raw_obs_processing_ms: 0.16333390603464665\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -203027.07746725224\n",
      "    episode_reward_mean: -213516.52507259604\n",
      "    episode_reward_min: -242226.89677700918\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -212805.13125097207\n",
      "      - -216823.38321513621\n",
      "      - -217064.03626057063\n",
      "      - -211786.07423106505\n",
      "      - -212831.27402927997\n",
      "      - -213330.1671384508\n",
      "      - -212692.08213370005\n",
      "      - -213982.66084018163\n",
      "      - -214062.68220758246\n",
      "      - -210775.92933676092\n",
      "      - -209810.81792264758\n",
      "      - -208158.0088764847\n",
      "      - -217938.9235721966\n",
      "      - -215935.17573048983\n",
      "      - -208704.59765558268\n",
      "      - -206596.77494589562\n",
      "      - -208917.42913029934\n",
      "      - -214982.7278428986\n",
      "      - -217894.63011553805\n",
      "      - -214213.52940806514\n",
      "      - -214818.375905009\n",
      "      - -215005.01700520923\n",
      "      - -218258.05907727862\n",
      "      - -214984.66972718836\n",
      "      - -213103.3053287769\n",
      "      - -208302.48108223968\n",
      "      - -210997.6239442601\n",
      "      - -210266.6470406032\n",
      "      - -213939.7499897015\n",
      "      - -211274.54986881453\n",
      "      - -223941.4686455765\n",
      "      - -204979.1255198577\n",
      "      - -219903.4247598453\n",
      "      - -216861.58904485693\n",
      "      - -219830.15173267687\n",
      "      - -208421.37913858338\n",
      "      - -213856.18068432013\n",
      "      - -215512.4279934174\n",
      "      - -210211.84143306967\n",
      "      - -204282.02535206903\n",
      "      - -217656.67767798493\n",
      "      - -213861.83393868682\n",
      "      - -217454.53337277193\n",
      "      - -223993.53978839534\n",
      "      - -216834.44919291555\n",
      "      - -209629.52072150604\n",
      "      - -215891.03140242575\n",
      "      - -220415.345187668\n",
      "      - -204579.31150202875\n",
      "      - -205281.30748505096\n",
      "      - -214234.60392747607\n",
      "      - -213480.4715371111\n",
      "      - -209925.49446503114\n",
      "      - -215582.19430544646\n",
      "      - -213976.95761309096\n",
      "      - -220906.72640412702\n",
      "      - -210983.2503260844\n",
      "      - -210255.3711419327\n",
      "      - -218035.99942972214\n",
      "      - -205589.84774236928\n",
      "      - -214183.6941975593\n",
      "      - -211977.34065835451\n",
      "      - -214773.14053020472\n",
      "      - -211172.3311012251\n",
      "      - -209824.04423488706\n",
      "      - -214647.15320122143\n",
      "      - -212737.12678147687\n",
      "      - -212761.72690538477\n",
      "      - -216425.82218281832\n",
      "      - -205918.76064193225\n",
      "      - -209219.1933020695\n",
      "      - -216258.293692775\n",
      "      - -211072.68082332413\n",
      "      - -203678.57672756672\n",
      "      - -212180.10889692625\n",
      "      - -216694.14097558116\n",
      "      - -209909.6090087697\n",
      "      - -215639.5206190662\n",
      "      - -242226.89677700918\n",
      "      - -215066.37198651826\n",
      "      - -216361.45912491123\n",
      "      - -220547.4454823887\n",
      "      - -212496.3955701889\n",
      "      - -215468.11711281145\n",
      "      - -215282.05154730834\n",
      "      - -214531.92242926435\n",
      "      - -209933.85388026314\n",
      "      - -212382.29150789007\n",
      "      - -217371.77071093654\n",
      "      - -211499.47459791467\n",
      "      - -215294.72494508923\n",
      "      - -213776.9090765006\n",
      "      - -206475.57997790218\n",
      "      - -216998.32440367353\n",
      "      - -206341.44102853787\n",
      "      - -214462.62262860383\n",
      "      - -213076.38069296768\n",
      "      - -223100.70133305984\n",
      "      - -210232.8342184961\n",
      "      - -203027.07746725224\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1184323014144466\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5150969100795971\n",
      "      mean_inference_ms: 1.5918840522932658\n",
      "      mean_raw_obs_processing_ms: 0.16333390603464665\n",
      "  time_since_restore: 594.3934872150421\n",
      "  time_this_iter_s: 15.542077779769897\n",
      "  time_total_s: 594.3934872150421\n",
      "  timers:\n",
      "    learn_throughput: 25670.358\n",
      "    learn_time_ms: 2492.525\n",
      "    load_throughput: 537592.649\n",
      "    load_time_ms: 119.019\n",
      "    training_iteration_time_ms: 15456.437\n",
      "    update_time_ms: 4.44\n",
      "  timestamp: 1665742809\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2431392\n",
      "  training_iteration: 38\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:20:09 (running for 00:10:11.64)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">         594.393</td><td style=\"text-align: right;\">2.43139e+06</td><td style=\"text-align: right;\"> -213517</td><td style=\"text-align: right;\">             -203027</td><td style=\"text-align: right;\">             -242227</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:20:14 (running for 00:10:16.71)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">         594.393</td><td style=\"text-align: right;\">2.43139e+06</td><td style=\"text-align: right;\"> -213517</td><td style=\"text-align: right;\">             -203027</td><td style=\"text-align: right;\">             -242227</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:20:19 (running for 00:10:21.93)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">         594.393</td><td style=\"text-align: right;\">2.43139e+06</td><td style=\"text-align: right;\"> -213517</td><td style=\"text-align: right;\">             -203027</td><td style=\"text-align: right;\">             -242227</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 2495376\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 2495376\n",
      "    num_agent_steps_trained: 2495376\n",
      "    num_env_steps_sampled: 2495376\n",
      "    num_env_steps_trained: 2495376\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-20-24\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -203027.07746725224\n",
      "  episode_reward_mean: -212835.43683733037\n",
      "  episode_reward_min: -246035.45101386987\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 2484\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1340737342834473\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0017944342689588666\n",
      "          model: {}\n",
      "          policy_loss: 0.0023200977593660355\n",
      "          total_loss: 10.00236701965332\n",
      "          vf_explained_var: 1.0943040251731873e-07\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 2495376\n",
      "    num_agent_steps_trained: 2495376\n",
      "    num_env_steps_sampled: 2495376\n",
      "    num_env_steps_trained: 2495376\n",
      "  iterations_since_restore: 39\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 2495376\n",
      "  num_agent_steps_trained: 2495376\n",
      "  num_env_steps_sampled: 2495376\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 2495376\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 73.45909090909089\n",
      "    ram_util_percent: 77.73636363636365\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1182022061378361\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5148279965535439\n",
      "    mean_inference_ms: 1.5915131958751432\n",
      "    mean_raw_obs_processing_ms: 0.1629433001445607\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -203027.07746725224\n",
      "    episode_reward_mean: -212835.43683733037\n",
      "    episode_reward_min: -246035.45101386987\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -214183.6941975593\n",
      "      - -211977.34065835451\n",
      "      - -214773.14053020472\n",
      "      - -211172.3311012251\n",
      "      - -209824.04423488706\n",
      "      - -214647.15320122143\n",
      "      - -212737.12678147687\n",
      "      - -212761.72690538477\n",
      "      - -216425.82218281832\n",
      "      - -205918.76064193225\n",
      "      - -209219.1933020695\n",
      "      - -216258.293692775\n",
      "      - -211072.68082332413\n",
      "      - -203678.57672756672\n",
      "      - -212180.10889692625\n",
      "      - -216694.14097558116\n",
      "      - -209909.6090087697\n",
      "      - -215639.5206190662\n",
      "      - -242226.89677700918\n",
      "      - -215066.37198651826\n",
      "      - -216361.45912491123\n",
      "      - -220547.4454823887\n",
      "      - -212496.3955701889\n",
      "      - -215468.11711281145\n",
      "      - -215282.05154730834\n",
      "      - -214531.92242926435\n",
      "      - -209933.85388026314\n",
      "      - -212382.29150789007\n",
      "      - -217371.77071093654\n",
      "      - -211499.47459791467\n",
      "      - -215294.72494508923\n",
      "      - -213776.9090765006\n",
      "      - -206475.57997790218\n",
      "      - -216998.32440367353\n",
      "      - -206341.44102853787\n",
      "      - -214462.62262860383\n",
      "      - -213076.38069296768\n",
      "      - -223100.70133305984\n",
      "      - -210232.8342184961\n",
      "      - -203027.07746725224\n",
      "      - -212663.28338787673\n",
      "      - -207509.98583933077\n",
      "      - -214471.54605402803\n",
      "      - -211169.5888126829\n",
      "      - -212706.94981363387\n",
      "      - -211110.83540242817\n",
      "      - -214746.12064388092\n",
      "      - -207911.79885858053\n",
      "      - -214095.3821715501\n",
      "      - -209884.44067050357\n",
      "      - -209904.57910651327\n",
      "      - -206644.15364409905\n",
      "      - -215007.60884514905\n",
      "      - -211986.51076412198\n",
      "      - -208614.39172398046\n",
      "      - -216471.05455116686\n",
      "      - -214624.31926451065\n",
      "      - -209342.44150004533\n",
      "      - -209709.82703615905\n",
      "      - -205456.75197174854\n",
      "      - -210803.2218288007\n",
      "      - -206594.82519968427\n",
      "      - -215163.29030004816\n",
      "      - -215984.17923579007\n",
      "      - -204064.5561329495\n",
      "      - -208751.32807434248\n",
      "      - -216082.50112559908\n",
      "      - -246035.45101386987\n",
      "      - -218359.95358498517\n",
      "      - -213414.73881501195\n",
      "      - -216045.54470502347\n",
      "      - -206073.83225766398\n",
      "      - -210329.84731245006\n",
      "      - -214744.5497190016\n",
      "      - -211486.98770763376\n",
      "      - -225407.2035495067\n",
      "      - -206556.2865968239\n",
      "      - -211274.7197527422\n",
      "      - -208015.48624629725\n",
      "      - -206608.80451122654\n",
      "      - -211134.59226475164\n",
      "      - -224175.76652161786\n",
      "      - -207758.68543187456\n",
      "      - -210289.169346855\n",
      "      - -209347.00974502074\n",
      "      - -211611.75538804723\n",
      "      - -210681.78609201292\n",
      "      - -209216.2539815274\n",
      "      - -214273.10135816212\n",
      "      - -214384.39440225702\n",
      "      - -211391.86956304885\n",
      "      - -204170.46125937806\n",
      "      - -211710.66623812827\n",
      "      - -217730.19821149466\n",
      "      - -203507.15361726045\n",
      "      - -210845.59547820737\n",
      "      - -220396.50242624982\n",
      "      - -210191.0133109368\n",
      "      - -211282.11989149093\n",
      "      - -218588.80049264862\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1182022061378361\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5148279965535439\n",
      "      mean_inference_ms: 1.5915131958751432\n",
      "      mean_raw_obs_processing_ms: 0.1629433001445607\n",
      "  time_since_restore: 609.4374434947968\n",
      "  time_this_iter_s: 15.043956279754639\n",
      "  time_total_s: 609.4374434947968\n",
      "  timers:\n",
      "    learn_throughput: 25965.661\n",
      "    learn_time_ms: 2464.178\n",
      "    load_throughput: 539828.942\n",
      "    load_time_ms: 118.526\n",
      "    training_iteration_time_ms: 15336.118\n",
      "    update_time_ms: 4.286\n",
      "  timestamp: 1665742824\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2495376\n",
      "  training_iteration: 39\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:20:29 (running for 00:10:32.01)<br>Memory usage on this node: 12.1/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         609.437</td><td style=\"text-align: right;\">2.49538e+06</td><td style=\"text-align: right;\"> -212835</td><td style=\"text-align: right;\">             -203027</td><td style=\"text-align: right;\">             -246035</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:20:34 (running for 00:10:37.03)<br>Memory usage on this node: 12.1/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         609.437</td><td style=\"text-align: right;\">2.49538e+06</td><td style=\"text-align: right;\"> -212835</td><td style=\"text-align: right;\">             -203027</td><td style=\"text-align: right;\">             -246035</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:20:39 (running for 00:10:42.04)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         609.437</td><td style=\"text-align: right;\">2.49538e+06</td><td style=\"text-align: right;\"> -212835</td><td style=\"text-align: right;\">             -203027</td><td style=\"text-align: right;\">             -246035</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 2559360\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 2559360\n",
      "    num_agent_steps_trained: 2559360\n",
      "    num_env_steps_sampled: 2559360\n",
      "    num_env_steps_trained: 2559360\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-20-40\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -203507.15361726045\n",
      "  episode_reward_mean: -211730.04631479405\n",
      "  episode_reward_min: -255113.14353589775\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 2556\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.133845329284668\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0018180700717493892\n",
      "          model: {}\n",
      "          policy_loss: 0.007808729540556669\n",
      "          total_loss: 10.007858276367188\n",
      "          vf_explained_var: 1.3122191830916563e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 2559360\n",
      "    num_agent_steps_trained: 2559360\n",
      "    num_env_steps_sampled: 2559360\n",
      "    num_env_steps_trained: 2559360\n",
      "  iterations_since_restore: 40\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 2559360\n",
      "  num_agent_steps_trained: 2559360\n",
      "  num_env_steps_sampled: 2559360\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 2559360\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.38181818181819\n",
      "    ram_util_percent: 78.39545454545454\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11852687629775423\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5154377117338952\n",
      "    mean_inference_ms: 1.5924142784485165\n",
      "    mean_raw_obs_processing_ms: 0.1630939686956585\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -203507.15361726045\n",
      "    episode_reward_mean: -211730.04631479405\n",
      "    episode_reward_min: -255113.14353589775\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -210329.84731245006\n",
      "      - -214744.5497190016\n",
      "      - -211486.98770763376\n",
      "      - -225407.2035495067\n",
      "      - -206556.2865968239\n",
      "      - -211274.7197527422\n",
      "      - -208015.48624629725\n",
      "      - -206608.80451122654\n",
      "      - -211134.59226475164\n",
      "      - -224175.76652161786\n",
      "      - -207758.68543187456\n",
      "      - -210289.169346855\n",
      "      - -209347.00974502074\n",
      "      - -211611.75538804723\n",
      "      - -210681.78609201292\n",
      "      - -209216.2539815274\n",
      "      - -214273.10135816212\n",
      "      - -214384.39440225702\n",
      "      - -211391.86956304885\n",
      "      - -204170.46125937806\n",
      "      - -211710.66623812827\n",
      "      - -217730.19821149466\n",
      "      - -203507.15361726045\n",
      "      - -210845.59547820737\n",
      "      - -220396.50242624982\n",
      "      - -210191.0133109368\n",
      "      - -211282.11989149093\n",
      "      - -218588.80049264862\n",
      "      - -217048.4729865893\n",
      "      - -211861.21302710706\n",
      "      - -217927.5903702694\n",
      "      - -206556.94871008923\n",
      "      - -209818.588327444\n",
      "      - -203911.1240054778\n",
      "      - -205416.14510959125\n",
      "      - -213483.40648692605\n",
      "      - -211046.29231597908\n",
      "      - -205981.42048397404\n",
      "      - -212452.1338818365\n",
      "      - -207878.93499255166\n",
      "      - -216688.56526940348\n",
      "      - -207407.82098445419\n",
      "      - -206872.17628722024\n",
      "      - -206440.46404345694\n",
      "      - -209440.832597167\n",
      "      - -208023.9527895417\n",
      "      - -236207.22937105715\n",
      "      - -205877.7744782516\n",
      "      - -207898.83023229742\n",
      "      - -208132.94401540188\n",
      "      - -218643.76830607094\n",
      "      - -207965.0438697581\n",
      "      - -215379.28973839263\n",
      "      - -212218.20382107922\n",
      "      - -206573.49791391284\n",
      "      - -255113.14353589775\n",
      "      - -207175.65484675142\n",
      "      - -205252.73717990558\n",
      "      - -208033.61257187737\n",
      "      - -206550.76422501606\n",
      "      - -203728.60041441367\n",
      "      - -209190.94245110996\n",
      "      - -210768.9028645781\n",
      "      - -217967.7524238636\n",
      "      - -214869.21395731185\n",
      "      - -206326.01169454237\n",
      "      - -218312.20643992958\n",
      "      - -213307.07074440317\n",
      "      - -210734.16985461832\n",
      "      - -210003.12465075197\n",
      "      - -210460.71979702407\n",
      "      - -209023.91004595422\n",
      "      - -214585.16071772703\n",
      "      - -208054.3943755165\n",
      "      - -206630.42214188457\n",
      "      - -208535.43907782916\n",
      "      - -212498.55357657105\n",
      "      - -217713.77465131905\n",
      "      - -207938.0865662805\n",
      "      - -211706.7681730748\n",
      "      - -208791.91818052414\n",
      "      - -208745.88084816324\n",
      "      - -207199.88958247658\n",
      "      - -208987.2800388222\n",
      "      - -206318.31535888708\n",
      "      - -209205.63496112142\n",
      "      - -207861.69295882748\n",
      "      - -212538.01730123782\n",
      "      - -208924.42870703046\n",
      "      - -210591.62617201003\n",
      "      - -214210.17181764956\n",
      "      - -211799.42433635192\n",
      "      - -211865.1157150501\n",
      "      - -251380.2225740846\n",
      "      - -208914.51218514115\n",
      "      - -212149.71144395726\n",
      "      - -207871.67637729915\n",
      "      - -209652.61188458907\n",
      "      - -211699.63064071984\n",
      "      - -205552.28858535353\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11852687629775423\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5154377117338952\n",
      "      mean_inference_ms: 1.5924142784485165\n",
      "      mean_raw_obs_processing_ms: 0.1630939686956585\n",
      "  time_since_restore: 625.404866695404\n",
      "  time_this_iter_s: 15.9674232006073\n",
      "  time_total_s: 625.404866695404\n",
      "  timers:\n",
      "    learn_throughput: 25984.01\n",
      "    learn_time_ms: 2462.437\n",
      "    load_throughput: 537660.61\n",
      "    load_time_ms: 119.004\n",
      "    training_iteration_time_ms: 15408.979\n",
      "    update_time_ms: 4.217\n",
      "  timestamp: 1665742840\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2559360\n",
      "  training_iteration: 40\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:20:46 (running for 00:10:48.29)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         625.405</td><td style=\"text-align: right;\">2.55936e+06</td><td style=\"text-align: right;\"> -211730</td><td style=\"text-align: right;\">             -203507</td><td style=\"text-align: right;\">             -255113</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:20:51 (running for 00:10:53.30)<br>Memory usage on this node: 12.1/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         625.405</td><td style=\"text-align: right;\">2.55936e+06</td><td style=\"text-align: right;\"> -211730</td><td style=\"text-align: right;\">             -203507</td><td style=\"text-align: right;\">             -255113</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:20:56 (running for 00:10:58.30)<br>Memory usage on this node: 12.1/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         625.405</td><td style=\"text-align: right;\">2.55936e+06</td><td style=\"text-align: right;\"> -211730</td><td style=\"text-align: right;\">             -203507</td><td style=\"text-align: right;\">             -255113</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 2623344\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 2623344\n",
      "    num_agent_steps_trained: 2623344\n",
      "    num_env_steps_sampled: 2623344\n",
      "    num_env_steps_trained: 2623344\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-20-56\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -201143.0543583375\n",
      "  episode_reward_mean: -210243.3114715463\n",
      "  episode_reward_min: -251380.2225740846\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 2616\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.125153064727783\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0020269020460546017\n",
      "          model: {}\n",
      "          policy_loss: 0.0033439937978982925\n",
      "          total_loss: 10.003437042236328\n",
      "          vf_explained_var: 2.3748725652694702e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 2623344\n",
      "    num_agent_steps_trained: 2623344\n",
      "    num_env_steps_sampled: 2623344\n",
      "    num_env_steps_trained: 2623344\n",
      "  iterations_since_restore: 41\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 2623344\n",
      "  num_agent_steps_trained: 2623344\n",
      "  num_env_steps_sampled: 2623344\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 2623344\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.69047619047619\n",
      "    ram_util_percent: 78.63809523809523\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11837437740230737\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5155233902643228\n",
      "    mean_inference_ms: 1.5922812252570049\n",
      "    mean_raw_obs_processing_ms: 0.16310308952028968\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -201143.0543583375\n",
      "    episode_reward_mean: -210243.3114715463\n",
      "    episode_reward_min: -251380.2225740846\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -203728.60041441367\n",
      "      - -209190.94245110996\n",
      "      - -210768.9028645781\n",
      "      - -217967.7524238636\n",
      "      - -214869.21395731185\n",
      "      - -206326.01169454237\n",
      "      - -218312.20643992958\n",
      "      - -213307.07074440317\n",
      "      - -210734.16985461832\n",
      "      - -210003.12465075197\n",
      "      - -210460.71979702407\n",
      "      - -209023.91004595422\n",
      "      - -214585.16071772703\n",
      "      - -208054.3943755165\n",
      "      - -206630.42214188457\n",
      "      - -208535.43907782916\n",
      "      - -212498.55357657105\n",
      "      - -217713.77465131905\n",
      "      - -207938.0865662805\n",
      "      - -211706.7681730748\n",
      "      - -208791.91818052414\n",
      "      - -208745.88084816324\n",
      "      - -207199.88958247658\n",
      "      - -208987.2800388222\n",
      "      - -206318.31535888708\n",
      "      - -209205.63496112142\n",
      "      - -207861.69295882748\n",
      "      - -212538.01730123782\n",
      "      - -208924.42870703046\n",
      "      - -210591.62617201003\n",
      "      - -214210.17181764956\n",
      "      - -211799.42433635192\n",
      "      - -211865.1157150501\n",
      "      - -251380.2225740846\n",
      "      - -208914.51218514115\n",
      "      - -212149.71144395726\n",
      "      - -207871.67637729915\n",
      "      - -209652.61188458907\n",
      "      - -211699.63064071984\n",
      "      - -205552.28858535353\n",
      "      - -220464.50444464546\n",
      "      - -211759.08075769924\n",
      "      - -212450.82776711037\n",
      "      - -211494.74247322048\n",
      "      - -209546.7214830381\n",
      "      - -210503.98281463457\n",
      "      - -222169.1587094926\n",
      "      - -206217.5156148145\n",
      "      - -212402.55405941844\n",
      "      - -207335.60944140248\n",
      "      - -214214.74155337465\n",
      "      - -210252.42563719995\n",
      "      - -208107.44154831037\n",
      "      - -210256.9840329264\n",
      "      - -210070.66901067394\n",
      "      - -205044.23601505964\n",
      "      - -203845.8438022993\n",
      "      - -219547.34041356327\n",
      "      - -209620.60174378025\n",
      "      - -210591.50245726673\n",
      "      - -205203.82509091595\n",
      "      - -205262.98468423486\n",
      "      - -218330.99379745647\n",
      "      - -206935.95429986843\n",
      "      - -207503.81373011167\n",
      "      - -208907.10843770954\n",
      "      - -213101.6093858631\n",
      "      - -204988.5503070763\n",
      "      - -206782.24360174\n",
      "      - -212967.4188447497\n",
      "      - -206130.8000437463\n",
      "      - -210746.02125807386\n",
      "      - -201143.0543583375\n",
      "      - -208451.01530798947\n",
      "      - -212840.40585675606\n",
      "      - -209689.3157893019\n",
      "      - -208541.31836584752\n",
      "      - -212216.8240034254\n",
      "      - -206047.5595473821\n",
      "      - -212949.53028233277\n",
      "      - -203721.01774265556\n",
      "      - -201824.83040318082\n",
      "      - -208807.2323135374\n",
      "      - -206433.2900947007\n",
      "      - -207525.33601612487\n",
      "      - -207290.5134031333\n",
      "      - -210666.75214986934\n",
      "      - -214608.2493742313\n",
      "      - -205605.48070766308\n",
      "      - -205500.96300804574\n",
      "      - -211781.48087356778\n",
      "      - -212277.5420817092\n",
      "      - -202585.74372995607\n",
      "      - -208733.54599385595\n",
      "      - -204716.1344554992\n",
      "      - -209194.10988929227\n",
      "      - -210773.16052178456\n",
      "      - -204002.79607821346\n",
      "      - -214646.75023980587\n",
      "      - -212384.1130169552\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11837437740230737\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5155233902643228\n",
      "      mean_inference_ms: 1.5922812252570049\n",
      "      mean_raw_obs_processing_ms: 0.16310308952028968\n",
      "  time_since_restore: 641.189227104187\n",
      "  time_this_iter_s: 15.784360408782959\n",
      "  time_total_s: 641.189227104187\n",
      "  timers:\n",
      "    learn_throughput: 25577.492\n",
      "    learn_time_ms: 2501.574\n",
      "    load_throughput: 536117.05\n",
      "    load_time_ms: 119.347\n",
      "    training_iteration_time_ms: 15456.136\n",
      "    update_time_ms: 4.194\n",
      "  timestamp: 1665742856\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2623344\n",
      "  training_iteration: 41\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:21:01 (running for 00:11:03.54)<br>Memory usage on this node: 12.1/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    41</td><td style=\"text-align: right;\">         641.189</td><td style=\"text-align: right;\">2.62334e+06</td><td style=\"text-align: right;\"> -210243</td><td style=\"text-align: right;\">             -201143</td><td style=\"text-align: right;\">             -251380</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:21:06 (running for 00:11:08.62)<br>Memory usage on this node: 12.1/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    41</td><td style=\"text-align: right;\">         641.189</td><td style=\"text-align: right;\">2.62334e+06</td><td style=\"text-align: right;\"> -210243</td><td style=\"text-align: right;\">             -201143</td><td style=\"text-align: right;\">             -251380</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 2687328\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 2687328\n",
      "    num_agent_steps_trained: 2687328\n",
      "    num_env_steps_sampled: 2687328\n",
      "    num_env_steps_trained: 2687328\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-21-11\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -201143.0543583375\n",
      "  episode_reward_mean: -209090.70772496102\n",
      "  episode_reward_min: -218771.31384616307\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 2676\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1268796920776367\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0014725906075909734\n",
      "          model: {}\n",
      "          policy_loss: 0.00046566128730773926\n",
      "          total_loss: 10.000447273254395\n",
      "          vf_explained_var: -6.409791808437149e-07\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 2687328\n",
      "    num_agent_steps_trained: 2687328\n",
      "    num_env_steps_sampled: 2687328\n",
      "    num_env_steps_trained: 2687328\n",
      "  iterations_since_restore: 42\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 2687328\n",
      "  num_agent_steps_trained: 2687328\n",
      "  num_env_steps_sampled: 2687328\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 2687328\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.16190476190475\n",
      "    ram_util_percent: 78.32380952380953\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1181470443127232\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5150997772381091\n",
      "    mean_inference_ms: 1.59123654339471\n",
      "    mean_raw_obs_processing_ms: 0.16272147835676123\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -201143.0543583375\n",
      "    episode_reward_mean: -209090.70772496102\n",
      "    episode_reward_min: -218771.31384616307\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -205203.82509091595\n",
      "      - -205262.98468423486\n",
      "      - -218330.99379745647\n",
      "      - -206935.95429986843\n",
      "      - -207503.81373011167\n",
      "      - -208907.10843770954\n",
      "      - -213101.6093858631\n",
      "      - -204988.5503070763\n",
      "      - -206782.24360174\n",
      "      - -212967.4188447497\n",
      "      - -206130.8000437463\n",
      "      - -210746.02125807386\n",
      "      - -201143.0543583375\n",
      "      - -208451.01530798947\n",
      "      - -212840.40585675606\n",
      "      - -209689.3157893019\n",
      "      - -208541.31836584752\n",
      "      - -212216.8240034254\n",
      "      - -206047.5595473821\n",
      "      - -212949.53028233277\n",
      "      - -203721.01774265556\n",
      "      - -201824.83040318082\n",
      "      - -208807.2323135374\n",
      "      - -206433.2900947007\n",
      "      - -207525.33601612487\n",
      "      - -207290.5134031333\n",
      "      - -210666.75214986934\n",
      "      - -214608.2493742313\n",
      "      - -205605.48070766308\n",
      "      - -205500.96300804574\n",
      "      - -211781.48087356778\n",
      "      - -212277.5420817092\n",
      "      - -202585.74372995607\n",
      "      - -208733.54599385595\n",
      "      - -204716.1344554992\n",
      "      - -209194.10988929227\n",
      "      - -210773.16052178456\n",
      "      - -204002.79607821346\n",
      "      - -214646.75023980587\n",
      "      - -212384.1130169552\n",
      "      - -202657.11622781883\n",
      "      - -205718.47398365906\n",
      "      - -213149.43087627462\n",
      "      - -212603.140286379\n",
      "      - -210971.0728738501\n",
      "      - -206592.8024555236\n",
      "      - -211810.96968158102\n",
      "      - -213446.58308512837\n",
      "      - -213383.03360536366\n",
      "      - -209811.84443749947\n",
      "      - -206959.45841663994\n",
      "      - -209911.28619577142\n",
      "      - -211899.82533135108\n",
      "      - -203688.97662786924\n",
      "      - -209571.93149611496\n",
      "      - -206907.2179059419\n",
      "      - -206082.02498784647\n",
      "      - -211635.6803411643\n",
      "      - -210055.7320393577\n",
      "      - -215142.91682197675\n",
      "      - -207156.16057041145\n",
      "      - -207068.73303407832\n",
      "      - -209617.49573173918\n",
      "      - -213623.24450303943\n",
      "      - -210120.17585071165\n",
      "      - -207997.52909167655\n",
      "      - -206569.6811214341\n",
      "      - -206650.39666247668\n",
      "      - -206086.98705080996\n",
      "      - -205305.39624696804\n",
      "      - -213990.6830998558\n",
      "      - -208342.91776266013\n",
      "      - -217469.3550407598\n",
      "      - -210391.81939695778\n",
      "      - -210556.7108630714\n",
      "      - -206509.06439403238\n",
      "      - -218771.31384616307\n",
      "      - -216569.9409442771\n",
      "      - -208761.08562662976\n",
      "      - -202535.1392602609\n",
      "      - -209108.96656439174\n",
      "      - -210519.29493483895\n",
      "      - -210680.2756183944\n",
      "      - -204367.21187067323\n",
      "      - -208076.72750416122\n",
      "      - -213956.7416248274\n",
      "      - -207171.38347008877\n",
      "      - -208177.31718872488\n",
      "      - -202158.87400488\n",
      "      - -212660.06184724404\n",
      "      - -213423.33224338436\n",
      "      - -209697.1146533146\n",
      "      - -211413.4204136476\n",
      "      - -202461.69044675498\n",
      "      - -206776.06388417783\n",
      "      - -211463.65355645007\n",
      "      - -208214.52238964845\n",
      "      - -210414.08781495102\n",
      "      - -211908.06841641702\n",
      "      - -208509.22718730738\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1181470443127232\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5150997772381091\n",
      "      mean_inference_ms: 1.59123654339471\n",
      "      mean_raw_obs_processing_ms: 0.16272147835676123\n",
      "  time_since_restore: 656.093416929245\n",
      "  time_this_iter_s: 14.904189825057983\n",
      "  time_total_s: 656.093416929245\n",
      "  timers:\n",
      "    learn_throughput: 26539.418\n",
      "    learn_time_ms: 2410.904\n",
      "    load_throughput: 536383.218\n",
      "    load_time_ms: 119.288\n",
      "    training_iteration_time_ms: 15292.821\n",
      "    update_time_ms: 4.223\n",
      "  timestamp: 1665742871\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2687328\n",
      "  training_iteration: 42\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:21:16 (running for 00:11:18.47)<br>Memory usage on this node: 12.1/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         656.093</td><td style=\"text-align: right;\">2.68733e+06</td><td style=\"text-align: right;\"> -209091</td><td style=\"text-align: right;\">             -201143</td><td style=\"text-align: right;\">             -218771</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:21:21 (running for 00:11:23.56)<br>Memory usage on this node: 12.1/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         656.093</td><td style=\"text-align: right;\">2.68733e+06</td><td style=\"text-align: right;\"> -209091</td><td style=\"text-align: right;\">             -201143</td><td style=\"text-align: right;\">             -218771</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:21:26 (running for 00:11:28.74)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         656.093</td><td style=\"text-align: right;\">2.68733e+06</td><td style=\"text-align: right;\"> -209091</td><td style=\"text-align: right;\">             -201143</td><td style=\"text-align: right;\">             -218771</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 2751312\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 2751312\n",
      "    num_agent_steps_trained: 2751312\n",
      "    num_env_steps_sampled: 2751312\n",
      "    num_env_steps_trained: 2751312\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-21-27\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -201849.366158543\n",
      "  episode_reward_mean: -210561.16480445326\n",
      "  episode_reward_min: -219109.27082521812\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 2748\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.12695574760437\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0018894858658313751\n",
      "          model: {}\n",
      "          policy_loss: 0.006222189404070377\n",
      "          total_loss: 10.006287574768066\n",
      "          vf_explained_var: -5.827500331179181e-07\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 2751312\n",
      "    num_agent_steps_trained: 2751312\n",
      "    num_env_steps_sampled: 2751312\n",
      "    num_env_steps_trained: 2751312\n",
      "  iterations_since_restore: 43\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 2751312\n",
      "  num_agent_steps_trained: 2751312\n",
      "  num_env_steps_sampled: 2751312\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 2751312\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.13181818181819\n",
      "    ram_util_percent: 78.43181818181819\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11828006345933005\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5150648842495237\n",
      "    mean_inference_ms: 1.5903169149887635\n",
      "    mean_raw_obs_processing_ms: 0.1627799510541422\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -201849.366158543\n",
      "    episode_reward_mean: -210561.16480445326\n",
      "    episode_reward_min: -219109.27082521812\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -217469.3550407598\n",
      "      - -210391.81939695778\n",
      "      - -210556.7108630714\n",
      "      - -206509.06439403238\n",
      "      - -218771.31384616307\n",
      "      - -216569.9409442771\n",
      "      - -208761.08562662976\n",
      "      - -202535.1392602609\n",
      "      - -209108.96656439174\n",
      "      - -210519.29493483895\n",
      "      - -210680.2756183944\n",
      "      - -204367.21187067323\n",
      "      - -208076.72750416122\n",
      "      - -213956.7416248274\n",
      "      - -207171.38347008877\n",
      "      - -208177.31718872488\n",
      "      - -202158.87400488\n",
      "      - -212660.06184724404\n",
      "      - -213423.33224338436\n",
      "      - -209697.1146533146\n",
      "      - -211413.4204136476\n",
      "      - -202461.69044675498\n",
      "      - -206776.06388417783\n",
      "      - -211463.65355645007\n",
      "      - -208214.52238964845\n",
      "      - -210414.08781495102\n",
      "      - -211908.06841641702\n",
      "      - -208509.22718730738\n",
      "      - -202899.46997679563\n",
      "      - -208055.87115229832\n",
      "      - -207089.61408294682\n",
      "      - -214839.24803452648\n",
      "      - -201849.366158543\n",
      "      - -216671.8622952481\n",
      "      - -208673.571640607\n",
      "      - -209522.61562199672\n",
      "      - -208373.51303768982\n",
      "      - -208395.52715975282\n",
      "      - -213575.07585727447\n",
      "      - -208634.12130034526\n",
      "      - -209979.0269026854\n",
      "      - -209938.60740686802\n",
      "      - -212374.48468226643\n",
      "      - -206462.09417662452\n",
      "      - -208716.91587597315\n",
      "      - -207258.2653759705\n",
      "      - -207258.39062671372\n",
      "      - -212795.62169455993\n",
      "      - -211355.77159438207\n",
      "      - -209797.12462648578\n",
      "      - -217373.2324505608\n",
      "      - -211593.36145642897\n",
      "      - -214807.53024652312\n",
      "      - -214091.04674897113\n",
      "      - -216401.6255512058\n",
      "      - -216048.97045184436\n",
      "      - -218964.0551866456\n",
      "      - -207422.6998609794\n",
      "      - -215139.37283894434\n",
      "      - -213742.85872881964\n",
      "      - -214216.90093017858\n",
      "      - -205659.09103342178\n",
      "      - -219109.27082521812\n",
      "      - -213729.75669261717\n",
      "      - -207421.03597563034\n",
      "      - -218081.79445545308\n",
      "      - -213329.76513260428\n",
      "      - -210701.6565731343\n",
      "      - -208403.28501265685\n",
      "      - -207066.88031044896\n",
      "      - -211841.86461310368\n",
      "      - -213319.75599038013\n",
      "      - -208438.14421946052\n",
      "      - -208238.97059590786\n",
      "      - -209418.6941817335\n",
      "      - -209833.1453170946\n",
      "      - -208812.1758216812\n",
      "      - -208269.6599541677\n",
      "      - -211832.5521741021\n",
      "      - -211683.33828073705\n",
      "      - -207446.4764351509\n",
      "      - -215525.12975192827\n",
      "      - -216228.48761004323\n",
      "      - -215102.4840241788\n",
      "      - -212720.2953895268\n",
      "      - -207069.939745732\n",
      "      - -208283.90290794158\n",
      "      - -210043.12893113538\n",
      "      - -210643.65731101568\n",
      "      - -206034.4324649857\n",
      "      - -204526.12564456632\n",
      "      - -214842.72178643\n",
      "      - -215068.0693583532\n",
      "      - -208455.76727988807\n",
      "      - -218056.12087751934\n",
      "      - -210170.1661349729\n",
      "      - -211803.36498213556\n",
      "      - -204873.37582610812\n",
      "      - -210226.56993017567\n",
      "      - -206765.14815589794\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11828006345933005\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5150648842495237\n",
      "      mean_inference_ms: 1.5903169149887635\n",
      "      mean_raw_obs_processing_ms: 0.1627799510541422\n",
      "  time_since_restore: 671.8944964408875\n",
      "  time_this_iter_s: 15.801079511642456\n",
      "  time_total_s: 671.8944964408875\n",
      "  timers:\n",
      "    learn_throughput: 25846.302\n",
      "    learn_time_ms: 2475.557\n",
      "    load_throughput: 532740.29\n",
      "    load_time_ms: 120.104\n",
      "    training_iteration_time_ms: 15344.928\n",
      "    update_time_ms: 4.329\n",
      "  timestamp: 1665742887\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2751312\n",
      "  training_iteration: 43\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:21:32 (running for 00:11:34.38)<br>Memory usage on this node: 12.1/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    43</td><td style=\"text-align: right;\">         671.894</td><td style=\"text-align: right;\">2.75131e+06</td><td style=\"text-align: right;\"> -210561</td><td style=\"text-align: right;\">             -201849</td><td style=\"text-align: right;\">             -219109</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:21:37 (running for 00:11:39.41)<br>Memory usage on this node: 12.1/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    43</td><td style=\"text-align: right;\">         671.894</td><td style=\"text-align: right;\">2.75131e+06</td><td style=\"text-align: right;\"> -210561</td><td style=\"text-align: right;\">             -201849</td><td style=\"text-align: right;\">             -219109</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 2815296\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 2815296\n",
      "    num_agent_steps_trained: 2815296\n",
      "    num_env_steps_sampled: 2815296\n",
      "    num_env_steps_trained: 2815296\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-21-42\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -203492.619766955\n",
      "  episode_reward_mean: -211104.8466920097\n",
      "  episode_reward_min: -273376.03640816786\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 2808\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.124091863632202\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.002389054512605071\n",
      "          model: {}\n",
      "          policy_loss: 0.002340897684916854\n",
      "          total_loss: 10.002507209777832\n",
      "          vf_explained_var: -9.380854066876054e-07\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 2815296\n",
      "    num_agent_steps_trained: 2815296\n",
      "    num_env_steps_sampled: 2815296\n",
      "    num_env_steps_trained: 2815296\n",
      "  iterations_since_restore: 44\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 2815296\n",
      "  num_agent_steps_trained: 2815296\n",
      "  num_env_steps_sampled: 2815296\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 2815296\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.18181818181817\n",
      "    ram_util_percent: 78.48636363636366\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11822557822494396\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5149712101127648\n",
      "    mean_inference_ms: 1.588472748293524\n",
      "    mean_raw_obs_processing_ms: 0.16279778108841764\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -203492.619766955\n",
      "    episode_reward_mean: -211104.8466920097\n",
      "    episode_reward_min: -273376.03640816786\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -214216.90093017858\n",
      "      - -205659.09103342178\n",
      "      - -219109.27082521812\n",
      "      - -213729.75669261717\n",
      "      - -207421.03597563034\n",
      "      - -218081.79445545308\n",
      "      - -213329.76513260428\n",
      "      - -210701.6565731343\n",
      "      - -208403.28501265685\n",
      "      - -207066.88031044896\n",
      "      - -211841.86461310368\n",
      "      - -213319.75599038013\n",
      "      - -208438.14421946052\n",
      "      - -208238.97059590786\n",
      "      - -209418.6941817335\n",
      "      - -209833.1453170946\n",
      "      - -208812.1758216812\n",
      "      - -208269.6599541677\n",
      "      - -211832.5521741021\n",
      "      - -211683.33828073705\n",
      "      - -207446.4764351509\n",
      "      - -215525.12975192827\n",
      "      - -216228.48761004323\n",
      "      - -215102.4840241788\n",
      "      - -212720.2953895268\n",
      "      - -207069.939745732\n",
      "      - -208283.90290794158\n",
      "      - -210043.12893113538\n",
      "      - -210643.65731101568\n",
      "      - -206034.4324649857\n",
      "      - -204526.12564456632\n",
      "      - -214842.72178643\n",
      "      - -215068.0693583532\n",
      "      - -208455.76727988807\n",
      "      - -218056.12087751934\n",
      "      - -210170.1661349729\n",
      "      - -211803.36498213556\n",
      "      - -204873.37582610812\n",
      "      - -210226.56993017567\n",
      "      - -206765.14815589794\n",
      "      - -210212.6604504512\n",
      "      - -211166.33341580754\n",
      "      - -215970.82703681733\n",
      "      - -208618.592023306\n",
      "      - -213660.84133514648\n",
      "      - -219773.12705833622\n",
      "      - -204745.76405348512\n",
      "      - -214364.73686628352\n",
      "      - -208047.28753389098\n",
      "      - -205337.6992538581\n",
      "      - -206116.7275743212\n",
      "      - -209644.10780456598\n",
      "      - -208890.3804399792\n",
      "      - -211064.8315977189\n",
      "      - -206873.24217179086\n",
      "      - -209173.39075074092\n",
      "      - -205032.43815667825\n",
      "      - -205377.6369625285\n",
      "      - -208037.79955795998\n",
      "      - -213577.76971208327\n",
      "      - -206048.25688099733\n",
      "      - -208652.33869899914\n",
      "      - -209738.92288803955\n",
      "      - -208040.04584161454\n",
      "      - -212177.33830486017\n",
      "      - -207902.18144378875\n",
      "      - -206641.27332021107\n",
      "      - -207869.1941655444\n",
      "      - -211302.02397241895\n",
      "      - -209338.98342553782\n",
      "      - -209452.9896784435\n",
      "      - -214124.6463025765\n",
      "      - -215726.52089981423\n",
      "      - -220752.62135965342\n",
      "      - -205903.25264012712\n",
      "      - -214351.1888882369\n",
      "      - -211305.68783265055\n",
      "      - -211566.54687776158\n",
      "      - -212111.61323696698\n",
      "      - -207158.71820878977\n",
      "      - -211300.15837292408\n",
      "      - -203492.619766955\n",
      "      - -212342.05820173994\n",
      "      - -211916.0086527302\n",
      "      - -207338.7186293229\n",
      "      - -210582.51351440302\n",
      "      - -206013.61975087074\n",
      "      - -211266.25862486078\n",
      "      - -204686.9451950991\n",
      "      - -212656.45830090615\n",
      "      - -211963.32052176527\n",
      "      - -273376.03640816786\n",
      "      - -212057.88484514356\n",
      "      - -217848.17160596023\n",
      "      - -215787.10179549758\n",
      "      - -211735.87852622816\n",
      "      - -207342.5144676579\n",
      "      - -210520.01987097308\n",
      "      - -204455.10332116354\n",
      "      - -214659.63756840155\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11822557822494396\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5149712101127648\n",
      "      mean_inference_ms: 1.588472748293524\n",
      "      mean_raw_obs_processing_ms: 0.16279778108841764\n",
      "  time_since_restore: 686.9171509742737\n",
      "  time_this_iter_s: 15.02265453338623\n",
      "  time_total_s: 686.9171509742737\n",
      "  timers:\n",
      "    learn_throughput: 25862.692\n",
      "    learn_time_ms: 2473.988\n",
      "    load_throughput: 533339.959\n",
      "    load_time_ms: 119.969\n",
      "    training_iteration_time_ms: 15278.622\n",
      "    update_time_ms: 4.256\n",
      "  timestamp: 1665742902\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2815296\n",
      "  training_iteration: 44\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:21:47 (running for 00:11:49.71)<br>Memory usage on this node: 12.1/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    44</td><td style=\"text-align: right;\">         686.917</td><td style=\"text-align: right;\">2.8153e+06</td><td style=\"text-align: right;\"> -211105</td><td style=\"text-align: right;\">             -203493</td><td style=\"text-align: right;\">             -273376</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:21:52 (running for 00:11:54.72)<br>Memory usage on this node: 12.1/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    44</td><td style=\"text-align: right;\">         686.917</td><td style=\"text-align: right;\">2.8153e+06</td><td style=\"text-align: right;\"> -211105</td><td style=\"text-align: right;\">             -203493</td><td style=\"text-align: right;\">             -273376</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:21:57 (running for 00:11:59.82)<br>Memory usage on this node: 12.1/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    44</td><td style=\"text-align: right;\">         686.917</td><td style=\"text-align: right;\">2.8153e+06</td><td style=\"text-align: right;\"> -211105</td><td style=\"text-align: right;\">             -203493</td><td style=\"text-align: right;\">             -273376</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 2879280\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 2879280\n",
      "    num_agent_steps_trained: 2879280\n",
      "    num_env_steps_sampled: 2879280\n",
      "    num_env_steps_trained: 2879280\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-21-58\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -201925.83368059693\n",
      "  episode_reward_mean: -211954.36956953286\n",
      "  episode_reward_min: -273376.03640816786\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 2868\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.124141216278076\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0025546480901539326\n",
      "          model: {}\n",
      "          policy_loss: -0.00588981993496418\n",
      "          total_loss: 9.994307518005371\n",
      "          vf_explained_var: -4.841731424676254e-07\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 2879280\n",
      "    num_agent_steps_trained: 2879280\n",
      "    num_env_steps_sampled: 2879280\n",
      "    num_env_steps_trained: 2879280\n",
      "  iterations_since_restore: 45\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 2879280\n",
      "  num_agent_steps_trained: 2879280\n",
      "  num_env_steps_sampled: 2879280\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 2879280\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.51818181818182\n",
      "    ram_util_percent: 78.39090909090912\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11820714963149377\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5144845246272016\n",
      "    mean_inference_ms: 1.5898675617798868\n",
      "    mean_raw_obs_processing_ms: 0.1625568393999499\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -201925.83368059693\n",
      "    episode_reward_mean: -211954.36956953286\n",
      "    episode_reward_min: -273376.03640816786\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -206048.25688099733\n",
      "      - -208652.33869899914\n",
      "      - -209738.92288803955\n",
      "      - -208040.04584161454\n",
      "      - -212177.33830486017\n",
      "      - -207902.18144378875\n",
      "      - -206641.27332021107\n",
      "      - -207869.1941655444\n",
      "      - -211302.02397241895\n",
      "      - -209338.98342553782\n",
      "      - -209452.9896784435\n",
      "      - -214124.6463025765\n",
      "      - -215726.52089981423\n",
      "      - -220752.62135965342\n",
      "      - -205903.25264012712\n",
      "      - -214351.1888882369\n",
      "      - -211305.68783265055\n",
      "      - -211566.54687776158\n",
      "      - -212111.61323696698\n",
      "      - -207158.71820878977\n",
      "      - -211300.15837292408\n",
      "      - -203492.619766955\n",
      "      - -212342.05820173994\n",
      "      - -211916.0086527302\n",
      "      - -207338.7186293229\n",
      "      - -210582.51351440302\n",
      "      - -206013.61975087074\n",
      "      - -211266.25862486078\n",
      "      - -204686.9451950991\n",
      "      - -212656.45830090615\n",
      "      - -211963.32052176527\n",
      "      - -273376.03640816786\n",
      "      - -212057.88484514356\n",
      "      - -217848.17160596023\n",
      "      - -215787.10179549758\n",
      "      - -211735.87852622816\n",
      "      - -207342.5144676579\n",
      "      - -210520.01987097308\n",
      "      - -204455.10332116354\n",
      "      - -214659.63756840155\n",
      "      - -208894.29153211004\n",
      "      - -209299.87522485878\n",
      "      - -215833.94459741344\n",
      "      - -223922.4213300969\n",
      "      - -209775.5793245857\n",
      "      - -213535.4745724559\n",
      "      - -209550.5947267409\n",
      "      - -210269.99913425438\n",
      "      - -210468.84366319704\n",
      "      - -211415.70020714213\n",
      "      - -208559.62373521106\n",
      "      - -210134.58821917415\n",
      "      - -211559.12793105206\n",
      "      - -217714.88754146642\n",
      "      - -207852.28958112188\n",
      "      - -217551.53520949814\n",
      "      - -210173.57587727127\n",
      "      - -207391.36649344902\n",
      "      - -212164.9467813764\n",
      "      - -208960.53003500734\n",
      "      - -203838.8939274313\n",
      "      - -210010.64231865807\n",
      "      - -208246.99581310851\n",
      "      - -201925.83368059693\n",
      "      - -206503.30946493754\n",
      "      - -209976.71668359687\n",
      "      - -257401.954061939\n",
      "      - -209820.14528236832\n",
      "      - -206517.70683709838\n",
      "      - -216462.81069102604\n",
      "      - -213904.49731934225\n",
      "      - -212324.747651714\n",
      "      - -207580.63953349355\n",
      "      - -221090.48177389475\n",
      "      - -209634.57400248217\n",
      "      - -217710.35013897743\n",
      "      - -209605.55534679588\n",
      "      - -210259.70535100243\n",
      "      - -205020.17325710977\n",
      "      - -211071.9283910685\n",
      "      - -208732.47594095243\n",
      "      - -221959.48258984712\n",
      "      - -208762.14782197052\n",
      "      - -217374.30680178577\n",
      "      - -211638.1361818287\n",
      "      - -208383.12385909454\n",
      "      - -207948.9450050893\n",
      "      - -207559.0312313735\n",
      "      - -213526.41096817594\n",
      "      - -212443.85542699872\n",
      "      - -216001.68148391615\n",
      "      - -208738.1627293713\n",
      "      - -203494.17482633176\n",
      "      - -211665.29827971535\n",
      "      - -208859.51990299136\n",
      "      - -215222.76640736804\n",
      "      - -212652.727693825\n",
      "      - -218475.23273601188\n",
      "      - -211169.97818960782\n",
      "      - -205387.2688251058\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11820714963149377\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5144845246272016\n",
      "      mean_inference_ms: 1.5898675617798868\n",
      "      mean_raw_obs_processing_ms: 0.1625568393999499\n",
      "  time_since_restore: 703.1097540855408\n",
      "  time_this_iter_s: 16.19260311126709\n",
      "  time_total_s: 703.1097540855408\n",
      "  timers:\n",
      "    learn_throughput: 25824.486\n",
      "    learn_time_ms: 2477.649\n",
      "    load_throughput: 531468.986\n",
      "    load_time_ms: 120.391\n",
      "    training_iteration_time_ms: 15414.5\n",
      "    update_time_ms: 4.22\n",
      "  timestamp: 1665742918\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2879280\n",
      "  training_iteration: 45\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:22:03 (running for 00:12:05.59)<br>Memory usage on this node: 12.1/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    45</td><td style=\"text-align: right;\">          703.11</td><td style=\"text-align: right;\">2.87928e+06</td><td style=\"text-align: right;\"> -211954</td><td style=\"text-align: right;\">             -201926</td><td style=\"text-align: right;\">             -273376</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:22:08 (running for 00:12:11.02)<br>Memory usage on this node: 12.1/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    45</td><td style=\"text-align: right;\">          703.11</td><td style=\"text-align: right;\">2.87928e+06</td><td style=\"text-align: right;\"> -211954</td><td style=\"text-align: right;\">             -201926</td><td style=\"text-align: right;\">             -273376</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 2943264\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 2943264\n",
      "    num_agent_steps_trained: 2943264\n",
      "    num_env_steps_sampled: 2943264\n",
      "    num_env_steps_trained: 2943264\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-22-13\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -203494.17482633176\n",
      "  episode_reward_mean: -211341.66232782352\n",
      "  episode_reward_min: -229291.99028035946\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 2940\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1148719787597656\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.001785535947419703\n",
      "          model: {}\n",
      "          policy_loss: 0.002856388920918107\n",
      "          total_loss: 10.002902030944824\n",
      "          vf_explained_var: -1.282416860703961e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 2943264\n",
      "    num_agent_steps_trained: 2943264\n",
      "    num_env_steps_sampled: 2943264\n",
      "    num_env_steps_trained: 2943264\n",
      "  iterations_since_restore: 46\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 2943264\n",
      "  num_agent_steps_trained: 2943264\n",
      "  num_env_steps_sampled: 2943264\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 2943264\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.10000000000001\n",
      "    ram_util_percent: 78.23809523809523\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1183334412480297\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5143500561840422\n",
      "    mean_inference_ms: 1.5908248845489725\n",
      "    mean_raw_obs_processing_ms: 0.16268690319788903\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -203494.17482633176\n",
      "    episode_reward_mean: -211341.66232782352\n",
      "    episode_reward_min: -229291.99028035946\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -207580.63953349355\n",
      "      - -221090.48177389475\n",
      "      - -209634.57400248217\n",
      "      - -217710.35013897743\n",
      "      - -209605.55534679588\n",
      "      - -210259.70535100243\n",
      "      - -205020.17325710977\n",
      "      - -211071.9283910685\n",
      "      - -208732.47594095243\n",
      "      - -221959.48258984712\n",
      "      - -208762.14782197052\n",
      "      - -217374.30680178577\n",
      "      - -211638.1361818287\n",
      "      - -208383.12385909454\n",
      "      - -207948.9450050893\n",
      "      - -207559.0312313735\n",
      "      - -213526.41096817594\n",
      "      - -212443.85542699872\n",
      "      - -216001.68148391615\n",
      "      - -208738.1627293713\n",
      "      - -203494.17482633176\n",
      "      - -211665.29827971535\n",
      "      - -208859.51990299136\n",
      "      - -215222.76640736804\n",
      "      - -212652.727693825\n",
      "      - -218475.23273601188\n",
      "      - -211169.97818960782\n",
      "      - -205387.2688251058\n",
      "      - -209813.3017759085\n",
      "      - -212410.43887363182\n",
      "      - -210647.0838607477\n",
      "      - -212669.0879751875\n",
      "      - -212399.54901520186\n",
      "      - -216161.63297821168\n",
      "      - -206723.24551552275\n",
      "      - -212672.33676630422\n",
      "      - -209973.31165287894\n",
      "      - -207224.02912455474\n",
      "      - -211675.54424182937\n",
      "      - -212290.8456338128\n",
      "      - -211519.01823343826\n",
      "      - -210636.11712288947\n",
      "      - -209253.2430275158\n",
      "      - -212246.81522384947\n",
      "      - -207367.76511764553\n",
      "      - -210771.38053614795\n",
      "      - -215519.8081702031\n",
      "      - -208940.3161060983\n",
      "      - -210263.84176606988\n",
      "      - -209931.8521186295\n",
      "      - -207409.4232405193\n",
      "      - -217948.90185149328\n",
      "      - -213112.15732520618\n",
      "      - -211062.63049582695\n",
      "      - -214350.2388183226\n",
      "      - -213717.92341968085\n",
      "      - -211757.90258302807\n",
      "      - -204315.80261391128\n",
      "      - -208742.6455889251\n",
      "      - -209401.5190710498\n",
      "      - -208292.44441132608\n",
      "      - -216519.50136748858\n",
      "      - -206571.63365986405\n",
      "      - -207084.01251449386\n",
      "      - -213954.7580431824\n",
      "      - -215690.10831046285\n",
      "      - -206350.3086898044\n",
      "      - -213302.61137701903\n",
      "      - -209752.0674907925\n",
      "      - -208007.18117638503\n",
      "      - -210849.55523907568\n",
      "      - -211205.27244868985\n",
      "      - -208583.707306113\n",
      "      - -212350.8293947087\n",
      "      - -212084.1386334838\n",
      "      - -209011.50285493332\n",
      "      - -221105.27753903234\n",
      "      - -214182.1178576448\n",
      "      - -214005.41011317202\n",
      "      - -210224.71987145036\n",
      "      - -213459.94531259453\n",
      "      - -207038.57525038958\n",
      "      - -213560.26862991098\n",
      "      - -209581.59948740294\n",
      "      - -212642.15577252343\n",
      "      - -208820.588615376\n",
      "      - -209898.84875416648\n",
      "      - -212535.98452102844\n",
      "      - -205200.43340958166\n",
      "      - -205640.71430271133\n",
      "      - -213566.78271236972\n",
      "      - -209088.54059000846\n",
      "      - -229291.99028035946\n",
      "      - -210196.2394262475\n",
      "      - -209581.45081300588\n",
      "      - -211281.15736457994\n",
      "      - -218542.85214928503\n",
      "      - -214718.0609928795\n",
      "      - -209505.7280207756\n",
      "      - -205989.31353760828\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1183334412480297\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5143500561840422\n",
      "      mean_inference_ms: 1.5908248845489725\n",
      "      mean_raw_obs_processing_ms: 0.16268690319788903\n",
      "  time_since_restore: 718.141165971756\n",
      "  time_this_iter_s: 15.03141188621521\n",
      "  time_total_s: 718.141165971756\n",
      "  timers:\n",
      "    learn_throughput: 25654.03\n",
      "    learn_time_ms: 2494.111\n",
      "    load_throughput: 535525.87\n",
      "    load_time_ms: 119.479\n",
      "    training_iteration_time_ms: 15401.865\n",
      "    update_time_ms: 4.218\n",
      "  timestamp: 1665742933\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 2943264\n",
      "  training_iteration: 46\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:22:19 (running for 00:12:21.26)<br>Memory usage on this node: 12.1/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    46</td><td style=\"text-align: right;\">         718.141</td><td style=\"text-align: right;\">2.94326e+06</td><td style=\"text-align: right;\"> -211342</td><td style=\"text-align: right;\">             -203494</td><td style=\"text-align: right;\">             -229292</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:22:24 (running for 00:12:26.26)<br>Memory usage on this node: 12.1/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    46</td><td style=\"text-align: right;\">         718.141</td><td style=\"text-align: right;\">2.94326e+06</td><td style=\"text-align: right;\"> -211342</td><td style=\"text-align: right;\">             -203494</td><td style=\"text-align: right;\">             -229292</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:22:29 (running for 00:12:31.39)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    46</td><td style=\"text-align: right;\">         718.141</td><td style=\"text-align: right;\">2.94326e+06</td><td style=\"text-align: right;\"> -211342</td><td style=\"text-align: right;\">             -203494</td><td style=\"text-align: right;\">             -229292</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 3007248\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 3007248\n",
      "    num_agent_steps_trained: 3007248\n",
      "    num_env_steps_sampled: 3007248\n",
      "    num_env_steps_trained: 3007248\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-22-29\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -204621.5585590346\n",
      "  episode_reward_mean: -210620.98052662\n",
      "  episode_reward_min: -229291.99028035946\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 3000\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.115812063217163\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0014630205696448684\n",
      "          model: {}\n",
      "          policy_loss: 0.005514125339686871\n",
      "          total_loss: 10.005495071411133\n",
      "          vf_explained_var: -2.5671261028037407e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 3007248\n",
      "    num_agent_steps_trained: 3007248\n",
      "    num_env_steps_sampled: 3007248\n",
      "    num_env_steps_trained: 3007248\n",
      "  iterations_since_restore: 47\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 3007248\n",
      "  num_agent_steps_trained: 3007248\n",
      "  num_env_steps_sampled: 3007248\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 3007248\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.80000000000003\n",
      "    ram_util_percent: 78.11739130434783\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1182206223155831\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5143618394748821\n",
      "    mean_inference_ms: 1.591889742829817\n",
      "    mean_raw_obs_processing_ms: 0.16277349048243062\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -204621.5585590346\n",
      "    episode_reward_mean: -210620.98052662\n",
      "    episode_reward_min: -229291.99028035946\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -208292.44441132608\n",
      "      - -216519.50136748858\n",
      "      - -206571.63365986405\n",
      "      - -207084.01251449386\n",
      "      - -213954.7580431824\n",
      "      - -215690.10831046285\n",
      "      - -206350.3086898044\n",
      "      - -213302.61137701903\n",
      "      - -209752.0674907925\n",
      "      - -208007.18117638503\n",
      "      - -210849.55523907568\n",
      "      - -211205.27244868985\n",
      "      - -208583.707306113\n",
      "      - -212350.8293947087\n",
      "      - -212084.1386334838\n",
      "      - -209011.50285493332\n",
      "      - -221105.27753903234\n",
      "      - -214182.1178576448\n",
      "      - -214005.41011317202\n",
      "      - -210224.71987145036\n",
      "      - -213459.94531259453\n",
      "      - -207038.57525038958\n",
      "      - -213560.26862991098\n",
      "      - -209581.59948740294\n",
      "      - -212642.15577252343\n",
      "      - -208820.588615376\n",
      "      - -209898.84875416648\n",
      "      - -212535.98452102844\n",
      "      - -205200.43340958166\n",
      "      - -205640.71430271133\n",
      "      - -213566.78271236972\n",
      "      - -209088.54059000846\n",
      "      - -229291.99028035946\n",
      "      - -210196.2394262475\n",
      "      - -209581.45081300588\n",
      "      - -211281.15736457994\n",
      "      - -218542.85214928503\n",
      "      - -214718.0609928795\n",
      "      - -209505.7280207756\n",
      "      - -205989.31353760828\n",
      "      - -205116.11749221684\n",
      "      - -207465.21973583696\n",
      "      - -210448.61618092487\n",
      "      - -218869.71602936735\n",
      "      - -206067.76146840022\n",
      "      - -213186.55548632698\n",
      "      - -207501.7625167411\n",
      "      - -213536.22632597268\n",
      "      - -210086.54714029646\n",
      "      - -212738.04978127265\n",
      "      - -219730.4830277457\n",
      "      - -208646.69043933495\n",
      "      - -216668.651129258\n",
      "      - -207046.29606965263\n",
      "      - -211176.99995529352\n",
      "      - -210547.78889236916\n",
      "      - -206943.63432906245\n",
      "      - -209865.5979750593\n",
      "      - -211966.77401026594\n",
      "      - -209380.93223464652\n",
      "      - -213625.53960007307\n",
      "      - -208544.6824577963\n",
      "      - -207985.24001724005\n",
      "      - -207470.53972487545\n",
      "      - -210302.28920218398\n",
      "      - -208765.41289639397\n",
      "      - -210033.89430859752\n",
      "      - -207794.57024991963\n",
      "      - -209538.65430870774\n",
      "      - -205959.04604875582\n",
      "      - -214335.649975487\n",
      "      - -207501.93347956098\n",
      "      - -213828.05098439928\n",
      "      - -206899.38696455883\n",
      "      - -208234.86401518364\n",
      "      - -211757.54731012302\n",
      "      - -210407.15100098884\n",
      "      - -211920.87749086219\n",
      "      - -216328.119701243\n",
      "      - -211589.54521376858\n",
      "      - -207102.42798164432\n",
      "      - -208400.9746146916\n",
      "      - -211649.5556084302\n",
      "      - -209172.97740230884\n",
      "      - -204621.5585590346\n",
      "      - -206937.132326335\n",
      "      - -211851.49861947386\n",
      "      - -207068.111734971\n",
      "      - -212511.80398135664\n",
      "      - -207155.93382504146\n",
      "      - -209804.75732919737\n",
      "      - -212001.67135103873\n",
      "      - -209369.04970138258\n",
      "      - -208825.36849673657\n",
      "      - -207758.5019631088\n",
      "      - -206070.25037283677\n",
      "      - -209164.15514555146\n",
      "      - -205477.81770879016\n",
      "      - -215480.73250411247\n",
      "      - -212591.9700232653\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1182206223155831\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5143618394748821\n",
      "      mean_inference_ms: 1.591889742829817\n",
      "      mean_raw_obs_processing_ms: 0.16277349048243062\n",
      "  time_since_restore: 734.5119032859802\n",
      "  time_this_iter_s: 16.370737314224243\n",
      "  time_total_s: 734.5119032859802\n",
      "  timers:\n",
      "    learn_throughput: 25539.717\n",
      "    learn_time_ms: 2505.274\n",
      "    load_throughput: 531868.607\n",
      "    load_time_ms: 120.3\n",
      "    training_iteration_time_ms: 15559.164\n",
      "    update_time_ms: 4.236\n",
      "  timestamp: 1665742949\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3007248\n",
      "  training_iteration: 47\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:22:34 (running for 00:12:37.05)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    47</td><td style=\"text-align: right;\">         734.512</td><td style=\"text-align: right;\">3.00725e+06</td><td style=\"text-align: right;\"> -210621</td><td style=\"text-align: right;\">             -204622</td><td style=\"text-align: right;\">             -229292</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:22:39 (running for 00:12:42.14)<br>Memory usage on this node: 12.0/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    47</td><td style=\"text-align: right;\">         734.512</td><td style=\"text-align: right;\">3.00725e+06</td><td style=\"text-align: right;\"> -210621</td><td style=\"text-align: right;\">             -204622</td><td style=\"text-align: right;\">             -229292</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:22:45 (running for 00:12:47.45)<br>Memory usage on this node: 11.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    47</td><td style=\"text-align: right;\">         734.512</td><td style=\"text-align: right;\">3.00725e+06</td><td style=\"text-align: right;\"> -210621</td><td style=\"text-align: right;\">             -204622</td><td style=\"text-align: right;\">             -229292</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 3071232\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 3071232\n",
      "    num_agent_steps_trained: 3071232\n",
      "    num_env_steps_sampled: 3071232\n",
      "    num_env_steps_trained: 3071232\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-22-45\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -204066.1226552671\n",
      "  episode_reward_mean: -210108.98370469653\n",
      "  episode_reward_min: -216883.67271508745\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 3060\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1129753589630127\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0010660489788278937\n",
      "          model: {}\n",
      "          policy_loss: 0.0024476670660078526\n",
      "          total_loss: 10.002349853515625\n",
      "          vf_explained_var: -2.3796008008503122e-07\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 3071232\n",
      "    num_agent_steps_trained: 3071232\n",
      "    num_env_steps_sampled: 3071232\n",
      "    num_env_steps_trained: 3071232\n",
      "  iterations_since_restore: 48\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 3071232\n",
      "  num_agent_steps_trained: 3071232\n",
      "  num_env_steps_sampled: 3071232\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 3071232\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 78.37727272727273\n",
      "    ram_util_percent: 77.65454545454544\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11814607382251285\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.513974896525829\n",
      "    mean_inference_ms: 1.593381008887158\n",
      "    mean_raw_obs_processing_ms: 0.1625750837874194\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -204066.1226552671\n",
      "    episode_reward_mean: -210108.98370469653\n",
      "    episode_reward_min: -216883.67271508745\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -213625.53960007307\n",
      "      - -208544.6824577963\n",
      "      - -207985.24001724005\n",
      "      - -207470.53972487545\n",
      "      - -210302.28920218398\n",
      "      - -208765.41289639397\n",
      "      - -210033.89430859752\n",
      "      - -207794.57024991963\n",
      "      - -209538.65430870774\n",
      "      - -205959.04604875582\n",
      "      - -214335.649975487\n",
      "      - -207501.93347956098\n",
      "      - -213828.05098439928\n",
      "      - -206899.38696455883\n",
      "      - -208234.86401518364\n",
      "      - -211757.54731012302\n",
      "      - -210407.15100098884\n",
      "      - -211920.87749086219\n",
      "      - -216328.119701243\n",
      "      - -211589.54521376858\n",
      "      - -207102.42798164432\n",
      "      - -208400.9746146916\n",
      "      - -211649.5556084302\n",
      "      - -209172.97740230884\n",
      "      - -204621.5585590346\n",
      "      - -206937.132326335\n",
      "      - -211851.49861947386\n",
      "      - -207068.111734971\n",
      "      - -212511.80398135664\n",
      "      - -207155.93382504146\n",
      "      - -209804.75732919737\n",
      "      - -212001.67135103873\n",
      "      - -209369.04970138258\n",
      "      - -208825.36849673657\n",
      "      - -207758.5019631088\n",
      "      - -206070.25037283677\n",
      "      - -209164.15514555146\n",
      "      - -205477.81770879016\n",
      "      - -215480.73250411247\n",
      "      - -212591.9700232653\n",
      "      - -205740.62677947019\n",
      "      - -205733.99350332943\n",
      "      - -208634.17093622716\n",
      "      - -210580.6948240233\n",
      "      - -214007.5851430163\n",
      "      - -212035.42464884327\n",
      "      - -210016.31655774722\n",
      "      - -208695.49866797254\n",
      "      - -207835.1217481124\n",
      "      - -213204.50044042204\n",
      "      - -211244.31656132106\n",
      "      - -211866.2883838768\n",
      "      - -212170.43318487523\n",
      "      - -208482.8536605285\n",
      "      - -211756.43602198522\n",
      "      - -211627.72387525334\n",
      "      - -211063.9990579747\n",
      "      - -211241.61710720783\n",
      "      - -208428.1752900796\n",
      "      - -207481.91301273182\n",
      "      - -214285.05903837946\n",
      "      - -208503.32721259716\n",
      "      - -209207.1393534009\n",
      "      - -211779.60241947434\n",
      "      - -210399.94258357774\n",
      "      - -211415.26000802912\n",
      "      - -210965.0794068338\n",
      "      - -215449.6693720749\n",
      "      - -205254.83234021746\n",
      "      - -210564.9468453406\n",
      "      - -215287.5526403448\n",
      "      - -209748.70082577755\n",
      "      - -210787.39606510356\n",
      "      - -210745.265101974\n",
      "      - -214526.50301686913\n",
      "      - -208313.89289198842\n",
      "      - -211026.42022582906\n",
      "      - -212092.69535539558\n",
      "      - -211549.02337502842\n",
      "      - -207179.66110150897\n",
      "      - -209540.40041283763\n",
      "      - -207073.9082216745\n",
      "      - -207844.8441983272\n",
      "      - -212892.14701899045\n",
      "      - -208006.08579676237\n",
      "      - -212797.1888392882\n",
      "      - -208528.89965071806\n",
      "      - -209334.67038429854\n",
      "      - -213243.79790744674\n",
      "      - -215680.40185305825\n",
      "      - -209466.0917718311\n",
      "      - -208466.68195744348\n",
      "      - -207599.4088542807\n",
      "      - -211379.72116144263\n",
      "      - -210604.05679104564\n",
      "      - -210915.0125451192\n",
      "      - -210769.81497528157\n",
      "      - -204066.1226552671\n",
      "      - -209036.53997468465\n",
      "      - -216883.67271508745\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11814607382251285\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.513974896525829\n",
      "      mean_inference_ms: 1.593381008887158\n",
      "      mean_raw_obs_processing_ms: 0.1625750837874194\n",
      "  time_since_restore: 750.4919018745422\n",
      "  time_this_iter_s: 15.979998588562012\n",
      "  time_total_s: 750.4919018745422\n",
      "  timers:\n",
      "    learn_throughput: 24965.095\n",
      "    learn_time_ms: 2562.938\n",
      "    load_throughput: 532432.51\n",
      "    load_time_ms: 120.173\n",
      "    training_iteration_time_ms: 15602.771\n",
      "    update_time_ms: 4.437\n",
      "  timestamp: 1665742965\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3071232\n",
      "  training_iteration: 48\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:22:50 (running for 00:12:53.14)<br>Memory usage on this node: 11.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    48</td><td style=\"text-align: right;\">         750.492</td><td style=\"text-align: right;\">3.07123e+06</td><td style=\"text-align: right;\"> -210109</td><td style=\"text-align: right;\">             -204066</td><td style=\"text-align: right;\">             -216884</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:22:56 (running for 00:12:58.50)<br>Memory usage on this node: 11.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    48</td><td style=\"text-align: right;\">         750.492</td><td style=\"text-align: right;\">3.07123e+06</td><td style=\"text-align: right;\"> -210109</td><td style=\"text-align: right;\">             -204066</td><td style=\"text-align: right;\">             -216884</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 3135216\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 3135216\n",
      "    num_agent_steps_trained: 3135216\n",
      "    num_env_steps_sampled: 3135216\n",
      "    num_env_steps_trained: 3135216\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-23-01\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -204058.18109268972\n",
      "  episode_reward_mean: -210112.22566527434\n",
      "  episode_reward_min: -218292.21040387842\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 3132\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1119656562805176\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0018015984678640962\n",
      "          model: {}\n",
      "          policy_loss: 0.002420231467112899\n",
      "          total_loss: 10.002470016479492\n",
      "          vf_explained_var: -2.905497240135446e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 3135216\n",
      "    num_agent_steps_trained: 3135216\n",
      "    num_env_steps_sampled: 3135216\n",
      "    num_env_steps_trained: 3135216\n",
      "  iterations_since_restore: 49\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 3135216\n",
      "  num_agent_steps_trained: 3135216\n",
      "  num_env_steps_sampled: 3135216\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 3135216\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.95454545454544\n",
      "    ram_util_percent: 76.94545454545458\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11848236435797749\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5140649444510121\n",
      "    mean_inference_ms: 1.5935370139857474\n",
      "    mean_raw_obs_processing_ms: 0.1627287604560101\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -204058.18109268972\n",
      "    episode_reward_mean: -210112.22566527434\n",
      "    episode_reward_min: -218292.21040387842\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -210787.39606510356\n",
      "      - -210745.265101974\n",
      "      - -214526.50301686913\n",
      "      - -208313.89289198842\n",
      "      - -211026.42022582906\n",
      "      - -212092.69535539558\n",
      "      - -211549.02337502842\n",
      "      - -207179.66110150897\n",
      "      - -209540.40041283763\n",
      "      - -207073.9082216745\n",
      "      - -207844.8441983272\n",
      "      - -212892.14701899045\n",
      "      - -208006.08579676237\n",
      "      - -212797.1888392882\n",
      "      - -208528.89965071806\n",
      "      - -209334.67038429854\n",
      "      - -213243.79790744674\n",
      "      - -215680.40185305825\n",
      "      - -209466.0917718311\n",
      "      - -208466.68195744348\n",
      "      - -207599.4088542807\n",
      "      - -211379.72116144263\n",
      "      - -210604.05679104564\n",
      "      - -210915.0125451192\n",
      "      - -210769.81497528157\n",
      "      - -204066.1226552671\n",
      "      - -209036.53997468465\n",
      "      - -216883.67271508745\n",
      "      - -206393.76844667993\n",
      "      - -215886.83477252733\n",
      "      - -205433.60855334913\n",
      "      - -206322.10506341216\n",
      "      - -213246.87744977753\n",
      "      - -210047.10727525162\n",
      "      - -211694.54395966858\n",
      "      - -208865.73349657704\n",
      "      - -213343.95144675006\n",
      "      - -209658.24223927903\n",
      "      - -204976.53786211854\n",
      "      - -211614.6443925596\n",
      "      - -212095.38998210928\n",
      "      - -212172.53708300256\n",
      "      - -209895.5072836385\n",
      "      - -213811.4368699961\n",
      "      - -212105.93737318256\n",
      "      - -204519.65632860825\n",
      "      - -209284.50476129557\n",
      "      - -209417.21866107316\n",
      "      - -210067.33638492116\n",
      "      - -212726.2404005907\n",
      "      - -207182.85621657778\n",
      "      - -207574.59982911762\n",
      "      - -212645.30910461966\n",
      "      - -208316.07705831507\n",
      "      - -208800.21669542752\n",
      "      - -211110.59600102968\n",
      "      - -209909.43213888397\n",
      "      - -209846.11402330647\n",
      "      - -207190.34549454722\n",
      "      - -208698.13865047845\n",
      "      - -211883.06492306056\n",
      "      - -213047.34362657196\n",
      "      - -210553.9113022241\n",
      "      - -210534.4097342614\n",
      "      - -214987.80588136593\n",
      "      - -217711.233680384\n",
      "      - -207533.5354587457\n",
      "      - -204058.18109268972\n",
      "      - -211976.07486416062\n",
      "      - -210916.94164486282\n",
      "      - -217945.70218811263\n",
      "      - -208349.0542701147\n",
      "      - -205430.30187689676\n",
      "      - -206541.61782872572\n",
      "      - -206438.39026420264\n",
      "      - -218292.21040387842\n",
      "      - -212741.33480677538\n",
      "      - -211316.737382851\n",
      "      - -214339.90631515032\n",
      "      - -207974.037194323\n",
      "      - -206580.67978170773\n",
      "      - -206311.73613629563\n",
      "      - -213192.40737020675\n",
      "      - -206619.12729458092\n",
      "      - -215484.18913232585\n",
      "      - -204285.51397598733\n",
      "      - -205327.67640785998\n",
      "      - -215088.61345898552\n",
      "      - -212827.5512306223\n",
      "      - -204552.97918218188\n",
      "      - -204775.29503866524\n",
      "      - -211285.85449373486\n",
      "      - -206472.14836984396\n",
      "      - -208521.98974213595\n",
      "      - -214499.02409202824\n",
      "      - -213169.232826998\n",
      "      - -212770.91335210184\n",
      "      - -207188.39916783196\n",
      "      - -209319.36502276908\n",
      "      - -205174.3455939609\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11848236435797749\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5140649444510121\n",
      "      mean_inference_ms: 1.5935370139857474\n",
      "      mean_raw_obs_processing_ms: 0.1627287604560101\n",
      "  time_since_restore: 765.8090431690216\n",
      "  time_this_iter_s: 15.31714129447937\n",
      "  time_total_s: 765.8090431690216\n",
      "  timers:\n",
      "    learn_throughput: 24887.253\n",
      "    learn_time_ms: 2570.955\n",
      "    load_throughput: 529948.792\n",
      "    load_time_ms: 120.736\n",
      "    training_iteration_time_ms: 15630.342\n",
      "    update_time_ms: 4.422\n",
      "  timestamp: 1665742981\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3135216\n",
      "  training_iteration: 49\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:23:06 (running for 00:13:08.87)<br>Memory usage on this node: 11.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    49</td><td style=\"text-align: right;\">         765.809</td><td style=\"text-align: right;\">3.13522e+06</td><td style=\"text-align: right;\"> -210112</td><td style=\"text-align: right;\">             -204058</td><td style=\"text-align: right;\">             -218292</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:23:11 (running for 00:13:13.88)<br>Memory usage on this node: 11.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    49</td><td style=\"text-align: right;\">         765.809</td><td style=\"text-align: right;\">3.13522e+06</td><td style=\"text-align: right;\"> -210112</td><td style=\"text-align: right;\">             -204058</td><td style=\"text-align: right;\">             -218292</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 3199200\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 3199200\n",
      "    num_agent_steps_trained: 3199200\n",
      "    num_env_steps_sampled: 3199200\n",
      "    num_env_steps_trained: 3199200\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-23-16\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -203181.4601174884\n",
      "  episode_reward_mean: -210447.80910205952\n",
      "  episode_reward_min: -267740.5793694569\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 3192\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.1120998859405518\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0019388669170439243\n",
      "          model: {}\n",
      "          policy_loss: 0.0021734798792749643\n",
      "          total_loss: 10.002249717712402\n",
      "          vf_explained_var: -2.770240598692908e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 3199200\n",
      "    num_agent_steps_trained: 3199200\n",
      "    num_env_steps_sampled: 3199200\n",
      "    num_env_steps_trained: 3199200\n",
      "  iterations_since_restore: 50\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 3199200\n",
      "  num_agent_steps_trained: 3199200\n",
      "  num_env_steps_sampled: 3199200\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 3199200\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.90454545454544\n",
      "    ram_util_percent: 76.6272727272727\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11830586469881453\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.514059399654302\n",
      "    mean_inference_ms: 1.591835018158354\n",
      "    mean_raw_obs_processing_ms: 0.1627682633547945\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -203181.4601174884\n",
      "    episode_reward_mean: -210447.80910205952\n",
      "    episode_reward_min: -267740.5793694569\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -211883.06492306056\n",
      "      - -213047.34362657196\n",
      "      - -210553.9113022241\n",
      "      - -210534.4097342614\n",
      "      - -214987.80588136593\n",
      "      - -217711.233680384\n",
      "      - -207533.5354587457\n",
      "      - -204058.18109268972\n",
      "      - -211976.07486416062\n",
      "      - -210916.94164486282\n",
      "      - -217945.70218811263\n",
      "      - -208349.0542701147\n",
      "      - -205430.30187689676\n",
      "      - -206541.61782872572\n",
      "      - -206438.39026420264\n",
      "      - -218292.21040387842\n",
      "      - -212741.33480677538\n",
      "      - -211316.737382851\n",
      "      - -214339.90631515032\n",
      "      - -207974.037194323\n",
      "      - -206580.67978170773\n",
      "      - -206311.73613629563\n",
      "      - -213192.40737020675\n",
      "      - -206619.12729458092\n",
      "      - -215484.18913232585\n",
      "      - -204285.51397598733\n",
      "      - -205327.67640785998\n",
      "      - -215088.61345898552\n",
      "      - -212827.5512306223\n",
      "      - -204552.97918218188\n",
      "      - -204775.29503866524\n",
      "      - -211285.85449373486\n",
      "      - -206472.14836984396\n",
      "      - -208521.98974213595\n",
      "      - -214499.02409202824\n",
      "      - -213169.232826998\n",
      "      - -212770.91335210184\n",
      "      - -207188.39916783196\n",
      "      - -209319.36502276908\n",
      "      - -205174.3455939609\n",
      "      - -208998.77971954056\n",
      "      - -204527.74063110925\n",
      "      - -210090.83674348603\n",
      "      - -205380.4276579692\n",
      "      - -209408.5845071298\n",
      "      - -204778.06943350227\n",
      "      - -208908.71648502894\n",
      "      - -208435.19365358385\n",
      "      - -205933.65355346407\n",
      "      - -211997.95311012\n",
      "      - -214862.22747278083\n",
      "      - -208026.56936472387\n",
      "      - -210013.95853290768\n",
      "      - -219383.27593708356\n",
      "      - -215395.45370915678\n",
      "      - -209728.64797266625\n",
      "      - -207490.98309378565\n",
      "      - -207071.0925008494\n",
      "      - -208600.03568074136\n",
      "      - -210482.54469630454\n",
      "      - -208588.32937769862\n",
      "      - -209804.52488084548\n",
      "      - -210246.17999647657\n",
      "      - -203181.4601174884\n",
      "      - -210315.74460652424\n",
      "      - -207455.48798137016\n",
      "      - -206536.16887593066\n",
      "      - -208826.70330883138\n",
      "      - -208080.71183909074\n",
      "      - -209912.80692150258\n",
      "      - -208920.51285574553\n",
      "      - -206163.3701263638\n",
      "      - -228184.70327545222\n",
      "      - -209992.99157435106\n",
      "      - -213758.49511664503\n",
      "      - -214176.91099905697\n",
      "      - -206211.9409184598\n",
      "      - -211330.50808750285\n",
      "      - -210145.414619942\n",
      "      - -208400.81885539263\n",
      "      - -209956.41486275292\n",
      "      - -267740.5793694569\n",
      "      - -207427.2575361802\n",
      "      - -208026.5058936442\n",
      "      - -207236.28122260605\n",
      "      - -220547.9305380579\n",
      "      - -206207.1760174693\n",
      "      - -204628.86215094296\n",
      "      - -208307.5213559816\n",
      "      - -209592.56183466842\n",
      "      - -220266.19253161785\n",
      "      - -208215.34592081464\n",
      "      - -211872.6781779682\n",
      "      - -207356.07501630308\n",
      "      - -213657.13270283575\n",
      "      - -206992.5456446526\n",
      "      - -204520.99299150886\n",
      "      - -206630.32270276878\n",
      "      - -211461.24363324587\n",
      "      - -208369.9249016952\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11830586469881453\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.514059399654302\n",
      "      mean_inference_ms: 1.591835018158354\n",
      "      mean_raw_obs_processing_ms: 0.1627682633547945\n",
      "  time_since_restore: 781.578408241272\n",
      "  time_this_iter_s: 15.769365072250366\n",
      "  time_total_s: 781.578408241272\n",
      "  timers:\n",
      "    learn_throughput: 24974.801\n",
      "    learn_time_ms: 2561.942\n",
      "    load_throughput: 309011.591\n",
      "    load_time_ms: 207.06\n",
      "    training_iteration_time_ms: 15610.435\n",
      "    update_time_ms: 4.431\n",
      "  timestamp: 1665742996\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3199200\n",
      "  training_iteration: 50\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:23:16 (running for 00:13:19.21)<br>Memory usage on this node: 11.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         781.578</td><td style=\"text-align: right;\">3.1992e+06</td><td style=\"text-align: right;\"> -210448</td><td style=\"text-align: right;\">             -203181</td><td style=\"text-align: right;\">             -267741</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:23:22 (running for 00:13:24.31)<br>Memory usage on this node: 11.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         781.578</td><td style=\"text-align: right;\">3.1992e+06</td><td style=\"text-align: right;\"> -210448</td><td style=\"text-align: right;\">             -203181</td><td style=\"text-align: right;\">             -267741</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:23:27 (running for 00:13:29.59)<br>Memory usage on this node: 11.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         781.578</td><td style=\"text-align: right;\">3.1992e+06</td><td style=\"text-align: right;\"> -210448</td><td style=\"text-align: right;\">             -203181</td><td style=\"text-align: right;\">             -267741</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 3263184\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 3263184\n",
      "    num_agent_steps_trained: 3263184\n",
      "    num_env_steps_sampled: 3263184\n",
      "    num_env_steps_trained: 3263184\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-23-31\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -201061.5664545836\n",
      "  episode_reward_mean: -209158.51245016715\n",
      "  episode_reward_min: -267740.5793694569\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 3252\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.108823776245117\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.002153043169528246\n",
      "          model: {}\n",
      "          policy_loss: 0.0018645982490852475\n",
      "          total_loss: 10.001984596252441\n",
      "          vf_explained_var: -2.2108738448878285e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 3263184\n",
      "    num_agent_steps_trained: 3263184\n",
      "    num_env_steps_sampled: 3263184\n",
      "    num_env_steps_trained: 3263184\n",
      "  iterations_since_restore: 51\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 3263184\n",
      "  num_agent_steps_trained: 3263184\n",
      "  num_env_steps_sampled: 3263184\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 3263184\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.0142857142857\n",
      "    ram_util_percent: 76.60476190476189\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11809135353916435\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5133891503760216\n",
      "    mean_inference_ms: 1.59046096295949\n",
      "    mean_raw_obs_processing_ms: 0.16242383105210595\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -201061.5664545836\n",
      "    episode_reward_mean: -209158.51245016715\n",
      "    episode_reward_min: -267740.5793694569\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -208588.32937769862\n",
      "      - -209804.52488084548\n",
      "      - -210246.17999647657\n",
      "      - -203181.4601174884\n",
      "      - -210315.74460652424\n",
      "      - -207455.48798137016\n",
      "      - -206536.16887593066\n",
      "      - -208826.70330883138\n",
      "      - -208080.71183909074\n",
      "      - -209912.80692150258\n",
      "      - -208920.51285574553\n",
      "      - -206163.3701263638\n",
      "      - -228184.70327545222\n",
      "      - -209992.99157435106\n",
      "      - -213758.49511664503\n",
      "      - -214176.91099905697\n",
      "      - -206211.9409184598\n",
      "      - -211330.50808750285\n",
      "      - -210145.414619942\n",
      "      - -208400.81885539263\n",
      "      - -209956.41486275292\n",
      "      - -267740.5793694569\n",
      "      - -207427.2575361802\n",
      "      - -208026.5058936442\n",
      "      - -207236.28122260605\n",
      "      - -220547.9305380579\n",
      "      - -206207.1760174693\n",
      "      - -204628.86215094296\n",
      "      - -208307.5213559816\n",
      "      - -209592.56183466842\n",
      "      - -220266.19253161785\n",
      "      - -208215.34592081464\n",
      "      - -211872.6781779682\n",
      "      - -207356.07501630308\n",
      "      - -213657.13270283575\n",
      "      - -206992.5456446526\n",
      "      - -204520.99299150886\n",
      "      - -206630.32270276878\n",
      "      - -211461.24363324587\n",
      "      - -208369.9249016952\n",
      "      - -213952.4003112689\n",
      "      - -212611.64182734856\n",
      "      - -212026.9799219855\n",
      "      - -207919.24361925895\n",
      "      - -202643.71632884763\n",
      "      - -210845.46685522486\n",
      "      - -203873.21673965652\n",
      "      - -204430.50186738715\n",
      "      - -210240.82031829626\n",
      "      - -207948.23552395205\n",
      "      - -208518.98885453853\n",
      "      - -208438.815913039\n",
      "      - -204696.83933368107\n",
      "      - -208384.26755165754\n",
      "      - -209426.4503515739\n",
      "      - -203308.63035622684\n",
      "      - -206187.06279468263\n",
      "      - -207263.19383149536\n",
      "      - -213049.95169655717\n",
      "      - -203687.87885105153\n",
      "      - -210799.28478556412\n",
      "      - -210492.3320783911\n",
      "      - -211498.39426172973\n",
      "      - -210499.17268318203\n",
      "      - -206933.2173470922\n",
      "      - -206181.28068392366\n",
      "      - -203372.03668584008\n",
      "      - -201061.5664545836\n",
      "      - -206899.7807842736\n",
      "      - -208760.81696816752\n",
      "      - -204456.28864751817\n",
      "      - -212496.32954608175\n",
      "      - -205969.83257202612\n",
      "      - -209274.57925270355\n",
      "      - -207514.97727160563\n",
      "      - -207947.00067895357\n",
      "      - -206054.83144677334\n",
      "      - -209801.77978563047\n",
      "      - -205846.795253752\n",
      "      - -209828.29683171012\n",
      "      - -206247.8008169089\n",
      "      - -206978.1238320398\n",
      "      - -206887.17921577865\n",
      "      - -209199.9549036901\n",
      "      - -206608.00745513997\n",
      "      - -202799.81730248776\n",
      "      - -206787.39879106055\n",
      "      - -208330.67589137907\n",
      "      - -204193.02892299744\n",
      "      - -207060.66206347264\n",
      "      - -205926.5578395944\n",
      "      - -203952.08492879933\n",
      "      - -216350.84325706618\n",
      "      - -205312.21536953203\n",
      "      - -206527.29250064897\n",
      "      - -209345.14708421993\n",
      "      - -212181.3492613475\n",
      "      - -209673.04204482996\n",
      "      - -208623.66944882832\n",
      "      - -208476.16787982083\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11809135353916435\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5133891503760216\n",
      "      mean_inference_ms: 1.59046096295949\n",
      "      mean_raw_obs_processing_ms: 0.16242383105210595\n",
      "  time_since_restore: 796.415577173233\n",
      "  time_this_iter_s: 14.83716893196106\n",
      "  time_total_s: 796.415577173233\n",
      "  timers:\n",
      "    learn_throughput: 25385.797\n",
      "    learn_time_ms: 2520.464\n",
      "    load_throughput: 308521.459\n",
      "    load_time_ms: 207.389\n",
      "    training_iteration_time_ms: 15515.717\n",
      "    update_time_ms: 4.437\n",
      "  timestamp: 1665743011\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3263184\n",
      "  training_iteration: 51\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:23:36 (running for 00:13:39.16)<br>Memory usage on this node: 11.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    51</td><td style=\"text-align: right;\">         796.416</td><td style=\"text-align: right;\">3.26318e+06</td><td style=\"text-align: right;\"> -209159</td><td style=\"text-align: right;\">             -201062</td><td style=\"text-align: right;\">             -267741</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:23:41 (running for 00:13:44.17)<br>Memory usage on this node: 11.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    51</td><td style=\"text-align: right;\">         796.416</td><td style=\"text-align: right;\">3.26318e+06</td><td style=\"text-align: right;\"> -209159</td><td style=\"text-align: right;\">             -201062</td><td style=\"text-align: right;\">             -267741</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:23:46 (running for 00:13:49.19)<br>Memory usage on this node: 11.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    51</td><td style=\"text-align: right;\">         796.416</td><td style=\"text-align: right;\">3.26318e+06</td><td style=\"text-align: right;\"> -209159</td><td style=\"text-align: right;\">             -201062</td><td style=\"text-align: right;\">             -267741</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 3327168\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 3327168\n",
      "    num_agent_steps_trained: 3327168\n",
      "    num_env_steps_sampled: 3327168\n",
      "    num_env_steps_trained: 3327168\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-23-47\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -201718.29990339532\n",
      "  episode_reward_mean: -207736.6693367319\n",
      "  episode_reward_min: -216350.84325706618\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 3324\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.10085129737854\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.002562887268140912\n",
      "          model: {}\n",
      "          policy_loss: 0.007424857467412949\n",
      "          total_loss: 10.0076265335083\n",
      "          vf_explained_var: 5.373588010115782e-07\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 3327168\n",
      "    num_agent_steps_trained: 3327168\n",
      "    num_env_steps_sampled: 3327168\n",
      "    num_env_steps_trained: 3327168\n",
      "  iterations_since_restore: 52\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 3327168\n",
      "  num_agent_steps_trained: 3327168\n",
      "  num_env_steps_sampled: 3327168\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 3327168\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.16190476190476\n",
      "    ram_util_percent: 76.78571428571428\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11824823664536602\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.513496274148681\n",
      "    mean_inference_ms: 1.5906828027245172\n",
      "    mean_raw_obs_processing_ms: 0.16246339893516765\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -201718.29990339532\n",
      "    episode_reward_mean: -207736.6693367319\n",
      "    episode_reward_min: -216350.84325706618\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -205969.83257202612\n",
      "      - -209274.57925270355\n",
      "      - -207514.97727160563\n",
      "      - -207947.00067895357\n",
      "      - -206054.83144677334\n",
      "      - -209801.77978563047\n",
      "      - -205846.795253752\n",
      "      - -209828.29683171012\n",
      "      - -206247.8008169089\n",
      "      - -206978.1238320398\n",
      "      - -206887.17921577865\n",
      "      - -209199.9549036901\n",
      "      - -206608.00745513997\n",
      "      - -202799.81730248776\n",
      "      - -206787.39879106055\n",
      "      - -208330.67589137907\n",
      "      - -204193.02892299744\n",
      "      - -207060.66206347264\n",
      "      - -205926.5578395944\n",
      "      - -203952.08492879933\n",
      "      - -216350.84325706618\n",
      "      - -205312.21536953203\n",
      "      - -206527.29250064897\n",
      "      - -209345.14708421993\n",
      "      - -212181.3492613475\n",
      "      - -209673.04204482996\n",
      "      - -208623.66944882832\n",
      "      - -208476.16787982083\n",
      "      - -203397.72365789022\n",
      "      - -207196.48119503097\n",
      "      - -204722.5348562223\n",
      "      - -207204.8497901795\n",
      "      - -212027.2057535007\n",
      "      - -203726.49032412845\n",
      "      - -216317.58621297526\n",
      "      - -209999.7322975833\n",
      "      - -204901.80187920475\n",
      "      - -208989.87610753317\n",
      "      - -213976.78731265035\n",
      "      - -206263.24163142202\n",
      "      - -212338.2052125969\n",
      "      - -203108.3708995038\n",
      "      - -208208.28112794575\n",
      "      - -204521.77633572088\n",
      "      - -214359.3571814205\n",
      "      - -205199.02464734096\n",
      "      - -211942.9166434497\n",
      "      - -209712.28005308786\n",
      "      - -213548.3223460998\n",
      "      - -212941.05600827668\n",
      "      - -208967.63221695987\n",
      "      - -203923.95352144382\n",
      "      - -206452.5242580383\n",
      "      - -208351.68643100167\n",
      "      - -212725.98531005316\n",
      "      - -215492.90751191636\n",
      "      - -205480.30019557834\n",
      "      - -201903.42672132523\n",
      "      - -209191.68263463367\n",
      "      - -207181.6980180146\n",
      "      - -205484.35515486947\n",
      "      - -202496.36116647208\n",
      "      - -207416.06305483\n",
      "      - -204281.75029731452\n",
      "      - -206578.20013633516\n",
      "      - -203924.91522315674\n",
      "      - -208313.03188870306\n",
      "      - -206638.23583335523\n",
      "      - -209851.3012077921\n",
      "      - -203386.1956414271\n",
      "      - -211245.98338088652\n",
      "      - -206049.0107168224\n",
      "      - -206530.23372672568\n",
      "      - -205554.00474775673\n",
      "      - -202358.65961671536\n",
      "      - -209225.15370164195\n",
      "      - -204397.44732460417\n",
      "      - -208225.7416579122\n",
      "      - -207452.9081915981\n",
      "      - -209666.3606052913\n",
      "      - -208316.4250101752\n",
      "      - -210237.47677645326\n",
      "      - -211143.15225983897\n",
      "      - -207552.1601466787\n",
      "      - -202915.46835719145\n",
      "      - -201981.80066280832\n",
      "      - -201718.29990339532\n",
      "      - -211519.53065932626\n",
      "      - -209041.43776251888\n",
      "      - -202514.47563344162\n",
      "      - -208280.42158945632\n",
      "      - -213819.91296417458\n",
      "      - -208138.76555866416\n",
      "      - -211410.60512765\n",
      "      - -205589.86396913143\n",
      "      - -209891.20315032493\n",
      "      - -211998.06559451553\n",
      "      - -204563.90552743286\n",
      "      - -209694.52666995133\n",
      "      - -206288.7128803209\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11824823664536602\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.513496274148681\n",
      "      mean_inference_ms: 1.5906828027245172\n",
      "      mean_raw_obs_processing_ms: 0.16246339893516765\n",
      "  time_since_restore: 811.8834340572357\n",
      "  time_this_iter_s: 15.467856884002686\n",
      "  time_total_s: 811.8834340572357\n",
      "  timers:\n",
      "    learn_throughput: 25428.804\n",
      "    learn_time_ms: 2516.202\n",
      "    load_throughput: 309358.86\n",
      "    load_time_ms: 206.828\n",
      "    training_iteration_time_ms: 15572.448\n",
      "    update_time_ms: 4.422\n",
      "  timestamp: 1665743027\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3327168\n",
      "  training_iteration: 52\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:23:52 (running for 00:13:54.58)<br>Memory usage on this node: 11.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    52</td><td style=\"text-align: right;\">         811.883</td><td style=\"text-align: right;\">3.32717e+06</td><td style=\"text-align: right;\"> -207737</td><td style=\"text-align: right;\">             -201718</td><td style=\"text-align: right;\">             -216351</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:23:57 (running for 00:13:59.87)<br>Memory usage on this node: 11.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    52</td><td style=\"text-align: right;\">         811.883</td><td style=\"text-align: right;\">3.32717e+06</td><td style=\"text-align: right;\"> -207737</td><td style=\"text-align: right;\">             -201718</td><td style=\"text-align: right;\">             -216351</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 3391152\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 3391152\n",
      "    num_agent_steps_trained: 3391152\n",
      "    num_env_steps_sampled: 3391152\n",
      "    num_env_steps_trained: 3391152\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-24-02\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -201416.86209345935\n",
      "  episode_reward_mean: -207046.11940520146\n",
      "  episode_reward_min: -216446.5624434\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 3384\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0951685905456543\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.002000845968723297\n",
      "          model: {}\n",
      "          policy_loss: 0.004241396673023701\n",
      "          total_loss: 10.004331588745117\n",
      "          vf_explained_var: 1.0346993803977966e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 3391152\n",
      "    num_agent_steps_trained: 3391152\n",
      "    num_env_steps_sampled: 3391152\n",
      "    num_env_steps_trained: 3391152\n",
      "  iterations_since_restore: 53\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 3391152\n",
      "  num_agent_steps_trained: 3391152\n",
      "  num_env_steps_sampled: 3391152\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 3391152\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 73.77727272727272\n",
      "    ram_util_percent: 76.73636363636365\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11805225996347875\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.513456230017074\n",
      "    mean_inference_ms: 1.5901877128981936\n",
      "    mean_raw_obs_processing_ms: 0.16248228706494808\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -201416.86209345935\n",
      "    episode_reward_mean: -207046.11940520146\n",
      "    episode_reward_min: -216446.5624434\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -205484.35515486947\n",
      "      - -202496.36116647208\n",
      "      - -207416.06305483\n",
      "      - -204281.75029731452\n",
      "      - -206578.20013633516\n",
      "      - -203924.91522315674\n",
      "      - -208313.03188870306\n",
      "      - -206638.23583335523\n",
      "      - -209851.3012077921\n",
      "      - -203386.1956414271\n",
      "      - -211245.98338088652\n",
      "      - -206049.0107168224\n",
      "      - -206530.23372672568\n",
      "      - -205554.00474775673\n",
      "      - -202358.65961671536\n",
      "      - -209225.15370164195\n",
      "      - -204397.44732460417\n",
      "      - -208225.7416579122\n",
      "      - -207452.9081915981\n",
      "      - -209666.3606052913\n",
      "      - -208316.4250101752\n",
      "      - -210237.47677645326\n",
      "      - -211143.15225983897\n",
      "      - -207552.1601466787\n",
      "      - -202915.46835719145\n",
      "      - -201981.80066280832\n",
      "      - -201718.29990339532\n",
      "      - -211519.53065932626\n",
      "      - -209041.43776251888\n",
      "      - -202514.47563344162\n",
      "      - -208280.42158945632\n",
      "      - -213819.91296417458\n",
      "      - -208138.76555866416\n",
      "      - -211410.60512765\n",
      "      - -205589.86396913143\n",
      "      - -209891.20315032493\n",
      "      - -211998.06559451553\n",
      "      - -204563.90552743286\n",
      "      - -209694.52666995133\n",
      "      - -206288.7128803209\n",
      "      - -203884.37652180987\n",
      "      - -203623.6009553806\n",
      "      - -203568.8067851702\n",
      "      - -206367.5813201215\n",
      "      - -204168.3918667622\n",
      "      - -206321.3359720379\n",
      "      - -205339.77814155995\n",
      "      - -208610.5196803045\n",
      "      - -206786.7926374921\n",
      "      - -205797.3326314115\n",
      "      - -207069.5780352945\n",
      "      - -214889.7937632813\n",
      "      - -204126.14853750105\n",
      "      - -202217.94040047913\n",
      "      - -205068.00135795344\n",
      "      - -207281.97265870168\n",
      "      - -207878.65494804672\n",
      "      - -207484.29857006052\n",
      "      - -208745.8565894315\n",
      "      - -204159.06164498164\n",
      "      - -210565.054426016\n",
      "      - -207263.42490481248\n",
      "      - -205405.5327573417\n",
      "      - -203693.63975367148\n",
      "      - -211046.59806656704\n",
      "      - -205787.8544396379\n",
      "      - -206892.35336562473\n",
      "      - -216446.5624434\n",
      "      - -206999.1338537737\n",
      "      - -208880.40557719412\n",
      "      - -208121.67330702688\n",
      "      - -206979.41751684662\n",
      "      - -211564.26444065705\n",
      "      - -208544.95112463512\n",
      "      - -208829.60724834356\n",
      "      - -206015.8524202309\n",
      "      - -206759.38119771905\n",
      "      - -204530.3542419116\n",
      "      - -212114.42918571059\n",
      "      - -204326.01264662802\n",
      "      - -206017.25025064888\n",
      "      - -208516.21073772875\n",
      "      - -209260.0643812925\n",
      "      - -204844.68750690098\n",
      "      - -206474.4983293985\n",
      "      - -205417.04312268697\n",
      "      - -209440.66275906964\n",
      "      - -205449.7779143551\n",
      "      - -204606.18803364568\n",
      "      - -212574.7323089408\n",
      "      - -205260.32213174415\n",
      "      - -204620.8761068561\n",
      "      - -203800.39185454004\n",
      "      - -201599.61694122807\n",
      "      - -207697.85791139345\n",
      "      - -215203.53642345438\n",
      "      - -207711.78333773548\n",
      "      - -201416.86209345935\n",
      "      - -211606.50080411002\n",
      "      - -203244.62815776913\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11805225996347875\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.513456230017074\n",
      "      mean_inference_ms: 1.5901877128981936\n",
      "      mean_raw_obs_processing_ms: 0.16248228706494808\n",
      "  time_since_restore: 827.1730501651764\n",
      "  time_this_iter_s: 15.289616107940674\n",
      "  time_total_s: 827.1730501651764\n",
      "  timers:\n",
      "    learn_throughput: 26143.523\n",
      "    learn_time_ms: 2447.413\n",
      "    load_throughput: 310285.641\n",
      "    load_time_ms: 206.21\n",
      "    training_iteration_time_ms: 15521.275\n",
      "    update_time_ms: 4.347\n",
      "  timestamp: 1665743042\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3391152\n",
      "  training_iteration: 53\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:24:02 (running for 00:14:04.90)<br>Memory usage on this node: 11.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    53</td><td style=\"text-align: right;\">         827.173</td><td style=\"text-align: right;\">3.39115e+06</td><td style=\"text-align: right;\"> -207046</td><td style=\"text-align: right;\">             -201417</td><td style=\"text-align: right;\">             -216447</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:24:07 (running for 00:14:09.99)<br>Memory usage on this node: 11.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    53</td><td style=\"text-align: right;\">         827.173</td><td style=\"text-align: right;\">3.39115e+06</td><td style=\"text-align: right;\"> -207046</td><td style=\"text-align: right;\">             -201417</td><td style=\"text-align: right;\">             -216447</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:24:12 (running for 00:14:14.99)<br>Memory usage on this node: 11.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    53</td><td style=\"text-align: right;\">         827.173</td><td style=\"text-align: right;\">3.39115e+06</td><td style=\"text-align: right;\"> -207046</td><td style=\"text-align: right;\">             -201417</td><td style=\"text-align: right;\">             -216447</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:24:17 (running for 00:14:20.05)<br>Memory usage on this node: 11.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    53</td><td style=\"text-align: right;\">         827.173</td><td style=\"text-align: right;\">3.39115e+06</td><td style=\"text-align: right;\"> -207046</td><td style=\"text-align: right;\">             -201417</td><td style=\"text-align: right;\">             -216447</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 3455136\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 3455136\n",
      "    num_agent_steps_trained: 3455136\n",
      "    num_env_steps_sampled: 3455136\n",
      "    num_env_steps_trained: 3455136\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-24-18\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -199007.79897711374\n",
      "  episode_reward_mean: -206777.48932434813\n",
      "  episode_reward_min: -216446.5624434\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 3444\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.094921588897705\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.001932706218212843\n",
      "          model: {}\n",
      "          policy_loss: 0.002328774891793728\n",
      "          total_loss: 10.002406120300293\n",
      "          vf_explained_var: -6.882473826408386e-07\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 3455136\n",
      "    num_agent_steps_trained: 3455136\n",
      "    num_env_steps_sampled: 3455136\n",
      "    num_env_steps_trained: 3455136\n",
      "  iterations_since_restore: 54\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 3455136\n",
      "  num_agent_steps_trained: 3455136\n",
      "  num_env_steps_sampled: 3455136\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 3455136\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.68181818181819\n",
      "    ram_util_percent: 76.79545454545452\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11785687395591372\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5132589281799059\n",
      "    mean_inference_ms: 1.5909371550495643\n",
      "    mean_raw_obs_processing_ms: 0.16240511937663707\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -199007.79897711374\n",
      "    episode_reward_mean: -206777.48932434813\n",
      "    episode_reward_min: -216446.5624434\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -210565.054426016\n",
      "      - -207263.42490481248\n",
      "      - -205405.5327573417\n",
      "      - -203693.63975367148\n",
      "      - -211046.59806656704\n",
      "      - -205787.8544396379\n",
      "      - -206892.35336562473\n",
      "      - -216446.5624434\n",
      "      - -206999.1338537737\n",
      "      - -208880.40557719412\n",
      "      - -208121.67330702688\n",
      "      - -206979.41751684662\n",
      "      - -211564.26444065705\n",
      "      - -208544.95112463512\n",
      "      - -208829.60724834356\n",
      "      - -206015.8524202309\n",
      "      - -206759.38119771905\n",
      "      - -204530.3542419116\n",
      "      - -212114.42918571059\n",
      "      - -204326.01264662802\n",
      "      - -206017.25025064888\n",
      "      - -208516.21073772875\n",
      "      - -209260.0643812925\n",
      "      - -204844.68750690098\n",
      "      - -206474.4983293985\n",
      "      - -205417.04312268697\n",
      "      - -209440.66275906964\n",
      "      - -205449.7779143551\n",
      "      - -204606.18803364568\n",
      "      - -212574.7323089408\n",
      "      - -205260.32213174415\n",
      "      - -204620.8761068561\n",
      "      - -203800.39185454004\n",
      "      - -201599.61694122807\n",
      "      - -207697.85791139345\n",
      "      - -215203.53642345438\n",
      "      - -207711.78333773548\n",
      "      - -201416.86209345935\n",
      "      - -211606.50080411002\n",
      "      - -203244.62815776913\n",
      "      - -203964.84676028186\n",
      "      - -214165.9726991195\n",
      "      - -205984.1804174784\n",
      "      - -209771.68978448235\n",
      "      - -203103.54877170137\n",
      "      - -203645.42035343818\n",
      "      - -200311.81696963846\n",
      "      - -206082.82606673703\n",
      "      - -208381.15220107345\n",
      "      - -209491.720832143\n",
      "      - -207381.16373528657\n",
      "      - -210076.4348120877\n",
      "      - -204158.08400930738\n",
      "      - -202835.28734370178\n",
      "      - -207220.58889076285\n",
      "      - -201943.7213735765\n",
      "      - -206440.74504094213\n",
      "      - -205194.33963110833\n",
      "      - -206204.2279547332\n",
      "      - -199007.79897711374\n",
      "      - -203438.41619529837\n",
      "      - -209273.6422559106\n",
      "      - -205489.44267780214\n",
      "      - -205855.46575524498\n",
      "      - -205660.48935507145\n",
      "      - -209620.6393132809\n",
      "      - -202656.04503418866\n",
      "      - -204493.04565257556\n",
      "      - -208411.5711091954\n",
      "      - -211211.39995188467\n",
      "      - -199353.77091882587\n",
      "      - -207135.14988249243\n",
      "      - -204950.11990237687\n",
      "      - -200370.3557028901\n",
      "      - -204441.83099764274\n",
      "      - -202469.4157417028\n",
      "      - -210518.8578515901\n",
      "      - -208341.91580078265\n",
      "      - -205160.9644005857\n",
      "      - -209793.94218780912\n",
      "      - -209866.1213080006\n",
      "      - -206721.81771695075\n",
      "      - -208640.88938340388\n",
      "      - -202403.89481583235\n",
      "      - -204607.3902396357\n",
      "      - -207738.4571045238\n",
      "      - -209059.63939831147\n",
      "      - -211198.4555688987\n",
      "      - -206481.63997422592\n",
      "      - -212381.49972678215\n",
      "      - -208458.56772899206\n",
      "      - -207048.12403867856\n",
      "      - -204840.4604384424\n",
      "      - -205035.07543373585\n",
      "      - -209547.35088314032\n",
      "      - -208603.894549621\n",
      "      - -203344.53425883452\n",
      "      - -204026.37244459952\n",
      "      - -210399.29538381705\n",
      "      - -207803.41070181126\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11785687395591372\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5132589281799059\n",
      "      mean_inference_ms: 1.5909371550495643\n",
      "      mean_raw_obs_processing_ms: 0.16240511937663707\n",
      "  time_since_restore: 843.0419788360596\n",
      "  time_this_iter_s: 15.868928670883179\n",
      "  time_total_s: 843.0419788360596\n",
      "  timers:\n",
      "    learn_throughput: 26202.845\n",
      "    learn_time_ms: 2441.872\n",
      "    load_throughput: 310263.149\n",
      "    load_time_ms: 206.225\n",
      "    training_iteration_time_ms: 15605.939\n",
      "    update_time_ms: 4.366\n",
      "  timestamp: 1665743058\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3455136\n",
      "  training_iteration: 54\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:24:23 (running for 00:14:25.96)<br>Memory usage on this node: 11.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    54</td><td style=\"text-align: right;\">         843.042</td><td style=\"text-align: right;\">3.45514e+06</td><td style=\"text-align: right;\"> -206777</td><td style=\"text-align: right;\">             -199008</td><td style=\"text-align: right;\">             -216447</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:24:28 (running for 00:14:31.04)<br>Memory usage on this node: 11.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    54</td><td style=\"text-align: right;\">         843.042</td><td style=\"text-align: right;\">3.45514e+06</td><td style=\"text-align: right;\"> -206777</td><td style=\"text-align: right;\">             -199008</td><td style=\"text-align: right;\">             -216447</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:24:33 (running for 00:14:36.05)<br>Memory usage on this node: 11.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    54</td><td style=\"text-align: right;\">         843.042</td><td style=\"text-align: right;\">3.45514e+06</td><td style=\"text-align: right;\"> -206777</td><td style=\"text-align: right;\">             -199008</td><td style=\"text-align: right;\">             -216447</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 3519120\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 3519120\n",
      "    num_agent_steps_trained: 3519120\n",
      "    num_env_steps_sampled: 3519120\n",
      "    num_env_steps_trained: 3519120\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-24-34\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -200370.3557028901\n",
      "  episode_reward_mean: -206148.95514783013\n",
      "  episode_reward_min: -215159.09972463624\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 3516\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.091977596282959\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0017911981558427215\n",
      "          model: {}\n",
      "          policy_loss: 0.007390835788100958\n",
      "          total_loss: 10.007440567016602\n",
      "          vf_explained_var: 1.5272544260369614e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 3519120\n",
      "    num_agent_steps_trained: 3519120\n",
      "    num_env_steps_sampled: 3519120\n",
      "    num_env_steps_trained: 3519120\n",
      "  iterations_since_restore: 55\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 3519120\n",
      "  num_agent_steps_trained: 3519120\n",
      "  num_env_steps_sampled: 3519120\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 3519120\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.78636363636363\n",
      "    ram_util_percent: 76.92727272727271\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11800123176770783\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.513451633591001\n",
      "    mean_inference_ms: 1.5921312249772177\n",
      "    mean_raw_obs_processing_ms: 0.16256747589012718\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -200370.3557028901\n",
      "    episode_reward_mean: -206148.95514783013\n",
      "    episode_reward_min: -215159.09972463624\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -204950.11990237687\n",
      "      - -200370.3557028901\n",
      "      - -204441.83099764274\n",
      "      - -202469.4157417028\n",
      "      - -210518.8578515901\n",
      "      - -208341.91580078265\n",
      "      - -205160.9644005857\n",
      "      - -209793.94218780912\n",
      "      - -209866.1213080006\n",
      "      - -206721.81771695075\n",
      "      - -208640.88938340388\n",
      "      - -202403.89481583235\n",
      "      - -204607.3902396357\n",
      "      - -207738.4571045238\n",
      "      - -209059.63939831147\n",
      "      - -211198.4555688987\n",
      "      - -206481.63997422592\n",
      "      - -212381.49972678215\n",
      "      - -208458.56772899206\n",
      "      - -207048.12403867856\n",
      "      - -204840.4604384424\n",
      "      - -205035.07543373585\n",
      "      - -209547.35088314032\n",
      "      - -208603.894549621\n",
      "      - -203344.53425883452\n",
      "      - -204026.37244459952\n",
      "      - -210399.29538381705\n",
      "      - -207803.41070181126\n",
      "      - -208363.84390455703\n",
      "      - -215159.09972463624\n",
      "      - -203451.94958498373\n",
      "      - -203059.49308115442\n",
      "      - -205417.7581630618\n",
      "      - -202138.38741324437\n",
      "      - -203850.6835840106\n",
      "      - -204873.77059938436\n",
      "      - -203540.70695811222\n",
      "      - -202151.89265122346\n",
      "      - -204802.96540242425\n",
      "      - -202288.55935093237\n",
      "      - -206856.30474522145\n",
      "      - -204493.35466627034\n",
      "      - -205721.43231605168\n",
      "      - -205174.43386435346\n",
      "      - -205290.86662499866\n",
      "      - -205232.5098019136\n",
      "      - -212882.6003873911\n",
      "      - -204884.09338560485\n",
      "      - -206324.62346213602\n",
      "      - -202967.39513327496\n",
      "      - -203300.11104974747\n",
      "      - -209544.18786332002\n",
      "      - -208971.3877838435\n",
      "      - -212274.40568516788\n",
      "      - -205953.20904657748\n",
      "      - -204179.72338906652\n",
      "      - -205342.1959546493\n",
      "      - -206994.12759884036\n",
      "      - -207367.64572410544\n",
      "      - -208009.6288580351\n",
      "      - -205123.73259069683\n",
      "      - -209729.99084541496\n",
      "      - -201918.82600549972\n",
      "      - -209763.6808768896\n",
      "      - -204166.19436543985\n",
      "      - -203635.8463885797\n",
      "      - -208333.47736659957\n",
      "      - -202954.9113005219\n",
      "      - -200490.3354621994\n",
      "      - -209589.88833563562\n",
      "      - -213266.5443301279\n",
      "      - -200865.14782859542\n",
      "      - -204535.836248254\n",
      "      - -203032.56252027326\n",
      "      - -209833.9769384357\n",
      "      - -206667.08526912954\n",
      "      - -201721.35832528758\n",
      "      - -203838.516517344\n",
      "      - -203868.34075629737\n",
      "      - -202668.58511238784\n",
      "      - -204262.84472042831\n",
      "      - -207097.71104268308\n",
      "      - -200715.065109053\n",
      "      - -204108.84877102566\n",
      "      - -202521.56885626324\n",
      "      - -203284.3837334735\n",
      "      - -210185.06751428143\n",
      "      - -202795.43943947714\n",
      "      - -211288.78992895663\n",
      "      - -210864.49284081062\n",
      "      - -206120.1724402359\n",
      "      - -205284.2620582147\n",
      "      - -208804.68680191014\n",
      "      - -201918.04260907357\n",
      "      - -210190.02436792938\n",
      "      - -208026.22046214086\n",
      "      - -204979.6782424536\n",
      "      - -201508.6533727259\n",
      "      - -211054.01287798115\n",
      "      - -208763.07076837248\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11800123176770783\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.513451633591001\n",
      "      mean_inference_ms: 1.5921312249772177\n",
      "      mean_raw_obs_processing_ms: 0.16256747589012718\n",
      "  time_since_restore: 858.7844557762146\n",
      "  time_this_iter_s: 15.74247694015503\n",
      "  time_total_s: 858.7844557762146\n",
      "  timers:\n",
      "    learn_throughput: 26263.875\n",
      "    learn_time_ms: 2436.198\n",
      "    load_throughput: 310723.755\n",
      "    load_time_ms: 205.919\n",
      "    training_iteration_time_ms: 15517.602\n",
      "    update_time_ms: 4.424\n",
      "  timestamp: 1665743074\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3519120\n",
      "  training_iteration: 55\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:24:39 (running for 00:14:41.67)<br>Memory usage on this node: 11.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    55</td><td style=\"text-align: right;\">         858.784</td><td style=\"text-align: right;\">3.51912e+06</td><td style=\"text-align: right;\"> -206149</td><td style=\"text-align: right;\">             -200370</td><td style=\"text-align: right;\">             -215159</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:24:44 (running for 00:14:46.68)<br>Memory usage on this node: 11.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    55</td><td style=\"text-align: right;\">         858.784</td><td style=\"text-align: right;\">3.51912e+06</td><td style=\"text-align: right;\"> -206149</td><td style=\"text-align: right;\">             -200370</td><td style=\"text-align: right;\">             -215159</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 3583104\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 3583104\n",
      "    num_agent_steps_trained: 3583104\n",
      "    num_env_steps_sampled: 3583104\n",
      "    num_env_steps_trained: 3583104\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-24-49\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -198687.53782411714\n",
      "  episode_reward_mean: -205302.62314265713\n",
      "  episode_reward_min: -217748.37403604336\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 3576\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0900039672851562\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0023225778713822365\n",
      "          model: {}\n",
      "          policy_loss: 0.0035094604827463627\n",
      "          total_loss: 10.00366497039795\n",
      "          vf_explained_var: -6.468035280704498e-07\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 3583104\n",
      "    num_agent_steps_trained: 3583104\n",
      "    num_env_steps_sampled: 3583104\n",
      "    num_env_steps_trained: 3583104\n",
      "  iterations_since_restore: 56\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 3583104\n",
      "  num_agent_steps_trained: 3583104\n",
      "  num_env_steps_sampled: 3583104\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 3583104\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.42499999999998\n",
      "    ram_util_percent: 77.11499999999998\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.117820184608753\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5134044388843207\n",
      "    mean_inference_ms: 1.5906244319646792\n",
      "    mean_raw_obs_processing_ms: 0.16269000395297803\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -198687.53782411714\n",
      "    episode_reward_mean: -205302.62314265713\n",
      "    episode_reward_min: -217748.37403604336\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -205123.73259069683\n",
      "      - -209729.99084541496\n",
      "      - -201918.82600549972\n",
      "      - -209763.6808768896\n",
      "      - -204166.19436543985\n",
      "      - -203635.8463885797\n",
      "      - -208333.47736659957\n",
      "      - -202954.9113005219\n",
      "      - -200490.3354621994\n",
      "      - -209589.88833563562\n",
      "      - -213266.5443301279\n",
      "      - -200865.14782859542\n",
      "      - -204535.836248254\n",
      "      - -203032.56252027326\n",
      "      - -209833.9769384357\n",
      "      - -206667.08526912954\n",
      "      - -201721.35832528758\n",
      "      - -203838.516517344\n",
      "      - -203868.34075629737\n",
      "      - -202668.58511238784\n",
      "      - -204262.84472042831\n",
      "      - -207097.71104268308\n",
      "      - -200715.065109053\n",
      "      - -204108.84877102566\n",
      "      - -202521.56885626324\n",
      "      - -203284.3837334735\n",
      "      - -210185.06751428143\n",
      "      - -202795.43943947714\n",
      "      - -211288.78992895663\n",
      "      - -210864.49284081062\n",
      "      - -206120.1724402359\n",
      "      - -205284.2620582147\n",
      "      - -208804.68680191014\n",
      "      - -201918.04260907357\n",
      "      - -210190.02436792938\n",
      "      - -208026.22046214086\n",
      "      - -204979.6782424536\n",
      "      - -201508.6533727259\n",
      "      - -211054.01287798115\n",
      "      - -208763.07076837248\n",
      "      - -202711.8345192091\n",
      "      - -204439.71387481663\n",
      "      - -201042.2945287793\n",
      "      - -202854.22277607716\n",
      "      - -202755.76116691573\n",
      "      - -205201.87534901974\n",
      "      - -203542.8960665682\n",
      "      - -217748.37403604336\n",
      "      - -207309.77239074494\n",
      "      - -203413.75044872225\n",
      "      - -202911.0926941996\n",
      "      - -199976.85105876098\n",
      "      - -212458.84519985114\n",
      "      - -204904.98217559047\n",
      "      - -205502.59380642316\n",
      "      - -209783.42987488437\n",
      "      - -203976.7377697795\n",
      "      - -202707.97533891763\n",
      "      - -204869.54597615675\n",
      "      - -206596.0366490072\n",
      "      - -205992.40376514295\n",
      "      - -205853.98583989206\n",
      "      - -203222.64030508138\n",
      "      - -205206.099609376\n",
      "      - -204878.79846709775\n",
      "      - -198687.53782411714\n",
      "      - -205694.99148576107\n",
      "      - -201237.4909888601\n",
      "      - -204936.0443880257\n",
      "      - -203817.33125193068\n",
      "      - -210422.21000259035\n",
      "      - -204700.64893186034\n",
      "      - -205560.32417436453\n",
      "      - -201606.50226756078\n",
      "      - -203020.46248549724\n",
      "      - -201100.2841697146\n",
      "      - -215324.27310880166\n",
      "      - -202654.4557604636\n",
      "      - -204301.9435515137\n",
      "      - -203818.08453930978\n",
      "      - -206312.09069167613\n",
      "      - -203235.7516418825\n",
      "      - -204728.42617771126\n",
      "      - -208038.15865596582\n",
      "      - -203531.14653808402\n",
      "      - -206884.26821142883\n",
      "      - -210487.61465954143\n",
      "      - -200901.11701410325\n",
      "      - -208213.86559232525\n",
      "      - -202115.62099441185\n",
      "      - -206431.0716123522\n",
      "      - -204750.30427033064\n",
      "      - -204636.85983046563\n",
      "      - -206871.7404956217\n",
      "      - -208933.17130415508\n",
      "      - -203865.05529675205\n",
      "      - -203769.16031453604\n",
      "      - -201950.07345157038\n",
      "      - -204163.0158985342\n",
      "      - -203920.82965573538\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.117820184608753\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5134044388843207\n",
      "      mean_inference_ms: 1.5906244319646792\n",
      "      mean_raw_obs_processing_ms: 0.16269000395297803\n",
      "  time_since_restore: 873.6776661872864\n",
      "  time_this_iter_s: 14.893210411071777\n",
      "  time_total_s: 873.6776661872864\n",
      "  timers:\n",
      "    learn_throughput: 26400.046\n",
      "    learn_time_ms: 2423.632\n",
      "    load_throughput: 311056.965\n",
      "    load_time_ms: 205.699\n",
      "    training_iteration_time_ms: 15503.754\n",
      "    update_time_ms: 4.425\n",
      "  timestamp: 1665743089\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3583104\n",
      "  training_iteration: 56\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:24:54 (running for 00:14:57.02)<br>Memory usage on this node: 11.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    56</td><td style=\"text-align: right;\">         873.678</td><td style=\"text-align: right;\">3.5831e+06</td><td style=\"text-align: right;\"> -205303</td><td style=\"text-align: right;\">             -198688</td><td style=\"text-align: right;\">             -217748</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:24:59 (running for 00:15:02.02)<br>Memory usage on this node: 11.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    56</td><td style=\"text-align: right;\">         873.678</td><td style=\"text-align: right;\">3.5831e+06</td><td style=\"text-align: right;\"> -205303</td><td style=\"text-align: right;\">             -198688</td><td style=\"text-align: right;\">             -217748</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 3647088\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 3647088\n",
      "    num_agent_steps_trained: 3647088\n",
      "    num_env_steps_sampled: 3647088\n",
      "    num_env_steps_trained: 3647088\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-25-04\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -198218.01886927022\n",
      "  episode_reward_mean: -204950.5325652503\n",
      "  episode_reward_min: -220303.23396581\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 3636\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0916552543640137\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0020159841515123844\n",
      "          model: {}\n",
      "          policy_loss: 0.0012899013236165047\n",
      "          total_loss: 10.001383781433105\n",
      "          vf_explained_var: -4.0885061025619507e-07\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 3647088\n",
      "    num_agent_steps_trained: 3647088\n",
      "    num_env_steps_sampled: 3647088\n",
      "    num_env_steps_trained: 3647088\n",
      "  iterations_since_restore: 57\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 3647088\n",
      "  num_agent_steps_trained: 3647088\n",
      "  num_env_steps_sampled: 3647088\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 3647088\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 72.31818181818181\n",
      "    ram_util_percent: 77.10909090909088\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11769617446593188\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5129175623160991\n",
      "    mean_inference_ms: 1.5891769057956313\n",
      "    mean_raw_obs_processing_ms: 0.1623762976637009\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -198218.01886927022\n",
      "    episode_reward_mean: -204950.5325652503\n",
      "    episode_reward_min: -220303.23396581\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -205992.40376514295\n",
      "      - -205853.98583989206\n",
      "      - -203222.64030508138\n",
      "      - -205206.099609376\n",
      "      - -204878.79846709775\n",
      "      - -198687.53782411714\n",
      "      - -205694.99148576107\n",
      "      - -201237.4909888601\n",
      "      - -204936.0443880257\n",
      "      - -203817.33125193068\n",
      "      - -210422.21000259035\n",
      "      - -204700.64893186034\n",
      "      - -205560.32417436453\n",
      "      - -201606.50226756078\n",
      "      - -203020.46248549724\n",
      "      - -201100.2841697146\n",
      "      - -215324.27310880166\n",
      "      - -202654.4557604636\n",
      "      - -204301.9435515137\n",
      "      - -203818.08453930978\n",
      "      - -206312.09069167613\n",
      "      - -203235.7516418825\n",
      "      - -204728.42617771126\n",
      "      - -208038.15865596582\n",
      "      - -203531.14653808402\n",
      "      - -206884.26821142883\n",
      "      - -210487.61465954143\n",
      "      - -200901.11701410325\n",
      "      - -208213.86559232525\n",
      "      - -202115.62099441185\n",
      "      - -206431.0716123522\n",
      "      - -204750.30427033064\n",
      "      - -204636.85983046563\n",
      "      - -206871.7404956217\n",
      "      - -208933.17130415508\n",
      "      - -203865.05529675205\n",
      "      - -203769.16031453604\n",
      "      - -201950.07345157038\n",
      "      - -204163.0158985342\n",
      "      - -203920.82965573538\n",
      "      - -205323.85294730336\n",
      "      - -209984.34229354945\n",
      "      - -209531.68222795203\n",
      "      - -201295.28893785892\n",
      "      - -204658.94266863662\n",
      "      - -206012.6414381269\n",
      "      - -202228.4943879433\n",
      "      - -206571.7519587284\n",
      "      - -208509.13874619405\n",
      "      - -202379.10262149642\n",
      "      - -201431.79170561946\n",
      "      - -198218.01886927022\n",
      "      - -203998.31445496672\n",
      "      - -204487.21434607485\n",
      "      - -207257.78861003096\n",
      "      - -198892.6523112593\n",
      "      - -201578.20203044658\n",
      "      - -207256.45778256876\n",
      "      - -206101.16359865898\n",
      "      - -202297.84331723518\n",
      "      - -205240.2772429762\n",
      "      - -202161.12935312605\n",
      "      - -205989.1554744015\n",
      "      - -210071.6918739891\n",
      "      - -202697.4783170619\n",
      "      - -204552.6892842067\n",
      "      - -203256.2851724601\n",
      "      - -205347.59714345436\n",
      "      - -203732.69198338425\n",
      "      - -199328.4054901123\n",
      "      - -205563.52874497138\n",
      "      - -204929.46611890514\n",
      "      - -205806.3670321092\n",
      "      - -201281.32007294052\n",
      "      - -205307.60742094746\n",
      "      - -208422.80014143695\n",
      "      - -199642.1246760063\n",
      "      - -206874.37227118158\n",
      "      - -202689.41186922844\n",
      "      - -203018.06789255192\n",
      "      - -206343.9269993578\n",
      "      - -212467.40570257592\n",
      "      - -202853.94201004316\n",
      "      - -220303.23396581\n",
      "      - -203325.31895435086\n",
      "      - -204008.1520590294\n",
      "      - -206054.47717240168\n",
      "      - -206105.1674487893\n",
      "      - -204973.8414187809\n",
      "      - -201872.37977033996\n",
      "      - -205277.35314595033\n",
      "      - -201344.45247268616\n",
      "      - -202143.4044925038\n",
      "      - -202915.92315370028\n",
      "      - -203530.51666120053\n",
      "      - -203207.0585171732\n",
      "      - -201999.89136626347\n",
      "      - -210455.17221331486\n",
      "      - -207704.64301638326\n",
      "      - -218463.98793085595\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11769617446593188\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5129175623160991\n",
      "      mean_inference_ms: 1.5891769057956313\n",
      "      mean_raw_obs_processing_ms: 0.1623762976637009\n",
      "  time_since_restore: 888.4475774765015\n",
      "  time_this_iter_s: 14.769911289215088\n",
      "  time_total_s: 888.4475774765015\n",
      "  timers:\n",
      "    learn_throughput: 26519.092\n",
      "    learn_time_ms: 2412.752\n",
      "    load_throughput: 311770.44\n",
      "    load_time_ms: 205.228\n",
      "    training_iteration_time_ms: 15343.48\n",
      "    update_time_ms: 4.44\n",
      "  timestamp: 1665743104\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3647088\n",
      "  training_iteration: 57\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:25:09 (running for 00:15:11.40)<br>Memory usage on this node: 11.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    57</td><td style=\"text-align: right;\">         888.448</td><td style=\"text-align: right;\">3.64709e+06</td><td style=\"text-align: right;\"> -204951</td><td style=\"text-align: right;\">             -198218</td><td style=\"text-align: right;\">             -220303</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:25:14 (running for 00:15:16.40)<br>Memory usage on this node: 11.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    57</td><td style=\"text-align: right;\">         888.448</td><td style=\"text-align: right;\">3.64709e+06</td><td style=\"text-align: right;\"> -204951</td><td style=\"text-align: right;\">             -198218</td><td style=\"text-align: right;\">             -220303</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:25:19 (running for 00:15:21.41)<br>Memory usage on this node: 11.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    57</td><td style=\"text-align: right;\">         888.448</td><td style=\"text-align: right;\">3.64709e+06</td><td style=\"text-align: right;\"> -204951</td><td style=\"text-align: right;\">             -198218</td><td style=\"text-align: right;\">             -220303</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 3711072\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 3711072\n",
      "    num_agent_steps_trained: 3711072\n",
      "    num_env_steps_sampled: 3711072\n",
      "    num_env_steps_trained: 3711072\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-25-19\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -199158.64226552387\n",
      "  episode_reward_mean: -207411.1501650241\n",
      "  episode_reward_min: -283769.5423456459\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 3708\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0930819511413574\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0017828620038926601\n",
      "          model: {}\n",
      "          policy_loss: 0.00714085204526782\n",
      "          total_loss: 10.007187843322754\n",
      "          vf_explained_var: -6.969158761194194e-08\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 3711072\n",
      "    num_agent_steps_trained: 3711072\n",
      "    num_env_steps_sampled: 3711072\n",
      "    num_env_steps_trained: 3711072\n",
      "  iterations_since_restore: 58\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 3711072\n",
      "  num_agent_steps_trained: 3711072\n",
      "  num_env_steps_sampled: 3711072\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 3711072\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.81428571428573\n",
      "    ram_util_percent: 77.10476190476189\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1179154401211712\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5131161059326765\n",
      "    mean_inference_ms: 1.5891686091563826\n",
      "    mean_raw_obs_processing_ms: 0.16236821020912046\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -199158.64226552387\n",
      "    episode_reward_mean: -207411.1501650241\n",
      "    episode_reward_min: -283769.5423456459\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -205806.3670321092\n",
      "      - -201281.32007294052\n",
      "      - -205307.60742094746\n",
      "      - -208422.80014143695\n",
      "      - -199642.1246760063\n",
      "      - -206874.37227118158\n",
      "      - -202689.41186922844\n",
      "      - -203018.06789255192\n",
      "      - -206343.9269993578\n",
      "      - -212467.40570257592\n",
      "      - -202853.94201004316\n",
      "      - -220303.23396581\n",
      "      - -203325.31895435086\n",
      "      - -204008.1520590294\n",
      "      - -206054.47717240168\n",
      "      - -206105.1674487893\n",
      "      - -204973.8414187809\n",
      "      - -201872.37977033996\n",
      "      - -205277.35314595033\n",
      "      - -201344.45247268616\n",
      "      - -202143.4044925038\n",
      "      - -202915.92315370028\n",
      "      - -203530.51666120053\n",
      "      - -203207.0585171732\n",
      "      - -201999.89136626347\n",
      "      - -210455.17221331486\n",
      "      - -207704.64301638326\n",
      "      - -218463.98793085595\n",
      "      - -206309.02754933602\n",
      "      - -205077.7141254217\n",
      "      - -205048.18440834424\n",
      "      - -205829.2494408934\n",
      "      - -283769.5423456459\n",
      "      - -203632.3232670781\n",
      "      - -205905.4795645641\n",
      "      - -203921.5625395781\n",
      "      - -207849.9410107836\n",
      "      - -207252.2483137638\n",
      "      - -208049.54872414033\n",
      "      - -201985.9688811758\n",
      "      - -207311.86574016174\n",
      "      - -204229.67613408066\n",
      "      - -212123.73964532054\n",
      "      - -205359.11419195545\n",
      "      - -205212.17237814635\n",
      "      - -218769.22404937135\n",
      "      - -203545.74330437282\n",
      "      - -208617.80885409814\n",
      "      - -204402.37803531063\n",
      "      - -205338.90529323547\n",
      "      - -209680.05775791645\n",
      "      - -247563.75472565548\n",
      "      - -205013.82161492278\n",
      "      - -209944.92895804628\n",
      "      - -208706.61583537265\n",
      "      - -207425.05948345442\n",
      "      - -207424.28407905655\n",
      "      - -204880.83690885513\n",
      "      - -202545.59139752635\n",
      "      - -200880.58392246414\n",
      "      - -206034.8633486489\n",
      "      - -201834.65527573336\n",
      "      - -203341.6627536055\n",
      "      - -283227.4143429623\n",
      "      - -205996.821765895\n",
      "      - -203380.40429916387\n",
      "      - -205351.89572886814\n",
      "      - -200923.88917703214\n",
      "      - -208254.06775499313\n",
      "      - -199158.64226552387\n",
      "      - -204525.62281012035\n",
      "      - -204005.63239948737\n",
      "      - -203568.33904892168\n",
      "      - -203786.29350056042\n",
      "      - -203535.53708046113\n",
      "      - -202054.19748924495\n",
      "      - -202143.93455824265\n",
      "      - -212475.47732021334\n",
      "      - -204684.9547162219\n",
      "      - -204224.38812601642\n",
      "      - -200438.6141220835\n",
      "      - -202053.5606839239\n",
      "      - -208938.26120435857\n",
      "      - -209646.1053316695\n",
      "      - -199568.19537060705\n",
      "      - -206096.73614484334\n",
      "      - -204301.6130332544\n",
      "      - -205716.84122175624\n",
      "      - -203766.69415062317\n",
      "      - -206424.70516104248\n",
      "      - -206256.23569435845\n",
      "      - -205043.24402116323\n",
      "      - -208159.09357539017\n",
      "      - -206097.92707091817\n",
      "      - -200846.52066269633\n",
      "      - -205666.41897588674\n",
      "      - -203449.01815158653\n",
      "      - -200411.04544614462\n",
      "      - -208990.15224235\n",
      "      - -204736.06814787266\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1179154401211712\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5131161059326765\n",
      "      mean_inference_ms: 1.5891686091563826\n",
      "      mean_raw_obs_processing_ms: 0.16236821020912046\n",
      "  time_since_restore: 903.8645088672638\n",
      "  time_this_iter_s: 15.416931390762329\n",
      "  time_total_s: 903.8645088672638\n",
      "  timers:\n",
      "    learn_throughput: 27111.06\n",
      "    learn_time_ms: 2360.07\n",
      "    load_throughput: 311960.743\n",
      "    load_time_ms: 205.103\n",
      "    training_iteration_time_ms: 15287.336\n",
      "    update_time_ms: 4.175\n",
      "  timestamp: 1665743119\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3711072\n",
      "  training_iteration: 58\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:25:24 (running for 00:15:26.79)<br>Memory usage on this node: 11.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    58</td><td style=\"text-align: right;\">         903.865</td><td style=\"text-align: right;\">3.71107e+06</td><td style=\"text-align: right;\"> -207411</td><td style=\"text-align: right;\">             -199159</td><td style=\"text-align: right;\">             -283770</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:25:30 (running for 00:15:32.29)<br>Memory usage on this node: 11.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    58</td><td style=\"text-align: right;\">         903.865</td><td style=\"text-align: right;\">3.71107e+06</td><td style=\"text-align: right;\"> -207411</td><td style=\"text-align: right;\">             -199159</td><td style=\"text-align: right;\">             -283770</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:25:35 (running for 00:15:37.36)<br>Memory usage on this node: 11.9/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    58</td><td style=\"text-align: right;\">         903.865</td><td style=\"text-align: right;\">3.71107e+06</td><td style=\"text-align: right;\"> -207411</td><td style=\"text-align: right;\">             -199159</td><td style=\"text-align: right;\">             -283770</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 3775056\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 3775056\n",
      "    num_agent_steps_trained: 3775056\n",
      "    num_env_steps_sampled: 3775056\n",
      "    num_env_steps_trained: 3775056\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-25-35\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -197808.8583960744\n",
      "  episode_reward_mean: -205675.7048134768\n",
      "  episode_reward_min: -283227.4143429623\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 3768\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.085527181625366\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0016014217399060726\n",
      "          model: {}\n",
      "          policy_loss: 0.0019145153928548098\n",
      "          total_loss: 10.00192642211914\n",
      "          vf_explained_var: 1.2223608791828156e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 3775056\n",
      "    num_agent_steps_trained: 3775056\n",
      "    num_env_steps_sampled: 3775056\n",
      "    num_env_steps_trained: 3775056\n",
      "  iterations_since_restore: 59\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 3775056\n",
      "  num_agent_steps_trained: 3775056\n",
      "  num_env_steps_sampled: 3775056\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 3775056\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.80000000000001\n",
      "    ram_util_percent: 77.13333333333333\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11779530467884068\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.513084649418339\n",
      "    mean_inference_ms: 1.588381685978103\n",
      "    mean_raw_obs_processing_ms: 0.16247160329077534\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -197808.8583960744\n",
      "    episode_reward_mean: -205675.7048134768\n",
      "    episode_reward_min: -283227.4143429623\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -206034.8633486489\n",
      "      - -201834.65527573336\n",
      "      - -203341.6627536055\n",
      "      - -283227.4143429623\n",
      "      - -205996.821765895\n",
      "      - -203380.40429916387\n",
      "      - -205351.89572886814\n",
      "      - -200923.88917703214\n",
      "      - -208254.06775499313\n",
      "      - -199158.64226552387\n",
      "      - -204525.62281012035\n",
      "      - -204005.63239948737\n",
      "      - -203568.33904892168\n",
      "      - -203786.29350056042\n",
      "      - -203535.53708046113\n",
      "      - -202054.19748924495\n",
      "      - -202143.93455824265\n",
      "      - -212475.47732021334\n",
      "      - -204684.9547162219\n",
      "      - -204224.38812601642\n",
      "      - -200438.6141220835\n",
      "      - -202053.5606839239\n",
      "      - -208938.26120435857\n",
      "      - -209646.1053316695\n",
      "      - -199568.19537060705\n",
      "      - -206096.73614484334\n",
      "      - -204301.6130332544\n",
      "      - -205716.84122175624\n",
      "      - -203766.69415062317\n",
      "      - -206424.70516104248\n",
      "      - -206256.23569435845\n",
      "      - -205043.24402116323\n",
      "      - -208159.09357539017\n",
      "      - -206097.92707091817\n",
      "      - -200846.52066269633\n",
      "      - -205666.41897588674\n",
      "      - -203449.01815158653\n",
      "      - -200411.04544614462\n",
      "      - -208990.15224235\n",
      "      - -204736.06814787266\n",
      "      - -207188.70086322445\n",
      "      - -204533.12368175323\n",
      "      - -208024.7985087857\n",
      "      - -206217.1915629344\n",
      "      - -203467.3903505024\n",
      "      - -202831.22404435277\n",
      "      - -202215.81590473506\n",
      "      - -204079.04989751833\n",
      "      - -206864.4392163333\n",
      "      - -205052.46549733757\n",
      "      - -201431.1540442407\n",
      "      - -223255.57126391167\n",
      "      - -207369.2386509716\n",
      "      - -215161.05520915642\n",
      "      - -202204.15207294983\n",
      "      - -203943.05949451335\n",
      "      - -205171.60632695392\n",
      "      - -199304.19258008784\n",
      "      - -207185.21713566725\n",
      "      - -207813.30014074172\n",
      "      - -205202.85272435198\n",
      "      - -205006.25733550923\n",
      "      - -200409.4827065383\n",
      "      - -208190.96143632315\n",
      "      - -202795.09469244047\n",
      "      - -200265.22412834942\n",
      "      - -201056.07133893244\n",
      "      - -208401.98736616335\n",
      "      - -207255.61784310112\n",
      "      - -202386.22539566143\n",
      "      - -200527.78688410085\n",
      "      - -203069.700121825\n",
      "      - -202645.72257708883\n",
      "      - -202905.32917077196\n",
      "      - -213237.9707823919\n",
      "      - -203839.20232688068\n",
      "      - -201805.64298075764\n",
      "      - -201780.0630485703\n",
      "      - -202139.29527408915\n",
      "      - -205055.25933212665\n",
      "      - -201341.20858491884\n",
      "      - -207496.27012029354\n",
      "      - -208700.9134125337\n",
      "      - -204181.9855996654\n",
      "      - -204748.46954782907\n",
      "      - -200538.36370339774\n",
      "      - -200283.51843135385\n",
      "      - -207794.34354692188\n",
      "      - -208120.3235480954\n",
      "      - -212717.05107546385\n",
      "      - -205780.03555938636\n",
      "      - -197808.8583960744\n",
      "      - -206968.553515509\n",
      "      - -206362.78768415566\n",
      "      - -203855.81275448855\n",
      "      - -204376.1486709466\n",
      "      - -201328.63498685692\n",
      "      - -211892.47944510815\n",
      "      - -198939.67745375584\n",
      "      - -213930.8072238365\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11779530467884068\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.513084649418339\n",
      "      mean_inference_ms: 1.588381685978103\n",
      "      mean_raw_obs_processing_ms: 0.16247160329077534\n",
      "  time_since_restore: 919.9476108551025\n",
      "  time_this_iter_s: 16.083101987838745\n",
      "  time_total_s: 919.9476108551025\n",
      "  timers:\n",
      "    learn_throughput: 26273.486\n",
      "    learn_time_ms: 2435.307\n",
      "    load_throughput: 312123.179\n",
      "    load_time_ms: 204.996\n",
      "    training_iteration_time_ms: 15363.668\n",
      "    update_time_ms: 4.141\n",
      "  timestamp: 1665743135\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3775056\n",
      "  training_iteration: 59\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:25:40 (running for 00:15:42.95)<br>Memory usage on this node: 12.1/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    59</td><td style=\"text-align: right;\">         919.948</td><td style=\"text-align: right;\">3.77506e+06</td><td style=\"text-align: right;\"> -205676</td><td style=\"text-align: right;\">             -197809</td><td style=\"text-align: right;\">             -283227</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:25:46 (running for 00:15:48.38)<br>Memory usage on this node: 12.1/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    59</td><td style=\"text-align: right;\">         919.948</td><td style=\"text-align: right;\">3.77506e+06</td><td style=\"text-align: right;\"> -205676</td><td style=\"text-align: right;\">             -197809</td><td style=\"text-align: right;\">             -283227</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:25:51 (running for 00:15:53.39)<br>Memory usage on this node: 12.1/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    59</td><td style=\"text-align: right;\">         919.948</td><td style=\"text-align: right;\">3.77506e+06</td><td style=\"text-align: right;\"> -205676</td><td style=\"text-align: right;\">             -197809</td><td style=\"text-align: right;\">             -283227</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 3839040\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 3839040\n",
      "    num_agent_steps_trained: 3839040\n",
      "    num_env_steps_sampled: 3839040\n",
      "    num_env_steps_trained: 3839040\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-25-51\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -197490.19658962815\n",
      "  episode_reward_mean: -204503.20313254744\n",
      "  episode_reward_min: -213930.8072238365\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 3828\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.079108476638794\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0017297810409218073\n",
      "          model: {}\n",
      "          policy_loss: 0.0016057547181844711\n",
      "          total_loss: 10.001644134521484\n",
      "          vf_explained_var: 1.0360963642597198e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 3839040\n",
      "    num_agent_steps_trained: 3839040\n",
      "    num_env_steps_sampled: 3839040\n",
      "    num_env_steps_trained: 3839040\n",
      "  iterations_since_restore: 60\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 3839040\n",
      "  num_agent_steps_trained: 3839040\n",
      "  num_env_steps_sampled: 3839040\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 3839040\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.92380952380952\n",
      "    ram_util_percent: 78.00000000000001\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11769174307756508\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5127898324327457\n",
      "    mean_inference_ms: 1.5885398208001487\n",
      "    mean_raw_obs_processing_ms: 0.16227429045582095\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -197490.19658962815\n",
      "    episode_reward_mean: -204503.20313254744\n",
      "    episode_reward_min: -213930.8072238365\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -205202.85272435198\n",
      "      - -205006.25733550923\n",
      "      - -200409.4827065383\n",
      "      - -208190.96143632315\n",
      "      - -202795.09469244047\n",
      "      - -200265.22412834942\n",
      "      - -201056.07133893244\n",
      "      - -208401.98736616335\n",
      "      - -207255.61784310112\n",
      "      - -202386.22539566143\n",
      "      - -200527.78688410085\n",
      "      - -203069.700121825\n",
      "      - -202645.72257708883\n",
      "      - -202905.32917077196\n",
      "      - -213237.9707823919\n",
      "      - -203839.20232688068\n",
      "      - -201805.64298075764\n",
      "      - -201780.0630485703\n",
      "      - -202139.29527408915\n",
      "      - -205055.25933212665\n",
      "      - -201341.20858491884\n",
      "      - -207496.27012029354\n",
      "      - -208700.9134125337\n",
      "      - -204181.9855996654\n",
      "      - -204748.46954782907\n",
      "      - -200538.36370339774\n",
      "      - -200283.51843135385\n",
      "      - -207794.34354692188\n",
      "      - -208120.3235480954\n",
      "      - -212717.05107546385\n",
      "      - -205780.03555938636\n",
      "      - -197808.8583960744\n",
      "      - -206968.553515509\n",
      "      - -206362.78768415566\n",
      "      - -203855.81275448855\n",
      "      - -204376.1486709466\n",
      "      - -201328.63498685692\n",
      "      - -211892.47944510815\n",
      "      - -198939.67745375584\n",
      "      - -213930.8072238365\n",
      "      - -199495.85952339665\n",
      "      - -207466.72190837824\n",
      "      - -203981.6374640567\n",
      "      - -204350.9648327674\n",
      "      - -211053.79163506755\n",
      "      - -197490.19658962815\n",
      "      - -211868.42507814863\n",
      "      - -204421.2450241571\n",
      "      - -202757.248190765\n",
      "      - -203852.1716174385\n",
      "      - -206288.29657286347\n",
      "      - -204797.90044518624\n",
      "      - -208149.4166723946\n",
      "      - -202272.29135556458\n",
      "      - -199579.5789760097\n",
      "      - -204325.41674180602\n",
      "      - -208773.17129901116\n",
      "      - -207506.109842374\n",
      "      - -201397.33006454958\n",
      "      - -204900.96478676226\n",
      "      - -199109.20736871444\n",
      "      - -203733.00266691006\n",
      "      - -208136.66790895446\n",
      "      - -206294.95523245278\n",
      "      - -206968.11728214702\n",
      "      - -202246.67360366558\n",
      "      - -209931.22778709684\n",
      "      - -206239.5399517298\n",
      "      - -203812.4901127691\n",
      "      - -199806.66023946108\n",
      "      - -205690.12608811632\n",
      "      - -202852.44795637537\n",
      "      - -208746.35786280673\n",
      "      - -205229.3037228848\n",
      "      - -205592.8127078635\n",
      "      - -205075.96082900118\n",
      "      - -201992.92729166124\n",
      "      - -204424.2679926443\n",
      "      - -207904.2302542365\n",
      "      - -207345.68281539806\n",
      "      - -204454.29572519445\n",
      "      - -203023.38372411407\n",
      "      - -203750.07419850954\n",
      "      - -201083.7778061628\n",
      "      - -204277.52587565812\n",
      "      - -204855.4859228415\n",
      "      - -204760.935187294\n",
      "      - -201781.16127631703\n",
      "      - -202940.55003646613\n",
      "      - -202314.8445366865\n",
      "      - -198927.37062635864\n",
      "      - -206014.13528061452\n",
      "      - -205268.88164100592\n",
      "      - -204316.1601981256\n",
      "      - -203872.14738298272\n",
      "      - -199053.95840910161\n",
      "      - -205479.60562249742\n",
      "      - -211092.89995249946\n",
      "      - -202921.43660981196\n",
      "      - -199128.29422072112\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11769174307756508\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5127898324327457\n",
      "      mean_inference_ms: 1.5885398208001487\n",
      "      mean_raw_obs_processing_ms: 0.16227429045582095\n",
      "  time_since_restore: 935.4769792556763\n",
      "  time_this_iter_s: 15.52936840057373\n",
      "  time_total_s: 935.4769792556763\n",
      "  timers:\n",
      "    learn_throughput: 26277.453\n",
      "    learn_time_ms: 2434.939\n",
      "    load_throughput: 542519.409\n",
      "    load_time_ms: 117.939\n",
      "    training_iteration_time_ms: 15339.584\n",
      "    update_time_ms: 4.164\n",
      "  timestamp: 1665743151\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3839040\n",
      "  training_iteration: 60\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:25:56 (running for 00:15:58.44)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    60</td><td style=\"text-align: right;\">         935.477</td><td style=\"text-align: right;\">3.83904e+06</td><td style=\"text-align: right;\"> -204503</td><td style=\"text-align: right;\">             -197490</td><td style=\"text-align: right;\">             -213931</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:26:01 (running for 00:16:03.53)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    60</td><td style=\"text-align: right;\">         935.477</td><td style=\"text-align: right;\">3.83904e+06</td><td style=\"text-align: right;\"> -204503</td><td style=\"text-align: right;\">             -197490</td><td style=\"text-align: right;\">             -213931</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:26:06 (running for 00:16:08.54)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    60</td><td style=\"text-align: right;\">         935.477</td><td style=\"text-align: right;\">3.83904e+06</td><td style=\"text-align: right;\"> -204503</td><td style=\"text-align: right;\">             -197490</td><td style=\"text-align: right;\">             -213931</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 3903024\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 3903024\n",
      "    num_agent_steps_trained: 3903024\n",
      "    num_env_steps_sampled: 3903024\n",
      "    num_env_steps_trained: 3903024\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-26-06\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -198927.37062635864\n",
      "  episode_reward_mean: -205102.90477094988\n",
      "  episode_reward_min: -234826.79584738126\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 3900\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.07684326171875\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.001798426965251565\n",
      "          model: {}\n",
      "          policy_loss: 0.006349161267280579\n",
      "          total_loss: 10.006400108337402\n",
      "          vf_explained_var: 7.042518177513557e-07\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 3903024\n",
      "    num_agent_steps_trained: 3903024\n",
      "    num_env_steps_sampled: 3903024\n",
      "    num_env_steps_trained: 3903024\n",
      "  iterations_since_restore: 61\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 3903024\n",
      "  num_agent_steps_trained: 3903024\n",
      "  num_env_steps_sampled: 3903024\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 3903024\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.77727272727275\n",
      "    ram_util_percent: 78.56363636363633\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11780579513184504\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5129580251409581\n",
      "    mean_inference_ms: 1.588688727109139\n",
      "    mean_raw_obs_processing_ms: 0.1622281575830934\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -198927.37062635864\n",
      "    episode_reward_mean: -205102.90477094988\n",
      "    episode_reward_min: -234826.79584738126\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -208746.35786280673\n",
      "      - -205229.3037228848\n",
      "      - -205592.8127078635\n",
      "      - -205075.96082900118\n",
      "      - -201992.92729166124\n",
      "      - -204424.2679926443\n",
      "      - -207904.2302542365\n",
      "      - -207345.68281539806\n",
      "      - -204454.29572519445\n",
      "      - -203023.38372411407\n",
      "      - -203750.07419850954\n",
      "      - -201083.7778061628\n",
      "      - -204277.52587565812\n",
      "      - -204855.4859228415\n",
      "      - -204760.935187294\n",
      "      - -201781.16127631703\n",
      "      - -202940.55003646613\n",
      "      - -202314.8445366865\n",
      "      - -198927.37062635864\n",
      "      - -206014.13528061452\n",
      "      - -205268.88164100592\n",
      "      - -204316.1601981256\n",
      "      - -203872.14738298272\n",
      "      - -199053.95840910161\n",
      "      - -205479.60562249742\n",
      "      - -211092.89995249946\n",
      "      - -202921.43660981196\n",
      "      - -199128.29422072112\n",
      "      - -203006.9472299175\n",
      "      - -206290.14530845635\n",
      "      - -203756.71474468528\n",
      "      - -205888.84554123535\n",
      "      - -205587.81105039665\n",
      "      - -205404.26737126565\n",
      "      - -204074.5607562879\n",
      "      - -203950.42598322185\n",
      "      - -202301.84040046204\n",
      "      - -199629.668117433\n",
      "      - -208509.48654820162\n",
      "      - -207114.69305272363\n",
      "      - -201083.86249593727\n",
      "      - -203667.20658246838\n",
      "      - -209181.56650341424\n",
      "      - -207535.72996481592\n",
      "      - -203723.73960088647\n",
      "      - -203375.97673987877\n",
      "      - -213889.84742747407\n",
      "      - -203723.79965007573\n",
      "      - -217021.1580994339\n",
      "      - -202672.8782963837\n",
      "      - -205752.43201296942\n",
      "      - -208923.30029617914\n",
      "      - -206808.02152607808\n",
      "      - -201506.9767442073\n",
      "      - -205202.9169268908\n",
      "      - -205131.20582860382\n",
      "      - -202807.26492917878\n",
      "      - -205016.44800593742\n",
      "      - -200762.45601964407\n",
      "      - -203061.0435427701\n",
      "      - -199621.6637085829\n",
      "      - -201534.27624691805\n",
      "      - -204904.64142054558\n",
      "      - -203036.44608373733\n",
      "      - -206764.37073675494\n",
      "      - -204986.83823182242\n",
      "      - -205615.40232750538\n",
      "      - -204519.83959622344\n",
      "      - -203438.25668427657\n",
      "      - -205765.5574123841\n",
      "      - -203156.56689312527\n",
      "      - -199912.29766657169\n",
      "      - -204336.157034697\n",
      "      - -213326.7164471296\n",
      "      - -206350.27166660508\n",
      "      - -209188.6860964279\n",
      "      - -207265.37026332467\n",
      "      - -200796.4903621101\n",
      "      - -206606.03492419256\n",
      "      - -206154.92176042876\n",
      "      - -201565.22935835144\n",
      "      - -206859.99311473445\n",
      "      - -203424.02124768015\n",
      "      - -207431.83235403584\n",
      "      - -202365.12789246722\n",
      "      - -207354.35573723138\n",
      "      - -203740.38555624237\n",
      "      - -201065.91558569414\n",
      "      - -234826.79584738126\n",
      "      - -205327.84908537834\n",
      "      - -206610.44350960336\n",
      "      - -208938.30277406293\n",
      "      - -203816.9706484665\n",
      "      - -201539.5276091561\n",
      "      - -208910.55248835566\n",
      "      - -204913.94650057814\n",
      "      - -202517.59836146364\n",
      "      - -202066.50611776114\n",
      "      - -208073.61782059606\n",
      "      - -209668.994915414\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11780579513184504\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5129580251409581\n",
      "      mean_inference_ms: 1.588688727109139\n",
      "      mean_raw_obs_processing_ms: 0.1622281575830934\n",
      "  time_since_restore: 950.8541505336761\n",
      "  time_this_iter_s: 15.377171277999878\n",
      "  time_total_s: 950.8541505336761\n",
      "  timers:\n",
      "    learn_throughput: 25783.867\n",
      "    learn_time_ms: 2481.552\n",
      "    load_throughput: 540601.999\n",
      "    load_time_ms: 118.357\n",
      "    training_iteration_time_ms: 15393.601\n",
      "    update_time_ms: 4.133\n",
      "  timestamp: 1665743166\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3903024\n",
      "  training_iteration: 61\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:26:11 (running for 00:16:13.93)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    61</td><td style=\"text-align: right;\">         950.854</td><td style=\"text-align: right;\">3.90302e+06</td><td style=\"text-align: right;\"> -205103</td><td style=\"text-align: right;\">             -198927</td><td style=\"text-align: right;\">             -234827</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:26:16 (running for 00:16:18.94)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    61</td><td style=\"text-align: right;\">         950.854</td><td style=\"text-align: right;\">3.90302e+06</td><td style=\"text-align: right;\"> -205103</td><td style=\"text-align: right;\">             -198927</td><td style=\"text-align: right;\">             -234827</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 3967008\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 3967008\n",
      "    num_agent_steps_trained: 3967008\n",
      "    num_env_steps_sampled: 3967008\n",
      "    num_env_steps_trained: 3967008\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-26-21\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -198588.3140241591\n",
      "  episode_reward_mean: -207207.14721486828\n",
      "  episode_reward_min: -269937.2523143925\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 3960\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0740396976470947\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0024448654148727655\n",
      "          model: {}\n",
      "          policy_loss: 0.0036656130105257034\n",
      "          total_loss: 10.003847122192383\n",
      "          vf_explained_var: 1.4435499906539917e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 3967008\n",
      "    num_agent_steps_trained: 3967008\n",
      "    num_env_steps_sampled: 3967008\n",
      "    num_env_steps_trained: 3967008\n",
      "  iterations_since_restore: 62\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 3967008\n",
      "  num_agent_steps_trained: 3967008\n",
      "  num_env_steps_sampled: 3967008\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 3967008\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.67619047619048\n",
      "    ram_util_percent: 78.60476190476187\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11763451238883915\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5128903733854684\n",
      "    mean_inference_ms: 1.5870681143670593\n",
      "    mean_raw_obs_processing_ms: 0.1624533577915063\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -198588.3140241591\n",
      "    episode_reward_mean: -207207.14721486828\n",
      "    episode_reward_min: -269937.2523143925\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -199621.6637085829\n",
      "      - -201534.27624691805\n",
      "      - -204904.64142054558\n",
      "      - -203036.44608373733\n",
      "      - -206764.37073675494\n",
      "      - -204986.83823182242\n",
      "      - -205615.40232750538\n",
      "      - -204519.83959622344\n",
      "      - -203438.25668427657\n",
      "      - -205765.5574123841\n",
      "      - -203156.56689312527\n",
      "      - -199912.29766657169\n",
      "      - -204336.157034697\n",
      "      - -213326.7164471296\n",
      "      - -206350.27166660508\n",
      "      - -209188.6860964279\n",
      "      - -207265.37026332467\n",
      "      - -200796.4903621101\n",
      "      - -206606.03492419256\n",
      "      - -206154.92176042876\n",
      "      - -201565.22935835144\n",
      "      - -206859.99311473445\n",
      "      - -203424.02124768015\n",
      "      - -207431.83235403584\n",
      "      - -202365.12789246722\n",
      "      - -207354.35573723138\n",
      "      - -203740.38555624237\n",
      "      - -201065.91558569414\n",
      "      - -234826.79584738126\n",
      "      - -205327.84908537834\n",
      "      - -206610.44350960336\n",
      "      - -208938.30277406293\n",
      "      - -203816.9706484665\n",
      "      - -201539.5276091561\n",
      "      - -208910.55248835566\n",
      "      - -204913.94650057814\n",
      "      - -202517.59836146364\n",
      "      - -202066.50611776114\n",
      "      - -208073.61782059606\n",
      "      - -209668.994915414\n",
      "      - -202327.0227551954\n",
      "      - -205286.4645977383\n",
      "      - -205076.77403018234\n",
      "      - -204938.87202371692\n",
      "      - -204160.4355843041\n",
      "      - -209745.4429172472\n",
      "      - -203177.4170237204\n",
      "      - -204436.0538859026\n",
      "      - -202769.63977435447\n",
      "      - -203774.19525323831\n",
      "      - -207533.96049504698\n",
      "      - -199918.26445829877\n",
      "      - -269937.2523143925\n",
      "      - -201272.85082605344\n",
      "      - -207809.4471172689\n",
      "      - -233441.94422383668\n",
      "      - -202880.23435514528\n",
      "      - -234592.98600673812\n",
      "      - -199606.46859262083\n",
      "      - -204590.32587852178\n",
      "      - -203200.57403988356\n",
      "      - -203623.24354540298\n",
      "      - -206518.82533580088\n",
      "      - -237883.02463394238\n",
      "      - -203484.47433382564\n",
      "      - -205816.89950364688\n",
      "      - -200621.95580166063\n",
      "      - -205118.31840208804\n",
      "      - -211245.59779386697\n",
      "      - -215095.93657109345\n",
      "      - -202167.68117319565\n",
      "      - -204495.94348858134\n",
      "      - -206281.73547461082\n",
      "      - -213369.34170792115\n",
      "      - -204635.19341773837\n",
      "      - -205637.6127633566\n",
      "      - -201439.23041785494\n",
      "      - -206165.32243322607\n",
      "      - -205844.57670393435\n",
      "      - -207496.5945519862\n",
      "      - -207068.89748587605\n",
      "      - -202151.37329834292\n",
      "      - -205272.1614741081\n",
      "      - -198588.3140241591\n",
      "      - -205240.23076183372\n",
      "      - -208126.11538725247\n",
      "      - -205348.93091821144\n",
      "      - -208900.2647680803\n",
      "      - -203729.6973918866\n",
      "      - -199352.6975587038\n",
      "      - -200335.4118048778\n",
      "      - -205473.00507255702\n",
      "      - -204145.3525785571\n",
      "      - -203832.6042087994\n",
      "      - -203885.1527098114\n",
      "      - -211607.2008020085\n",
      "      - -201495.66705488146\n",
      "      - -253133.90261827092\n",
      "      - -204983.09821315904\n",
      "      - -202327.73706029746\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11763451238883915\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5128903733854684\n",
      "      mean_inference_ms: 1.5870681143670593\n",
      "      mean_raw_obs_processing_ms: 0.1624533577915063\n",
      "  time_since_restore: 965.8629922866821\n",
      "  time_this_iter_s: 15.008841753005981\n",
      "  time_total_s: 965.8629922866821\n",
      "  timers:\n",
      "    learn_throughput: 25808.573\n",
      "    learn_time_ms: 2479.176\n",
      "    load_throughput: 541212.958\n",
      "    load_time_ms: 118.223\n",
      "    training_iteration_time_ms: 15347.528\n",
      "    update_time_ms: 4.162\n",
      "  timestamp: 1665743181\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3967008\n",
      "  training_iteration: 62\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:26:26 (running for 00:16:28.97)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    62</td><td style=\"text-align: right;\">         965.863</td><td style=\"text-align: right;\">3.96701e+06</td><td style=\"text-align: right;\"> -207207</td><td style=\"text-align: right;\">             -198588</td><td style=\"text-align: right;\">             -269937</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:26:31 (running for 00:16:33.97)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    62</td><td style=\"text-align: right;\">         965.863</td><td style=\"text-align: right;\">3.96701e+06</td><td style=\"text-align: right;\"> -207207</td><td style=\"text-align: right;\">             -198588</td><td style=\"text-align: right;\">             -269937</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:26:36 (running for 00:16:39.08)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    62</td><td style=\"text-align: right;\">         965.863</td><td style=\"text-align: right;\">3.96701e+06</td><td style=\"text-align: right;\"> -207207</td><td style=\"text-align: right;\">             -198588</td><td style=\"text-align: right;\">             -269937</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 4030992\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 4030992\n",
      "    num_agent_steps_trained: 4030992\n",
      "    num_env_steps_sampled: 4030992\n",
      "    num_env_steps_trained: 4030992\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-26-36\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -197108.43548622134\n",
      "  episode_reward_mean: -205820.62776283437\n",
      "  episode_reward_min: -253133.90261827092\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 4020\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0630714893341064\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.002168940845876932\n",
      "          model: {}\n",
      "          policy_loss: 0.002763541415333748\n",
      "          total_loss: 10.002890586853027\n",
      "          vf_explained_var: 2.0815059542655945e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 4030992\n",
      "    num_agent_steps_trained: 4030992\n",
      "    num_env_steps_sampled: 4030992\n",
      "    num_env_steps_trained: 4030992\n",
      "  iterations_since_restore: 63\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 4030992\n",
      "  num_agent_steps_trained: 4030992\n",
      "  num_env_steps_sampled: 4030992\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 4030992\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.65714285714286\n",
      "    ram_util_percent: 78.59999999999998\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11752395787319238\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5123484784917605\n",
      "    mean_inference_ms: 1.5858628139742115\n",
      "    mean_raw_obs_processing_ms: 0.16229131804553076\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -197108.43548622134\n",
      "    episode_reward_mean: -205820.62776283437\n",
      "    episode_reward_min: -253133.90261827092\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -203200.57403988356\n",
      "      - -203623.24354540298\n",
      "      - -206518.82533580088\n",
      "      - -237883.02463394238\n",
      "      - -203484.47433382564\n",
      "      - -205816.89950364688\n",
      "      - -200621.95580166063\n",
      "      - -205118.31840208804\n",
      "      - -211245.59779386697\n",
      "      - -215095.93657109345\n",
      "      - -202167.68117319565\n",
      "      - -204495.94348858134\n",
      "      - -206281.73547461082\n",
      "      - -213369.34170792115\n",
      "      - -204635.19341773837\n",
      "      - -205637.6127633566\n",
      "      - -201439.23041785494\n",
      "      - -206165.32243322607\n",
      "      - -205844.57670393435\n",
      "      - -207496.5945519862\n",
      "      - -207068.89748587605\n",
      "      - -202151.37329834292\n",
      "      - -205272.1614741081\n",
      "      - -198588.3140241591\n",
      "      - -205240.23076183372\n",
      "      - -208126.11538725247\n",
      "      - -205348.93091821144\n",
      "      - -208900.2647680803\n",
      "      - -203729.6973918866\n",
      "      - -199352.6975587038\n",
      "      - -200335.4118048778\n",
      "      - -205473.00507255702\n",
      "      - -204145.3525785571\n",
      "      - -203832.6042087994\n",
      "      - -203885.1527098114\n",
      "      - -211607.2008020085\n",
      "      - -201495.66705488146\n",
      "      - -253133.90261827092\n",
      "      - -204983.09821315904\n",
      "      - -202327.73706029746\n",
      "      - -205863.3299642491\n",
      "      - -198605.72190548864\n",
      "      - -210428.0817906386\n",
      "      - -203458.10473701247\n",
      "      - -204639.33796314936\n",
      "      - -210779.72927823066\n",
      "      - -204044.52857379007\n",
      "      - -202777.8446043427\n",
      "      - -205258.32043644116\n",
      "      - -206770.91926328203\n",
      "      - -204056.70127592463\n",
      "      - -197108.43548622134\n",
      "      - -209275.34911893524\n",
      "      - -202492.07548705087\n",
      "      - -204987.66613075483\n",
      "      - -203522.1218783148\n",
      "      - -202891.86074058458\n",
      "      - -211562.1757024005\n",
      "      - -208173.19089010177\n",
      "      - -206710.11156821952\n",
      "      - -205658.43572712733\n",
      "      - -203916.50034534335\n",
      "      - -202523.1498878546\n",
      "      - -203971.00785572742\n",
      "      - -203649.26404604327\n",
      "      - -200887.08773923316\n",
      "      - -208351.50376831467\n",
      "      - -202222.02769105378\n",
      "      - -203924.1444538142\n",
      "      - -202644.3619649445\n",
      "      - -209701.50348497686\n",
      "      - -202370.66437886914\n",
      "      - -204068.12953100834\n",
      "      - -206090.85339378504\n",
      "      - -205035.4766990477\n",
      "      - -204967.11018881825\n",
      "      - -205571.2121911371\n",
      "      - -203723.3315916939\n",
      "      - -209009.11141359597\n",
      "      - -205555.77355004958\n",
      "      - -202855.2028438474\n",
      "      - -203879.78703206455\n",
      "      - -212145.11449850057\n",
      "      - -200475.19538096545\n",
      "      - -201754.66003284324\n",
      "      - -205595.520570456\n",
      "      - -204594.8823524793\n",
      "      - -206270.11389166187\n",
      "      - -209665.8061327799\n",
      "      - -203060.95067464767\n",
      "      - -202670.7218088979\n",
      "      - -208711.95550362318\n",
      "      - -208361.89848000722\n",
      "      - -204502.05276835157\n",
      "      - -200536.9331665195\n",
      "      - -205284.56167608683\n",
      "      - -202814.11327559085\n",
      "      - -202773.65227134235\n",
      "      - -210576.9851833959\n",
      "      - -203146.51475651495\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11752395787319238\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5123484784917605\n",
      "      mean_inference_ms: 1.5858628139742115\n",
      "      mean_raw_obs_processing_ms: 0.16229131804553076\n",
      "  time_since_restore: 981.0593154430389\n",
      "  time_this_iter_s: 15.196323156356812\n",
      "  time_total_s: 981.0593154430389\n",
      "  timers:\n",
      "    learn_throughput: 25415.268\n",
      "    learn_time_ms: 2517.542\n",
      "    load_throughput: 540860.54\n",
      "    load_time_ms: 118.3\n",
      "    training_iteration_time_ms: 15338.162\n",
      "    update_time_ms: 4.114\n",
      "  timestamp: 1665743196\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4030992\n",
      "  training_iteration: 63\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:26:41 (running for 00:16:44.11)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    63</td><td style=\"text-align: right;\">         981.059</td><td style=\"text-align: right;\">4.03099e+06</td><td style=\"text-align: right;\"> -205821</td><td style=\"text-align: right;\">             -197108</td><td style=\"text-align: right;\">             -253134</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:26:47 (running for 00:16:49.43)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    63</td><td style=\"text-align: right;\">         981.059</td><td style=\"text-align: right;\">4.03099e+06</td><td style=\"text-align: right;\"> -205821</td><td style=\"text-align: right;\">             -197108</td><td style=\"text-align: right;\">             -253134</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 4094976\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 4094976\n",
      "    num_agent_steps_trained: 4094976\n",
      "    num_env_steps_sampled: 4094976\n",
      "    num_env_steps_trained: 4094976\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-26-52\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -198166.32729571735\n",
      "  episode_reward_mean: -204170.79646591446\n",
      "  episode_reward_min: -213961.69659830548\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 4092\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.057204484939575\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0018753528129309416\n",
      "          model: {}\n",
      "          policy_loss: 0.005624176934361458\n",
      "          total_loss: 10.005694389343262\n",
      "          vf_explained_var: -1.1838399132102495e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 4094976\n",
      "    num_agent_steps_trained: 4094976\n",
      "    num_env_steps_sampled: 4094976\n",
      "    num_env_steps_trained: 4094976\n",
      "  iterations_since_restore: 64\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 4094976\n",
      "  num_agent_steps_trained: 4094976\n",
      "  num_env_steps_sampled: 4094976\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 4094976\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.32727272727273\n",
      "    ram_util_percent: 78.6181818181818\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11766391089038315\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5124568442308852\n",
      "    mean_inference_ms: 1.5856853615021662\n",
      "    mean_raw_obs_processing_ms: 0.16222413404106945\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -198166.32729571735\n",
      "    episode_reward_mean: -204170.79646591446\n",
      "    episode_reward_min: -213961.69659830548\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -204068.12953100834\n",
      "      - -206090.85339378504\n",
      "      - -205035.4766990477\n",
      "      - -204967.11018881825\n",
      "      - -205571.2121911371\n",
      "      - -203723.3315916939\n",
      "      - -209009.11141359597\n",
      "      - -205555.77355004958\n",
      "      - -202855.2028438474\n",
      "      - -203879.78703206455\n",
      "      - -212145.11449850057\n",
      "      - -200475.19538096545\n",
      "      - -201754.66003284324\n",
      "      - -205595.520570456\n",
      "      - -204594.8823524793\n",
      "      - -206270.11389166187\n",
      "      - -209665.8061327799\n",
      "      - -203060.95067464767\n",
      "      - -202670.7218088979\n",
      "      - -208711.95550362318\n",
      "      - -208361.89848000722\n",
      "      - -204502.05276835157\n",
      "      - -200536.9331665195\n",
      "      - -205284.56167608683\n",
      "      - -202814.11327559085\n",
      "      - -202773.65227134235\n",
      "      - -210576.9851833959\n",
      "      - -203146.51475651495\n",
      "      - -205342.7459914154\n",
      "      - -203234.32430437233\n",
      "      - -201488.04360927892\n",
      "      - -204406.05663329718\n",
      "      - -204428.22217011586\n",
      "      - -199239.92736327235\n",
      "      - -209131.68262017786\n",
      "      - -198166.32729571735\n",
      "      - -202255.42452371502\n",
      "      - -202107.87167898662\n",
      "      - -202245.30553411963\n",
      "      - -204507.78251256686\n",
      "      - -205376.88353051164\n",
      "      - -205537.67785009212\n",
      "      - -201983.60328040825\n",
      "      - -207500.51531207399\n",
      "      - -204120.66876950537\n",
      "      - -203655.4064659184\n",
      "      - -207645.03200272078\n",
      "      - -200664.33373912328\n",
      "      - -202985.84504905212\n",
      "      - -206408.29529628134\n",
      "      - -202676.29720784657\n",
      "      - -203167.64000078553\n",
      "      - -201235.9757560406\n",
      "      - -201706.1006624258\n",
      "      - -203065.86059729685\n",
      "      - -207904.0540255646\n",
      "      - -205666.0507224539\n",
      "      - -201568.9438191649\n",
      "      - -204251.67436785332\n",
      "      - -202006.42600625881\n",
      "      - -201057.27846231803\n",
      "      - -203319.45833689382\n",
      "      - -206211.68220605524\n",
      "      - -202729.71671796258\n",
      "      - -203189.06027827357\n",
      "      - -201561.4238398156\n",
      "      - -202276.2251659454\n",
      "      - -207967.76160950252\n",
      "      - -202792.42777358546\n",
      "      - -204443.09542048693\n",
      "      - -198883.90060784516\n",
      "      - -198913.953783344\n",
      "      - -205296.32588275566\n",
      "      - -204669.43469470475\n",
      "      - -201452.6769464432\n",
      "      - -205709.40019010732\n",
      "      - -204947.92928990067\n",
      "      - -206553.63898670155\n",
      "      - -198189.26817320997\n",
      "      - -202242.2118291756\n",
      "      - -203113.91264064927\n",
      "      - -213961.69659830548\n",
      "      - -208961.56055595027\n",
      "      - -207643.6384919878\n",
      "      - -207003.85583583408\n",
      "      - -201321.9434721526\n",
      "      - -204602.75273883142\n",
      "      - -207970.71055059717\n",
      "      - -204953.81776422248\n",
      "      - -205624.40067719537\n",
      "      - -199976.17546478554\n",
      "      - -203406.16195843669\n",
      "      - -203611.7879083854\n",
      "      - -204854.04139794686\n",
      "      - -204197.92953413696\n",
      "      - -202817.5682840192\n",
      "      - -201613.05757423613\n",
      "      - -204617.1643367509\n",
      "      - -201800.45606520897\n",
      "      - -203241.52498866187\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11766391089038315\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5124568442308852\n",
      "      mean_inference_ms: 1.5856853615021662\n",
      "      mean_raw_obs_processing_ms: 0.16222413404106945\n",
      "  time_since_restore: 996.213282585144\n",
      "  time_this_iter_s: 15.153967142105103\n",
      "  time_total_s: 996.213282585144\n",
      "  timers:\n",
      "    learn_throughput: 25359.135\n",
      "    learn_time_ms: 2523.114\n",
      "    load_throughput: 539945.374\n",
      "    load_time_ms: 118.501\n",
      "    training_iteration_time_ms: 15266.542\n",
      "    update_time_ms: 4.139\n",
      "  timestamp: 1665743212\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4094976\n",
      "  training_iteration: 64\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:26:57 (running for 00:16:59.39)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    64</td><td style=\"text-align: right;\">         996.213</td><td style=\"text-align: right;\">4.09498e+06</td><td style=\"text-align: right;\"> -204171</td><td style=\"text-align: right;\">             -198166</td><td style=\"text-align: right;\">             -213962</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:27:02 (running for 00:17:04.49)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    64</td><td style=\"text-align: right;\">         996.213</td><td style=\"text-align: right;\">4.09498e+06</td><td style=\"text-align: right;\"> -204171</td><td style=\"text-align: right;\">             -198166</td><td style=\"text-align: right;\">             -213962</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:27:07 (running for 00:17:09.80)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    64</td><td style=\"text-align: right;\">         996.213</td><td style=\"text-align: right;\">4.09498e+06</td><td style=\"text-align: right;\"> -204171</td><td style=\"text-align: right;\">             -198166</td><td style=\"text-align: right;\">             -213962</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 4158960\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 4158960\n",
      "    num_agent_steps_trained: 4158960\n",
      "    num_env_steps_sampled: 4158960\n",
      "    num_env_steps_trained: 4158960\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-27-07\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -198189.26817320997\n",
      "  episode_reward_mean: -203772.64477314064\n",
      "  episode_reward_min: -219985.65816770607\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 4152\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.054586172103882\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0020445608533918858\n",
      "          model: {}\n",
      "          policy_loss: 0.0023171440698206425\n",
      "          total_loss: 10.002420425415039\n",
      "          vf_explained_var: -2.09991753763461e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 4158960\n",
      "    num_agent_steps_trained: 4158960\n",
      "    num_env_steps_sampled: 4158960\n",
      "    num_env_steps_trained: 4158960\n",
      "  iterations_since_restore: 65\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 4158960\n",
      "  num_agent_steps_trained: 4158960\n",
      "  num_env_steps_sampled: 4158960\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 4158960\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.55714285714285\n",
      "    ram_util_percent: 78.60476190476187\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11749625101485116\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5124450330833088\n",
      "    mean_inference_ms: 1.5840225942970168\n",
      "    mean_raw_obs_processing_ms: 0.16235848017688295\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -198189.26817320997\n",
      "    episode_reward_mean: -203772.64477314064\n",
      "    episode_reward_min: -219985.65816770607\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -201057.27846231803\n",
      "      - -203319.45833689382\n",
      "      - -206211.68220605524\n",
      "      - -202729.71671796258\n",
      "      - -203189.06027827357\n",
      "      - -201561.4238398156\n",
      "      - -202276.2251659454\n",
      "      - -207967.76160950252\n",
      "      - -202792.42777358546\n",
      "      - -204443.09542048693\n",
      "      - -198883.90060784516\n",
      "      - -198913.953783344\n",
      "      - -205296.32588275566\n",
      "      - -204669.43469470475\n",
      "      - -201452.6769464432\n",
      "      - -205709.40019010732\n",
      "      - -204947.92928990067\n",
      "      - -206553.63898670155\n",
      "      - -198189.26817320997\n",
      "      - -202242.2118291756\n",
      "      - -203113.91264064927\n",
      "      - -213961.69659830548\n",
      "      - -208961.56055595027\n",
      "      - -207643.6384919878\n",
      "      - -207003.85583583408\n",
      "      - -201321.9434721526\n",
      "      - -204602.75273883142\n",
      "      - -207970.71055059717\n",
      "      - -204953.81776422248\n",
      "      - -205624.40067719537\n",
      "      - -199976.17546478554\n",
      "      - -203406.16195843669\n",
      "      - -203611.7879083854\n",
      "      - -204854.04139794686\n",
      "      - -204197.92953413696\n",
      "      - -202817.5682840192\n",
      "      - -201613.05757423613\n",
      "      - -204617.1643367509\n",
      "      - -201800.45606520897\n",
      "      - -203241.52498866187\n",
      "      - -200261.09701535033\n",
      "      - -203918.2218828203\n",
      "      - -202694.38938151265\n",
      "      - -200141.6200492226\n",
      "      - -200820.28571639943\n",
      "      - -206240.09774793015\n",
      "      - -204687.67985336352\n",
      "      - -202163.08713296897\n",
      "      - -200377.1495922631\n",
      "      - -203430.61464482825\n",
      "      - -201641.48255577195\n",
      "      - -204209.85416482773\n",
      "      - -201986.86162517488\n",
      "      - -203078.84837481618\n",
      "      - -201637.4209560371\n",
      "      - -205193.41776425648\n",
      "      - -208345.06373784353\n",
      "      - -205118.38353733375\n",
      "      - -201206.62859636557\n",
      "      - -203860.78302543756\n",
      "      - -204395.1052480597\n",
      "      - -204664.36066079699\n",
      "      - -199901.99318412654\n",
      "      - -202870.53331505627\n",
      "      - -200947.01467429317\n",
      "      - -202438.22244006695\n",
      "      - -206073.66494301794\n",
      "      - -205734.85745019658\n",
      "      - -204955.67646083422\n",
      "      - -198935.01555522706\n",
      "      - -199473.0873391133\n",
      "      - -200712.94532187041\n",
      "      - -208523.97398839542\n",
      "      - -201527.45648166744\n",
      "      - -205339.17539848815\n",
      "      - -201246.58827385923\n",
      "      - -204249.94016357104\n",
      "      - -203862.62372135388\n",
      "      - -202231.870482651\n",
      "      - -201536.87425299414\n",
      "      - -200389.18864883785\n",
      "      - -203153.13943290725\n",
      "      - -200476.80284630606\n",
      "      - -212893.54320833806\n",
      "      - -203932.18406856467\n",
      "      - -210091.45085148088\n",
      "      - -207917.5696183127\n",
      "      - -203908.33094495814\n",
      "      - -201592.93890150817\n",
      "      - -203114.9247983064\n",
      "      - -203625.73443397201\n",
      "      - -199877.0274991856\n",
      "      - -202546.06134442007\n",
      "      - -202359.63584870356\n",
      "      - -208615.50087039097\n",
      "      - -210306.1987200899\n",
      "      - -219985.65816770607\n",
      "      - -201775.89226283564\n",
      "      - -200174.3682910567\n",
      "      - -202193.33281269943\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11749625101485116\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5124450330833088\n",
      "      mean_inference_ms: 1.5840225942970168\n",
      "      mean_raw_obs_processing_ms: 0.16235848017688295\n",
      "  time_since_restore: 1011.9477519989014\n",
      "  time_this_iter_s: 15.734469413757324\n",
      "  time_total_s: 1011.9477519989014\n",
      "  timers:\n",
      "    learn_throughput: 24449.111\n",
      "    learn_time_ms: 2617.028\n",
      "    load_throughput: 539703.227\n",
      "    load_time_ms: 118.554\n",
      "    training_iteration_time_ms: 15309.135\n",
      "    update_time_ms: 4.132\n",
      "  timestamp: 1665743227\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4158960\n",
      "  training_iteration: 65\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:27:12 (running for 00:17:15.16)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    65</td><td style=\"text-align: right;\">         1011.95</td><td style=\"text-align: right;\">4.15896e+06</td><td style=\"text-align: right;\"> -203773</td><td style=\"text-align: right;\">             -198189</td><td style=\"text-align: right;\">             -219986</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:27:17 (running for 00:17:20.23)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    65</td><td style=\"text-align: right;\">         1011.95</td><td style=\"text-align: right;\">4.15896e+06</td><td style=\"text-align: right;\"> -203773</td><td style=\"text-align: right;\">             -198189</td><td style=\"text-align: right;\">             -219986</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:27:23 (running for 00:17:25.23)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    65</td><td style=\"text-align: right;\">         1011.95</td><td style=\"text-align: right;\">4.15896e+06</td><td style=\"text-align: right;\"> -203773</td><td style=\"text-align: right;\">             -198189</td><td style=\"text-align: right;\">             -219986</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 4222944\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 4222944\n",
      "    num_agent_steps_trained: 4222944\n",
      "    num_env_steps_sampled: 4222944\n",
      "    num_env_steps_trained: 4222944\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-27-23\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -196593.62263427526\n",
      "  episode_reward_mean: -204697.88013235683\n",
      "  episode_reward_min: -256606.001004404\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 4212\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0513429641723633\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.002177581889554858\n",
      "          model: {}\n",
      "          policy_loss: 0.0005826698034070432\n",
      "          total_loss: 10.000713348388672\n",
      "          vf_explained_var: -9.403779017702618e-07\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 4222944\n",
      "    num_agent_steps_trained: 4222944\n",
      "    num_env_steps_sampled: 4222944\n",
      "    num_env_steps_trained: 4222944\n",
      "  iterations_since_restore: 66\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 4222944\n",
      "  num_agent_steps_trained: 4222944\n",
      "  num_env_steps_sampled: 4222944\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 4222944\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.30952380952381\n",
      "    ram_util_percent: 78.63809523809523\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11739532297389264\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5119944802372783\n",
      "    mean_inference_ms: 1.583768679043686\n",
      "    mean_raw_obs_processing_ms: 0.162095486202486\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -196593.62263427526\n",
      "    episode_reward_mean: -204697.88013235683\n",
      "    episode_reward_min: -256606.001004404\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -204395.1052480597\n",
      "      - -204664.36066079699\n",
      "      - -199901.99318412654\n",
      "      - -202870.53331505627\n",
      "      - -200947.01467429317\n",
      "      - -202438.22244006695\n",
      "      - -206073.66494301794\n",
      "      - -205734.85745019658\n",
      "      - -204955.67646083422\n",
      "      - -198935.01555522706\n",
      "      - -199473.0873391133\n",
      "      - -200712.94532187041\n",
      "      - -208523.97398839542\n",
      "      - -201527.45648166744\n",
      "      - -205339.17539848815\n",
      "      - -201246.58827385923\n",
      "      - -204249.94016357104\n",
      "      - -203862.62372135388\n",
      "      - -202231.870482651\n",
      "      - -201536.87425299414\n",
      "      - -200389.18864883785\n",
      "      - -203153.13943290725\n",
      "      - -200476.80284630606\n",
      "      - -212893.54320833806\n",
      "      - -203932.18406856467\n",
      "      - -210091.45085148088\n",
      "      - -207917.5696183127\n",
      "      - -203908.33094495814\n",
      "      - -201592.93890150817\n",
      "      - -203114.9247983064\n",
      "      - -203625.73443397201\n",
      "      - -199877.0274991856\n",
      "      - -202546.06134442007\n",
      "      - -202359.63584870356\n",
      "      - -208615.50087039097\n",
      "      - -210306.1987200899\n",
      "      - -219985.65816770607\n",
      "      - -201775.89226283564\n",
      "      - -200174.3682910567\n",
      "      - -202193.33281269943\n",
      "      - -197677.83905084457\n",
      "      - -203574.9474892049\n",
      "      - -203792.22551354795\n",
      "      - -201060.93383010072\n",
      "      - -200566.29880530704\n",
      "      - -197077.55688528225\n",
      "      - -207083.93290325897\n",
      "      - -200023.0093829666\n",
      "      - -208045.4708512717\n",
      "      - -199602.67159127496\n",
      "      - -204401.5547562293\n",
      "      - -208157.14312851254\n",
      "      - -205199.6622216049\n",
      "      - -200748.00280624116\n",
      "      - -203629.77782536592\n",
      "      - -204182.83203887613\n",
      "      - -198435.2231115668\n",
      "      - -203144.05172985315\n",
      "      - -207533.52634926594\n",
      "      - -206216.11938728957\n",
      "      - -200672.58710662703\n",
      "      - -200916.84447808296\n",
      "      - -207113.15080964394\n",
      "      - -203757.39142240115\n",
      "      - -198001.56726219828\n",
      "      - -200609.471764555\n",
      "      - -207825.5652662519\n",
      "      - -201024.4823355342\n",
      "      - -256416.38701893247\n",
      "      - -201402.27282138614\n",
      "      - -207591.78569812133\n",
      "      - -202304.4489873906\n",
      "      - -207527.31838503713\n",
      "      - -203679.24341356062\n",
      "      - -202189.92120454583\n",
      "      - -196827.84490305805\n",
      "      - -201391.0938694107\n",
      "      - -201884.09926046256\n",
      "      - -201296.033905717\n",
      "      - -211094.66926264422\n",
      "      - -197200.32585559317\n",
      "      - -213676.2468693221\n",
      "      - -197233.5970802657\n",
      "      - -196593.62263427526\n",
      "      - -205873.0339261155\n",
      "      - -202155.34282237547\n",
      "      - -201930.09965169942\n",
      "      - -204221.2914154051\n",
      "      - -205167.46793230172\n",
      "      - -209679.45953811295\n",
      "      - -204680.31441648197\n",
      "      - -206141.49893121116\n",
      "      - -204950.88017498495\n",
      "      - -205233.43536363545\n",
      "      - -205016.19530898618\n",
      "      - -202453.844754652\n",
      "      - -202797.96360168883\n",
      "      - -204107.61300317693\n",
      "      - -256606.001004404\n",
      "      - -211840.357191349\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11739532297389264\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5119944802372783\n",
      "      mean_inference_ms: 1.583768679043686\n",
      "      mean_raw_obs_processing_ms: 0.162095486202486\n",
      "  time_since_restore: 1027.4022209644318\n",
      "  time_this_iter_s: 15.454468965530396\n",
      "  time_total_s: 1027.4022209644318\n",
      "  timers:\n",
      "    learn_throughput: 24417.245\n",
      "    learn_time_ms: 2620.443\n",
      "    load_throughput: 536190.745\n",
      "    load_time_ms: 119.331\n",
      "    training_iteration_time_ms: 15365.346\n",
      "    update_time_ms: 4.145\n",
      "  timestamp: 1665743243\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4222944\n",
      "  training_iteration: 66\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:27:28 (running for 00:17:30.91)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    66</td><td style=\"text-align: right;\">          1027.4</td><td style=\"text-align: right;\">4.22294e+06</td><td style=\"text-align: right;\"> -204698</td><td style=\"text-align: right;\">             -196594</td><td style=\"text-align: right;\">             -256606</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:27:33 (running for 00:17:36.01)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    66</td><td style=\"text-align: right;\">          1027.4</td><td style=\"text-align: right;\">4.22294e+06</td><td style=\"text-align: right;\"> -204698</td><td style=\"text-align: right;\">             -196594</td><td style=\"text-align: right;\">             -256606</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 4286928\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 4286928\n",
      "    num_agent_steps_trained: 4286928\n",
      "    num_env_steps_sampled: 4286928\n",
      "    num_env_steps_trained: 4286928\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-27-38\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -196593.62263427526\n",
      "  episode_reward_mean: -204676.488779084\n",
      "  episode_reward_min: -256606.001004404\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 4284\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.05147123336792\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0018241916550323367\n",
      "          model: {}\n",
      "          policy_loss: 0.002646371955052018\n",
      "          total_loss: 10.002706527709961\n",
      "          vf_explained_var: 1.1659585652523674e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 4286928\n",
      "    num_agent_steps_trained: 4286928\n",
      "    num_env_steps_sampled: 4286928\n",
      "    num_env_steps_trained: 4286928\n",
      "  iterations_since_restore: 67\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 4286928\n",
      "  num_agent_steps_trained: 4286928\n",
      "  num_env_steps_sampled: 4286928\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 4286928\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.42272727272727\n",
      "    ram_util_percent: 78.61363636363635\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11750276852736116\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5118612379807307\n",
      "    mean_inference_ms: 1.5851304415508174\n",
      "    mean_raw_obs_processing_ms: 0.1620880967871348\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -196593.62263427526\n",
      "    episode_reward_mean: -204676.488779084\n",
      "    episode_reward_min: -256606.001004404\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -207527.31838503713\n",
      "      - -203679.24341356062\n",
      "      - -202189.92120454583\n",
      "      - -196827.84490305805\n",
      "      - -201391.0938694107\n",
      "      - -201884.09926046256\n",
      "      - -201296.033905717\n",
      "      - -211094.66926264422\n",
      "      - -197200.32585559317\n",
      "      - -213676.2468693221\n",
      "      - -197233.5970802657\n",
      "      - -196593.62263427526\n",
      "      - -205873.0339261155\n",
      "      - -202155.34282237547\n",
      "      - -201930.09965169942\n",
      "      - -204221.2914154051\n",
      "      - -205167.46793230172\n",
      "      - -209679.45953811295\n",
      "      - -204680.31441648197\n",
      "      - -206141.49893121116\n",
      "      - -204950.88017498495\n",
      "      - -205233.43536363545\n",
      "      - -205016.19530898618\n",
      "      - -202453.844754652\n",
      "      - -202797.96360168883\n",
      "      - -204107.61300317693\n",
      "      - -256606.001004404\n",
      "      - -211840.357191349\n",
      "      - -203462.25936198808\n",
      "      - -210497.86198776387\n",
      "      - -205604.81101982133\n",
      "      - -198065.9400489964\n",
      "      - -211826.0214203514\n",
      "      - -204492.2553712256\n",
      "      - -201052.44226817944\n",
      "      - -216966.7271222969\n",
      "      - -204749.2837574578\n",
      "      - -203814.04923505333\n",
      "      - -209817.64743543693\n",
      "      - -202518.50772298648\n",
      "      - -199999.1070693407\n",
      "      - -205342.79314776283\n",
      "      - -199430.98581068896\n",
      "      - -205656.29451978498\n",
      "      - -204446.02249471346\n",
      "      - -203815.03311173114\n",
      "      - -202120.12488823017\n",
      "      - -208564.2560125695\n",
      "      - -199724.5768932652\n",
      "      - -204562.30545516912\n",
      "      - -205295.15940950607\n",
      "      - -202817.05857895158\n",
      "      - -205469.47078717523\n",
      "      - -200361.8268470233\n",
      "      - -207359.99696744644\n",
      "      - -207493.85338876984\n",
      "      - -201716.841129507\n",
      "      - -204607.56816467547\n",
      "      - -202316.71118042467\n",
      "      - -208645.4483680522\n",
      "      - -203369.7415178108\n",
      "      - -201702.81898555963\n",
      "      - -204849.80300118617\n",
      "      - -204022.45437252795\n",
      "      - -201245.59884294742\n",
      "      - -201247.52514783602\n",
      "      - -203272.68187245293\n",
      "      - -204637.5930960442\n",
      "      - -202778.80711835762\n",
      "      - -202091.44480435338\n",
      "      - -202252.0702386964\n",
      "      - -200797.13783749935\n",
      "      - -204763.07109357746\n",
      "      - -205060.44082526417\n",
      "      - -206141.00057416168\n",
      "      - -204936.01278696043\n",
      "      - -198893.71152756482\n",
      "      - -203551.94698163445\n",
      "      - -201594.7906552109\n",
      "      - -204299.37534388102\n",
      "      - -205066.96931534848\n",
      "      - -204809.4541882963\n",
      "      - -201527.0337059983\n",
      "      - -204349.2081344636\n",
      "      - -207316.91452238985\n",
      "      - -202390.67585027812\n",
      "      - -205362.0000636215\n",
      "      - -201263.24782128754\n",
      "      - -204804.56974591498\n",
      "      - -206251.2301964267\n",
      "      - -204899.82008015426\n",
      "      - -206827.03543547858\n",
      "      - -206469.29540496282\n",
      "      - -200997.50849453692\n",
      "      - -203516.57866844733\n",
      "      - -204730.61601416807\n",
      "      - -205365.3737795929\n",
      "      - -206102.0433013727\n",
      "      - -205259.83043700046\n",
      "      - -202769.3894683177\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11750276852736116\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5118612379807307\n",
      "      mean_inference_ms: 1.5851304415508174\n",
      "      mean_raw_obs_processing_ms: 0.1620880967871348\n",
      "  time_since_restore: 1042.797528743744\n",
      "  time_this_iter_s: 15.395307779312134\n",
      "  time_total_s: 1042.797528743744\n",
      "  timers:\n",
      "    learn_throughput: 24383.377\n",
      "    learn_time_ms: 2624.083\n",
      "    load_throughput: 536127.76\n",
      "    load_time_ms: 119.345\n",
      "    training_iteration_time_ms: 15427.67\n",
      "    update_time_ms: 4.098\n",
      "  timestamp: 1665743258\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4286928\n",
      "  training_iteration: 67\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:27:44 (running for 00:17:46.63)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    67</td><td style=\"text-align: right;\">          1042.8</td><td style=\"text-align: right;\">4.28693e+06</td><td style=\"text-align: right;\"> -204676</td><td style=\"text-align: right;\">             -196594</td><td style=\"text-align: right;\">             -256606</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:27:49 (running for 00:17:51.64)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    67</td><td style=\"text-align: right;\">          1042.8</td><td style=\"text-align: right;\">4.28693e+06</td><td style=\"text-align: right;\"> -204676</td><td style=\"text-align: right;\">             -196594</td><td style=\"text-align: right;\">             -256606</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:27:54 (running for 00:17:56.65)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    67</td><td style=\"text-align: right;\">          1042.8</td><td style=\"text-align: right;\">4.28693e+06</td><td style=\"text-align: right;\"> -204676</td><td style=\"text-align: right;\">             -196594</td><td style=\"text-align: right;\">             -256606</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 4350912\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 4350912\n",
      "    num_agent_steps_trained: 4350912\n",
      "    num_env_steps_sampled: 4350912\n",
      "    num_env_steps_trained: 4350912\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-27-54\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -196331.4015021484\n",
      "  episode_reward_mean: -204055.6499073507\n",
      "  episode_reward_min: -210132.73478825073\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 4344\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0482003688812256\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.002070184564217925\n",
      "          model: {}\n",
      "          policy_loss: 0.0016516397008672357\n",
      "          total_loss: 10.001760482788086\n",
      "          vf_explained_var: -2.296154207215295e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 4350912\n",
      "    num_agent_steps_trained: 4350912\n",
      "    num_env_steps_sampled: 4350912\n",
      "    num_env_steps_trained: 4350912\n",
      "  iterations_since_restore: 68\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 4350912\n",
      "  num_agent_steps_trained: 4350912\n",
      "  num_env_steps_sampled: 4350912\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 4350912\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.40454545454547\n",
      "    ram_util_percent: 78.63636363636363\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11732546408502177\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5119491952538634\n",
      "    mean_inference_ms: 1.5845343508157144\n",
      "    mean_raw_obs_processing_ms: 0.16227764612493772\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -196331.4015021484\n",
      "    episode_reward_mean: -204055.6499073507\n",
      "    episode_reward_min: -210132.73478825073\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -203369.7415178108\n",
      "      - -201702.81898555963\n",
      "      - -204849.80300118617\n",
      "      - -204022.45437252795\n",
      "      - -201245.59884294742\n",
      "      - -201247.52514783602\n",
      "      - -203272.68187245293\n",
      "      - -204637.5930960442\n",
      "      - -202778.80711835762\n",
      "      - -202091.44480435338\n",
      "      - -202252.0702386964\n",
      "      - -200797.13783749935\n",
      "      - -204763.07109357746\n",
      "      - -205060.44082526417\n",
      "      - -206141.00057416168\n",
      "      - -204936.01278696043\n",
      "      - -198893.71152756482\n",
      "      - -203551.94698163445\n",
      "      - -201594.7906552109\n",
      "      - -204299.37534388102\n",
      "      - -205066.96931534848\n",
      "      - -204809.4541882963\n",
      "      - -201527.0337059983\n",
      "      - -204349.2081344636\n",
      "      - -207316.91452238985\n",
      "      - -202390.67585027812\n",
      "      - -205362.0000636215\n",
      "      - -201263.24782128754\n",
      "      - -204804.56974591498\n",
      "      - -206251.2301964267\n",
      "      - -204899.82008015426\n",
      "      - -206827.03543547858\n",
      "      - -206469.29540496282\n",
      "      - -200997.50849453692\n",
      "      - -203516.57866844733\n",
      "      - -204730.61601416807\n",
      "      - -205365.3737795929\n",
      "      - -206102.0433013727\n",
      "      - -205259.83043700046\n",
      "      - -202769.3894683177\n",
      "      - -200661.7624956951\n",
      "      - -203712.69530652225\n",
      "      - -202889.14418258998\n",
      "      - -203652.05711228968\n",
      "      - -196331.4015021484\n",
      "      - -204480.09469412421\n",
      "      - -203700.77410250416\n",
      "      - -203421.72578549077\n",
      "      - -206122.27082362806\n",
      "      - -199029.37518939035\n",
      "      - -200992.89756943638\n",
      "      - -200169.64742688663\n",
      "      - -206064.50781218434\n",
      "      - -204414.90008336297\n",
      "      - -204047.11861235267\n",
      "      - -206100.8469414638\n",
      "      - -202263.20854975423\n",
      "      - -202473.88770627594\n",
      "      - -200426.94960020503\n",
      "      - -209119.38459072058\n",
      "      - -209610.68162863926\n",
      "      - -208281.928238592\n",
      "      - -204519.61249791714\n",
      "      - -204416.235861027\n",
      "      - -201153.3683718015\n",
      "      - -199715.87270612433\n",
      "      - -202817.8258716758\n",
      "      - -206224.0271581258\n",
      "      - -208708.2878829794\n",
      "      - -203181.14311808324\n",
      "      - -200945.79660822728\n",
      "      - -209443.35142623607\n",
      "      - -202588.2009203508\n",
      "      - -207641.43671997558\n",
      "      - -207477.54738127816\n",
      "      - -208612.28955330738\n",
      "      - -205323.9905391427\n",
      "      - -203347.7797803632\n",
      "      - -201950.8775966178\n",
      "      - -207228.34998502408\n",
      "      - -206539.08160678743\n",
      "      - -198138.66982923675\n",
      "      - -202067.0386812293\n",
      "      - -201070.25581598753\n",
      "      - -209186.41706267517\n",
      "      - -206113.61845747646\n",
      "      - -202633.95863585264\n",
      "      - -198482.53443685226\n",
      "      - -201167.4579909979\n",
      "      - -210132.73478825073\n",
      "      - -201518.31461446546\n",
      "      - -207190.75986176977\n",
      "      - -204878.60125453759\n",
      "      - -206988.9485019387\n",
      "      - -207593.08533478386\n",
      "      - -202823.68475440747\n",
      "      - -206123.69624467407\n",
      "      - -203924.79223436984\n",
      "      - -205712.67533214088\n",
      "      - -208428.59011253624\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11732546408502177\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5119491952538634\n",
      "      mean_inference_ms: 1.5845343508157144\n",
      "      mean_raw_obs_processing_ms: 0.16227764612493772\n",
      "  time_since_restore: 1058.6943247318268\n",
      "  time_this_iter_s: 15.896795988082886\n",
      "  time_total_s: 1058.6943247318268\n",
      "  timers:\n",
      "    learn_throughput: 23943.529\n",
      "    learn_time_ms: 2672.288\n",
      "    load_throughput: 536783.931\n",
      "    load_time_ms: 119.199\n",
      "    training_iteration_time_ms: 15475.656\n",
      "    update_time_ms: 4.269\n",
      "  timestamp: 1665743274\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4350912\n",
      "  training_iteration: 68\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:27:59 (running for 00:18:01.91)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    68</td><td style=\"text-align: right;\">         1058.69</td><td style=\"text-align: right;\">4.35091e+06</td><td style=\"text-align: right;\"> -204056</td><td style=\"text-align: right;\">             -196331</td><td style=\"text-align: right;\">             -210133</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:28:04 (running for 00:18:07.00)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    68</td><td style=\"text-align: right;\">         1058.69</td><td style=\"text-align: right;\">4.35091e+06</td><td style=\"text-align: right;\"> -204056</td><td style=\"text-align: right;\">             -196331</td><td style=\"text-align: right;\">             -210133</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:28:09 (running for 00:18:12.15)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    68</td><td style=\"text-align: right;\">         1058.69</td><td style=\"text-align: right;\">4.35091e+06</td><td style=\"text-align: right;\"> -204056</td><td style=\"text-align: right;\">             -196331</td><td style=\"text-align: right;\">             -210133</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 4414896\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 4414896\n",
      "    num_agent_steps_trained: 4414896\n",
      "    num_env_steps_sampled: 4414896\n",
      "    num_env_steps_trained: 4414896\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-28-09\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -198138.66982923675\n",
      "  episode_reward_mean: -204275.64610600204\n",
      "  episode_reward_min: -213686.58678551123\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 4404\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0484304428100586\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0022594621405005455\n",
      "          model: {}\n",
      "          policy_loss: -0.004959865938872099\n",
      "          total_loss: 9.99518871307373\n",
      "          vf_explained_var: -1.4979106026657973e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 4414896\n",
      "    num_agent_steps_trained: 4414896\n",
      "    num_env_steps_sampled: 4414896\n",
      "    num_env_steps_trained: 4414896\n",
      "  iterations_since_restore: 69\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 4414896\n",
      "  num_agent_steps_trained: 4414896\n",
      "  num_env_steps_sampled: 4414896\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 4414896\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.69545454545454\n",
      "    ram_util_percent: 78.66363636363636\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11724140447916119\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5117929050689095\n",
      "    mean_inference_ms: 1.5842699046416036\n",
      "    mean_raw_obs_processing_ms: 0.1620373269415486\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -198138.66982923675\n",
      "    episode_reward_mean: -204275.64610600204\n",
      "    episode_reward_min: -213686.58678551123\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -209610.68162863926\n",
      "      - -208281.928238592\n",
      "      - -204519.61249791714\n",
      "      - -204416.235861027\n",
      "      - -201153.3683718015\n",
      "      - -199715.87270612433\n",
      "      - -202817.8258716758\n",
      "      - -206224.0271581258\n",
      "      - -208708.2878829794\n",
      "      - -203181.14311808324\n",
      "      - -200945.79660822728\n",
      "      - -209443.35142623607\n",
      "      - -202588.2009203508\n",
      "      - -207641.43671997558\n",
      "      - -207477.54738127816\n",
      "      - -208612.28955330738\n",
      "      - -205323.9905391427\n",
      "      - -203347.7797803632\n",
      "      - -201950.8775966178\n",
      "      - -207228.34998502408\n",
      "      - -206539.08160678743\n",
      "      - -198138.66982923675\n",
      "      - -202067.0386812293\n",
      "      - -201070.25581598753\n",
      "      - -209186.41706267517\n",
      "      - -206113.61845747646\n",
      "      - -202633.95863585264\n",
      "      - -198482.53443685226\n",
      "      - -201167.4579909979\n",
      "      - -210132.73478825073\n",
      "      - -201518.31461446546\n",
      "      - -207190.75986176977\n",
      "      - -204878.60125453759\n",
      "      - -206988.9485019387\n",
      "      - -207593.08533478386\n",
      "      - -202823.68475440747\n",
      "      - -206123.69624467407\n",
      "      - -203924.79223436984\n",
      "      - -205712.67533214088\n",
      "      - -208428.59011253624\n",
      "      - -201910.7566117282\n",
      "      - -202544.4560603787\n",
      "      - -199663.3903310633\n",
      "      - -201786.42989079922\n",
      "      - -202892.1723767517\n",
      "      - -202610.7175487571\n",
      "      - -207887.18626049257\n",
      "      - -207298.5483048835\n",
      "      - -200212.83336952326\n",
      "      - -201210.45567901045\n",
      "      - -201796.46682602828\n",
      "      - -202517.22548018524\n",
      "      - -201470.67591226468\n",
      "      - -198679.43845491816\n",
      "      - -201446.49703499416\n",
      "      - -202982.79347278332\n",
      "      - -203035.6005412117\n",
      "      - -203117.08754792475\n",
      "      - -213686.58678551123\n",
      "      - -207169.18044206384\n",
      "      - -209025.3090050572\n",
      "      - -205640.29469979097\n",
      "      - -205476.508410783\n",
      "      - -205165.99385978488\n",
      "      - -201589.58196720434\n",
      "      - -199840.18246021806\n",
      "      - -207982.69760392854\n",
      "      - -206806.43432688017\n",
      "      - -203059.9785351374\n",
      "      - -199777.84297025466\n",
      "      - -206817.7565390975\n",
      "      - -203625.491090615\n",
      "      - -200706.08998549075\n",
      "      - -202183.37411663184\n",
      "      - -202362.04387104735\n",
      "      - -199256.60449115504\n",
      "      - -211771.06055748707\n",
      "      - -206168.1110745608\n",
      "      - -203596.88203936748\n",
      "      - -210182.76702319665\n",
      "      - -200693.0550524108\n",
      "      - -202762.31483616008\n",
      "      - -200524.9881328157\n",
      "      - -201794.25407028588\n",
      "      - -212836.3049371829\n",
      "      - -201330.4824828726\n",
      "      - -205406.17565125448\n",
      "      - -204977.27702397248\n",
      "      - -203500.38542989417\n",
      "      - -204708.5898972014\n",
      "      - -202010.6538917411\n",
      "      - -212536.3876186898\n",
      "      - -208328.04612183527\n",
      "      - -205309.5408377173\n",
      "      - -201091.5357655767\n",
      "      - -204908.7032429626\n",
      "      - -204288.1473142777\n",
      "      - -203014.80127205985\n",
      "      - -198564.48911498697\n",
      "      - -200121.45495088154\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11724140447916119\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5117929050689095\n",
      "      mean_inference_ms: 1.5842699046416036\n",
      "      mean_raw_obs_processing_ms: 0.1620373269415486\n",
      "  time_since_restore: 1073.9541606903076\n",
      "  time_this_iter_s: 15.259835958480835\n",
      "  time_total_s: 1073.9541606903076\n",
      "  timers:\n",
      "    learn_throughput: 24646.042\n",
      "    learn_time_ms: 2596.117\n",
      "    load_throughput: 532961.832\n",
      "    load_time_ms: 120.054\n",
      "    training_iteration_time_ms: 15393.472\n",
      "    update_time_ms: 4.366\n",
      "  timestamp: 1665743289\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4414896\n",
      "  training_iteration: 69\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:28:15 (running for 00:18:17.29)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    69</td><td style=\"text-align: right;\">         1073.95</td><td style=\"text-align: right;\">4.4149e+06</td><td style=\"text-align: right;\"> -204276</td><td style=\"text-align: right;\">             -198139</td><td style=\"text-align: right;\">             -213687</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:28:20 (running for 00:18:22.30)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    69</td><td style=\"text-align: right;\">         1073.95</td><td style=\"text-align: right;\">4.4149e+06</td><td style=\"text-align: right;\"> -204276</td><td style=\"text-align: right;\">             -198139</td><td style=\"text-align: right;\">             -213687</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:28:25 (running for 00:18:27.30)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    69</td><td style=\"text-align: right;\">         1073.95</td><td style=\"text-align: right;\">4.4149e+06</td><td style=\"text-align: right;\"> -204276</td><td style=\"text-align: right;\">             -198139</td><td style=\"text-align: right;\">             -213687</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 4478880\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 4478880\n",
      "    num_agent_steps_trained: 4478880\n",
      "    num_env_steps_sampled: 4478880\n",
      "    num_env_steps_trained: 4478880\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-28-25\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -197926.93057874523\n",
      "  episode_reward_mean: -203912.76286958612\n",
      "  episode_reward_min: -214524.4927342088\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 4476\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.050753116607666\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.001667803735472262\n",
      "          model: {}\n",
      "          policy_loss: 0.002219259738922119\n",
      "          total_loss: 10.00224781036377\n",
      "          vf_explained_var: -9.940221161741647e-07\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 4478880\n",
      "    num_agent_steps_trained: 4478880\n",
      "    num_env_steps_sampled: 4478880\n",
      "    num_env_steps_trained: 4478880\n",
      "  iterations_since_restore: 70\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 4478880\n",
      "  num_agent_steps_trained: 4478880\n",
      "  num_env_steps_sampled: 4478880\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 4478880\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.53181818181818\n",
      "    ram_util_percent: 78.72272727272728\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11742365842259259\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5118087526331843\n",
      "    mean_inference_ms: 1.5853482157438383\n",
      "    mean_raw_obs_processing_ms: 0.16203625697865845\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -197926.93057874523\n",
      "    episode_reward_mean: -203912.76286958612\n",
      "    episode_reward_min: -214524.4927342088\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -200706.08998549075\n",
      "      - -202183.37411663184\n",
      "      - -202362.04387104735\n",
      "      - -199256.60449115504\n",
      "      - -211771.06055748707\n",
      "      - -206168.1110745608\n",
      "      - -203596.88203936748\n",
      "      - -210182.76702319665\n",
      "      - -200693.0550524108\n",
      "      - -202762.31483616008\n",
      "      - -200524.9881328157\n",
      "      - -201794.25407028588\n",
      "      - -212836.3049371829\n",
      "      - -201330.4824828726\n",
      "      - -205406.17565125448\n",
      "      - -204977.27702397248\n",
      "      - -203500.38542989417\n",
      "      - -204708.5898972014\n",
      "      - -202010.6538917411\n",
      "      - -212536.3876186898\n",
      "      - -208328.04612183527\n",
      "      - -205309.5408377173\n",
      "      - -201091.5357655767\n",
      "      - -204908.7032429626\n",
      "      - -204288.1473142777\n",
      "      - -203014.80127205985\n",
      "      - -198564.48911498697\n",
      "      - -200121.45495088154\n",
      "      - -206131.90693028367\n",
      "      - -202968.348611103\n",
      "      - -212058.42719963318\n",
      "      - -206260.37727344752\n",
      "      - -207935.5497340685\n",
      "      - -201254.4875734534\n",
      "      - -206382.32171727833\n",
      "      - -201696.1223073831\n",
      "      - -199680.0125506746\n",
      "      - -198723.30410543777\n",
      "      - -204363.92647864766\n",
      "      - -203022.91588993644\n",
      "      - -209610.25190253544\n",
      "      - -200046.61016111364\n",
      "      - -207535.48671704094\n",
      "      - -205412.13027887704\n",
      "      - -204334.52193623479\n",
      "      - -207777.68585771444\n",
      "      - -205170.68996051812\n",
      "      - -200994.10010813427\n",
      "      - -198408.2659210929\n",
      "      - -204116.5833321293\n",
      "      - -209867.1326738551\n",
      "      - -200952.56186199086\n",
      "      - -203857.92782254706\n",
      "      - -203772.46809362996\n",
      "      - -204093.79447613683\n",
      "      - -197926.93057874523\n",
      "      - -200138.17158537087\n",
      "      - -204774.4325998382\n",
      "      - -202838.3030004145\n",
      "      - -198337.95132424746\n",
      "      - -203141.15951884302\n",
      "      - -204159.52683721684\n",
      "      - -203469.25002923358\n",
      "      - -201866.53169918852\n",
      "      - -214524.4927342088\n",
      "      - -199804.01342523302\n",
      "      - -203393.26813225125\n",
      "      - -200829.73143202998\n",
      "      - -207954.30849629352\n",
      "      - -201416.40350484432\n",
      "      - -210981.61082053074\n",
      "      - -199937.09860248124\n",
      "      - -204120.20753597593\n",
      "      - -202255.57096414317\n",
      "      - -213918.3301991955\n",
      "      - -204753.90840976225\n",
      "      - -201203.2963787106\n",
      "      - -203759.5325378524\n",
      "      - -201983.0705938024\n",
      "      - -202396.66814582387\n",
      "      - -200445.27452276027\n",
      "      - -203602.6030490585\n",
      "      - -207024.65551683414\n",
      "      - -209217.0276440441\n",
      "      - -202239.28945479606\n",
      "      - -205213.53309727102\n",
      "      - -203040.07233963083\n",
      "      - -204187.31651877513\n",
      "      - -203744.72762322542\n",
      "      - -200179.28546546068\n",
      "      - -203085.42940030675\n",
      "      - -200349.49782475195\n",
      "      - -199467.71376776343\n",
      "      - -201425.16143579388\n",
      "      - -205461.7663832075\n",
      "      - -205922.79979661232\n",
      "      - -202948.96142615072\n",
      "      - -200273.60347743888\n",
      "      - -211508.6850723006\n",
      "      - -200692.6817775849\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11742365842259259\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5118087526331843\n",
      "      mean_inference_ms: 1.5853482157438383\n",
      "      mean_raw_obs_processing_ms: 0.16203625697865845\n",
      "  time_since_restore: 1089.525276184082\n",
      "  time_this_iter_s: 15.571115493774414\n",
      "  time_total_s: 1089.525276184082\n",
      "  timers:\n",
      "    learn_throughput: 24548.28\n",
      "    learn_time_ms: 2606.456\n",
      "    load_throughput: 532962.044\n",
      "    load_time_ms: 120.054\n",
      "    training_iteration_time_ms: 15397.651\n",
      "    update_time_ms: 4.364\n",
      "  timestamp: 1665743305\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4478880\n",
      "  training_iteration: 70\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:28:30 (running for 00:18:33.02)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    70</td><td style=\"text-align: right;\">         1089.53</td><td style=\"text-align: right;\">4.47888e+06</td><td style=\"text-align: right;\"> -203913</td><td style=\"text-align: right;\">             -197927</td><td style=\"text-align: right;\">             -214524</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:28:35 (running for 00:18:38.11)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    70</td><td style=\"text-align: right;\">         1089.53</td><td style=\"text-align: right;\">4.47888e+06</td><td style=\"text-align: right;\"> -203913</td><td style=\"text-align: right;\">             -197927</td><td style=\"text-align: right;\">             -214524</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:28:41 (running for 00:18:43.43)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    70</td><td style=\"text-align: right;\">         1089.53</td><td style=\"text-align: right;\">4.47888e+06</td><td style=\"text-align: right;\"> -203913</td><td style=\"text-align: right;\">             -197927</td><td style=\"text-align: right;\">             -214524</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 4542864\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 4542864\n",
      "    num_agent_steps_trained: 4542864\n",
      "    num_env_steps_sampled: 4542864\n",
      "    num_env_steps_trained: 4542864\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-28-41\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -198688.24192980622\n",
      "  episode_reward_mean: -203448.04673760623\n",
      "  episode_reward_min: -214524.4927342088\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 4536\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.045938730239868\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0019442883785814047\n",
      "          model: {}\n",
      "          policy_loss: 0.004992700647562742\n",
      "          total_loss: 10.005077362060547\n",
      "          vf_explained_var: -1.1118559086753521e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 4542864\n",
      "    num_agent_steps_trained: 4542864\n",
      "    num_env_steps_sampled: 4542864\n",
      "    num_env_steps_trained: 4542864\n",
      "  iterations_since_restore: 71\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 4542864\n",
      "  num_agent_steps_trained: 4542864\n",
      "  num_env_steps_sampled: 4542864\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 4542864\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.52727272727273\n",
      "    ram_util_percent: 78.70000000000002\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1172728030342234\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.511769239075209\n",
      "    mean_inference_ms: 1.5854885691589982\n",
      "    mean_raw_obs_processing_ms: 0.1622184500806343\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -198688.24192980622\n",
      "    episode_reward_mean: -203448.04673760623\n",
      "    episode_reward_min: -214524.4927342088\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -203141.15951884302\n",
      "      - -204159.52683721684\n",
      "      - -203469.25002923358\n",
      "      - -201866.53169918852\n",
      "      - -214524.4927342088\n",
      "      - -199804.01342523302\n",
      "      - -203393.26813225125\n",
      "      - -200829.73143202998\n",
      "      - -207954.30849629352\n",
      "      - -201416.40350484432\n",
      "      - -210981.61082053074\n",
      "      - -199937.09860248124\n",
      "      - -204120.20753597593\n",
      "      - -202255.57096414317\n",
      "      - -213918.3301991955\n",
      "      - -204753.90840976225\n",
      "      - -201203.2963787106\n",
      "      - -203759.5325378524\n",
      "      - -201983.0705938024\n",
      "      - -202396.66814582387\n",
      "      - -200445.27452276027\n",
      "      - -203602.6030490585\n",
      "      - -207024.65551683414\n",
      "      - -209217.0276440441\n",
      "      - -202239.28945479606\n",
      "      - -205213.53309727102\n",
      "      - -203040.07233963083\n",
      "      - -204187.31651877513\n",
      "      - -203744.72762322542\n",
      "      - -200179.28546546068\n",
      "      - -203085.42940030675\n",
      "      - -200349.49782475195\n",
      "      - -199467.71376776343\n",
      "      - -201425.16143579388\n",
      "      - -205461.7663832075\n",
      "      - -205922.79979661232\n",
      "      - -202948.96142615072\n",
      "      - -200273.60347743888\n",
      "      - -211508.6850723006\n",
      "      - -200692.6817775849\n",
      "      - -207783.05439291606\n",
      "      - -199307.49557199806\n",
      "      - -206007.16391451194\n",
      "      - -202524.7936737016\n",
      "      - -203619.518509761\n",
      "      - -202500.10665223596\n",
      "      - -201260.58324292355\n",
      "      - -209091.0216883073\n",
      "      - -204105.2549702912\n",
      "      - -201923.02863147343\n",
      "      - -203072.76143566807\n",
      "      - -201051.45318059466\n",
      "      - -199767.69245958512\n",
      "      - -208126.83392816014\n",
      "      - -207566.86120931202\n",
      "      - -199290.04036470357\n",
      "      - -198985.1356901254\n",
      "      - -204819.48581871323\n",
      "      - -205062.9672753843\n",
      "      - -203322.12558131636\n",
      "      - -200368.93278625316\n",
      "      - -199661.8711454501\n",
      "      - -199386.03877895806\n",
      "      - -207804.6625563535\n",
      "      - -202014.41778117232\n",
      "      - -205102.6904927005\n",
      "      - -209476.8665079978\n",
      "      - -202632.1376998873\n",
      "      - -202015.59719975104\n",
      "      - -204962.92500893766\n",
      "      - -199635.6738192267\n",
      "      - -200940.2027975621\n",
      "      - -202701.84426145154\n",
      "      - -199633.5670333349\n",
      "      - -206995.89621263617\n",
      "      - -206738.42780911148\n",
      "      - -204346.58593793126\n",
      "      - -201680.73261692238\n",
      "      - -199156.71213888124\n",
      "      - -204263.20643690028\n",
      "      - -201754.61956794208\n",
      "      - -205678.0932550712\n",
      "      - -199844.8391771002\n",
      "      - -203569.27868366745\n",
      "      - -204558.33289114296\n",
      "      - -201092.27157618542\n",
      "      - -201547.17726775497\n",
      "      - -203153.11773179146\n",
      "      - -198847.3114666303\n",
      "      - -211894.0162025564\n",
      "      - -202124.66269973616\n",
      "      - -203484.77461889404\n",
      "      - -206361.5212826689\n",
      "      - -206498.6194609226\n",
      "      - -198688.24192980622\n",
      "      - -206021.84670870117\n",
      "      - -202265.91234541117\n",
      "      - -202483.90334720304\n",
      "      - -200908.8930169528\n",
      "      - -199422.80772600026\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1172728030342234\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.511769239075209\n",
      "      mean_inference_ms: 1.5854885691589982\n",
      "      mean_raw_obs_processing_ms: 0.1622184500806343\n",
      "  time_since_restore: 1105.298701286316\n",
      "  time_this_iter_s: 15.773425102233887\n",
      "  time_total_s: 1105.298701286316\n",
      "  timers:\n",
      "    learn_throughput: 24983.312\n",
      "    learn_time_ms: 2561.07\n",
      "    load_throughput: 535036.989\n",
      "    load_time_ms: 119.588\n",
      "    training_iteration_time_ms: 15437.097\n",
      "    update_time_ms: 4.516\n",
      "  timestamp: 1665743321\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4542864\n",
      "  training_iteration: 71\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:28:47 (running for 00:18:49.28)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    71</td><td style=\"text-align: right;\">          1105.3</td><td style=\"text-align: right;\">4.54286e+06</td><td style=\"text-align: right;\"> -203448</td><td style=\"text-align: right;\">             -198688</td><td style=\"text-align: right;\">             -214524</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:28:52 (running for 00:18:54.28)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    71</td><td style=\"text-align: right;\">          1105.3</td><td style=\"text-align: right;\">4.54286e+06</td><td style=\"text-align: right;\"> -203448</td><td style=\"text-align: right;\">             -198688</td><td style=\"text-align: right;\">             -214524</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:28:57 (running for 00:18:59.29)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    71</td><td style=\"text-align: right;\">          1105.3</td><td style=\"text-align: right;\">4.54286e+06</td><td style=\"text-align: right;\"> -203448</td><td style=\"text-align: right;\">             -198688</td><td style=\"text-align: right;\">             -214524</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 4606848\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 4606848\n",
      "    num_agent_steps_trained: 4606848\n",
      "    num_env_steps_sampled: 4606848\n",
      "    num_env_steps_trained: 4606848\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-28-57\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -197896.68152869362\n",
      "  episode_reward_mean: -203348.4422838128\n",
      "  episode_reward_min: -218315.8232404109\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 4596\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0451269149780273\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0019354162504896522\n",
      "          model: {}\n",
      "          policy_loss: 0.001067624893039465\n",
      "          total_loss: 10.001150131225586\n",
      "          vf_explained_var: -5.048054845246952e-07\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 4606848\n",
      "    num_agent_steps_trained: 4606848\n",
      "    num_env_steps_sampled: 4606848\n",
      "    num_env_steps_trained: 4606848\n",
      "  iterations_since_restore: 72\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 4606848\n",
      "  num_agent_steps_trained: 4606848\n",
      "  num_env_steps_sampled: 4606848\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 4606848\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.29545454545453\n",
      "    ram_util_percent: 78.70000000000002\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11718214200075623\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5114818028996588\n",
      "    mean_inference_ms: 1.5861859665580997\n",
      "    mean_raw_obs_processing_ms: 0.16195783979474715\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -197896.68152869362\n",
      "    episode_reward_mean: -203348.4422838128\n",
      "    episode_reward_min: -218315.8232404109\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -200368.93278625316\n",
      "      - -199661.8711454501\n",
      "      - -199386.03877895806\n",
      "      - -207804.6625563535\n",
      "      - -202014.41778117232\n",
      "      - -205102.6904927005\n",
      "      - -209476.8665079978\n",
      "      - -202632.1376998873\n",
      "      - -202015.59719975104\n",
      "      - -204962.92500893766\n",
      "      - -199635.6738192267\n",
      "      - -200940.2027975621\n",
      "      - -202701.84426145154\n",
      "      - -199633.5670333349\n",
      "      - -206995.89621263617\n",
      "      - -206738.42780911148\n",
      "      - -204346.58593793126\n",
      "      - -201680.73261692238\n",
      "      - -199156.71213888124\n",
      "      - -204263.20643690028\n",
      "      - -201754.61956794208\n",
      "      - -205678.0932550712\n",
      "      - -199844.8391771002\n",
      "      - -203569.27868366745\n",
      "      - -204558.33289114296\n",
      "      - -201092.27157618542\n",
      "      - -201547.17726775497\n",
      "      - -203153.11773179146\n",
      "      - -198847.3114666303\n",
      "      - -211894.0162025564\n",
      "      - -202124.66269973616\n",
      "      - -203484.77461889404\n",
      "      - -206361.5212826689\n",
      "      - -206498.6194609226\n",
      "      - -198688.24192980622\n",
      "      - -206021.84670870117\n",
      "      - -202265.91234541117\n",
      "      - -202483.90334720304\n",
      "      - -200908.8930169528\n",
      "      - -199422.80772600026\n",
      "      - -199380.45483380673\n",
      "      - -201894.3018697081\n",
      "      - -203476.253088392\n",
      "      - -203153.80825894212\n",
      "      - -200714.15094484924\n",
      "      - -200270.64220659906\n",
      "      - -204621.44777552554\n",
      "      - -206610.20826188335\n",
      "      - -218315.8232404109\n",
      "      - -200491.32315088582\n",
      "      - -205382.23936405868\n",
      "      - -203528.86716107224\n",
      "      - -204395.62833279182\n",
      "      - -202152.27302800101\n",
      "      - -202352.92667351087\n",
      "      - -206274.85422012236\n",
      "      - -205411.9501208312\n",
      "      - -200564.49384161105\n",
      "      - -207440.3195157268\n",
      "      - -207063.63703462103\n",
      "      - -203622.99994713406\n",
      "      - -203157.8071617469\n",
      "      - -203856.76645769086\n",
      "      - -200817.16702056176\n",
      "      - -204616.39591530908\n",
      "      - -205836.7218907125\n",
      "      - -207142.8509957268\n",
      "      - -207204.9077774035\n",
      "      - -204299.72219943468\n",
      "      - -202380.64377487902\n",
      "      - -202719.83516849132\n",
      "      - -203951.70223471252\n",
      "      - -207405.10112838584\n",
      "      - -199682.11984786965\n",
      "      - -205626.23001551357\n",
      "      - -206426.0336523927\n",
      "      - -201356.2971970516\n",
      "      - -197896.68152869362\n",
      "      - -204390.43705892522\n",
      "      - -211996.3129488017\n",
      "      - -198234.67678161315\n",
      "      - -201246.23904167925\n",
      "      - -204102.70745427665\n",
      "      - -210421.03071938714\n",
      "      - -202750.2619776224\n",
      "      - -204626.7267679556\n",
      "      - -200103.44149850507\n",
      "      - -204139.4477253423\n",
      "      - -200803.3202941834\n",
      "      - -201870.88587617467\n",
      "      - -204859.17299779056\n",
      "      - -205808.8848592535\n",
      "      - -201437.25901769818\n",
      "      - -199687.49631744856\n",
      "      - -201772.15915186875\n",
      "      - -199750.26443618513\n",
      "      - -202566.14373030842\n",
      "      - -199284.9721351462\n",
      "      - -202407.5486491803\n",
      "      - -201370.0221273144\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11718214200075623\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5114818028996588\n",
      "      mean_inference_ms: 1.5861859665580997\n",
      "      mean_raw_obs_processing_ms: 0.16195783979474715\n",
      "  time_since_restore: 1121.209564447403\n",
      "  time_this_iter_s: 15.910863161087036\n",
      "  time_total_s: 1121.209564447403\n",
      "  timers:\n",
      "    learn_throughput: 24528.624\n",
      "    learn_time_ms: 2608.544\n",
      "    load_throughput: 530866.479\n",
      "    load_time_ms: 120.527\n",
      "    training_iteration_time_ms: 15527.533\n",
      "    update_time_ms: 4.537\n",
      "  timestamp: 1665743337\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4606848\n",
      "  training_iteration: 72\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:29:02 (running for 00:19:04.55)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    72</td><td style=\"text-align: right;\">         1121.21</td><td style=\"text-align: right;\">4.60685e+06</td><td style=\"text-align: right;\"> -203348</td><td style=\"text-align: right;\">             -197897</td><td style=\"text-align: right;\">             -218316</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:29:07 (running for 00:19:09.65)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    72</td><td style=\"text-align: right;\">         1121.21</td><td style=\"text-align: right;\">4.60685e+06</td><td style=\"text-align: right;\"> -203348</td><td style=\"text-align: right;\">             -197897</td><td style=\"text-align: right;\">             -218316</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:29:12 (running for 00:19:14.66)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    72</td><td style=\"text-align: right;\">         1121.21</td><td style=\"text-align: right;\">4.60685e+06</td><td style=\"text-align: right;\"> -203348</td><td style=\"text-align: right;\">             -197897</td><td style=\"text-align: right;\">             -218316</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 4670832\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 4670832\n",
      "    num_agent_steps_trained: 4670832\n",
      "    num_env_steps_sampled: 4670832\n",
      "    num_env_steps_trained: 4670832\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-29-12\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -196313.45008928442\n",
      "  episode_reward_mean: -203218.1880100631\n",
      "  episode_reward_min: -213828.99293795438\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 4668\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.051132917404175\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0020879467483609915\n",
      "          model: {}\n",
      "          policy_loss: 0.006989163812249899\n",
      "          total_loss: 10.007102012634277\n",
      "          vf_explained_var: -2.1622731765091885e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 4670832\n",
      "    num_agent_steps_trained: 4670832\n",
      "    num_env_steps_sampled: 4670832\n",
      "    num_env_steps_trained: 4670832\n",
      "  iterations_since_restore: 73\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 4670832\n",
      "  num_agent_steps_trained: 4670832\n",
      "  num_env_steps_sampled: 4670832\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 4670832\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.15238095238095\n",
      "    ram_util_percent: 78.70000000000002\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1173036956032436\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5114472727195936\n",
      "    mean_inference_ms: 1.5874826800234216\n",
      "    mean_raw_obs_processing_ms: 0.16188728875924266\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -196313.45008928442\n",
      "    episode_reward_mean: -203218.1880100631\n",
      "    episode_reward_min: -213828.99293795438\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -207405.10112838584\n",
      "      - -199682.11984786965\n",
      "      - -205626.23001551357\n",
      "      - -206426.0336523927\n",
      "      - -201356.2971970516\n",
      "      - -197896.68152869362\n",
      "      - -204390.43705892522\n",
      "      - -211996.3129488017\n",
      "      - -198234.67678161315\n",
      "      - -201246.23904167925\n",
      "      - -204102.70745427665\n",
      "      - -210421.03071938714\n",
      "      - -202750.2619776224\n",
      "      - -204626.7267679556\n",
      "      - -200103.44149850507\n",
      "      - -204139.4477253423\n",
      "      - -200803.3202941834\n",
      "      - -201870.88587617467\n",
      "      - -204859.17299779056\n",
      "      - -205808.8848592535\n",
      "      - -201437.25901769818\n",
      "      - -199687.49631744856\n",
      "      - -201772.15915186875\n",
      "      - -199750.26443618513\n",
      "      - -202566.14373030842\n",
      "      - -199284.9721351462\n",
      "      - -202407.5486491803\n",
      "      - -201370.0221273144\n",
      "      - -203522.5653026556\n",
      "      - -202705.22349773353\n",
      "      - -199353.21935151098\n",
      "      - -202167.86617245202\n",
      "      - -200741.30077792317\n",
      "      - -213828.99293795438\n",
      "      - -198608.8304921543\n",
      "      - -200710.67074980258\n",
      "      - -203243.66738280773\n",
      "      - -204816.8105799625\n",
      "      - -202297.2989430331\n",
      "      - -206969.34107291445\n",
      "      - -201812.20056114017\n",
      "      - -207170.51078862313\n",
      "      - -201823.43222535672\n",
      "      - -211472.64065164435\n",
      "      - -203057.13921872646\n",
      "      - -207886.79479931033\n",
      "      - -204716.56177631754\n",
      "      - -201402.6859174878\n",
      "      - -203213.47400358453\n",
      "      - -199270.7572354371\n",
      "      - -202329.7903677164\n",
      "      - -201468.8434566718\n",
      "      - -204223.149888911\n",
      "      - -198014.6139019375\n",
      "      - -204058.94482337649\n",
      "      - -201572.15965011416\n",
      "      - -207085.4140766459\n",
      "      - -201419.47940841704\n",
      "      - -208713.69310793674\n",
      "      - -208134.48371774875\n",
      "      - -199642.6243923067\n",
      "      - -203125.96141964037\n",
      "      - -203865.41894242\n",
      "      - -213637.92608297043\n",
      "      - -205280.05311855025\n",
      "      - -202523.2538704751\n",
      "      - -201237.00604924368\n",
      "      - -205266.9616281454\n",
      "      - -205043.7997313949\n",
      "      - -202484.29394054937\n",
      "      - -203094.32401676002\n",
      "      - -201586.3562784861\n",
      "      - -202598.21026813795\n",
      "      - -203220.5002510289\n",
      "      - -204933.84861801288\n",
      "      - -204493.58378007665\n",
      "      - -203659.1376686927\n",
      "      - -201054.31276714252\n",
      "      - -203679.86058318624\n",
      "      - -205028.96536337075\n",
      "      - -201072.2151743605\n",
      "      - -205236.0609348664\n",
      "      - -200867.01280740259\n",
      "      - -201425.57004909703\n",
      "      - -204518.22523656065\n",
      "      - -200854.64027545886\n",
      "      - -201209.63943676997\n",
      "      - -199871.9359194169\n",
      "      - -198119.3668460922\n",
      "      - -202052.00289389043\n",
      "      - -208030.50709999754\n",
      "      - -205072.9612854045\n",
      "      - -201488.73917782403\n",
      "      - -203376.84516371938\n",
      "      - -203369.81637103186\n",
      "      - -199043.55491358787\n",
      "      - -203505.3593992796\n",
      "      - -196313.45008928442\n",
      "      - -207451.2809673703\n",
      "      - -203648.7864197268\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1173036956032436\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5114472727195936\n",
      "      mean_inference_ms: 1.5874826800234216\n",
      "      mean_raw_obs_processing_ms: 0.16188728875924266\n",
      "  time_since_restore: 1136.5801701545715\n",
      "  time_this_iter_s: 15.370605707168579\n",
      "  time_total_s: 1136.5801701545715\n",
      "  timers:\n",
      "    learn_throughput: 24875.31\n",
      "    learn_time_ms: 2572.189\n",
      "    load_throughput: 533219.896\n",
      "    load_time_ms: 119.996\n",
      "    training_iteration_time_ms: 15545.113\n",
      "    update_time_ms: 4.511\n",
      "  timestamp: 1665743352\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4670832\n",
      "  training_iteration: 73\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:29:18 (running for 00:19:20.47)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    73</td><td style=\"text-align: right;\">         1136.58</td><td style=\"text-align: right;\">4.67083e+06</td><td style=\"text-align: right;\"> -203218</td><td style=\"text-align: right;\">             -196313</td><td style=\"text-align: right;\">             -213829</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:29:23 (running for 00:19:25.47)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    73</td><td style=\"text-align: right;\">         1136.58</td><td style=\"text-align: right;\">4.67083e+06</td><td style=\"text-align: right;\"> -203218</td><td style=\"text-align: right;\">             -196313</td><td style=\"text-align: right;\">             -213829</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 4734816\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 4734816\n",
      "    num_agent_steps_trained: 4734816\n",
      "    num_env_steps_sampled: 4734816\n",
      "    num_env_steps_trained: 4734816\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-29-28\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -196313.45008928442\n",
      "  episode_reward_mean: -204342.92212778374\n",
      "  episode_reward_min: -282814.3090520009\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 4728\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.046569347381592\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0024900096468627453\n",
      "          model: {}\n",
      "          policy_loss: 0.0009922027820721269\n",
      "          total_loss: 10.001185417175293\n",
      "          vf_explained_var: -3.2186508747145126e-07\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 4734816\n",
      "    num_agent_steps_trained: 4734816\n",
      "    num_env_steps_sampled: 4734816\n",
      "    num_env_steps_trained: 4734816\n",
      "  iterations_since_restore: 74\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 4734816\n",
      "  num_agent_steps_trained: 4734816\n",
      "  num_env_steps_sampled: 4734816\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 4734816\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.8090909090909\n",
      "    ram_util_percent: 78.71363636363638\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11715776188525134\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5114032380357407\n",
      "    mean_inference_ms: 1.586435279029782\n",
      "    mean_raw_obs_processing_ms: 0.16207015482895176\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -196313.45008928442\n",
      "    episode_reward_mean: -204342.92212778374\n",
      "    episode_reward_min: -282814.3090520009\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -199642.6243923067\n",
      "      - -203125.96141964037\n",
      "      - -203865.41894242\n",
      "      - -213637.92608297043\n",
      "      - -205280.05311855025\n",
      "      - -202523.2538704751\n",
      "      - -201237.00604924368\n",
      "      - -205266.9616281454\n",
      "      - -205043.7997313949\n",
      "      - -202484.29394054937\n",
      "      - -203094.32401676002\n",
      "      - -201586.3562784861\n",
      "      - -202598.21026813795\n",
      "      - -203220.5002510289\n",
      "      - -204933.84861801288\n",
      "      - -204493.58378007665\n",
      "      - -203659.1376686927\n",
      "      - -201054.31276714252\n",
      "      - -203679.86058318624\n",
      "      - -205028.96536337075\n",
      "      - -201072.2151743605\n",
      "      - -205236.0609348664\n",
      "      - -200867.01280740259\n",
      "      - -201425.57004909703\n",
      "      - -204518.22523656065\n",
      "      - -200854.64027545886\n",
      "      - -201209.63943676997\n",
      "      - -199871.9359194169\n",
      "      - -198119.3668460922\n",
      "      - -202052.00289389043\n",
      "      - -208030.50709999754\n",
      "      - -205072.9612854045\n",
      "      - -201488.73917782403\n",
      "      - -203376.84516371938\n",
      "      - -203369.81637103186\n",
      "      - -199043.55491358787\n",
      "      - -203505.3593992796\n",
      "      - -196313.45008928442\n",
      "      - -207451.2809673703\n",
      "      - -203648.7864197268\n",
      "      - -207512.82984029056\n",
      "      - -239369.9062213497\n",
      "      - -201943.50358188257\n",
      "      - -205679.4946693154\n",
      "      - -199423.98895407564\n",
      "      - -203761.63718153312\n",
      "      - -209245.8869134823\n",
      "      - -205142.56287554113\n",
      "      - -205786.97058906266\n",
      "      - -200327.85005971507\n",
      "      - -203211.44097173342\n",
      "      - -200373.05393706114\n",
      "      - -199489.03267676567\n",
      "      - -207630.29642264926\n",
      "      - -206616.08330379476\n",
      "      - -200538.05769809903\n",
      "      - -200902.52766237382\n",
      "      - -197348.58934029948\n",
      "      - -198071.5043335518\n",
      "      - -209908.98948519022\n",
      "      - -201283.9268264203\n",
      "      - -198775.3114942173\n",
      "      - -200239.62516099983\n",
      "      - -201698.49902849467\n",
      "      - -201758.40713280375\n",
      "      - -205551.26548715096\n",
      "      - -201481.23652346208\n",
      "      - -203847.1708595862\n",
      "      - -203385.50077792487\n",
      "      - -204362.35254790695\n",
      "      - -203849.78037400835\n",
      "      - -198824.75978274955\n",
      "      - -204411.9018401676\n",
      "      - -197430.25571518549\n",
      "      - -208300.42541677988\n",
      "      - -205342.2107759377\n",
      "      - -204498.06607127946\n",
      "      - -208064.76128924877\n",
      "      - -201898.0433994033\n",
      "      - -202651.1869774395\n",
      "      - -211255.6948653851\n",
      "      - -203934.55197200616\n",
      "      - -204222.12409861287\n",
      "      - -201887.21624571498\n",
      "      - -282814.3090520009\n",
      "      - -203968.77061656996\n",
      "      - -203400.01314966808\n",
      "      - -201246.81213632436\n",
      "      - -201442.17432176557\n",
      "      - -205348.17959296997\n",
      "      - -200023.48547970402\n",
      "      - -204823.17836257815\n",
      "      - -205050.7274308348\n",
      "      - -205852.5702271222\n",
      "      - -204486.1595687601\n",
      "      - -202512.2311355197\n",
      "      - -203510.76147543173\n",
      "      - -201800.24781587865\n",
      "      - -203005.55724196174\n",
      "      - -201784.18455890255\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11715776188525134\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5114032380357407\n",
      "      mean_inference_ms: 1.586435279029782\n",
      "      mean_raw_obs_processing_ms: 0.16207015482895176\n",
      "  time_since_restore: 1152.0478830337524\n",
      "  time_this_iter_s: 15.467712879180908\n",
      "  time_total_s: 1152.0478830337524\n",
      "  timers:\n",
      "    learn_throughput: 24507.902\n",
      "    learn_time_ms: 2610.75\n",
      "    load_throughput: 533996.969\n",
      "    load_time_ms: 119.821\n",
      "    training_iteration_time_ms: 15576.432\n",
      "    update_time_ms: 4.556\n",
      "  timestamp: 1665743368\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4734816\n",
      "  training_iteration: 74\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:29:33 (running for 00:19:35.54)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    74</td><td style=\"text-align: right;\">         1152.05</td><td style=\"text-align: right;\">4.73482e+06</td><td style=\"text-align: right;\"> -204343</td><td style=\"text-align: right;\">             -196313</td><td style=\"text-align: right;\">             -282814</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:29:38 (running for 00:19:40.88)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    74</td><td style=\"text-align: right;\">         1152.05</td><td style=\"text-align: right;\">4.73482e+06</td><td style=\"text-align: right;\"> -204343</td><td style=\"text-align: right;\">             -196313</td><td style=\"text-align: right;\">             -282814</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 4798800\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 4798800\n",
      "    num_agent_steps_trained: 4798800\n",
      "    num_env_steps_sampled: 4798800\n",
      "    num_env_steps_trained: 4798800\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-29-43\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -197430.25571518549\n",
      "  episode_reward_mean: -204027.2744258288\n",
      "  episode_reward_min: -282814.3090520009\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 4788\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0412936210632324\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.002029765397310257\n",
      "          model: {}\n",
      "          policy_loss: 6.987573578953743e-05\n",
      "          total_loss: 10.000170707702637\n",
      "          vf_explained_var: -2.149958163499832e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 4798800\n",
      "    num_agent_steps_trained: 4798800\n",
      "    num_env_steps_sampled: 4798800\n",
      "    num_env_steps_trained: 4798800\n",
      "  iterations_since_restore: 75\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 4798800\n",
      "  num_agent_steps_trained: 4798800\n",
      "  num_env_steps_sampled: 4798800\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 4798800\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.66190476190478\n",
      "    ram_util_percent: 78.70000000000002\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11706569610334717\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5111958990909612\n",
      "    mean_inference_ms: 1.5853700659686707\n",
      "    mean_raw_obs_processing_ms: 0.1618169760983785\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -197430.25571518549\n",
      "    episode_reward_mean: -204027.2744258288\n",
      "    episode_reward_min: -282814.3090520009\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -201283.9268264203\n",
      "      - -198775.3114942173\n",
      "      - -200239.62516099983\n",
      "      - -201698.49902849467\n",
      "      - -201758.40713280375\n",
      "      - -205551.26548715096\n",
      "      - -201481.23652346208\n",
      "      - -203847.1708595862\n",
      "      - -203385.50077792487\n",
      "      - -204362.35254790695\n",
      "      - -203849.78037400835\n",
      "      - -198824.75978274955\n",
      "      - -204411.9018401676\n",
      "      - -197430.25571518549\n",
      "      - -208300.42541677988\n",
      "      - -205342.2107759377\n",
      "      - -204498.06607127946\n",
      "      - -208064.76128924877\n",
      "      - -201898.0433994033\n",
      "      - -202651.1869774395\n",
      "      - -211255.6948653851\n",
      "      - -203934.55197200616\n",
      "      - -204222.12409861287\n",
      "      - -201887.21624571498\n",
      "      - -282814.3090520009\n",
      "      - -203968.77061656996\n",
      "      - -203400.01314966808\n",
      "      - -201246.81213632436\n",
      "      - -201442.17432176557\n",
      "      - -205348.17959296997\n",
      "      - -200023.48547970402\n",
      "      - -204823.17836257815\n",
      "      - -205050.7274308348\n",
      "      - -205852.5702271222\n",
      "      - -204486.1595687601\n",
      "      - -202512.2311355197\n",
      "      - -203510.76147543173\n",
      "      - -201800.24781587865\n",
      "      - -203005.55724196174\n",
      "      - -201784.18455890255\n",
      "      - -201056.34654681673\n",
      "      - -200233.91640318924\n",
      "      - -200066.47693189586\n",
      "      - -202614.29585868138\n",
      "      - -200752.04033790345\n",
      "      - -201728.81604041156\n",
      "      - -202305.0919751953\n",
      "      - -205751.9801862292\n",
      "      - -217635.40123506833\n",
      "      - -199634.69523255606\n",
      "      - -206007.35242876026\n",
      "      - -202010.8571083307\n",
      "      - -205829.71368046384\n",
      "      - -203816.83544090425\n",
      "      - -200364.74613993216\n",
      "      - -201625.31928011146\n",
      "      - -203282.21843572994\n",
      "      - -202633.95140736576\n",
      "      - -204606.26894086256\n",
      "      - -199698.48325864715\n",
      "      - -201325.96654461758\n",
      "      - -197617.08796660628\n",
      "      - -206217.98906310715\n",
      "      - -197522.43624428083\n",
      "      - -203359.1464703933\n",
      "      - -199290.48491228966\n",
      "      - -202495.8724044063\n",
      "      - -198780.97465274847\n",
      "      - -200385.37662647397\n",
      "      - -202815.55066215125\n",
      "      - -205433.2586568203\n",
      "      - -208389.95264881314\n",
      "      - -202122.855625187\n",
      "      - -202468.0609183055\n",
      "      - -210420.34702370348\n",
      "      - -204255.174003719\n",
      "      - -199261.26174778852\n",
      "      - -202889.09474896337\n",
      "      - -208232.43785421707\n",
      "      - -207147.8766566211\n",
      "      - -204330.06086071674\n",
      "      - -205669.54825587737\n",
      "      - -205476.4643707881\n",
      "      - -202599.2201760075\n",
      "      - -199897.4402058091\n",
      "      - -206332.77109554326\n",
      "      - -206270.10992519022\n",
      "      - -202941.63804191854\n",
      "      - -200256.12961289985\n",
      "      - -199460.24813688974\n",
      "      - -201327.97300603305\n",
      "      - -201922.5314512308\n",
      "      - -198111.1468006787\n",
      "      - -210914.30903287267\n",
      "      - -204971.60562848562\n",
      "      - -203693.43951917315\n",
      "      - -203565.22598051283\n",
      "      - -206750.54441373312\n",
      "      - -205252.13223363197\n",
      "      - -200875.25470573787\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11706569610334717\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5111958990909612\n",
      "      mean_inference_ms: 1.5853700659686707\n",
      "      mean_raw_obs_processing_ms: 0.1618169760983785\n",
      "  time_since_restore: 1166.925458431244\n",
      "  time_this_iter_s: 14.877575397491455\n",
      "  time_total_s: 1166.925458431244\n",
      "  timers:\n",
      "    learn_throughput: 25379.854\n",
      "    learn_time_ms: 2521.055\n",
      "    load_throughput: 533329.572\n",
      "    load_time_ms: 119.971\n",
      "    training_iteration_time_ms: 15490.695\n",
      "    update_time_ms: 4.464\n",
      "  timestamp: 1665743383\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4798800\n",
      "  training_iteration: 75\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:29:48 (running for 00:19:50.47)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    75</td><td style=\"text-align: right;\">         1166.93</td><td style=\"text-align: right;\">4.7988e+06</td><td style=\"text-align: right;\"> -204027</td><td style=\"text-align: right;\">             -197430</td><td style=\"text-align: right;\">             -282814</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:29:53 (running for 00:19:55.47)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    75</td><td style=\"text-align: right;\">         1166.93</td><td style=\"text-align: right;\">4.7988e+06</td><td style=\"text-align: right;\"> -204027</td><td style=\"text-align: right;\">             -197430</td><td style=\"text-align: right;\">             -282814</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:29:58 (running for 00:20:00.91)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    75</td><td style=\"text-align: right;\">         1166.93</td><td style=\"text-align: right;\">4.7988e+06</td><td style=\"text-align: right;\"> -204027</td><td style=\"text-align: right;\">             -197430</td><td style=\"text-align: right;\">             -282814</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 4862784\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 4862784\n",
      "    num_agent_steps_trained: 4862784\n",
      "    num_env_steps_sampled: 4862784\n",
      "    num_env_steps_trained: 4862784\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-29-58\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -196178.24050406768\n",
      "  episode_reward_mean: -204345.6093412924\n",
      "  episode_reward_min: -270032.6033101867\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 4860\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0453131198883057\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0022886618971824646\n",
      "          model: {}\n",
      "          policy_loss: 0.006944410502910614\n",
      "          total_loss: 10.007097244262695\n",
      "          vf_explained_var: -2.1737355382356327e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 4862784\n",
      "    num_agent_steps_trained: 4862784\n",
      "    num_env_steps_sampled: 4862784\n",
      "    num_env_steps_trained: 4862784\n",
      "  iterations_since_restore: 76\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 4862784\n",
      "  num_agent_steps_trained: 4862784\n",
      "  num_env_steps_sampled: 4862784\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 4862784\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.55454545454546\n",
      "    ram_util_percent: 78.70000000000002\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11718215247155203\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.511359230456504\n",
      "    mean_inference_ms: 1.5851747519348804\n",
      "    mean_raw_obs_processing_ms: 0.16173559186202394\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -196178.24050406768\n",
      "    episode_reward_mean: -204345.6093412924\n",
      "    episode_reward_min: -270032.6033101867\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -202122.855625187\n",
      "      - -202468.0609183055\n",
      "      - -210420.34702370348\n",
      "      - -204255.174003719\n",
      "      - -199261.26174778852\n",
      "      - -202889.09474896337\n",
      "      - -208232.43785421707\n",
      "      - -207147.8766566211\n",
      "      - -204330.06086071674\n",
      "      - -205669.54825587737\n",
      "      - -205476.4643707881\n",
      "      - -202599.2201760075\n",
      "      - -199897.4402058091\n",
      "      - -206332.77109554326\n",
      "      - -206270.10992519022\n",
      "      - -202941.63804191854\n",
      "      - -200256.12961289985\n",
      "      - -199460.24813688974\n",
      "      - -201327.97300603305\n",
      "      - -201922.5314512308\n",
      "      - -198111.1468006787\n",
      "      - -210914.30903287267\n",
      "      - -204971.60562848562\n",
      "      - -203693.43951917315\n",
      "      - -203565.22598051283\n",
      "      - -206750.54441373312\n",
      "      - -205252.13223363197\n",
      "      - -200875.25470573787\n",
      "      - -207275.56462739658\n",
      "      - -204789.53286740498\n",
      "      - -204667.18152095957\n",
      "      - -201019.38523277288\n",
      "      - -203539.5218011581\n",
      "      - -198958.86532189182\n",
      "      - -204944.95214247177\n",
      "      - -199708.1373354955\n",
      "      - -204582.173121212\n",
      "      - -203178.8296571753\n",
      "      - -202772.11013197975\n",
      "      - -204260.9548837174\n",
      "      - -201841.43552418862\n",
      "      - -200367.41370371354\n",
      "      - -208226.68666134033\n",
      "      - -206311.18862649915\n",
      "      - -199941.59110857954\n",
      "      - -201135.73639720288\n",
      "      - -210184.67732019117\n",
      "      - -203459.87753060125\n",
      "      - -203048.15973833617\n",
      "      - -198656.3070120003\n",
      "      - -204279.8537393935\n",
      "      - -204262.14069540883\n",
      "      - -207097.92064369976\n",
      "      - -200567.46495021728\n",
      "      - -205869.33878492433\n",
      "      - -210211.01762083085\n",
      "      - -203396.57991403685\n",
      "      - -204186.2052600354\n",
      "      - -202188.2068474242\n",
      "      - -198990.46950940904\n",
      "      - -205000.98524736703\n",
      "      - -207849.13006534922\n",
      "      - -207034.54049438136\n",
      "      - -204654.70593583083\n",
      "      - -210512.84862899163\n",
      "      - -200793.61496389445\n",
      "      - -199236.36326594945\n",
      "      - -198962.22146719682\n",
      "      - -212951.49355141644\n",
      "      - -199682.42658168345\n",
      "      - -207994.55459332035\n",
      "      - -206075.98758900745\n",
      "      - -202582.18077357166\n",
      "      - -199619.1366094327\n",
      "      - -201793.8508856829\n",
      "      - -212245.229822464\n",
      "      - -270032.6033101867\n",
      "      - -200692.29809772814\n",
      "      - -204854.17445441152\n",
      "      - -204803.4991836586\n",
      "      - -207791.83239974163\n",
      "      - -207724.70507566197\n",
      "      - -197976.59524687324\n",
      "      - -202035.28811265985\n",
      "      - -197572.88654576903\n",
      "      - -200620.55314568654\n",
      "      - -202427.54733587487\n",
      "      - -207888.8398938594\n",
      "      - -201442.0271982589\n",
      "      - -197312.52862769898\n",
      "      - -205178.11345607755\n",
      "      - -202316.14917122378\n",
      "      - -200471.56486724413\n",
      "      - -208942.30217842717\n",
      "      - -209836.06262739963\n",
      "      - -205489.04723060803\n",
      "      - -200993.02414873394\n",
      "      - -201892.2435100922\n",
      "      - -196178.24050406768\n",
      "      - -201765.15506785212\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11718215247155203\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.511359230456504\n",
      "      mean_inference_ms: 1.5851747519348804\n",
      "      mean_raw_obs_processing_ms: 0.16173559186202394\n",
      "  time_since_restore: 1182.736876487732\n",
      "  time_this_iter_s: 15.811418056488037\n",
      "  time_total_s: 1182.736876487732\n",
      "  timers:\n",
      "    learn_throughput: 24566.911\n",
      "    learn_time_ms: 2604.479\n",
      "    load_throughput: 535849.97\n",
      "    load_time_ms: 119.407\n",
      "    training_iteration_time_ms: 15526.294\n",
      "    update_time_ms: 4.536\n",
      "  timestamp: 1665743398\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4862784\n",
      "  training_iteration: 76\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:30:03 (running for 00:20:06.21)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    76</td><td style=\"text-align: right;\">         1182.74</td><td style=\"text-align: right;\">4.86278e+06</td><td style=\"text-align: right;\"> -204346</td><td style=\"text-align: right;\">             -196178</td><td style=\"text-align: right;\">             -270033</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:30:09 (running for 00:20:11.31)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    76</td><td style=\"text-align: right;\">         1182.74</td><td style=\"text-align: right;\">4.86278e+06</td><td style=\"text-align: right;\"> -204346</td><td style=\"text-align: right;\">             -196178</td><td style=\"text-align: right;\">             -270033</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 4926768\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 4926768\n",
      "    num_agent_steps_trained: 4926768\n",
      "    num_env_steps_sampled: 4926768\n",
      "    num_env_steps_trained: 4926768\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-30-13\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -195866.69122603137\n",
      "  episode_reward_mean: -203604.62479654522\n",
      "  episode_reward_min: -270032.6033101867\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 4920\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0443601608276367\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.001945028081536293\n",
      "          model: {}\n",
      "          policy_loss: 0.0031095538288354874\n",
      "          total_loss: 10.003194808959961\n",
      "          vf_explained_var: -2.8703361749649048e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 4926768\n",
      "    num_agent_steps_trained: 4926768\n",
      "    num_env_steps_sampled: 4926768\n",
      "    num_env_steps_trained: 4926768\n",
      "  iterations_since_restore: 77\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 4926768\n",
      "  num_agent_steps_trained: 4926768\n",
      "  num_env_steps_sampled: 4926768\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 4926768\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.01904761904761\n",
      "    ram_util_percent: 78.70000000000002\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11703068749179284\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5113128099808201\n",
      "    mean_inference_ms: 1.5837608882488552\n",
      "    mean_raw_obs_processing_ms: 0.1619015002228169\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -195866.69122603137\n",
      "    episode_reward_mean: -203604.62479654522\n",
      "    episode_reward_min: -270032.6033101867\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -205000.98524736703\n",
      "      - -207849.13006534922\n",
      "      - -207034.54049438136\n",
      "      - -204654.70593583083\n",
      "      - -210512.84862899163\n",
      "      - -200793.61496389445\n",
      "      - -199236.36326594945\n",
      "      - -198962.22146719682\n",
      "      - -212951.49355141644\n",
      "      - -199682.42658168345\n",
      "      - -207994.55459332035\n",
      "      - -206075.98758900745\n",
      "      - -202582.18077357166\n",
      "      - -199619.1366094327\n",
      "      - -201793.8508856829\n",
      "      - -212245.229822464\n",
      "      - -270032.6033101867\n",
      "      - -200692.29809772814\n",
      "      - -204854.17445441152\n",
      "      - -204803.4991836586\n",
      "      - -207791.83239974163\n",
      "      - -207724.70507566197\n",
      "      - -197976.59524687324\n",
      "      - -202035.28811265985\n",
      "      - -197572.88654576903\n",
      "      - -200620.55314568654\n",
      "      - -202427.54733587487\n",
      "      - -207888.8398938594\n",
      "      - -201442.0271982589\n",
      "      - -197312.52862769898\n",
      "      - -205178.11345607755\n",
      "      - -202316.14917122378\n",
      "      - -200471.56486724413\n",
      "      - -208942.30217842717\n",
      "      - -209836.06262739963\n",
      "      - -205489.04723060803\n",
      "      - -200993.02414873394\n",
      "      - -201892.2435100922\n",
      "      - -196178.24050406768\n",
      "      - -201765.15506785212\n",
      "      - -200954.6308097113\n",
      "      - -197559.80528282397\n",
      "      - -206259.18357377927\n",
      "      - -207044.66457223127\n",
      "      - -205050.63811585843\n",
      "      - -201847.96488313016\n",
      "      - -208130.26798907982\n",
      "      - -200017.70902717597\n",
      "      - -202971.01051035157\n",
      "      - -203070.55673325495\n",
      "      - -200070.0125543155\n",
      "      - -201457.46218817637\n",
      "      - -201835.16401614\n",
      "      - -201946.66436959273\n",
      "      - -211641.75979422225\n",
      "      - -202807.43444663845\n",
      "      - -201023.18321591566\n",
      "      - -201239.55367665435\n",
      "      - -199524.1686403207\n",
      "      - -203888.4549053712\n",
      "      - -203310.29691597243\n",
      "      - -203187.71771447416\n",
      "      - -199684.9633716527\n",
      "      - -199988.42577985197\n",
      "      - -203907.37958030327\n",
      "      - -202018.9120656321\n",
      "      - -202490.72333491914\n",
      "      - -202458.41704308055\n",
      "      - -203056.98545653452\n",
      "      - -195866.69122603137\n",
      "      - -200241.9890326732\n",
      "      - -204808.97603749376\n",
      "      - -199718.60568928893\n",
      "      - -200700.08506506804\n",
      "      - -205137.84775712472\n",
      "      - -207827.11880280645\n",
      "      - -205297.0970315412\n",
      "      - -206233.51772624365\n",
      "      - -199357.29413584655\n",
      "      - -199353.26683221466\n",
      "      - -199612.97531045196\n",
      "      - -201761.2773580435\n",
      "      - -201171.48214767687\n",
      "      - -201392.55508421632\n",
      "      - -202736.97911035735\n",
      "      - -198900.14296470786\n",
      "      - -203692.60798021883\n",
      "      - -199991.2864701184\n",
      "      - -201776.35935084036\n",
      "      - -200001.61708204716\n",
      "      - -207529.6640338761\n",
      "      - -205651.14343908973\n",
      "      - -200739.31279844933\n",
      "      - -199444.23022048356\n",
      "      - -205463.0753998098\n",
      "      - -208223.5771259817\n",
      "      - -198764.8168993373\n",
      "      - -201912.17463537052\n",
      "      - -200469.96256826888\n",
      "      - -205014.0879063423\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11703068749179284\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5113128099808201\n",
      "      mean_inference_ms: 1.5837608882488552\n",
      "      mean_raw_obs_processing_ms: 0.1619015002228169\n",
      "  time_since_restore: 1197.7054204940796\n",
      "  time_this_iter_s: 14.968544006347656\n",
      "  time_total_s: 1197.7054204940796\n",
      "  timers:\n",
      "    learn_throughput: 24532.673\n",
      "    learn_time_ms: 2608.114\n",
      "    load_throughput: 535962.978\n",
      "    load_time_ms: 119.381\n",
      "    training_iteration_time_ms: 15483.618\n",
      "    update_time_ms: 4.691\n",
      "  timestamp: 1665743413\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4926768\n",
      "  training_iteration: 77\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:30:19 (running for 00:20:21.24)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    77</td><td style=\"text-align: right;\">         1197.71</td><td style=\"text-align: right;\">4.92677e+06</td><td style=\"text-align: right;\"> -203605</td><td style=\"text-align: right;\">             -195867</td><td style=\"text-align: right;\">             -270033</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:30:24 (running for 00:20:26.34)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    77</td><td style=\"text-align: right;\">         1197.71</td><td style=\"text-align: right;\">4.92677e+06</td><td style=\"text-align: right;\"> -203605</td><td style=\"text-align: right;\">             -195867</td><td style=\"text-align: right;\">             -270033</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:30:29 (running for 00:20:31.35)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    77</td><td style=\"text-align: right;\">         1197.71</td><td style=\"text-align: right;\">4.92677e+06</td><td style=\"text-align: right;\"> -203605</td><td style=\"text-align: right;\">             -195867</td><td style=\"text-align: right;\">             -270033</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 4990752\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 4990752\n",
      "    num_agent_steps_trained: 4990752\n",
      "    num_env_steps_sampled: 4990752\n",
      "    num_env_steps_trained: 4990752\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-30-29\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -195866.69122603137\n",
      "  episode_reward_mean: -202392.6525821397\n",
      "  episode_reward_min: -210127.84984943643\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 4980\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.049996852874756\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0018802082631736994\n",
      "          model: {}\n",
      "          policy_loss: 0.0023330599069595337\n",
      "          total_loss: 10.00240421295166\n",
      "          vf_explained_var: -1.616310328245163e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 4990752\n",
      "    num_agent_steps_trained: 4990752\n",
      "    num_env_steps_sampled: 4990752\n",
      "    num_env_steps_trained: 4990752\n",
      "  iterations_since_restore: 78\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 4990752\n",
      "  num_agent_steps_trained: 4990752\n",
      "  num_env_steps_sampled: 4990752\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 4990752\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.80000000000001\n",
      "    ram_util_percent: 78.70000000000002\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1169338942679292\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5110191380060698\n",
      "    mean_inference_ms: 1.5827661316000874\n",
      "    mean_raw_obs_processing_ms: 0.16164462283010791\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -195866.69122603137\n",
      "    episode_reward_mean: -202392.6525821397\n",
      "    episode_reward_min: -210127.84984943643\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -203310.29691597243\n",
      "      - -203187.71771447416\n",
      "      - -199684.9633716527\n",
      "      - -199988.42577985197\n",
      "      - -203907.37958030327\n",
      "      - -202018.9120656321\n",
      "      - -202490.72333491914\n",
      "      - -202458.41704308055\n",
      "      - -203056.98545653452\n",
      "      - -195866.69122603137\n",
      "      - -200241.9890326732\n",
      "      - -204808.97603749376\n",
      "      - -199718.60568928893\n",
      "      - -200700.08506506804\n",
      "      - -205137.84775712472\n",
      "      - -207827.11880280645\n",
      "      - -205297.0970315412\n",
      "      - -206233.51772624365\n",
      "      - -199357.29413584655\n",
      "      - -199353.26683221466\n",
      "      - -199612.97531045196\n",
      "      - -201761.2773580435\n",
      "      - -201171.48214767687\n",
      "      - -201392.55508421632\n",
      "      - -202736.97911035735\n",
      "      - -198900.14296470786\n",
      "      - -203692.60798021883\n",
      "      - -199991.2864701184\n",
      "      - -201776.35935084036\n",
      "      - -200001.61708204716\n",
      "      - -207529.6640338761\n",
      "      - -205651.14343908973\n",
      "      - -200739.31279844933\n",
      "      - -199444.23022048356\n",
      "      - -205463.0753998098\n",
      "      - -208223.5771259817\n",
      "      - -198764.8168993373\n",
      "      - -201912.17463537052\n",
      "      - -200469.96256826888\n",
      "      - -205014.0879063423\n",
      "      - -204455.87317383033\n",
      "      - -197431.735726093\n",
      "      - -206248.18730828815\n",
      "      - -199619.01915024393\n",
      "      - -202143.9416446068\n",
      "      - -206874.98171253724\n",
      "      - -197841.34775112703\n",
      "      - -203798.64798599723\n",
      "      - -202328.4531321735\n",
      "      - -201515.86941629683\n",
      "      - -203918.03723830948\n",
      "      - -202656.52828359115\n",
      "      - -202665.92137725072\n",
      "      - -199395.28675789502\n",
      "      - -201419.14362249762\n",
      "      - -203775.6461855494\n",
      "      - -203178.8648705622\n",
      "      - -203851.73334659243\n",
      "      - -203528.26269092294\n",
      "      - -199835.31235662047\n",
      "      - -196111.737211519\n",
      "      - -202523.2590628983\n",
      "      - -197501.7444006192\n",
      "      - -200159.90222498553\n",
      "      - -201033.05752557438\n",
      "      - -206596.9570506558\n",
      "      - -202221.92143085395\n",
      "      - -200874.97657784613\n",
      "      - -202969.85360575255\n",
      "      - -199955.3160008193\n",
      "      - -202199.85058813635\n",
      "      - -201344.94319549497\n",
      "      - -205056.63001822034\n",
      "      - -202319.87456272877\n",
      "      - -210127.84984943643\n",
      "      - -204592.84592368483\n",
      "      - -206513.86568811414\n",
      "      - -203898.5757142656\n",
      "      - -201272.761081848\n",
      "      - -201541.11211532727\n",
      "      - -199008.83264618498\n",
      "      - -202392.50640242262\n",
      "      - -204071.74446956645\n",
      "      - -201175.38622952136\n",
      "      - -204534.36458111386\n",
      "      - -202178.4967872557\n",
      "      - -200616.9531457463\n",
      "      - -204385.7119732268\n",
      "      - -204979.54526112234\n",
      "      - -205318.64532841498\n",
      "      - -201061.13961183548\n",
      "      - -203105.34383881884\n",
      "      - -204024.47172466436\n",
      "      - -200145.63938183335\n",
      "      - -201760.78656879062\n",
      "      - -202784.0367624955\n",
      "      - -204472.27399613487\n",
      "      - -203469.58628955932\n",
      "      - -201522.1760018871\n",
      "      - -204062.1511691654\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1169338942679292\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5110191380060698\n",
      "      mean_inference_ms: 1.5827661316000874\n",
      "      mean_raw_obs_processing_ms: 0.16164462283010791\n",
      "  time_since_restore: 1212.997006893158\n",
      "  time_this_iter_s: 15.29158639907837\n",
      "  time_total_s: 1212.997006893158\n",
      "  timers:\n",
      "    learn_throughput: 24595.728\n",
      "    learn_time_ms: 2601.427\n",
      "    load_throughput: 533108.147\n",
      "    load_time_ms: 120.021\n",
      "    training_iteration_time_ms: 15422.935\n",
      "    update_time_ms: 4.511\n",
      "  timestamp: 1665743429\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4990752\n",
      "  training_iteration: 78\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:30:34 (running for 00:20:36.63)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    78</td><td style=\"text-align: right;\">            1213</td><td style=\"text-align: right;\">4.99075e+06</td><td style=\"text-align: right;\"> -202393</td><td style=\"text-align: right;\">             -195867</td><td style=\"text-align: right;\">             -210128</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:30:39 (running for 00:20:41.64)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    78</td><td style=\"text-align: right;\">            1213</td><td style=\"text-align: right;\">4.99075e+06</td><td style=\"text-align: right;\"> -202393</td><td style=\"text-align: right;\">             -195867</td><td style=\"text-align: right;\">             -210128</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 5054736\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 5054736\n",
      "    num_agent_steps_trained: 5054736\n",
      "    num_env_steps_sampled: 5054736\n",
      "    num_env_steps_trained: 5054736\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-30-44\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -196014.3391998138\n",
      "  episode_reward_mean: -202177.3241307193\n",
      "  episode_reward_min: -210127.84984943643\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 5052\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0589303970336914\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0017351630376651883\n",
      "          model: {}\n",
      "          policy_loss: 0.006487692706286907\n",
      "          total_loss: 10.006529808044434\n",
      "          vf_explained_var: -2.5593317332095467e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 5054736\n",
      "    num_agent_steps_trained: 5054736\n",
      "    num_env_steps_sampled: 5054736\n",
      "    num_env_steps_trained: 5054736\n",
      "  iterations_since_restore: 79\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 5054736\n",
      "  num_agent_steps_trained: 5054736\n",
      "  num_env_steps_sampled: 5054736\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 5054736\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 73.77727272727272\n",
      "    ram_util_percent: 78.70454545454547\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11722021542740454\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5108942550197709\n",
      "    mean_inference_ms: 1.5827108433150243\n",
      "    mean_raw_obs_processing_ms: 0.1615628975425584\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -196014.3391998138\n",
      "    episode_reward_mean: -202177.3241307193\n",
      "    episode_reward_min: -210127.84984943643\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -205056.63001822034\n",
      "      - -202319.87456272877\n",
      "      - -210127.84984943643\n",
      "      - -204592.84592368483\n",
      "      - -206513.86568811414\n",
      "      - -203898.5757142656\n",
      "      - -201272.761081848\n",
      "      - -201541.11211532727\n",
      "      - -199008.83264618498\n",
      "      - -202392.50640242262\n",
      "      - -204071.74446956645\n",
      "      - -201175.38622952136\n",
      "      - -204534.36458111386\n",
      "      - -202178.4967872557\n",
      "      - -200616.9531457463\n",
      "      - -204385.7119732268\n",
      "      - -204979.54526112234\n",
      "      - -205318.64532841498\n",
      "      - -201061.13961183548\n",
      "      - -203105.34383881884\n",
      "      - -204024.47172466436\n",
      "      - -200145.63938183335\n",
      "      - -201760.78656879062\n",
      "      - -202784.0367624955\n",
      "      - -204472.27399613487\n",
      "      - -203469.58628955932\n",
      "      - -201522.1760018871\n",
      "      - -204062.1511691654\n",
      "      - -200604.7354303263\n",
      "      - -201142.28771607217\n",
      "      - -207766.7409553943\n",
      "      - -199799.11482287888\n",
      "      - -202975.47647086717\n",
      "      - -204036.98975869917\n",
      "      - -207196.10068204705\n",
      "      - -198415.83319211856\n",
      "      - -203220.80682247304\n",
      "      - -198876.57181426816\n",
      "      - -198070.8465980263\n",
      "      - -207521.17259888965\n",
      "      - -198891.68017439742\n",
      "      - -202771.70069545944\n",
      "      - -204615.8962399051\n",
      "      - -196014.3391998138\n",
      "      - -204939.655280003\n",
      "      - -196986.73772381386\n",
      "      - -203703.1347833295\n",
      "      - -201327.637697562\n",
      "      - -204909.44172360754\n",
      "      - -207432.979425402\n",
      "      - -200129.35218402944\n",
      "      - -206496.61926092856\n",
      "      - -199449.70785577458\n",
      "      - -198334.32293463568\n",
      "      - -196240.39561347463\n",
      "      - -200057.54664772243\n",
      "      - -200783.58461857037\n",
      "      - -204013.4379378551\n",
      "      - -201535.53184664616\n",
      "      - -200067.7175168107\n",
      "      - -201871.4636386718\n",
      "      - -200163.7264677771\n",
      "      - -201716.6811960968\n",
      "      - -199629.0874310609\n",
      "      - -208395.20363208352\n",
      "      - -196507.92459532496\n",
      "      - -200794.60579681402\n",
      "      - -202196.57813408677\n",
      "      - -199019.21638180022\n",
      "      - -199387.62887861827\n",
      "      - -200674.1378450397\n",
      "      - -198793.9081399319\n",
      "      - -196781.0720084442\n",
      "      - -202650.6018883307\n",
      "      - -199066.9276634599\n",
      "      - -199634.4248832935\n",
      "      - -203791.06040197966\n",
      "      - -201826.84651218104\n",
      "      - -202447.37883264723\n",
      "      - -206792.69582956575\n",
      "      - -203958.56000209812\n",
      "      - -201749.1322951859\n",
      "      - -201679.4205193863\n",
      "      - -205353.87933118717\n",
      "      - -200848.1411585542\n",
      "      - -202709.20987015488\n",
      "      - -199842.73759774177\n",
      "      - -202520.36688612163\n",
      "      - -202975.14953566573\n",
      "      - -196506.93925621847\n",
      "      - -203141.23404615332\n",
      "      - -203077.08107766282\n",
      "      - -202020.09613675074\n",
      "      - -197276.67594831556\n",
      "      - -200649.31100823605\n",
      "      - -206746.9754248388\n",
      "      - -204955.81584890088\n",
      "      - -205949.866781925\n",
      "      - -204315.98386473942\n",
      "      - -200593.26297969586\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11722021542740454\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5108942550197709\n",
      "      mean_inference_ms: 1.5827108433150243\n",
      "      mean_raw_obs_processing_ms: 0.1615628975425584\n",
      "  time_since_restore: 1227.9684524536133\n",
      "  time_this_iter_s: 14.971445560455322\n",
      "  time_total_s: 1227.9684524536133\n",
      "  timers:\n",
      "    learn_throughput: 24569.308\n",
      "    learn_time_ms: 2604.225\n",
      "    load_throughput: 536611.02\n",
      "    load_time_ms: 119.237\n",
      "    training_iteration_time_ms: 15394.031\n",
      "    update_time_ms: 4.581\n",
      "  timestamp: 1665743444\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5054736\n",
      "  training_iteration: 79\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:30:49 (running for 00:20:51.63)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    79</td><td style=\"text-align: right;\">         1227.97</td><td style=\"text-align: right;\">5.05474e+06</td><td style=\"text-align: right;\"> -202177</td><td style=\"text-align: right;\">             -196014</td><td style=\"text-align: right;\">             -210128</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:30:54 (running for 00:20:56.64)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    79</td><td style=\"text-align: right;\">         1227.97</td><td style=\"text-align: right;\">5.05474e+06</td><td style=\"text-align: right;\"> -202177</td><td style=\"text-align: right;\">             -196014</td><td style=\"text-align: right;\">             -210128</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:30:59 (running for 00:21:01.65)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    79</td><td style=\"text-align: right;\">         1227.97</td><td style=\"text-align: right;\">5.05474e+06</td><td style=\"text-align: right;\"> -202177</td><td style=\"text-align: right;\">             -196014</td><td style=\"text-align: right;\">             -210128</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 5118720\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 5118720\n",
      "    num_agent_steps_trained: 5118720\n",
      "    num_env_steps_sampled: 5118720\n",
      "    num_env_steps_trained: 5118720\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-30-59\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -195035.87452056087\n",
      "  episode_reward_mean: -201972.88153149252\n",
      "  episode_reward_min: -213750.19572346038\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 5112\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.062365770339966\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0014694205019623041\n",
      "          model: {}\n",
      "          policy_loss: 0.0027210917323827744\n",
      "          total_loss: 10.002708435058594\n",
      "          vf_explained_var: 3.757886588573456e-07\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 5118720\n",
      "    num_agent_steps_trained: 5118720\n",
      "    num_env_steps_sampled: 5118720\n",
      "    num_env_steps_trained: 5118720\n",
      "  iterations_since_restore: 80\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 5118720\n",
      "  num_agent_steps_trained: 5118720\n",
      "  num_env_steps_sampled: 5118720\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 5118720\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.84761904761905\n",
      "    ram_util_percent: 78.75714285714285\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11705091850858977\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.510800696422566\n",
      "    mean_inference_ms: 1.5816877509059872\n",
      "    mean_raw_obs_processing_ms: 0.16176629295031245\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -195035.87452056087\n",
      "    episode_reward_mean: -201972.88153149252\n",
      "    episode_reward_min: -213750.19572346038\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -201871.4636386718\n",
      "      - -200163.7264677771\n",
      "      - -201716.6811960968\n",
      "      - -199629.0874310609\n",
      "      - -208395.20363208352\n",
      "      - -196507.92459532496\n",
      "      - -200794.60579681402\n",
      "      - -202196.57813408677\n",
      "      - -199019.21638180022\n",
      "      - -199387.62887861827\n",
      "      - -200674.1378450397\n",
      "      - -198793.9081399319\n",
      "      - -196781.0720084442\n",
      "      - -202650.6018883307\n",
      "      - -199066.9276634599\n",
      "      - -199634.4248832935\n",
      "      - -203791.06040197966\n",
      "      - -201826.84651218104\n",
      "      - -202447.37883264723\n",
      "      - -206792.69582956575\n",
      "      - -203958.56000209812\n",
      "      - -201749.1322951859\n",
      "      - -201679.4205193863\n",
      "      - -205353.87933118717\n",
      "      - -200848.1411585542\n",
      "      - -202709.20987015488\n",
      "      - -199842.73759774177\n",
      "      - -202520.36688612163\n",
      "      - -202975.14953566573\n",
      "      - -196506.93925621847\n",
      "      - -203141.23404615332\n",
      "      - -203077.08107766282\n",
      "      - -202020.09613675074\n",
      "      - -197276.67594831556\n",
      "      - -200649.31100823605\n",
      "      - -206746.9754248388\n",
      "      - -204955.81584890088\n",
      "      - -205949.866781925\n",
      "      - -204315.98386473942\n",
      "      - -200593.26297969586\n",
      "      - -201789.59065498522\n",
      "      - -198374.48465778376\n",
      "      - -199571.5101705607\n",
      "      - -200887.00190162132\n",
      "      - -203677.06366654098\n",
      "      - -201436.8644565034\n",
      "      - -201398.09782084136\n",
      "      - -201712.2070675664\n",
      "      - -200309.2046988891\n",
      "      - -204205.0244530989\n",
      "      - -199173.94204073393\n",
      "      - -213750.19572346038\n",
      "      - -196773.8793126874\n",
      "      - -200587.737487115\n",
      "      - -199377.93036814974\n",
      "      - -198102.24288134\n",
      "      - -204641.34823586958\n",
      "      - -199554.93375856194\n",
      "      - -203504.98595315966\n",
      "      - -204511.0365853257\n",
      "      - -206865.99913606653\n",
      "      - -198264.1005642561\n",
      "      - -203811.40703122213\n",
      "      - -199042.32490412044\n",
      "      - -209138.65102538117\n",
      "      - -198642.80913407053\n",
      "      - -205947.7606564896\n",
      "      - -198627.94621109968\n",
      "      - -204151.85694775495\n",
      "      - -208155.29184578624\n",
      "      - -207309.5531026571\n",
      "      - -201859.42091148425\n",
      "      - -199218.8270632107\n",
      "      - -203234.97312887144\n",
      "      - -201339.89679894358\n",
      "      - -199139.6301756894\n",
      "      - -202615.1899316284\n",
      "      - -195035.87452056087\n",
      "      - -200177.58023820524\n",
      "      - -201546.7159631281\n",
      "      - -199118.83669554206\n",
      "      - -203056.32135988786\n",
      "      - -205057.33338188045\n",
      "      - -200810.08339386343\n",
      "      - -196833.82357243393\n",
      "      - -200871.53577286444\n",
      "      - -204030.9768949468\n",
      "      - -203354.26092086025\n",
      "      - -205744.6781471591\n",
      "      - -198690.33576446975\n",
      "      - -208213.9246583638\n",
      "      - -195996.70106131857\n",
      "      - -213697.08041271794\n",
      "      - -200932.87244972482\n",
      "      - -201600.15460522214\n",
      "      - -203493.36983634045\n",
      "      - -199879.28311368512\n",
      "      - -202804.4301530795\n",
      "      - -206564.5600073743\n",
      "      - -200061.490035354\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11705091850858977\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.510800696422566\n",
      "      mean_inference_ms: 1.5816877509059872\n",
      "      mean_raw_obs_processing_ms: 0.16176629295031245\n",
      "  time_since_restore: 1243.1598689556122\n",
      "  time_this_iter_s: 15.191416501998901\n",
      "  time_total_s: 1243.1598689556122\n",
      "  timers:\n",
      "    learn_throughput: 24644.948\n",
      "    learn_time_ms: 2596.232\n",
      "    load_throughput: 535736.902\n",
      "    load_time_ms: 119.432\n",
      "    training_iteration_time_ms: 15355.968\n",
      "    update_time_ms: 4.566\n",
      "  timestamp: 1665743459\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5118720\n",
      "  training_iteration: 80\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:31:04 (running for 00:21:06.77)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">         1243.16</td><td style=\"text-align: right;\">5.11872e+06</td><td style=\"text-align: right;\"> -201973</td><td style=\"text-align: right;\">             -195036</td><td style=\"text-align: right;\">             -213750</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:31:09 (running for 00:21:11.87)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">         1243.16</td><td style=\"text-align: right;\">5.11872e+06</td><td style=\"text-align: right;\"> -201973</td><td style=\"text-align: right;\">             -195036</td><td style=\"text-align: right;\">             -213750</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:31:14 (running for 00:21:16.88)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">         1243.16</td><td style=\"text-align: right;\">5.11872e+06</td><td style=\"text-align: right;\"> -201973</td><td style=\"text-align: right;\">             -195036</td><td style=\"text-align: right;\">             -213750</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 5182704\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 5182704\n",
      "    num_agent_steps_trained: 5182704\n",
      "    num_env_steps_sampled: 5182704\n",
      "    num_env_steps_trained: 5182704\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-31-15\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -195035.87452056087\n",
      "  episode_reward_mean: -202150.0500864693\n",
      "  episode_reward_min: -213697.08041271794\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 5172\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.060580253601074\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0017315176082774997\n",
      "          model: {}\n",
      "          policy_loss: 0.0021941419690847397\n",
      "          total_loss: 10.002233505249023\n",
      "          vf_explained_var: 1.9636936485767365e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 5182704\n",
      "    num_agent_steps_trained: 5182704\n",
      "    num_env_steps_sampled: 5182704\n",
      "    num_env_steps_trained: 5182704\n",
      "  iterations_since_restore: 81\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 5182704\n",
      "  num_agent_steps_trained: 5182704\n",
      "  num_env_steps_sampled: 5182704\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 5182704\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.0\n",
      "    ram_util_percent: 78.80454545454545\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11699353207486704\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5106958032206363\n",
      "    mean_inference_ms: 1.5820333262669948\n",
      "    mean_raw_obs_processing_ms: 0.16157044039001278\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -195035.87452056087\n",
      "    episode_reward_mean: -202150.0500864693\n",
      "    episode_reward_min: -213697.08041271794\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -206865.99913606653\n",
      "      - -198264.1005642561\n",
      "      - -203811.40703122213\n",
      "      - -199042.32490412044\n",
      "      - -209138.65102538117\n",
      "      - -198642.80913407053\n",
      "      - -205947.7606564896\n",
      "      - -198627.94621109968\n",
      "      - -204151.85694775495\n",
      "      - -208155.29184578624\n",
      "      - -207309.5531026571\n",
      "      - -201859.42091148425\n",
      "      - -199218.8270632107\n",
      "      - -203234.97312887144\n",
      "      - -201339.89679894358\n",
      "      - -199139.6301756894\n",
      "      - -202615.1899316284\n",
      "      - -195035.87452056087\n",
      "      - -200177.58023820524\n",
      "      - -201546.7159631281\n",
      "      - -199118.83669554206\n",
      "      - -203056.32135988786\n",
      "      - -205057.33338188045\n",
      "      - -200810.08339386343\n",
      "      - -196833.82357243393\n",
      "      - -200871.53577286444\n",
      "      - -204030.9768949468\n",
      "      - -203354.26092086025\n",
      "      - -205744.6781471591\n",
      "      - -198690.33576446975\n",
      "      - -208213.9246583638\n",
      "      - -195996.70106131857\n",
      "      - -213697.08041271794\n",
      "      - -200932.87244972482\n",
      "      - -201600.15460522214\n",
      "      - -203493.36983634045\n",
      "      - -199879.28311368512\n",
      "      - -202804.4301530795\n",
      "      - -206564.5600073743\n",
      "      - -200061.490035354\n",
      "      - -198662.85084620753\n",
      "      - -196529.85855629\n",
      "      - -198489.16175535266\n",
      "      - -208195.2373373458\n",
      "      - -201220.47010092135\n",
      "      - -199017.69944271128\n",
      "      - -200051.98606142617\n",
      "      - -199918.3605136104\n",
      "      - -201824.7800711719\n",
      "      - -204209.91807717094\n",
      "      - -200967.5711499831\n",
      "      - -204809.0324363097\n",
      "      - -202096.12223909434\n",
      "      - -200206.81217724772\n",
      "      - -203142.13494849834\n",
      "      - -203232.90865768335\n",
      "      - -201047.92589273394\n",
      "      - -200766.71605774364\n",
      "      - -204002.85813034984\n",
      "      - -205653.89483326275\n",
      "      - -200956.3336026564\n",
      "      - -204606.81790534712\n",
      "      - -201911.50017687038\n",
      "      - -203952.7889904381\n",
      "      - -199319.11669886843\n",
      "      - -208529.23366901986\n",
      "      - -201187.6444070599\n",
      "      - -205651.58521684373\n",
      "      - -205958.74743234538\n",
      "      - -200585.63941974682\n",
      "      - -202724.28445304895\n",
      "      - -203779.4722644979\n",
      "      - -204217.42135918725\n",
      "      - -199189.75118260036\n",
      "      - -197284.9799033603\n",
      "      - -204976.42032962778\n",
      "      - -202113.07344832926\n",
      "      - -205265.82868406284\n",
      "      - -200776.47688596486\n",
      "      - -196937.7990271362\n",
      "      - -202697.1861663828\n",
      "      - -206152.6131944633\n",
      "      - -201520.81709425582\n",
      "      - -200013.19037734545\n",
      "      - -204673.96930600825\n",
      "      - -201877.62782697365\n",
      "      - -203522.6936442583\n",
      "      - -203304.39248820962\n",
      "      - -201698.27687292563\n",
      "      - -199710.57805369332\n",
      "      - -205182.76683400467\n",
      "      - -204168.49692437352\n",
      "      - -197663.3126932315\n",
      "      - -199009.9272540791\n",
      "      - -200504.47910993506\n",
      "      - -204718.43867008173\n",
      "      - -203532.5394223859\n",
      "      - -199407.00339627694\n",
      "      - -197649.23896615437\n",
      "      - -199088.38448205334\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11699353207486704\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5106958032206363\n",
      "      mean_inference_ms: 1.5820333262669948\n",
      "      mean_raw_obs_processing_ms: 0.16157044039001278\n",
      "  time_since_restore: 1259.105830192566\n",
      "  time_this_iter_s: 15.945961236953735\n",
      "  time_total_s: 1259.105830192566\n",
      "  timers:\n",
      "    learn_throughput: 24628.181\n",
      "    learn_time_ms: 2597.999\n",
      "    load_throughput: 533800.578\n",
      "    load_time_ms: 119.865\n",
      "    training_iteration_time_ms: 15373.146\n",
      "    update_time_ms: 4.713\n",
      "  timestamp: 1665743475\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5182704\n",
      "  training_iteration: 81\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:31:20 (running for 00:21:22.87)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    81</td><td style=\"text-align: right;\">         1259.11</td><td style=\"text-align: right;\">5.1827e+06</td><td style=\"text-align: right;\"> -202150</td><td style=\"text-align: right;\">             -195036</td><td style=\"text-align: right;\">             -213697</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:31:25 (running for 00:21:28.17)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    81</td><td style=\"text-align: right;\">         1259.11</td><td style=\"text-align: right;\">5.1827e+06</td><td style=\"text-align: right;\"> -202150</td><td style=\"text-align: right;\">             -195036</td><td style=\"text-align: right;\">             -213697</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 5246688\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 5246688\n",
      "    num_agent_steps_trained: 5246688\n",
      "    num_env_steps_sampled: 5246688\n",
      "    num_env_steps_trained: 5246688\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-31-30\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -195961.7913125172\n",
      "  episode_reward_mean: -201616.5387006141\n",
      "  episode_reward_min: -213826.48647899483\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 5244\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0633647441864014\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0013658785028383136\n",
      "          model: {}\n",
      "          policy_loss: 0.0071385642513632774\n",
      "          total_loss: 10.00710678100586\n",
      "          vf_explained_var: 2.19345088225964e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 5246688\n",
      "    num_agent_steps_trained: 5246688\n",
      "    num_env_steps_sampled: 5246688\n",
      "    num_env_steps_trained: 5246688\n",
      "  iterations_since_restore: 82\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 5246688\n",
      "  num_agent_steps_trained: 5246688\n",
      "  num_env_steps_sampled: 5246688\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 5246688\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.15714285714286\n",
      "    ram_util_percent: 78.8142857142857\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1171775482134748\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.510746913828812\n",
      "    mean_inference_ms: 1.5832755431410994\n",
      "    mean_raw_obs_processing_ms: 0.16154858578508655\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -195961.7913125172\n",
      "    episode_reward_mean: -201616.5387006141\n",
      "    episode_reward_min: -213826.48647899483\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -204217.42135918725\n",
      "      - -199189.75118260036\n",
      "      - -197284.9799033603\n",
      "      - -204976.42032962778\n",
      "      - -202113.07344832926\n",
      "      - -205265.82868406284\n",
      "      - -200776.47688596486\n",
      "      - -196937.7990271362\n",
      "      - -202697.1861663828\n",
      "      - -206152.6131944633\n",
      "      - -201520.81709425582\n",
      "      - -200013.19037734545\n",
      "      - -204673.96930600825\n",
      "      - -201877.62782697365\n",
      "      - -203522.6936442583\n",
      "      - -203304.39248820962\n",
      "      - -201698.27687292563\n",
      "      - -199710.57805369332\n",
      "      - -205182.76683400467\n",
      "      - -204168.49692437352\n",
      "      - -197663.3126932315\n",
      "      - -199009.9272540791\n",
      "      - -200504.47910993506\n",
      "      - -204718.43867008173\n",
      "      - -203532.5394223859\n",
      "      - -199407.00339627694\n",
      "      - -197649.23896615437\n",
      "      - -199088.38448205334\n",
      "      - -199432.81776982913\n",
      "      - -202752.17709377265\n",
      "      - -198750.1646831024\n",
      "      - -200424.2339591968\n",
      "      - -204405.59751790846\n",
      "      - -200418.4703792651\n",
      "      - -203309.45212290555\n",
      "      - -207796.90428835942\n",
      "      - -202586.12904550796\n",
      "      - -200308.9314600376\n",
      "      - -202217.9522738612\n",
      "      - -200197.20117462805\n",
      "      - -202835.92552597437\n",
      "      - -201099.8268345076\n",
      "      - -195961.7913125172\n",
      "      - -197187.59309823418\n",
      "      - -198841.34653496498\n",
      "      - -201140.8849599603\n",
      "      - -202855.40095579872\n",
      "      - -198280.19037091563\n",
      "      - -203530.90584521292\n",
      "      - -201373.34645029582\n",
      "      - -200567.93279558705\n",
      "      - -201647.21859094888\n",
      "      - -198094.34142184092\n",
      "      - -205834.0636988075\n",
      "      - -199411.8515023421\n",
      "      - -200114.73504885554\n",
      "      - -201164.17724457165\n",
      "      - -202587.9418120158\n",
      "      - -201756.0771348625\n",
      "      - -202876.18751035878\n",
      "      - -206175.49742201646\n",
      "      - -200894.63541733706\n",
      "      - -199555.66479176286\n",
      "      - -197296.7356119698\n",
      "      - -201651.9370218664\n",
      "      - -202044.51250793412\n",
      "      - -206345.8095598571\n",
      "      - -202462.79448357172\n",
      "      - -200995.11389474498\n",
      "      - -200171.6269806891\n",
      "      - -199957.0868472278\n",
      "      - -199493.15975114345\n",
      "      - -211142.4866321058\n",
      "      - -200906.9121483434\n",
      "      - -200883.79780577405\n",
      "      - -204635.0243287548\n",
      "      - -200604.75812554837\n",
      "      - -200323.426956861\n",
      "      - -199613.26782581714\n",
      "      - -205551.6909886484\n",
      "      - -198557.45811993125\n",
      "      - -199080.82838748884\n",
      "      - -199395.9792831579\n",
      "      - -196736.3872172047\n",
      "      - -203752.07587272397\n",
      "      - -198903.980486319\n",
      "      - -204985.67164083337\n",
      "      - -196123.83638506415\n",
      "      - -202442.16174765787\n",
      "      - -213826.48647899483\n",
      "      - -203579.45983522484\n",
      "      - -202267.2034332264\n",
      "      - -202151.23725996402\n",
      "      - -204898.25078300212\n",
      "      - -204227.34483211333\n",
      "      - -199818.52466677947\n",
      "      - -203677.4356889779\n",
      "      - -202632.2823576237\n",
      "      - -197680.45900852594\n",
      "      - -199591.41346031294\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1171775482134748\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.510746913828812\n",
      "      mean_inference_ms: 1.5832755431410994\n",
      "      mean_raw_obs_processing_ms: 0.16154858578508655\n",
      "  time_since_restore: 1274.4355945587158\n",
      "  time_this_iter_s: 15.329764366149902\n",
      "  time_total_s: 1274.4355945587158\n",
      "  timers:\n",
      "    learn_throughput: 25040.274\n",
      "    learn_time_ms: 2555.244\n",
      "    load_throughput: 534607.247\n",
      "    load_time_ms: 119.684\n",
      "    training_iteration_time_ms: 15314.728\n",
      "    update_time_ms: 4.722\n",
      "  timestamp: 1665743490\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5246688\n",
      "  training_iteration: 82\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:31:30 (running for 00:21:33.22)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    82</td><td style=\"text-align: right;\">         1274.44</td><td style=\"text-align: right;\">5.24669e+06</td><td style=\"text-align: right;\"> -201617</td><td style=\"text-align: right;\">             -195962</td><td style=\"text-align: right;\">             -213826</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:31:35 (running for 00:21:38.23)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    82</td><td style=\"text-align: right;\">         1274.44</td><td style=\"text-align: right;\">5.24669e+06</td><td style=\"text-align: right;\"> -201617</td><td style=\"text-align: right;\">             -195962</td><td style=\"text-align: right;\">             -213826</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:31:41 (running for 00:21:43.23)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    82</td><td style=\"text-align: right;\">         1274.44</td><td style=\"text-align: right;\">5.24669e+06</td><td style=\"text-align: right;\"> -201617</td><td style=\"text-align: right;\">             -195962</td><td style=\"text-align: right;\">             -213826</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:31:46 (running for 00:21:48.47)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    82</td><td style=\"text-align: right;\">         1274.44</td><td style=\"text-align: right;\">5.24669e+06</td><td style=\"text-align: right;\"> -201617</td><td style=\"text-align: right;\">             -195962</td><td style=\"text-align: right;\">             -213826</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 5310672\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 5310672\n",
      "    num_agent_steps_trained: 5310672\n",
      "    num_env_steps_sampled: 5310672\n",
      "    num_env_steps_trained: 5310672\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-31-47\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -195057.95553914396\n",
      "  episode_reward_mean: -201571.92261616435\n",
      "  episode_reward_min: -213826.48647899483\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 5304\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0545639991760254\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0017130468040704727\n",
      "          model: {}\n",
      "          policy_loss: 0.0030614566057920456\n",
      "          total_loss: 10.003098487854004\n",
      "          vf_explained_var: -2.086162567138672e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 5310672\n",
      "    num_agent_steps_trained: 5310672\n",
      "    num_env_steps_sampled: 5310672\n",
      "    num_env_steps_trained: 5310672\n",
      "  iterations_since_restore: 83\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 5310672\n",
      "  num_agent_steps_trained: 5310672\n",
      "  num_env_steps_sampled: 5310672\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 5310672\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.71363636363637\n",
      "    ram_util_percent: 78.85000000000002\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11708732311821966\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5109545333478167\n",
      "    mean_inference_ms: 1.5836402382486392\n",
      "    mean_raw_obs_processing_ms: 0.16183520456227826\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -195057.95553914396\n",
      "    episode_reward_mean: -201571.92261616435\n",
      "    episode_reward_min: -213826.48647899483\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -206175.49742201646\n",
      "      - -200894.63541733706\n",
      "      - -199555.66479176286\n",
      "      - -197296.7356119698\n",
      "      - -201651.9370218664\n",
      "      - -202044.51250793412\n",
      "      - -206345.8095598571\n",
      "      - -202462.79448357172\n",
      "      - -200995.11389474498\n",
      "      - -200171.6269806891\n",
      "      - -199957.0868472278\n",
      "      - -199493.15975114345\n",
      "      - -211142.4866321058\n",
      "      - -200906.9121483434\n",
      "      - -200883.79780577405\n",
      "      - -204635.0243287548\n",
      "      - -200604.75812554837\n",
      "      - -200323.426956861\n",
      "      - -199613.26782581714\n",
      "      - -205551.6909886484\n",
      "      - -198557.45811993125\n",
      "      - -199080.82838748884\n",
      "      - -199395.9792831579\n",
      "      - -196736.3872172047\n",
      "      - -203752.07587272397\n",
      "      - -198903.980486319\n",
      "      - -204985.67164083337\n",
      "      - -196123.83638506415\n",
      "      - -202442.16174765787\n",
      "      - -213826.48647899483\n",
      "      - -203579.45983522484\n",
      "      - -202267.2034332264\n",
      "      - -202151.23725996402\n",
      "      - -204898.25078300212\n",
      "      - -204227.34483211333\n",
      "      - -199818.52466677947\n",
      "      - -203677.4356889779\n",
      "      - -202632.2823576237\n",
      "      - -197680.45900852594\n",
      "      - -199591.41346031294\n",
      "      - -199963.62880244871\n",
      "      - -197705.92696335062\n",
      "      - -205560.17696287006\n",
      "      - -197447.85203025182\n",
      "      - -204783.88599767713\n",
      "      - -200363.79623780612\n",
      "      - -198262.21308942646\n",
      "      - -209588.05647892505\n",
      "      - -200825.25222331932\n",
      "      - -203360.03156531672\n",
      "      - -198290.7255913574\n",
      "      - -203642.64093790116\n",
      "      - -198751.6310507118\n",
      "      - -203759.9680110424\n",
      "      - -198807.0714037069\n",
      "      - -198388.7563516261\n",
      "      - -199856.08730696334\n",
      "      - -203862.24778977715\n",
      "      - -198396.46370207806\n",
      "      - -205163.5946891693\n",
      "      - -204470.63067857656\n",
      "      - -204212.67266998507\n",
      "      - -199569.7810206885\n",
      "      - -200664.03978655435\n",
      "      - -201113.04388941376\n",
      "      - -201098.66788733407\n",
      "      - -202096.31857889978\n",
      "      - -206449.4096424698\n",
      "      - -199431.72960191453\n",
      "      - -206415.6260868898\n",
      "      - -200239.68122681064\n",
      "      - -200041.18757733004\n",
      "      - -197239.89598118595\n",
      "      - -203456.3191211627\n",
      "      - -200553.84089561287\n",
      "      - -201513.98632673215\n",
      "      - -199001.13702600566\n",
      "      - -198494.14197900784\n",
      "      - -201430.71700939225\n",
      "      - -200834.14275126776\n",
      "      - -199594.89116431482\n",
      "      - -203287.3484878431\n",
      "      - -208407.8056518799\n",
      "      - -202074.4438912342\n",
      "      - -200363.2362150076\n",
      "      - -200364.0397767051\n",
      "      - -195057.95553914396\n",
      "      - -201637.65237271995\n",
      "      - -196145.42522593556\n",
      "      - -202853.1800340171\n",
      "      - -201107.45141531056\n",
      "      - -198716.94277952853\n",
      "      - -198958.50667144175\n",
      "      - -202742.7122387052\n",
      "      - -198471.5205264199\n",
      "      - -203344.2011314972\n",
      "      - -205811.9626920501\n",
      "      - -200386.6825914831\n",
      "      - -203863.57957352095\n",
      "      - -203861.33066762108\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11708732311821966\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5109545333478167\n",
      "      mean_inference_ms: 1.5836402382486392\n",
      "      mean_raw_obs_processing_ms: 0.16183520456227826\n",
      "  time_since_restore: 1290.8597166538239\n",
      "  time_this_iter_s: 16.424122095108032\n",
      "  time_total_s: 1290.8597166538239\n",
      "  timers:\n",
      "    learn_throughput: 25053.699\n",
      "    learn_time_ms: 2553.874\n",
      "    load_throughput: 532874.738\n",
      "    load_time_ms: 120.073\n",
      "    training_iteration_time_ms: 15419.964\n",
      "    update_time_ms: 4.73\n",
      "  timestamp: 1665743507\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5310672\n",
      "  training_iteration: 83\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:31:52 (running for 00:21:54.67)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    83</td><td style=\"text-align: right;\">         1290.86</td><td style=\"text-align: right;\">5.31067e+06</td><td style=\"text-align: right;\"> -201572</td><td style=\"text-align: right;\">             -195058</td><td style=\"text-align: right;\">             -213826</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:31:57 (running for 00:21:59.67)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    83</td><td style=\"text-align: right;\">         1290.86</td><td style=\"text-align: right;\">5.31067e+06</td><td style=\"text-align: right;\"> -201572</td><td style=\"text-align: right;\">             -195058</td><td style=\"text-align: right;\">             -213826</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:32:02 (running for 00:22:04.68)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    83</td><td style=\"text-align: right;\">         1290.86</td><td style=\"text-align: right;\">5.31067e+06</td><td style=\"text-align: right;\"> -201572</td><td style=\"text-align: right;\">             -195058</td><td style=\"text-align: right;\">             -213826</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 5374656\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 5374656\n",
      "    num_agent_steps_trained: 5374656\n",
      "    num_env_steps_sampled: 5374656\n",
      "    num_env_steps_trained: 5374656\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-32-02\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -195057.95553914396\n",
      "  episode_reward_mean: -201496.97528478503\n",
      "  episode_reward_min: -221611.36277709386\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 5364\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.059065341949463\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.002208181656897068\n",
      "          model: {}\n",
      "          policy_loss: 0.0010320725850760937\n",
      "          total_loss: 10.001167297363281\n",
      "          vf_explained_var: -1.3355165719985962e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 5374656\n",
      "    num_agent_steps_trained: 5374656\n",
      "    num_env_steps_sampled: 5374656\n",
      "    num_env_steps_trained: 5374656\n",
      "  iterations_since_restore: 84\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 5374656\n",
      "  num_agent_steps_trained: 5374656\n",
      "  num_env_steps_sampled: 5374656\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 5374656\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.64999999999999\n",
      "    ram_util_percent: 78.85454545454546\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11708816451315293\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5108299733917613\n",
      "    mean_inference_ms: 1.5841083535875804\n",
      "    mean_raw_obs_processing_ms: 0.16169887541505393\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -195057.95553914396\n",
      "    episode_reward_mean: -201496.97528478503\n",
      "    episode_reward_min: -221611.36277709386\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -204470.63067857656\n",
      "      - -204212.67266998507\n",
      "      - -199569.7810206885\n",
      "      - -200664.03978655435\n",
      "      - -201113.04388941376\n",
      "      - -201098.66788733407\n",
      "      - -202096.31857889978\n",
      "      - -206449.4096424698\n",
      "      - -199431.72960191453\n",
      "      - -206415.6260868898\n",
      "      - -200239.68122681064\n",
      "      - -200041.18757733004\n",
      "      - -197239.89598118595\n",
      "      - -203456.3191211627\n",
      "      - -200553.84089561287\n",
      "      - -201513.98632673215\n",
      "      - -199001.13702600566\n",
      "      - -198494.14197900784\n",
      "      - -201430.71700939225\n",
      "      - -200834.14275126776\n",
      "      - -199594.89116431482\n",
      "      - -203287.3484878431\n",
      "      - -208407.8056518799\n",
      "      - -202074.4438912342\n",
      "      - -200363.2362150076\n",
      "      - -200364.0397767051\n",
      "      - -195057.95553914396\n",
      "      - -201637.65237271995\n",
      "      - -196145.42522593556\n",
      "      - -202853.1800340171\n",
      "      - -201107.45141531056\n",
      "      - -198716.94277952853\n",
      "      - -198958.50667144175\n",
      "      - -202742.7122387052\n",
      "      - -198471.5205264199\n",
      "      - -203344.2011314972\n",
      "      - -205811.9626920501\n",
      "      - -200386.6825914831\n",
      "      - -203863.57957352095\n",
      "      - -203861.33066762108\n",
      "      - -204077.88545965988\n",
      "      - -196136.31561230202\n",
      "      - -213608.66812165815\n",
      "      - -199102.22739187346\n",
      "      - -200695.8595072152\n",
      "      - -196997.8191017877\n",
      "      - -200219.9591304755\n",
      "      - -204725.34492680483\n",
      "      - -201854.2061831672\n",
      "      - -204660.23762148016\n",
      "      - -202488.9329134905\n",
      "      - -206313.2770370019\n",
      "      - -199233.4805675109\n",
      "      - -204536.66328112103\n",
      "      - -200941.34658576123\n",
      "      - -201969.5521577904\n",
      "      - -201160.1016949257\n",
      "      - -200971.2130518253\n",
      "      - -200004.27100426555\n",
      "      - -199807.31308022322\n",
      "      - -201723.65576749653\n",
      "      - -195795.0232980772\n",
      "      - -201919.83050650617\n",
      "      - -198330.336458377\n",
      "      - -198148.15568300628\n",
      "      - -202427.36046992178\n",
      "      - -204072.62692682623\n",
      "      - -199568.6089545994\n",
      "      - -199328.77430394548\n",
      "      - -201005.14640908068\n",
      "      - -200610.0101992005\n",
      "      - -201285.85233578677\n",
      "      - -197794.67669457218\n",
      "      - -199179.52839996817\n",
      "      - -202119.05340549906\n",
      "      - -201396.46472495206\n",
      "      - -203382.526387239\n",
      "      - -200767.77410907965\n",
      "      - -201897.9437976332\n",
      "      - -206881.33383717408\n",
      "      - -198545.08627017675\n",
      "      - -197020.73168543467\n",
      "      - -200901.23738781226\n",
      "      - -200923.35673003976\n",
      "      - -200917.85872019973\n",
      "      - -202777.29985145375\n",
      "      - -198221.50677049693\n",
      "      - -201742.00855584268\n",
      "      - -198685.7136042769\n",
      "      - -204164.08005653202\n",
      "      - -203388.4982558338\n",
      "      - -201360.66382225344\n",
      "      - -195397.63004902255\n",
      "      - -200748.00873836112\n",
      "      - -206242.05856591783\n",
      "      - -201051.4543055123\n",
      "      - -199554.05777574878\n",
      "      - -202800.91100978368\n",
      "      - -221611.36277709386\n",
      "      - -201126.80806381674\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11708816451315293\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5108299733917613\n",
      "      mean_inference_ms: 1.5841083535875804\n",
      "      mean_raw_obs_processing_ms: 0.16169887541505393\n",
      "  time_since_restore: 1306.1239314079285\n",
      "  time_this_iter_s: 15.264214754104614\n",
      "  time_total_s: 1306.1239314079285\n",
      "  timers:\n",
      "    learn_throughput: 25501.556\n",
      "    learn_time_ms: 2509.023\n",
      "    load_throughput: 530390.886\n",
      "    load_time_ms: 120.636\n",
      "    training_iteration_time_ms: 15399.759\n",
      "    update_time_ms: 4.698\n",
      "  timestamp: 1665743522\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5374656\n",
      "  training_iteration: 84\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:32:07 (running for 00:22:09.86)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    84</td><td style=\"text-align: right;\">         1306.12</td><td style=\"text-align: right;\">5.37466e+06</td><td style=\"text-align: right;\"> -201497</td><td style=\"text-align: right;\">             -195058</td><td style=\"text-align: right;\">             -221611</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:32:12 (running for 00:22:15.22)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    84</td><td style=\"text-align: right;\">         1306.12</td><td style=\"text-align: right;\">5.37466e+06</td><td style=\"text-align: right;\"> -201497</td><td style=\"text-align: right;\">             -195058</td><td style=\"text-align: right;\">             -221611</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:32:17 (running for 00:22:20.23)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    84</td><td style=\"text-align: right;\">         1306.12</td><td style=\"text-align: right;\">5.37466e+06</td><td style=\"text-align: right;\"> -201497</td><td style=\"text-align: right;\">             -195058</td><td style=\"text-align: right;\">             -221611</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 5438640\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 5438640\n",
      "    num_agent_steps_trained: 5438640\n",
      "    num_env_steps_sampled: 5438640\n",
      "    num_env_steps_trained: 5438640\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-32-19\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -194091.68142748435\n",
      "  episode_reward_mean: -201011.30953872076\n",
      "  episode_reward_min: -221611.36277709386\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 5436\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.055572509765625\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0021894818637520075\n",
      "          model: {}\n",
      "          policy_loss: 0.005966085009276867\n",
      "          total_loss: 10.006097793579102\n",
      "          vf_explained_var: -1.8949691593661555e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 5438640\n",
      "    num_agent_steps_trained: 5438640\n",
      "    num_env_steps_sampled: 5438640\n",
      "    num_env_steps_trained: 5438640\n",
      "  iterations_since_restore: 85\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 5438640\n",
      "  num_agent_steps_trained: 5438640\n",
      "  num_env_steps_sampled: 5438640\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 5438640\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 78.62272727272727\n",
      "    ram_util_percent: 78.8818181818182\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11726615880078002\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5108863775687943\n",
      "    mean_inference_ms: 1.5865373361136503\n",
      "    mean_raw_obs_processing_ms: 0.16170778767599578\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -194091.68142748435\n",
      "    episode_reward_mean: -201011.30953872076\n",
      "    episode_reward_min: -221611.36277709386\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -197794.67669457218\n",
      "      - -199179.52839996817\n",
      "      - -202119.05340549906\n",
      "      - -201396.46472495206\n",
      "      - -203382.526387239\n",
      "      - -200767.77410907965\n",
      "      - -201897.9437976332\n",
      "      - -206881.33383717408\n",
      "      - -198545.08627017675\n",
      "      - -197020.73168543467\n",
      "      - -200901.23738781226\n",
      "      - -200923.35673003976\n",
      "      - -200917.85872019973\n",
      "      - -202777.29985145375\n",
      "      - -198221.50677049693\n",
      "      - -201742.00855584268\n",
      "      - -198685.7136042769\n",
      "      - -204164.08005653202\n",
      "      - -203388.4982558338\n",
      "      - -201360.66382225344\n",
      "      - -195397.63004902255\n",
      "      - -200748.00873836112\n",
      "      - -206242.05856591783\n",
      "      - -201051.4543055123\n",
      "      - -199554.05777574878\n",
      "      - -202800.91100978368\n",
      "      - -221611.36277709386\n",
      "      - -201126.80806381674\n",
      "      - -202932.73843453842\n",
      "      - -199653.4286294644\n",
      "      - -202315.58131864472\n",
      "      - -199414.33419566663\n",
      "      - -199581.81920139756\n",
      "      - -201558.38276629607\n",
      "      - -195527.03673094665\n",
      "      - -200900.34535301657\n",
      "      - -198756.86420141708\n",
      "      - -197940.96185770386\n",
      "      - -198555.84719511503\n",
      "      - -204089.32130962427\n",
      "      - -201112.60328549196\n",
      "      - -201823.58835043226\n",
      "      - -200579.1583994304\n",
      "      - -200910.25090411084\n",
      "      - -203371.68110535588\n",
      "      - -199396.9705183536\n",
      "      - -198163.2937394461\n",
      "      - -200680.7939802371\n",
      "      - -197317.95374712854\n",
      "      - -201334.34167933415\n",
      "      - -195923.2012264767\n",
      "      - -200331.19845851365\n",
      "      - -200745.28414396994\n",
      "      - -215727.03088009174\n",
      "      - -199594.87281365538\n",
      "      - -197937.58056605016\n",
      "      - -203681.51871722087\n",
      "      - -200068.15761324397\n",
      "      - -198498.805628482\n",
      "      - -204078.5638248807\n",
      "      - -203065.32738436677\n",
      "      - -198360.14507643614\n",
      "      - -202722.4271841864\n",
      "      - -201664.69744571002\n",
      "      - -203005.56337727926\n",
      "      - -199187.89369616954\n",
      "      - -194091.68142748435\n",
      "      - -201638.155719761\n",
      "      - -202007.95123466064\n",
      "      - -204785.13709446753\n",
      "      - -201763.79330313846\n",
      "      - -205233.52229177172\n",
      "      - -200259.70885412456\n",
      "      - -200519.5418521465\n",
      "      - -204761.51667655204\n",
      "      - -200001.8356525317\n",
      "      - -200334.5977997011\n",
      "      - -202532.8243005764\n",
      "      - -201265.57277532126\n",
      "      - -198178.85033630056\n",
      "      - -198714.27345550605\n",
      "      - -200659.6095737496\n",
      "      - -198179.3871919136\n",
      "      - -203120.01032562577\n",
      "      - -201924.45627003637\n",
      "      - -199282.52677702357\n",
      "      - -197809.82216910148\n",
      "      - -195870.64781375052\n",
      "      - -195806.63881510778\n",
      "      - -208454.53235387165\n",
      "      - -200281.54043634547\n",
      "      - -199946.83295103855\n",
      "      - -196603.7879121434\n",
      "      - -198835.5078612582\n",
      "      - -205651.12211089017\n",
      "      - -202626.71587546766\n",
      "      - -199363.39611633224\n",
      "      - -201491.9072369346\n",
      "      - -200093.16865361232\n",
      "      - -197931.18136222282\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11726615880078002\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5108863775687943\n",
      "      mean_inference_ms: 1.5865373361136503\n",
      "      mean_raw_obs_processing_ms: 0.16170778767599578\n",
      "  time_since_restore: 1322.564642906189\n",
      "  time_this_iter_s: 16.440711498260498\n",
      "  time_total_s: 1322.564642906189\n",
      "  timers:\n",
      "    learn_throughput: 25427.272\n",
      "    learn_time_ms: 2516.353\n",
      "    load_throughput: 531513.932\n",
      "    load_time_ms: 120.381\n",
      "    training_iteration_time_ms: 15555.946\n",
      "    update_time_ms: 4.707\n",
      "  timestamp: 1665743539\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5438640\n",
      "  training_iteration: 85\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:32:24 (running for 00:22:26.45)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    85</td><td style=\"text-align: right;\">         1322.56</td><td style=\"text-align: right;\">5.43864e+06</td><td style=\"text-align: right;\"> -201011</td><td style=\"text-align: right;\">             -194092</td><td style=\"text-align: right;\">             -221611</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:32:29 (running for 00:22:31.46)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    85</td><td style=\"text-align: right;\">         1322.56</td><td style=\"text-align: right;\">5.43864e+06</td><td style=\"text-align: right;\"> -201011</td><td style=\"text-align: right;\">             -194092</td><td style=\"text-align: right;\">             -221611</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:32:34 (running for 00:22:36.47)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    85</td><td style=\"text-align: right;\">         1322.56</td><td style=\"text-align: right;\">5.43864e+06</td><td style=\"text-align: right;\"> -201011</td><td style=\"text-align: right;\">             -194092</td><td style=\"text-align: right;\">             -221611</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 5502624\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 5502624\n",
      "    num_agent_steps_trained: 5502624\n",
      "    num_env_steps_sampled: 5502624\n",
      "    num_env_steps_trained: 5502624\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-32-34\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -194091.68142748435\n",
      "  episode_reward_mean: -200901.06695715763\n",
      "  episode_reward_min: -208997.92061321015\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 5496\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.054316520690918\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0021568210795521736\n",
      "          model: {}\n",
      "          policy_loss: 0.0023503247648477554\n",
      "          total_loss: 10.002476692199707\n",
      "          vf_explained_var: -3.1958334147930145e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 5502624\n",
      "    num_agent_steps_trained: 5502624\n",
      "    num_env_steps_sampled: 5502624\n",
      "    num_env_steps_trained: 5502624\n",
      "  iterations_since_restore: 86\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 5502624\n",
      "  num_agent_steps_trained: 5502624\n",
      "  num_env_steps_sampled: 5502624\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 5502624\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.10869565217392\n",
      "    ram_util_percent: 78.90000000000003\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11718873488089898\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5109086423053814\n",
      "    mean_inference_ms: 1.5861355125651802\n",
      "    mean_raw_obs_processing_ms: 0.16196554624575402\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -194091.68142748435\n",
      "    episode_reward_mean: -200901.06695715763\n",
      "    episode_reward_min: -208997.92061321015\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -203065.32738436677\n",
      "      - -198360.14507643614\n",
      "      - -202722.4271841864\n",
      "      - -201664.69744571002\n",
      "      - -203005.56337727926\n",
      "      - -199187.89369616954\n",
      "      - -194091.68142748435\n",
      "      - -201638.155719761\n",
      "      - -202007.95123466064\n",
      "      - -204785.13709446753\n",
      "      - -201763.79330313846\n",
      "      - -205233.52229177172\n",
      "      - -200259.70885412456\n",
      "      - -200519.5418521465\n",
      "      - -204761.51667655204\n",
      "      - -200001.8356525317\n",
      "      - -200334.5977997011\n",
      "      - -202532.8243005764\n",
      "      - -201265.57277532126\n",
      "      - -198178.85033630056\n",
      "      - -198714.27345550605\n",
      "      - -200659.6095737496\n",
      "      - -198179.3871919136\n",
      "      - -203120.01032562577\n",
      "      - -201924.45627003637\n",
      "      - -199282.52677702357\n",
      "      - -197809.82216910148\n",
      "      - -195870.64781375052\n",
      "      - -195806.63881510778\n",
      "      - -208454.53235387165\n",
      "      - -200281.54043634547\n",
      "      - -199946.83295103855\n",
      "      - -196603.7879121434\n",
      "      - -198835.5078612582\n",
      "      - -205651.12211089017\n",
      "      - -202626.71587546766\n",
      "      - -199363.39611633224\n",
      "      - -201491.9072369346\n",
      "      - -200093.16865361232\n",
      "      - -197931.18136222282\n",
      "      - -199894.1869110345\n",
      "      - -197487.89446238984\n",
      "      - -200407.4265912854\n",
      "      - -207229.66493864227\n",
      "      - -197914.0306695115\n",
      "      - -197805.48431599844\n",
      "      - -194179.86563115826\n",
      "      - -196992.43289823516\n",
      "      - -204111.0190672403\n",
      "      - -198616.96920315552\n",
      "      - -202113.13586333176\n",
      "      - -202946.6875999008\n",
      "      - -199534.30733462414\n",
      "      - -202367.77599797107\n",
      "      - -198030.5299163028\n",
      "      - -202666.39597728717\n",
      "      - -200698.59314592287\n",
      "      - -202680.93578425387\n",
      "      - -200670.1193531757\n",
      "      - -199788.7747587533\n",
      "      - -203401.5273712145\n",
      "      - -202353.8352780852\n",
      "      - -201900.76166915204\n",
      "      - -205242.24793741448\n",
      "      - -201838.86448648965\n",
      "      - -199879.21800691\n",
      "      - -202804.52475289107\n",
      "      - -203932.5890558123\n",
      "      - -199854.96932785082\n",
      "      - -198435.47501146307\n",
      "      - -200156.15529476348\n",
      "      - -200719.5615065906\n",
      "      - -200788.4871168082\n",
      "      - -204507.90997784468\n",
      "      - -202585.64423204787\n",
      "      - -199174.52396283168\n",
      "      - -198531.6721725579\n",
      "      - -200188.2857521102\n",
      "      - -202359.8370517063\n",
      "      - -201092.21676282957\n",
      "      - -196783.7251836341\n",
      "      - -208997.92061321015\n",
      "      - -200497.2130671166\n",
      "      - -201233.25987821448\n",
      "      - -200954.71080881692\n",
      "      - -205622.07305858206\n",
      "      - -198645.01164374425\n",
      "      - -203011.81526007803\n",
      "      - -200665.0289128305\n",
      "      - -197616.86767045574\n",
      "      - -205024.4128184374\n",
      "      - -197277.14698594948\n",
      "      - -200886.1022680001\n",
      "      - -202380.7473481194\n",
      "      - -200031.73572284658\n",
      "      - -199693.41353402444\n",
      "      - -199776.08527876643\n",
      "      - -201396.51714792522\n",
      "      - -203666.4392754029\n",
      "      - -202034.12334744306\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11718873488089898\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5109086423053814\n",
      "      mean_inference_ms: 1.5861355125651802\n",
      "      mean_raw_obs_processing_ms: 0.16196554624575402\n",
      "  time_since_restore: 1338.2702128887177\n",
      "  time_this_iter_s: 15.705569982528687\n",
      "  time_total_s: 1338.2702128887177\n",
      "  timers:\n",
      "    learn_throughput: 25868.948\n",
      "    learn_time_ms: 2473.39\n",
      "    load_throughput: 533698.456\n",
      "    load_time_ms: 119.888\n",
      "    training_iteration_time_ms: 15544.898\n",
      "    update_time_ms: 4.943\n",
      "  timestamp: 1665743554\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5502624\n",
      "  training_iteration: 86\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:32:39 (running for 00:22:42.08)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    86</td><td style=\"text-align: right;\">         1338.27</td><td style=\"text-align: right;\">5.50262e+06</td><td style=\"text-align: right;\"> -200901</td><td style=\"text-align: right;\">             -194092</td><td style=\"text-align: right;\">             -208998</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:32:45 (running for 00:22:47.57)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    86</td><td style=\"text-align: right;\">         1338.27</td><td style=\"text-align: right;\">5.50262e+06</td><td style=\"text-align: right;\"> -200901</td><td style=\"text-align: right;\">             -194092</td><td style=\"text-align: right;\">             -208998</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:32:50 (running for 00:22:52.57)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    86</td><td style=\"text-align: right;\">         1338.27</td><td style=\"text-align: right;\">5.50262e+06</td><td style=\"text-align: right;\"> -200901</td><td style=\"text-align: right;\">             -194092</td><td style=\"text-align: right;\">             -208998</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 5566608\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 5566608\n",
      "    num_agent_steps_trained: 5566608\n",
      "    num_env_steps_sampled: 5566608\n",
      "    num_env_steps_trained: 5566608\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-32-50\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -192988.35553517897\n",
      "  episode_reward_mean: -200488.17914484377\n",
      "  episode_reward_min: -208997.92061321015\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 5556\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.043914318084717\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0016257179668173194\n",
      "          model: {}\n",
      "          policy_loss: 0.0022464680951088667\n",
      "          total_loss: 10.002266883850098\n",
      "          vf_explained_var: -3.2901764370762976e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 5566608\n",
      "    num_agent_steps_trained: 5566608\n",
      "    num_env_steps_sampled: 5566608\n",
      "    num_env_steps_trained: 5566608\n",
      "  iterations_since_restore: 87\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 5566608\n",
      "  num_agent_steps_trained: 5566608\n",
      "  num_env_steps_sampled: 5566608\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 5566608\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.3409090909091\n",
      "    ram_util_percent: 78.90000000000003\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11718632001613041\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5108485302184052\n",
      "    mean_inference_ms: 1.5857492865973604\n",
      "    mean_raw_obs_processing_ms: 0.16182223185625821\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -192988.35553517897\n",
      "    episode_reward_mean: -200488.17914484377\n",
      "    episode_reward_min: -208997.92061321015\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -203401.5273712145\n",
      "      - -202353.8352780852\n",
      "      - -201900.76166915204\n",
      "      - -205242.24793741448\n",
      "      - -201838.86448648965\n",
      "      - -199879.21800691\n",
      "      - -202804.52475289107\n",
      "      - -203932.5890558123\n",
      "      - -199854.96932785082\n",
      "      - -198435.47501146307\n",
      "      - -200156.15529476348\n",
      "      - -200719.5615065906\n",
      "      - -200788.4871168082\n",
      "      - -204507.90997784468\n",
      "      - -202585.64423204787\n",
      "      - -199174.52396283168\n",
      "      - -198531.6721725579\n",
      "      - -200188.2857521102\n",
      "      - -202359.8370517063\n",
      "      - -201092.21676282957\n",
      "      - -196783.7251836341\n",
      "      - -208997.92061321015\n",
      "      - -200497.2130671166\n",
      "      - -201233.25987821448\n",
      "      - -200954.71080881692\n",
      "      - -205622.07305858206\n",
      "      - -198645.01164374425\n",
      "      - -203011.81526007803\n",
      "      - -200665.0289128305\n",
      "      - -197616.86767045574\n",
      "      - -205024.4128184374\n",
      "      - -197277.14698594948\n",
      "      - -200886.1022680001\n",
      "      - -202380.7473481194\n",
      "      - -200031.73572284658\n",
      "      - -199693.41353402444\n",
      "      - -199776.08527876643\n",
      "      - -201396.51714792522\n",
      "      - -203666.4392754029\n",
      "      - -202034.12334744306\n",
      "      - -200248.78543296244\n",
      "      - -199336.30432234667\n",
      "      - -200870.57649510927\n",
      "      - -200345.82625909202\n",
      "      - -197956.00351147252\n",
      "      - -200097.28532826327\n",
      "      - -199439.003785323\n",
      "      - -201707.8673660236\n",
      "      - -199557.03942622355\n",
      "      - -205057.45591936467\n",
      "      - -198981.36527731782\n",
      "      - -198550.5362653369\n",
      "      - -197111.06848284614\n",
      "      - -196850.22547807827\n",
      "      - -199523.04636934106\n",
      "      - -199097.72040774114\n",
      "      - -200583.7200964496\n",
      "      - -199237.3620410613\n",
      "      - -198668.11110282107\n",
      "      - -202443.46306469443\n",
      "      - -208398.1973926231\n",
      "      - -198243.79226144557\n",
      "      - -199029.79289196123\n",
      "      - -200788.59121345103\n",
      "      - -194669.97552912676\n",
      "      - -200991.36676506113\n",
      "      - -198531.8363142393\n",
      "      - -200883.61111093315\n",
      "      - -198205.0305512162\n",
      "      - -202423.42968730966\n",
      "      - -200097.75511620825\n",
      "      - -201191.36631746896\n",
      "      - -201498.24292246127\n",
      "      - -202100.12388562114\n",
      "      - -200816.711404976\n",
      "      - -203727.43100408334\n",
      "      - -194062.78081537262\n",
      "      - -198385.88423569614\n",
      "      - -197490.80595194647\n",
      "      - -203117.35130873873\n",
      "      - -203777.5892886329\n",
      "      - -196754.8702011394\n",
      "      - -196157.59080885342\n",
      "      - -202190.71670042654\n",
      "      - -199290.68775573306\n",
      "      - -200202.2998950284\n",
      "      - -198233.59468820834\n",
      "      - -203081.10107995747\n",
      "      - -199526.97201130257\n",
      "      - -199045.18093274633\n",
      "      - -200130.840997149\n",
      "      - -198399.52179830946\n",
      "      - -198465.69037769723\n",
      "      - -201135.20736273454\n",
      "      - -204301.89659897715\n",
      "      - -202252.61144546396\n",
      "      - -199348.37727428155\n",
      "      - -192988.35553517897\n",
      "      - -197669.33939890642\n",
      "      - -199605.970670868\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11718632001613041\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5108485302184052\n",
      "      mean_inference_ms: 1.5857492865973604\n",
      "      mean_raw_obs_processing_ms: 0.16182223185625821\n",
      "  time_since_restore: 1353.7916090488434\n",
      "  time_this_iter_s: 15.521396160125732\n",
      "  time_total_s: 1353.7916090488434\n",
      "  timers:\n",
      "    learn_throughput: 25868.486\n",
      "    learn_time_ms: 2473.434\n",
      "    load_throughput: 535501.827\n",
      "    load_time_ms: 119.484\n",
      "    training_iteration_time_ms: 15600.576\n",
      "    update_time_ms: 4.811\n",
      "  timestamp: 1665743570\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5566608\n",
      "  training_iteration: 87\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:32:55 (running for 00:22:57.75)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    87</td><td style=\"text-align: right;\">         1353.79</td><td style=\"text-align: right;\">5.56661e+06</td><td style=\"text-align: right;\"> -200488</td><td style=\"text-align: right;\">             -192988</td><td style=\"text-align: right;\">             -208998</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:33:00 (running for 00:23:02.75)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    87</td><td style=\"text-align: right;\">         1353.79</td><td style=\"text-align: right;\">5.56661e+06</td><td style=\"text-align: right;\"> -200488</td><td style=\"text-align: right;\">             -192988</td><td style=\"text-align: right;\">             -208998</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:33:05 (running for 00:23:07.76)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    87</td><td style=\"text-align: right;\">         1353.79</td><td style=\"text-align: right;\">5.56661e+06</td><td style=\"text-align: right;\"> -200488</td><td style=\"text-align: right;\">             -192988</td><td style=\"text-align: right;\">             -208998</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 5630592\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 5630592\n",
      "    num_agent_steps_trained: 5630592\n",
      "    num_env_steps_sampled: 5630592\n",
      "    num_env_steps_trained: 5630592\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-33-06\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -192988.35553517897\n",
      "  episode_reward_mean: -199419.4541522317\n",
      "  episode_reward_min: -207235.46835697992\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 5628\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0375723838806152\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.001982492860406637\n",
      "          model: {}\n",
      "          policy_loss: 0.005671824794262648\n",
      "          total_loss: 10.005764961242676\n",
      "          vf_explained_var: -4.597352017299272e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 5630592\n",
      "    num_agent_steps_trained: 5630592\n",
      "    num_env_steps_sampled: 5630592\n",
      "    num_env_steps_trained: 5630592\n",
      "  iterations_since_restore: 88\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 5630592\n",
      "  num_agent_steps_trained: 5630592\n",
      "  num_env_steps_sampled: 5630592\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 5630592\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.86190476190477\n",
      "    ram_util_percent: 78.90000000000002\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11733503558731498\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5109876459769279\n",
      "    mean_inference_ms: 1.5867882986402577\n",
      "    mean_raw_obs_processing_ms: 0.1617616389667278\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -192988.35553517897\n",
      "    episode_reward_mean: -199419.4541522317\n",
      "    episode_reward_min: -207235.46835697992\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -201498.24292246127\n",
      "      - -202100.12388562114\n",
      "      - -200816.711404976\n",
      "      - -203727.43100408334\n",
      "      - -194062.78081537262\n",
      "      - -198385.88423569614\n",
      "      - -197490.80595194647\n",
      "      - -203117.35130873873\n",
      "      - -203777.5892886329\n",
      "      - -196754.8702011394\n",
      "      - -196157.59080885342\n",
      "      - -202190.71670042654\n",
      "      - -199290.68775573306\n",
      "      - -200202.2998950284\n",
      "      - -198233.59468820834\n",
      "      - -203081.10107995747\n",
      "      - -199526.97201130257\n",
      "      - -199045.18093274633\n",
      "      - -200130.840997149\n",
      "      - -198399.52179830946\n",
      "      - -198465.69037769723\n",
      "      - -201135.20736273454\n",
      "      - -204301.89659897715\n",
      "      - -202252.61144546396\n",
      "      - -199348.37727428155\n",
      "      - -192988.35553517897\n",
      "      - -197669.33939890642\n",
      "      - -199605.970670868\n",
      "      - -197449.6772910501\n",
      "      - -199590.04281713453\n",
      "      - -201389.14928108433\n",
      "      - -200944.65989023627\n",
      "      - -206330.2683024417\n",
      "      - -199318.95774018567\n",
      "      - -196768.3075223645\n",
      "      - -199982.79198236053\n",
      "      - -195927.54026421768\n",
      "      - -201822.19264569224\n",
      "      - -200518.5475180728\n",
      "      - -198777.9316866858\n",
      "      - -207235.46835697992\n",
      "      - -197855.2962307971\n",
      "      - -197022.22587215804\n",
      "      - -199748.07730301537\n",
      "      - -197616.8255459414\n",
      "      - -197234.88207377167\n",
      "      - -198786.1098284268\n",
      "      - -201076.61335419863\n",
      "      - -199216.50792158482\n",
      "      - -202353.0385687074\n",
      "      - -199097.42152463456\n",
      "      - -203227.41664771686\n",
      "      - -197805.82680288708\n",
      "      - -197779.92207636035\n",
      "      - -200519.52183776538\n",
      "      - -203616.36658251059\n",
      "      - -198632.90255191454\n",
      "      - -199094.24939836448\n",
      "      - -200454.294283779\n",
      "      - -200151.42043878036\n",
      "      - -197335.6941514972\n",
      "      - -198150.5593143457\n",
      "      - -194813.71354670986\n",
      "      - -204278.88346160512\n",
      "      - -201187.49606640523\n",
      "      - -199122.82140040226\n",
      "      - -196375.3308102878\n",
      "      - -194367.24266126033\n",
      "      - -198178.10600244784\n",
      "      - -195785.03595914625\n",
      "      - -195127.69386220348\n",
      "      - -198144.969246792\n",
      "      - -204488.91030437537\n",
      "      - -201492.98219288205\n",
      "      - -200134.0891557732\n",
      "      - -200968.36760344764\n",
      "      - -197253.6468489669\n",
      "      - -200799.48931819407\n",
      "      - -197323.062591794\n",
      "      - -197539.67094897592\n",
      "      - -201518.6936908099\n",
      "      - -198452.962233649\n",
      "      - -194692.33148538726\n",
      "      - -201846.52922439203\n",
      "      - -195425.85945172177\n",
      "      - -202080.34210853823\n",
      "      - -196874.02350923425\n",
      "      - -196383.0378530651\n",
      "      - -199646.30470538972\n",
      "      - -200089.2149123301\n",
      "      - -202033.98974086874\n",
      "      - -201669.7672983933\n",
      "      - -201400.79033236808\n",
      "      - -197954.5851848515\n",
      "      - -199501.73190787534\n",
      "      - -197341.72392947023\n",
      "      - -197214.98666261302\n",
      "      - -197762.77457457024\n",
      "      - -197532.45676315355\n",
      "      - -198553.34371466865\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11733503558731498\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5109876459769279\n",
      "      mean_inference_ms: 1.5867882986402577\n",
      "      mean_raw_obs_processing_ms: 0.1617616389667278\n",
      "  time_since_restore: 1369.6439099311829\n",
      "  time_this_iter_s: 15.852300882339478\n",
      "  time_total_s: 1369.6439099311829\n",
      "  timers:\n",
      "    learn_throughput: 25889.494\n",
      "    learn_time_ms: 2471.427\n",
      "    load_throughput: 536688.607\n",
      "    load_time_ms: 119.22\n",
      "    training_iteration_time_ms: 15656.709\n",
      "    update_time_ms: 4.876\n",
      "  timestamp: 1665743586\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5630592\n",
      "  training_iteration: 88\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:33:11 (running for 00:23:13.51)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    88</td><td style=\"text-align: right;\">         1369.64</td><td style=\"text-align: right;\">5.63059e+06</td><td style=\"text-align: right;\"> -199419</td><td style=\"text-align: right;\">             -192988</td><td style=\"text-align: right;\">             -207235</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:33:16 (running for 00:23:18.98)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    88</td><td style=\"text-align: right;\">         1369.64</td><td style=\"text-align: right;\">5.63059e+06</td><td style=\"text-align: right;\"> -199419</td><td style=\"text-align: right;\">             -192988</td><td style=\"text-align: right;\">             -207235</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:33:21 (running for 00:23:23.99)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    88</td><td style=\"text-align: right;\">         1369.64</td><td style=\"text-align: right;\">5.63059e+06</td><td style=\"text-align: right;\"> -199419</td><td style=\"text-align: right;\">             -192988</td><td style=\"text-align: right;\">             -207235</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 5694576\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 5694576\n",
      "    num_agent_steps_trained: 5694576\n",
      "    num_env_steps_sampled: 5694576\n",
      "    num_env_steps_trained: 5694576\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-33-21\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -194367.24266126033\n",
      "  episode_reward_mean: -198898.0163877001\n",
      "  episode_reward_min: -204651.90629439885\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 5688\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0394766330718994\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0017254347912967205\n",
      "          model: {}\n",
      "          policy_loss: 0.0024262634105980396\n",
      "          total_loss: 10.00246810913086\n",
      "          vf_explained_var: -4.047613856528187e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 5694576\n",
      "    num_agent_steps_trained: 5694576\n",
      "    num_env_steps_sampled: 5694576\n",
      "    num_env_steps_trained: 5694576\n",
      "  iterations_since_restore: 89\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 5694576\n",
      "  num_agent_steps_trained: 5694576\n",
      "  num_env_steps_sampled: 5694576\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 5694576\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.23913043478261\n",
      "    ram_util_percent: 78.90000000000003\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11723963081789184\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5110631252868565\n",
      "    mean_inference_ms: 1.586075519230315\n",
      "    mean_raw_obs_processing_ms: 0.16197386593066793\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -194367.24266126033\n",
      "    episode_reward_mean: -198898.0163877001\n",
      "    episode_reward_min: -204651.90629439885\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -197335.6941514972\n",
      "      - -198150.5593143457\n",
      "      - -194813.71354670986\n",
      "      - -204278.88346160512\n",
      "      - -201187.49606640523\n",
      "      - -199122.82140040226\n",
      "      - -196375.3308102878\n",
      "      - -194367.24266126033\n",
      "      - -198178.10600244784\n",
      "      - -195785.03595914625\n",
      "      - -195127.69386220348\n",
      "      - -198144.969246792\n",
      "      - -204488.91030437537\n",
      "      - -201492.98219288205\n",
      "      - -200134.0891557732\n",
      "      - -200968.36760344764\n",
      "      - -197253.6468489669\n",
      "      - -200799.48931819407\n",
      "      - -197323.062591794\n",
      "      - -197539.67094897592\n",
      "      - -201518.6936908099\n",
      "      - -198452.962233649\n",
      "      - -194692.33148538726\n",
      "      - -201846.52922439203\n",
      "      - -195425.85945172177\n",
      "      - -202080.34210853823\n",
      "      - -196874.02350923425\n",
      "      - -196383.0378530651\n",
      "      - -199646.30470538972\n",
      "      - -200089.2149123301\n",
      "      - -202033.98974086874\n",
      "      - -201669.7672983933\n",
      "      - -201400.79033236808\n",
      "      - -197954.5851848515\n",
      "      - -199501.73190787534\n",
      "      - -197341.72392947023\n",
      "      - -197214.98666261302\n",
      "      - -197762.77457457024\n",
      "      - -197532.45676315355\n",
      "      - -198553.34371466865\n",
      "      - -197325.6010455139\n",
      "      - -199498.418309868\n",
      "      - -197358.42643483335\n",
      "      - -197665.49876728805\n",
      "      - -199526.41235636172\n",
      "      - -199062.5223102148\n",
      "      - -198706.21709098294\n",
      "      - -197629.4299959004\n",
      "      - -197070.4109280338\n",
      "      - -198143.11731874692\n",
      "      - -199755.84502155436\n",
      "      - -201121.467492981\n",
      "      - -200459.307538862\n",
      "      - -197814.98585471942\n",
      "      - -202515.7143555411\n",
      "      - -195515.30215396397\n",
      "      - -203121.47569556301\n",
      "      - -197135.1162028856\n",
      "      - -197303.1680347835\n",
      "      - -197410.61744566116\n",
      "      - -197937.21290072455\n",
      "      - -197939.21974345227\n",
      "      - -195382.53977011394\n",
      "      - -196391.21394791573\n",
      "      - -197918.3411579777\n",
      "      - -197043.29668302476\n",
      "      - -198106.53047469407\n",
      "      - -196466.7039661778\n",
      "      - -199565.98209866573\n",
      "      - -200354.66405189395\n",
      "      - -195792.81617558925\n",
      "      - -194892.81939629483\n",
      "      - -200814.9551574421\n",
      "      - -200541.2010200462\n",
      "      - -198430.3842898361\n",
      "      - -203886.93929232046\n",
      "      - -204651.90629439885\n",
      "      - -197250.45545681627\n",
      "      - -198974.06073454834\n",
      "      - -196636.99979599676\n",
      "      - -198787.4324886354\n",
      "      - -197564.4182058019\n",
      "      - -196780.36902681645\n",
      "      - -198394.725236263\n",
      "      - -199129.2989824317\n",
      "      - -202137.18514164852\n",
      "      - -203141.503477453\n",
      "      - -202912.39255299716\n",
      "      - -200030.18912273293\n",
      "      - -198484.94815502779\n",
      "      - -198529.69006725546\n",
      "      - -202662.13132028453\n",
      "      - -199737.1262772735\n",
      "      - -200792.3710777971\n",
      "      - -200596.88480119672\n",
      "      - -200107.88790799674\n",
      "      - -194868.76147979108\n",
      "      - -198769.99054264015\n",
      "      - -198328.122677508\n",
      "      - -204085.69873540796\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11723963081789184\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5110631252868565\n",
      "      mean_inference_ms: 1.586075519230315\n",
      "      mean_raw_obs_processing_ms: 0.16197386593066793\n",
      "  time_since_restore: 1385.1219623088837\n",
      "  time_this_iter_s: 15.478052377700806\n",
      "  time_total_s: 1385.1219623088837\n",
      "  timers:\n",
      "    learn_throughput: 25924.475\n",
      "    learn_time_ms: 2468.092\n",
      "    load_throughput: 536626.364\n",
      "    load_time_ms: 119.234\n",
      "    training_iteration_time_ms: 15707.268\n",
      "    update_time_ms: 4.682\n",
      "  timestamp: 1665743601\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5694576\n",
      "  training_iteration: 89\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:33:26 (running for 00:23:29.13)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    89</td><td style=\"text-align: right;\">         1385.12</td><td style=\"text-align: right;\">5.69458e+06</td><td style=\"text-align: right;\"> -198898</td><td style=\"text-align: right;\">             -194367</td><td style=\"text-align: right;\">             -204652</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:33:31 (running for 00:23:34.13)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    89</td><td style=\"text-align: right;\">         1385.12</td><td style=\"text-align: right;\">5.69458e+06</td><td style=\"text-align: right;\"> -198898</td><td style=\"text-align: right;\">             -194367</td><td style=\"text-align: right;\">             -204652</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:33:37 (running for 00:23:39.40)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    89</td><td style=\"text-align: right;\">         1385.12</td><td style=\"text-align: right;\">5.69458e+06</td><td style=\"text-align: right;\"> -198898</td><td style=\"text-align: right;\">             -194367</td><td style=\"text-align: right;\">             -204652</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 5758560\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 5758560\n",
      "    num_agent_steps_trained: 5758560\n",
      "    num_env_steps_sampled: 5758560\n",
      "    num_env_steps_trained: 5758560\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-33-37\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -194595.36176408423\n",
      "  episode_reward_mean: -199700.69465492442\n",
      "  episode_reward_min: -209327.0679408759\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 5748\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0456252098083496\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0021726470440626144\n",
      "          model: {}\n",
      "          policy_loss: -0.004090239759534597\n",
      "          total_loss: 9.996039390563965\n",
      "          vf_explained_var: -6.350186936288083e-07\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 5758560\n",
      "    num_agent_steps_trained: 5758560\n",
      "    num_env_steps_sampled: 5758560\n",
      "    num_env_steps_trained: 5758560\n",
      "  iterations_since_restore: 90\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 5758560\n",
      "  num_agent_steps_trained: 5758560\n",
      "  num_env_steps_sampled: 5758560\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 5758560\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 78.43636363636362\n",
      "    ram_util_percent: 78.90000000000003\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11719842137011587\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5109239697540826\n",
      "    mean_inference_ms: 1.586267535120105\n",
      "    mean_raw_obs_processing_ms: 0.16188736098426673\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -194595.36176408423\n",
      "    episode_reward_mean: -199700.69465492442\n",
      "    episode_reward_min: -209327.0679408759\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -197937.21290072455\n",
      "      - -197939.21974345227\n",
      "      - -195382.53977011394\n",
      "      - -196391.21394791573\n",
      "      - -197918.3411579777\n",
      "      - -197043.29668302476\n",
      "      - -198106.53047469407\n",
      "      - -196466.7039661778\n",
      "      - -199565.98209866573\n",
      "      - -200354.66405189395\n",
      "      - -195792.81617558925\n",
      "      - -194892.81939629483\n",
      "      - -200814.9551574421\n",
      "      - -200541.2010200462\n",
      "      - -198430.3842898361\n",
      "      - -203886.93929232046\n",
      "      - -204651.90629439885\n",
      "      - -197250.45545681627\n",
      "      - -198974.06073454834\n",
      "      - -196636.99979599676\n",
      "      - -198787.4324886354\n",
      "      - -197564.4182058019\n",
      "      - -196780.36902681645\n",
      "      - -198394.725236263\n",
      "      - -199129.2989824317\n",
      "      - -202137.18514164852\n",
      "      - -203141.503477453\n",
      "      - -202912.39255299716\n",
      "      - -200030.18912273293\n",
      "      - -198484.94815502779\n",
      "      - -198529.69006725546\n",
      "      - -202662.13132028453\n",
      "      - -199737.1262772735\n",
      "      - -200792.3710777971\n",
      "      - -200596.88480119672\n",
      "      - -200107.88790799674\n",
      "      - -194868.76147979108\n",
      "      - -198769.99054264015\n",
      "      - -198328.122677508\n",
      "      - -204085.69873540796\n",
      "      - -202731.6994592178\n",
      "      - -201272.14334853925\n",
      "      - -203033.61724206444\n",
      "      - -198366.36725123678\n",
      "      - -207144.64523767482\n",
      "      - -198613.47957684833\n",
      "      - -209327.0679408759\n",
      "      - -200602.38605708597\n",
      "      - -199286.6490089905\n",
      "      - -200211.75601360714\n",
      "      - -205115.77442964917\n",
      "      - -197886.47947232035\n",
      "      - -202562.808356846\n",
      "      - -200302.41391892356\n",
      "      - -198398.26818501882\n",
      "      - -198765.27933634876\n",
      "      - -194595.36176408423\n",
      "      - -197616.88994334696\n",
      "      - -199206.07147831944\n",
      "      - -202153.72281988224\n",
      "      - -200853.86625939797\n",
      "      - -199138.13740816072\n",
      "      - -200229.570171833\n",
      "      - -201869.756431786\n",
      "      - -199784.06735732517\n",
      "      - -198102.066494162\n",
      "      - -199025.65676142843\n",
      "      - -198462.29464324878\n",
      "      - -197792.3739157782\n",
      "      - -196936.45545814547\n",
      "      - -199879.5452964787\n",
      "      - -197059.30804950048\n",
      "      - -201102.59552167018\n",
      "      - -203201.9160148836\n",
      "      - -202435.29121655237\n",
      "      - -198644.45087255753\n",
      "      - -195224.140341704\n",
      "      - -201751.75261484663\n",
      "      - -200668.22838648994\n",
      "      - -197186.40851071876\n",
      "      - -198935.15940723362\n",
      "      - -196660.47874218237\n",
      "      - -200493.79691506756\n",
      "      - -203189.2747181561\n",
      "      - -202147.17544862712\n",
      "      - -204742.94165613464\n",
      "      - -196730.53407873682\n",
      "      - -199247.99718400178\n",
      "      - -200021.51563374393\n",
      "      - -200767.20269836736\n",
      "      - -203817.58553728354\n",
      "      - -199653.62049087606\n",
      "      - -204703.41513225267\n",
      "      - -195864.36951959136\n",
      "      - -197398.75463233798\n",
      "      - -197791.95752042427\n",
      "      - -195297.37571518068\n",
      "      - -202112.76921798888\n",
      "      - -200056.22572833503\n",
      "      - -199077.18326347848\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11719842137011587\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5109239697540826\n",
      "      mean_inference_ms: 1.586267535120105\n",
      "      mean_raw_obs_processing_ms: 0.16188736098426673\n",
      "  time_since_restore: 1401.089281320572\n",
      "  time_this_iter_s: 15.967319011688232\n",
      "  time_total_s: 1401.089281320572\n",
      "  timers:\n",
      "    learn_throughput: 25887.538\n",
      "    learn_time_ms: 2471.614\n",
      "    load_throughput: 534303.157\n",
      "    load_time_ms: 119.752\n",
      "    training_iteration_time_ms: 15784.305\n",
      "    update_time_ms: 5.053\n",
      "  timestamp: 1665743617\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5758560\n",
      "  training_iteration: 90\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:33:42 (running for 00:23:45.03)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    90</td><td style=\"text-align: right;\">         1401.09</td><td style=\"text-align: right;\">5.75856e+06</td><td style=\"text-align: right;\"> -199701</td><td style=\"text-align: right;\">             -194595</td><td style=\"text-align: right;\">             -209327</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:33:47 (running for 00:23:50.15)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    90</td><td style=\"text-align: right;\">         1401.09</td><td style=\"text-align: right;\">5.75856e+06</td><td style=\"text-align: right;\"> -199701</td><td style=\"text-align: right;\">             -194595</td><td style=\"text-align: right;\">             -209327</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:33:52 (running for 00:23:55.15)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    90</td><td style=\"text-align: right;\">         1401.09</td><td style=\"text-align: right;\">5.75856e+06</td><td style=\"text-align: right;\"> -199701</td><td style=\"text-align: right;\">             -194595</td><td style=\"text-align: right;\">             -209327</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 5822544\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 5822544\n",
      "    num_agent_steps_trained: 5822544\n",
      "    num_env_steps_sampled: 5822544\n",
      "    num_env_steps_trained: 5822544\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-33-53\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -194889.12445942633\n",
      "  episode_reward_mean: -199605.70221577835\n",
      "  episode_reward_min: -205274.8734062402\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 5820\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0490639209747314\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0022852953989058733\n",
      "          model: {}\n",
      "          policy_loss: 0.0021264732349663973\n",
      "          total_loss: 10.002280235290527\n",
      "          vf_explained_var: 6.4189618065313425e-09\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 5822544\n",
      "    num_agent_steps_trained: 5822544\n",
      "    num_env_steps_sampled: 5822544\n",
      "    num_env_steps_trained: 5822544\n",
      "  iterations_since_restore: 91\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 5822544\n",
      "  num_agent_steps_trained: 5822544\n",
      "  num_env_steps_sampled: 5822544\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 5822544\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.58260869565218\n",
      "    ram_util_percent: 78.92608695652177\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11741117904926619\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5110794803678612\n",
      "    mean_inference_ms: 1.5875572896359238\n",
      "    mean_raw_obs_processing_ms: 0.16186703754264822\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -194889.12445942633\n",
      "    episode_reward_mean: -199605.70221577835\n",
      "    episode_reward_min: -205274.8734062402\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -201102.59552167018\n",
      "      - -203201.9160148836\n",
      "      - -202435.29121655237\n",
      "      - -198644.45087255753\n",
      "      - -195224.140341704\n",
      "      - -201751.75261484663\n",
      "      - -200668.22838648994\n",
      "      - -197186.40851071876\n",
      "      - -198935.15940723362\n",
      "      - -196660.47874218237\n",
      "      - -200493.79691506756\n",
      "      - -203189.2747181561\n",
      "      - -202147.17544862712\n",
      "      - -204742.94165613464\n",
      "      - -196730.53407873682\n",
      "      - -199247.99718400178\n",
      "      - -200021.51563374393\n",
      "      - -200767.20269836736\n",
      "      - -203817.58553728354\n",
      "      - -199653.62049087606\n",
      "      - -204703.41513225267\n",
      "      - -195864.36951959136\n",
      "      - -197398.75463233798\n",
      "      - -197791.95752042427\n",
      "      - -195297.37571518068\n",
      "      - -202112.76921798888\n",
      "      - -200056.22572833503\n",
      "      - -199077.18326347848\n",
      "      - -201285.56828399262\n",
      "      - -200460.11859493522\n",
      "      - -200650.7706740189\n",
      "      - -195862.54679911167\n",
      "      - -198813.67001885767\n",
      "      - -198787.6748218938\n",
      "      - -200441.34865394287\n",
      "      - -195137.26275515475\n",
      "      - -200859.2102263225\n",
      "      - -198648.05996871402\n",
      "      - -201885.60442994477\n",
      "      - -200895.53918855457\n",
      "      - -196649.06931582038\n",
      "      - -195838.32834015889\n",
      "      - -195770.51867515434\n",
      "      - -198907.00989721718\n",
      "      - -205274.8734062402\n",
      "      - -201816.78148091797\n",
      "      - -200234.85883653344\n",
      "      - -200022.98780369898\n",
      "      - -198831.65444552645\n",
      "      - -200654.65314168145\n",
      "      - -198959.2276573838\n",
      "      - -200167.49450050617\n",
      "      - -199241.73850568585\n",
      "      - -200287.98009987306\n",
      "      - -203348.67752720602\n",
      "      - -200473.55680378532\n",
      "      - -199083.1745247507\n",
      "      - -200497.96585620605\n",
      "      - -200344.70150553292\n",
      "      - -197752.76497200225\n",
      "      - -198497.2353273537\n",
      "      - -201830.43448223607\n",
      "      - -198030.80416769892\n",
      "      - -198862.0189714278\n",
      "      - -204615.89295502516\n",
      "      - -196948.0880551443\n",
      "      - -202692.8085562861\n",
      "      - -202943.99261179965\n",
      "      - -199031.98837652674\n",
      "      - -198417.00676541615\n",
      "      - -195506.35114836026\n",
      "      - -198538.1755444158\n",
      "      - -202303.67663057984\n",
      "      - -200403.68493108166\n",
      "      - -198720.76299807985\n",
      "      - -197050.86950415102\n",
      "      - -200824.94894994082\n",
      "      - -198873.03883213966\n",
      "      - -197124.79830337694\n",
      "      - -201400.8630782076\n",
      "      - -198338.02009329788\n",
      "      - -200051.61769828334\n",
      "      - -201676.82950323733\n",
      "      - -199327.38517139424\n",
      "      - -198079.55186294168\n",
      "      - -195665.04530493112\n",
      "      - -194889.12445942633\n",
      "      - -198514.33467587872\n",
      "      - -200605.36383843308\n",
      "      - -199584.47861731326\n",
      "      - -199707.0978410838\n",
      "      - -200053.44794049222\n",
      "      - -204979.15968483174\n",
      "      - -195717.23890873132\n",
      "      - -199999.39657305393\n",
      "      - -199998.7298564732\n",
      "      - -197864.04143495267\n",
      "      - -199581.58678467703\n",
      "      - -196652.75679938594\n",
      "      - -199858.06590902572\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11741117904926619\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5110794803678612\n",
      "      mean_inference_ms: 1.5875572896359238\n",
      "      mean_raw_obs_processing_ms: 0.16186703754264822\n",
      "  time_since_restore: 1416.793894290924\n",
      "  time_this_iter_s: 15.704612970352173\n",
      "  time_total_s: 1416.793894290924\n",
      "  timers:\n",
      "    learn_throughput: 25815.142\n",
      "    learn_time_ms: 2478.545\n",
      "    load_throughput: 535983.958\n",
      "    load_time_ms: 119.377\n",
      "    training_iteration_time_ms: 15760.409\n",
      "    update_time_ms: 5.013\n",
      "  timestamp: 1665743633\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5822544\n",
      "  training_iteration: 91\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:33:58 (running for 00:24:00.88)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    91</td><td style=\"text-align: right;\">         1416.79</td><td style=\"text-align: right;\">5.82254e+06</td><td style=\"text-align: right;\"> -199606</td><td style=\"text-align: right;\">             -194889</td><td style=\"text-align: right;\">             -205275</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:34:03 (running for 00:24:05.89)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    91</td><td style=\"text-align: right;\">         1416.79</td><td style=\"text-align: right;\">5.82254e+06</td><td style=\"text-align: right;\"> -199606</td><td style=\"text-align: right;\">             -194889</td><td style=\"text-align: right;\">             -205275</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:34:08 (running for 00:24:11.04)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    91</td><td style=\"text-align: right;\">         1416.79</td><td style=\"text-align: right;\">5.82254e+06</td><td style=\"text-align: right;\"> -199606</td><td style=\"text-align: right;\">             -194889</td><td style=\"text-align: right;\">             -205275</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 5886528\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 5886528\n",
      "    num_agent_steps_trained: 5886528\n",
      "    num_env_steps_sampled: 5886528\n",
      "    num_env_steps_trained: 5886528\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-34-09\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -194152.4825892386\n",
      "  episode_reward_mean: -198957.07322699868\n",
      "  episode_reward_min: -205007.7785190491\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 5880\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0429794788360596\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0019301999127492309\n",
      "          model: {}\n",
      "          policy_loss: 0.0056528192944824696\n",
      "          total_loss: 10.005733489990234\n",
      "          vf_explained_var: -4.869240797233942e-07\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 5886528\n",
      "    num_agent_steps_trained: 5886528\n",
      "    num_env_steps_sampled: 5886528\n",
      "    num_env_steps_trained: 5886528\n",
      "  iterations_since_restore: 92\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 5886528\n",
      "  num_agent_steps_trained: 5886528\n",
      "  num_env_steps_sampled: 5886528\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 5886528\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 78.30909090909091\n",
      "    ram_util_percent: 78.90909090909093\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11740306315774358\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5112709667208102\n",
      "    mean_inference_ms: 1.587067927705725\n",
      "    mean_raw_obs_processing_ms: 0.16208397492334284\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -194152.4825892386\n",
      "    episode_reward_mean: -198957.07322699868\n",
      "    episode_reward_min: -205007.7785190491\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -198497.2353273537\n",
      "      - -201830.43448223607\n",
      "      - -198030.80416769892\n",
      "      - -198862.0189714278\n",
      "      - -204615.89295502516\n",
      "      - -196948.0880551443\n",
      "      - -202692.8085562861\n",
      "      - -202943.99261179965\n",
      "      - -199031.98837652674\n",
      "      - -198417.00676541615\n",
      "      - -195506.35114836026\n",
      "      - -198538.1755444158\n",
      "      - -202303.67663057984\n",
      "      - -200403.68493108166\n",
      "      - -198720.76299807985\n",
      "      - -197050.86950415102\n",
      "      - -200824.94894994082\n",
      "      - -198873.03883213966\n",
      "      - -197124.79830337694\n",
      "      - -201400.8630782076\n",
      "      - -198338.02009329788\n",
      "      - -200051.61769828334\n",
      "      - -201676.82950323733\n",
      "      - -199327.38517139424\n",
      "      - -198079.55186294168\n",
      "      - -195665.04530493112\n",
      "      - -194889.12445942633\n",
      "      - -198514.33467587872\n",
      "      - -200605.36383843308\n",
      "      - -199584.47861731326\n",
      "      - -199707.0978410838\n",
      "      - -200053.44794049222\n",
      "      - -204979.15968483174\n",
      "      - -195717.23890873132\n",
      "      - -199999.39657305393\n",
      "      - -199998.7298564732\n",
      "      - -197864.04143495267\n",
      "      - -199581.58678467703\n",
      "      - -196652.75679938594\n",
      "      - -199858.06590902572\n",
      "      - -197318.04733587176\n",
      "      - -200182.8507650411\n",
      "      - -202238.01851509744\n",
      "      - -195032.36133267795\n",
      "      - -197650.30390306472\n",
      "      - -196654.91588137695\n",
      "      - -199208.1922193527\n",
      "      - -199605.4797429842\n",
      "      - -196470.31844302404\n",
      "      - -200982.7265768336\n",
      "      - -198172.79657408193\n",
      "      - -197315.10035970298\n",
      "      - -197420.3538449403\n",
      "      - -199327.37670839828\n",
      "      - -198699.15636916194\n",
      "      - -195288.7600701427\n",
      "      - -197794.00149910507\n",
      "      - -197400.6533652284\n",
      "      - -197027.37285601668\n",
      "      - -204382.63087564046\n",
      "      - -199146.43914611376\n",
      "      - -198295.06959874232\n",
      "      - -201831.22839370024\n",
      "      - -196985.4283815096\n",
      "      - -194425.2314069102\n",
      "      - -200326.7663122287\n",
      "      - -199646.3896987255\n",
      "      - -196553.82270434193\n",
      "      - -196522.15568445908\n",
      "      - -197507.97293166112\n",
      "      - -196398.43648236335\n",
      "      - -194152.4825892386\n",
      "      - -200446.6003189386\n",
      "      - -200868.14373804492\n",
      "      - -195105.51105656163\n",
      "      - -195060.4728582308\n",
      "      - -201039.04940120882\n",
      "      - -194356.52178281688\n",
      "      - -201824.9266973204\n",
      "      - -195972.07795045606\n",
      "      - -197800.40559393968\n",
      "      - -197215.4090859477\n",
      "      - -201642.12894855684\n",
      "      - -202940.04716644567\n",
      "      - -197526.79650356274\n",
      "      - -198851.06023183808\n",
      "      - -200943.5203350202\n",
      "      - -201196.41235102812\n",
      "      - -195746.62228149825\n",
      "      - -199314.24589975242\n",
      "      - -198235.14541510734\n",
      "      - -202656.13607375228\n",
      "      - -200597.35236063754\n",
      "      - -199157.41271994382\n",
      "      - -200428.32463860014\n",
      "      - -201477.44687018613\n",
      "      - -200176.8433703087\n",
      "      - -199502.85019713896\n",
      "      - -205007.7785190491\n",
      "      - -196894.52661914792\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11740306315774358\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5112709667208102\n",
      "      mean_inference_ms: 1.587067927705725\n",
      "      mean_raw_obs_processing_ms: 0.16208397492334284\n",
      "  time_since_restore: 1432.6128678321838\n",
      "  time_this_iter_s: 15.818973541259766\n",
      "  time_total_s: 1432.6128678321838\n",
      "  timers:\n",
      "    learn_throughput: 25840.639\n",
      "    learn_time_ms: 2476.1\n",
      "    load_throughput: 536427.712\n",
      "    load_time_ms: 119.278\n",
      "    training_iteration_time_ms: 15809.205\n",
      "    update_time_ms: 4.872\n",
      "  timestamp: 1665743649\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5886528\n",
      "  training_iteration: 92\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:34:14 (running for 00:24:16.63)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    92</td><td style=\"text-align: right;\">         1432.61</td><td style=\"text-align: right;\">5.88653e+06</td><td style=\"text-align: right;\"> -198957</td><td style=\"text-align: right;\">             -194152</td><td style=\"text-align: right;\">             -205008</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:34:19 (running for 00:24:22.16)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    92</td><td style=\"text-align: right;\">         1432.61</td><td style=\"text-align: right;\">5.88653e+06</td><td style=\"text-align: right;\"> -198957</td><td style=\"text-align: right;\">             -194152</td><td style=\"text-align: right;\">             -205008</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:34:24 (running for 00:24:27.17)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    92</td><td style=\"text-align: right;\">         1432.61</td><td style=\"text-align: right;\">5.88653e+06</td><td style=\"text-align: right;\"> -198957</td><td style=\"text-align: right;\">             -194152</td><td style=\"text-align: right;\">             -205008</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 5950512\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 5950512\n",
      "    num_agent_steps_trained: 5950512\n",
      "    num_env_steps_sampled: 5950512\n",
      "    num_env_steps_trained: 5950512\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-34-24\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -194152.4825892386\n",
      "  episode_reward_mean: -199170.98882802262\n",
      "  episode_reward_min: -208635.49914251655\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 5940\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0425162315368652\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0013906549429520965\n",
      "          model: {}\n",
      "          policy_loss: 0.00277988170273602\n",
      "          total_loss: 10.002754211425781\n",
      "          vf_explained_var: -1.443807946088782e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 5950512\n",
      "    num_agent_steps_trained: 5950512\n",
      "    num_env_steps_sampled: 5950512\n",
      "    num_env_steps_trained: 5950512\n",
      "  iterations_since_restore: 93\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 5950512\n",
      "  num_agent_steps_trained: 5950512\n",
      "  num_env_steps_sampled: 5950512\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 5950512\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 78.08181818181818\n",
      "    ram_util_percent: 78.95454545454548\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11744916247982093\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5112122718946119\n",
      "    mean_inference_ms: 1.5869617780834226\n",
      "    mean_raw_obs_processing_ms: 0.16201071194890498\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -194152.4825892386\n",
      "    episode_reward_mean: -199170.98882802262\n",
      "    episode_reward_min: -208635.49914251655\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -199146.43914611376\n",
      "      - -198295.06959874232\n",
      "      - -201831.22839370024\n",
      "      - -196985.4283815096\n",
      "      - -194425.2314069102\n",
      "      - -200326.7663122287\n",
      "      - -199646.3896987255\n",
      "      - -196553.82270434193\n",
      "      - -196522.15568445908\n",
      "      - -197507.97293166112\n",
      "      - -196398.43648236335\n",
      "      - -194152.4825892386\n",
      "      - -200446.6003189386\n",
      "      - -200868.14373804492\n",
      "      - -195105.51105656163\n",
      "      - -195060.4728582308\n",
      "      - -201039.04940120882\n",
      "      - -194356.52178281688\n",
      "      - -201824.9266973204\n",
      "      - -195972.07795045606\n",
      "      - -197800.40559393968\n",
      "      - -197215.4090859477\n",
      "      - -201642.12894855684\n",
      "      - -202940.04716644567\n",
      "      - -197526.79650356274\n",
      "      - -198851.06023183808\n",
      "      - -200943.5203350202\n",
      "      - -201196.41235102812\n",
      "      - -195746.62228149825\n",
      "      - -199314.24589975242\n",
      "      - -198235.14541510734\n",
      "      - -202656.13607375228\n",
      "      - -200597.35236063754\n",
      "      - -199157.41271994382\n",
      "      - -200428.32463860014\n",
      "      - -201477.44687018613\n",
      "      - -200176.8433703087\n",
      "      - -199502.85019713896\n",
      "      - -205007.7785190491\n",
      "      - -196894.52661914792\n",
      "      - -203137.29822690904\n",
      "      - -198438.15012207237\n",
      "      - -195665.89153278564\n",
      "      - -198395.78818738207\n",
      "      - -196179.19093311345\n",
      "      - -201434.2690764333\n",
      "      - -198991.90528627342\n",
      "      - -197954.23462436127\n",
      "      - -200516.9861886148\n",
      "      - -197500.93399480547\n",
      "      - -198313.585304552\n",
      "      - -202719.72528886676\n",
      "      - -198425.2267360957\n",
      "      - -201648.58920575576\n",
      "      - -196939.35836614607\n",
      "      - -200038.7970404423\n",
      "      - -204640.34885639496\n",
      "      - -198564.0128924848\n",
      "      - -195967.66443681458\n",
      "      - -203671.30250305403\n",
      "      - -197255.5177416024\n",
      "      - -201648.15164042107\n",
      "      - -204815.0293125215\n",
      "      - -196334.19237762305\n",
      "      - -200349.28445373202\n",
      "      - -197730.33320375066\n",
      "      - -196930.74489492032\n",
      "      - -202374.52222310254\n",
      "      - -199092.31921120727\n",
      "      - -197423.99164286107\n",
      "      - -201004.18442689127\n",
      "      - -200281.39711704105\n",
      "      - -199458.65029579395\n",
      "      - -203325.96228887045\n",
      "      - -201754.49267627316\n",
      "      - -197388.65479418158\n",
      "      - -196509.05249254178\n",
      "      - -199718.91137903018\n",
      "      - -197474.6763798777\n",
      "      - -200736.58026800436\n",
      "      - -200385.2255919674\n",
      "      - -198705.637158914\n",
      "      - -196624.80439857213\n",
      "      - -197722.9772096353\n",
      "      - -197990.0787756423\n",
      "      - -196019.30650617942\n",
      "      - -195499.18311200046\n",
      "      - -201721.7938610742\n",
      "      - -197106.03117379136\n",
      "      - -194644.69781465788\n",
      "      - -208635.49914251655\n",
      "      - -201081.73007371393\n",
      "      - -196925.42077497\n",
      "      - -206215.9371131869\n",
      "      - -201728.89278203796\n",
      "      - -198237.51829297346\n",
      "      - -200002.23616102355\n",
      "      - -199975.2989342363\n",
      "      - -197606.22510434172\n",
      "      - -195745.28888218693\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11744916247982093\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5112122718946119\n",
      "      mean_inference_ms: 1.5869617780834226\n",
      "      mean_raw_obs_processing_ms: 0.16201071194890498\n",
      "  time_since_restore: 1448.1660223007202\n",
      "  time_this_iter_s: 15.553154468536377\n",
      "  time_total_s: 1448.1660223007202\n",
      "  timers:\n",
      "    learn_throughput: 25838.516\n",
      "    learn_time_ms: 2476.303\n",
      "    load_throughput: 532967.019\n",
      "    load_time_ms: 120.052\n",
      "    training_iteration_time_ms: 15722.186\n",
      "    update_time_ms: 4.997\n",
      "  timestamp: 1665743664\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5950512\n",
      "  training_iteration: 93\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:34:30 (running for 00:24:32.33)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    93</td><td style=\"text-align: right;\">         1448.17</td><td style=\"text-align: right;\">5.95051e+06</td><td style=\"text-align: right;\"> -199171</td><td style=\"text-align: right;\">             -194152</td><td style=\"text-align: right;\">             -208635</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:34:35 (running for 00:24:37.33)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    93</td><td style=\"text-align: right;\">         1448.17</td><td style=\"text-align: right;\">5.95051e+06</td><td style=\"text-align: right;\"> -199171</td><td style=\"text-align: right;\">             -194152</td><td style=\"text-align: right;\">             -208635</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:34:40 (running for 00:24:42.34)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    93</td><td style=\"text-align: right;\">         1448.17</td><td style=\"text-align: right;\">5.95051e+06</td><td style=\"text-align: right;\"> -199171</td><td style=\"text-align: right;\">             -194152</td><td style=\"text-align: right;\">             -208635</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 6014496\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 6014496\n",
      "    num_agent_steps_trained: 6014496\n",
      "    num_env_steps_sampled: 6014496\n",
      "    num_env_steps_trained: 6014496\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-34-40\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -193975.2361685401\n",
      "  episode_reward_mean: -199101.25982154146\n",
      "  episode_reward_min: -210580.39865432636\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 6012\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0345237255096436\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.002613974967971444\n",
      "          model: {}\n",
      "          policy_loss: 6.164518708828837e-05\n",
      "          total_loss: 10.000280380249023\n",
      "          vf_explained_var: -2.8880742775072576e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 6014496\n",
      "    num_agent_steps_trained: 6014496\n",
      "    num_env_steps_sampled: 6014496\n",
      "    num_env_steps_trained: 6014496\n",
      "  iterations_since_restore: 94\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 6014496\n",
      "  num_agent_steps_trained: 6014496\n",
      "  num_env_steps_sampled: 6014496\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 6014496\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.1\n",
      "    ram_util_percent: 78.95909090909093\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11773675185161857\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5113940974349017\n",
      "    mean_inference_ms: 1.5884687749350581\n",
      "    mean_raw_obs_processing_ms: 0.1620100941354368\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -193975.2361685401\n",
      "    episode_reward_mean: -199101.25982154146\n",
      "    episode_reward_min: -210580.39865432636\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -199458.65029579395\n",
      "      - -203325.96228887045\n",
      "      - -201754.49267627316\n",
      "      - -197388.65479418158\n",
      "      - -196509.05249254178\n",
      "      - -199718.91137903018\n",
      "      - -197474.6763798777\n",
      "      - -200736.58026800436\n",
      "      - -200385.2255919674\n",
      "      - -198705.637158914\n",
      "      - -196624.80439857213\n",
      "      - -197722.9772096353\n",
      "      - -197990.0787756423\n",
      "      - -196019.30650617942\n",
      "      - -195499.18311200046\n",
      "      - -201721.7938610742\n",
      "      - -197106.03117379136\n",
      "      - -194644.69781465788\n",
      "      - -208635.49914251655\n",
      "      - -201081.73007371393\n",
      "      - -196925.42077497\n",
      "      - -206215.9371131869\n",
      "      - -201728.89278203796\n",
      "      - -198237.51829297346\n",
      "      - -200002.23616102355\n",
      "      - -199975.2989342363\n",
      "      - -197606.22510434172\n",
      "      - -195745.28888218693\n",
      "      - -201680.31090466795\n",
      "      - -198153.6603466863\n",
      "      - -196981.58055484333\n",
      "      - -202442.29980023825\n",
      "      - -199486.98434839502\n",
      "      - -194404.96904924748\n",
      "      - -197238.37645022268\n",
      "      - -198573.44840550568\n",
      "      - -203437.81954203278\n",
      "      - -207030.1744031511\n",
      "      - -197520.7704312822\n",
      "      - -196684.66615951018\n",
      "      - -194707.72032953263\n",
      "      - -199474.23571154877\n",
      "      - -202366.24369692148\n",
      "      - -199884.81984042944\n",
      "      - -208101.6861924482\n",
      "      - -198539.42104839406\n",
      "      - -201745.62835280158\n",
      "      - -201735.87445127429\n",
      "      - -201435.9648970374\n",
      "      - -194109.48985504953\n",
      "      - -197126.09483376693\n",
      "      - -197542.20716326378\n",
      "      - -199370.78665064668\n",
      "      - -201677.42429674714\n",
      "      - -195770.08417146953\n",
      "      - -200170.1253589799\n",
      "      - -195548.39437649213\n",
      "      - -198341.41557568248\n",
      "      - -200172.3538567978\n",
      "      - -207174.746835338\n",
      "      - -197581.458701158\n",
      "      - -198306.44772493964\n",
      "      - -206133.31899335555\n",
      "      - -196925.91344411866\n",
      "      - -200321.46603785755\n",
      "      - -198100.51494942358\n",
      "      - -194927.81497987808\n",
      "      - -196525.4709693538\n",
      "      - -195883.6418597455\n",
      "      - -196961.88488371714\n",
      "      - -200120.21540967174\n",
      "      - -193975.2361685401\n",
      "      - -202013.91535671402\n",
      "      - -210580.39865432636\n",
      "      - -199822.77035745143\n",
      "      - -196056.38306942483\n",
      "      - -195388.57237115415\n",
      "      - -199518.4786087353\n",
      "      - -197392.05249635025\n",
      "      - -195031.70351839619\n",
      "      - -200472.79646246674\n",
      "      - -198018.8415492803\n",
      "      - -202769.70584538675\n",
      "      - -197322.67816326782\n",
      "      - -196395.59507700184\n",
      "      - -194102.8058640359\n",
      "      - -196017.42473270337\n",
      "      - -199503.78109179993\n",
      "      - -201899.11730933606\n",
      "      - -200944.18708783394\n",
      "      - -200777.29115830216\n",
      "      - -200444.79438555965\n",
      "      - -199738.18218205267\n",
      "      - -195935.00868790684\n",
      "      - -195817.96681367586\n",
      "      - -196097.63648750025\n",
      "      - -202850.53253260913\n",
      "      - -194481.4476248153\n",
      "      - -194930.10515615853\n",
      "      - -202467.88405954238\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11773675185161857\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5113940974349017\n",
      "      mean_inference_ms: 1.5884687749350581\n",
      "      mean_raw_obs_processing_ms: 0.1620100941354368\n",
      "  time_since_restore: 1464.092259645462\n",
      "  time_this_iter_s: 15.926237344741821\n",
      "  time_total_s: 1464.092259645462\n",
      "  timers:\n",
      "    learn_throughput: 25754.27\n",
      "    learn_time_ms: 2484.404\n",
      "    load_throughput: 535021.629\n",
      "    load_time_ms: 119.591\n",
      "    training_iteration_time_ms: 15788.546\n",
      "    update_time_ms: 5.004\n",
      "  timestamp: 1665743680\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6014496\n",
      "  training_iteration: 94\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:34:45 (running for 00:24:48.17)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    94</td><td style=\"text-align: right;\">         1464.09</td><td style=\"text-align: right;\">6.0145e+06</td><td style=\"text-align: right;\"> -199101</td><td style=\"text-align: right;\">             -193975</td><td style=\"text-align: right;\">             -210580</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:34:51 (running for 00:24:53.36)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    94</td><td style=\"text-align: right;\">         1464.09</td><td style=\"text-align: right;\">6.0145e+06</td><td style=\"text-align: right;\"> -199101</td><td style=\"text-align: right;\">             -193975</td><td style=\"text-align: right;\">             -210580</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:34:56 (running for 00:24:58.37)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    94</td><td style=\"text-align: right;\">         1464.09</td><td style=\"text-align: right;\">6.0145e+06</td><td style=\"text-align: right;\"> -199101</td><td style=\"text-align: right;\">             -193975</td><td style=\"text-align: right;\">             -210580</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 6078480\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 6078480\n",
      "    num_agent_steps_trained: 6078480\n",
      "    num_env_steps_sampled: 6078480\n",
      "    num_env_steps_trained: 6078480\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-34-56\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -192873.30516481274\n",
      "  episode_reward_mean: -198575.63559803006\n",
      "  episode_reward_min: -210580.39865432636\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 6072\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0366756916046143\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0017711444525048137\n",
      "          model: {}\n",
      "          policy_loss: 0.001527270651422441\n",
      "          total_loss: 10.001578330993652\n",
      "          vf_explained_var: -6.813269237682107e-07\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 6078480\n",
      "    num_agent_steps_trained: 6078480\n",
      "    num_env_steps_sampled: 6078480\n",
      "    num_env_steps_trained: 6078480\n",
      "  iterations_since_restore: 95\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 6078480\n",
      "  num_agent_steps_trained: 6078480\n",
      "  num_env_steps_sampled: 6078480\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 6078480\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.75909090909092\n",
      "    ram_util_percent: 78.99545454545455\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11773977398341183\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5115996819959068\n",
      "    mean_inference_ms: 1.5877401163582425\n",
      "    mean_raw_obs_processing_ms: 0.16220479693680215\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -192873.30516481274\n",
      "    episode_reward_mean: -198575.63559803006\n",
      "    episode_reward_min: -210580.39865432636\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -197581.458701158\n",
      "      - -198306.44772493964\n",
      "      - -206133.31899335555\n",
      "      - -196925.91344411866\n",
      "      - -200321.46603785755\n",
      "      - -198100.51494942358\n",
      "      - -194927.81497987808\n",
      "      - -196525.4709693538\n",
      "      - -195883.6418597455\n",
      "      - -196961.88488371714\n",
      "      - -200120.21540967174\n",
      "      - -193975.2361685401\n",
      "      - -202013.91535671402\n",
      "      - -210580.39865432636\n",
      "      - -199822.77035745143\n",
      "      - -196056.38306942483\n",
      "      - -195388.57237115415\n",
      "      - -199518.4786087353\n",
      "      - -197392.05249635025\n",
      "      - -195031.70351839619\n",
      "      - -200472.79646246674\n",
      "      - -198018.8415492803\n",
      "      - -202769.70584538675\n",
      "      - -197322.67816326782\n",
      "      - -196395.59507700184\n",
      "      - -194102.8058640359\n",
      "      - -196017.42473270337\n",
      "      - -199503.78109179993\n",
      "      - -201899.11730933606\n",
      "      - -200944.18708783394\n",
      "      - -200777.29115830216\n",
      "      - -200444.79438555965\n",
      "      - -199738.18218205267\n",
      "      - -195935.00868790684\n",
      "      - -195817.96681367586\n",
      "      - -196097.63648750025\n",
      "      - -202850.53253260913\n",
      "      - -194481.4476248153\n",
      "      - -194930.10515615853\n",
      "      - -202467.88405954238\n",
      "      - -199462.3568750504\n",
      "      - -196264.02868035028\n",
      "      - -196798.02454545666\n",
      "      - -196623.47811181535\n",
      "      - -199405.95611259283\n",
      "      - -198125.5188069001\n",
      "      - -196721.3108432476\n",
      "      - -203136.69972051328\n",
      "      - -194530.35148912633\n",
      "      - -200561.8145843362\n",
      "      - -196547.10420269088\n",
      "      - -200454.69568190366\n",
      "      - -204816.7699261591\n",
      "      - -195399.45484314286\n",
      "      - -196426.5500864372\n",
      "      - -200827.88262777872\n",
      "      - -199495.7462216359\n",
      "      - -197077.45797084\n",
      "      - -200243.84608279006\n",
      "      - -199209.51538742706\n",
      "      - -199527.4018974918\n",
      "      - -201438.273018397\n",
      "      - -200682.35510403855\n",
      "      - -195782.9848449375\n",
      "      - -194726.6350021066\n",
      "      - -206659.72328963573\n",
      "      - -198767.1245421993\n",
      "      - -200829.43505095938\n",
      "      - -198112.26984385255\n",
      "      - -199921.6397794283\n",
      "      - -205044.58215044235\n",
      "      - -195727.74242639355\n",
      "      - -197421.30362431897\n",
      "      - -198337.38741457893\n",
      "      - -199360.27741541973\n",
      "      - -200713.54882662423\n",
      "      - -199605.2449467161\n",
      "      - -201765.59454832674\n",
      "      - -197694.9937783857\n",
      "      - -195427.48469810915\n",
      "      - -195405.0987397619\n",
      "      - -199968.08459000196\n",
      "      - -204372.48655230735\n",
      "      - -197814.01609675353\n",
      "      - -198052.41137323948\n",
      "      - -197519.6266608063\n",
      "      - -197735.76141345128\n",
      "      - -201641.3644592105\n",
      "      - -195807.07892407235\n",
      "      - -197279.35017850896\n",
      "      - -196971.3859788902\n",
      "      - -192873.30516481274\n",
      "      - -198825.94889899532\n",
      "      - -194283.40623010034\n",
      "      - -194516.31258564725\n",
      "      - -198761.1346567695\n",
      "      - -201396.71556955713\n",
      "      - -195243.6944003372\n",
      "      - -200314.5284345622\n",
      "      - -196551.84306711506\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11773977398341183\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5115996819959068\n",
      "      mean_inference_ms: 1.5877401163582425\n",
      "      mean_raw_obs_processing_ms: 0.16220479693680215\n",
      "  time_since_restore: 1479.614816904068\n",
      "  time_this_iter_s: 15.522557258605957\n",
      "  time_total_s: 1479.614816904068\n",
      "  timers:\n",
      "    learn_throughput: 25797.364\n",
      "    learn_time_ms: 2480.253\n",
      "    load_throughput: 537202.019\n",
      "    load_time_ms: 119.106\n",
      "    training_iteration_time_ms: 15696.744\n",
      "    update_time_ms: 5.031\n",
      "  timestamp: 1665743696\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6078480\n",
      "  training_iteration: 95\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:35:01 (running for 00:25:03.85)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    95</td><td style=\"text-align: right;\">         1479.61</td><td style=\"text-align: right;\">6.07848e+06</td><td style=\"text-align: right;\"> -198576</td><td style=\"text-align: right;\">             -192873</td><td style=\"text-align: right;\">             -210580</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:35:06 (running for 00:25:08.86)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    95</td><td style=\"text-align: right;\">         1479.61</td><td style=\"text-align: right;\">6.07848e+06</td><td style=\"text-align: right;\"> -198576</td><td style=\"text-align: right;\">             -192873</td><td style=\"text-align: right;\">             -210580</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:35:11 (running for 00:25:13.86)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    95</td><td style=\"text-align: right;\">         1479.61</td><td style=\"text-align: right;\">6.07848e+06</td><td style=\"text-align: right;\"> -198576</td><td style=\"text-align: right;\">             -192873</td><td style=\"text-align: right;\">             -210580</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 6142464\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 6142464\n",
      "    num_agent_steps_trained: 6142464\n",
      "    num_env_steps_sampled: 6142464\n",
      "    num_env_steps_trained: 6142464\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-35-12\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -192873.30516481274\n",
      "  episode_reward_mean: -198270.58298801142\n",
      "  episode_reward_min: -208243.24658263824\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 6132\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0328190326690674\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.001983275404199958\n",
      "          model: {}\n",
      "          policy_loss: 0.0016473153373226523\n",
      "          total_loss: 10.001740455627441\n",
      "          vf_explained_var: -1.3754918315456166e-09\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 6142464\n",
      "    num_agent_steps_trained: 6142464\n",
      "    num_env_steps_sampled: 6142464\n",
      "    num_env_steps_trained: 6142464\n",
      "  iterations_since_restore: 96\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 6142464\n",
      "  num_agent_steps_trained: 6142464\n",
      "  num_env_steps_sampled: 6142464\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 6142464\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.31363636363636\n",
      "    ram_util_percent: 79.0\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11766847499899466\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5115076021317274\n",
      "    mean_inference_ms: 1.5880244063758915\n",
      "    mean_raw_obs_processing_ms: 0.16205372720701328\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -192873.30516481274\n",
      "    episode_reward_mean: -198270.58298801142\n",
      "    episode_reward_min: -208243.24658263824\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -199527.4018974918\n",
      "      - -201438.273018397\n",
      "      - -200682.35510403855\n",
      "      - -195782.9848449375\n",
      "      - -194726.6350021066\n",
      "      - -206659.72328963573\n",
      "      - -198767.1245421993\n",
      "      - -200829.43505095938\n",
      "      - -198112.26984385255\n",
      "      - -199921.6397794283\n",
      "      - -205044.58215044235\n",
      "      - -195727.74242639355\n",
      "      - -197421.30362431897\n",
      "      - -198337.38741457893\n",
      "      - -199360.27741541973\n",
      "      - -200713.54882662423\n",
      "      - -199605.2449467161\n",
      "      - -201765.59454832674\n",
      "      - -197694.9937783857\n",
      "      - -195427.48469810915\n",
      "      - -195405.0987397619\n",
      "      - -199968.08459000196\n",
      "      - -204372.48655230735\n",
      "      - -197814.01609675353\n",
      "      - -198052.41137323948\n",
      "      - -197519.6266608063\n",
      "      - -197735.76141345128\n",
      "      - -201641.3644592105\n",
      "      - -195807.07892407235\n",
      "      - -197279.35017850896\n",
      "      - -196971.3859788902\n",
      "      - -192873.30516481274\n",
      "      - -198825.94889899532\n",
      "      - -194283.40623010034\n",
      "      - -194516.31258564725\n",
      "      - -198761.1346567695\n",
      "      - -201396.71556955713\n",
      "      - -195243.6944003372\n",
      "      - -200314.5284345622\n",
      "      - -196551.84306711506\n",
      "      - -194557.27090027716\n",
      "      - -198934.99662397808\n",
      "      - -196469.50147732528\n",
      "      - -204258.8363617887\n",
      "      - -193182.6092261194\n",
      "      - -201290.21403252424\n",
      "      - -201990.79471724722\n",
      "      - -197445.6238594138\n",
      "      - -200769.8653208264\n",
      "      - -197068.80080569262\n",
      "      - -197462.38670834494\n",
      "      - -199884.48708100445\n",
      "      - -205616.6670950412\n",
      "      - -199409.2691432392\n",
      "      - -196665.99831246838\n",
      "      - -198429.5022626676\n",
      "      - -194046.45017707505\n",
      "      - -193871.90647787214\n",
      "      - -200758.6487974569\n",
      "      - -196003.67927912212\n",
      "      - -198429.43085371694\n",
      "      - -196056.9615620935\n",
      "      - -196883.26563889818\n",
      "      - -198588.46670606014\n",
      "      - -194604.911834753\n",
      "      - -195741.14681375062\n",
      "      - -195913.45843458766\n",
      "      - -201087.22888829734\n",
      "      - -199493.001244327\n",
      "      - -199197.60669543108\n",
      "      - -198636.93828378464\n",
      "      - -197578.84665583144\n",
      "      - -197702.01679608665\n",
      "      - -197187.71213774927\n",
      "      - -197282.04993844044\n",
      "      - -197315.46592119508\n",
      "      - -199984.563249177\n",
      "      - -208243.24658263824\n",
      "      - -199887.46641248278\n",
      "      - -197040.51711282966\n",
      "      - -196727.8695626069\n",
      "      - -204765.30617495129\n",
      "      - -197952.62395476387\n",
      "      - -194709.34462211622\n",
      "      - -198317.14099307658\n",
      "      - -194016.35947055326\n",
      "      - -196217.6722947318\n",
      "      - -198807.2670405406\n",
      "      - -197013.81262068203\n",
      "      - -196445.58921344878\n",
      "      - -198291.07238628442\n",
      "      - -195882.2449843398\n",
      "      - -195373.12984922752\n",
      "      - -193997.92552855267\n",
      "      - -195127.75976195163\n",
      "      - -200929.61508150256\n",
      "      - -202947.51150871252\n",
      "      - -196068.33964791146\n",
      "      - -196998.76341000354\n",
      "      - -198617.58409630728\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11766847499899466\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5115076021317274\n",
      "      mean_inference_ms: 1.5880244063758915\n",
      "      mean_raw_obs_processing_ms: 0.16205372720701328\n",
      "  time_since_restore: 1495.4680602550507\n",
      "  time_this_iter_s: 15.853243350982666\n",
      "  time_total_s: 1495.4680602550507\n",
      "  timers:\n",
      "    learn_throughput: 26209.828\n",
      "    learn_time_ms: 2441.222\n",
      "    load_throughput: 537567.666\n",
      "    load_time_ms: 119.025\n",
      "    training_iteration_time_ms: 15711.741\n",
      "    update_time_ms: 4.698\n",
      "  timestamp: 1665743712\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6142464\n",
      "  training_iteration: 96\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:35:17 (running for 00:25:19.62)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    96</td><td style=\"text-align: right;\">         1495.47</td><td style=\"text-align: right;\">6.14246e+06</td><td style=\"text-align: right;\"> -198271</td><td style=\"text-align: right;\">             -192873</td><td style=\"text-align: right;\">             -208243</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:35:22 (running for 00:25:24.74)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    96</td><td style=\"text-align: right;\">         1495.47</td><td style=\"text-align: right;\">6.14246e+06</td><td style=\"text-align: right;\"> -198271</td><td style=\"text-align: right;\">             -192873</td><td style=\"text-align: right;\">             -208243</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:35:27 (running for 00:25:29.96)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    96</td><td style=\"text-align: right;\">         1495.47</td><td style=\"text-align: right;\">6.14246e+06</td><td style=\"text-align: right;\"> -198271</td><td style=\"text-align: right;\">             -192873</td><td style=\"text-align: right;\">             -208243</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 6206448\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 6206448\n",
      "    num_agent_steps_trained: 6206448\n",
      "    num_env_steps_sampled: 6206448\n",
      "    num_env_steps_trained: 6206448\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-35-28\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -192437.20738004986\n",
      "  episode_reward_mean: -198226.58898928226\n",
      "  episode_reward_min: -208846.4480127758\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 6204\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0334360599517822\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0019070057896897197\n",
      "          model: {}\n",
      "          policy_loss: 0.006527278572320938\n",
      "          total_loss: 10.00660514831543\n",
      "          vf_explained_var: -6.217222789928201e-07\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 6206448\n",
      "    num_agent_steps_trained: 6206448\n",
      "    num_env_steps_sampled: 6206448\n",
      "    num_env_steps_trained: 6206448\n",
      "  iterations_since_restore: 97\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 6206448\n",
      "  num_agent_steps_trained: 6206448\n",
      "  num_env_steps_sampled: 6206448\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 6206448\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.2090909090909\n",
      "    ram_util_percent: 79.0\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11781610735199546\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.511678177316093\n",
      "    mean_inference_ms: 1.589452158700367\n",
      "    mean_raw_obs_processing_ms: 0.16201494993189833\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -192437.20738004986\n",
      "    episode_reward_mean: -198226.58898928226\n",
      "    episode_reward_min: -208846.4480127758\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -197702.01679608665\n",
      "      - -197187.71213774927\n",
      "      - -197282.04993844044\n",
      "      - -197315.46592119508\n",
      "      - -199984.563249177\n",
      "      - -208243.24658263824\n",
      "      - -199887.46641248278\n",
      "      - -197040.51711282966\n",
      "      - -196727.8695626069\n",
      "      - -204765.30617495129\n",
      "      - -197952.62395476387\n",
      "      - -194709.34462211622\n",
      "      - -198317.14099307658\n",
      "      - -194016.35947055326\n",
      "      - -196217.6722947318\n",
      "      - -198807.2670405406\n",
      "      - -197013.81262068203\n",
      "      - -196445.58921344878\n",
      "      - -198291.07238628442\n",
      "      - -195882.2449843398\n",
      "      - -195373.12984922752\n",
      "      - -193997.92552855267\n",
      "      - -195127.75976195163\n",
      "      - -200929.61508150256\n",
      "      - -202947.51150871252\n",
      "      - -196068.33964791146\n",
      "      - -196998.76341000354\n",
      "      - -198617.58409630728\n",
      "      - -202604.84062066872\n",
      "      - -199191.3173745339\n",
      "      - -195992.28309678924\n",
      "      - -194420.46148874762\n",
      "      - -196761.8752866819\n",
      "      - -202754.40159095038\n",
      "      - -199757.9129149406\n",
      "      - -196556.9398100845\n",
      "      - -201487.71547857317\n",
      "      - -202621.1351224743\n",
      "      - -197641.66998078735\n",
      "      - -200037.69413201255\n",
      "      - -204426.2468369122\n",
      "      - -197631.7116802626\n",
      "      - -197899.48374159954\n",
      "      - -196556.97868911116\n",
      "      - -196944.14786802762\n",
      "      - -196543.72183655767\n",
      "      - -199523.0149084111\n",
      "      - -194212.6922014649\n",
      "      - -196457.19299922668\n",
      "      - -198843.2211557862\n",
      "      - -199101.93892827333\n",
      "      - -194967.70189498458\n",
      "      - -194931.97887417843\n",
      "      - -201270.64501068473\n",
      "      - -195678.83068459923\n",
      "      - -197685.27709086754\n",
      "      - -198506.23141812085\n",
      "      - -198854.76170563372\n",
      "      - -201312.22723129485\n",
      "      - -196880.15486242005\n",
      "      - -202284.33930260356\n",
      "      - -200702.3127437983\n",
      "      - -202102.1558595921\n",
      "      - -208846.4480127758\n",
      "      - -197051.32957957737\n",
      "      - -195108.70632570758\n",
      "      - -200207.65604931326\n",
      "      - -198615.28835865846\n",
      "      - -197161.50458443622\n",
      "      - -198170.8867692338\n",
      "      - -195617.15530409108\n",
      "      - -196812.36979148252\n",
      "      - -200760.50324771408\n",
      "      - -196105.27500421176\n",
      "      - -196721.00334900443\n",
      "      - -200551.06796245012\n",
      "      - -199789.26426841033\n",
      "      - -198042.43876013265\n",
      "      - -197273.1883232112\n",
      "      - -196865.43405774533\n",
      "      - -203308.73074973235\n",
      "      - -194675.44487637264\n",
      "      - -196127.23288844846\n",
      "      - -199487.53592106214\n",
      "      - -196075.6733769317\n",
      "      - -197837.61282533538\n",
      "      - -203710.28387729716\n",
      "      - -197808.97948272026\n",
      "      - -193903.3134800823\n",
      "      - -197830.89230950794\n",
      "      - -202488.7393696618\n",
      "      - -195167.93729029057\n",
      "      - -196323.3290118452\n",
      "      - -195340.71132624513\n",
      "      - -196010.74831587885\n",
      "      - -198595.9215310781\n",
      "      - -198861.4517918492\n",
      "      - -199577.93878829925\n",
      "      - -196394.50981286223\n",
      "      - -192437.20738004986\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11781610735199546\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.511678177316093\n",
      "      mean_inference_ms: 1.589452158700367\n",
      "      mean_raw_obs_processing_ms: 0.16201494993189833\n",
      "  time_since_restore: 1511.4669079780579\n",
      "  time_this_iter_s: 15.998847723007202\n",
      "  time_total_s: 1511.4669079780579\n",
      "  timers:\n",
      "    learn_throughput: 25763.812\n",
      "    learn_time_ms: 2483.483\n",
      "    load_throughput: 538275.948\n",
      "    load_time_ms: 118.868\n",
      "    training_iteration_time_ms: 15758.845\n",
      "    update_time_ms: 4.765\n",
      "  timestamp: 1665743728\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6206448\n",
      "  training_iteration: 97\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:35:33 (running for 00:25:35.78)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    97</td><td style=\"text-align: right;\">         1511.47</td><td style=\"text-align: right;\">6.20645e+06</td><td style=\"text-align: right;\"> -198227</td><td style=\"text-align: right;\">             -192437</td><td style=\"text-align: right;\">             -208846</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:35:38 (running for 00:25:40.78)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    97</td><td style=\"text-align: right;\">         1511.47</td><td style=\"text-align: right;\">6.20645e+06</td><td style=\"text-align: right;\"> -198227</td><td style=\"text-align: right;\">             -192437</td><td style=\"text-align: right;\">             -208846</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:35:43 (running for 00:25:45.79)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    97</td><td style=\"text-align: right;\">         1511.47</td><td style=\"text-align: right;\">6.20645e+06</td><td style=\"text-align: right;\"> -198227</td><td style=\"text-align: right;\">             -192437</td><td style=\"text-align: right;\">             -208846</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 6270432\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 6270432\n",
      "    num_agent_steps_trained: 6270432\n",
      "    num_env_steps_sampled: 6270432\n",
      "    num_env_steps_trained: 6270432\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-35-43\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -192437.20738004986\n",
      "  episode_reward_mean: -199223.44076962967\n",
      "  episode_reward_min: -218552.6417391568\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 6264\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.03695011138916\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0019296678947284818\n",
      "          model: {}\n",
      "          policy_loss: 0.006028033792972565\n",
      "          total_loss: 10.006110191345215\n",
      "          vf_explained_var: 2.92900949716568e-07\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 6270432\n",
      "    num_agent_steps_trained: 6270432\n",
      "    num_env_steps_sampled: 6270432\n",
      "    num_env_steps_trained: 6270432\n",
      "  iterations_since_restore: 98\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 6270432\n",
      "  num_agent_steps_trained: 6270432\n",
      "  num_env_steps_sampled: 6270432\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 6270432\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.32272727272728\n",
      "    ram_util_percent: 79.0\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1177319949332687\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5117273949213716\n",
      "    mean_inference_ms: 1.5886827196630213\n",
      "    mean_raw_obs_processing_ms: 0.16221841415769908\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -192437.20738004986\n",
      "    episode_reward_mean: -199223.44076962967\n",
      "    episode_reward_min: -218552.6417391568\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -202284.33930260356\n",
      "      - -200702.3127437983\n",
      "      - -202102.1558595921\n",
      "      - -208846.4480127758\n",
      "      - -197051.32957957737\n",
      "      - -195108.70632570758\n",
      "      - -200207.65604931326\n",
      "      - -198615.28835865846\n",
      "      - -197161.50458443622\n",
      "      - -198170.8867692338\n",
      "      - -195617.15530409108\n",
      "      - -196812.36979148252\n",
      "      - -200760.50324771408\n",
      "      - -196105.27500421176\n",
      "      - -196721.00334900443\n",
      "      - -200551.06796245012\n",
      "      - -199789.26426841033\n",
      "      - -198042.43876013265\n",
      "      - -197273.1883232112\n",
      "      - -196865.43405774533\n",
      "      - -203308.73074973235\n",
      "      - -194675.44487637264\n",
      "      - -196127.23288844846\n",
      "      - -199487.53592106214\n",
      "      - -196075.6733769317\n",
      "      - -197837.61282533538\n",
      "      - -203710.28387729716\n",
      "      - -197808.97948272026\n",
      "      - -193903.3134800823\n",
      "      - -197830.89230950794\n",
      "      - -202488.7393696618\n",
      "      - -195167.93729029057\n",
      "      - -196323.3290118452\n",
      "      - -195340.71132624513\n",
      "      - -196010.74831587885\n",
      "      - -198595.9215310781\n",
      "      - -198861.4517918492\n",
      "      - -199577.93878829925\n",
      "      - -196394.50981286223\n",
      "      - -192437.20738004986\n",
      "      - -198123.8492999243\n",
      "      - -206047.93849054247\n",
      "      - -196421.29048784112\n",
      "      - -196159.0465376219\n",
      "      - -206405.2397289787\n",
      "      - -196231.77972857564\n",
      "      - -199681.1516213444\n",
      "      - -198749.95584189723\n",
      "      - -196976.716317129\n",
      "      - -199825.68440241518\n",
      "      - -200777.26364171703\n",
      "      - -202069.77591342825\n",
      "      - -194933.32324085973\n",
      "      - -195472.6070314342\n",
      "      - -201638.15696843743\n",
      "      - -207467.06436464924\n",
      "      - -195965.9525906277\n",
      "      - -198205.71234180153\n",
      "      - -198560.21184991524\n",
      "      - -198533.19207536386\n",
      "      - -198630.1409573899\n",
      "      - -197399.80560147375\n",
      "      - -218552.6417391568\n",
      "      - -201707.21966900385\n",
      "      - -200170.66593646797\n",
      "      - -200099.78497706028\n",
      "      - -198915.24833976838\n",
      "      - -198843.01896403424\n",
      "      - -194901.56698554824\n",
      "      - -202205.33653283503\n",
      "      - -204892.41482553395\n",
      "      - -198655.37849082673\n",
      "      - -199155.83563632218\n",
      "      - -199343.3407882139\n",
      "      - -195108.07660317697\n",
      "      - -197761.03985592458\n",
      "      - -201558.2002084216\n",
      "      - -195935.4433327807\n",
      "      - -201532.58438713517\n",
      "      - -199555.45989996803\n",
      "      - -201210.962520698\n",
      "      - -201674.53505939955\n",
      "      - -199238.5599258901\n",
      "      - -203843.07259950062\n",
      "      - -198064.0049328913\n",
      "      - -207242.61375423326\n",
      "      - -200662.624477479\n",
      "      - -195254.2846896865\n",
      "      - -194685.7865948239\n",
      "      - -199274.1629657842\n",
      "      - -203399.29445637777\n",
      "      - -198760.2287835889\n",
      "      - -195415.7310089261\n",
      "      - -200569.73911411833\n",
      "      - -199909.46044891278\n",
      "      - -196571.18578807154\n",
      "      - -196198.40733485285\n",
      "      - -201966.34708329145\n",
      "      - -204153.76255438663\n",
      "      - -200327.67460480545\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1177319949332687\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5117273949213716\n",
      "      mean_inference_ms: 1.5886827196630213\n",
      "      mean_raw_obs_processing_ms: 0.16221841415769908\n",
      "  time_since_restore: 1526.8170602321625\n",
      "  time_this_iter_s: 15.350152254104614\n",
      "  time_total_s: 1526.8170602321625\n",
      "  timers:\n",
      "    learn_throughput: 26227.844\n",
      "    learn_time_ms: 2439.545\n",
      "    load_throughput: 539068.922\n",
      "    load_time_ms: 118.694\n",
      "    training_iteration_time_ms: 15708.689\n",
      "    update_time_ms: 4.712\n",
      "  timestamp: 1665743743\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6270432\n",
      "  training_iteration: 98\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:35:49 (running for 00:25:51.47)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    98</td><td style=\"text-align: right;\">         1526.82</td><td style=\"text-align: right;\">6.27043e+06</td><td style=\"text-align: right;\"> -199223</td><td style=\"text-align: right;\">             -192437</td><td style=\"text-align: right;\">             -218553</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:35:54 (running for 00:25:56.59)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    98</td><td style=\"text-align: right;\">         1526.82</td><td style=\"text-align: right;\">6.27043e+06</td><td style=\"text-align: right;\"> -199223</td><td style=\"text-align: right;\">             -192437</td><td style=\"text-align: right;\">             -218553</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:35:59 (running for 00:26:01.60)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    98</td><td style=\"text-align: right;\">         1526.82</td><td style=\"text-align: right;\">6.27043e+06</td><td style=\"text-align: right;\"> -199223</td><td style=\"text-align: right;\">             -192437</td><td style=\"text-align: right;\">             -218553</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 6334416\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 6334416\n",
      "    num_agent_steps_trained: 6334416\n",
      "    num_env_steps_sampled: 6334416\n",
      "    num_env_steps_trained: 6334416\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-35-59\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -193058.5024655844\n",
      "  episode_reward_mean: -199215.05146092325\n",
      "  episode_reward_min: -219839.44927017175\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 6324\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.032841205596924\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0022375923581421375\n",
      "          model: {}\n",
      "          policy_loss: 0.0005803573876619339\n",
      "          total_loss: 10.000724792480469\n",
      "          vf_explained_var: 1.0258518159389496e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 6334416\n",
      "    num_agent_steps_trained: 6334416\n",
      "    num_env_steps_sampled: 6334416\n",
      "    num_env_steps_trained: 6334416\n",
      "  iterations_since_restore: 99\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 6334416\n",
      "  num_agent_steps_trained: 6334416\n",
      "  num_env_steps_sampled: 6334416\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 6334416\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.2\n",
      "    ram_util_percent: 79.00454545454545\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11766924272867631\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5114912383082456\n",
      "    mean_inference_ms: 1.5885992716400963\n",
      "    mean_raw_obs_processing_ms: 0.16208417666346797\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -193058.5024655844\n",
      "    episode_reward_mean: -199215.05146092325\n",
      "    episode_reward_min: -219839.44927017175\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -198630.1409573899\n",
      "      - -197399.80560147375\n",
      "      - -218552.6417391568\n",
      "      - -201707.21966900385\n",
      "      - -200170.66593646797\n",
      "      - -200099.78497706028\n",
      "      - -198915.24833976838\n",
      "      - -198843.01896403424\n",
      "      - -194901.56698554824\n",
      "      - -202205.33653283503\n",
      "      - -204892.41482553395\n",
      "      - -198655.37849082673\n",
      "      - -199155.83563632218\n",
      "      - -199343.3407882139\n",
      "      - -195108.07660317697\n",
      "      - -197761.03985592458\n",
      "      - -201558.2002084216\n",
      "      - -195935.4433327807\n",
      "      - -201532.58438713517\n",
      "      - -199555.45989996803\n",
      "      - -201210.962520698\n",
      "      - -201674.53505939955\n",
      "      - -199238.5599258901\n",
      "      - -203843.07259950062\n",
      "      - -198064.0049328913\n",
      "      - -207242.61375423326\n",
      "      - -200662.624477479\n",
      "      - -195254.2846896865\n",
      "      - -194685.7865948239\n",
      "      - -199274.1629657842\n",
      "      - -203399.29445637777\n",
      "      - -198760.2287835889\n",
      "      - -195415.7310089261\n",
      "      - -200569.73911411833\n",
      "      - -199909.46044891278\n",
      "      - -196571.18578807154\n",
      "      - -196198.40733485285\n",
      "      - -201966.34708329145\n",
      "      - -204153.76255438663\n",
      "      - -200327.67460480545\n",
      "      - -197530.9204773242\n",
      "      - -199678.53377919205\n",
      "      - -196107.34680029872\n",
      "      - -203694.82800149175\n",
      "      - -199041.28494364832\n",
      "      - -193058.5024655844\n",
      "      - -195898.0399021093\n",
      "      - -196432.79947980712\n",
      "      - -193435.67213157722\n",
      "      - -198426.17787712382\n",
      "      - -196498.2521186943\n",
      "      - -199773.35015681005\n",
      "      - -200719.30912992888\n",
      "      - -200079.74168316313\n",
      "      - -199730.16204580976\n",
      "      - -194183.41032501127\n",
      "      - -197602.48315342204\n",
      "      - -197351.89379118345\n",
      "      - -197603.35731879342\n",
      "      - -199613.30069607598\n",
      "      - -199838.998423693\n",
      "      - -197611.12536445292\n",
      "      - -194965.96211711512\n",
      "      - -199270.7292325799\n",
      "      - -200250.86205158714\n",
      "      - -197318.05807215537\n",
      "      - -195041.01374950682\n",
      "      - -197486.24133159436\n",
      "      - -197259.5970030028\n",
      "      - -200435.70729768218\n",
      "      - -198683.03389580522\n",
      "      - -199918.34796007996\n",
      "      - -199443.27155300192\n",
      "      - -199732.38791739524\n",
      "      - -201480.25204147454\n",
      "      - -201530.99289490626\n",
      "      - -198263.33705996035\n",
      "      - -198308.778797148\n",
      "      - -198992.44988424497\n",
      "      - -198721.31878740055\n",
      "      - -200996.99920434153\n",
      "      - -200970.92229313313\n",
      "      - -197500.88503089885\n",
      "      - -194930.2845981089\n",
      "      - -196283.8757459442\n",
      "      - -194707.57239574703\n",
      "      - -198038.73223978918\n",
      "      - -193845.96138396114\n",
      "      - -198663.93321101266\n",
      "      - -201414.42923513733\n",
      "      - -219839.44927017175\n",
      "      - -202814.18220131978\n",
      "      - -199730.2359037451\n",
      "      - -194784.82576582234\n",
      "      - -197032.79480527068\n",
      "      - -199631.57102581818\n",
      "      - -196492.4223456471\n",
      "      - -197026.85881243076\n",
      "      - -202809.27521470946\n",
      "      - -199632.46126872321\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11766924272867631\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5114912383082456\n",
      "      mean_inference_ms: 1.5885992716400963\n",
      "      mean_raw_obs_processing_ms: 0.16208417666346797\n",
      "  time_since_restore: 1542.6907818317413\n",
      "  time_this_iter_s: 15.873721599578857\n",
      "  time_total_s: 1542.6907818317413\n",
      "  timers:\n",
      "    learn_throughput: 25846.43\n",
      "    learn_time_ms: 2475.545\n",
      "    load_throughput: 538760.711\n",
      "    load_time_ms: 118.761\n",
      "    training_iteration_time_ms: 15748.312\n",
      "    update_time_ms: 4.77\n",
      "  timestamp: 1665743759\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6334416\n",
      "  training_iteration: 99\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:36:04 (running for 00:26:07.05)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    99</td><td style=\"text-align: right;\">         1542.69</td><td style=\"text-align: right;\">6.33442e+06</td><td style=\"text-align: right;\"> -199215</td><td style=\"text-align: right;\">             -193059</td><td style=\"text-align: right;\">             -219839</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:36:09 (running for 00:26:12.17)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    99</td><td style=\"text-align: right;\">         1542.69</td><td style=\"text-align: right;\">6.33442e+06</td><td style=\"text-align: right;\"> -199215</td><td style=\"text-align: right;\">             -193059</td><td style=\"text-align: right;\">             -219839</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:36:14 (running for 00:26:17.18)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">    99</td><td style=\"text-align: right;\">         1542.69</td><td style=\"text-align: right;\">6.33442e+06</td><td style=\"text-align: right;\"> -199215</td><td style=\"text-align: right;\">             -193059</td><td style=\"text-align: right;\">             -219839</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 6398400\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 6398400\n",
      "    num_agent_steps_trained: 6398400\n",
      "    num_env_steps_sampled: 6398400\n",
      "    num_env_steps_trained: 6398400\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-36-15\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -191804.9193443664\n",
      "  episode_reward_mean: -198453.81705990777\n",
      "  episode_reward_min: -219839.44927017175\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 6396\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0192806720733643\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.002408919157460332\n",
      "          model: {}\n",
      "          policy_loss: 0.003906775265932083\n",
      "          total_loss: 10.0040864944458\n",
      "          vf_explained_var: -1.5222109368551173e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 6398400\n",
      "    num_agent_steps_trained: 6398400\n",
      "    num_env_steps_sampled: 6398400\n",
      "    num_env_steps_trained: 6398400\n",
      "  iterations_since_restore: 100\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 6398400\n",
      "  num_agent_steps_trained: 6398400\n",
      "  num_env_steps_sampled: 6398400\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 6398400\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.39090909090909\n",
      "    ram_util_percent: 79.0\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.117814234205074\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5116528138233124\n",
      "    mean_inference_ms: 1.5895905570444746\n",
      "    mean_raw_obs_processing_ms: 0.1620507091770511\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -191804.9193443664\n",
      "    episode_reward_mean: -198453.81705990777\n",
      "    episode_reward_min: -219839.44927017175\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -199443.27155300192\n",
      "      - -199732.38791739524\n",
      "      - -201480.25204147454\n",
      "      - -201530.99289490626\n",
      "      - -198263.33705996035\n",
      "      - -198308.778797148\n",
      "      - -198992.44988424497\n",
      "      - -198721.31878740055\n",
      "      - -200996.99920434153\n",
      "      - -200970.92229313313\n",
      "      - -197500.88503089885\n",
      "      - -194930.2845981089\n",
      "      - -196283.8757459442\n",
      "      - -194707.57239574703\n",
      "      - -198038.73223978918\n",
      "      - -193845.96138396114\n",
      "      - -198663.93321101266\n",
      "      - -201414.42923513733\n",
      "      - -219839.44927017175\n",
      "      - -202814.18220131978\n",
      "      - -199730.2359037451\n",
      "      - -194784.82576582234\n",
      "      - -197032.79480527068\n",
      "      - -199631.57102581818\n",
      "      - -196492.4223456471\n",
      "      - -197026.85881243076\n",
      "      - -202809.27521470946\n",
      "      - -199632.46126872321\n",
      "      - -204716.12882384815\n",
      "      - -199855.97969521684\n",
      "      - -194470.68451580362\n",
      "      - -196313.64577870257\n",
      "      - -193474.98362903934\n",
      "      - -205335.72642122835\n",
      "      - -200481.4703242426\n",
      "      - -198120.512594369\n",
      "      - -198405.66544771707\n",
      "      - -195155.36687871194\n",
      "      - -195717.7078682051\n",
      "      - -196043.14420337713\n",
      "      - -199841.09972047832\n",
      "      - -198881.02399443017\n",
      "      - -195088.43348156218\n",
      "      - -198156.21701429255\n",
      "      - -196047.9225066828\n",
      "      - -194523.37310198226\n",
      "      - -198326.5318415384\n",
      "      - -194699.06855877818\n",
      "      - -197119.1430150081\n",
      "      - -199941.0289527427\n",
      "      - -194954.92924431228\n",
      "      - -200062.54030868728\n",
      "      - -201717.71672704435\n",
      "      - -198912.38374740316\n",
      "      - -198310.25203770472\n",
      "      - -195740.44316842005\n",
      "      - -197250.3490384196\n",
      "      - -196768.01391669165\n",
      "      - -214856.18967115748\n",
      "      - -197179.84812366928\n",
      "      - -197416.7143465041\n",
      "      - -198276.1653405834\n",
      "      - -197470.48052334983\n",
      "      - -199404.24410027932\n",
      "      - -201153.76423275765\n",
      "      - -197715.42675061745\n",
      "      - -197058.17488678417\n",
      "      - -195262.16694716108\n",
      "      - -193380.27375610065\n",
      "      - -198924.35160201328\n",
      "      - -200528.31392081906\n",
      "      - -196028.9710430951\n",
      "      - -198492.74179180164\n",
      "      - -200340.95544909293\n",
      "      - -200038.00278416346\n",
      "      - -205941.64192320177\n",
      "      - -196981.3334841116\n",
      "      - -193584.68540059673\n",
      "      - -193072.80818775957\n",
      "      - -194899.61586871886\n",
      "      - -201313.1800109122\n",
      "      - -200486.67196883206\n",
      "      - -196894.42227341695\n",
      "      - -195075.4591776006\n",
      "      - -194459.4890613734\n",
      "      - -205683.4804071007\n",
      "      - -195052.70321677538\n",
      "      - -195965.67134300523\n",
      "      - -200115.26235220232\n",
      "      - -196219.35476131746\n",
      "      - -198669.03155369888\n",
      "      - -198392.6276364749\n",
      "      - -198534.80565680558\n",
      "      - -200381.85916556165\n",
      "      - -200924.00573947155\n",
      "      - -193472.97918005683\n",
      "      - -191804.9193443664\n",
      "      - -194262.05691768328\n",
      "      - -198188.38095127643\n",
      "      - -203426.5276946029\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.117814234205074\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5116528138233124\n",
      "      mean_inference_ms: 1.5895905570444746\n",
      "      mean_raw_obs_processing_ms: 0.1620507091770511\n",
      "  time_since_restore: 1558.1347219944\n",
      "  time_this_iter_s: 15.443940162658691\n",
      "  time_total_s: 1558.1347219944\n",
      "  timers:\n",
      "    learn_throughput: 25835.76\n",
      "    learn_time_ms: 2476.567\n",
      "    load_throughput: 539902.901\n",
      "    load_time_ms: 118.51\n",
      "    training_iteration_time_ms: 15696.556\n",
      "    update_time_ms: 4.443\n",
      "  timestamp: 1665743775\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6398400\n",
      "  training_iteration: 100\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:36:20 (running for 00:26:22.43)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         1558.13</td><td style=\"text-align: right;\">6.3984e+06</td><td style=\"text-align: right;\"> -198454</td><td style=\"text-align: right;\">             -191805</td><td style=\"text-align: right;\">             -219839</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:36:25 (running for 00:26:27.55)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         1558.13</td><td style=\"text-align: right;\">6.3984e+06</td><td style=\"text-align: right;\"> -198454</td><td style=\"text-align: right;\">             -191805</td><td style=\"text-align: right;\">             -219839</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:36:30 (running for 00:26:32.78)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">         1558.13</td><td style=\"text-align: right;\">6.3984e+06</td><td style=\"text-align: right;\"> -198454</td><td style=\"text-align: right;\">             -191805</td><td style=\"text-align: right;\">             -219839</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 6462384\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 6462384\n",
      "    num_agent_steps_trained: 6462384\n",
      "    num_env_steps_sampled: 6462384\n",
      "    num_env_steps_trained: 6462384\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-36-31\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -191804.9193443664\n",
      "  episode_reward_mean: -197512.129222581\n",
      "  episode_reward_min: -205941.64192320177\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 6456\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.027315139770508\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0021440559066832066\n",
      "          model: {}\n",
      "          policy_loss: 0.004059511236846447\n",
      "          total_loss: 10.004185676574707\n",
      "          vf_explained_var: 1.232139766216278e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 6462384\n",
      "    num_agent_steps_trained: 6462384\n",
      "    num_env_steps_sampled: 6462384\n",
      "    num_env_steps_trained: 6462384\n",
      "  iterations_since_restore: 101\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 6462384\n",
      "  num_agent_steps_trained: 6462384\n",
      "  num_env_steps_sampled: 6462384\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 6462384\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.30909090909091\n",
      "    ram_util_percent: 79.0\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11773075064681668\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5117108234158496\n",
      "    mean_inference_ms: 1.58884017825427\n",
      "    mean_raw_obs_processing_ms: 0.16225682213864473\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -191804.9193443664\n",
      "    episode_reward_mean: -197512.129222581\n",
      "    episode_reward_min: -205941.64192320177\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -197416.7143465041\n",
      "      - -198276.1653405834\n",
      "      - -197470.48052334983\n",
      "      - -199404.24410027932\n",
      "      - -201153.76423275765\n",
      "      - -197715.42675061745\n",
      "      - -197058.17488678417\n",
      "      - -195262.16694716108\n",
      "      - -193380.27375610065\n",
      "      - -198924.35160201328\n",
      "      - -200528.31392081906\n",
      "      - -196028.9710430951\n",
      "      - -198492.74179180164\n",
      "      - -200340.95544909293\n",
      "      - -200038.00278416346\n",
      "      - -205941.64192320177\n",
      "      - -196981.3334841116\n",
      "      - -193584.68540059673\n",
      "      - -193072.80818775957\n",
      "      - -194899.61586871886\n",
      "      - -201313.1800109122\n",
      "      - -200486.67196883206\n",
      "      - -196894.42227341695\n",
      "      - -195075.4591776006\n",
      "      - -194459.4890613734\n",
      "      - -205683.4804071007\n",
      "      - -195052.70321677538\n",
      "      - -195965.67134300523\n",
      "      - -200115.26235220232\n",
      "      - -196219.35476131746\n",
      "      - -198669.03155369888\n",
      "      - -198392.6276364749\n",
      "      - -198534.80565680558\n",
      "      - -200381.85916556165\n",
      "      - -200924.00573947155\n",
      "      - -193472.97918005683\n",
      "      - -191804.9193443664\n",
      "      - -194262.05691768328\n",
      "      - -198188.38095127643\n",
      "      - -203426.5276946029\n",
      "      - -194701.4842527887\n",
      "      - -196207.48316889486\n",
      "      - -194759.08847544316\n",
      "      - -197630.41788597923\n",
      "      - -198759.5628532901\n",
      "      - -196167.31812891475\n",
      "      - -197952.81561367557\n",
      "      - -195779.15191919057\n",
      "      - -198772.63537266236\n",
      "      - -192929.5777688881\n",
      "      - -202871.7282512574\n",
      "      - -196376.60749026737\n",
      "      - -195207.59966712722\n",
      "      - -195230.86776653616\n",
      "      - -198052.2174140064\n",
      "      - -200700.98687523828\n",
      "      - -196934.02008638796\n",
      "      - -194094.87779578025\n",
      "      - -200165.3592693329\n",
      "      - -201520.86360500124\n",
      "      - -197547.78944448775\n",
      "      - -196716.5627867746\n",
      "      - -197345.52902793972\n",
      "      - -194083.02827887548\n",
      "      - -200603.5860373354\n",
      "      - -195473.44239228556\n",
      "      - -197265.03982381365\n",
      "      - -194843.36879927674\n",
      "      - -198361.04991816566\n",
      "      - -201988.02605489513\n",
      "      - -197522.1003685603\n",
      "      - -197954.74368845316\n",
      "      - -193639.28440776322\n",
      "      - -193793.3055263234\n",
      "      - -204210.85074283453\n",
      "      - -199520.6820383773\n",
      "      - -200969.01625885098\n",
      "      - -195939.29785979088\n",
      "      - -199778.0543645441\n",
      "      - -194533.3285242695\n",
      "      - -195317.179588083\n",
      "      - -195323.6143019041\n",
      "      - -195330.9465658535\n",
      "      - -196513.36574456532\n",
      "      - -200840.94084427762\n",
      "      - -196342.5267694338\n",
      "      - -194822.1023282214\n",
      "      - -200305.78400281622\n",
      "      - -196196.95032757192\n",
      "      - -196208.2692515866\n",
      "      - -194346.73020415168\n",
      "      - -199983.9397655758\n",
      "      - -197010.93009558218\n",
      "      - -197315.66194889115\n",
      "      - -193092.22715254853\n",
      "      - -202478.29961601194\n",
      "      - -196380.117424781\n",
      "      - -195753.5856998472\n",
      "      - -197470.10645727598\n",
      "      - -197983.173412794\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11773075064681668\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5117108234158496\n",
      "      mean_inference_ms: 1.58884017825427\n",
      "      mean_raw_obs_processing_ms: 0.16225682213864473\n",
      "  time_since_restore: 1573.990445137024\n",
      "  time_this_iter_s: 15.855723142623901\n",
      "  time_total_s: 1573.990445137024\n",
      "  timers:\n",
      "    learn_throughput: 25513.547\n",
      "    learn_time_ms: 2507.844\n",
      "    load_throughput: 540432.387\n",
      "    load_time_ms: 118.394\n",
      "    training_iteration_time_ms: 15711.509\n",
      "    update_time_ms: 4.166\n",
      "  timestamp: 1665743791\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6462384\n",
      "  training_iteration: 101\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:36:36 (running for 00:26:38.43)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   101</td><td style=\"text-align: right;\">         1573.99</td><td style=\"text-align: right;\">6.46238e+06</td><td style=\"text-align: right;\"> -197512</td><td style=\"text-align: right;\">             -191805</td><td style=\"text-align: right;\">             -205942</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:36:41 (running for 00:26:43.44)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   101</td><td style=\"text-align: right;\">         1573.99</td><td style=\"text-align: right;\">6.46238e+06</td><td style=\"text-align: right;\"> -197512</td><td style=\"text-align: right;\">             -191805</td><td style=\"text-align: right;\">             -205942</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:36:46 (running for 00:26:48.44)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   101</td><td style=\"text-align: right;\">         1573.99</td><td style=\"text-align: right;\">6.46238e+06</td><td style=\"text-align: right;\"> -197512</td><td style=\"text-align: right;\">             -191805</td><td style=\"text-align: right;\">             -205942</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 6526368\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 6526368\n",
      "    num_agent_steps_trained: 6526368\n",
      "    num_env_steps_sampled: 6526368\n",
      "    num_env_steps_trained: 6526368\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-36-46\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -192487.8989052338\n",
      "  episode_reward_mean: -197452.12697655745\n",
      "  episode_reward_min: -204639.5919588653\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 6516\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.024416446685791\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.002439779695123434\n",
      "          model: {}\n",
      "          policy_loss: 0.0012100031599402428\n",
      "          total_loss: 10.001395225524902\n",
      "          vf_explained_var: -2.5122426450252533e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 6526368\n",
      "    num_agent_steps_trained: 6526368\n",
      "    num_env_steps_sampled: 6526368\n",
      "    num_env_steps_trained: 6526368\n",
      "  iterations_since_restore: 102\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 6526368\n",
      "  num_agent_steps_trained: 6526368\n",
      "  num_env_steps_sampled: 6526368\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 6526368\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.98636363636363\n",
      "    ram_util_percent: 79.0090909090909\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11772954843865087\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5114838510038434\n",
      "    mean_inference_ms: 1.5888132955901404\n",
      "    mean_raw_obs_processing_ms: 0.16212362707321137\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -192487.8989052338\n",
      "    episode_reward_mean: -197452.12697655745\n",
      "    episode_reward_min: -204639.5919588653\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -197547.78944448775\n",
      "      - -196716.5627867746\n",
      "      - -197345.52902793972\n",
      "      - -194083.02827887548\n",
      "      - -200603.5860373354\n",
      "      - -195473.44239228556\n",
      "      - -197265.03982381365\n",
      "      - -194843.36879927674\n",
      "      - -198361.04991816566\n",
      "      - -201988.02605489513\n",
      "      - -197522.1003685603\n",
      "      - -197954.74368845316\n",
      "      - -193639.28440776322\n",
      "      - -193793.3055263234\n",
      "      - -204210.85074283453\n",
      "      - -199520.6820383773\n",
      "      - -200969.01625885098\n",
      "      - -195939.29785979088\n",
      "      - -199778.0543645441\n",
      "      - -194533.3285242695\n",
      "      - -195317.179588083\n",
      "      - -195323.6143019041\n",
      "      - -195330.9465658535\n",
      "      - -196513.36574456532\n",
      "      - -200840.94084427762\n",
      "      - -196342.5267694338\n",
      "      - -194822.1023282214\n",
      "      - -200305.78400281622\n",
      "      - -196196.95032757192\n",
      "      - -196208.2692515866\n",
      "      - -194346.73020415168\n",
      "      - -199983.9397655758\n",
      "      - -197010.93009558218\n",
      "      - -197315.66194889115\n",
      "      - -193092.22715254853\n",
      "      - -202478.29961601194\n",
      "      - -196380.117424781\n",
      "      - -195753.5856998472\n",
      "      - -197470.10645727598\n",
      "      - -197983.173412794\n",
      "      - -194233.87341700285\n",
      "      - -200963.31327778703\n",
      "      - -197567.09849380262\n",
      "      - -193352.04691938026\n",
      "      - -197247.0203948446\n",
      "      - -192573.85509873883\n",
      "      - -193925.8312512585\n",
      "      - -196996.67048309988\n",
      "      - -203854.17274554848\n",
      "      - -196233.6849510152\n",
      "      - -196078.98542388188\n",
      "      - -200413.62161803464\n",
      "      - -196910.17662057653\n",
      "      - -195686.57594304482\n",
      "      - -196992.10744710837\n",
      "      - -197947.98472538605\n",
      "      - -197635.68330353286\n",
      "      - -200213.72915751726\n",
      "      - -198042.14533966896\n",
      "      - -197446.47201698812\n",
      "      - -192708.00025437528\n",
      "      - -202096.2601565639\n",
      "      - -193003.62614050167\n",
      "      - -200274.55402290326\n",
      "      - -192487.8989052338\n",
      "      - -198026.90409624387\n",
      "      - -196916.73964788826\n",
      "      - -198084.40378856924\n",
      "      - -204639.5919588653\n",
      "      - -194790.20288354115\n",
      "      - -195355.64758515178\n",
      "      - -195864.40665161455\n",
      "      - -197004.3152811057\n",
      "      - -200465.86044954366\n",
      "      - -195437.73325803454\n",
      "      - -198529.2508489478\n",
      "      - -193816.53345432392\n",
      "      - -196689.14769094883\n",
      "      - -198915.7382040995\n",
      "      - -194987.58074012748\n",
      "      - -195646.78813167516\n",
      "      - -196106.32014162987\n",
      "      - -199738.96994820324\n",
      "      - -199180.86616824713\n",
      "      - -195983.32851403335\n",
      "      - -197066.66703983318\n",
      "      - -198011.09143927117\n",
      "      - -201173.36572997895\n",
      "      - -196667.76450703855\n",
      "      - -196706.9013288838\n",
      "      - -199477.46989208742\n",
      "      - -197623.93944282207\n",
      "      - -197645.16159728097\n",
      "      - -198399.30039835002\n",
      "      - -201131.27958894783\n",
      "      - -198926.74774828154\n",
      "      - -198755.40279503286\n",
      "      - -197338.82062290164\n",
      "      - -201643.1881606414\n",
      "      - -202475.34196841408\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11772954843865087\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5114838510038434\n",
      "      mean_inference_ms: 1.5888132955901404\n",
      "      mean_raw_obs_processing_ms: 0.16212362707321137\n",
      "  time_since_restore: 1589.543833732605\n",
      "  time_this_iter_s: 15.553388595581055\n",
      "  time_total_s: 1589.543833732605\n",
      "  timers:\n",
      "    learn_throughput: 25489.4\n",
      "    learn_time_ms: 2510.22\n",
      "    load_throughput: 541113.0\n",
      "    load_time_ms: 118.245\n",
      "    training_iteration_time_ms: 15685.211\n",
      "    update_time_ms: 4.331\n",
      "  timestamp: 1665743806\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6526368\n",
      "  training_iteration: 102\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:36:51 (running for 00:26:54.22)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   102</td><td style=\"text-align: right;\">         1589.54</td><td style=\"text-align: right;\">6.52637e+06</td><td style=\"text-align: right;\"> -197452</td><td style=\"text-align: right;\">             -192488</td><td style=\"text-align: right;\">             -204640</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:36:57 (running for 00:26:59.35)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   102</td><td style=\"text-align: right;\">         1589.54</td><td style=\"text-align: right;\">6.52637e+06</td><td style=\"text-align: right;\"> -197452</td><td style=\"text-align: right;\">             -192488</td><td style=\"text-align: right;\">             -204640</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:37:02 (running for 00:27:04.68)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   102</td><td style=\"text-align: right;\">         1589.54</td><td style=\"text-align: right;\">6.52637e+06</td><td style=\"text-align: right;\"> -197452</td><td style=\"text-align: right;\">             -192488</td><td style=\"text-align: right;\">             -204640</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 6590352\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 6590352\n",
      "    num_agent_steps_trained: 6590352\n",
      "    num_env_steps_sampled: 6590352\n",
      "    num_env_steps_trained: 6590352\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-37-03\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -191299.0942261166\n",
      "  episode_reward_mean: -197158.6196325903\n",
      "  episode_reward_min: -210614.4027939816\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 6588\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.024167537689209\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0016967899864539504\n",
      "          model: {}\n",
      "          policy_loss: 0.006191089749336243\n",
      "          total_loss: 10.006227493286133\n",
      "          vf_explained_var: -1.839032506723015e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 6590352\n",
      "    num_agent_steps_trained: 6590352\n",
      "    num_env_steps_sampled: 6590352\n",
      "    num_env_steps_trained: 6590352\n",
      "  iterations_since_restore: 103\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 6590352\n",
      "  num_agent_steps_trained: 6590352\n",
      "  num_env_steps_sampled: 6590352\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 6590352\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.23478260869565\n",
      "    ram_util_percent: 79.0\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11789348785062156\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5116307746025676\n",
      "    mean_inference_ms: 1.5899570561905279\n",
      "    mean_raw_obs_processing_ms: 0.1620947875174749\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -191299.0942261166\n",
      "    episode_reward_mean: -197158.6196325903\n",
      "    episode_reward_min: -210614.4027939816\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -197004.3152811057\n",
      "      - -200465.86044954366\n",
      "      - -195437.73325803454\n",
      "      - -198529.2508489478\n",
      "      - -193816.53345432392\n",
      "      - -196689.14769094883\n",
      "      - -198915.7382040995\n",
      "      - -194987.58074012748\n",
      "      - -195646.78813167516\n",
      "      - -196106.32014162987\n",
      "      - -199738.96994820324\n",
      "      - -199180.86616824713\n",
      "      - -195983.32851403335\n",
      "      - -197066.66703983318\n",
      "      - -198011.09143927117\n",
      "      - -201173.36572997895\n",
      "      - -196667.76450703855\n",
      "      - -196706.9013288838\n",
      "      - -199477.46989208742\n",
      "      - -197623.93944282207\n",
      "      - -197645.16159728097\n",
      "      - -198399.30039835002\n",
      "      - -201131.27958894783\n",
      "      - -198926.74774828154\n",
      "      - -198755.40279503286\n",
      "      - -197338.82062290164\n",
      "      - -201643.1881606414\n",
      "      - -202475.34196841408\n",
      "      - -194689.9884708744\n",
      "      - -195124.316755896\n",
      "      - -197115.89036548205\n",
      "      - -200178.36113869405\n",
      "      - -197287.05243493314\n",
      "      - -194977.82846168696\n",
      "      - -194079.52711095943\n",
      "      - -201652.74391951167\n",
      "      - -194286.78143693288\n",
      "      - -196341.8896673888\n",
      "      - -195469.9268428874\n",
      "      - -194448.4431329209\n",
      "      - -195450.16766192176\n",
      "      - -193883.8261562931\n",
      "      - -196228.58897140733\n",
      "      - -195727.39731561686\n",
      "      - -194783.66579355826\n",
      "      - -198996.35236403602\n",
      "      - -194419.22701860603\n",
      "      - -197840.13688217595\n",
      "      - -199133.47454831074\n",
      "      - -199606.39068525765\n",
      "      - -196614.38814154017\n",
      "      - -195927.5505815333\n",
      "      - -193015.24116300023\n",
      "      - -198110.0397093584\n",
      "      - -195453.51341497444\n",
      "      - -198380.52301708778\n",
      "      - -200851.58364272962\n",
      "      - -202042.54583130378\n",
      "      - -199948.02656283238\n",
      "      - -197126.90126702833\n",
      "      - -195219.33275993567\n",
      "      - -199521.82029619892\n",
      "      - -198904.05017132626\n",
      "      - -194896.88359728095\n",
      "      - -197714.7091719574\n",
      "      - -197784.3964270573\n",
      "      - -200650.72624338174\n",
      "      - -193345.1525081279\n",
      "      - -196759.81489255818\n",
      "      - -197419.83804246996\n",
      "      - -196014.5065261683\n",
      "      - -195003.48444813775\n",
      "      - -194818.5382554156\n",
      "      - -195852.15556320222\n",
      "      - -197878.1717508233\n",
      "      - -197551.58531726996\n",
      "      - -202984.93586858152\n",
      "      - -195967.07091086218\n",
      "      - -195401.7181204479\n",
      "      - -193012.45131834364\n",
      "      - -193339.61658280378\n",
      "      - -194346.1604955813\n",
      "      - -197469.10288005573\n",
      "      - -194708.4920779679\n",
      "      - -196094.50989210996\n",
      "      - -197510.7414293654\n",
      "      - -195492.3273239782\n",
      "      - -195228.079251351\n",
      "      - -200325.15791761194\n",
      "      - -198983.39054638986\n",
      "      - -200209.98278281483\n",
      "      - -193368.97120850725\n",
      "      - -210614.4027939816\n",
      "      - -192829.59361829484\n",
      "      - -191299.0942261166\n",
      "      - -195836.4219914988\n",
      "      - -194974.4342712311\n",
      "      - -195108.47105816274\n",
      "      - -200839.1635530754\n",
      "      - -195845.34161116285\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11789348785062156\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5116307746025676\n",
      "      mean_inference_ms: 1.5899570561905279\n",
      "      mean_raw_obs_processing_ms: 0.1620947875174749\n",
      "  time_since_restore: 1606.0122683048248\n",
      "  time_this_iter_s: 16.46843457221985\n",
      "  time_total_s: 1606.0122683048248\n",
      "  timers:\n",
      "    learn_throughput: 24596.764\n",
      "    learn_time_ms: 2601.318\n",
      "    load_throughput: 544499.073\n",
      "    load_time_ms: 117.51\n",
      "    training_iteration_time_ms: 15776.706\n",
      "    update_time_ms: 4.192\n",
      "  timestamp: 1665743823\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6590352\n",
      "  training_iteration: 103\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:37:08 (running for 00:27:10.51)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   103</td><td style=\"text-align: right;\">         1606.01</td><td style=\"text-align: right;\">6.59035e+06</td><td style=\"text-align: right;\"> -197159</td><td style=\"text-align: right;\">             -191299</td><td style=\"text-align: right;\">             -210614</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:37:13 (running for 00:27:15.92)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   103</td><td style=\"text-align: right;\">         1606.01</td><td style=\"text-align: right;\">6.59035e+06</td><td style=\"text-align: right;\"> -197159</td><td style=\"text-align: right;\">             -191299</td><td style=\"text-align: right;\">             -210614</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:37:18 (running for 00:27:20.92)<br>Memory usage on this node: 12.2/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   103</td><td style=\"text-align: right;\">         1606.01</td><td style=\"text-align: right;\">6.59035e+06</td><td style=\"text-align: right;\"> -197159</td><td style=\"text-align: right;\">             -191299</td><td style=\"text-align: right;\">             -210614</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 6654336\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 6654336\n",
      "    num_agent_steps_trained: 6654336\n",
      "    num_env_steps_sampled: 6654336\n",
      "    num_env_steps_trained: 6654336\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-37-18\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -191299.0942261166\n",
      "  episode_reward_mean: -196438.31189220317\n",
      "  episode_reward_min: -210614.4027939816\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 6648\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.024392604827881\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.002407497726380825\n",
      "          model: {}\n",
      "          policy_loss: 0.0035545225255191326\n",
      "          total_loss: 10.00373363494873\n",
      "          vf_explained_var: -1.3434328138828278e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 6654336\n",
      "    num_agent_steps_trained: 6654336\n",
      "    num_env_steps_sampled: 6654336\n",
      "    num_env_steps_trained: 6654336\n",
      "  iterations_since_restore: 104\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 6654336\n",
      "  num_agent_steps_trained: 6654336\n",
      "  num_env_steps_sampled: 6654336\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 6654336\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.89545454545456\n",
      "    ram_util_percent: 79.01363636363635\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11787102304774802\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5117437556499396\n",
      "    mean_inference_ms: 1.589218882755555\n",
      "    mean_raw_obs_processing_ms: 0.16231601709753804\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -191299.0942261166\n",
      "    episode_reward_mean: -196438.31189220317\n",
      "    episode_reward_min: -210614.4027939816\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -195219.33275993567\n",
      "      - -199521.82029619892\n",
      "      - -198904.05017132626\n",
      "      - -194896.88359728095\n",
      "      - -197714.7091719574\n",
      "      - -197784.3964270573\n",
      "      - -200650.72624338174\n",
      "      - -193345.1525081279\n",
      "      - -196759.81489255818\n",
      "      - -197419.83804246996\n",
      "      - -196014.5065261683\n",
      "      - -195003.48444813775\n",
      "      - -194818.5382554156\n",
      "      - -195852.15556320222\n",
      "      - -197878.1717508233\n",
      "      - -197551.58531726996\n",
      "      - -202984.93586858152\n",
      "      - -195967.07091086218\n",
      "      - -195401.7181204479\n",
      "      - -193012.45131834364\n",
      "      - -193339.61658280378\n",
      "      - -194346.1604955813\n",
      "      - -197469.10288005573\n",
      "      - -194708.4920779679\n",
      "      - -196094.50989210996\n",
      "      - -197510.7414293654\n",
      "      - -195492.3273239782\n",
      "      - -195228.079251351\n",
      "      - -200325.15791761194\n",
      "      - -198983.39054638986\n",
      "      - -200209.98278281483\n",
      "      - -193368.97120850725\n",
      "      - -210614.4027939816\n",
      "      - -192829.59361829484\n",
      "      - -191299.0942261166\n",
      "      - -195836.4219914988\n",
      "      - -194974.4342712311\n",
      "      - -195108.47105816274\n",
      "      - -200839.1635530754\n",
      "      - -195845.34161116285\n",
      "      - -192936.43947977148\n",
      "      - -197906.56987500482\n",
      "      - -194354.72494045948\n",
      "      - -194108.92485830782\n",
      "      - -194890.91439755406\n",
      "      - -196560.24172865468\n",
      "      - -195534.38032824016\n",
      "      - -192895.62511188988\n",
      "      - -199255.30211076944\n",
      "      - -195924.8736195725\n",
      "      - -192995.53814415057\n",
      "      - -195454.95343615886\n",
      "      - -195497.79273888355\n",
      "      - -197031.04557803294\n",
      "      - -194711.72323631225\n",
      "      - -196890.4419307868\n",
      "      - -194021.741491086\n",
      "      - -196889.12156321254\n",
      "      - -195346.4002594911\n",
      "      - -193997.38491977783\n",
      "      - -193146.26490078005\n",
      "      - -197871.24227503818\n",
      "      - -196647.71783026258\n",
      "      - -197419.24567598308\n",
      "      - -198805.54274521457\n",
      "      - -195018.78239543177\n",
      "      - -193928.91004689792\n",
      "      - -198207.858196187\n",
      "      - -193165.226286476\n",
      "      - -194360.6652835885\n",
      "      - -197059.53630542682\n",
      "      - -194368.9901703053\n",
      "      - -197636.7750467925\n",
      "      - -197773.49782921642\n",
      "      - -201854.07698378427\n",
      "      - -195886.92473034127\n",
      "      - -192965.458757587\n",
      "      - -198527.9541597399\n",
      "      - -199204.43133455815\n",
      "      - -191800.03311879383\n",
      "      - -196318.23491727258\n",
      "      - -198532.6681428811\n",
      "      - -204371.38394723815\n",
      "      - -194390.43725359073\n",
      "      - -194159.5150338471\n",
      "      - -193052.34078916008\n",
      "      - -201252.20157071567\n",
      "      - -196998.870531925\n",
      "      - -198893.29753346913\n",
      "      - -195845.06333490033\n",
      "      - -204483.8761033816\n",
      "      - -193314.00630766517\n",
      "      - -192296.9264683388\n",
      "      - -198448.6285536359\n",
      "      - -198100.61902917386\n",
      "      - -195743.65643349415\n",
      "      - -197407.51312580233\n",
      "      - -194114.53023700358\n",
      "      - -195957.55529379257\n",
      "      - -196171.79309089982\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11787102304774802\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5117437556499396\n",
      "      mean_inference_ms: 1.589218882755555\n",
      "      mean_raw_obs_processing_ms: 0.16231601709753804\n",
      "  time_since_restore: 1621.6771574020386\n",
      "  time_this_iter_s: 15.664889097213745\n",
      "  time_total_s: 1621.6771574020386\n",
      "  timers:\n",
      "    learn_throughput: 24623.16\n",
      "    learn_time_ms: 2598.529\n",
      "    load_throughput: 532131.944\n",
      "    load_time_ms: 120.241\n",
      "    training_iteration_time_ms: 15750.53\n",
      "    update_time_ms: 4.248\n",
      "  timestamp: 1665743838\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6654336\n",
      "  training_iteration: 104\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:37:23 (running for 00:27:26.09)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   104</td><td style=\"text-align: right;\">         1621.68</td><td style=\"text-align: right;\">6.65434e+06</td><td style=\"text-align: right;\"> -196438</td><td style=\"text-align: right;\">             -191299</td><td style=\"text-align: right;\">             -210614</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:37:28 (running for 00:27:31.22)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   104</td><td style=\"text-align: right;\">         1621.68</td><td style=\"text-align: right;\">6.65434e+06</td><td style=\"text-align: right;\"> -196438</td><td style=\"text-align: right;\">             -191299</td><td style=\"text-align: right;\">             -210614</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:37:34 (running for 00:27:36.63)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   104</td><td style=\"text-align: right;\">         1621.68</td><td style=\"text-align: right;\">6.65434e+06</td><td style=\"text-align: right;\"> -196438</td><td style=\"text-align: right;\">             -191299</td><td style=\"text-align: right;\">             -210614</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 6718320\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 6718320\n",
      "    num_agent_steps_trained: 6718320\n",
      "    num_env_steps_sampled: 6718320\n",
      "    num_env_steps_trained: 6718320\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-37-34\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -191437.47197951755\n",
      "  episode_reward_mean: -196329.3758959074\n",
      "  episode_reward_min: -204483.8761033816\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 6708\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.018235921859741\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.002099212259054184\n",
      "          model: {}\n",
      "          policy_loss: 0.0012371838092803955\n",
      "          total_loss: 10.00135612487793\n",
      "          vf_explained_var: -5.085021257400513e-07\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 6718320\n",
      "    num_agent_steps_trained: 6718320\n",
      "    num_env_steps_sampled: 6718320\n",
      "    num_env_steps_trained: 6718320\n",
      "  iterations_since_restore: 105\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 6718320\n",
      "  num_agent_steps_trained: 6718320\n",
      "  num_env_steps_sampled: 6718320\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 6718320\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 78.76818181818182\n",
      "    ram_util_percent: 79.1818181818182\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11786657372725282\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5117653647960411\n",
      "    mean_inference_ms: 1.5895463666109253\n",
      "    mean_raw_obs_processing_ms: 0.16218965975263422\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -191437.47197951755\n",
      "    episode_reward_mean: -196329.3758959074\n",
      "    episode_reward_min: -204483.8761033816\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -193146.26490078005\n",
      "      - -197871.24227503818\n",
      "      - -196647.71783026258\n",
      "      - -197419.24567598308\n",
      "      - -198805.54274521457\n",
      "      - -195018.78239543177\n",
      "      - -193928.91004689792\n",
      "      - -198207.858196187\n",
      "      - -193165.226286476\n",
      "      - -194360.6652835885\n",
      "      - -197059.53630542682\n",
      "      - -194368.9901703053\n",
      "      - -197636.7750467925\n",
      "      - -197773.49782921642\n",
      "      - -201854.07698378427\n",
      "      - -195886.92473034127\n",
      "      - -192965.458757587\n",
      "      - -198527.9541597399\n",
      "      - -199204.43133455815\n",
      "      - -191800.03311879383\n",
      "      - -196318.23491727258\n",
      "      - -198532.6681428811\n",
      "      - -204371.38394723815\n",
      "      - -194390.43725359073\n",
      "      - -194159.5150338471\n",
      "      - -193052.34078916008\n",
      "      - -201252.20157071567\n",
      "      - -196998.870531925\n",
      "      - -198893.29753346913\n",
      "      - -195845.06333490033\n",
      "      - -204483.8761033816\n",
      "      - -193314.00630766517\n",
      "      - -192296.9264683388\n",
      "      - -198448.6285536359\n",
      "      - -198100.61902917386\n",
      "      - -195743.65643349415\n",
      "      - -197407.51312580233\n",
      "      - -194114.53023700358\n",
      "      - -195957.55529379257\n",
      "      - -196171.79309089982\n",
      "      - -196121.80540349032\n",
      "      - -195288.7577095137\n",
      "      - -195022.95346972646\n",
      "      - -195996.2044927469\n",
      "      - -195487.2948853656\n",
      "      - -199505.31608231357\n",
      "      - -197285.82700285286\n",
      "      - -197721.02238796794\n",
      "      - -193614.83133655542\n",
      "      - -196816.76500120852\n",
      "      - -194318.36940003812\n",
      "      - -194643.13128748702\n",
      "      - -191437.47197951755\n",
      "      - -193205.05058693266\n",
      "      - -196350.94636523962\n",
      "      - -191966.83306429413\n",
      "      - -199378.6027517837\n",
      "      - -196739.82232496658\n",
      "      - -197795.8465536666\n",
      "      - -194733.45968668553\n",
      "      - -196266.86460481648\n",
      "      - -200421.1654815547\n",
      "      - -199530.48806927082\n",
      "      - -198984.21704149374\n",
      "      - -198001.07273414967\n",
      "      - -192667.47389493178\n",
      "      - -193268.0100466167\n",
      "      - -195885.23750053495\n",
      "      - -201064.31217942265\n",
      "      - -194438.21045205413\n",
      "      - -193899.7961844649\n",
      "      - -199006.89828838644\n",
      "      - -195167.54656196557\n",
      "      - -199499.2510212645\n",
      "      - -194919.38592364392\n",
      "      - -194398.44489247588\n",
      "      - -192820.45838283503\n",
      "      - -195125.0536427955\n",
      "      - -194337.00062792763\n",
      "      - -194900.637951993\n",
      "      - -194671.39508446466\n",
      "      - -194808.14156245205\n",
      "      - -197951.2183220291\n",
      "      - -197449.04433494667\n",
      "      - -199577.33374360876\n",
      "      - -201945.36741200855\n",
      "      - -195147.7555278679\n",
      "      - -196249.8919534289\n",
      "      - -196360.431412526\n",
      "      - -196810.65682064265\n",
      "      - -194713.77737850358\n",
      "      - -193610.3728176875\n",
      "      - -195462.27869302858\n",
      "      - -193441.83912224346\n",
      "      - -197787.97382342315\n",
      "      - -197277.2539844049\n",
      "      - -196531.66927718627\n",
      "      - -196115.99887256257\n",
      "      - -199086.41219490656\n",
      "      - -194404.68822727219\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11786657372725282\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5117653647960411\n",
      "      mean_inference_ms: 1.5895463666109253\n",
      "      mean_raw_obs_processing_ms: 0.16218965975263422\n",
      "  time_since_restore: 1637.652642250061\n",
      "  time_this_iter_s: 15.975484848022461\n",
      "  time_total_s: 1637.652642250061\n",
      "  timers:\n",
      "    learn_throughput: 24687.911\n",
      "    learn_time_ms: 2591.714\n",
      "    load_throughput: 529124.915\n",
      "    load_time_ms: 120.924\n",
      "    training_iteration_time_ms: 15795.898\n",
      "    update_time_ms: 4.254\n",
      "  timestamp: 1665743854\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6718320\n",
      "  training_iteration: 105\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:37:40 (running for 00:27:42.81)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   105</td><td style=\"text-align: right;\">         1637.65</td><td style=\"text-align: right;\">6.71832e+06</td><td style=\"text-align: right;\"> -196329</td><td style=\"text-align: right;\">             -191437</td><td style=\"text-align: right;\">             -204484</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:37:45 (running for 00:27:47.81)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   105</td><td style=\"text-align: right;\">         1637.65</td><td style=\"text-align: right;\">6.71832e+06</td><td style=\"text-align: right;\"> -196329</td><td style=\"text-align: right;\">             -191437</td><td style=\"text-align: right;\">             -204484</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:37:50 (running for 00:27:52.82)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   105</td><td style=\"text-align: right;\">         1637.65</td><td style=\"text-align: right;\">6.71832e+06</td><td style=\"text-align: right;\"> -196329</td><td style=\"text-align: right;\">             -191437</td><td style=\"text-align: right;\">             -204484</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 6782304\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 6782304\n",
      "    num_agent_steps_trained: 6782304\n",
      "    num_env_steps_sampled: 6782304\n",
      "    num_env_steps_trained: 6782304\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-37-50\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -191120.4162198066\n",
      "  episode_reward_mean: -196000.91845057037\n",
      "  episode_reward_min: -202025.45265193298\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 6780\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0104191303253174\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0021656907629221678\n",
      "          model: {}\n",
      "          policy_loss: 0.005692791659384966\n",
      "          total_loss: 10.005824089050293\n",
      "          vf_explained_var: -1.93531695913407e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 6782304\n",
      "    num_agent_steps_trained: 6782304\n",
      "    num_env_steps_sampled: 6782304\n",
      "    num_env_steps_trained: 6782304\n",
      "  iterations_since_restore: 106\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 6782304\n",
      "  num_agent_steps_trained: 6782304\n",
      "  num_env_steps_sampled: 6782304\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 6782304\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.87272727272726\n",
      "    ram_util_percent: 79.28181818181817\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11807628112803802\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5120119695778\n",
      "    mean_inference_ms: 1.591358821319123\n",
      "    mean_raw_obs_processing_ms: 0.16217159664066239\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -191120.4162198066\n",
      "    episode_reward_mean: -196000.91845057037\n",
      "    episode_reward_min: -202025.45265193298\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -195167.54656196557\n",
      "      - -199499.2510212645\n",
      "      - -194919.38592364392\n",
      "      - -194398.44489247588\n",
      "      - -192820.45838283503\n",
      "      - -195125.0536427955\n",
      "      - -194337.00062792763\n",
      "      - -194900.637951993\n",
      "      - -194671.39508446466\n",
      "      - -194808.14156245205\n",
      "      - -197951.2183220291\n",
      "      - -197449.04433494667\n",
      "      - -199577.33374360876\n",
      "      - -201945.36741200855\n",
      "      - -195147.7555278679\n",
      "      - -196249.8919534289\n",
      "      - -196360.431412526\n",
      "      - -196810.65682064265\n",
      "      - -194713.77737850358\n",
      "      - -193610.3728176875\n",
      "      - -195462.27869302858\n",
      "      - -193441.83912224346\n",
      "      - -197787.97382342315\n",
      "      - -197277.2539844049\n",
      "      - -196531.66927718627\n",
      "      - -196115.99887256257\n",
      "      - -199086.41219490656\n",
      "      - -194404.68822727219\n",
      "      - -195413.21800882704\n",
      "      - -194413.05718330172\n",
      "      - -195228.36676563445\n",
      "      - -194015.48201682058\n",
      "      - -191120.4162198066\n",
      "      - -193887.05329901873\n",
      "      - -192429.1444634196\n",
      "      - -194487.28233530297\n",
      "      - -199559.574188285\n",
      "      - -197925.71595986915\n",
      "      - -195546.50751390084\n",
      "      - -195030.15140621478\n",
      "      - -194322.5031188808\n",
      "      - -195796.96803656535\n",
      "      - -194622.07930198606\n",
      "      - -193887.4384874742\n",
      "      - -198282.7601526022\n",
      "      - -194674.34205424396\n",
      "      - -194828.9918733886\n",
      "      - -196706.5914843432\n",
      "      - -197894.63091548238\n",
      "      - -198363.78977267622\n",
      "      - -194380.52537260653\n",
      "      - -198694.86988660513\n",
      "      - -196193.52851201416\n",
      "      - -195586.68814772036\n",
      "      - -194182.75687123465\n",
      "      - -198433.93142555072\n",
      "      - -196665.68502941844\n",
      "      - -196585.2494234959\n",
      "      - -199693.23297953163\n",
      "      - -193468.40298866277\n",
      "      - -197208.91111957433\n",
      "      - -194586.92327741653\n",
      "      - -194523.6404996054\n",
      "      - -194422.6138634752\n",
      "      - -194573.54117621662\n",
      "      - -193813.85751481107\n",
      "      - -195788.08177258735\n",
      "      - -200876.79335757476\n",
      "      - -194618.86242604113\n",
      "      - -198101.8895799487\n",
      "      - -194779.00220615335\n",
      "      - -197596.41787867615\n",
      "      - -198572.3915262003\n",
      "      - -198775.04232226327\n",
      "      - -202025.45265193298\n",
      "      - -194399.62266971634\n",
      "      - -194148.86826672032\n",
      "      - -196866.14110310594\n",
      "      - -195479.83635111086\n",
      "      - -197208.53717313815\n",
      "      - -196797.38144990732\n",
      "      - -194157.12136192853\n",
      "      - -198267.14438160724\n",
      "      - -201695.0172644146\n",
      "      - -197390.74189851384\n",
      "      - -198716.87190956282\n",
      "      - -193900.03618922667\n",
      "      - -192963.09033942202\n",
      "      - -197100.4199820042\n",
      "      - -193319.05079256961\n",
      "      - -193964.34604978448\n",
      "      - -197976.42521409236\n",
      "      - -195775.5301338538\n",
      "      - -194250.3419238482\n",
      "      - -197463.85071330378\n",
      "      - -194851.9872598875\n",
      "      - -193899.02781128703\n",
      "      - -195472.77496762207\n",
      "      - -195283.19214488546\n",
      "      - -195588.85176805986\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11807628112803802\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5120119695778\n",
      "      mean_inference_ms: 1.591358821319123\n",
      "      mean_raw_obs_processing_ms: 0.16217159664066239\n",
      "  time_since_restore: 1653.6500759124756\n",
      "  time_this_iter_s: 15.99743366241455\n",
      "  time_total_s: 1653.6500759124756\n",
      "  timers:\n",
      "    learn_throughput: 24669.133\n",
      "    learn_time_ms: 2593.687\n",
      "    load_throughput: 525357.246\n",
      "    load_time_ms: 121.791\n",
      "    training_iteration_time_ms: 15810.523\n",
      "    update_time_ms: 4.281\n",
      "  timestamp: 1665743870\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6782304\n",
      "  training_iteration: 106\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:37:56 (running for 00:27:58.72)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   106</td><td style=\"text-align: right;\">         1653.65</td><td style=\"text-align: right;\">6.7823e+06</td><td style=\"text-align: right;\"> -196001</td><td style=\"text-align: right;\">             -191120</td><td style=\"text-align: right;\">             -202025</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:38:01 (running for 00:28:04.05)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   106</td><td style=\"text-align: right;\">         1653.65</td><td style=\"text-align: right;\">6.7823e+06</td><td style=\"text-align: right;\"> -196001</td><td style=\"text-align: right;\">             -191120</td><td style=\"text-align: right;\">             -202025</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:38:06 (running for 00:28:09.07)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   106</td><td style=\"text-align: right;\">         1653.65</td><td style=\"text-align: right;\">6.7823e+06</td><td style=\"text-align: right;\"> -196001</td><td style=\"text-align: right;\">             -191120</td><td style=\"text-align: right;\">             -202025</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 6846288\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 6846288\n",
      "    num_agent_steps_trained: 6846288\n",
      "    num_env_steps_sampled: 6846288\n",
      "    num_env_steps_trained: 6846288\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-38-07\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -190040.3072940065\n",
      "  episode_reward_mean: -195848.4353621638\n",
      "  episode_reward_min: -207990.14039927555\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 6840\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0070641040802\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0016554485773667693\n",
      "          model: {}\n",
      "          policy_loss: 0.004226282704621553\n",
      "          total_loss: 10.004257202148438\n",
      "          vf_explained_var: -4.081986844539642e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 6846288\n",
      "    num_agent_steps_trained: 6846288\n",
      "    num_env_steps_sampled: 6846288\n",
      "    num_env_steps_trained: 6846288\n",
      "  iterations_since_restore: 107\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 6846288\n",
      "  num_agent_steps_trained: 6846288\n",
      "  num_env_steps_sampled: 6846288\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 6846288\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.64347826086956\n",
      "    ram_util_percent: 79.25217391304348\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11809468277431176\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5122248975876778\n",
      "    mean_inference_ms: 1.5914778228725408\n",
      "    mean_raw_obs_processing_ms: 0.16238328754551698\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -190040.3072940065\n",
      "    episode_reward_mean: -195848.4353621638\n",
      "    episode_reward_min: -207990.14039927555\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -197208.91111957433\n",
      "      - -194586.92327741653\n",
      "      - -194523.6404996054\n",
      "      - -194422.6138634752\n",
      "      - -194573.54117621662\n",
      "      - -193813.85751481107\n",
      "      - -195788.08177258735\n",
      "      - -200876.79335757476\n",
      "      - -194618.86242604113\n",
      "      - -198101.8895799487\n",
      "      - -194779.00220615335\n",
      "      - -197596.41787867615\n",
      "      - -198572.3915262003\n",
      "      - -198775.04232226327\n",
      "      - -202025.45265193298\n",
      "      - -194399.62266971634\n",
      "      - -194148.86826672032\n",
      "      - -196866.14110310594\n",
      "      - -195479.83635111086\n",
      "      - -197208.53717313815\n",
      "      - -196797.38144990732\n",
      "      - -194157.12136192853\n",
      "      - -198267.14438160724\n",
      "      - -201695.0172644146\n",
      "      - -197390.74189851384\n",
      "      - -198716.87190956282\n",
      "      - -193900.03618922667\n",
      "      - -192963.09033942202\n",
      "      - -197100.4199820042\n",
      "      - -193319.05079256961\n",
      "      - -193964.34604978448\n",
      "      - -197976.42521409236\n",
      "      - -195775.5301338538\n",
      "      - -194250.3419238482\n",
      "      - -197463.85071330378\n",
      "      - -194851.9872598875\n",
      "      - -193899.02781128703\n",
      "      - -195472.77496762207\n",
      "      - -195283.19214488546\n",
      "      - -195588.85176805986\n",
      "      - -192929.062496374\n",
      "      - -197350.5737895324\n",
      "      - -202919.37120546823\n",
      "      - -194860.31858335543\n",
      "      - -194463.47175934786\n",
      "      - -195044.56300428807\n",
      "      - -196969.58381306665\n",
      "      - -193940.05816135666\n",
      "      - -207990.14039927555\n",
      "      - -193538.49880298864\n",
      "      - -197300.48230943418\n",
      "      - -196064.50736678264\n",
      "      - -197312.52861559737\n",
      "      - -195072.15696219692\n",
      "      - -191446.33324412126\n",
      "      - -194832.23986358626\n",
      "      - -191208.1782600157\n",
      "      - -197624.77134443243\n",
      "      - -196841.65916583122\n",
      "      - -196116.30590280928\n",
      "      - -195203.39101807814\n",
      "      - -197603.79355096814\n",
      "      - -194241.4371734763\n",
      "      - -195075.26872240656\n",
      "      - -194688.9271806185\n",
      "      - -196307.83782692414\n",
      "      - -193780.89092431974\n",
      "      - -195601.1538337815\n",
      "      - -192471.0205180387\n",
      "      - -193789.5224149371\n",
      "      - -192447.96203761076\n",
      "      - -197677.9016175172\n",
      "      - -198708.33859947193\n",
      "      - -194214.88867466862\n",
      "      - -194205.09635879166\n",
      "      - -190040.3072940065\n",
      "      - -199586.471203126\n",
      "      - -193401.18193884575\n",
      "      - -194176.94155803535\n",
      "      - -200492.3024384953\n",
      "      - -192768.65255817887\n",
      "      - -196460.65684161222\n",
      "      - -195623.24171177155\n",
      "      - -192913.69092550533\n",
      "      - -195439.7557036081\n",
      "      - -199870.14589711855\n",
      "      - -194573.091476995\n",
      "      - -194912.06616328168\n",
      "      - -199994.9000599692\n",
      "      - -193630.98040680971\n",
      "      - -195414.29215276372\n",
      "      - -194657.67184348515\n",
      "      - -200370.42188884757\n",
      "      - -193561.3173980808\n",
      "      - -192098.82925345967\n",
      "      - -197675.82577542536\n",
      "      - -193745.29108589515\n",
      "      - -196102.28072556684\n",
      "      - -194955.92017238654\n",
      "      - -195335.43394958682\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11809468277431176\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5122248975876778\n",
      "      mean_inference_ms: 1.5914778228725408\n",
      "      mean_raw_obs_processing_ms: 0.16238328754551698\n",
      "  time_since_restore: 1669.9304451942444\n",
      "  time_this_iter_s: 16.2803692817688\n",
      "  time_total_s: 1669.9304451942444\n",
      "  timers:\n",
      "    learn_throughput: 25093.714\n",
      "    learn_time_ms: 2549.802\n",
      "    load_throughput: 524872.477\n",
      "    load_time_ms: 121.904\n",
      "    training_iteration_time_ms: 15839.253\n",
      "    update_time_ms: 4.247\n",
      "  timestamp: 1665743887\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6846288\n",
      "  training_iteration: 107\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:38:12 (running for 00:28:14.45)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   107</td><td style=\"text-align: right;\">         1669.93</td><td style=\"text-align: right;\">6.84629e+06</td><td style=\"text-align: right;\"> -195848</td><td style=\"text-align: right;\">             -190040</td><td style=\"text-align: right;\">             -207990</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:38:17 (running for 00:28:19.80)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   107</td><td style=\"text-align: right;\">         1669.93</td><td style=\"text-align: right;\">6.84629e+06</td><td style=\"text-align: right;\"> -195848</td><td style=\"text-align: right;\">             -190040</td><td style=\"text-align: right;\">             -207990</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:38:22 (running for 00:28:24.81)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   107</td><td style=\"text-align: right;\">         1669.93</td><td style=\"text-align: right;\">6.84629e+06</td><td style=\"text-align: right;\"> -195848</td><td style=\"text-align: right;\">             -190040</td><td style=\"text-align: right;\">             -207990</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 6910272\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 6910272\n",
      "    num_agent_steps_trained: 6910272\n",
      "    num_env_steps_sampled: 6910272\n",
      "    num_env_steps_trained: 6910272\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-38-22\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -190040.3072940065\n",
      "  episode_reward_mean: -195939.40773981708\n",
      "  episode_reward_min: -219798.43942692122\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 6900\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 3.0011799335479736\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.002226785058155656\n",
      "          model: {}\n",
      "          policy_loss: 0.0006265025585889816\n",
      "          total_loss: 10.000771522521973\n",
      "          vf_explained_var: 5.275942385196686e-07\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 6910272\n",
      "    num_agent_steps_trained: 6910272\n",
      "    num_env_steps_sampled: 6910272\n",
      "    num_env_steps_trained: 6910272\n",
      "  iterations_since_restore: 108\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 6910272\n",
      "  num_agent_steps_trained: 6910272\n",
      "  num_env_steps_sampled: 6910272\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 6910272\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.78636363636365\n",
      "    ram_util_percent: 79.28181818181817\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11812311497896198\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5122146951392549\n",
      "    mean_inference_ms: 1.5918008388011389\n",
      "    mean_raw_obs_processing_ms: 0.1622503829989074\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -190040.3072940065\n",
      "    episode_reward_mean: -195939.40773981708\n",
      "    episode_reward_min: -219798.43942692122\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -195203.39101807814\n",
      "      - -197603.79355096814\n",
      "      - -194241.4371734763\n",
      "      - -195075.26872240656\n",
      "      - -194688.9271806185\n",
      "      - -196307.83782692414\n",
      "      - -193780.89092431974\n",
      "      - -195601.1538337815\n",
      "      - -192471.0205180387\n",
      "      - -193789.5224149371\n",
      "      - -192447.96203761076\n",
      "      - -197677.9016175172\n",
      "      - -198708.33859947193\n",
      "      - -194214.88867466862\n",
      "      - -194205.09635879166\n",
      "      - -190040.3072940065\n",
      "      - -199586.471203126\n",
      "      - -193401.18193884575\n",
      "      - -194176.94155803535\n",
      "      - -200492.3024384953\n",
      "      - -192768.65255817887\n",
      "      - -196460.65684161222\n",
      "      - -195623.24171177155\n",
      "      - -192913.69092550533\n",
      "      - -195439.7557036081\n",
      "      - -199870.14589711855\n",
      "      - -194573.091476995\n",
      "      - -194912.06616328168\n",
      "      - -199994.9000599692\n",
      "      - -193630.98040680971\n",
      "      - -195414.29215276372\n",
      "      - -194657.67184348515\n",
      "      - -200370.42188884757\n",
      "      - -193561.3173980808\n",
      "      - -192098.82925345967\n",
      "      - -197675.82577542536\n",
      "      - -193745.29108589515\n",
      "      - -196102.28072556684\n",
      "      - -194955.92017238654\n",
      "      - -195335.43394958682\n",
      "      - -195377.88494149703\n",
      "      - -194201.64954092863\n",
      "      - -196178.70647298917\n",
      "      - -195844.187913454\n",
      "      - -196612.19210291596\n",
      "      - -196739.8116398369\n",
      "      - -192759.71027433145\n",
      "      - -193538.52947351462\n",
      "      - -196710.96319322303\n",
      "      - -192685.877393658\n",
      "      - -199475.99187144486\n",
      "      - -212540.39930116027\n",
      "      - -198105.65984744416\n",
      "      - -194593.75269908714\n",
      "      - -192286.46776447614\n",
      "      - -200161.16722388746\n",
      "      - -193372.54670710274\n",
      "      - -192564.05431519065\n",
      "      - -191928.6974610362\n",
      "      - -194398.53879668977\n",
      "      - -193145.8335248543\n",
      "      - -196018.72337239332\n",
      "      - -200446.19481029376\n",
      "      - -200923.63609075584\n",
      "      - -196024.21996836684\n",
      "      - -196248.9158106473\n",
      "      - -191889.2969998046\n",
      "      - -193515.08594783646\n",
      "      - -193469.47328804684\n",
      "      - -199777.98459267666\n",
      "      - -198748.04673943127\n",
      "      - -195880.59977011368\n",
      "      - -192947.85368066162\n",
      "      - -195114.48938112915\n",
      "      - -196316.74745184125\n",
      "      - -196194.89897044256\n",
      "      - -198613.51363467178\n",
      "      - -198144.22394468673\n",
      "      - -197240.8691277921\n",
      "      - -194004.39012965938\n",
      "      - -195375.53910080856\n",
      "      - -193870.19930120106\n",
      "      - -195707.2023788456\n",
      "      - -194289.06600765078\n",
      "      - -219798.43942692122\n",
      "      - -201688.53815322064\n",
      "      - -196326.96989759846\n",
      "      - -197230.11822276327\n",
      "      - -194145.82960930455\n",
      "      - -195863.00415806624\n",
      "      - -197779.45193573783\n",
      "      - -196431.70318763788\n",
      "      - -190892.74829599715\n",
      "      - -197060.18835372126\n",
      "      - -193286.52919559757\n",
      "      - -194966.42335042063\n",
      "      - -196004.28064017108\n",
      "      - -196211.3189927639\n",
      "      - -193864.93210257776\n",
      "      - -194587.40462626825\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11812311497896198\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5122146951392549\n",
      "      mean_inference_ms: 1.5918008388011389\n",
      "      mean_raw_obs_processing_ms: 0.1622503829989074\n",
      "  time_since_restore: 1685.5118021965027\n",
      "  time_this_iter_s: 15.5813570022583\n",
      "  time_total_s: 1685.5118021965027\n",
      "  timers:\n",
      "    learn_throughput: 25053.195\n",
      "    learn_time_ms: 2553.926\n",
      "    load_throughput: 525639.807\n",
      "    load_time_ms: 121.726\n",
      "    training_iteration_time_ms: 15862.447\n",
      "    update_time_ms: 4.221\n",
      "  timestamp: 1665743902\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6910272\n",
      "  training_iteration: 108\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:38:28 (running for 00:28:30.45)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   108</td><td style=\"text-align: right;\">         1685.51</td><td style=\"text-align: right;\">6.91027e+06</td><td style=\"text-align: right;\"> -195939</td><td style=\"text-align: right;\">             -190040</td><td style=\"text-align: right;\">             -219798</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:38:33 (running for 00:28:35.45)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   108</td><td style=\"text-align: right;\">         1685.51</td><td style=\"text-align: right;\">6.91027e+06</td><td style=\"text-align: right;\"> -195939</td><td style=\"text-align: right;\">             -190040</td><td style=\"text-align: right;\">             -219798</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:38:38 (running for 00:28:40.46)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   108</td><td style=\"text-align: right;\">         1685.51</td><td style=\"text-align: right;\">6.91027e+06</td><td style=\"text-align: right;\"> -195939</td><td style=\"text-align: right;\">             -190040</td><td style=\"text-align: right;\">             -219798</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 6974256\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 6974256\n",
      "    num_agent_steps_trained: 6974256\n",
      "    num_env_steps_sampled: 6974256\n",
      "    num_env_steps_trained: 6974256\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-38-39\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -190453.63501521782\n",
      "  episode_reward_mean: -196501.47989346142\n",
      "  episode_reward_min: -219798.43942692122\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 6972\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 2.9918274879455566\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0018737147329375148\n",
      "          model: {}\n",
      "          policy_loss: 0.004109811037778854\n",
      "          total_loss: 10.004185676574707\n",
      "          vf_explained_var: -8.757297678130271e-07\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 6974256\n",
      "    num_agent_steps_trained: 6974256\n",
      "    num_env_steps_sampled: 6974256\n",
      "    num_env_steps_trained: 6974256\n",
      "  iterations_since_restore: 109\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 6974256\n",
      "  num_agent_steps_trained: 6974256\n",
      "  num_env_steps_sampled: 6974256\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 6974256\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 78.23181818181818\n",
      "    ram_util_percent: 79.29999999999998\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11826006195530664\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5123372528636727\n",
      "    mean_inference_ms: 1.5937660091003827\n",
      "    mean_raw_obs_processing_ms: 0.16230825698825688\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -190453.63501521782\n",
      "    episode_reward_mean: -196501.47989346142\n",
      "    episode_reward_min: -219798.43942692122\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -192947.85368066162\n",
      "      - -195114.48938112915\n",
      "      - -196316.74745184125\n",
      "      - -196194.89897044256\n",
      "      - -198613.51363467178\n",
      "      - -198144.22394468673\n",
      "      - -197240.8691277921\n",
      "      - -194004.39012965938\n",
      "      - -195375.53910080856\n",
      "      - -193870.19930120106\n",
      "      - -195707.2023788456\n",
      "      - -194289.06600765078\n",
      "      - -219798.43942692122\n",
      "      - -201688.53815322064\n",
      "      - -196326.96989759846\n",
      "      - -197230.11822276327\n",
      "      - -194145.82960930455\n",
      "      - -195863.00415806624\n",
      "      - -197779.45193573783\n",
      "      - -196431.70318763788\n",
      "      - -190892.74829599715\n",
      "      - -197060.18835372126\n",
      "      - -193286.52919559757\n",
      "      - -194966.42335042063\n",
      "      - -196004.28064017108\n",
      "      - -196211.3189927639\n",
      "      - -193864.93210257776\n",
      "      - -194587.40462626825\n",
      "      - -196094.33546141337\n",
      "      - -200795.9326259106\n",
      "      - -193586.89030522827\n",
      "      - -194646.1766556564\n",
      "      - -201191.94752145844\n",
      "      - -194214.7914662693\n",
      "      - -195635.57273497494\n",
      "      - -199595.7983635871\n",
      "      - -192888.11584841151\n",
      "      - -192785.392716028\n",
      "      - -202245.2438911609\n",
      "      - -194804.70939610855\n",
      "      - -193206.2156339105\n",
      "      - -195900.43746447953\n",
      "      - -198698.82251361685\n",
      "      - -195044.6744998495\n",
      "      - -200683.2823412423\n",
      "      - -197244.0561584396\n",
      "      - -208346.87223677413\n",
      "      - -195269.07454408423\n",
      "      - -211873.17460030125\n",
      "      - -192804.60135525066\n",
      "      - -192893.157330221\n",
      "      - -197526.86443727338\n",
      "      - -196692.70147345535\n",
      "      - -199814.22120048656\n",
      "      - -190652.26245979866\n",
      "      - -200026.91412699845\n",
      "      - -192882.65527099167\n",
      "      - -190453.63501521782\n",
      "      - -193282.5199629743\n",
      "      - -195932.15694017196\n",
      "      - -194478.28208955066\n",
      "      - -194221.39399392213\n",
      "      - -192103.02245780075\n",
      "      - -196176.7072430968\n",
      "      - -193331.8442104611\n",
      "      - -201082.56479200616\n",
      "      - -198539.04524153587\n",
      "      - -195015.9425037936\n",
      "      - -193830.8282305915\n",
      "      - -195595.9708476895\n",
      "      - -195888.59451551523\n",
      "      - -192270.97327274736\n",
      "      - -198921.18832648778\n",
      "      - -195348.9124862624\n",
      "      - -201393.72683133892\n",
      "      - -196494.94749682193\n",
      "      - -192076.88821219085\n",
      "      - -196282.66463479094\n",
      "      - -193979.63933047227\n",
      "      - -192133.9555175689\n",
      "      - -197474.3173327739\n",
      "      - -194378.3846087708\n",
      "      - -193487.76366021327\n",
      "      - -191844.3266842268\n",
      "      - -195600.15897700685\n",
      "      - -206882.14958589152\n",
      "      - -193692.58839805954\n",
      "      - -196127.35598694457\n",
      "      - -195943.25733178167\n",
      "      - -193057.5896025252\n",
      "      - -193960.53490296492\n",
      "      - -210024.88797586763\n",
      "      - -210114.81918298805\n",
      "      - -192429.27259192793\n",
      "      - -196201.4059866225\n",
      "      - -194053.53169595427\n",
      "      - -196329.7704481262\n",
      "      - -195883.18639329818\n",
      "      - -194572.78204048047\n",
      "      - -197252.7339151713\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11826006195530664\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5123372528636727\n",
      "      mean_inference_ms: 1.5937660091003827\n",
      "      mean_raw_obs_processing_ms: 0.16230825698825688\n",
      "  time_since_restore: 1701.881855249405\n",
      "  time_this_iter_s: 16.37005305290222\n",
      "  time_total_s: 1701.881855249405\n",
      "  timers:\n",
      "    learn_throughput: 25384.793\n",
      "    learn_time_ms: 2520.564\n",
      "    load_throughput: 526348.47\n",
      "    load_time_ms: 121.562\n",
      "    training_iteration_time_ms: 15911.574\n",
      "    update_time_ms: 4.247\n",
      "  timestamp: 1665743919\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6974256\n",
      "  training_iteration: 109\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:38:44 (running for 00:28:46.74)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   109</td><td style=\"text-align: right;\">         1701.88</td><td style=\"text-align: right;\">6.97426e+06</td><td style=\"text-align: right;\"> -196501</td><td style=\"text-align: right;\">             -190454</td><td style=\"text-align: right;\">             -219798</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:38:49 (running for 00:28:51.87)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   109</td><td style=\"text-align: right;\">         1701.88</td><td style=\"text-align: right;\">6.97426e+06</td><td style=\"text-align: right;\"> -196501</td><td style=\"text-align: right;\">             -190454</td><td style=\"text-align: right;\">             -219798</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:38:54 (running for 00:28:56.87)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   109</td><td style=\"text-align: right;\">         1701.88</td><td style=\"text-align: right;\">6.97426e+06</td><td style=\"text-align: right;\"> -196501</td><td style=\"text-align: right;\">             -190454</td><td style=\"text-align: right;\">             -219798</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 7038240\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 7038240\n",
      "    num_agent_steps_trained: 7038240\n",
      "    num_env_steps_sampled: 7038240\n",
      "    num_env_steps_trained: 7038240\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-38-55\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -190948.7451762392\n",
      "  episode_reward_mean: -196266.6091879642\n",
      "  episode_reward_min: -212856.63433354645\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 7032\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 2.983985185623169\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0023628149647265673\n",
      "          model: {}\n",
      "          policy_loss: 0.003139384323731065\n",
      "          total_loss: 10.003313064575195\n",
      "          vf_explained_var: -2.81517316125246e-07\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 7038240\n",
      "    num_agent_steps_trained: 7038240\n",
      "    num_env_steps_sampled: 7038240\n",
      "    num_env_steps_trained: 7038240\n",
      "  iterations_since_restore: 110\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 7038240\n",
      "  num_agent_steps_trained: 7038240\n",
      "  num_env_steps_sampled: 7038240\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 7038240\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.07272727272728\n",
      "    ram_util_percent: 79.29999999999998\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1181897950336004\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5124046392488129\n",
      "    mean_inference_ms: 1.5933683018748537\n",
      "    mean_raw_obs_processing_ms: 0.16248967857666347\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -190948.7451762392\n",
      "    episode_reward_mean: -196266.6091879642\n",
      "    episode_reward_min: -212856.63433354645\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -194478.28208955066\n",
      "      - -194221.39399392213\n",
      "      - -192103.02245780075\n",
      "      - -196176.7072430968\n",
      "      - -193331.8442104611\n",
      "      - -201082.56479200616\n",
      "      - -198539.04524153587\n",
      "      - -195015.9425037936\n",
      "      - -193830.8282305915\n",
      "      - -195595.9708476895\n",
      "      - -195888.59451551523\n",
      "      - -192270.97327274736\n",
      "      - -198921.18832648778\n",
      "      - -195348.9124862624\n",
      "      - -201393.72683133892\n",
      "      - -196494.94749682193\n",
      "      - -192076.88821219085\n",
      "      - -196282.66463479094\n",
      "      - -193979.63933047227\n",
      "      - -192133.9555175689\n",
      "      - -197474.3173327739\n",
      "      - -194378.3846087708\n",
      "      - -193487.76366021327\n",
      "      - -191844.3266842268\n",
      "      - -195600.15897700685\n",
      "      - -206882.14958589152\n",
      "      - -193692.58839805954\n",
      "      - -196127.35598694457\n",
      "      - -195943.25733178167\n",
      "      - -193057.5896025252\n",
      "      - -193960.53490296492\n",
      "      - -210024.88797586763\n",
      "      - -210114.81918298805\n",
      "      - -192429.27259192793\n",
      "      - -196201.4059866225\n",
      "      - -194053.53169595427\n",
      "      - -196329.7704481262\n",
      "      - -195883.18639329818\n",
      "      - -194572.78204048047\n",
      "      - -197252.7339151713\n",
      "      - -197040.32792282794\n",
      "      - -196756.17386294287\n",
      "      - -196386.7983190035\n",
      "      - -192461.85493716798\n",
      "      - -195973.70415570593\n",
      "      - -193743.9355364915\n",
      "      - -198370.59976072243\n",
      "      - -192695.677330025\n",
      "      - -195519.21245868242\n",
      "      - -200737.4271486722\n",
      "      - -196415.6461153503\n",
      "      - -207570.02498317673\n",
      "      - -195542.25039408088\n",
      "      - -193257.828982513\n",
      "      - -194120.4872809004\n",
      "      - -195062.61947202135\n",
      "      - -194793.30064275666\n",
      "      - -191930.3524781437\n",
      "      - -190948.7451762392\n",
      "      - -203486.989123081\n",
      "      - -194051.39000888506\n",
      "      - -193874.50804521883\n",
      "      - -195539.7961299171\n",
      "      - -196965.40527449214\n",
      "      - -194242.30152031168\n",
      "      - -194490.70606391865\n",
      "      - -193032.13543893522\n",
      "      - -194224.7248850704\n",
      "      - -196915.28160633953\n",
      "      - -193446.80568247626\n",
      "      - -197176.84624745123\n",
      "      - -193352.26232506748\n",
      "      - -195037.3122044604\n",
      "      - -195335.25953472097\n",
      "      - -196983.10095739792\n",
      "      - -197613.90166442908\n",
      "      - -198291.40617556102\n",
      "      - -192444.2999997232\n",
      "      - -197582.8072683038\n",
      "      - -194609.11049860608\n",
      "      - -202143.28039739977\n",
      "      - -197810.33421991678\n",
      "      - -196181.9990068007\n",
      "      - -199781.6816182676\n",
      "      - -212856.63433354645\n",
      "      - -195975.5533392272\n",
      "      - -192810.7959904378\n",
      "      - -193648.84720309536\n",
      "      - -194759.83385600024\n",
      "      - -212855.78323605837\n",
      "      - -196478.07301827447\n",
      "      - -191592.52663899236\n",
      "      - -196172.6335248996\n",
      "      - -201628.45590385422\n",
      "      - -198199.44812981627\n",
      "      - -193888.7599797595\n",
      "      - -194537.15305177757\n",
      "      - -191455.0773187598\n",
      "      - -195706.81950717774\n",
      "      - -191676.00137432158\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1181897950336004\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5124046392488129\n",
      "      mean_inference_ms: 1.5933683018748537\n",
      "      mean_raw_obs_processing_ms: 0.16248967857666347\n",
      "  time_since_restore: 1717.7662980556488\n",
      "  time_this_iter_s: 15.884442806243896\n",
      "  time_total_s: 1717.7662980556488\n",
      "  timers:\n",
      "    learn_throughput: 24964.218\n",
      "    learn_time_ms: 2563.028\n",
      "    load_throughput: 527231.657\n",
      "    load_time_ms: 121.358\n",
      "    training_iteration_time_ms: 15955.746\n",
      "    update_time_ms: 4.165\n",
      "  timestamp: 1665743935\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7038240\n",
      "  training_iteration: 110\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:39:00 (running for 00:29:02.52)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   110</td><td style=\"text-align: right;\">         1717.77</td><td style=\"text-align: right;\">7.03824e+06</td><td style=\"text-align: right;\"> -196267</td><td style=\"text-align: right;\">             -190949</td><td style=\"text-align: right;\">             -212857</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:39:05 (running for 00:29:07.65)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   110</td><td style=\"text-align: right;\">         1717.77</td><td style=\"text-align: right;\">7.03824e+06</td><td style=\"text-align: right;\"> -196267</td><td style=\"text-align: right;\">             -190949</td><td style=\"text-align: right;\">             -212857</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:39:10 (running for 00:29:12.66)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   110</td><td style=\"text-align: right;\">         1717.77</td><td style=\"text-align: right;\">7.03824e+06</td><td style=\"text-align: right;\"> -196267</td><td style=\"text-align: right;\">             -190949</td><td style=\"text-align: right;\">             -212857</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 7102224\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 7102224\n",
      "    num_agent_steps_trained: 7102224\n",
      "    num_env_steps_sampled: 7102224\n",
      "    num_env_steps_trained: 7102224\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-39-11\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -189399.61783644816\n",
      "  episode_reward_mean: -195452.09066737897\n",
      "  episode_reward_min: -212856.63433354645\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 7092\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 2.9849698543548584\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.002009602729231119\n",
      "          model: {}\n",
      "          policy_loss: 0.0008205441408790648\n",
      "          total_loss: 10.000924110412598\n",
      "          vf_explained_var: 1.1187333370799024e-07\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 7102224\n",
      "    num_agent_steps_trained: 7102224\n",
      "    num_env_steps_sampled: 7102224\n",
      "    num_env_steps_trained: 7102224\n",
      "  iterations_since_restore: 111\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 7102224\n",
      "  num_agent_steps_trained: 7102224\n",
      "  num_env_steps_sampled: 7102224\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 7102224\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.04347826086956\n",
      "    ram_util_percent: 79.29999999999998\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11813038571660062\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.512364359411418\n",
      "    mean_inference_ms: 1.5934758591560925\n",
      "    mean_raw_obs_processing_ms: 0.1623916129335603\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -189399.61783644816\n",
      "    episode_reward_mean: -195452.09066737897\n",
      "    episode_reward_min: -212856.63433354645\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -194051.39000888506\n",
      "      - -193874.50804521883\n",
      "      - -195539.7961299171\n",
      "      - -196965.40527449214\n",
      "      - -194242.30152031168\n",
      "      - -194490.70606391865\n",
      "      - -193032.13543893522\n",
      "      - -194224.7248850704\n",
      "      - -196915.28160633953\n",
      "      - -193446.80568247626\n",
      "      - -197176.84624745123\n",
      "      - -193352.26232506748\n",
      "      - -195037.3122044604\n",
      "      - -195335.25953472097\n",
      "      - -196983.10095739792\n",
      "      - -197613.90166442908\n",
      "      - -198291.40617556102\n",
      "      - -192444.2999997232\n",
      "      - -197582.8072683038\n",
      "      - -194609.11049860608\n",
      "      - -202143.28039739977\n",
      "      - -197810.33421991678\n",
      "      - -196181.9990068007\n",
      "      - -199781.6816182676\n",
      "      - -212856.63433354645\n",
      "      - -195975.5533392272\n",
      "      - -192810.7959904378\n",
      "      - -193648.84720309536\n",
      "      - -194759.83385600024\n",
      "      - -212855.78323605837\n",
      "      - -196478.07301827447\n",
      "      - -191592.52663899236\n",
      "      - -196172.6335248996\n",
      "      - -201628.45590385422\n",
      "      - -198199.44812981627\n",
      "      - -193888.7599797595\n",
      "      - -194537.15305177757\n",
      "      - -191455.0773187598\n",
      "      - -195706.81950717774\n",
      "      - -191676.00137432158\n",
      "      - -190628.60950892515\n",
      "      - -190820.27385412456\n",
      "      - -192995.89799110597\n",
      "      - -194086.75853972466\n",
      "      - -190795.3443658076\n",
      "      - -197809.64538295867\n",
      "      - -196055.9805344005\n",
      "      - -193647.66267963275\n",
      "      - -201611.43812678065\n",
      "      - -196177.2295505113\n",
      "      - -191078.66665281926\n",
      "      - -198621.45495199296\n",
      "      - -193918.22106523145\n",
      "      - -193560.48050154414\n",
      "      - -201423.65464272446\n",
      "      - -193580.9323455796\n",
      "      - -193782.65587027906\n",
      "      - -193538.6553457647\n",
      "      - -193286.4046020279\n",
      "      - -198696.9550758971\n",
      "      - -192362.060900293\n",
      "      - -194360.69343255757\n",
      "      - -193520.33346925673\n",
      "      - -201633.14738885296\n",
      "      - -192074.97755345426\n",
      "      - -194132.6703704337\n",
      "      - -196259.691011126\n",
      "      - -196678.24517330644\n",
      "      - -191261.08995853286\n",
      "      - -192757.3995443661\n",
      "      - -196101.68675086155\n",
      "      - -198746.23765908007\n",
      "      - -201977.19624599858\n",
      "      - -193029.7195405374\n",
      "      - -192493.77932448764\n",
      "      - -189399.61783644816\n",
      "      - -198333.67662623027\n",
      "      - -191217.85902987025\n",
      "      - -191456.28747012792\n",
      "      - -195585.60672512927\n",
      "      - -199585.93348971222\n",
      "      - -196887.21568640377\n",
      "      - -197370.10236963426\n",
      "      - -192371.63495781238\n",
      "      - -197301.142188949\n",
      "      - -196784.07914719792\n",
      "      - -197295.33712535456\n",
      "      - -194799.00699911936\n",
      "      - -190837.1498026715\n",
      "      - -197364.93707729323\n",
      "      - -196454.19887427732\n",
      "      - -194789.0034633479\n",
      "      - -191971.84075318492\n",
      "      - -200881.6819217104\n",
      "      - -191511.1786719657\n",
      "      - -191921.2378092048\n",
      "      - -190377.20847058122\n",
      "      - -194496.6012953638\n",
      "      - -194898.11846015294\n",
      "      - -192443.50739550433\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11813038571660062\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.512364359411418\n",
      "      mean_inference_ms: 1.5934758591560925\n",
      "      mean_raw_obs_processing_ms: 0.1623916129335603\n",
      "  time_since_restore: 1733.631406545639\n",
      "  time_this_iter_s: 15.865108489990234\n",
      "  time_total_s: 1733.631406545639\n",
      "  timers:\n",
      "    learn_throughput: 25345.318\n",
      "    learn_time_ms: 2524.49\n",
      "    load_throughput: 526070.406\n",
      "    load_time_ms: 121.626\n",
      "    training_iteration_time_ms: 15957.01\n",
      "    update_time_ms: 4.581\n",
      "  timestamp: 1665743951\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7102224\n",
      "  training_iteration: 111\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:39:16 (running for 00:29:18.54)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   111</td><td style=\"text-align: right;\">         1733.63</td><td style=\"text-align: right;\">7.10222e+06</td><td style=\"text-align: right;\"> -195452</td><td style=\"text-align: right;\">             -189400</td><td style=\"text-align: right;\">             -212857</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:39:21 (running for 00:29:23.68)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   111</td><td style=\"text-align: right;\">         1733.63</td><td style=\"text-align: right;\">7.10222e+06</td><td style=\"text-align: right;\"> -195452</td><td style=\"text-align: right;\">             -189400</td><td style=\"text-align: right;\">             -212857</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:39:26 (running for 00:29:28.68)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   111</td><td style=\"text-align: right;\">         1733.63</td><td style=\"text-align: right;\">7.10222e+06</td><td style=\"text-align: right;\"> -195452</td><td style=\"text-align: right;\">             -189400</td><td style=\"text-align: right;\">             -212857</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 7166208\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 7166208\n",
      "    num_agent_steps_trained: 7166208\n",
      "    num_env_steps_sampled: 7166208\n",
      "    num_env_steps_trained: 7166208\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-39-27\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -189399.61783644816\n",
      "  episode_reward_mean: -194889.10118889128\n",
      "  episode_reward_min: -210502.88022200754\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 7164\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 2.9910898208618164\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.002140353200957179\n",
      "          model: {}\n",
      "          policy_loss: 0.0022262465208768845\n",
      "          total_loss: 10.002354621887207\n",
      "          vf_explained_var: -1.6895623957680073e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 7166208\n",
      "    num_agent_steps_trained: 7166208\n",
      "    num_env_steps_sampled: 7166208\n",
      "    num_env_steps_trained: 7166208\n",
      "  iterations_since_restore: 112\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 7166208\n",
      "  num_agent_steps_trained: 7166208\n",
      "  num_env_steps_sampled: 7166208\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 7166208\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.01739130434784\n",
      "    ram_util_percent: 79.29565217391303\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1182566861460553\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5124162098008785\n",
      "    mean_inference_ms: 1.5953700793053\n",
      "    mean_raw_obs_processing_ms: 0.16232787821218905\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -189399.61783644816\n",
      "    episode_reward_mean: -194889.10118889128\n",
      "    episode_reward_min: -210502.88022200754\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -201977.19624599858\n",
      "      - -193029.7195405374\n",
      "      - -192493.77932448764\n",
      "      - -189399.61783644816\n",
      "      - -198333.67662623027\n",
      "      - -191217.85902987025\n",
      "      - -191456.28747012792\n",
      "      - -195585.60672512927\n",
      "      - -199585.93348971222\n",
      "      - -196887.21568640377\n",
      "      - -197370.10236963426\n",
      "      - -192371.63495781238\n",
      "      - -197301.142188949\n",
      "      - -196784.07914719792\n",
      "      - -197295.33712535456\n",
      "      - -194799.00699911936\n",
      "      - -190837.1498026715\n",
      "      - -197364.93707729323\n",
      "      - -196454.19887427732\n",
      "      - -194789.0034633479\n",
      "      - -191971.84075318492\n",
      "      - -200881.6819217104\n",
      "      - -191511.1786719657\n",
      "      - -191921.2378092048\n",
      "      - -190377.20847058122\n",
      "      - -194496.6012953638\n",
      "      - -194898.11846015294\n",
      "      - -192443.50739550433\n",
      "      - -193768.33886773392\n",
      "      - -193223.31946207717\n",
      "      - -197888.6703598601\n",
      "      - -194703.12048672448\n",
      "      - -194686.9676216807\n",
      "      - -192204.3515314901\n",
      "      - -196165.20714260137\n",
      "      - -200547.03087676744\n",
      "      - -191834.96368379184\n",
      "      - -196752.62189283592\n",
      "      - -196400.106395533\n",
      "      - -193910.08373914057\n",
      "      - -198934.44154544832\n",
      "      - -193978.6865624765\n",
      "      - -193743.36504538683\n",
      "      - -192406.7163894681\n",
      "      - -193766.7931132998\n",
      "      - -192646.22415529448\n",
      "      - -199623.28025046724\n",
      "      - -192245.84335976536\n",
      "      - -198517.9863564846\n",
      "      - -193763.17432621916\n",
      "      - -193284.97165323744\n",
      "      - -194980.1713389446\n",
      "      - -202955.45020455847\n",
      "      - -194875.45380509773\n",
      "      - -195272.68607359254\n",
      "      - -190433.5606018086\n",
      "      - -190931.21211644393\n",
      "      - -192520.7558327094\n",
      "      - -192761.7429264677\n",
      "      - -193932.32593512276\n",
      "      - -194152.30252520883\n",
      "      - -192518.444078486\n",
      "      - -192572.97716163538\n",
      "      - -192997.12144201205\n",
      "      - -195150.4698399118\n",
      "      - -192120.36185614733\n",
      "      - -192748.00168148763\n",
      "      - -192699.31156500793\n",
      "      - -194379.84510139836\n",
      "      - -194200.2301082713\n",
      "      - -195809.0045662937\n",
      "      - -192720.99761711797\n",
      "      - -193601.72099376647\n",
      "      - -195446.11210972883\n",
      "      - -198501.52872158086\n",
      "      - -196579.58356870592\n",
      "      - -197595.33913627837\n",
      "      - -193219.18389066742\n",
      "      - -199805.81434990722\n",
      "      - -193493.72124887086\n",
      "      - -190724.76578750342\n",
      "      - -193097.9936103109\n",
      "      - -196653.78175165123\n",
      "      - -196832.33279087002\n",
      "      - -195612.69252714585\n",
      "      - -210502.88022200754\n",
      "      - -199875.77871594578\n",
      "      - -191790.66260780845\n",
      "      - -196765.5028493395\n",
      "      - -193027.46185136103\n",
      "      - -197891.0530344827\n",
      "      - -192703.573057339\n",
      "      - -193611.700864298\n",
      "      - -191334.2425981847\n",
      "      - -196222.55903370323\n",
      "      - -194829.41561659877\n",
      "      - -193834.60942180984\n",
      "      - -195564.39043950132\n",
      "      - -198030.46863284757\n",
      "      - -192197.69950313246\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1182566861460553\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5124162098008785\n",
      "      mean_inference_ms: 1.5953700793053\n",
      "      mean_raw_obs_processing_ms: 0.16232787821218905\n",
      "  time_since_restore: 1749.5677230358124\n",
      "  time_this_iter_s: 15.93631649017334\n",
      "  time_total_s: 1749.5677230358124\n",
      "  timers:\n",
      "    learn_throughput: 25322.458\n",
      "    learn_time_ms: 2526.769\n",
      "    load_throughput: 525609.643\n",
      "    load_time_ms: 121.733\n",
      "    training_iteration_time_ms: 15995.329\n",
      "    update_time_ms: 4.46\n",
      "  timestamp: 1665743967\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7166208\n",
      "  training_iteration: 112\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:39:32 (running for 00:29:34.40)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   112</td><td style=\"text-align: right;\">         1749.57</td><td style=\"text-align: right;\">7.16621e+06</td><td style=\"text-align: right;\"> -194889</td><td style=\"text-align: right;\">             -189400</td><td style=\"text-align: right;\">             -210503</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:39:37 (running for 00:29:39.67)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   112</td><td style=\"text-align: right;\">         1749.57</td><td style=\"text-align: right;\">7.16621e+06</td><td style=\"text-align: right;\"> -194889</td><td style=\"text-align: right;\">             -189400</td><td style=\"text-align: right;\">             -210503</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:39:42 (running for 00:29:44.68)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   112</td><td style=\"text-align: right;\">         1749.57</td><td style=\"text-align: right;\">7.16621e+06</td><td style=\"text-align: right;\"> -194889</td><td style=\"text-align: right;\">             -189400</td><td style=\"text-align: right;\">             -210503</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 7230192\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 7230192\n",
      "    num_agent_steps_trained: 7230192\n",
      "    num_env_steps_sampled: 7230192\n",
      "    num_env_steps_trained: 7230192\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-39-42\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -189441.35088448302\n",
      "  episode_reward_mean: -195285.61356435623\n",
      "  episode_reward_min: -210502.88022200754\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 7224\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 2.9851322174072266\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0017383708618581295\n",
      "          model: {}\n",
      "          policy_loss: 0.0023002743255347013\n",
      "          total_loss: 10.002349853515625\n",
      "          vf_explained_var: -3.0302085178846028e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 7230192\n",
      "    num_agent_steps_trained: 7230192\n",
      "    num_env_steps_sampled: 7230192\n",
      "    num_env_steps_trained: 7230192\n",
      "  iterations_since_restore: 113\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 7230192\n",
      "  num_agent_steps_trained: 7230192\n",
      "  num_env_steps_sampled: 7230192\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 7230192\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.13333333333333\n",
      "    ram_util_percent: 79.28095238095237\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11817529068347313\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5126051665391923\n",
      "    mean_inference_ms: 1.5946450135728059\n",
      "    mean_raw_obs_processing_ms: 0.16250136522544956\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -189441.35088448302\n",
      "    episode_reward_mean: -195285.61356435623\n",
      "    episode_reward_min: -210502.88022200754\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -194152.30252520883\n",
      "      - -192518.444078486\n",
      "      - -192572.97716163538\n",
      "      - -192997.12144201205\n",
      "      - -195150.4698399118\n",
      "      - -192120.36185614733\n",
      "      - -192748.00168148763\n",
      "      - -192699.31156500793\n",
      "      - -194379.84510139836\n",
      "      - -194200.2301082713\n",
      "      - -195809.0045662937\n",
      "      - -192720.99761711797\n",
      "      - -193601.72099376647\n",
      "      - -195446.11210972883\n",
      "      - -198501.52872158086\n",
      "      - -196579.58356870592\n",
      "      - -197595.33913627837\n",
      "      - -193219.18389066742\n",
      "      - -199805.81434990722\n",
      "      - -193493.72124887086\n",
      "      - -190724.76578750342\n",
      "      - -193097.9936103109\n",
      "      - -196653.78175165123\n",
      "      - -196832.33279087002\n",
      "      - -195612.69252714585\n",
      "      - -210502.88022200754\n",
      "      - -199875.77871594578\n",
      "      - -191790.66260780845\n",
      "      - -196765.5028493395\n",
      "      - -193027.46185136103\n",
      "      - -197891.0530344827\n",
      "      - -192703.573057339\n",
      "      - -193611.700864298\n",
      "      - -191334.2425981847\n",
      "      - -196222.55903370323\n",
      "      - -194829.41561659877\n",
      "      - -193834.60942180984\n",
      "      - -195564.39043950132\n",
      "      - -198030.46863284757\n",
      "      - -192197.69950313246\n",
      "      - -194718.18112262918\n",
      "      - -193884.33879834876\n",
      "      - -195381.03254573417\n",
      "      - -197257.49274656884\n",
      "      - -193183.00244186312\n",
      "      - -199647.04552122508\n",
      "      - -195729.4217007305\n",
      "      - -197597.86381617206\n",
      "      - -190494.04821072926\n",
      "      - -191557.22408800834\n",
      "      - -191347.68592939776\n",
      "      - -192151.03005200037\n",
      "      - -192662.5648692633\n",
      "      - -192980.0876000466\n",
      "      - -194916.09750253236\n",
      "      - -193812.0618935051\n",
      "      - -193946.9566025521\n",
      "      - -190859.3020473109\n",
      "      - -196920.8209786698\n",
      "      - -192644.96210921445\n",
      "      - -200793.83200069214\n",
      "      - -193793.7111551681\n",
      "      - -193802.96037587585\n",
      "      - -194649.37673403343\n",
      "      - -193956.45483463403\n",
      "      - -199022.50051375895\n",
      "      - -209990.5311433266\n",
      "      - -206011.50096073086\n",
      "      - -192346.96568505393\n",
      "      - -195610.30167002795\n",
      "      - -190863.66934489302\n",
      "      - -192902.9982286597\n",
      "      - -194647.051190412\n",
      "      - -193294.7400430321\n",
      "      - -199252.66244331957\n",
      "      - -196354.76253678117\n",
      "      - -196086.607188923\n",
      "      - -194048.84306861897\n",
      "      - -193754.48879133657\n",
      "      - -196137.18357016385\n",
      "      - -191003.42541031397\n",
      "      - -193139.73034605407\n",
      "      - -191934.598892108\n",
      "      - -196280.5048620359\n",
      "      - -190859.06950437088\n",
      "      - -196256.15897493725\n",
      "      - -194695.66327054639\n",
      "      - -201045.17757936567\n",
      "      - -201245.20762967027\n",
      "      - -195669.7382519443\n",
      "      - -195225.60143178303\n",
      "      - -194375.39638347604\n",
      "      - -189441.35088448302\n",
      "      - -192343.32114440238\n",
      "      - -194236.3428685556\n",
      "      - -201259.1616659083\n",
      "      - -195478.12037497913\n",
      "      - -206107.89205563138\n",
      "      - -202221.476071272\n",
      "      - -195315.42029952232\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11817529068347313\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5126051665391923\n",
      "      mean_inference_ms: 1.5946450135728059\n",
      "      mean_raw_obs_processing_ms: 0.16250136522544956\n",
      "  time_since_restore: 1764.9712455272675\n",
      "  time_this_iter_s: 15.403522491455078\n",
      "  time_total_s: 1764.9712455272675\n",
      "  timers:\n",
      "    learn_throughput: 26269.707\n",
      "    learn_time_ms: 2435.657\n",
      "    load_throughput: 526353.942\n",
      "    load_time_ms: 121.561\n",
      "    training_iteration_time_ms: 15888.63\n",
      "    update_time_ms: 4.424\n",
      "  timestamp: 1665743982\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7230192\n",
      "  training_iteration: 113\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:39:47 (running for 00:29:50.13)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   113</td><td style=\"text-align: right;\">         1764.97</td><td style=\"text-align: right;\">7.23019e+06</td><td style=\"text-align: right;\"> -195286</td><td style=\"text-align: right;\">             -189441</td><td style=\"text-align: right;\">             -210503</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:39:53 (running for 00:29:55.27)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   113</td><td style=\"text-align: right;\">         1764.97</td><td style=\"text-align: right;\">7.23019e+06</td><td style=\"text-align: right;\"> -195286</td><td style=\"text-align: right;\">             -189441</td><td style=\"text-align: right;\">             -210503</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:39:58 (running for 00:30:00.27)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   113</td><td style=\"text-align: right;\">         1764.97</td><td style=\"text-align: right;\">7.23019e+06</td><td style=\"text-align: right;\"> -195286</td><td style=\"text-align: right;\">             -189441</td><td style=\"text-align: right;\">             -210503</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 7294176\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 7294176\n",
      "    num_agent_steps_trained: 7294176\n",
      "    num_env_steps_sampled: 7294176\n",
      "    num_env_steps_trained: 7294176\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-39-58\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -189380.6258153018\n",
      "  episode_reward_mean: -194884.0950353116\n",
      "  episode_reward_min: -209990.5311433266\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 7284\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 2.9853625297546387\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0021493907552212477\n",
      "          model: {}\n",
      "          policy_loss: -0.0033631750848144293\n",
      "          total_loss: 9.9967679977417\n",
      "          vf_explained_var: -2.5964700398617424e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 7294176\n",
      "    num_agent_steps_trained: 7294176\n",
      "    num_env_steps_sampled: 7294176\n",
      "    num_env_steps_trained: 7294176\n",
      "  iterations_since_restore: 114\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 7294176\n",
      "  num_agent_steps_trained: 7294176\n",
      "  num_env_steps_sampled: 7294176\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 7294176\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.7090909090909\n",
      "    ram_util_percent: 79.29999999999998\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11815786397133309\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5125772602810059\n",
      "    mean_inference_ms: 1.5947146324828703\n",
      "    mean_raw_obs_processing_ms: 0.1624001980520938\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -189380.6258153018\n",
      "    episode_reward_mean: -194884.0950353116\n",
      "    episode_reward_min: -209990.5311433266\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -200793.83200069214\n",
      "      - -193793.7111551681\n",
      "      - -193802.96037587585\n",
      "      - -194649.37673403343\n",
      "      - -193956.45483463403\n",
      "      - -199022.50051375895\n",
      "      - -209990.5311433266\n",
      "      - -206011.50096073086\n",
      "      - -192346.96568505393\n",
      "      - -195610.30167002795\n",
      "      - -190863.66934489302\n",
      "      - -192902.9982286597\n",
      "      - -194647.051190412\n",
      "      - -193294.7400430321\n",
      "      - -199252.66244331957\n",
      "      - -196354.76253678117\n",
      "      - -196086.607188923\n",
      "      - -194048.84306861897\n",
      "      - -193754.48879133657\n",
      "      - -196137.18357016385\n",
      "      - -191003.42541031397\n",
      "      - -193139.73034605407\n",
      "      - -191934.598892108\n",
      "      - -196280.5048620359\n",
      "      - -190859.06950437088\n",
      "      - -196256.15897493725\n",
      "      - -194695.66327054639\n",
      "      - -201045.17757936567\n",
      "      - -201245.20762967027\n",
      "      - -195669.7382519443\n",
      "      - -195225.60143178303\n",
      "      - -194375.39638347604\n",
      "      - -189441.35088448302\n",
      "      - -192343.32114440238\n",
      "      - -194236.3428685556\n",
      "      - -201259.1616659083\n",
      "      - -195478.12037497913\n",
      "      - -206107.89205563138\n",
      "      - -202221.476071272\n",
      "      - -195315.42029952232\n",
      "      - -193622.80336536822\n",
      "      - -193847.99165569418\n",
      "      - -193067.2349554803\n",
      "      - -193884.84512316223\n",
      "      - -193488.09930043144\n",
      "      - -193511.6270903035\n",
      "      - -191761.48571385496\n",
      "      - -198556.62215697684\n",
      "      - -198695.75501189553\n",
      "      - -193248.3568501252\n",
      "      - -191748.20716253313\n",
      "      - -194286.19569637306\n",
      "      - -194410.23872068888\n",
      "      - -194762.24155634455\n",
      "      - -191925.25991619602\n",
      "      - -192952.33452591012\n",
      "      - -193578.02229877442\n",
      "      - -192118.71107275502\n",
      "      - -194205.69478681553\n",
      "      - -191979.61640604908\n",
      "      - -193962.08005351663\n",
      "      - -193494.60523347603\n",
      "      - -193575.66661351014\n",
      "      - -192503.16743711787\n",
      "      - -193437.34403644392\n",
      "      - -196228.37920572975\n",
      "      - -190297.5048260723\n",
      "      - -201320.19034407721\n",
      "      - -195567.11727909534\n",
      "      - -191788.9346642656\n",
      "      - -191897.13747952908\n",
      "      - -193257.24965713627\n",
      "      - -193097.76365200992\n",
      "      - -192951.98250925753\n",
      "      - -189380.6258153018\n",
      "      - -192471.00896995375\n",
      "      - -192723.34616577072\n",
      "      - -191120.08854119646\n",
      "      - -197235.28608710002\n",
      "      - -195007.0805351641\n",
      "      - -194990.21460079067\n",
      "      - -196581.30268844008\n",
      "      - -189928.9343503654\n",
      "      - -190964.72324445815\n",
      "      - -195155.13047205264\n",
      "      - -191779.56689439408\n",
      "      - -193957.3713112369\n",
      "      - -190124.42898579742\n",
      "      - -192058.72955090777\n",
      "      - -193983.56864097685\n",
      "      - -191696.71094036632\n",
      "      - -196079.64458937212\n",
      "      - -198667.69284225506\n",
      "      - -199167.62541077624\n",
      "      - -192055.12231213812\n",
      "      - -201836.33975256394\n",
      "      - -192470.06126579992\n",
      "      - -196116.8719646725\n",
      "      - -191452.7729279352\n",
      "      - -206920.28893360618\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11815786397133309\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5125772602810059\n",
      "      mean_inference_ms: 1.5947146324828703\n",
      "      mean_raw_obs_processing_ms: 0.1624001980520938\n",
      "  time_since_restore: 1780.9798855781555\n",
      "  time_this_iter_s: 16.00864005088806\n",
      "  time_total_s: 1780.9798855781555\n",
      "  timers:\n",
      "    learn_throughput: 26265.011\n",
      "    learn_time_ms: 2436.093\n",
      "    load_throughput: 538457.713\n",
      "    load_time_ms: 118.828\n",
      "    training_iteration_time_ms: 15922.782\n",
      "    update_time_ms: 4.39\n",
      "  timestamp: 1665743998\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7294176\n",
      "  training_iteration: 114\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:40:04 (running for 00:30:06.60)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   114</td><td style=\"text-align: right;\">         1780.98</td><td style=\"text-align: right;\">7.29418e+06</td><td style=\"text-align: right;\"> -194884</td><td style=\"text-align: right;\">             -189381</td><td style=\"text-align: right;\">             -209991</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:40:09 (running for 00:30:11.60)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   114</td><td style=\"text-align: right;\">         1780.98</td><td style=\"text-align: right;\">7.29418e+06</td><td style=\"text-align: right;\"> -194884</td><td style=\"text-align: right;\">             -189381</td><td style=\"text-align: right;\">             -209991</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:40:14 (running for 00:30:17.03)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   114</td><td style=\"text-align: right;\">         1780.98</td><td style=\"text-align: right;\">7.29418e+06</td><td style=\"text-align: right;\"> -194884</td><td style=\"text-align: right;\">             -189381</td><td style=\"text-align: right;\">             -209991</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 7358160\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 7358160\n",
      "    num_agent_steps_trained: 7358160\n",
      "    num_env_steps_sampled: 7358160\n",
      "    num_env_steps_trained: 7358160\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-40-15\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -187420.44675768237\n",
      "  episode_reward_mean: -193821.831322811\n",
      "  episode_reward_min: -206920.28893360618\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 7356\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 2.991173028945923\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0019895019941031933\n",
      "          model: {}\n",
      "          policy_loss: 0.0016351460944861174\n",
      "          total_loss: 10.00173568725586\n",
      "          vf_explained_var: -1.7863053471955936e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 7358160\n",
      "    num_agent_steps_trained: 7358160\n",
      "    num_env_steps_sampled: 7358160\n",
      "    num_env_steps_trained: 7358160\n",
      "  iterations_since_restore: 115\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 7358160\n",
      "  num_agent_steps_trained: 7358160\n",
      "  num_env_steps_sampled: 7358160\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 7358160\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.30869565217391\n",
      "    ram_util_percent: 79.29999999999998\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11829552234304173\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5125209581260688\n",
      "    mean_inference_ms: 1.5964628873444133\n",
      "    mean_raw_obs_processing_ms: 0.16241682444110667\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -187420.44675768237\n",
      "    episode_reward_mean: -193821.831322811\n",
      "    episode_reward_min: -206920.28893360618\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -193097.76365200992\n",
      "      - -192951.98250925753\n",
      "      - -189380.6258153018\n",
      "      - -192471.00896995375\n",
      "      - -192723.34616577072\n",
      "      - -191120.08854119646\n",
      "      - -197235.28608710002\n",
      "      - -195007.0805351641\n",
      "      - -194990.21460079067\n",
      "      - -196581.30268844008\n",
      "      - -189928.9343503654\n",
      "      - -190964.72324445815\n",
      "      - -195155.13047205264\n",
      "      - -191779.56689439408\n",
      "      - -193957.3713112369\n",
      "      - -190124.42898579742\n",
      "      - -192058.72955090777\n",
      "      - -193983.56864097685\n",
      "      - -191696.71094036632\n",
      "      - -196079.64458937212\n",
      "      - -198667.69284225506\n",
      "      - -199167.62541077624\n",
      "      - -192055.12231213812\n",
      "      - -201836.33975256394\n",
      "      - -192470.06126579992\n",
      "      - -196116.8719646725\n",
      "      - -191452.7729279352\n",
      "      - -206920.28893360618\n",
      "      - -191768.51481733657\n",
      "      - -191781.12682433732\n",
      "      - -196920.02064021374\n",
      "      - -196234.48482216202\n",
      "      - -193913.140344923\n",
      "      - -191510.4198569159\n",
      "      - -193390.54911563962\n",
      "      - -193523.22947420698\n",
      "      - -200577.5579210952\n",
      "      - -194848.4243953194\n",
      "      - -189670.551885093\n",
      "      - -189753.14600612855\n",
      "      - -195118.2090626436\n",
      "      - -192218.10913060757\n",
      "      - -196638.64721034703\n",
      "      - -197050.2573416476\n",
      "      - -194409.00689936185\n",
      "      - -194127.4173061626\n",
      "      - -189989.3227463385\n",
      "      - -191935.89620975283\n",
      "      - -194782.32820662064\n",
      "      - -194236.22557361404\n",
      "      - -192030.7925768659\n",
      "      - -191784.91578729864\n",
      "      - -193701.19998747832\n",
      "      - -196382.43908741907\n",
      "      - -193844.15365360994\n",
      "      - -187420.44675768237\n",
      "      - -189344.17052593592\n",
      "      - -206490.7340992409\n",
      "      - -191400.1880276013\n",
      "      - -188249.33024428316\n",
      "      - -195488.83463272528\n",
      "      - -192544.8803510601\n",
      "      - -191551.7231301909\n",
      "      - -191447.99271467252\n",
      "      - -194496.94816405964\n",
      "      - -191032.5863013227\n",
      "      - -192494.18289747648\n",
      "      - -193326.67211334265\n",
      "      - -194481.86266472522\n",
      "      - -194403.03763424043\n",
      "      - -194736.82295990878\n",
      "      - -190315.09462167622\n",
      "      - -193287.97438440373\n",
      "      - -192262.59614391907\n",
      "      - -196803.02353163602\n",
      "      - -193715.54595609586\n",
      "      - -194077.70210615257\n",
      "      - -192805.97363217053\n",
      "      - -189294.77719164614\n",
      "      - -191381.51005906382\n",
      "      - -194231.50117125714\n",
      "      - -200461.89394897682\n",
      "      - -196408.0831001158\n",
      "      - -192614.17485348275\n",
      "      - -192824.497376168\n",
      "      - -195307.72539180808\n",
      "      - -193749.06144981523\n",
      "      - -193807.0527972843\n",
      "      - -194645.56529304927\n",
      "      - -195696.93541431235\n",
      "      - -194129.60124618548\n",
      "      - -193538.143677777\n",
      "      - -193709.68541731927\n",
      "      - -193386.1836579515\n",
      "      - -195636.04269120027\n",
      "      - -192781.1021163494\n",
      "      - -190917.77341187032\n",
      "      - -198920.06561705284\n",
      "      - -193569.0781306388\n",
      "      - -190879.98383544615\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11829552234304173\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5125209581260688\n",
      "      mean_inference_ms: 1.5964628873444133\n",
      "      mean_raw_obs_processing_ms: 0.16241682444110667\n",
      "  time_since_restore: 1797.6580634117126\n",
      "  time_this_iter_s: 16.67817783355713\n",
      "  time_total_s: 1797.6580634117126\n",
      "  timers:\n",
      "    learn_throughput: 25304.926\n",
      "    learn_time_ms: 2528.52\n",
      "    load_throughput: 538359.417\n",
      "    load_time_ms: 118.85\n",
      "    training_iteration_time_ms: 15992.92\n",
      "    update_time_ms: 4.389\n",
      "  timestamp: 1665744015\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7358160\n",
      "  training_iteration: 115\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:40:20 (running for 00:30:22.51)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   115</td><td style=\"text-align: right;\">         1797.66</td><td style=\"text-align: right;\">7.35816e+06</td><td style=\"text-align: right;\"> -193822</td><td style=\"text-align: right;\">             -187420</td><td style=\"text-align: right;\">             -206920</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:40:25 (running for 00:30:27.86)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   115</td><td style=\"text-align: right;\">         1797.66</td><td style=\"text-align: right;\">7.35816e+06</td><td style=\"text-align: right;\"> -193822</td><td style=\"text-align: right;\">             -187420</td><td style=\"text-align: right;\">             -206920</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:40:30 (running for 00:30:32.87)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   115</td><td style=\"text-align: right;\">         1797.66</td><td style=\"text-align: right;\">7.35816e+06</td><td style=\"text-align: right;\"> -193822</td><td style=\"text-align: right;\">             -187420</td><td style=\"text-align: right;\">             -206920</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 7422144\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 7422144\n",
      "    num_agent_steps_trained: 7422144\n",
      "    num_env_steps_sampled: 7422144\n",
      "    num_env_steps_trained: 7422144\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-40-30\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -187327.25755563864\n",
      "  episode_reward_mean: -194131.34823340236\n",
      "  episode_reward_min: -207058.8497800384\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 7416\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 2.9937405586242676\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0019007906084880233\n",
      "          model: {}\n",
      "          policy_loss: 0.0061987098306417465\n",
      "          total_loss: 10.006279945373535\n",
      "          vf_explained_var: -1.2677448921749601e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 7422144\n",
      "    num_agent_steps_trained: 7422144\n",
      "    num_env_steps_sampled: 7422144\n",
      "    num_env_steps_trained: 7422144\n",
      "  iterations_since_restore: 116\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 7422144\n",
      "  num_agent_steps_trained: 7422144\n",
      "  num_env_steps_sampled: 7422144\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 7422144\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.89090909090909\n",
      "    ram_util_percent: 79.29999999999998\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11821428318013746\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5125113874080819\n",
      "    mean_inference_ms: 1.5958930697979965\n",
      "    mean_raw_obs_processing_ms: 0.16258359916052886\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -187327.25755563864\n",
      "    episode_reward_mean: -194131.34823340236\n",
      "    episode_reward_min: -207058.8497800384\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -195488.83463272528\n",
      "      - -192544.8803510601\n",
      "      - -191551.7231301909\n",
      "      - -191447.99271467252\n",
      "      - -194496.94816405964\n",
      "      - -191032.5863013227\n",
      "      - -192494.18289747648\n",
      "      - -193326.67211334265\n",
      "      - -194481.86266472522\n",
      "      - -194403.03763424043\n",
      "      - -194736.82295990878\n",
      "      - -190315.09462167622\n",
      "      - -193287.97438440373\n",
      "      - -192262.59614391907\n",
      "      - -196803.02353163602\n",
      "      - -193715.54595609586\n",
      "      - -194077.70210615257\n",
      "      - -192805.97363217053\n",
      "      - -189294.77719164614\n",
      "      - -191381.51005906382\n",
      "      - -194231.50117125714\n",
      "      - -200461.89394897682\n",
      "      - -196408.0831001158\n",
      "      - -192614.17485348275\n",
      "      - -192824.497376168\n",
      "      - -195307.72539180808\n",
      "      - -193749.06144981523\n",
      "      - -193807.0527972843\n",
      "      - -194645.56529304927\n",
      "      - -195696.93541431235\n",
      "      - -194129.60124618548\n",
      "      - -193538.143677777\n",
      "      - -193709.68541731927\n",
      "      - -193386.1836579515\n",
      "      - -195636.04269120027\n",
      "      - -192781.1021163494\n",
      "      - -190917.77341187032\n",
      "      - -198920.06561705284\n",
      "      - -193569.0781306388\n",
      "      - -190879.98383544615\n",
      "      - -193437.27980461367\n",
      "      - -195892.76990091417\n",
      "      - -195865.65996590644\n",
      "      - -203123.57672523262\n",
      "      - -193275.37062240098\n",
      "      - -196443.11161210088\n",
      "      - -193697.80861772958\n",
      "      - -198167.82257539066\n",
      "      - -199366.80391197643\n",
      "      - -200713.61200199206\n",
      "      - -193331.34156583168\n",
      "      - -194311.3989872356\n",
      "      - -193742.2172683669\n",
      "      - -194939.9249582719\n",
      "      - -198286.61196403045\n",
      "      - -189363.0704201265\n",
      "      - -196959.09682549458\n",
      "      - -190410.34734014986\n",
      "      - -196464.80020779493\n",
      "      - -197962.79388361165\n",
      "      - -191592.8787996187\n",
      "      - -193626.11719511927\n",
      "      - -192060.89701546027\n",
      "      - -195647.65836427346\n",
      "      - -189948.78175645837\n",
      "      - -195220.40650909903\n",
      "      - -195831.2492710704\n",
      "      - -193423.0026416603\n",
      "      - -195454.3847461392\n",
      "      - -193721.10128763018\n",
      "      - -195070.153031656\n",
      "      - -189418.39155925944\n",
      "      - -191531.55050658074\n",
      "      - -189981.00481838683\n",
      "      - -189763.46899417616\n",
      "      - -192354.72768420682\n",
      "      - -195881.6891286869\n",
      "      - -192146.71924101302\n",
      "      - -194380.45463275502\n",
      "      - -193486.27005102925\n",
      "      - -192545.57338625987\n",
      "      - -207058.8497800384\n",
      "      - -192580.8736986842\n",
      "      - -196015.96390540226\n",
      "      - -195145.85651331287\n",
      "      - -187327.25755563864\n",
      "      - -192821.88201460484\n",
      "      - -192859.28829249748\n",
      "      - -195050.01340614527\n",
      "      - -191673.12327905704\n",
      "      - -197936.44796954645\n",
      "      - -194635.648567462\n",
      "      - -198236.60726626447\n",
      "      - -194338.8682315628\n",
      "      - -192792.1455142409\n",
      "      - -191461.6427095181\n",
      "      - -194672.3176554959\n",
      "      - -194367.1114877174\n",
      "      - -195883.65966410798\n",
      "      - -192271.4742606765\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11821428318013746\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5125113874080819\n",
      "      mean_inference_ms: 1.5958930697979965\n",
      "      mean_raw_obs_processing_ms: 0.16258359916052886\n",
      "  time_since_restore: 1813.1956453323364\n",
      "  time_this_iter_s: 15.53758192062378\n",
      "  time_total_s: 1813.1956453323364\n",
      "  timers:\n",
      "    learn_throughput: 25299.57\n",
      "    learn_time_ms: 2529.055\n",
      "    load_throughput: 541477.219\n",
      "    load_time_ms: 118.166\n",
      "    training_iteration_time_ms: 15946.927\n",
      "    update_time_ms: 4.418\n",
      "  timestamp: 1665744030\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7422144\n",
      "  training_iteration: 116\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:40:36 (running for 00:30:38.45)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   116</td><td style=\"text-align: right;\">          1813.2</td><td style=\"text-align: right;\">7.42214e+06</td><td style=\"text-align: right;\"> -194131</td><td style=\"text-align: right;\">             -187327</td><td style=\"text-align: right;\">             -207059</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:40:41 (running for 00:30:43.45)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   116</td><td style=\"text-align: right;\">          1813.2</td><td style=\"text-align: right;\">7.42214e+06</td><td style=\"text-align: right;\"> -194131</td><td style=\"text-align: right;\">             -187327</td><td style=\"text-align: right;\">             -207059</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:40:46 (running for 00:30:48.47)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   116</td><td style=\"text-align: right;\">          1813.2</td><td style=\"text-align: right;\">7.42214e+06</td><td style=\"text-align: right;\"> -194131</td><td style=\"text-align: right;\">             -187327</td><td style=\"text-align: right;\">             -207059</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 7486128\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 7486128\n",
      "    num_agent_steps_trained: 7486128\n",
      "    num_env_steps_sampled: 7486128\n",
      "    num_env_steps_trained: 7486128\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-40-46\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -187327.25755563864\n",
      "  episode_reward_mean: -194720.9072794314\n",
      "  episode_reward_min: -211403.1997556516\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 7476\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 2.991116523742676\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.002024339744821191\n",
      "          model: {}\n",
      "          policy_loss: 0.002042394829913974\n",
      "          total_loss: 10.002148628234863\n",
      "          vf_explained_var: -4.1938747017411515e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 7486128\n",
      "    num_agent_steps_trained: 7486128\n",
      "    num_env_steps_sampled: 7486128\n",
      "    num_env_steps_trained: 7486128\n",
      "  iterations_since_restore: 117\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 7486128\n",
      "  num_agent_steps_trained: 7486128\n",
      "  num_env_steps_sampled: 7486128\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 7486128\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.02173913043478\n",
      "    ram_util_percent: 79.29999999999998\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11816361665342491\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5124390855688604\n",
      "    mean_inference_ms: 1.5956063640558065\n",
      "    mean_raw_obs_processing_ms: 0.1624904051238602\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -187327.25755563864\n",
      "    episode_reward_mean: -194720.9072794314\n",
      "    episode_reward_min: -211403.1997556516\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -191592.8787996187\n",
      "      - -193626.11719511927\n",
      "      - -192060.89701546027\n",
      "      - -195647.65836427346\n",
      "      - -189948.78175645837\n",
      "      - -195220.40650909903\n",
      "      - -195831.2492710704\n",
      "      - -193423.0026416603\n",
      "      - -195454.3847461392\n",
      "      - -193721.10128763018\n",
      "      - -195070.153031656\n",
      "      - -189418.39155925944\n",
      "      - -191531.55050658074\n",
      "      - -189981.00481838683\n",
      "      - -189763.46899417616\n",
      "      - -192354.72768420682\n",
      "      - -195881.6891286869\n",
      "      - -192146.71924101302\n",
      "      - -194380.45463275502\n",
      "      - -193486.27005102925\n",
      "      - -192545.57338625987\n",
      "      - -207058.8497800384\n",
      "      - -192580.8736986842\n",
      "      - -196015.96390540226\n",
      "      - -195145.85651331287\n",
      "      - -187327.25755563864\n",
      "      - -192821.88201460484\n",
      "      - -192859.28829249748\n",
      "      - -195050.01340614527\n",
      "      - -191673.12327905704\n",
      "      - -197936.44796954645\n",
      "      - -194635.648567462\n",
      "      - -198236.60726626447\n",
      "      - -194338.8682315628\n",
      "      - -192792.1455142409\n",
      "      - -191461.6427095181\n",
      "      - -194672.3176554959\n",
      "      - -194367.1114877174\n",
      "      - -195883.65966410798\n",
      "      - -192271.4742606765\n",
      "      - -193282.8504837814\n",
      "      - -197247.87562604324\n",
      "      - -193684.8435963101\n",
      "      - -193650.87147646645\n",
      "      - -190577.3453966912\n",
      "      - -206067.83936960148\n",
      "      - -194427.46942693292\n",
      "      - -192116.19244557578\n",
      "      - -191822.30805932274\n",
      "      - -198962.42269503916\n",
      "      - -199071.0333271192\n",
      "      - -192872.6913001722\n",
      "      - -208647.32816368283\n",
      "      - -198664.72911932308\n",
      "      - -194266.0856296769\n",
      "      - -193250.61570537052\n",
      "      - -196248.3316396806\n",
      "      - -196754.2100067752\n",
      "      - -192924.09993881764\n",
      "      - -194119.31350535344\n",
      "      - -193095.33639113457\n",
      "      - -192580.18109989734\n",
      "      - -193953.18264376625\n",
      "      - -193772.68825985375\n",
      "      - -195208.7795562416\n",
      "      - -197060.11426233687\n",
      "      - -211403.1997556516\n",
      "      - -198381.30185765753\n",
      "      - -190987.26370452973\n",
      "      - -195537.3834380402\n",
      "      - -193420.337003587\n",
      "      - -194419.77556122554\n",
      "      - -199044.7881456446\n",
      "      - -193342.1444582187\n",
      "      - -198117.4598112373\n",
      "      - -195838.31116215573\n",
      "      - -193533.7947372986\n",
      "      - -191013.99437536\n",
      "      - -190480.04554699527\n",
      "      - -192805.56391878103\n",
      "      - -198922.02183510642\n",
      "      - -210894.62049953197\n",
      "      - -195830.0100754337\n",
      "      - -192280.30522806174\n",
      "      - -194626.54393216106\n",
      "      - -191005.1897772057\n",
      "      - -193673.00756516395\n",
      "      - -197816.467747559\n",
      "      - -188716.02120988155\n",
      "      - -193273.61286368337\n",
      "      - -193388.17616066273\n",
      "      - -195195.528377137\n",
      "      - -198724.37704487116\n",
      "      - -197162.64178717826\n",
      "      - -192622.72454227915\n",
      "      - -194430.15198401507\n",
      "      - -191279.81398189845\n",
      "      - -192275.94041638996\n",
      "      - -192281.6953436305\n",
      "      - -194822.26257742808\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11816361665342491\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5124390855688604\n",
      "      mean_inference_ms: 1.5956063640558065\n",
      "      mean_raw_obs_processing_ms: 0.1624904051238602\n",
      "  time_since_restore: 1829.2812902927399\n",
      "  time_this_iter_s: 16.085644960403442\n",
      "  time_total_s: 1829.2812902927399\n",
      "  timers:\n",
      "    learn_throughput: 24819.773\n",
      "    learn_time_ms: 2577.945\n",
      "    load_throughput: 538603.278\n",
      "    load_time_ms: 118.796\n",
      "    training_iteration_time_ms: 15927.458\n",
      "    update_time_ms: 4.419\n",
      "  timestamp: 1665744046\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7486128\n",
      "  training_iteration: 117\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:40:51 (running for 00:30:54.19)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   117</td><td style=\"text-align: right;\">         1829.28</td><td style=\"text-align: right;\">7.48613e+06</td><td style=\"text-align: right;\"> -194721</td><td style=\"text-align: right;\">             -187327</td><td style=\"text-align: right;\">             -211403</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:40:57 (running for 00:30:59.33)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   117</td><td style=\"text-align: right;\">         1829.28</td><td style=\"text-align: right;\">7.48613e+06</td><td style=\"text-align: right;\"> -194721</td><td style=\"text-align: right;\">             -187327</td><td style=\"text-align: right;\">             -211403</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:41:02 (running for 00:31:04.34)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   117</td><td style=\"text-align: right;\">         1829.28</td><td style=\"text-align: right;\">7.48613e+06</td><td style=\"text-align: right;\"> -194721</td><td style=\"text-align: right;\">             -187327</td><td style=\"text-align: right;\">             -211403</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 7550112\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 7550112\n",
      "    num_agent_steps_trained: 7550112\n",
      "    num_env_steps_sampled: 7550112\n",
      "    num_env_steps_trained: 7550112\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-41-02\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -188716.02120988155\n",
      "  episode_reward_mean: -194097.44825495034\n",
      "  episode_reward_min: -210894.62049953197\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 7548\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 2.989914655685425\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.001534457434900105\n",
      "          model: {}\n",
      "          policy_loss: 0.0067589785903692245\n",
      "          total_loss: 10.006766319274902\n",
      "          vf_explained_var: -3.441480430410593e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 7550112\n",
      "    num_agent_steps_trained: 7550112\n",
      "    num_env_steps_sampled: 7550112\n",
      "    num_env_steps_trained: 7550112\n",
      "  iterations_since_restore: 118\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 7550112\n",
      "  num_agent_steps_trained: 7550112\n",
      "  num_env_steps_sampled: 7550112\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 7550112\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.36666666666667\n",
      "    ram_util_percent: 79.29999999999998\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1183316801160406\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5124723493840734\n",
      "    mean_inference_ms: 1.5966096485851329\n",
      "    mean_raw_obs_processing_ms: 0.16244325410794785\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -188716.02120988155\n",
      "    episode_reward_mean: -194097.44825495034\n",
      "    episode_reward_min: -210894.62049953197\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -199044.7881456446\n",
      "      - -193342.1444582187\n",
      "      - -198117.4598112373\n",
      "      - -195838.31116215573\n",
      "      - -193533.7947372986\n",
      "      - -191013.99437536\n",
      "      - -190480.04554699527\n",
      "      - -192805.56391878103\n",
      "      - -198922.02183510642\n",
      "      - -210894.62049953197\n",
      "      - -195830.0100754337\n",
      "      - -192280.30522806174\n",
      "      - -194626.54393216106\n",
      "      - -191005.1897772057\n",
      "      - -193673.00756516395\n",
      "      - -197816.467747559\n",
      "      - -188716.02120988155\n",
      "      - -193273.61286368337\n",
      "      - -193388.17616066273\n",
      "      - -195195.528377137\n",
      "      - -198724.37704487116\n",
      "      - -197162.64178717826\n",
      "      - -192622.72454227915\n",
      "      - -194430.15198401507\n",
      "      - -191279.81398189845\n",
      "      - -192275.94041638996\n",
      "      - -192281.6953436305\n",
      "      - -194822.26257742808\n",
      "      - -194800.09403577694\n",
      "      - -193381.04347913168\n",
      "      - -190113.14713141878\n",
      "      - -193454.65745207138\n",
      "      - -190881.7582232978\n",
      "      - -193010.9685798775\n",
      "      - -196337.56681385395\n",
      "      - -195551.44218336034\n",
      "      - -193564.95004936215\n",
      "      - -191425.6664124784\n",
      "      - -196623.24073840954\n",
      "      - -194023.65836678195\n",
      "      - -193499.06329311634\n",
      "      - -193373.2474806995\n",
      "      - -194833.5952566434\n",
      "      - -194474.91197879825\n",
      "      - -191242.71566667198\n",
      "      - -194119.02571659823\n",
      "      - -193900.75116563932\n",
      "      - -190138.18121492624\n",
      "      - -193887.65830365138\n",
      "      - -194700.38977087912\n",
      "      - -192973.74182635042\n",
      "      - -195978.37816410974\n",
      "      - -198865.68479599844\n",
      "      - -195654.07652474855\n",
      "      - -196723.86102674177\n",
      "      - -194971.27426710483\n",
      "      - -191998.34835788264\n",
      "      - -197532.48280375474\n",
      "      - -193037.9031954249\n",
      "      - -196074.55136417807\n",
      "      - -191274.6971933132\n",
      "      - -192287.94888310402\n",
      "      - -191124.1215097446\n",
      "      - -189621.0331837744\n",
      "      - -195345.29532174589\n",
      "      - -195951.5891302269\n",
      "      - -192361.17275980313\n",
      "      - -193593.48524056794\n",
      "      - -191020.31785092087\n",
      "      - -195742.84577326872\n",
      "      - -194931.26936491602\n",
      "      - -197700.52047733642\n",
      "      - -193469.29595237013\n",
      "      - -195269.92135686116\n",
      "      - -194407.1526822841\n",
      "      - -189322.3519958116\n",
      "      - -192301.91207113556\n",
      "      - -194567.56333236195\n",
      "      - -193977.6284266805\n",
      "      - -192554.94435547607\n",
      "      - -192600.4378970881\n",
      "      - -194082.0597009041\n",
      "      - -197199.4817585459\n",
      "      - -190742.61268112776\n",
      "      - -195547.3193541493\n",
      "      - -192717.18435654358\n",
      "      - -194823.83658182868\n",
      "      - -196955.29004291366\n",
      "      - -194465.4404605961\n",
      "      - -191789.49305227728\n",
      "      - -195969.72529460772\n",
      "      - -191956.35014614306\n",
      "      - -196693.622016435\n",
      "      - -195208.89223334842\n",
      "      - -190821.98017097407\n",
      "      - -190303.95293835094\n",
      "      - -194643.81087548204\n",
      "      - -192029.86452726406\n",
      "      - -196498.98061486875\n",
      "      - -193324.17318517537\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1183316801160406\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5124723493840734\n",
      "      mean_inference_ms: 1.5966096485851329\n",
      "      mean_raw_obs_processing_ms: 0.16244325410794785\n",
      "  time_since_restore: 1844.7650816440582\n",
      "  time_this_iter_s: 15.48379135131836\n",
      "  time_total_s: 1844.7650816440582\n",
      "  timers:\n",
      "    learn_throughput: 24809.465\n",
      "    learn_time_ms: 2579.016\n",
      "    load_throughput: 535643.125\n",
      "    load_time_ms: 119.453\n",
      "    training_iteration_time_ms: 15917.815\n",
      "    update_time_ms: 4.467\n",
      "  timestamp: 1665744062\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7550112\n",
      "  training_iteration: 118\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:41:07 (running for 00:31:09.84)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   118</td><td style=\"text-align: right;\">         1844.77</td><td style=\"text-align: right;\">7.55011e+06</td><td style=\"text-align: right;\"> -194097</td><td style=\"text-align: right;\">             -188716</td><td style=\"text-align: right;\">             -210895</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:41:12 (running for 00:31:14.84)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   118</td><td style=\"text-align: right;\">         1844.77</td><td style=\"text-align: right;\">7.55011e+06</td><td style=\"text-align: right;\"> -194097</td><td style=\"text-align: right;\">             -188716</td><td style=\"text-align: right;\">             -210895</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:41:17 (running for 00:31:19.85)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   118</td><td style=\"text-align: right;\">         1844.77</td><td style=\"text-align: right;\">7.55011e+06</td><td style=\"text-align: right;\"> -194097</td><td style=\"text-align: right;\">             -188716</td><td style=\"text-align: right;\">             -210895</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 7614096\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 7614096\n",
      "    num_agent_steps_trained: 7614096\n",
      "    num_env_steps_sampled: 7614096\n",
      "    num_env_steps_trained: 7614096\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-41-18\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -189322.3519958116\n",
      "  episode_reward_mean: -193981.55895725722\n",
      "  episode_reward_min: -202170.51686375836\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 7608\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 2.994584321975708\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0021090295631438494\n",
      "          model: {}\n",
      "          policy_loss: 0.001280246302485466\n",
      "          total_loss: 10.001402854919434\n",
      "          vf_explained_var: -2.053609250651789e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 7614096\n",
      "    num_agent_steps_trained: 7614096\n",
      "    num_env_steps_sampled: 7614096\n",
      "    num_env_steps_trained: 7614096\n",
      "  iterations_since_restore: 119\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 7614096\n",
      "  num_agent_steps_trained: 7614096\n",
      "  num_env_steps_sampled: 7614096\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 7614096\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.98636363636363\n",
      "    ram_util_percent: 79.31363636363636\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11827431050642709\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5124723883802326\n",
      "    mean_inference_ms: 1.5959167712228066\n",
      "    mean_raw_obs_processing_ms: 0.1626041725259398\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -189322.3519958116\n",
      "    episode_reward_mean: -193981.55895725722\n",
      "    episode_reward_min: -202170.51686375836\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -191274.6971933132\n",
      "      - -192287.94888310402\n",
      "      - -191124.1215097446\n",
      "      - -189621.0331837744\n",
      "      - -195345.29532174589\n",
      "      - -195951.5891302269\n",
      "      - -192361.17275980313\n",
      "      - -193593.48524056794\n",
      "      - -191020.31785092087\n",
      "      - -195742.84577326872\n",
      "      - -194931.26936491602\n",
      "      - -197700.52047733642\n",
      "      - -193469.29595237013\n",
      "      - -195269.92135686116\n",
      "      - -194407.1526822841\n",
      "      - -189322.3519958116\n",
      "      - -192301.91207113556\n",
      "      - -194567.56333236195\n",
      "      - -193977.6284266805\n",
      "      - -192554.94435547607\n",
      "      - -192600.4378970881\n",
      "      - -194082.0597009041\n",
      "      - -197199.4817585459\n",
      "      - -190742.61268112776\n",
      "      - -195547.3193541493\n",
      "      - -192717.18435654358\n",
      "      - -194823.83658182868\n",
      "      - -196955.29004291366\n",
      "      - -194465.4404605961\n",
      "      - -191789.49305227728\n",
      "      - -195969.72529460772\n",
      "      - -191956.35014614306\n",
      "      - -196693.622016435\n",
      "      - -195208.89223334842\n",
      "      - -190821.98017097407\n",
      "      - -190303.95293835094\n",
      "      - -194643.81087548204\n",
      "      - -192029.86452726406\n",
      "      - -196498.98061486875\n",
      "      - -193324.17318517537\n",
      "      - -192798.86000777618\n",
      "      - -191426.09047387823\n",
      "      - -193925.9673127767\n",
      "      - -192045.11268047648\n",
      "      - -192005.67525480152\n",
      "      - -192998.67908707264\n",
      "      - -199451.67235688295\n",
      "      - -193149.71000182693\n",
      "      - -195594.09511581116\n",
      "      - -191835.605186711\n",
      "      - -194825.7722225497\n",
      "      - -193385.9500030222\n",
      "      - -196507.57989967635\n",
      "      - -193289.25380112705\n",
      "      - -190027.00279690156\n",
      "      - -191984.13421078958\n",
      "      - -193636.03431740662\n",
      "      - -194979.86568530646\n",
      "      - -195580.401409312\n",
      "      - -202170.51686375836\n",
      "      - -194128.98175624292\n",
      "      - -193876.587802191\n",
      "      - -193131.9933053808\n",
      "      - -195763.6336622015\n",
      "      - -195509.14280716298\n",
      "      - -197180.8483047994\n",
      "      - -195058.64208135058\n",
      "      - -195009.54055052172\n",
      "      - -191594.91852295978\n",
      "      - -191551.66780663806\n",
      "      - -195783.51056712045\n",
      "      - -193103.55851551218\n",
      "      - -192328.9278149873\n",
      "      - -191916.4775825395\n",
      "      - -190168.73202307057\n",
      "      - -194239.18992730617\n",
      "      - -196926.9894940238\n",
      "      - -192138.30942492597\n",
      "      - -193800.49538232252\n",
      "      - -201606.31175383367\n",
      "      - -201728.77564189807\n",
      "      - -194738.81451997388\n",
      "      - -190606.3677484923\n",
      "      - -192015.6251002525\n",
      "      - -192962.93060113976\n",
      "      - -195110.06281979557\n",
      "      - -193084.87828429657\n",
      "      - -193163.8866082819\n",
      "      - -194804.52361687823\n",
      "      - -191038.415851847\n",
      "      - -193186.54569029048\n",
      "      - -191060.08677354094\n",
      "      - -198827.5377252609\n",
      "      - -195102.36709060037\n",
      "      - -193057.02723948655\n",
      "      - -192792.74316464996\n",
      "      - -194194.81620238206\n",
      "      - -196021.9313965138\n",
      "      - -199476.05831321728\n",
      "      - -193546.48881364192\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11827431050642709\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5124723883802326\n",
      "      mean_inference_ms: 1.5959167712228066\n",
      "      mean_raw_obs_processing_ms: 0.1626041725259398\n",
      "  time_since_restore: 1860.8205044269562\n",
      "  time_this_iter_s: 16.05542278289795\n",
      "  time_total_s: 1860.8205044269562\n",
      "  timers:\n",
      "    learn_throughput: 24434.58\n",
      "    learn_time_ms: 2618.584\n",
      "    load_throughput: 530447.811\n",
      "    load_time_ms: 120.623\n",
      "    training_iteration_time_ms: 15887.083\n",
      "    update_time_ms: 4.456\n",
      "  timestamp: 1665744078\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7614096\n",
      "  training_iteration: 119\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:41:23 (running for 00:31:25.79)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   119</td><td style=\"text-align: right;\">         1860.82</td><td style=\"text-align: right;\">7.6141e+06</td><td style=\"text-align: right;\"> -193982</td><td style=\"text-align: right;\">             -189322</td><td style=\"text-align: right;\">             -202171</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:41:28 (running for 00:31:30.93)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   119</td><td style=\"text-align: right;\">         1860.82</td><td style=\"text-align: right;\">7.6141e+06</td><td style=\"text-align: right;\"> -193982</td><td style=\"text-align: right;\">             -189322</td><td style=\"text-align: right;\">             -202171</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:41:33 (running for 00:31:35.94)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   119</td><td style=\"text-align: right;\">         1860.82</td><td style=\"text-align: right;\">7.6141e+06</td><td style=\"text-align: right;\"> -193982</td><td style=\"text-align: right;\">             -189322</td><td style=\"text-align: right;\">             -202171</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 7678080\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 7678080\n",
      "    num_agent_steps_trained: 7678080\n",
      "    num_env_steps_sampled: 7678080\n",
      "    num_env_steps_trained: 7678080\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-41-33\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -188938.74672374036\n",
      "  episode_reward_mean: -193780.68102693823\n",
      "  episode_reward_min: -202310.6468856208\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 7668\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 2.9885711669921875\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0020129969343543053\n",
      "          model: {}\n",
      "          policy_loss: 0.0012434907257556915\n",
      "          total_loss: 10.001347541809082\n",
      "          vf_explained_var: -1.2121163308620453e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 7678080\n",
      "    num_agent_steps_trained: 7678080\n",
      "    num_env_steps_sampled: 7678080\n",
      "    num_env_steps_trained: 7678080\n",
      "  iterations_since_restore: 120\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 7678080\n",
      "  num_agent_steps_trained: 7678080\n",
      "  num_env_steps_sampled: 7678080\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 7678080\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.33181818181819\n",
      "    ram_util_percent: 79.29999999999998\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11824833749092126\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5123487354267499\n",
      "    mean_inference_ms: 1.5955402274473256\n",
      "    mean_raw_obs_processing_ms: 0.16249329001527918\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -188938.74672374036\n",
      "    episode_reward_mean: -193780.68102693823\n",
      "    episode_reward_min: -202310.6468856208\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -194128.98175624292\n",
      "      - -193876.587802191\n",
      "      - -193131.9933053808\n",
      "      - -195763.6336622015\n",
      "      - -195509.14280716298\n",
      "      - -197180.8483047994\n",
      "      - -195058.64208135058\n",
      "      - -195009.54055052172\n",
      "      - -191594.91852295978\n",
      "      - -191551.66780663806\n",
      "      - -195783.51056712045\n",
      "      - -193103.55851551218\n",
      "      - -192328.9278149873\n",
      "      - -191916.4775825395\n",
      "      - -190168.73202307057\n",
      "      - -194239.18992730617\n",
      "      - -196926.9894940238\n",
      "      - -192138.30942492597\n",
      "      - -193800.49538232252\n",
      "      - -201606.31175383367\n",
      "      - -201728.77564189807\n",
      "      - -194738.81451997388\n",
      "      - -190606.3677484923\n",
      "      - -192015.6251002525\n",
      "      - -192962.93060113976\n",
      "      - -195110.06281979557\n",
      "      - -193084.87828429657\n",
      "      - -193163.8866082819\n",
      "      - -194804.52361687823\n",
      "      - -191038.415851847\n",
      "      - -193186.54569029048\n",
      "      - -191060.08677354094\n",
      "      - -198827.5377252609\n",
      "      - -195102.36709060037\n",
      "      - -193057.02723948655\n",
      "      - -192792.74316464996\n",
      "      - -194194.81620238206\n",
      "      - -196021.9313965138\n",
      "      - -199476.05831321728\n",
      "      - -193546.48881364192\n",
      "      - -195274.25499699055\n",
      "      - -193289.85448350987\n",
      "      - -192164.1964673436\n",
      "      - -191992.43118748663\n",
      "      - -195799.35887239047\n",
      "      - -192565.7344966158\n",
      "      - -194917.92243095452\n",
      "      - -191705.11998715895\n",
      "      - -191403.46710903145\n",
      "      - -194667.30428455325\n",
      "      - -192192.085699332\n",
      "      - -190997.81203082934\n",
      "      - -192117.08872714834\n",
      "      - -191987.1838430484\n",
      "      - -193197.85173983613\n",
      "      - -190200.37006841225\n",
      "      - -195155.51787099437\n",
      "      - -192443.12885239258\n",
      "      - -192637.4108810345\n",
      "      - -194061.47150379507\n",
      "      - -195314.52295829635\n",
      "      - -191989.39053497915\n",
      "      - -190696.41975490292\n",
      "      - -198293.4881998462\n",
      "      - -193471.269642742\n",
      "      - -193383.98029635445\n",
      "      - -189574.5603445554\n",
      "      - -188938.74672374036\n",
      "      - -192658.46955369308\n",
      "      - -193544.87849445437\n",
      "      - -193955.3137838408\n",
      "      - -190571.03092266395\n",
      "      - -194302.3159092159\n",
      "      - -191447.20462825906\n",
      "      - -191711.81416302806\n",
      "      - -194057.02131140538\n",
      "      - -189551.3550823649\n",
      "      - -195320.6252388112\n",
      "      - -193500.1495610664\n",
      "      - -193052.87847264542\n",
      "      - -191372.38084040923\n",
      "      - -199860.99941311034\n",
      "      - -193085.70438469446\n",
      "      - -195123.43367067247\n",
      "      - -196111.65755227592\n",
      "      - -192230.58044881374\n",
      "      - -190283.96867145837\n",
      "      - -191058.9714423861\n",
      "      - -194376.06856889746\n",
      "      - -190305.01144424744\n",
      "      - -193092.01121667825\n",
      "      - -194369.13705645915\n",
      "      - -197346.60017974602\n",
      "      - -194443.39059829433\n",
      "      - -195967.75878621536\n",
      "      - -194507.88975117097\n",
      "      - -192996.1422765429\n",
      "      - -194427.995087743\n",
      "      - -199354.4110211304\n",
      "      - -202310.6468856208\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11824833749092126\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5123487354267499\n",
      "      mean_inference_ms: 1.5955402274473256\n",
      "      mean_raw_obs_processing_ms: 0.16249329001527918\n",
      "  time_since_restore: 1876.12264752388\n",
      "  time_this_iter_s: 15.302143096923828\n",
      "  time_total_s: 1876.12264752388\n",
      "  timers:\n",
      "    learn_throughput: 24914.669\n",
      "    learn_time_ms: 2568.126\n",
      "    load_throughput: 528881.951\n",
      "    load_time_ms: 120.98\n",
      "    training_iteration_time_ms: 15829.066\n",
      "    update_time_ms: 4.417\n",
      "  timestamp: 1665744093\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7678080\n",
      "  training_iteration: 120\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:41:39 (running for 00:31:41.48)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   120</td><td style=\"text-align: right;\">         1876.12</td><td style=\"text-align: right;\">7.67808e+06</td><td style=\"text-align: right;\"> -193781</td><td style=\"text-align: right;\">             -188939</td><td style=\"text-align: right;\">             -202311</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:41:44 (running for 00:31:46.48)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   120</td><td style=\"text-align: right;\">         1876.12</td><td style=\"text-align: right;\">7.67808e+06</td><td style=\"text-align: right;\"> -193781</td><td style=\"text-align: right;\">             -188939</td><td style=\"text-align: right;\">             -202311</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:41:49 (running for 00:31:51.81)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   120</td><td style=\"text-align: right;\">         1876.12</td><td style=\"text-align: right;\">7.67808e+06</td><td style=\"text-align: right;\"> -193781</td><td style=\"text-align: right;\">             -188939</td><td style=\"text-align: right;\">             -202311</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 7742064\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 7742064\n",
      "    num_agent_steps_trained: 7742064\n",
      "    num_env_steps_sampled: 7742064\n",
      "    num_env_steps_trained: 7742064\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-41-50\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -187244.36006962426\n",
      "  episode_reward_mean: -194498.5853613473\n",
      "  episode_reward_min: -219718.75404474433\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 7740\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 2.988121271133423\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0019216041546314955\n",
      "          model: {}\n",
      "          policy_loss: 0.006630155723541975\n",
      "          total_loss: 10.006715774536133\n",
      "          vf_explained_var: -3.7372112728917273e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 7742064\n",
      "    num_agent_steps_trained: 7742064\n",
      "    num_env_steps_sampled: 7742064\n",
      "    num_env_steps_trained: 7742064\n",
      "  iterations_since_restore: 121\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 7742064\n",
      "  num_agent_steps_trained: 7742064\n",
      "  num_env_steps_sampled: 7742064\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 7742064\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 78.57826086956521\n",
      "    ram_util_percent: 79.3086956521739\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11835738589055342\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5124219886518375\n",
      "    mean_inference_ms: 1.5966828877074624\n",
      "    mean_raw_obs_processing_ms: 0.16244083521563776\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -187244.36006962426\n",
      "    episode_reward_mean: -194498.5853613473\n",
      "    episode_reward_min: -219718.75404474433\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -194302.3159092159\n",
      "      - -191447.20462825906\n",
      "      - -191711.81416302806\n",
      "      - -194057.02131140538\n",
      "      - -189551.3550823649\n",
      "      - -195320.6252388112\n",
      "      - -193500.1495610664\n",
      "      - -193052.87847264542\n",
      "      - -191372.38084040923\n",
      "      - -199860.99941311034\n",
      "      - -193085.70438469446\n",
      "      - -195123.43367067247\n",
      "      - -196111.65755227592\n",
      "      - -192230.58044881374\n",
      "      - -190283.96867145837\n",
      "      - -191058.9714423861\n",
      "      - -194376.06856889746\n",
      "      - -190305.01144424744\n",
      "      - -193092.01121667825\n",
      "      - -194369.13705645915\n",
      "      - -197346.60017974602\n",
      "      - -194443.39059829433\n",
      "      - -195967.75878621536\n",
      "      - -194507.88975117097\n",
      "      - -192996.1422765429\n",
      "      - -194427.995087743\n",
      "      - -199354.4110211304\n",
      "      - -202310.6468856208\n",
      "      - -193657.02478510552\n",
      "      - -189624.83235669092\n",
      "      - -194485.12328088013\n",
      "      - -191484.10955755794\n",
      "      - -198399.28413908946\n",
      "      - -219718.75404474433\n",
      "      - -195814.37077479364\n",
      "      - -192157.45855719026\n",
      "      - -208598.5678912738\n",
      "      - -195008.03138977924\n",
      "      - -192673.01631764343\n",
      "      - -200324.45719913614\n",
      "      - -194282.64837849585\n",
      "      - -194002.30571923175\n",
      "      - -196475.19661658414\n",
      "      - -195326.12524249277\n",
      "      - -193748.23799610074\n",
      "      - -193007.55962969514\n",
      "      - -193273.98028019562\n",
      "      - -191128.82066755343\n",
      "      - -194977.4960400232\n",
      "      - -198141.68754852936\n",
      "      - -193205.20282047233\n",
      "      - -198547.09662009755\n",
      "      - -193586.8850204732\n",
      "      - -196493.09312607007\n",
      "      - -192613.19747759457\n",
      "      - -192104.63908064118\n",
      "      - -202012.72377694712\n",
      "      - -191117.25867507505\n",
      "      - -200781.4112756222\n",
      "      - -191793.55668302462\n",
      "      - -191600.19071720223\n",
      "      - -193358.77290069257\n",
      "      - -194601.69598219165\n",
      "      - -192883.26486518516\n",
      "      - -193559.494895219\n",
      "      - -194417.72819334845\n",
      "      - -193180.01477885252\n",
      "      - -195734.03155236717\n",
      "      - -201237.3241243638\n",
      "      - -193930.81290692228\n",
      "      - -191802.99199557776\n",
      "      - -193541.47811417456\n",
      "      - -191546.99124552397\n",
      "      - -192760.36919475588\n",
      "      - -195198.4538141157\n",
      "      - -191362.94801140725\n",
      "      - -195645.2119342698\n",
      "      - -192050.87293048654\n",
      "      - -193191.60281994008\n",
      "      - -192933.6432159497\n",
      "      - -192827.9191767059\n",
      "      - -202620.16189989937\n",
      "      - -192149.26493244115\n",
      "      - -200923.4363814308\n",
      "      - -195476.784158362\n",
      "      - -193828.10646158815\n",
      "      - -193313.50222024674\n",
      "      - -194057.2419209453\n",
      "      - -193522.48757919265\n",
      "      - -187244.36006962426\n",
      "      - -193823.01182788852\n",
      "      - -191683.2786134821\n",
      "      - -194337.64110580258\n",
      "      - -194713.40860974364\n",
      "      - -189483.15533045854\n",
      "      - -192291.32469437658\n",
      "      - -193857.8953836242\n",
      "      - -190604.95374673745\n",
      "      - -193582.86205137317\n",
      "      - -190847.56914610084\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11835738589055342\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5124219886518375\n",
      "      mean_inference_ms: 1.5966828877074624\n",
      "      mean_raw_obs_processing_ms: 0.16244083521563776\n",
      "  time_since_restore: 1892.6857845783234\n",
      "  time_this_iter_s: 16.56313705444336\n",
      "  time_total_s: 1892.6857845783234\n",
      "  timers:\n",
      "    learn_throughput: 24087.177\n",
      "    learn_time_ms: 2656.351\n",
      "    load_throughput: 525300.071\n",
      "    load_time_ms: 121.805\n",
      "    training_iteration_time_ms: 15898.427\n",
      "    update_time_ms: 4.571\n",
      "  timestamp: 1665744110\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7742064\n",
      "  training_iteration: 121\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:41:55 (running for 00:31:57.74)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   121</td><td style=\"text-align: right;\">         1892.69</td><td style=\"text-align: right;\">7.74206e+06</td><td style=\"text-align: right;\"> -194499</td><td style=\"text-align: right;\">             -187244</td><td style=\"text-align: right;\">             -219719</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:42:00 (running for 00:32:03.00)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   121</td><td style=\"text-align: right;\">         1892.69</td><td style=\"text-align: right;\">7.74206e+06</td><td style=\"text-align: right;\"> -194499</td><td style=\"text-align: right;\">             -187244</td><td style=\"text-align: right;\">             -219719</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:42:05 (running for 00:32:08.00)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   121</td><td style=\"text-align: right;\">         1892.69</td><td style=\"text-align: right;\">7.74206e+06</td><td style=\"text-align: right;\"> -194499</td><td style=\"text-align: right;\">             -187244</td><td style=\"text-align: right;\">             -219719</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 7806048\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 7806048\n",
      "    num_agent_steps_trained: 7806048\n",
      "    num_env_steps_sampled: 7806048\n",
      "    num_env_steps_trained: 7806048\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-42-06\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -187244.36006962426\n",
      "  episode_reward_mean: -193821.57982932363\n",
      "  episode_reward_min: -202620.16189989937\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 7800\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 2.987783670425415\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0019863799680024385\n",
      "          model: {}\n",
      "          policy_loss: 0.0035051354207098484\n",
      "          total_loss: 10.0036039352417\n",
      "          vf_explained_var: -5.811452865600586e-07\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 7806048\n",
      "    num_agent_steps_trained: 7806048\n",
      "    num_env_steps_sampled: 7806048\n",
      "    num_env_steps_trained: 7806048\n",
      "  iterations_since_restore: 122\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 7806048\n",
      "  num_agent_steps_trained: 7806048\n",
      "  num_env_steps_sampled: 7806048\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 7806048\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.56818181818181\n",
      "    ram_util_percent: 79.29999999999998\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11828551908094372\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5124684695456262\n",
      "    mean_inference_ms: 1.5962608527213513\n",
      "    mean_raw_obs_processing_ms: 0.16260006312193323\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -187244.36006962426\n",
      "    episode_reward_mean: -193821.57982932363\n",
      "    episode_reward_min: -202620.16189989937\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -191600.19071720223\n",
      "      - -193358.77290069257\n",
      "      - -194601.69598219165\n",
      "      - -192883.26486518516\n",
      "      - -193559.494895219\n",
      "      - -194417.72819334845\n",
      "      - -193180.01477885252\n",
      "      - -195734.03155236717\n",
      "      - -201237.3241243638\n",
      "      - -193930.81290692228\n",
      "      - -191802.99199557776\n",
      "      - -193541.47811417456\n",
      "      - -191546.99124552397\n",
      "      - -192760.36919475588\n",
      "      - -195198.4538141157\n",
      "      - -191362.94801140725\n",
      "      - -195645.2119342698\n",
      "      - -192050.87293048654\n",
      "      - -193191.60281994008\n",
      "      - -192933.6432159497\n",
      "      - -192827.9191767059\n",
      "      - -202620.16189989937\n",
      "      - -192149.26493244115\n",
      "      - -200923.4363814308\n",
      "      - -195476.784158362\n",
      "      - -193828.10646158815\n",
      "      - -193313.50222024674\n",
      "      - -194057.2419209453\n",
      "      - -193522.48757919265\n",
      "      - -187244.36006962426\n",
      "      - -193823.01182788852\n",
      "      - -191683.2786134821\n",
      "      - -194337.64110580258\n",
      "      - -194713.40860974364\n",
      "      - -189483.15533045854\n",
      "      - -192291.32469437658\n",
      "      - -193857.8953836242\n",
      "      - -190604.95374673745\n",
      "      - -193582.86205137317\n",
      "      - -190847.56914610084\n",
      "      - -190910.94976408244\n",
      "      - -193886.02558619404\n",
      "      - -200067.2253005465\n",
      "      - -190511.79456607116\n",
      "      - -195895.14428086282\n",
      "      - -193916.4748434967\n",
      "      - -195553.00357732055\n",
      "      - -193170.9038052493\n",
      "      - -189141.35162988762\n",
      "      - -191405.83231282234\n",
      "      - -191117.38502344786\n",
      "      - -195904.0578273059\n",
      "      - -193260.20075483838\n",
      "      - -194562.48515873888\n",
      "      - -194020.6954861129\n",
      "      - -199334.1021276056\n",
      "      - -195880.7713456277\n",
      "      - -193130.28811386816\n",
      "      - -191500.6695795605\n",
      "      - -193897.07652276906\n",
      "      - -195209.92686780053\n",
      "      - -193456.37258289394\n",
      "      - -193515.90607717502\n",
      "      - -200145.38362688507\n",
      "      - -194850.31529627353\n",
      "      - -195392.99909922373\n",
      "      - -193472.55892771616\n",
      "      - -194933.74413084926\n",
      "      - -193389.20572363498\n",
      "      - -192832.67544519753\n",
      "      - -192363.39506277756\n",
      "      - -196882.88357777186\n",
      "      - -194344.99928946723\n",
      "      - -190961.58069829093\n",
      "      - -190536.6421741205\n",
      "      - -192241.78480822782\n",
      "      - -191850.41807734626\n",
      "      - -192979.2830370027\n",
      "      - -194225.65743726623\n",
      "      - -192801.0075034301\n",
      "      - -191560.5404589403\n",
      "      - -196319.14183294988\n",
      "      - -189806.32300103802\n",
      "      - -193424.50424081358\n",
      "      - -198189.72595352426\n",
      "      - -190852.70331471413\n",
      "      - -192840.85630277442\n",
      "      - -192178.5347998907\n",
      "      - -197485.73666162984\n",
      "      - -193572.2053050252\n",
      "      - -198981.23333836818\n",
      "      - -191518.88007216557\n",
      "      - -194130.43564959778\n",
      "      - -192917.50915860655\n",
      "      - -193653.17591530303\n",
      "      - -200629.31828337675\n",
      "      - -196334.970850418\n",
      "      - -193936.43597356605\n",
      "      - -191685.38592633582\n",
      "      - -192960.92934099035\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11828551908094372\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5124684695456262\n",
      "      mean_inference_ms: 1.5962608527213513\n",
      "      mean_raw_obs_processing_ms: 0.16260006312193323\n",
      "  time_since_restore: 1908.3750426769257\n",
      "  time_this_iter_s: 15.689258098602295\n",
      "  time_total_s: 1908.3750426769257\n",
      "  timers:\n",
      "    learn_throughput: 24165.812\n",
      "    learn_time_ms: 2647.707\n",
      "    load_throughput: 524244.473\n",
      "    load_time_ms: 122.05\n",
      "    training_iteration_time_ms: 15873.615\n",
      "    update_time_ms: 4.486\n",
      "  timestamp: 1665744126\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7806048\n",
      "  training_iteration: 122\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:42:11 (running for 00:32:13.71)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   122</td><td style=\"text-align: right;\">         1908.38</td><td style=\"text-align: right;\">7.80605e+06</td><td style=\"text-align: right;\"> -193822</td><td style=\"text-align: right;\">             -187244</td><td style=\"text-align: right;\">             -202620</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:42:16 (running for 00:32:18.72)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   122</td><td style=\"text-align: right;\">         1908.38</td><td style=\"text-align: right;\">7.80605e+06</td><td style=\"text-align: right;\"> -193822</td><td style=\"text-align: right;\">             -187244</td><td style=\"text-align: right;\">             -202620</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:42:21 (running for 00:32:23.73)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   122</td><td style=\"text-align: right;\">         1908.38</td><td style=\"text-align: right;\">7.80605e+06</td><td style=\"text-align: right;\"> -193822</td><td style=\"text-align: right;\">             -187244</td><td style=\"text-align: right;\">             -202620</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 7870032\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 7870032\n",
      "    num_agent_steps_trained: 7870032\n",
      "    num_env_steps_sampled: 7870032\n",
      "    num_env_steps_trained: 7870032\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-42-22\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -189418.47123512762\n",
      "  episode_reward_mean: -193907.4438983875\n",
      "  episode_reward_min: -201539.5768286346\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 7860\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 2.989750623703003\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0023515475913882256\n",
      "          model: {}\n",
      "          policy_loss: -0.0004245741292834282\n",
      "          total_loss: 9.999746322631836\n",
      "          vf_explained_var: -1.4156103134155273e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 7870032\n",
      "    num_agent_steps_trained: 7870032\n",
      "    num_env_steps_sampled: 7870032\n",
      "    num_env_steps_trained: 7870032\n",
      "  iterations_since_restore: 123\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 7870032\n",
      "  num_agent_steps_trained: 7870032\n",
      "  num_env_steps_sampled: 7870032\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 7870032\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.21818181818182\n",
      "    ram_util_percent: 79.30454545454545\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1182423628040814\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5124340972277391\n",
      "    mean_inference_ms: 1.5965186261556108\n",
      "    mean_raw_obs_processing_ms: 0.16253204746877764\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -189418.47123512762\n",
      "    episode_reward_mean: -193907.4438983875\n",
      "    episode_reward_min: -201539.5768286346\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -195209.92686780053\n",
      "      - -193456.37258289394\n",
      "      - -193515.90607717502\n",
      "      - -200145.38362688507\n",
      "      - -194850.31529627353\n",
      "      - -195392.99909922373\n",
      "      - -193472.55892771616\n",
      "      - -194933.74413084926\n",
      "      - -193389.20572363498\n",
      "      - -192832.67544519753\n",
      "      - -192363.39506277756\n",
      "      - -196882.88357777186\n",
      "      - -194344.99928946723\n",
      "      - -190961.58069829093\n",
      "      - -190536.6421741205\n",
      "      - -192241.78480822782\n",
      "      - -191850.41807734626\n",
      "      - -192979.2830370027\n",
      "      - -194225.65743726623\n",
      "      - -192801.0075034301\n",
      "      - -191560.5404589403\n",
      "      - -196319.14183294988\n",
      "      - -189806.32300103802\n",
      "      - -193424.50424081358\n",
      "      - -198189.72595352426\n",
      "      - -190852.70331471413\n",
      "      - -192840.85630277442\n",
      "      - -192178.5347998907\n",
      "      - -197485.73666162984\n",
      "      - -193572.2053050252\n",
      "      - -198981.23333836818\n",
      "      - -191518.88007216557\n",
      "      - -194130.43564959778\n",
      "      - -192917.50915860655\n",
      "      - -193653.17591530303\n",
      "      - -200629.31828337675\n",
      "      - -196334.970850418\n",
      "      - -193936.43597356605\n",
      "      - -191685.38592633582\n",
      "      - -192960.92934099035\n",
      "      - -193079.68867199277\n",
      "      - -190161.53969733982\n",
      "      - -191730.17330528487\n",
      "      - -196095.44720902643\n",
      "      - -192486.50633893537\n",
      "      - -194254.4280926262\n",
      "      - -191075.0247784554\n",
      "      - -192968.69093429387\n",
      "      - -192943.67763803358\n",
      "      - -194600.6272089696\n",
      "      - -193905.29538111202\n",
      "      - -196722.4903486033\n",
      "      - -192474.9163695502\n",
      "      - -196935.00043037243\n",
      "      - -195313.9983412733\n",
      "      - -192984.70301845233\n",
      "      - -192244.9374921798\n",
      "      - -190262.21989452007\n",
      "      - -195520.11163870592\n",
      "      - -189418.47123512762\n",
      "      - -195926.09005484273\n",
      "      - -191552.07868278926\n",
      "      - -192505.13299450206\n",
      "      - -189910.6785666763\n",
      "      - -193753.51643606104\n",
      "      - -192855.8766958992\n",
      "      - -193226.22874130006\n",
      "      - -193747.8737268838\n",
      "      - -195468.20847613996\n",
      "      - -192727.4823173473\n",
      "      - -192300.18852584765\n",
      "      - -193440.35805546804\n",
      "      - -194632.7057567421\n",
      "      - -195586.0776851933\n",
      "      - -194628.88184736928\n",
      "      - -194489.9958214581\n",
      "      - -193689.36777418852\n",
      "      - -192533.18819763788\n",
      "      - -195047.37454661488\n",
      "      - -197863.61738959877\n",
      "      - -194463.0843587936\n",
      "      - -194707.0550180305\n",
      "      - -195360.61873597678\n",
      "      - -193570.26232839175\n",
      "      - -193525.38312558827\n",
      "      - -194182.01621314892\n",
      "      - -194215.039551481\n",
      "      - -193239.67413761123\n",
      "      - -194276.9783347846\n",
      "      - -199417.4376970475\n",
      "      - -192386.36751265317\n",
      "      - -201539.5768286346\n",
      "      - -193742.51635100704\n",
      "      - -193500.18453046764\n",
      "      - -193654.99646361987\n",
      "      - -193892.66911855873\n",
      "      - -192330.45118810513\n",
      "      - -193197.77769746166\n",
      "      - -195142.06773866914\n",
      "      - -193972.07676791685\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1182423628040814\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5124340972277391\n",
      "      mean_inference_ms: 1.5965186261556108\n",
      "      mean_raw_obs_processing_ms: 0.16253204746877764\n",
      "  time_since_restore: 1924.3914585113525\n",
      "  time_this_iter_s: 16.01641583442688\n",
      "  time_total_s: 1924.3914585113525\n",
      "  timers:\n",
      "    learn_throughput: 24179.042\n",
      "    learn_time_ms: 2646.259\n",
      "    load_throughput: 524836.14\n",
      "    load_time_ms: 121.912\n",
      "    training_iteration_time_ms: 15935.139\n",
      "    update_time_ms: 4.508\n",
      "  timestamp: 1665744142\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7870032\n",
      "  training_iteration: 123\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:42:27 (running for 00:32:29.51)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   123</td><td style=\"text-align: right;\">         1924.39</td><td style=\"text-align: right;\">7.87003e+06</td><td style=\"text-align: right;\"> -193907</td><td style=\"text-align: right;\">             -189418</td><td style=\"text-align: right;\">             -201540</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:42:32 (running for 00:32:34.79)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   123</td><td style=\"text-align: right;\">         1924.39</td><td style=\"text-align: right;\">7.87003e+06</td><td style=\"text-align: right;\"> -193907</td><td style=\"text-align: right;\">             -189418</td><td style=\"text-align: right;\">             -201540</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:42:37 (running for 00:32:39.79)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   123</td><td style=\"text-align: right;\">         1924.39</td><td style=\"text-align: right;\">7.87003e+06</td><td style=\"text-align: right;\"> -193907</td><td style=\"text-align: right;\">             -189418</td><td style=\"text-align: right;\">             -201540</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 7934016\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 7934016\n",
      "    num_agent_steps_trained: 7934016\n",
      "    num_env_steps_sampled: 7934016\n",
      "    num_env_steps_trained: 7934016\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-42-37\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -189965.29257176977\n",
      "  episode_reward_mean: -194352.85060781057\n",
      "  episode_reward_min: -209680.31359992968\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 7932\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 2.985276937484741\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0023891045711934566\n",
      "          model: {}\n",
      "          policy_loss: 0.005140863824635744\n",
      "          total_loss: 10.00532054901123\n",
      "          vf_explained_var: -4.677130618802039e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 7934016\n",
      "    num_agent_steps_trained: 7934016\n",
      "    num_env_steps_sampled: 7934016\n",
      "    num_env_steps_trained: 7934016\n",
      "  iterations_since_restore: 124\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 7934016\n",
      "  num_agent_steps_trained: 7934016\n",
      "  num_env_steps_sampled: 7934016\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 7934016\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.27727272727273\n",
      "    ram_util_percent: 79.29999999999998\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11838869630186516\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5126186401901848\n",
      "    mean_inference_ms: 1.5976352839880446\n",
      "    mean_raw_obs_processing_ms: 0.1624918847227439\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -189965.29257176977\n",
      "    episode_reward_mean: -194352.85060781057\n",
      "    episode_reward_min: -209680.31359992968\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -194632.7057567421\n",
      "      - -195586.0776851933\n",
      "      - -194628.88184736928\n",
      "      - -194489.9958214581\n",
      "      - -193689.36777418852\n",
      "      - -192533.18819763788\n",
      "      - -195047.37454661488\n",
      "      - -197863.61738959877\n",
      "      - -194463.0843587936\n",
      "      - -194707.0550180305\n",
      "      - -195360.61873597678\n",
      "      - -193570.26232839175\n",
      "      - -193525.38312558827\n",
      "      - -194182.01621314892\n",
      "      - -194215.039551481\n",
      "      - -193239.67413761123\n",
      "      - -194276.9783347846\n",
      "      - -199417.4376970475\n",
      "      - -192386.36751265317\n",
      "      - -201539.5768286346\n",
      "      - -193742.51635100704\n",
      "      - -193500.18453046764\n",
      "      - -193654.99646361987\n",
      "      - -193892.66911855873\n",
      "      - -192330.45118810513\n",
      "      - -193197.77769746166\n",
      "      - -195142.06773866914\n",
      "      - -193972.07676791685\n",
      "      - -190622.60015708822\n",
      "      - -196005.2093986337\n",
      "      - -191476.73534692996\n",
      "      - -192563.76954977144\n",
      "      - -193304.836546585\n",
      "      - -189965.29257176977\n",
      "      - -193816.3851233184\n",
      "      - -192035.44802718516\n",
      "      - -196024.57169660513\n",
      "      - -190889.8949230684\n",
      "      - -195258.4324082211\n",
      "      - -194395.8827068314\n",
      "      - -192708.34811469194\n",
      "      - -192750.0728413191\n",
      "      - -191305.41603374417\n",
      "      - -192170.29114737108\n",
      "      - -194901.92880483475\n",
      "      - -191047.68627052024\n",
      "      - -193610.6636320447\n",
      "      - -191888.57310170398\n",
      "      - -200577.86149361776\n",
      "      - -190045.15239064087\n",
      "      - -192380.26459195936\n",
      "      - -193457.95921791223\n",
      "      - -192312.9144734247\n",
      "      - -195120.1163965528\n",
      "      - -198152.1788198478\n",
      "      - -193522.6268357923\n",
      "      - -197429.594920561\n",
      "      - -195114.38444235042\n",
      "      - -193060.40462499973\n",
      "      - -194950.2884675139\n",
      "      - -199875.17947340678\n",
      "      - -191084.48717840458\n",
      "      - -194099.21120587952\n",
      "      - -192557.38955672475\n",
      "      - -198339.65518224466\n",
      "      - -194422.0309905967\n",
      "      - -193346.52252309615\n",
      "      - -198530.34703952319\n",
      "      - -191592.62457375225\n",
      "      - -197151.10659240768\n",
      "      - -193510.8089732937\n",
      "      - -191021.9292620862\n",
      "      - -191724.5057810634\n",
      "      - -191132.2236002293\n",
      "      - -193591.79783842777\n",
      "      - -191411.33502017116\n",
      "      - -193636.84545440014\n",
      "      - -192150.30017796386\n",
      "      - -193693.05345803156\n",
      "      - -193430.1148028442\n",
      "      - -193547.3799965219\n",
      "      - -201687.23009102646\n",
      "      - -193508.4324736308\n",
      "      - -191327.20023354926\n",
      "      - -194073.40137266475\n",
      "      - -193552.9702574797\n",
      "      - -198075.86765281184\n",
      "      - -193222.05274548227\n",
      "      - -193899.77446333872\n",
      "      - -190435.50081792418\n",
      "      - -195438.87128132093\n",
      "      - -196566.15816974532\n",
      "      - -194756.21736967965\n",
      "      - -191932.21617133898\n",
      "      - -203743.61127322676\n",
      "      - -193500.11755151485\n",
      "      - -196041.7137767967\n",
      "      - -209680.31359992968\n",
      "      - -197056.6562173832\n",
      "      - -195284.67878698275\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11838869630186516\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5126186401901848\n",
      "      mean_inference_ms: 1.5976352839880446\n",
      "      mean_raw_obs_processing_ms: 0.1624918847227439\n",
      "  time_since_restore: 1939.7793626785278\n",
      "  time_this_iter_s: 15.387904167175293\n",
      "  time_total_s: 1939.7793626785278\n",
      "  timers:\n",
      "    learn_throughput: 24201.381\n",
      "    learn_time_ms: 2643.816\n",
      "    load_throughput: 525133.656\n",
      "    load_time_ms: 121.843\n",
      "    training_iteration_time_ms: 15873.217\n",
      "    update_time_ms: 4.56\n",
      "  timestamp: 1665744157\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7934016\n",
      "  training_iteration: 124\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:42:43 (running for 00:32:45.25)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   124</td><td style=\"text-align: right;\">         1939.78</td><td style=\"text-align: right;\">7.93402e+06</td><td style=\"text-align: right;\"> -194353</td><td style=\"text-align: right;\">             -189965</td><td style=\"text-align: right;\">             -209680</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:42:48 (running for 00:32:50.25)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   124</td><td style=\"text-align: right;\">         1939.78</td><td style=\"text-align: right;\">7.93402e+06</td><td style=\"text-align: right;\"> -194353</td><td style=\"text-align: right;\">             -189965</td><td style=\"text-align: right;\">             -209680</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:42:53 (running for 00:32:55.26)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   124</td><td style=\"text-align: right;\">         1939.78</td><td style=\"text-align: right;\">7.93402e+06</td><td style=\"text-align: right;\"> -194353</td><td style=\"text-align: right;\">             -189965</td><td style=\"text-align: right;\">             -209680</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 7998000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 7998000\n",
      "    num_agent_steps_trained: 7998000\n",
      "    num_env_steps_sampled: 7998000\n",
      "    num_env_steps_trained: 7998000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-42-53\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -189678.7560356628\n",
      "  episode_reward_mean: -194014.93108476623\n",
      "  episode_reward_min: -209680.31359992968\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 7992\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 2.9803988933563232\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00228344788774848\n",
      "          model: {}\n",
      "          policy_loss: 0.003052324056625366\n",
      "          total_loss: 10.003210067749023\n",
      "          vf_explained_var: -1.703854650259018e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 7998000\n",
      "    num_agent_steps_trained: 7998000\n",
      "    num_env_steps_sampled: 7998000\n",
      "    num_env_steps_trained: 7998000\n",
      "  iterations_since_restore: 125\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 7998000\n",
      "  num_agent_steps_trained: 7998000\n",
      "  num_env_steps_sampled: 7998000\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 7998000\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 79.8409090909091\n",
      "    ram_util_percent: 79.32272727272725\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11830522552276433\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5126933750775702\n",
      "    mean_inference_ms: 1.5971983883628438\n",
      "    mean_raw_obs_processing_ms: 0.1626834126206538\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -189678.7560356628\n",
      "    episode_reward_mean: -194014.93108476623\n",
      "    episode_reward_min: -209680.31359992968\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -199875.17947340678\n",
      "      - -191084.48717840458\n",
      "      - -194099.21120587952\n",
      "      - -192557.38955672475\n",
      "      - -198339.65518224466\n",
      "      - -194422.0309905967\n",
      "      - -193346.52252309615\n",
      "      - -198530.34703952319\n",
      "      - -191592.62457375225\n",
      "      - -197151.10659240768\n",
      "      - -193510.8089732937\n",
      "      - -191021.9292620862\n",
      "      - -191724.5057810634\n",
      "      - -191132.2236002293\n",
      "      - -193591.79783842777\n",
      "      - -191411.33502017116\n",
      "      - -193636.84545440014\n",
      "      - -192150.30017796386\n",
      "      - -193693.05345803156\n",
      "      - -193430.1148028442\n",
      "      - -193547.3799965219\n",
      "      - -201687.23009102646\n",
      "      - -193508.4324736308\n",
      "      - -191327.20023354926\n",
      "      - -194073.40137266475\n",
      "      - -193552.9702574797\n",
      "      - -198075.86765281184\n",
      "      - -193222.05274548227\n",
      "      - -193899.77446333872\n",
      "      - -190435.50081792418\n",
      "      - -195438.87128132093\n",
      "      - -196566.15816974532\n",
      "      - -194756.21736967965\n",
      "      - -191932.21617133898\n",
      "      - -203743.61127322676\n",
      "      - -193500.11755151485\n",
      "      - -196041.7137767967\n",
      "      - -209680.31359992968\n",
      "      - -197056.6562173832\n",
      "      - -195284.67878698275\n",
      "      - -191748.07841216004\n",
      "      - -193915.08961834194\n",
      "      - -192495.51520353666\n",
      "      - -189989.82067023104\n",
      "      - -196566.61790945326\n",
      "      - -196364.3564224954\n",
      "      - -196683.3723258505\n",
      "      - -208537.42869224097\n",
      "      - -193451.85972589298\n",
      "      - -195076.56600743544\n",
      "      - -191860.66120933037\n",
      "      - -195860.62648026302\n",
      "      - -189678.7560356628\n",
      "      - -191230.19986058437\n",
      "      - -190418.91379132654\n",
      "      - -190285.59434827304\n",
      "      - -192543.57917316747\n",
      "      - -193422.49431036497\n",
      "      - -192750.57951599767\n",
      "      - -192506.4058024393\n",
      "      - -194206.75575378467\n",
      "      - -194248.3767550369\n",
      "      - -192539.82922941254\n",
      "      - -191620.5175965933\n",
      "      - -192912.99128056323\n",
      "      - -193889.60949262124\n",
      "      - -196496.39790383773\n",
      "      - -191371.36404450983\n",
      "      - -197686.90096489483\n",
      "      - -191143.52321551426\n",
      "      - -192533.24558997597\n",
      "      - -193724.68809543192\n",
      "      - -195270.89411317743\n",
      "      - -192044.64797593124\n",
      "      - -193650.3853165003\n",
      "      - -195289.50586783685\n",
      "      - -195708.99615843478\n",
      "      - -195958.27500118216\n",
      "      - -191822.43180510413\n",
      "      - -189905.867698521\n",
      "      - -191467.42045649252\n",
      "      - -191426.99035123066\n",
      "      - -194963.67102376794\n",
      "      - -192002.1644542071\n",
      "      - -194403.63867966237\n",
      "      - -194059.10954021322\n",
      "      - -194466.9658720417\n",
      "      - -191147.8457677347\n",
      "      - -193249.81512352184\n",
      "      - -193368.07553546378\n",
      "      - -191005.09012947115\n",
      "      - -192377.93910051233\n",
      "      - -197320.76626446898\n",
      "      - -190932.44303245307\n",
      "      - -190241.46341383964\n",
      "      - -194026.4549825037\n",
      "      - -192391.824929031\n",
      "      - -193311.84327914225\n",
      "      - -193832.18068231395\n",
      "      - -194453.85349773875\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11830522552276433\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5126933750775702\n",
      "      mean_inference_ms: 1.5971983883628438\n",
      "      mean_raw_obs_processing_ms: 0.1626834126206538\n",
      "  time_since_restore: 1955.7859296798706\n",
      "  time_this_iter_s: 16.006567001342773\n",
      "  time_total_s: 1955.7859296798706\n",
      "  timers:\n",
      "    learn_throughput: 25032.487\n",
      "    learn_time_ms: 2556.038\n",
      "    load_throughput: 526311.929\n",
      "    load_time_ms: 121.57\n",
      "    training_iteration_time_ms: 15806.182\n",
      "    update_time_ms: 4.607\n",
      "  timestamp: 1665744173\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 7998000\n",
      "  training_iteration: 125\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:42:58 (running for 00:33:00.98)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">       ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   125</td><td style=\"text-align: right;\">         1955.79</td><td style=\"text-align: right;\">7.998e+06</td><td style=\"text-align: right;\"> -194015</td><td style=\"text-align: right;\">             -189679</td><td style=\"text-align: right;\">             -209680</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:43:03 (running for 00:33:06.12)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">       ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   125</td><td style=\"text-align: right;\">         1955.79</td><td style=\"text-align: right;\">7.998e+06</td><td style=\"text-align: right;\"> -194015</td><td style=\"text-align: right;\">             -189679</td><td style=\"text-align: right;\">             -209680</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:43:08 (running for 00:33:11.12)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">       ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   125</td><td style=\"text-align: right;\">         1955.79</td><td style=\"text-align: right;\">7.998e+06</td><td style=\"text-align: right;\"> -194015</td><td style=\"text-align: right;\">             -189679</td><td style=\"text-align: right;\">             -209680</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 8061984\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 8061984\n",
      "    num_agent_steps_trained: 8061984\n",
      "    num_env_steps_sampled: 8061984\n",
      "    num_env_steps_trained: 8061984\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-43-09\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -188160.24334307518\n",
      "  episode_reward_mean: -193342.29639524536\n",
      "  episode_reward_min: -204898.39382509515\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 8052\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 2.9759788513183594\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0022047567181289196\n",
      "          model: {}\n",
      "          policy_loss: 0.0016015078872442245\n",
      "          total_loss: 10.001745223999023\n",
      "          vf_explained_var: 5.862675607204437e-07\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 8061984\n",
      "    num_agent_steps_trained: 8061984\n",
      "    num_env_steps_sampled: 8061984\n",
      "    num_env_steps_trained: 8061984\n",
      "  iterations_since_restore: 126\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 8061984\n",
      "  num_agent_steps_trained: 8061984\n",
      "  num_env_steps_sampled: 8061984\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 8061984\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.48181818181818\n",
      "    ram_util_percent: 79.29999999999998\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1183172196846456\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.512585787348906\n",
      "    mean_inference_ms: 1.5969948830365592\n",
      "    mean_raw_obs_processing_ms: 0.1626200556759648\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -188160.24334307518\n",
      "    episode_reward_mean: -193342.29639524536\n",
      "    episode_reward_min: -204898.39382509515\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -194206.75575378467\n",
      "      - -194248.3767550369\n",
      "      - -192539.82922941254\n",
      "      - -191620.5175965933\n",
      "      - -192912.99128056323\n",
      "      - -193889.60949262124\n",
      "      - -196496.39790383773\n",
      "      - -191371.36404450983\n",
      "      - -197686.90096489483\n",
      "      - -191143.52321551426\n",
      "      - -192533.24558997597\n",
      "      - -193724.68809543192\n",
      "      - -195270.89411317743\n",
      "      - -192044.64797593124\n",
      "      - -193650.3853165003\n",
      "      - -195289.50586783685\n",
      "      - -195708.99615843478\n",
      "      - -195958.27500118216\n",
      "      - -191822.43180510413\n",
      "      - -189905.867698521\n",
      "      - -191467.42045649252\n",
      "      - -191426.99035123066\n",
      "      - -194963.67102376794\n",
      "      - -192002.1644542071\n",
      "      - -194403.63867966237\n",
      "      - -194059.10954021322\n",
      "      - -194466.9658720417\n",
      "      - -191147.8457677347\n",
      "      - -193249.81512352184\n",
      "      - -193368.07553546378\n",
      "      - -191005.09012947115\n",
      "      - -192377.93910051233\n",
      "      - -197320.76626446898\n",
      "      - -190932.44303245307\n",
      "      - -190241.46341383964\n",
      "      - -194026.4549825037\n",
      "      - -192391.824929031\n",
      "      - -193311.84327914225\n",
      "      - -193832.18068231395\n",
      "      - -194453.85349773875\n",
      "      - -192971.30341042113\n",
      "      - -188160.24334307518\n",
      "      - -192198.56253846927\n",
      "      - -190883.71654933548\n",
      "      - -190782.1524870373\n",
      "      - -198873.0524204158\n",
      "      - -190873.24074524402\n",
      "      - -191819.97797227858\n",
      "      - -192339.26039121085\n",
      "      - -193197.96117396982\n",
      "      - -189905.84639516345\n",
      "      - -190331.6319862992\n",
      "      - -190647.5532131453\n",
      "      - -190951.00337020485\n",
      "      - -204898.39382509515\n",
      "      - -196335.7385717134\n",
      "      - -192407.22286713342\n",
      "      - -190796.82696933765\n",
      "      - -194071.00660542736\n",
      "      - -192070.43827375968\n",
      "      - -193899.0836070054\n",
      "      - -194986.1192692513\n",
      "      - -195511.12996118524\n",
      "      - -190946.71535092927\n",
      "      - -197568.6435441763\n",
      "      - -193407.82911372546\n",
      "      - -193693.4221407419\n",
      "      - -196550.51171996462\n",
      "      - -191751.23722097595\n",
      "      - -193820.12258902876\n",
      "      - -192763.58564473232\n",
      "      - -196769.649525807\n",
      "      - -194456.4365392942\n",
      "      - -195810.2991950079\n",
      "      - -197374.85679413966\n",
      "      - -191366.55062110614\n",
      "      - -192957.30674525828\n",
      "      - -199346.02242522346\n",
      "      - -191832.18816207303\n",
      "      - -192387.09561524593\n",
      "      - -192706.8017536317\n",
      "      - -194739.97479192316\n",
      "      - -192053.9449215341\n",
      "      - -192209.47442223202\n",
      "      - -193045.08651799863\n",
      "      - -191519.52662368902\n",
      "      - -197331.56700497522\n",
      "      - -191734.5713529409\n",
      "      - -203225.96260681932\n",
      "      - -193321.34533039975\n",
      "      - -190203.9590894987\n",
      "      - -189575.02840305315\n",
      "      - -194201.0296815327\n",
      "      - -192893.59369598684\n",
      "      - -191361.1803351167\n",
      "      - -192544.7828869562\n",
      "      - -190168.63204705596\n",
      "      - -192911.87208797695\n",
      "      - -190500.26112699235\n",
      "      - -193792.34597593962\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1183172196846456\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.512585787348906\n",
      "      mean_inference_ms: 1.5969948830365592\n",
      "      mean_raw_obs_processing_ms: 0.1626200556759648\n",
      "  time_since_restore: 1971.1972823143005\n",
      "  time_this_iter_s: 15.411352634429932\n",
      "  time_total_s: 1971.1972823143005\n",
      "  timers:\n",
      "    learn_throughput: 25060.494\n",
      "    learn_time_ms: 2553.182\n",
      "    load_throughput: 525356.115\n",
      "    load_time_ms: 121.792\n",
      "    training_iteration_time_ms: 15793.713\n",
      "    update_time_ms: 4.587\n",
      "  timestamp: 1665744189\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8061984\n",
      "  training_iteration: 126\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:43:14 (running for 00:33:16.82)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   126</td><td style=\"text-align: right;\">          1971.2</td><td style=\"text-align: right;\">8.06198e+06</td><td style=\"text-align: right;\"> -193342</td><td style=\"text-align: right;\">             -188160</td><td style=\"text-align: right;\">             -204898</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:43:19 (running for 00:33:21.83)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   126</td><td style=\"text-align: right;\">          1971.2</td><td style=\"text-align: right;\">8.06198e+06</td><td style=\"text-align: right;\"> -193342</td><td style=\"text-align: right;\">             -188160</td><td style=\"text-align: right;\">             -204898</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:43:24 (running for 00:33:26.84)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   126</td><td style=\"text-align: right;\">          1971.2</td><td style=\"text-align: right;\">8.06198e+06</td><td style=\"text-align: right;\"> -193342</td><td style=\"text-align: right;\">             -188160</td><td style=\"text-align: right;\">             -204898</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 8125968\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 8125968\n",
      "    num_agent_steps_trained: 8125968\n",
      "    num_env_steps_sampled: 8125968\n",
      "    num_env_steps_trained: 8125968\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-43-25\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -188673.34245822817\n",
      "  episode_reward_mean: -194044.36271872278\n",
      "  episode_reward_min: -208702.47764539346\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 8124\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 2.9791786670684814\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0021340397652238607\n",
      "          model: {}\n",
      "          policy_loss: 0.0054238587617874146\n",
      "          total_loss: 10.005553245544434\n",
      "          vf_explained_var: -3.1760105230205227e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 8125968\n",
      "    num_agent_steps_trained: 8125968\n",
      "    num_env_steps_sampled: 8125968\n",
      "    num_env_steps_trained: 8125968\n",
      "  iterations_since_restore: 127\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 8125968\n",
      "  num_agent_steps_trained: 8125968\n",
      "  num_env_steps_sampled: 8125968\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 8125968\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.97272727272728\n",
      "    ram_util_percent: 79.35909090909091\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11846846794151691\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5127603499239771\n",
      "    mean_inference_ms: 1.5984146588989663\n",
      "    mean_raw_obs_processing_ms: 0.16258318782759137\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -188673.34245822817\n",
      "    episode_reward_mean: -194044.36271872278\n",
      "    episode_reward_min: -208702.47764539346\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -194456.4365392942\n",
      "      - -195810.2991950079\n",
      "      - -197374.85679413966\n",
      "      - -191366.55062110614\n",
      "      - -192957.30674525828\n",
      "      - -199346.02242522346\n",
      "      - -191832.18816207303\n",
      "      - -192387.09561524593\n",
      "      - -192706.8017536317\n",
      "      - -194739.97479192316\n",
      "      - -192053.9449215341\n",
      "      - -192209.47442223202\n",
      "      - -193045.08651799863\n",
      "      - -191519.52662368902\n",
      "      - -197331.56700497522\n",
      "      - -191734.5713529409\n",
      "      - -203225.96260681932\n",
      "      - -193321.34533039975\n",
      "      - -190203.9590894987\n",
      "      - -189575.02840305315\n",
      "      - -194201.0296815327\n",
      "      - -192893.59369598684\n",
      "      - -191361.1803351167\n",
      "      - -192544.7828869562\n",
      "      - -190168.63204705596\n",
      "      - -192911.87208797695\n",
      "      - -190500.26112699235\n",
      "      - -193792.34597593962\n",
      "      - -196465.37189777428\n",
      "      - -189602.67603368135\n",
      "      - -190172.01329292168\n",
      "      - -195158.99595133602\n",
      "      - -193991.25491926612\n",
      "      - -193023.05301397468\n",
      "      - -193717.02600406372\n",
      "      - -200311.57568721578\n",
      "      - -193258.81938682598\n",
      "      - -193652.54215720232\n",
      "      - -191458.48779109426\n",
      "      - -192407.2019727056\n",
      "      - -196622.49818667307\n",
      "      - -191897.3348306125\n",
      "      - -193687.2560809368\n",
      "      - -192329.46991519735\n",
      "      - -195763.32466735653\n",
      "      - -192475.27228856232\n",
      "      - -197248.33997570604\n",
      "      - -198071.3838164976\n",
      "      - -190474.4631775604\n",
      "      - -194659.73439923112\n",
      "      - -195436.11357525294\n",
      "      - -194922.53814920248\n",
      "      - -201700.91360534332\n",
      "      - -191998.19549460444\n",
      "      - -194800.01317112206\n",
      "      - -204440.45581065866\n",
      "      - -191506.45614119296\n",
      "      - -194815.57335427077\n",
      "      - -194855.8816734064\n",
      "      - -189773.41050549113\n",
      "      - -193047.01549177853\n",
      "      - -192511.06754138425\n",
      "      - -191663.85532623532\n",
      "      - -194626.88857021608\n",
      "      - -191863.36571784865\n",
      "      - -196190.62846349415\n",
      "      - -191490.8634175048\n",
      "      - -205595.0968921267\n",
      "      - -208702.47764539346\n",
      "      - -195970.07691020635\n",
      "      - -192972.62421459073\n",
      "      - -195439.8088791506\n",
      "      - -193965.16936593276\n",
      "      - -188673.34245822817\n",
      "      - -191002.98528210123\n",
      "      - -191895.5533546557\n",
      "      - -188933.75455585515\n",
      "      - -191466.83875820733\n",
      "      - -189687.31659109337\n",
      "      - -193013.23657485854\n",
      "      - -198274.09286837335\n",
      "      - -194531.67087418106\n",
      "      - -194871.0605267412\n",
      "      - -194408.75222706478\n",
      "      - -192175.11446623618\n",
      "      - -206081.84900923978\n",
      "      - -195118.00829349476\n",
      "      - -197488.84803490908\n",
      "      - -190377.5955687007\n",
      "      - -191563.5407539397\n",
      "      - -195776.79734337053\n",
      "      - -194128.41216994496\n",
      "      - -192441.7071021361\n",
      "      - -191175.99216957207\n",
      "      - -193269.90549218244\n",
      "      - -191813.91224121084\n",
      "      - -192188.53668964613\n",
      "      - -188764.88371226192\n",
      "      - -202015.84624483017\n",
      "      - -192988.43639283828\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11846846794151691\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5127603499239771\n",
      "      mean_inference_ms: 1.5984146588989663\n",
      "      mean_raw_obs_processing_ms: 0.16258318782759137\n",
      "  time_since_restore: 1987.2400844097137\n",
      "  time_this_iter_s: 16.042802095413208\n",
      "  time_total_s: 1987.2400844097137\n",
      "  timers:\n",
      "    learn_throughput: 25503.18\n",
      "    learn_time_ms: 2508.864\n",
      "    load_throughput: 527258.485\n",
      "    load_time_ms: 121.352\n",
      "    training_iteration_time_ms: 15789.193\n",
      "    update_time_ms: 4.555\n",
      "  timestamp: 1665744205\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8125968\n",
      "  training_iteration: 127\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:43:30 (running for 00:33:32.90)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   127</td><td style=\"text-align: right;\">         1987.24</td><td style=\"text-align: right;\">8.12597e+06</td><td style=\"text-align: right;\"> -194044</td><td style=\"text-align: right;\">             -188673</td><td style=\"text-align: right;\">             -208702</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:43:35 (running for 00:33:38.05)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   127</td><td style=\"text-align: right;\">         1987.24</td><td style=\"text-align: right;\">8.12597e+06</td><td style=\"text-align: right;\"> -194044</td><td style=\"text-align: right;\">             -188673</td><td style=\"text-align: right;\">             -208702</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:43:41 (running for 00:33:43.24)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   127</td><td style=\"text-align: right;\">         1987.24</td><td style=\"text-align: right;\">8.12597e+06</td><td style=\"text-align: right;\"> -194044</td><td style=\"text-align: right;\">             -188673</td><td style=\"text-align: right;\">             -208702</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 8189952\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 8189952\n",
      "    num_agent_steps_trained: 8189952\n",
      "    num_env_steps_sampled: 8189952\n",
      "    num_env_steps_trained: 8189952\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-43-41\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -188673.34245822817\n",
      "  episode_reward_mean: -194029.70259250642\n",
      "  episode_reward_min: -214342.44287236602\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 8184\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 2.968961238861084\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.00192514737136662\n",
      "          model: {}\n",
      "          policy_loss: 0.00380867812782526\n",
      "          total_loss: 10.003896713256836\n",
      "          vf_explained_var: -4.0745362639427185e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 8189952\n",
      "    num_agent_steps_trained: 8189952\n",
      "    num_env_steps_sampled: 8189952\n",
      "    num_env_steps_trained: 8189952\n",
      "  iterations_since_restore: 128\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 8189952\n",
      "  num_agent_steps_trained: 8189952\n",
      "  num_env_steps_sampled: 8189952\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 8189952\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.76521739130435\n",
      "    ram_util_percent: 79.35652173913044\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11839683765366064\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5129112059805158\n",
      "    mean_inference_ms: 1.5976701441526244\n",
      "    mean_raw_obs_processing_ms: 0.1627318321940901\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -188673.34245822817\n",
      "    episode_reward_mean: -194029.70259250642\n",
      "    episode_reward_min: -214342.44287236602\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -193047.01549177853\n",
      "      - -192511.06754138425\n",
      "      - -191663.85532623532\n",
      "      - -194626.88857021608\n",
      "      - -191863.36571784865\n",
      "      - -196190.62846349415\n",
      "      - -191490.8634175048\n",
      "      - -205595.0968921267\n",
      "      - -208702.47764539346\n",
      "      - -195970.07691020635\n",
      "      - -192972.62421459073\n",
      "      - -195439.8088791506\n",
      "      - -193965.16936593276\n",
      "      - -188673.34245822817\n",
      "      - -191002.98528210123\n",
      "      - -191895.5533546557\n",
      "      - -188933.75455585515\n",
      "      - -191466.83875820733\n",
      "      - -189687.31659109337\n",
      "      - -193013.23657485854\n",
      "      - -198274.09286837335\n",
      "      - -194531.67087418106\n",
      "      - -194871.0605267412\n",
      "      - -194408.75222706478\n",
      "      - -192175.11446623618\n",
      "      - -206081.84900923978\n",
      "      - -195118.00829349476\n",
      "      - -197488.84803490908\n",
      "      - -190377.5955687007\n",
      "      - -191563.5407539397\n",
      "      - -195776.79734337053\n",
      "      - -194128.41216994496\n",
      "      - -192441.7071021361\n",
      "      - -191175.99216957207\n",
      "      - -193269.90549218244\n",
      "      - -191813.91224121084\n",
      "      - -192188.53668964613\n",
      "      - -188764.88371226192\n",
      "      - -202015.84624483017\n",
      "      - -192988.43639283828\n",
      "      - -194754.32988809768\n",
      "      - -192708.82268455694\n",
      "      - -194087.1239564157\n",
      "      - -192157.70591425116\n",
      "      - -192263.4134898671\n",
      "      - -192639.40020471514\n",
      "      - -195854.13999015538\n",
      "      - -190765.58095281728\n",
      "      - -195466.12099899104\n",
      "      - -196019.83675374577\n",
      "      - -195037.34440044238\n",
      "      - -189938.9098569194\n",
      "      - -190739.83064290232\n",
      "      - -195495.04945354236\n",
      "      - -190245.9358770336\n",
      "      - -193243.162190473\n",
      "      - -197943.73593801245\n",
      "      - -198401.62673431882\n",
      "      - -194605.4843240445\n",
      "      - -189097.8370969298\n",
      "      - -192063.7197791308\n",
      "      - -197588.85611201415\n",
      "      - -190985.49470325364\n",
      "      - -192271.21320669365\n",
      "      - -193756.85174155765\n",
      "      - -198900.4318533937\n",
      "      - -194390.8797230181\n",
      "      - -214342.44287236602\n",
      "      - -192062.8858246437\n",
      "      - -196659.62576459383\n",
      "      - -196554.15880872507\n",
      "      - -194262.69108336305\n",
      "      - -193332.9750793473\n",
      "      - -191369.05243704584\n",
      "      - -196384.72287376208\n",
      "      - -194931.8619213563\n",
      "      - -194157.28780943394\n",
      "      - -194778.8198659249\n",
      "      - -191137.99157966496\n",
      "      - -194425.9718980289\n",
      "      - -193068.68381045814\n",
      "      - -192637.39477951106\n",
      "      - -190376.69611656127\n",
      "      - -192722.77861550404\n",
      "      - -197481.2649161507\n",
      "      - -202299.70403762508\n",
      "      - -192793.32618623527\n",
      "      - -189926.23733355454\n",
      "      - -191381.68322952252\n",
      "      - -194842.12055976063\n",
      "      - -194527.9947605668\n",
      "      - -190461.60699709572\n",
      "      - -197812.77801884932\n",
      "      - -188776.12023703955\n",
      "      - -192610.25515672992\n",
      "      - -192972.20569992522\n",
      "      - -190445.01202889576\n",
      "      - -190513.22701428673\n",
      "      - -189428.0274289669\n",
      "      - -193902.88784611752\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11839683765366064\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5129112059805158\n",
      "      mean_inference_ms: 1.5976701441526244\n",
      "      mean_raw_obs_processing_ms: 0.1627318321940901\n",
      "  time_since_restore: 2003.0229694843292\n",
      "  time_this_iter_s: 15.782885074615479\n",
      "  time_total_s: 2003.0229694843292\n",
      "  timers:\n",
      "    learn_throughput: 25141.429\n",
      "    learn_time_ms: 2544.963\n",
      "    load_throughput: 523726.899\n",
      "    load_time_ms: 122.171\n",
      "    training_iteration_time_ms: 15818.906\n",
      "    update_time_ms: 4.556\n",
      "  timestamp: 1665744221\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8189952\n",
      "  training_iteration: 128\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:43:46 (running for 00:33:48.45)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   128</td><td style=\"text-align: right;\">         2003.02</td><td style=\"text-align: right;\">8.18995e+06</td><td style=\"text-align: right;\"> -194030</td><td style=\"text-align: right;\">             -188673</td><td style=\"text-align: right;\">             -214342</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:43:51 (running for 00:33:53.45)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   128</td><td style=\"text-align: right;\">         2003.02</td><td style=\"text-align: right;\">8.18995e+06</td><td style=\"text-align: right;\"> -194030</td><td style=\"text-align: right;\">             -188673</td><td style=\"text-align: right;\">             -214342</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:43:56 (running for 00:33:58.47)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   128</td><td style=\"text-align: right;\">         2003.02</td><td style=\"text-align: right;\">8.18995e+06</td><td style=\"text-align: right;\"> -194030</td><td style=\"text-align: right;\">             -188673</td><td style=\"text-align: right;\">             -214342</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 8253936\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 8253936\n",
      "    num_agent_steps_trained: 8253936\n",
      "    num_env_steps_sampled: 8253936\n",
      "    num_env_steps_trained: 8253936\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-43-56\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -188776.12023703955\n",
      "  episode_reward_mean: -194042.09858714946\n",
      "  episode_reward_min: -218101.75207521368\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 8244\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 2.9602746963500977\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.002211654093116522\n",
      "          model: {}\n",
      "          policy_loss: 0.002994619309902191\n",
      "          total_loss: 10.003141403198242\n",
      "          vf_explained_var: -1.5124678611755371e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 8253936\n",
      "    num_agent_steps_trained: 8253936\n",
      "    num_env_steps_sampled: 8253936\n",
      "    num_env_steps_trained: 8253936\n",
      "  iterations_since_restore: 129\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 8253936\n",
      "  num_agent_steps_trained: 8253936\n",
      "  num_env_steps_sampled: 8253936\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 8253936\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 80.1952380952381\n",
      "    ram_util_percent: 79.36666666666667\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11837703291726762\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5127962830100186\n",
      "    mean_inference_ms: 1.5973721835499202\n",
      "    mean_raw_obs_processing_ms: 0.16262105876002306\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -188776.12023703955\n",
      "    episode_reward_mean: -194042.09858714946\n",
      "    episode_reward_min: -218101.75207521368\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -192063.7197791308\n",
      "      - -197588.85611201415\n",
      "      - -190985.49470325364\n",
      "      - -192271.21320669365\n",
      "      - -193756.85174155765\n",
      "      - -198900.4318533937\n",
      "      - -194390.8797230181\n",
      "      - -214342.44287236602\n",
      "      - -192062.8858246437\n",
      "      - -196659.62576459383\n",
      "      - -196554.15880872507\n",
      "      - -194262.69108336305\n",
      "      - -193332.9750793473\n",
      "      - -191369.05243704584\n",
      "      - -196384.72287376208\n",
      "      - -194931.8619213563\n",
      "      - -194157.28780943394\n",
      "      - -194778.8198659249\n",
      "      - -191137.99157966496\n",
      "      - -194425.9718980289\n",
      "      - -193068.68381045814\n",
      "      - -192637.39477951106\n",
      "      - -190376.69611656127\n",
      "      - -192722.77861550404\n",
      "      - -197481.2649161507\n",
      "      - -202299.70403762508\n",
      "      - -192793.32618623527\n",
      "      - -189926.23733355454\n",
      "      - -191381.68322952252\n",
      "      - -194842.12055976063\n",
      "      - -194527.9947605668\n",
      "      - -190461.60699709572\n",
      "      - -197812.77801884932\n",
      "      - -188776.12023703955\n",
      "      - -192610.25515672992\n",
      "      - -192972.20569992522\n",
      "      - -190445.01202889576\n",
      "      - -190513.22701428673\n",
      "      - -189428.0274289669\n",
      "      - -193902.88784611752\n",
      "      - -194044.58402972404\n",
      "      - -200221.36435989884\n",
      "      - -192595.7455125066\n",
      "      - -195364.83136591114\n",
      "      - -195289.87345759678\n",
      "      - -191264.96649436385\n",
      "      - -193967.39545461035\n",
      "      - -194041.29286266895\n",
      "      - -194074.65347364463\n",
      "      - -190854.33472696773\n",
      "      - -194167.21929177598\n",
      "      - -192931.13763517147\n",
      "      - -191958.86485718878\n",
      "      - -190908.56071493376\n",
      "      - -192548.21657998607\n",
      "      - -191985.96362821473\n",
      "      - -190932.64255924965\n",
      "      - -189750.26652839847\n",
      "      - -195484.2830623473\n",
      "      - -193008.1760930023\n",
      "      - -192716.05550423294\n",
      "      - -193434.65639237856\n",
      "      - -196168.16446724033\n",
      "      - -195495.24194691336\n",
      "      - -202152.27804637773\n",
      "      - -189508.0748909368\n",
      "      - -191790.11613847554\n",
      "      - -191829.07530863627\n",
      "      - -192623.35610251463\n",
      "      - -190002.64383047394\n",
      "      - -190696.8101789745\n",
      "      - -193151.15492446793\n",
      "      - -193874.78648881378\n",
      "      - -193290.15513705066\n",
      "      - -191936.8251635531\n",
      "      - -194787.52751339198\n",
      "      - -194043.3571260459\n",
      "      - -192922.42349727324\n",
      "      - -192063.77097035846\n",
      "      - -190866.13012680592\n",
      "      - -193499.83397090243\n",
      "      - -195648.82188537784\n",
      "      - -194447.79416859668\n",
      "      - -192001.4972674488\n",
      "      - -189695.2285189411\n",
      "      - -191149.64291573878\n",
      "      - -195358.8739654919\n",
      "      - -197418.9087955811\n",
      "      - -192389.28799659156\n",
      "      - -195504.37406275645\n",
      "      - -194615.06055576642\n",
      "      - -218101.75207521368\n",
      "      - -190698.26154043377\n",
      "      - -190586.42870603933\n",
      "      - -195426.4799072226\n",
      "      - -192999.79167553317\n",
      "      - -190986.008884948\n",
      "      - -190833.84990845333\n",
      "      - -216489.2373733162\n",
      "      - -194273.80838684278\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11837703291726762\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5127962830100186\n",
      "      mean_inference_ms: 1.5973721835499202\n",
      "      mean_raw_obs_processing_ms: 0.16262105876002306\n",
      "  time_since_restore: 2018.6227004528046\n",
      "  time_this_iter_s: 15.599730968475342\n",
      "  time_total_s: 2018.6227004528046\n",
      "  timers:\n",
      "    learn_throughput: 25590.503\n",
      "    learn_time_ms: 2500.303\n",
      "    load_throughput: 527627.729\n",
      "    load_time_ms: 121.267\n",
      "    training_iteration_time_ms: 15773.112\n",
      "    update_time_ms: 4.534\n",
      "  timestamp: 1665744236\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8253936\n",
      "  training_iteration: 129\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:44:02 (running for 00:34:04.33)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   129</td><td style=\"text-align: right;\">         2018.62</td><td style=\"text-align: right;\">8.25394e+06</td><td style=\"text-align: right;\"> -194042</td><td style=\"text-align: right;\">             -188776</td><td style=\"text-align: right;\">             -218102</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:44:07 (running for 00:34:09.47)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   129</td><td style=\"text-align: right;\">         2018.62</td><td style=\"text-align: right;\">8.25394e+06</td><td style=\"text-align: right;\"> -194042</td><td style=\"text-align: right;\">             -188776</td><td style=\"text-align: right;\">             -218102</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:44:12 (running for 00:34:14.55)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   129</td><td style=\"text-align: right;\">         2018.62</td><td style=\"text-align: right;\">8.25394e+06</td><td style=\"text-align: right;\"> -194042</td><td style=\"text-align: right;\">             -188776</td><td style=\"text-align: right;\">             -218102</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 8317920\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 8317920\n",
      "    num_agent_steps_trained: 8317920\n",
      "    num_env_steps_sampled: 8317920\n",
      "    num_env_steps_trained: 8317920\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-44-12\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -187884.93637135488\n",
      "  episode_reward_mean: -193257.23516601173\n",
      "  episode_reward_min: -218101.75207521368\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 8316\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 2.964703321456909\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.001890482846647501\n",
      "          model: {}\n",
      "          policy_loss: 0.005353663116693497\n",
      "          total_loss: 10.0054349899292\n",
      "          vf_explained_var: -2.9816076221322874e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 8317920\n",
      "    num_agent_steps_trained: 8317920\n",
      "    num_env_steps_sampled: 8317920\n",
      "    num_env_steps_trained: 8317920\n",
      "  iterations_since_restore: 130\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 8317920\n",
      "  num_agent_steps_trained: 8317920\n",
      "  num_env_steps_sampled: 8317920\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 8317920\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.8608695652174\n",
      "    ram_util_percent: 79.32173913043478\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11844926041931136\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5127589713614624\n",
      "    mean_inference_ms: 1.5989484329594676\n",
      "    mean_raw_obs_processing_ms: 0.16257201775092947\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -187884.93637135488\n",
      "    episode_reward_mean: -193257.23516601173\n",
      "    episode_reward_min: -218101.75207521368\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -193874.78648881378\n",
      "      - -193290.15513705066\n",
      "      - -191936.8251635531\n",
      "      - -194787.52751339198\n",
      "      - -194043.3571260459\n",
      "      - -192922.42349727324\n",
      "      - -192063.77097035846\n",
      "      - -190866.13012680592\n",
      "      - -193499.83397090243\n",
      "      - -195648.82188537784\n",
      "      - -194447.79416859668\n",
      "      - -192001.4972674488\n",
      "      - -189695.2285189411\n",
      "      - -191149.64291573878\n",
      "      - -195358.8739654919\n",
      "      - -197418.9087955811\n",
      "      - -192389.28799659156\n",
      "      - -195504.37406275645\n",
      "      - -194615.06055576642\n",
      "      - -218101.75207521368\n",
      "      - -190698.26154043377\n",
      "      - -190586.42870603933\n",
      "      - -195426.4799072226\n",
      "      - -192999.79167553317\n",
      "      - -190986.008884948\n",
      "      - -190833.84990845333\n",
      "      - -216489.2373733162\n",
      "      - -194273.80838684278\n",
      "      - -194075.61591438233\n",
      "      - -192827.28665922457\n",
      "      - -214589.81407633948\n",
      "      - -193877.79600508406\n",
      "      - -195169.32438978046\n",
      "      - -192974.4060879832\n",
      "      - -192805.635568775\n",
      "      - -191334.95275883842\n",
      "      - -192328.484603427\n",
      "      - -190039.2455294793\n",
      "      - -191538.14740773168\n",
      "      - -190365.10911343055\n",
      "      - -196279.827939572\n",
      "      - -195066.1287301649\n",
      "      - -192479.1636104878\n",
      "      - -198418.9353962203\n",
      "      - -193209.25877096824\n",
      "      - -191264.9585735188\n",
      "      - -196873.68068480393\n",
      "      - -188314.10232996973\n",
      "      - -190605.90793338176\n",
      "      - -192996.7940682789\n",
      "      - -190506.46407938347\n",
      "      - -188730.97119909065\n",
      "      - -191503.9096195926\n",
      "      - -192908.3491789701\n",
      "      - -192487.11395824107\n",
      "      - -193145.64890427055\n",
      "      - -193994.13814446083\n",
      "      - -194224.68610929037\n",
      "      - -188406.35567262844\n",
      "      - -192480.78275250658\n",
      "      - -192568.32357692972\n",
      "      - -190052.03717912338\n",
      "      - -190532.3718628628\n",
      "      - -191396.18650073744\n",
      "      - -193634.77361987377\n",
      "      - -194679.52618750092\n",
      "      - -190907.03702890544\n",
      "      - -192517.93856796913\n",
      "      - -194727.7620770389\n",
      "      - -193550.76993938308\n",
      "      - -190117.07623257168\n",
      "      - -191736.8306716089\n",
      "      - -196422.34085801808\n",
      "      - -187884.93637135488\n",
      "      - -192094.02295891327\n",
      "      - -192830.68133859828\n",
      "      - -191582.2141399462\n",
      "      - -192368.62460290504\n",
      "      - -190374.1813609958\n",
      "      - -191783.20862785832\n",
      "      - -191608.30458987498\n",
      "      - -193280.04400012022\n",
      "      - -194152.3860867669\n",
      "      - -189892.24918784449\n",
      "      - -188983.46961490184\n",
      "      - -191884.2722891146\n",
      "      - -196391.05560934357\n",
      "      - -189689.18241413258\n",
      "      - -193948.610617211\n",
      "      - -192133.6565066378\n",
      "      - -189278.41925297372\n",
      "      - -191035.79930016753\n",
      "      - -192324.75061073722\n",
      "      - -198983.75225671098\n",
      "      - -191143.93234030413\n",
      "      - -190649.89964115294\n",
      "      - -189300.43464647737\n",
      "      - -189525.41991597746\n",
      "      - -194717.7371841235\n",
      "      - -193306.38247874044\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11844926041931136\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5127589713614624\n",
      "      mean_inference_ms: 1.5989484329594676\n",
      "      mean_raw_obs_processing_ms: 0.16257201775092947\n",
      "  time_since_restore: 2034.7310135364532\n",
      "  time_this_iter_s: 16.10831308364868\n",
      "  time_total_s: 2034.7310135364532\n",
      "  timers:\n",
      "    learn_throughput: 25578.278\n",
      "    learn_time_ms: 2501.498\n",
      "    load_throughput: 528641.189\n",
      "    load_time_ms: 121.035\n",
      "    training_iteration_time_ms: 15853.638\n",
      "    update_time_ms: 4.754\n",
      "  timestamp: 1665744252\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8317920\n",
      "  training_iteration: 130\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:44:18 (running for 00:34:20.24)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   130</td><td style=\"text-align: right;\">         2034.73</td><td style=\"text-align: right;\">8.31792e+06</td><td style=\"text-align: right;\"> -193257</td><td style=\"text-align: right;\">             -187885</td><td style=\"text-align: right;\">             -218102</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:44:23 (running for 00:34:25.72)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   130</td><td style=\"text-align: right;\">         2034.73</td><td style=\"text-align: right;\">8.31792e+06</td><td style=\"text-align: right;\"> -193257</td><td style=\"text-align: right;\">             -187885</td><td style=\"text-align: right;\">             -218102</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 8381904\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 8381904\n",
      "    num_agent_steps_trained: 8381904\n",
      "    num_env_steps_sampled: 8381904\n",
      "    num_env_steps_trained: 8381904\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-44-28\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -187884.93637135488\n",
      "  episode_reward_mean: -192500.41192648245\n",
      "  episode_reward_min: -201662.3335482013\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 8376\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 2.961832284927368\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.001963771879673004\n",
      "          model: {}\n",
      "          policy_loss: 0.003964942879974842\n",
      "          total_loss: 10.004060745239258\n",
      "          vf_explained_var: 4.2980536818504333e-07\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 8381904\n",
      "    num_agent_steps_trained: 8381904\n",
      "    num_env_steps_sampled: 8381904\n",
      "    num_env_steps_trained: 8381904\n",
      "  iterations_since_restore: 131\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 8381904\n",
      "  num_agent_steps_trained: 8381904\n",
      "  num_env_steps_sampled: 8381904\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 8381904\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.42727272727274\n",
      "    ram_util_percent: 79.39545454545458\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11840240395454865\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5127906439731666\n",
      "    mean_inference_ms: 1.598284543994306\n",
      "    mean_raw_obs_processing_ms: 0.16271499938771647\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -187884.93637135488\n",
      "    episode_reward_mean: -192500.41192648245\n",
      "    episode_reward_min: -201662.3335482013\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -192568.32357692972\n",
      "      - -190052.03717912338\n",
      "      - -190532.3718628628\n",
      "      - -191396.18650073744\n",
      "      - -193634.77361987377\n",
      "      - -194679.52618750092\n",
      "      - -190907.03702890544\n",
      "      - -192517.93856796913\n",
      "      - -194727.7620770389\n",
      "      - -193550.76993938308\n",
      "      - -190117.07623257168\n",
      "      - -191736.8306716089\n",
      "      - -196422.34085801808\n",
      "      - -187884.93637135488\n",
      "      - -192094.02295891327\n",
      "      - -192830.68133859828\n",
      "      - -191582.2141399462\n",
      "      - -192368.62460290504\n",
      "      - -190374.1813609958\n",
      "      - -191783.20862785832\n",
      "      - -191608.30458987498\n",
      "      - -193280.04400012022\n",
      "      - -194152.3860867669\n",
      "      - -189892.24918784449\n",
      "      - -188983.46961490184\n",
      "      - -191884.2722891146\n",
      "      - -196391.05560934357\n",
      "      - -189689.18241413258\n",
      "      - -193948.610617211\n",
      "      - -192133.6565066378\n",
      "      - -189278.41925297372\n",
      "      - -191035.79930016753\n",
      "      - -192324.75061073722\n",
      "      - -198983.75225671098\n",
      "      - -191143.93234030413\n",
      "      - -190649.89964115294\n",
      "      - -189300.43464647737\n",
      "      - -189525.41991597746\n",
      "      - -194717.7371841235\n",
      "      - -193306.38247874044\n",
      "      - -192884.02225664226\n",
      "      - -190263.15449828634\n",
      "      - -191881.23952697922\n",
      "      - -191911.138295053\n",
      "      - -195927.24579305633\n",
      "      - -195558.67905502196\n",
      "      - -190667.50801832622\n",
      "      - -191602.82261397725\n",
      "      - -195194.30921416412\n",
      "      - -194753.31865515176\n",
      "      - -190584.922645581\n",
      "      - -199073.27371088276\n",
      "      - -193924.6910128504\n",
      "      - -191537.84893407888\n",
      "      - -193004.36329313467\n",
      "      - -188225.79281798474\n",
      "      - -195771.94670438083\n",
      "      - -194276.59571309827\n",
      "      - -192217.19522377677\n",
      "      - -190169.10355323696\n",
      "      - -194495.09575945654\n",
      "      - -193756.6874411995\n",
      "      - -192049.14960244912\n",
      "      - -189981.5695414041\n",
      "      - -189756.05815880143\n",
      "      - -189985.93303607078\n",
      "      - -192857.42392323344\n",
      "      - -195418.66380600707\n",
      "      - -192746.43168908783\n",
      "      - -190253.0303222206\n",
      "      - -191089.0364065828\n",
      "      - -194526.45082222784\n",
      "      - -192767.86828138996\n",
      "      - -190721.33558798287\n",
      "      - -190519.47751828207\n",
      "      - -193361.97405417418\n",
      "      - -197943.15706102605\n",
      "      - -192978.17713521986\n",
      "      - -188460.9563162868\n",
      "      - -193170.90876781289\n",
      "      - -190901.74187612458\n",
      "      - -196455.7814446174\n",
      "      - -192566.191495149\n",
      "      - -190579.2388928355\n",
      "      - -193115.12503353567\n",
      "      - -191479.21618372088\n",
      "      - -194496.03141145612\n",
      "      - -190912.00812092284\n",
      "      - -189891.90960140654\n",
      "      - -201662.3335482013\n",
      "      - -194880.22134005185\n",
      "      - -197161.78549976862\n",
      "      - -192309.93132971146\n",
      "      - -193044.86759641365\n",
      "      - -191031.81489694383\n",
      "      - -194822.18163384323\n",
      "      - -190621.11676350853\n",
      "      - -192545.80902226386\n",
      "      - -192321.7440345049\n",
      "      - -188982.98391027746\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11840240395454865\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5127906439731666\n",
      "      mean_inference_ms: 1.598284543994306\n",
      "      mean_raw_obs_processing_ms: 0.16271499938771647\n",
      "  time_since_restore: 2050.1110010147095\n",
      "  time_this_iter_s: 15.379987478256226\n",
      "  time_total_s: 2050.1110010147095\n",
      "  timers:\n",
      "    learn_throughput: 26561.913\n",
      "    learn_time_ms: 2408.863\n",
      "    load_throughput: 532767.787\n",
      "    load_time_ms: 120.097\n",
      "    training_iteration_time_ms: 15735.632\n",
      "    update_time_ms: 4.276\n",
      "  timestamp: 1665744268\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8381904\n",
      "  training_iteration: 131\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:44:33 (running for 00:34:36.07)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   131</td><td style=\"text-align: right;\">         2050.11</td><td style=\"text-align: right;\">8.3819e+06</td><td style=\"text-align: right;\"> -192500</td><td style=\"text-align: right;\">             -187885</td><td style=\"text-align: right;\">             -201662</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:44:38 (running for 00:34:41.08)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   131</td><td style=\"text-align: right;\">         2050.11</td><td style=\"text-align: right;\">8.3819e+06</td><td style=\"text-align: right;\"> -192500</td><td style=\"text-align: right;\">             -187885</td><td style=\"text-align: right;\">             -201662</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:44:43 (running for 00:34:46.10)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   131</td><td style=\"text-align: right;\">         2050.11</td><td style=\"text-align: right;\">8.3819e+06</td><td style=\"text-align: right;\"> -192500</td><td style=\"text-align: right;\">             -187885</td><td style=\"text-align: right;\">             -201662</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 8445888\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 8445888\n",
      "    num_agent_steps_trained: 8445888\n",
      "    num_env_steps_sampled: 8445888\n",
      "    num_env_steps_trained: 8445888\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-44-43\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -188460.9563162868\n",
      "  episode_reward_mean: -193754.23423643806\n",
      "  episode_reward_min: -217789.99057153985\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 8436\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 2.963819742202759\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0022496571764349937\n",
      "          model: {}\n",
      "          policy_loss: 0.0014378591440618038\n",
      "          total_loss: 10.001591682434082\n",
      "          vf_explained_var: -2.1177988855924923e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 8445888\n",
      "    num_agent_steps_trained: 8445888\n",
      "    num_env_steps_sampled: 8445888\n",
      "    num_env_steps_trained: 8445888\n",
      "  iterations_since_restore: 132\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 8445888\n",
      "  num_agent_steps_trained: 8445888\n",
      "  num_env_steps_sampled: 8445888\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 8445888\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.75\n",
      "    ram_util_percent: 79.40000000000003\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11843293205478461\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5126940282745452\n",
      "    mean_inference_ms: 1.598022869766657\n",
      "    mean_raw_obs_processing_ms: 0.16261595898959558\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -188460.9563162868\n",
      "    episode_reward_mean: -193754.23423643806\n",
      "    episode_reward_min: -217789.99057153985\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -194495.09575945654\n",
      "      - -193756.6874411995\n",
      "      - -192049.14960244912\n",
      "      - -189981.5695414041\n",
      "      - -189756.05815880143\n",
      "      - -189985.93303607078\n",
      "      - -192857.42392323344\n",
      "      - -195418.66380600707\n",
      "      - -192746.43168908783\n",
      "      - -190253.0303222206\n",
      "      - -191089.0364065828\n",
      "      - -194526.45082222784\n",
      "      - -192767.86828138996\n",
      "      - -190721.33558798287\n",
      "      - -190519.47751828207\n",
      "      - -193361.97405417418\n",
      "      - -197943.15706102605\n",
      "      - -192978.17713521986\n",
      "      - -188460.9563162868\n",
      "      - -193170.90876781289\n",
      "      - -190901.74187612458\n",
      "      - -196455.7814446174\n",
      "      - -192566.191495149\n",
      "      - -190579.2388928355\n",
      "      - -193115.12503353567\n",
      "      - -191479.21618372088\n",
      "      - -194496.03141145612\n",
      "      - -190912.00812092284\n",
      "      - -189891.90960140654\n",
      "      - -201662.3335482013\n",
      "      - -194880.22134005185\n",
      "      - -197161.78549976862\n",
      "      - -192309.93132971146\n",
      "      - -193044.86759641365\n",
      "      - -191031.81489694383\n",
      "      - -194822.18163384323\n",
      "      - -190621.11676350853\n",
      "      - -192545.80902226386\n",
      "      - -192321.7440345049\n",
      "      - -188982.98391027746\n",
      "      - -190983.91757748462\n",
      "      - -191735.61262975904\n",
      "      - -192183.12313829802\n",
      "      - -193908.04657407582\n",
      "      - -193727.03457397176\n",
      "      - -192902.95626434713\n",
      "      - -192543.72334917216\n",
      "      - -194526.03309908506\n",
      "      - -194261.62222538175\n",
      "      - -194320.78302716493\n",
      "      - -195257.69595344493\n",
      "      - -217789.99057153985\n",
      "      - -194304.91832722924\n",
      "      - -191790.73693380147\n",
      "      - -193167.94231123885\n",
      "      - -191902.3966906523\n",
      "      - -192875.59268050484\n",
      "      - -193708.6991606452\n",
      "      - -194067.87355101053\n",
      "      - -194957.42794777072\n",
      "      - -196424.55498962218\n",
      "      - -194487.59937695318\n",
      "      - -204202.53107325415\n",
      "      - -206030.0214597728\n",
      "      - -193968.87245251393\n",
      "      - -189653.8532142015\n",
      "      - -194298.66804273764\n",
      "      - -198323.32471522095\n",
      "      - -194590.93612883543\n",
      "      - -197108.7320343452\n",
      "      - -202279.78630323953\n",
      "      - -195336.21433105535\n",
      "      - -191703.65389063413\n",
      "      - -191486.36180449196\n",
      "      - -195065.17865074414\n",
      "      - -193004.57190226592\n",
      "      - -193719.57985743994\n",
      "      - -192486.2011679003\n",
      "      - -194984.28210321625\n",
      "      - -196026.64047987165\n",
      "      - -192630.45211490832\n",
      "      - -196240.66293851833\n",
      "      - -193676.13381400736\n",
      "      - -193037.57966038436\n",
      "      - -195379.1373114932\n",
      "      - -195156.12100218548\n",
      "      - -190661.75934157296\n",
      "      - -191477.217999464\n",
      "      - -195503.18454950032\n",
      "      - -192537.15535501164\n",
      "      - -190724.75339024977\n",
      "      - -195365.46923690676\n",
      "      - -191766.97934373538\n",
      "      - -193204.09636353786\n",
      "      - -193751.32411127657\n",
      "      - -189288.4038991138\n",
      "      - -193463.89117518818\n",
      "      - -193629.21656827835\n",
      "      - -194484.07093111295\n",
      "      - -190726.70510628662\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11843293205478461\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5126940282745452\n",
      "      mean_inference_ms: 1.598022869766657\n",
      "      mean_raw_obs_processing_ms: 0.16261595898959558\n",
      "  time_since_restore: 2065.8176684379578\n",
      "  time_this_iter_s: 15.706667423248291\n",
      "  time_total_s: 2065.8176684379578\n",
      "  timers:\n",
      "    learn_throughput: 26469.853\n",
      "    learn_time_ms: 2417.241\n",
      "    load_throughput: 532949.555\n",
      "    load_time_ms: 120.056\n",
      "    training_iteration_time_ms: 15737.408\n",
      "    update_time_ms: 4.61\n",
      "  timestamp: 1665744283\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8445888\n",
      "  training_iteration: 132\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:44:49 (running for 00:34:51.38)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   132</td><td style=\"text-align: right;\">         2065.82</td><td style=\"text-align: right;\">8.44589e+06</td><td style=\"text-align: right;\"> -193754</td><td style=\"text-align: right;\">             -188461</td><td style=\"text-align: right;\">             -217790</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:44:54 (running for 00:34:56.38)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   132</td><td style=\"text-align: right;\">         2065.82</td><td style=\"text-align: right;\">8.44589e+06</td><td style=\"text-align: right;\"> -193754</td><td style=\"text-align: right;\">             -188461</td><td style=\"text-align: right;\">             -217790</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:44:59 (running for 00:35:01.39)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   132</td><td style=\"text-align: right;\">         2065.82</td><td style=\"text-align: right;\">8.44589e+06</td><td style=\"text-align: right;\"> -193754</td><td style=\"text-align: right;\">             -188461</td><td style=\"text-align: right;\">             -217790</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 8509872\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 8509872\n",
      "    num_agent_steps_trained: 8509872\n",
      "    num_env_steps_sampled: 8509872\n",
      "    num_env_steps_trained: 8509872\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-44-59\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -188597.53809183562\n",
      "  episode_reward_mean: -193189.17461916953\n",
      "  episode_reward_min: -203931.0980834958\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 8508\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 2.9517805576324463\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0025149488355964422\n",
      "          model: {}\n",
      "          policy_loss: 0.004018332343548536\n",
      "          total_loss: 10.004226684570312\n",
      "          vf_explained_var: -3.1498761927650776e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 8509872\n",
      "    num_agent_steps_trained: 8509872\n",
      "    num_env_steps_sampled: 8509872\n",
      "    num_env_steps_trained: 8509872\n",
      "  iterations_since_restore: 133\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 8509872\n",
      "  num_agent_steps_trained: 8509872\n",
      "  num_env_steps_sampled: 8509872\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 8509872\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.52727272727273\n",
      "    ram_util_percent: 79.40000000000003\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11850706673721356\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5128781585614409\n",
      "    mean_inference_ms: 1.5989932212846047\n",
      "    mean_raw_obs_processing_ms: 0.16259990755418824\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -188597.53809183562\n",
      "    episode_reward_mean: -193189.17461916953\n",
      "    episode_reward_min: -203931.0980834958\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -191703.65389063413\n",
      "      - -191486.36180449196\n",
      "      - -195065.17865074414\n",
      "      - -193004.57190226592\n",
      "      - -193719.57985743994\n",
      "      - -192486.2011679003\n",
      "      - -194984.28210321625\n",
      "      - -196026.64047987165\n",
      "      - -192630.45211490832\n",
      "      - -196240.66293851833\n",
      "      - -193676.13381400736\n",
      "      - -193037.57966038436\n",
      "      - -195379.1373114932\n",
      "      - -195156.12100218548\n",
      "      - -190661.75934157296\n",
      "      - -191477.217999464\n",
      "      - -195503.18454950032\n",
      "      - -192537.15535501164\n",
      "      - -190724.75339024977\n",
      "      - -195365.46923690676\n",
      "      - -191766.97934373538\n",
      "      - -193204.09636353786\n",
      "      - -193751.32411127657\n",
      "      - -189288.4038991138\n",
      "      - -193463.89117518818\n",
      "      - -193629.21656827835\n",
      "      - -194484.07093111295\n",
      "      - -190726.70510628662\n",
      "      - -192341.71420781143\n",
      "      - -189546.6671958937\n",
      "      - -189598.64088902765\n",
      "      - -190342.16349377474\n",
      "      - -193874.43929217648\n",
      "      - -192264.79969726547\n",
      "      - -188889.10755437321\n",
      "      - -196116.42182009775\n",
      "      - -191844.09381698057\n",
      "      - -191246.75843495905\n",
      "      - -190047.0260118803\n",
      "      - -195658.2507875188\n",
      "      - -191553.68204649357\n",
      "      - -192240.5490748951\n",
      "      - -197170.32886300323\n",
      "      - -193428.20559626102\n",
      "      - -195957.07075036172\n",
      "      - -191864.34098029303\n",
      "      - -193650.12627323653\n",
      "      - -198873.03378726076\n",
      "      - -190350.8743345382\n",
      "      - -193085.6262266753\n",
      "      - -194950.2051662371\n",
      "      - -193788.6373878079\n",
      "      - -198473.1783759553\n",
      "      - -190441.35490989548\n",
      "      - -194488.96278155045\n",
      "      - -196301.40564327344\n",
      "      - -203931.0980834958\n",
      "      - -188765.88750788913\n",
      "      - -192581.1261498098\n",
      "      - -194790.27494599854\n",
      "      - -193330.4600454536\n",
      "      - -195215.48677107983\n",
      "      - -193332.7475868194\n",
      "      - -202991.6717673754\n",
      "      - -191706.0001014956\n",
      "      - -190594.74039599745\n",
      "      - -191681.6280914755\n",
      "      - -191414.4587488873\n",
      "      - -193473.99302795297\n",
      "      - -194539.61419180865\n",
      "      - -195324.7977939113\n",
      "      - -193780.43222326486\n",
      "      - -193676.35959789288\n",
      "      - -191623.45804221067\n",
      "      - -192642.87307378443\n",
      "      - -196783.34017759346\n",
      "      - -190835.17336329186\n",
      "      - -192411.9364863048\n",
      "      - -192140.0264251591\n",
      "      - -190060.89136802722\n",
      "      - -193639.578522123\n",
      "      - -193591.93877574228\n",
      "      - -192067.8358265187\n",
      "      - -194190.38987457255\n",
      "      - -191056.87720003366\n",
      "      - -194878.5912109999\n",
      "      - -189389.0366389633\n",
      "      - -192248.3330442454\n",
      "      - -189891.68755218564\n",
      "      - -195107.7987934218\n",
      "      - -191765.98846447535\n",
      "      - -194174.8510095742\n",
      "      - -195993.6867331968\n",
      "      - -195227.08213495376\n",
      "      - -188597.53809183562\n",
      "      - -193868.24083725776\n",
      "      - -189008.340408865\n",
      "      - -191108.19207029245\n",
      "      - -192212.03349237595\n",
      "      - -193702.51579954443\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11850706673721356\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5128781585614409\n",
      "      mean_inference_ms: 1.5989932212846047\n",
      "      mean_raw_obs_processing_ms: 0.16259990755418824\n",
      "  time_since_restore: 2081.2079882621765\n",
      "  time_this_iter_s: 15.39031982421875\n",
      "  time_total_s: 2081.2079882621765\n",
      "  timers:\n",
      "    learn_throughput: 26437.388\n",
      "    learn_time_ms: 2420.209\n",
      "    load_throughput: 530846.842\n",
      "    load_time_ms: 120.532\n",
      "    training_iteration_time_ms: 15674.696\n",
      "    update_time_ms: 4.896\n",
      "  timestamp: 1665744299\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8509872\n",
      "  training_iteration: 133\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:45:04 (running for 00:35:06.65)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   133</td><td style=\"text-align: right;\">         2081.21</td><td style=\"text-align: right;\">8.50987e+06</td><td style=\"text-align: right;\"> -193189</td><td style=\"text-align: right;\">             -188598</td><td style=\"text-align: right;\">             -203931</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:45:09 (running for 00:35:11.81)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   133</td><td style=\"text-align: right;\">         2081.21</td><td style=\"text-align: right;\">8.50987e+06</td><td style=\"text-align: right;\"> -193189</td><td style=\"text-align: right;\">             -188598</td><td style=\"text-align: right;\">             -203931</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:45:14 (running for 00:35:16.89)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   133</td><td style=\"text-align: right;\">         2081.21</td><td style=\"text-align: right;\">8.50987e+06</td><td style=\"text-align: right;\"> -193189</td><td style=\"text-align: right;\">             -188598</td><td style=\"text-align: right;\">             -203931</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 8573856\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 8573856\n",
      "    num_agent_steps_trained: 8573856\n",
      "    num_env_steps_sampled: 8573856\n",
      "    num_env_steps_trained: 8573856\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-45-15\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -188597.53809183562\n",
      "  episode_reward_mean: -193737.4670043215\n",
      "  episode_reward_min: -217446.60803897856\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 8568\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 2.942706346511841\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0019276465754956007\n",
      "          model: {}\n",
      "          policy_loss: 0.003338882001116872\n",
      "          total_loss: 10.003429412841797\n",
      "          vf_explained_var: -4.283740054233931e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 8573856\n",
      "    num_agent_steps_trained: 8573856\n",
      "    num_env_steps_sampled: 8573856\n",
      "    num_env_steps_trained: 8573856\n",
      "  iterations_since_restore: 134\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 8573856\n",
      "  num_agent_steps_trained: 8573856\n",
      "  num_env_steps_sampled: 8573856\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 8573856\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 78.89047619047618\n",
      "    ram_util_percent: 79.4\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11843488858757095\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5129774148134402\n",
      "    mean_inference_ms: 1.5982894800469547\n",
      "    mean_raw_obs_processing_ms: 0.16273794230777086\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -188597.53809183562\n",
      "    episode_reward_mean: -193737.4670043215\n",
      "    episode_reward_min: -217446.60803897856\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -193330.4600454536\n",
      "      - -195215.48677107983\n",
      "      - -193332.7475868194\n",
      "      - -202991.6717673754\n",
      "      - -191706.0001014956\n",
      "      - -190594.74039599745\n",
      "      - -191681.6280914755\n",
      "      - -191414.4587488873\n",
      "      - -193473.99302795297\n",
      "      - -194539.61419180865\n",
      "      - -195324.7977939113\n",
      "      - -193780.43222326486\n",
      "      - -193676.35959789288\n",
      "      - -191623.45804221067\n",
      "      - -192642.87307378443\n",
      "      - -196783.34017759346\n",
      "      - -190835.17336329186\n",
      "      - -192411.9364863048\n",
      "      - -192140.0264251591\n",
      "      - -190060.89136802722\n",
      "      - -193639.578522123\n",
      "      - -193591.93877574228\n",
      "      - -192067.8358265187\n",
      "      - -194190.38987457255\n",
      "      - -191056.87720003366\n",
      "      - -194878.5912109999\n",
      "      - -189389.0366389633\n",
      "      - -192248.3330442454\n",
      "      - -189891.68755218564\n",
      "      - -195107.7987934218\n",
      "      - -191765.98846447535\n",
      "      - -194174.8510095742\n",
      "      - -195993.6867331968\n",
      "      - -195227.08213495376\n",
      "      - -188597.53809183562\n",
      "      - -193868.24083725776\n",
      "      - -189008.340408865\n",
      "      - -191108.19207029245\n",
      "      - -192212.03349237595\n",
      "      - -193702.51579954443\n",
      "      - -191767.52793517814\n",
      "      - -192639.2177373005\n",
      "      - -192502.8402953824\n",
      "      - -193893.3479990196\n",
      "      - -190768.33280732832\n",
      "      - -196818.4875234726\n",
      "      - -194358.59648637037\n",
      "      - -197430.14767305262\n",
      "      - -194023.80047127628\n",
      "      - -192242.70155920956\n",
      "      - -195148.28368716402\n",
      "      - -195416.619909043\n",
      "      - -189591.45479319396\n",
      "      - -195892.27050768022\n",
      "      - -194072.12692267407\n",
      "      - -203167.9551290823\n",
      "      - -194698.39974703707\n",
      "      - -191329.95970815886\n",
      "      - -200146.2457870547\n",
      "      - -192355.71888360113\n",
      "      - -197997.3862296436\n",
      "      - -193022.11574827202\n",
      "      - -193203.74205969714\n",
      "      - -190262.75097918216\n",
      "      - -194122.12851068735\n",
      "      - -196473.59791029198\n",
      "      - -190593.34717948418\n",
      "      - -191409.43149532733\n",
      "      - -191558.6814832914\n",
      "      - -193421.40581447235\n",
      "      - -193185.77009510092\n",
      "      - -217446.60803897856\n",
      "      - -192342.28643164766\n",
      "      - -194140.150960521\n",
      "      - -196253.34944924002\n",
      "      - -194949.28432837367\n",
      "      - -193948.07296991747\n",
      "      - -194858.68421370527\n",
      "      - -190917.48118535173\n",
      "      - -189334.81882331718\n",
      "      - -192284.64312584774\n",
      "      - -193782.0842198663\n",
      "      - -192937.60226775985\n",
      "      - -193829.2395326853\n",
      "      - -192310.41633647794\n",
      "      - -193925.0107128476\n",
      "      - -192567.09683133452\n",
      "      - -191241.48771860448\n",
      "      - -192628.77885326685\n",
      "      - -193001.2112095\n",
      "      - -197197.67250595635\n",
      "      - -192697.10399478298\n",
      "      - -191472.66520593077\n",
      "      - -190806.14579507968\n",
      "      - -194810.88244833407\n",
      "      - -204862.8091685432\n",
      "      - -192387.19419691712\n",
      "      - -195769.24548299747\n",
      "      - -194909.37859182042\n",
      "      - -193340.2770038512\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11843488858757095\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5129774148134402\n",
      "      mean_inference_ms: 1.5982894800469547\n",
      "      mean_raw_obs_processing_ms: 0.16273794230777086\n",
      "  time_since_restore: 2096.8290209770203\n",
      "  time_this_iter_s: 15.62103271484375\n",
      "  time_total_s: 2096.8290209770203\n",
      "  timers:\n",
      "    learn_throughput: 26454.251\n",
      "    learn_time_ms: 2418.666\n",
      "    load_throughput: 529594.686\n",
      "    load_time_ms: 120.817\n",
      "    training_iteration_time_ms: 15697.925\n",
      "    update_time_ms: 4.874\n",
      "  timestamp: 1665744315\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8573856\n",
      "  training_iteration: 134\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:45:20 (running for 00:35:22.45)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   134</td><td style=\"text-align: right;\">         2096.83</td><td style=\"text-align: right;\">8.57386e+06</td><td style=\"text-align: right;\"> -193737</td><td style=\"text-align: right;\">             -188598</td><td style=\"text-align: right;\">             -217447</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:45:25 (running for 00:35:27.46)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   134</td><td style=\"text-align: right;\">         2096.83</td><td style=\"text-align: right;\">8.57386e+06</td><td style=\"text-align: right;\"> -193737</td><td style=\"text-align: right;\">             -188598</td><td style=\"text-align: right;\">             -217447</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:45:30 (running for 00:35:32.47)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   134</td><td style=\"text-align: right;\">         2096.83</td><td style=\"text-align: right;\">8.57386e+06</td><td style=\"text-align: right;\"> -193737</td><td style=\"text-align: right;\">             -188598</td><td style=\"text-align: right;\">             -217447</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 8637840\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 8637840\n",
      "    num_agent_steps_trained: 8637840\n",
      "    num_env_steps_sampled: 8637840\n",
      "    num_env_steps_trained: 8637840\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-45-30\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -188701.28213261205\n",
      "  episode_reward_mean: -193582.69630342178\n",
      "  episode_reward_min: -217446.60803897856\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 8628\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 2.9446816444396973\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.002011392032727599\n",
      "          model: {}\n",
      "          policy_loss: -0.002504633506760001\n",
      "          total_loss: 9.997602462768555\n",
      "          vf_explained_var: -1.02382443856186e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 8637840\n",
      "    num_agent_steps_trained: 8637840\n",
      "    num_env_steps_sampled: 8637840\n",
      "    num_env_steps_trained: 8637840\n",
      "  iterations_since_restore: 135\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 8637840\n",
      "  num_agent_steps_trained: 8637840\n",
      "  num_env_steps_sampled: 8637840\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 8637840\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.1590909090909\n",
      "    ram_util_percent: 79.5\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11838455560541519\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5128812817768772\n",
      "    mean_inference_ms: 1.5978186223168211\n",
      "    mean_raw_obs_processing_ms: 0.162629695021983\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -188701.28213261205\n",
      "    episode_reward_mean: -193582.69630342178\n",
      "    episode_reward_min: -217446.60803897856\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -197997.3862296436\n",
      "      - -193022.11574827202\n",
      "      - -193203.74205969714\n",
      "      - -190262.75097918216\n",
      "      - -194122.12851068735\n",
      "      - -196473.59791029198\n",
      "      - -190593.34717948418\n",
      "      - -191409.43149532733\n",
      "      - -191558.6814832914\n",
      "      - -193421.40581447235\n",
      "      - -193185.77009510092\n",
      "      - -217446.60803897856\n",
      "      - -192342.28643164766\n",
      "      - -194140.150960521\n",
      "      - -196253.34944924002\n",
      "      - -194949.28432837367\n",
      "      - -193948.07296991747\n",
      "      - -194858.68421370527\n",
      "      - -190917.48118535173\n",
      "      - -189334.81882331718\n",
      "      - -192284.64312584774\n",
      "      - -193782.0842198663\n",
      "      - -192937.60226775985\n",
      "      - -193829.2395326853\n",
      "      - -192310.41633647794\n",
      "      - -193925.0107128476\n",
      "      - -192567.09683133452\n",
      "      - -191241.48771860448\n",
      "      - -192628.77885326685\n",
      "      - -193001.2112095\n",
      "      - -197197.67250595635\n",
      "      - -192697.10399478298\n",
      "      - -191472.66520593077\n",
      "      - -190806.14579507968\n",
      "      - -194810.88244833407\n",
      "      - -204862.8091685432\n",
      "      - -192387.19419691712\n",
      "      - -195769.24548299747\n",
      "      - -194909.37859182042\n",
      "      - -193340.2770038512\n",
      "      - -191590.58857718378\n",
      "      - -188701.28213261205\n",
      "      - -198214.43599340992\n",
      "      - -192963.48707022052\n",
      "      - -192219.35333389594\n",
      "      - -192188.77095592182\n",
      "      - -190807.412654999\n",
      "      - -190617.8696311146\n",
      "      - -189813.44915285386\n",
      "      - -190823.1498345793\n",
      "      - -195645.4782061719\n",
      "      - -192927.76647798775\n",
      "      - -191963.75724402638\n",
      "      - -194183.63859919246\n",
      "      - -191841.58690757878\n",
      "      - -194434.00156244237\n",
      "      - -190318.27122908\n",
      "      - -194313.79306605062\n",
      "      - -192135.96742405568\n",
      "      - -192424.15074768127\n",
      "      - -192360.42822244464\n",
      "      - -192748.03479488724\n",
      "      - -191825.72769388376\n",
      "      - -192123.69445921903\n",
      "      - -195712.4512486223\n",
      "      - -193158.69682623824\n",
      "      - -189608.56107658302\n",
      "      - -194191.1378095273\n",
      "      - -197094.83449905485\n",
      "      - -193423.59102097875\n",
      "      - -191743.2766631828\n",
      "      - -189490.75352028848\n",
      "      - -190937.32027843315\n",
      "      - -191937.50846772516\n",
      "      - -192502.8735582322\n",
      "      - -191554.772574313\n",
      "      - -191542.01300773554\n",
      "      - -191679.26222255095\n",
      "      - -205121.74141586878\n",
      "      - -192576.0758108575\n",
      "      - -197951.6915911705\n",
      "      - -193068.10086510718\n",
      "      - -192492.58627096837\n",
      "      - -196568.62968190986\n",
      "      - -191474.62417632615\n",
      "      - -193959.6542988168\n",
      "      - -194484.68939542855\n",
      "      - -191798.30116193424\n",
      "      - -194606.3450094471\n",
      "      - -192107.0981133828\n",
      "      - -192522.23230611676\n",
      "      - -195045.19106889094\n",
      "      - -193751.02701262047\n",
      "      - -193177.94185907522\n",
      "      - -194231.71942720714\n",
      "      - -189396.8028527464\n",
      "      - -194591.05870910312\n",
      "      - -196126.53686960952\n",
      "      - -191762.98896243173\n",
      "      - -203489.40562929158\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11838455560541519\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5128812817768772\n",
      "      mean_inference_ms: 1.5978186223168211\n",
      "      mean_raw_obs_processing_ms: 0.162629695021983\n",
      "  time_since_restore: 2112.0659263134003\n",
      "  time_this_iter_s: 15.236905336380005\n",
      "  time_total_s: 2112.0659263134003\n",
      "  timers:\n",
      "    learn_throughput: 26452.297\n",
      "    learn_time_ms: 2418.845\n",
      "    load_throughput: 527251.441\n",
      "    load_time_ms: 121.354\n",
      "    training_iteration_time_ms: 15621.041\n",
      "    update_time_ms: 4.821\n",
      "  timestamp: 1665744330\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8637840\n",
      "  training_iteration: 135\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:45:35 (running for 00:35:37.58)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   135</td><td style=\"text-align: right;\">         2112.07</td><td style=\"text-align: right;\">8.63784e+06</td><td style=\"text-align: right;\"> -193583</td><td style=\"text-align: right;\">             -188701</td><td style=\"text-align: right;\">             -217447</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:45:40 (running for 00:35:42.74)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   135</td><td style=\"text-align: right;\">         2112.07</td><td style=\"text-align: right;\">8.63784e+06</td><td style=\"text-align: right;\"> -193583</td><td style=\"text-align: right;\">             -188701</td><td style=\"text-align: right;\">             -217447</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:45:45 (running for 00:35:48.10)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   135</td><td style=\"text-align: right;\">         2112.07</td><td style=\"text-align: right;\">8.63784e+06</td><td style=\"text-align: right;\"> -193583</td><td style=\"text-align: right;\">             -188701</td><td style=\"text-align: right;\">             -217447</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 8701824\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 8701824\n",
      "    num_agent_steps_trained: 8701824\n",
      "    num_env_steps_sampled: 8701824\n",
      "    num_env_steps_trained: 8701824\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-45-45\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -188171.7733783317\n",
      "  episode_reward_mean: -194275.0021539623\n",
      "  episode_reward_min: -212194.44421172366\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 8700\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 2.9309675693511963\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0023203380405902863\n",
      "          model: {}\n",
      "          policy_loss: 0.0012992977863177657\n",
      "          total_loss: 10.001470565795898\n",
      "          vf_explained_var: -3.181971123922267e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 8701824\n",
      "    num_agent_steps_trained: 8701824\n",
      "    num_env_steps_sampled: 8701824\n",
      "    num_env_steps_trained: 8701824\n",
      "  iterations_since_restore: 136\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 8701824\n",
      "  num_agent_steps_trained: 8701824\n",
      "  num_env_steps_sampled: 8701824\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 8701824\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 78.18571428571428\n",
      "    ram_util_percent: 79.5\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11843986531913663\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5128756417851794\n",
      "    mean_inference_ms: 1.5989864463236796\n",
      "    mean_raw_obs_processing_ms: 0.1626125922251235\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -188171.7733783317\n",
      "    episode_reward_mean: -194275.0021539623\n",
      "    episode_reward_min: -212194.44421172366\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -190937.32027843315\n",
      "      - -191937.50846772516\n",
      "      - -192502.8735582322\n",
      "      - -191554.772574313\n",
      "      - -191542.01300773554\n",
      "      - -191679.26222255095\n",
      "      - -205121.74141586878\n",
      "      - -192576.0758108575\n",
      "      - -197951.6915911705\n",
      "      - -193068.10086510718\n",
      "      - -192492.58627096837\n",
      "      - -196568.62968190986\n",
      "      - -191474.62417632615\n",
      "      - -193959.6542988168\n",
      "      - -194484.68939542855\n",
      "      - -191798.30116193424\n",
      "      - -194606.3450094471\n",
      "      - -192107.0981133828\n",
      "      - -192522.23230611676\n",
      "      - -195045.19106889094\n",
      "      - -193751.02701262047\n",
      "      - -193177.94185907522\n",
      "      - -194231.71942720714\n",
      "      - -189396.8028527464\n",
      "      - -194591.05870910312\n",
      "      - -196126.53686960952\n",
      "      - -191762.98896243173\n",
      "      - -203489.40562929158\n",
      "      - -189673.10813248792\n",
      "      - -194064.6419830004\n",
      "      - -194135.89975223131\n",
      "      - -190251.3593372094\n",
      "      - -195152.30891930286\n",
      "      - -194932.07261605264\n",
      "      - -197198.60054445374\n",
      "      - -196093.9705460363\n",
      "      - -193308.44612802437\n",
      "      - -199758.3000024657\n",
      "      - -206222.98895069503\n",
      "      - -194644.2788347233\n",
      "      - -197417.5167596738\n",
      "      - -194797.42272842795\n",
      "      - -195743.33445697493\n",
      "      - -191265.23303486843\n",
      "      - -198221.45043106689\n",
      "      - -191306.71063498844\n",
      "      - -196221.77219991197\n",
      "      - -193290.22087972882\n",
      "      - -191456.50637220978\n",
      "      - -197932.47816398332\n",
      "      - -191390.06122208014\n",
      "      - -193167.123475956\n",
      "      - -192938.87567565628\n",
      "      - -191019.84852482428\n",
      "      - -191612.4773451871\n",
      "      - -191285.43364387532\n",
      "      - -194797.8323129194\n",
      "      - -193876.61143478882\n",
      "      - -193241.61317361367\n",
      "      - -191629.04965320122\n",
      "      - -196310.0292330133\n",
      "      - -190871.2630436022\n",
      "      - -188171.7733783317\n",
      "      - -212194.44421172366\n",
      "      - -194981.9429562817\n",
      "      - -190453.38904822126\n",
      "      - -194109.56316358657\n",
      "      - -197605.3576251645\n",
      "      - -201364.40441364195\n",
      "      - -194860.5203528551\n",
      "      - -192311.13176827313\n",
      "      - -195096.46234330582\n",
      "      - -193925.15894602053\n",
      "      - -194284.5229423819\n",
      "      - -197157.32941584187\n",
      "      - -193366.70595394785\n",
      "      - -191297.08949016163\n",
      "      - -191255.46194333144\n",
      "      - -194140.66275671113\n",
      "      - -199584.33564212962\n",
      "      - -196321.4310011051\n",
      "      - -194695.93943533246\n",
      "      - -189834.7002485668\n",
      "      - -195436.5243954808\n",
      "      - -198986.37192995386\n",
      "      - -191102.5919739176\n",
      "      - -192275.3272246178\n",
      "      - -195243.40945027713\n",
      "      - -191213.57891780089\n",
      "      - -191611.56669390234\n",
      "      - -191706.37581049907\n",
      "      - -197633.9287705142\n",
      "      - -191171.54853397634\n",
      "      - -191382.05991101297\n",
      "      - -192532.50966296258\n",
      "      - -200121.82177793345\n",
      "      - -195496.4164153253\n",
      "      - -195844.98807437916\n",
      "      - -192442.6892080646\n",
      "      - -190599.14686415755\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11843986531913663\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5128756417851794\n",
      "      mean_inference_ms: 1.5989864463236796\n",
      "      mean_raw_obs_processing_ms: 0.1626125922251235\n",
      "  time_since_restore: 2127.697988510132\n",
      "  time_this_iter_s: 15.632062196731567\n",
      "  time_total_s: 2127.697988510132\n",
      "  timers:\n",
      "    learn_throughput: 26479.418\n",
      "    learn_time_ms: 2416.367\n",
      "    load_throughput: 523098.981\n",
      "    load_time_ms: 122.317\n",
      "    training_iteration_time_ms: 15642.962\n",
      "    update_time_ms: 4.842\n",
      "  timestamp: 1665744345\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8701824\n",
      "  training_iteration: 136\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:45:51 (running for 00:35:53.40)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   136</td><td style=\"text-align: right;\">          2127.7</td><td style=\"text-align: right;\">8.70182e+06</td><td style=\"text-align: right;\"> -194275</td><td style=\"text-align: right;\">             -188172</td><td style=\"text-align: right;\">             -212194</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:45:56 (running for 00:35:58.40)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   136</td><td style=\"text-align: right;\">          2127.7</td><td style=\"text-align: right;\">8.70182e+06</td><td style=\"text-align: right;\"> -194275</td><td style=\"text-align: right;\">             -188172</td><td style=\"text-align: right;\">             -212194</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:46:01 (running for 00:36:03.42)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   136</td><td style=\"text-align: right;\">          2127.7</td><td style=\"text-align: right;\">8.70182e+06</td><td style=\"text-align: right;\"> -194275</td><td style=\"text-align: right;\">             -188172</td><td style=\"text-align: right;\">             -212194</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 8765808\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 8765808\n",
      "    num_agent_steps_trained: 8765808\n",
      "    num_env_steps_sampled: 8765808\n",
      "    num_env_steps_trained: 8765808\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-46-01\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -188171.7733783317\n",
      "  episode_reward_mean: -193986.69996717863\n",
      "  episode_reward_min: -212194.44421172366\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 8760\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 2.927401304244995\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0019268888281658292\n",
      "          model: {}\n",
      "          policy_loss: 0.007210954092442989\n",
      "          total_loss: 10.007303237915039\n",
      "          vf_explained_var: -7.425821877404815e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 8765808\n",
      "    num_agent_steps_trained: 8765808\n",
      "    num_env_steps_sampled: 8765808\n",
      "    num_env_steps_trained: 8765808\n",
      "  iterations_since_restore: 137\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 8765808\n",
      "  num_agent_steps_trained: 8765808\n",
      "  num_env_steps_sampled: 8765808\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 8765808\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 74.04090909090907\n",
      "    ram_util_percent: 79.5\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11836015157216348\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5129598278828885\n",
      "    mean_inference_ms: 1.5980422260093607\n",
      "    mean_raw_obs_processing_ms: 0.16276081793760397\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -188171.7733783317\n",
      "    episode_reward_mean: -193986.69996717863\n",
      "    episode_reward_min: -212194.44421172366\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -196310.0292330133\n",
      "      - -190871.2630436022\n",
      "      - -188171.7733783317\n",
      "      - -212194.44421172366\n",
      "      - -194981.9429562817\n",
      "      - -190453.38904822126\n",
      "      - -194109.56316358657\n",
      "      - -197605.3576251645\n",
      "      - -201364.40441364195\n",
      "      - -194860.5203528551\n",
      "      - -192311.13176827313\n",
      "      - -195096.46234330582\n",
      "      - -193925.15894602053\n",
      "      - -194284.5229423819\n",
      "      - -197157.32941584187\n",
      "      - -193366.70595394785\n",
      "      - -191297.08949016163\n",
      "      - -191255.46194333144\n",
      "      - -194140.66275671113\n",
      "      - -199584.33564212962\n",
      "      - -196321.4310011051\n",
      "      - -194695.93943533246\n",
      "      - -189834.7002485668\n",
      "      - -195436.5243954808\n",
      "      - -198986.37192995386\n",
      "      - -191102.5919739176\n",
      "      - -192275.3272246178\n",
      "      - -195243.40945027713\n",
      "      - -191213.57891780089\n",
      "      - -191611.56669390234\n",
      "      - -191706.37581049907\n",
      "      - -197633.9287705142\n",
      "      - -191171.54853397634\n",
      "      - -191382.05991101297\n",
      "      - -192532.50966296258\n",
      "      - -200121.82177793345\n",
      "      - -195496.4164153253\n",
      "      - -195844.98807437916\n",
      "      - -192442.6892080646\n",
      "      - -190599.14686415755\n",
      "      - -203818.5462739512\n",
      "      - -194160.26179969893\n",
      "      - -208763.93529938432\n",
      "      - -193082.91839085225\n",
      "      - -190484.72320408275\n",
      "      - -193101.6300079216\n",
      "      - -195513.66150981336\n",
      "      - -192489.8969371159\n",
      "      - -195880.73757329903\n",
      "      - -194357.03516867018\n",
      "      - -197544.94533863012\n",
      "      - -194523.81448497737\n",
      "      - -190874.56011726477\n",
      "      - -192612.1742772321\n",
      "      - -190397.54042404576\n",
      "      - -194903.1046330568\n",
      "      - -191277.4607478083\n",
      "      - -195623.0914222965\n",
      "      - -190106.7940292531\n",
      "      - -193527.72350147294\n",
      "      - -201226.4149460079\n",
      "      - -190932.31141941532\n",
      "      - -194980.54924970018\n",
      "      - -196252.36652461006\n",
      "      - -194114.41949966238\n",
      "      - -203808.8831523397\n",
      "      - -201003.45742597172\n",
      "      - -192206.9017291942\n",
      "      - -192151.3186042035\n",
      "      - -196263.24423120896\n",
      "      - -191520.00833836978\n",
      "      - -188582.0691745122\n",
      "      - -190895.51147113263\n",
      "      - -190457.49106587516\n",
      "      - -188506.7591311216\n",
      "      - -192113.7889333955\n",
      "      - -188306.12249343802\n",
      "      - -190956.69650105786\n",
      "      - -194044.92279996115\n",
      "      - -193624.79153687693\n",
      "      - -191970.0314923469\n",
      "      - -192220.783325684\n",
      "      - -194002.8179964781\n",
      "      - -190269.0766983597\n",
      "      - -193473.7316960362\n",
      "      - -193372.4021555715\n",
      "      - -192165.86805534823\n",
      "      - -190118.64647924496\n",
      "      - -191955.1825237181\n",
      "      - -195416.71238115415\n",
      "      - -195318.91587875554\n",
      "      - -191752.7560191249\n",
      "      - -193292.38923520673\n",
      "      - -194825.15355771178\n",
      "      - -193251.19838038267\n",
      "      - -189524.30928685534\n",
      "      - -193358.30089906833\n",
      "      - -193871.47910699592\n",
      "      - -195144.6995579403\n",
      "      - -189378.48369468664\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11836015157216348\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5129598278828885\n",
      "      mean_inference_ms: 1.5980422260093607\n",
      "      mean_raw_obs_processing_ms: 0.16276081793760397\n",
      "  time_since_restore: 2142.8758561611176\n",
      "  time_this_iter_s: 15.177867650985718\n",
      "  time_total_s: 2142.8758561611176\n",
      "  timers:\n",
      "    learn_throughput: 26548.115\n",
      "    learn_time_ms: 2410.115\n",
      "    load_throughput: 524041.884\n",
      "    load_time_ms: 122.097\n",
      "    training_iteration_time_ms: 15556.654\n",
      "    update_time_ms: 4.877\n",
      "  timestamp: 1665744361\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8765808\n",
      "  training_iteration: 137\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:46:06 (running for 00:36:08.45)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   137</td><td style=\"text-align: right;\">         2142.88</td><td style=\"text-align: right;\">8.76581e+06</td><td style=\"text-align: right;\"> -193987</td><td style=\"text-align: right;\">             -188172</td><td style=\"text-align: right;\">             -212194</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:46:11 (running for 00:36:13.61)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   137</td><td style=\"text-align: right;\">         2142.88</td><td style=\"text-align: right;\">8.76581e+06</td><td style=\"text-align: right;\"> -193987</td><td style=\"text-align: right;\">             -188172</td><td style=\"text-align: right;\">             -212194</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:46:16 (running for 00:36:18.61)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   137</td><td style=\"text-align: right;\">         2142.88</td><td style=\"text-align: right;\">8.76581e+06</td><td style=\"text-align: right;\"> -193987</td><td style=\"text-align: right;\">             -188172</td><td style=\"text-align: right;\">             -212194</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 8829792\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 8829792\n",
      "    num_agent_steps_trained: 8829792\n",
      "    num_env_steps_sampled: 8829792\n",
      "    num_env_steps_trained: 8829792\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-46-16\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -188306.12249343802\n",
      "  episode_reward_mean: -193475.20540238862\n",
      "  episode_reward_min: -213626.7281106848\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 8820\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 2.9353628158569336\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0018989498494192958\n",
      "          model: {}\n",
      "          policy_loss: 0.0035921090748161077\n",
      "          total_loss: 10.003679275512695\n",
      "          vf_explained_var: -6.244732730920077e-07\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 8829792\n",
      "    num_agent_steps_trained: 8829792\n",
      "    num_env_steps_sampled: 8829792\n",
      "    num_env_steps_trained: 8829792\n",
      "  iterations_since_restore: 138\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 8829792\n",
      "  num_agent_steps_trained: 8829792\n",
      "  num_env_steps_sampled: 8829792\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 8829792\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 78.54285714285713\n",
      "    ram_util_percent: 79.5\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11831089581288215\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5128659642542673\n",
      "    mean_inference_ms: 1.5977196900511297\n",
      "    mean_raw_obs_processing_ms: 0.16264845929806293\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -188306.12249343802\n",
      "    episode_reward_mean: -193475.20540238862\n",
      "    episode_reward_min: -213626.7281106848\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -201226.4149460079\n",
      "      - -190932.31141941532\n",
      "      - -194980.54924970018\n",
      "      - -196252.36652461006\n",
      "      - -194114.41949966238\n",
      "      - -203808.8831523397\n",
      "      - -201003.45742597172\n",
      "      - -192206.9017291942\n",
      "      - -192151.3186042035\n",
      "      - -196263.24423120896\n",
      "      - -191520.00833836978\n",
      "      - -188582.0691745122\n",
      "      - -190895.51147113263\n",
      "      - -190457.49106587516\n",
      "      - -188506.7591311216\n",
      "      - -192113.7889333955\n",
      "      - -188306.12249343802\n",
      "      - -190956.69650105786\n",
      "      - -194044.92279996115\n",
      "      - -193624.79153687693\n",
      "      - -191970.0314923469\n",
      "      - -192220.783325684\n",
      "      - -194002.8179964781\n",
      "      - -190269.0766983597\n",
      "      - -193473.7316960362\n",
      "      - -193372.4021555715\n",
      "      - -192165.86805534823\n",
      "      - -190118.64647924496\n",
      "      - -191955.1825237181\n",
      "      - -195416.71238115415\n",
      "      - -195318.91587875554\n",
      "      - -191752.7560191249\n",
      "      - -193292.38923520673\n",
      "      - -194825.15355771178\n",
      "      - -193251.19838038267\n",
      "      - -189524.30928685534\n",
      "      - -193358.30089906833\n",
      "      - -193871.47910699592\n",
      "      - -195144.6995579403\n",
      "      - -189378.48369468664\n",
      "      - -213626.7281106848\n",
      "      - -193609.7770462\n",
      "      - -189764.67455044488\n",
      "      - -191458.04707042553\n",
      "      - -191038.86985046807\n",
      "      - -190929.09251872366\n",
      "      - -190034.78576405466\n",
      "      - -190938.89782008034\n",
      "      - -188556.20586639587\n",
      "      - -193145.70102054195\n",
      "      - -196612.1919325369\n",
      "      - -194639.38038606418\n",
      "      - -194059.78637674163\n",
      "      - -190752.37200560528\n",
      "      - -191813.9970203992\n",
      "      - -194606.95106259658\n",
      "      - -190444.87924020962\n",
      "      - -191243.9160465904\n",
      "      - -209882.1279268594\n",
      "      - -192080.8535907089\n",
      "      - -189622.32805273074\n",
      "      - -190442.40953841494\n",
      "      - -196049.10497338686\n",
      "      - -193865.20141988897\n",
      "      - -192813.95152829963\n",
      "      - -191514.79761141454\n",
      "      - -193207.57644643143\n",
      "      - -191684.01962894207\n",
      "      - -193443.23030873446\n",
      "      - -190075.32570290496\n",
      "      - -194899.43003094467\n",
      "      - -189971.69797406526\n",
      "      - -192587.4916856959\n",
      "      - -190666.27266711902\n",
      "      - -195529.27896624838\n",
      "      - -196047.9026284954\n",
      "      - -193251.41833392077\n",
      "      - -193854.57260619715\n",
      "      - -196907.9788451832\n",
      "      - -190588.9959991018\n",
      "      - -197962.2509429569\n",
      "      - -193283.1273585492\n",
      "      - -192225.51070700146\n",
      "      - -193884.56438689696\n",
      "      - -191300.71536820845\n",
      "      - -191628.63327740048\n",
      "      - -190737.11896575888\n",
      "      - -190823.35189614163\n",
      "      - -199514.83323617707\n",
      "      - -193428.46266440724\n",
      "      - -211474.26867835879\n",
      "      - -192376.1400292695\n",
      "      - -190204.52122641777\n",
      "      - -189986.9896606957\n",
      "      - -203720.383207368\n",
      "      - -188335.84933179902\n",
      "      - -194091.16314683456\n",
      "      - -190490.60422513695\n",
      "      - -195387.22283595207\n",
      "      - -193771.6422903546\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11831089581288215\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5128659642542673\n",
      "      mean_inference_ms: 1.5977196900511297\n",
      "      mean_raw_obs_processing_ms: 0.16264845929806293\n",
      "  time_since_restore: 2158.592231273651\n",
      "  time_this_iter_s: 15.71637511253357\n",
      "  time_total_s: 2158.592231273651\n",
      "  timers:\n",
      "    learn_throughput: 26958.025\n",
      "    learn_time_ms: 2373.468\n",
      "    load_throughput: 529517.256\n",
      "    load_time_ms: 120.835\n",
      "    training_iteration_time_ms: 15550.016\n",
      "    update_time_ms: 4.863\n",
      "  timestamp: 1665744376\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8829792\n",
      "  training_iteration: 138\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:46:22 (running for 00:36:24.89)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   138</td><td style=\"text-align: right;\">         2158.59</td><td style=\"text-align: right;\">8.82979e+06</td><td style=\"text-align: right;\"> -193475</td><td style=\"text-align: right;\">             -188306</td><td style=\"text-align: right;\">             -213627</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:46:27 (running for 00:36:29.89)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   138</td><td style=\"text-align: right;\">         2158.59</td><td style=\"text-align: right;\">8.82979e+06</td><td style=\"text-align: right;\"> -193475</td><td style=\"text-align: right;\">             -188306</td><td style=\"text-align: right;\">             -213627</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:46:32 (running for 00:36:34.89)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   138</td><td style=\"text-align: right;\">         2158.59</td><td style=\"text-align: right;\">8.82979e+06</td><td style=\"text-align: right;\"> -193475</td><td style=\"text-align: right;\">             -188306</td><td style=\"text-align: right;\">             -213627</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 8893776\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 8893776\n",
      "    num_agent_steps_trained: 8893776\n",
      "    num_env_steps_sampled: 8893776\n",
      "    num_env_steps_trained: 8893776\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-46-33\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -188335.84933179902\n",
      "  episode_reward_mean: -193122.84968029297\n",
      "  episode_reward_min: -211474.26867835879\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 8892\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 2.939621686935425\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.002108360407873988\n",
      "          model: {}\n",
      "          policy_loss: -0.0006705960258841515\n",
      "          total_loss: 9.999457359313965\n",
      "          vf_explained_var: -2.6148100005229935e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 8893776\n",
      "    num_agent_steps_trained: 8893776\n",
      "    num_env_steps_sampled: 8893776\n",
      "    num_env_steps_trained: 8893776\n",
      "  iterations_since_restore: 139\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 8893776\n",
      "  num_agent_steps_trained: 8893776\n",
      "  num_env_steps_sampled: 8893776\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 8893776\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.51739130434783\n",
      "    ram_util_percent: 79.4913043478261\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1183662525134632\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5130317445205708\n",
      "    mean_inference_ms: 1.598970764642346\n",
      "    mean_raw_obs_processing_ms: 0.16257298212810517\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -188335.84933179902\n",
      "    episode_reward_mean: -193122.84968029297\n",
      "    episode_reward_min: -211474.26867835879\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -192587.4916856959\n",
      "      - -190666.27266711902\n",
      "      - -195529.27896624838\n",
      "      - -196047.9026284954\n",
      "      - -193251.41833392077\n",
      "      - -193854.57260619715\n",
      "      - -196907.9788451832\n",
      "      - -190588.9959991018\n",
      "      - -197962.2509429569\n",
      "      - -193283.1273585492\n",
      "      - -192225.51070700146\n",
      "      - -193884.56438689696\n",
      "      - -191300.71536820845\n",
      "      - -191628.63327740048\n",
      "      - -190737.11896575888\n",
      "      - -190823.35189614163\n",
      "      - -199514.83323617707\n",
      "      - -193428.46266440724\n",
      "      - -211474.26867835879\n",
      "      - -192376.1400292695\n",
      "      - -190204.52122641777\n",
      "      - -189986.9896606957\n",
      "      - -203720.383207368\n",
      "      - -188335.84933179902\n",
      "      - -194091.16314683456\n",
      "      - -190490.60422513695\n",
      "      - -195387.22283595207\n",
      "      - -193771.6422903546\n",
      "      - -194089.2669623664\n",
      "      - -192441.33767098354\n",
      "      - -191726.36352167648\n",
      "      - -190857.1613539127\n",
      "      - -194438.29555677902\n",
      "      - -192159.1714586897\n",
      "      - -191768.3275883587\n",
      "      - -189567.9306152912\n",
      "      - -192779.32829316918\n",
      "      - -192134.3917211724\n",
      "      - -192900.05097085674\n",
      "      - -189934.34405372883\n",
      "      - -195407.38439368387\n",
      "      - -191522.28639587708\n",
      "      - -189442.4424125617\n",
      "      - -188741.3236583657\n",
      "      - -195487.82302635972\n",
      "      - -193029.07894616757\n",
      "      - -191786.58514102697\n",
      "      - -189780.71189862685\n",
      "      - -191327.9919400632\n",
      "      - -196117.85112999805\n",
      "      - -190617.36857008893\n",
      "      - -192979.3970796839\n",
      "      - -191939.7934568251\n",
      "      - -189472.37973814574\n",
      "      - -194867.48419288543\n",
      "      - -194398.3292624327\n",
      "      - -192954.9032368204\n",
      "      - -191894.05784109051\n",
      "      - -190901.41674974936\n",
      "      - -191733.94865715178\n",
      "      - -190278.60459690896\n",
      "      - -190988.70479315077\n",
      "      - -190951.32121851906\n",
      "      - -190298.3440683494\n",
      "      - -192756.96710949758\n",
      "      - -192314.51173970883\n",
      "      - -193854.02294010256\n",
      "      - -189925.25014214485\n",
      "      - -194103.84104016962\n",
      "      - -193346.54470271725\n",
      "      - -190910.0051689984\n",
      "      - -196496.4463997465\n",
      "      - -191936.08183877915\n",
      "      - -193021.19867640393\n",
      "      - -196485.97411848733\n",
      "      - -194245.06015793604\n",
      "      - -190954.58861904708\n",
      "      - -192623.79278468396\n",
      "      - -197141.59474428356\n",
      "      - -197238.43330649482\n",
      "      - -197433.31519747528\n",
      "      - -192437.57818107159\n",
      "      - -189357.02491509102\n",
      "      - -192046.65863007726\n",
      "      - -201100.38956564394\n",
      "      - -191794.151310543\n",
      "      - -196299.45039748878\n",
      "      - -191912.64673348694\n",
      "      - -199676.6809381735\n",
      "      - -191162.94410821315\n",
      "      - -190281.78837616157\n",
      "      - -193439.54161511917\n",
      "      - -192176.27707594263\n",
      "      - -192846.99191123337\n",
      "      - -192930.62293684832\n",
      "      - -192759.4449119452\n",
      "      - -189733.96035850397\n",
      "      - -191791.10027112425\n",
      "      - -194574.36519558908\n",
      "      - -195398.95457120083\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1183662525134632\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5130317445205708\n",
      "      mean_inference_ms: 1.598970764642346\n",
      "      mean_raw_obs_processing_ms: 0.16257298212810517\n",
      "  time_since_restore: 2175.021178007126\n",
      "  time_this_iter_s: 16.42894673347473\n",
      "  time_total_s: 2175.021178007126\n",
      "  timers:\n",
      "    learn_throughput: 26001.317\n",
      "    learn_time_ms: 2460.798\n",
      "    load_throughput: 530291.321\n",
      "    load_time_ms: 120.658\n",
      "    training_iteration_time_ms: 15633.118\n",
      "    update_time_ms: 5.273\n",
      "  timestamp: 1665744393\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8893776\n",
      "  training_iteration: 139\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:46:38 (running for 00:36:40.82)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   139</td><td style=\"text-align: right;\">         2175.02</td><td style=\"text-align: right;\">8.89378e+06</td><td style=\"text-align: right;\"> -193123</td><td style=\"text-align: right;\">             -188336</td><td style=\"text-align: right;\">             -211474</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:46:43 (running for 00:36:45.82)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   139</td><td style=\"text-align: right;\">         2175.02</td><td style=\"text-align: right;\">8.89378e+06</td><td style=\"text-align: right;\"> -193123</td><td style=\"text-align: right;\">             -188336</td><td style=\"text-align: right;\">             -211474</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:46:48 (running for 00:36:50.83)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   139</td><td style=\"text-align: right;\">         2175.02</td><td style=\"text-align: right;\">8.89378e+06</td><td style=\"text-align: right;\"> -193123</td><td style=\"text-align: right;\">             -188336</td><td style=\"text-align: right;\">             -211474</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 8957760\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 8957760\n",
      "    num_agent_steps_trained: 8957760\n",
      "    num_env_steps_sampled: 8957760\n",
      "    num_env_steps_trained: 8957760\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-46-48\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -188858.4824345231\n",
      "  episode_reward_mean: -193649.8372005031\n",
      "  episode_reward_min: -215769.1343579096\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 8952\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 2.9366681575775146\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0016847060760483146\n",
      "          model: {}\n",
      "          policy_loss: 0.00583272147923708\n",
      "          total_loss: 10.005876541137695\n",
      "          vf_explained_var: 1.0325358061891166e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 8957760\n",
      "    num_agent_steps_trained: 8957760\n",
      "    num_env_steps_sampled: 8957760\n",
      "    num_env_steps_trained: 8957760\n",
      "  iterations_since_restore: 140\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 8957760\n",
      "  num_agent_steps_trained: 8957760\n",
      "  num_env_steps_sampled: 8957760\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 8957760\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 78.2095238095238\n",
      "    ram_util_percent: 79.48571428571428\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1182898154170589\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5130525314394996\n",
      "    mean_inference_ms: 1.5981152883031695\n",
      "    mean_raw_obs_processing_ms: 0.1627039214047862\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -188858.4824345231\n",
      "    episode_reward_mean: -193649.8372005031\n",
      "    episode_reward_min: -215769.1343579096\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -190278.60459690896\n",
      "      - -190988.70479315077\n",
      "      - -190951.32121851906\n",
      "      - -190298.3440683494\n",
      "      - -192756.96710949758\n",
      "      - -192314.51173970883\n",
      "      - -193854.02294010256\n",
      "      - -189925.25014214485\n",
      "      - -194103.84104016962\n",
      "      - -193346.54470271725\n",
      "      - -190910.0051689984\n",
      "      - -196496.4463997465\n",
      "      - -191936.08183877915\n",
      "      - -193021.19867640393\n",
      "      - -196485.97411848733\n",
      "      - -194245.06015793604\n",
      "      - -190954.58861904708\n",
      "      - -192623.79278468396\n",
      "      - -197141.59474428356\n",
      "      - -197238.43330649482\n",
      "      - -197433.31519747528\n",
      "      - -192437.57818107159\n",
      "      - -189357.02491509102\n",
      "      - -192046.65863007726\n",
      "      - -201100.38956564394\n",
      "      - -191794.151310543\n",
      "      - -196299.45039748878\n",
      "      - -191912.64673348694\n",
      "      - -199676.6809381735\n",
      "      - -191162.94410821315\n",
      "      - -190281.78837616157\n",
      "      - -193439.54161511917\n",
      "      - -192176.27707594263\n",
      "      - -192846.99191123337\n",
      "      - -192930.62293684832\n",
      "      - -192759.4449119452\n",
      "      - -189733.96035850397\n",
      "      - -191791.10027112425\n",
      "      - -194574.36519558908\n",
      "      - -195398.95457120083\n",
      "      - -213683.91692015796\n",
      "      - -194351.51940417246\n",
      "      - -190034.03655887602\n",
      "      - -193813.59094691148\n",
      "      - -193534.19457786903\n",
      "      - -188922.9239847607\n",
      "      - -190307.38095027895\n",
      "      - -190484.2517587537\n",
      "      - -189325.8946364689\n",
      "      - -192155.28504164057\n",
      "      - -191373.11504398784\n",
      "      - -192728.6929597029\n",
      "      - -194470.61773999577\n",
      "      - -191151.33599242152\n",
      "      - -193114.21042403218\n",
      "      - -188858.4824345231\n",
      "      - -191827.3490148901\n",
      "      - -190616.31652953065\n",
      "      - -193586.13680739162\n",
      "      - -192135.79800130037\n",
      "      - -189048.18849074884\n",
      "      - -192413.73353156055\n",
      "      - -193415.53790275395\n",
      "      - -190341.71588794628\n",
      "      - -191061.0567246045\n",
      "      - -194786.95296515795\n",
      "      - -191043.058704011\n",
      "      - -194461.68194237878\n",
      "      - -204939.08512514306\n",
      "      - -191035.9488733834\n",
      "      - -191022.66308225854\n",
      "      - -197031.93467010933\n",
      "      - -193299.30403579192\n",
      "      - -215769.1343579096\n",
      "      - -192085.61743635\n",
      "      - -201280.23458366585\n",
      "      - -195464.01499802177\n",
      "      - -189949.35418444418\n",
      "      - -197227.27589844313\n",
      "      - -191518.35683788333\n",
      "      - -190735.3168002304\n",
      "      - -194295.3608063565\n",
      "      - -193620.91876115263\n",
      "      - -192438.70481860064\n",
      "      - -191251.81775104738\n",
      "      - -204405.2380328691\n",
      "      - -193050.0639717594\n",
      "      - -192895.15612374988\n",
      "      - -197652.42176687997\n",
      "      - -195322.37527259914\n",
      "      - -193606.8510556102\n",
      "      - -192856.68772185157\n",
      "      - -196588.01321925785\n",
      "      - -191008.8689393769\n",
      "      - -190704.93577635798\n",
      "      - -195582.97875896844\n",
      "      - -199454.39526922276\n",
      "      - -190651.93131725112\n",
      "      - -194975.77405508104\n",
      "      - -191190.83450479136\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1182898154170589\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5130525314394996\n",
      "      mean_inference_ms: 1.5981152883031695\n",
      "      mean_raw_obs_processing_ms: 0.1627039214047862\n",
      "  time_since_restore: 2190.2178139686584\n",
      "  time_this_iter_s: 15.196635961532593\n",
      "  time_total_s: 2190.2178139686584\n",
      "  timers:\n",
      "    learn_throughput: 25972.336\n",
      "    learn_time_ms: 2463.544\n",
      "    load_throughput: 531144.276\n",
      "    load_time_ms: 120.464\n",
      "    training_iteration_time_ms: 15541.891\n",
      "    update_time_ms: 5.152\n",
      "  timestamp: 1665744408\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8957760\n",
      "  training_iteration: 140\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:46:53 (running for 00:36:55.91)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   140</td><td style=\"text-align: right;\">         2190.22</td><td style=\"text-align: right;\">8.95776e+06</td><td style=\"text-align: right;\"> -193650</td><td style=\"text-align: right;\">             -188858</td><td style=\"text-align: right;\">             -215769</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:46:58 (running for 00:37:01.06)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   140</td><td style=\"text-align: right;\">         2190.22</td><td style=\"text-align: right;\">8.95776e+06</td><td style=\"text-align: right;\"> -193650</td><td style=\"text-align: right;\">             -188858</td><td style=\"text-align: right;\">             -215769</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:47:03 (running for 00:37:06.07)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   140</td><td style=\"text-align: right;\">         2190.22</td><td style=\"text-align: right;\">8.95776e+06</td><td style=\"text-align: right;\"> -193650</td><td style=\"text-align: right;\">             -188858</td><td style=\"text-align: right;\">             -215769</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 9021744\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 9021744\n",
      "    num_agent_steps_trained: 9021744\n",
      "    num_env_steps_sampled: 9021744\n",
      "    num_env_steps_trained: 9021744\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-47-04\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -188331.03618033737\n",
      "  episode_reward_mean: -195424.59945926006\n",
      "  episode_reward_min: -244725.71339162154\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 9012\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 2.9382898807525635\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0018547696527093649\n",
      "          model: {}\n",
      "          policy_loss: 0.0017099472461268306\n",
      "          total_loss: 10.001787185668945\n",
      "          vf_explained_var: -1.1063539204769768e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 9021744\n",
      "    num_agent_steps_trained: 9021744\n",
      "    num_env_steps_sampled: 9021744\n",
      "    num_env_steps_trained: 9021744\n",
      "  iterations_since_restore: 141\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 9021744\n",
      "  num_agent_steps_trained: 9021744\n",
      "  num_env_steps_sampled: 9021744\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 9021744\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.7\n",
      "    ram_util_percent: 79.5\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11826568538601895\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5128392807233992\n",
      "    mean_inference_ms: 1.5978259765829859\n",
      "    mean_raw_obs_processing_ms: 0.1625940830185751\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -188331.03618033737\n",
      "    episode_reward_mean: -195424.59945926006\n",
      "    episode_reward_min: -244725.71339162154\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -189048.18849074884\n",
      "      - -192413.73353156055\n",
      "      - -193415.53790275395\n",
      "      - -190341.71588794628\n",
      "      - -191061.0567246045\n",
      "      - -194786.95296515795\n",
      "      - -191043.058704011\n",
      "      - -194461.68194237878\n",
      "      - -204939.08512514306\n",
      "      - -191035.9488733834\n",
      "      - -191022.66308225854\n",
      "      - -197031.93467010933\n",
      "      - -193299.30403579192\n",
      "      - -215769.1343579096\n",
      "      - -192085.61743635\n",
      "      - -201280.23458366585\n",
      "      - -195464.01499802177\n",
      "      - -189949.35418444418\n",
      "      - -197227.27589844313\n",
      "      - -191518.35683788333\n",
      "      - -190735.3168002304\n",
      "      - -194295.3608063565\n",
      "      - -193620.91876115263\n",
      "      - -192438.70481860064\n",
      "      - -191251.81775104738\n",
      "      - -204405.2380328691\n",
      "      - -193050.0639717594\n",
      "      - -192895.15612374988\n",
      "      - -197652.42176687997\n",
      "      - -195322.37527259914\n",
      "      - -193606.8510556102\n",
      "      - -192856.68772185157\n",
      "      - -196588.01321925785\n",
      "      - -191008.8689393769\n",
      "      - -190704.93577635798\n",
      "      - -195582.97875896844\n",
      "      - -199454.39526922276\n",
      "      - -190651.93131725112\n",
      "      - -194975.77405508104\n",
      "      - -191190.83450479136\n",
      "      - -195455.6580378108\n",
      "      - -200335.74214121647\n",
      "      - -191983.6458332714\n",
      "      - -204873.0553404317\n",
      "      - -197058.51182958766\n",
      "      - -190587.69528928117\n",
      "      - -192541.9721703632\n",
      "      - -191392.65096575627\n",
      "      - -195260.56488549316\n",
      "      - -194411.04356621453\n",
      "      - -191505.41592396196\n",
      "      - -189800.50263876893\n",
      "      - -193853.00923194815\n",
      "      - -191621.64353621975\n",
      "      - -200808.37005752328\n",
      "      - -196743.34160393264\n",
      "      - -189480.9330466409\n",
      "      - -190933.80248903477\n",
      "      - -194926.7909400174\n",
      "      - -194758.69454011353\n",
      "      - -210372.7933606392\n",
      "      - -232072.51469243714\n",
      "      - -192248.09732956937\n",
      "      - -198507.2063475523\n",
      "      - -188331.03618033737\n",
      "      - -194717.81310910787\n",
      "      - -199238.15960065\n",
      "      - -197924.34587445846\n",
      "      - -197048.17689361068\n",
      "      - -189841.0829657434\n",
      "      - -203095.7196246176\n",
      "      - -195535.0290181412\n",
      "      - -190077.11120528946\n",
      "      - -193040.8162944614\n",
      "      - -191176.72374943114\n",
      "      - -191015.13182742678\n",
      "      - -195373.5311395725\n",
      "      - -196864.76836047645\n",
      "      - -192095.70566613457\n",
      "      - -190568.91191281631\n",
      "      - -192195.28597803658\n",
      "      - -193971.15315321198\n",
      "      - -190552.09415086042\n",
      "      - -197126.22591034957\n",
      "      - -193007.1051586886\n",
      "      - -193411.02137539376\n",
      "      - -199487.63455938024\n",
      "      - -190468.37198890603\n",
      "      - -203959.512177004\n",
      "      - -194438.5874498664\n",
      "      - -191141.0953942703\n",
      "      - -199621.28242754022\n",
      "      - -193057.8055742106\n",
      "      - -194046.99479275476\n",
      "      - -192749.15928462366\n",
      "      - -189119.2249950669\n",
      "      - -195586.3064892125\n",
      "      - -195826.46759833116\n",
      "      - -244725.71339162154\n",
      "      - -191007.68990103502\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11826568538601895\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5128392807233992\n",
      "      mean_inference_ms: 1.5978259765829859\n",
      "      mean_raw_obs_processing_ms: 0.1625940830185751\n",
      "  time_since_restore: 2206.2912423610687\n",
      "  time_this_iter_s: 16.07342839241028\n",
      "  time_total_s: 2206.2912423610687\n",
      "  timers:\n",
      "    learn_throughput: 25459.295\n",
      "    learn_time_ms: 2513.188\n",
      "    load_throughput: 532065.479\n",
      "    load_time_ms: 120.256\n",
      "    training_iteration_time_ms: 15611.169\n",
      "    update_time_ms: 5.112\n",
      "  timestamp: 1665744424\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 9021744\n",
      "  training_iteration: 141\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:47:09 (running for 00:37:12.17)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   141</td><td style=\"text-align: right;\">         2206.29</td><td style=\"text-align: right;\">9.02174e+06</td><td style=\"text-align: right;\"> -195425</td><td style=\"text-align: right;\">             -188331</td><td style=\"text-align: right;\">             -244726</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:47:15 (running for 00:37:17.54)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   141</td><td style=\"text-align: right;\">         2206.29</td><td style=\"text-align: right;\">9.02174e+06</td><td style=\"text-align: right;\"> -195425</td><td style=\"text-align: right;\">             -188331</td><td style=\"text-align: right;\">             -244726</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:47:20 (running for 00:37:22.55)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   141</td><td style=\"text-align: right;\">         2206.29</td><td style=\"text-align: right;\">9.02174e+06</td><td style=\"text-align: right;\"> -195425</td><td style=\"text-align: right;\">             -188331</td><td style=\"text-align: right;\">             -244726</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 9085728\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 9085728\n",
      "    num_agent_steps_trained: 9085728\n",
      "    num_env_steps_sampled: 9085728\n",
      "    num_env_steps_trained: 9085728\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-47-20\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -189119.2249950669\n",
      "  episode_reward_mean: -194226.18683386172\n",
      "  episode_reward_min: -244725.71339162154\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 9084\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 2.939167022705078\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0016248460160568357\n",
      "          model: {}\n",
      "          policy_loss: 0.0063977325335145\n",
      "          total_loss: 10.006428718566895\n",
      "          vf_explained_var: 1.99538021661283e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 9085728\n",
      "    num_agent_steps_trained: 9085728\n",
      "    num_env_steps_sampled: 9085728\n",
      "    num_env_steps_trained: 9085728\n",
      "  iterations_since_restore: 142\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 9085728\n",
      "  num_agent_steps_trained: 9085728\n",
      "  num_env_steps_sampled: 9085728\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 9085728\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.70476190476191\n",
      "    ram_util_percent: 79.5\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11836386847082243\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5128708256850735\n",
      "    mean_inference_ms: 1.5991290097138298\n",
      "    mean_raw_obs_processing_ms: 0.16251906117760892\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -189119.2249950669\n",
      "    episode_reward_mean: -194226.18683386172\n",
      "    episode_reward_min: -244725.71339162154\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -190077.11120528946\n",
      "      - -193040.8162944614\n",
      "      - -191176.72374943114\n",
      "      - -191015.13182742678\n",
      "      - -195373.5311395725\n",
      "      - -196864.76836047645\n",
      "      - -192095.70566613457\n",
      "      - -190568.91191281631\n",
      "      - -192195.28597803658\n",
      "      - -193971.15315321198\n",
      "      - -190552.09415086042\n",
      "      - -197126.22591034957\n",
      "      - -193007.1051586886\n",
      "      - -193411.02137539376\n",
      "      - -199487.63455938024\n",
      "      - -190468.37198890603\n",
      "      - -203959.512177004\n",
      "      - -194438.5874498664\n",
      "      - -191141.0953942703\n",
      "      - -199621.28242754022\n",
      "      - -193057.8055742106\n",
      "      - -194046.99479275476\n",
      "      - -192749.15928462366\n",
      "      - -189119.2249950669\n",
      "      - -195586.3064892125\n",
      "      - -195826.46759833116\n",
      "      - -244725.71339162154\n",
      "      - -191007.68990103502\n",
      "      - -192042.3429438986\n",
      "      - -193502.1614807269\n",
      "      - -190095.56752151955\n",
      "      - -194315.70534586403\n",
      "      - -192909.5399448634\n",
      "      - -194824.405524439\n",
      "      - -193280.68539527492\n",
      "      - -195210.1534773007\n",
      "      - -189943.40434911082\n",
      "      - -191290.2795322926\n",
      "      - -191191.81275039367\n",
      "      - -189493.32846123425\n",
      "      - -192291.6711148758\n",
      "      - -197841.889855413\n",
      "      - -193563.6713442689\n",
      "      - -199241.09074527954\n",
      "      - -190958.63392741777\n",
      "      - -189882.36450194588\n",
      "      - -198303.50716992372\n",
      "      - -193223.96555269288\n",
      "      - -204337.21141819825\n",
      "      - -208017.60866091304\n",
      "      - -191905.55262489055\n",
      "      - -189517.5170783303\n",
      "      - -190458.80965140212\n",
      "      - -195217.02061765868\n",
      "      - -191381.33159289398\n",
      "      - -196649.1908079162\n",
      "      - -191385.08024546353\n",
      "      - -191692.92920576\n",
      "      - -192920.81753461817\n",
      "      - -192077.37165019277\n",
      "      - -192868.64827179958\n",
      "      - -196469.33286299353\n",
      "      - -194764.49658583835\n",
      "      - -195516.44695281846\n",
      "      - -191792.57619012822\n",
      "      - -192583.16304407094\n",
      "      - -196613.7723723622\n",
      "      - -191709.0715795114\n",
      "      - -192891.89313896207\n",
      "      - -197832.2848083314\n",
      "      - -193157.62388622994\n",
      "      - -192838.42148486275\n",
      "      - -193947.16011228986\n",
      "      - -191011.74607897163\n",
      "      - -192589.5708240134\n",
      "      - -204773.4610445711\n",
      "      - -191179.8309144298\n",
      "      - -191293.41722063677\n",
      "      - -197506.77636575\n",
      "      - -190751.61769144615\n",
      "      - -193303.91403006244\n",
      "      - -192161.77937968622\n",
      "      - -195912.02599100125\n",
      "      - -193870.04526223318\n",
      "      - -199562.5023420955\n",
      "      - -191717.67678257302\n",
      "      - -193201.07122482784\n",
      "      - -191046.12762291782\n",
      "      - -191736.5390210407\n",
      "      - -190932.86458697473\n",
      "      - -193773.84652852276\n",
      "      - -191632.59669604138\n",
      "      - -192831.00086959137\n",
      "      - -191397.47161190782\n",
      "      - -201147.53690702145\n",
      "      - -193851.64762067224\n",
      "      - -193248.78069426687\n",
      "      - -190541.84251369213\n",
      "      - -192242.7179424034\n",
      "      - -191737.33039567727\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11836386847082243\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5128708256850735\n",
      "      mean_inference_ms: 1.5991290097138298\n",
      "      mean_raw_obs_processing_ms: 0.16251906117760892\n",
      "  time_since_restore: 2221.907561779022\n",
      "  time_this_iter_s: 15.616319417953491\n",
      "  time_total_s: 2221.907561779022\n",
      "  timers:\n",
      "    learn_throughput: 25475.35\n",
      "    learn_time_ms: 2511.604\n",
      "    load_throughput: 533615.683\n",
      "    load_time_ms: 119.907\n",
      "    training_iteration_time_ms: 15602.184\n",
      "    update_time_ms: 4.843\n",
      "  timestamp: 1665744440\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 9085728\n",
      "  training_iteration: 142\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:47:25 (running for 00:37:27.83)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   142</td><td style=\"text-align: right;\">         2221.91</td><td style=\"text-align: right;\">9.08573e+06</td><td style=\"text-align: right;\"> -194226</td><td style=\"text-align: right;\">             -189119</td><td style=\"text-align: right;\">             -244726</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:47:30 (running for 00:37:32.99)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   142</td><td style=\"text-align: right;\">         2221.91</td><td style=\"text-align: right;\">9.08573e+06</td><td style=\"text-align: right;\"> -194226</td><td style=\"text-align: right;\">             -189119</td><td style=\"text-align: right;\">             -244726</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:47:35 (running for 00:37:38.00)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   142</td><td style=\"text-align: right;\">         2221.91</td><td style=\"text-align: right;\">9.08573e+06</td><td style=\"text-align: right;\"> -194226</td><td style=\"text-align: right;\">             -189119</td><td style=\"text-align: right;\">             -244726</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 9149712\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 9149712\n",
      "    num_agent_steps_trained: 9149712\n",
      "    num_env_steps_sampled: 9149712\n",
      "    num_env_steps_trained: 9149712\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-47-36\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -188362.73100947018\n",
      "  episode_reward_mean: -194395.79694661553\n",
      "  episode_reward_min: -220175.5933046717\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 9144\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 2.9229722023010254\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0023651549126952887\n",
      "          model: {}\n",
      "          policy_loss: 0.0017895549535751343\n",
      "          total_loss: 10.001970291137695\n",
      "          vf_explained_var: -2.530869096517563e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 9149712\n",
      "    num_agent_steps_trained: 9149712\n",
      "    num_env_steps_sampled: 9149712\n",
      "    num_env_steps_trained: 9149712\n",
      "  iterations_since_restore: 143\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 9149712\n",
      "  num_agent_steps_trained: 9149712\n",
      "  num_env_steps_sampled: 9149712\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 9149712\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.49545454545454\n",
      "    ram_util_percent: 79.5\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11827373363934222\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5129640611384745\n",
      "    mean_inference_ms: 1.5989323727840554\n",
      "    mean_raw_obs_processing_ms: 0.16263932859401697\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -188362.73100947018\n",
      "    episode_reward_mean: -194395.79694661553\n",
      "    episode_reward_min: -220175.5933046717\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -192868.64827179958\n",
      "      - -196469.33286299353\n",
      "      - -194764.49658583835\n",
      "      - -195516.44695281846\n",
      "      - -191792.57619012822\n",
      "      - -192583.16304407094\n",
      "      - -196613.7723723622\n",
      "      - -191709.0715795114\n",
      "      - -192891.89313896207\n",
      "      - -197832.2848083314\n",
      "      - -193157.62388622994\n",
      "      - -192838.42148486275\n",
      "      - -193947.16011228986\n",
      "      - -191011.74607897163\n",
      "      - -192589.5708240134\n",
      "      - -204773.4610445711\n",
      "      - -191179.8309144298\n",
      "      - -191293.41722063677\n",
      "      - -197506.77636575\n",
      "      - -190751.61769144615\n",
      "      - -193303.91403006244\n",
      "      - -192161.77937968622\n",
      "      - -195912.02599100125\n",
      "      - -193870.04526223318\n",
      "      - -199562.5023420955\n",
      "      - -191717.67678257302\n",
      "      - -193201.07122482784\n",
      "      - -191046.12762291782\n",
      "      - -191736.5390210407\n",
      "      - -190932.86458697473\n",
      "      - -193773.84652852276\n",
      "      - -191632.59669604138\n",
      "      - -192831.00086959137\n",
      "      - -191397.47161190782\n",
      "      - -201147.53690702145\n",
      "      - -193851.64762067224\n",
      "      - -193248.78069426687\n",
      "      - -190541.84251369213\n",
      "      - -192242.7179424034\n",
      "      - -191737.33039567727\n",
      "      - -192195.80056512024\n",
      "      - -192425.87536206807\n",
      "      - -194589.24396297708\n",
      "      - -191130.4403799688\n",
      "      - -190560.35914303773\n",
      "      - -195557.51612781582\n",
      "      - -191082.16108302784\n",
      "      - -193111.59280073975\n",
      "      - -202552.96447354212\n",
      "      - -192595.46877093625\n",
      "      - -196481.24718041817\n",
      "      - -192014.52769105605\n",
      "      - -192724.51727372588\n",
      "      - -188362.73100947018\n",
      "      - -193584.60110228174\n",
      "      - -193122.30332488945\n",
      "      - -190635.2033025348\n",
      "      - -188438.98535556722\n",
      "      - -196828.71429130403\n",
      "      - -191820.55229255348\n",
      "      - -190823.20688398962\n",
      "      - -194645.13915585226\n",
      "      - -195772.0650070471\n",
      "      - -190070.03989072907\n",
      "      - -193903.3395866511\n",
      "      - -204380.82588569613\n",
      "      - -191879.760018292\n",
      "      - -190423.7809396721\n",
      "      - -207261.93915559948\n",
      "      - -198872.72659747084\n",
      "      - -193848.85998142752\n",
      "      - -194332.33178901504\n",
      "      - -190868.6943613094\n",
      "      - -210198.09933946945\n",
      "      - -189209.76786696774\n",
      "      - -193262.73523517192\n",
      "      - -196055.40539806566\n",
      "      - -189119.0242521609\n",
      "      - -196652.60372009498\n",
      "      - -195805.16192131033\n",
      "      - -195420.5912258319\n",
      "      - -205170.79414240038\n",
      "      - -193024.85454042073\n",
      "      - -195102.39777575008\n",
      "      - -192719.2185217361\n",
      "      - -197049.21886932448\n",
      "      - -191961.11769391975\n",
      "      - -194306.3741172189\n",
      "      - -197634.9955066721\n",
      "      - -200510.55054735616\n",
      "      - -220175.5933046717\n",
      "      - -191056.49993282818\n",
      "      - -190218.00708405834\n",
      "      - -193481.54940755153\n",
      "      - -191214.71524198522\n",
      "      - -200745.2642076779\n",
      "      - -189532.74294177108\n",
      "      - -197212.35073803147\n",
      "      - -192292.60368712666\n",
      "      - -195609.31324296762\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11827373363934222\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5129640611384745\n",
      "      mean_inference_ms: 1.5989323727840554\n",
      "      mean_raw_obs_processing_ms: 0.16263932859401697\n",
      "  time_since_restore: 2238.0164144039154\n",
      "  time_this_iter_s: 16.10885262489319\n",
      "  time_total_s: 2238.0164144039154\n",
      "  timers:\n",
      "    learn_throughput: 25484.296\n",
      "    learn_time_ms: 2510.723\n",
      "    load_throughput: 535246.568\n",
      "    load_time_ms: 119.541\n",
      "    training_iteration_time_ms: 15673.98\n",
      "    update_time_ms: 4.59\n",
      "  timestamp: 1665744456\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 9149712\n",
      "  training_iteration: 143\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:47:41 (running for 00:37:43.96)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   143</td><td style=\"text-align: right;\">         2238.02</td><td style=\"text-align: right;\">9.14971e+06</td><td style=\"text-align: right;\"> -194396</td><td style=\"text-align: right;\">             -188363</td><td style=\"text-align: right;\">             -220176</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:47:46 (running for 00:37:48.97)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   143</td><td style=\"text-align: right;\">         2238.02</td><td style=\"text-align: right;\">9.14971e+06</td><td style=\"text-align: right;\"> -194396</td><td style=\"text-align: right;\">             -188363</td><td style=\"text-align: right;\">             -220176</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 9213696\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 9213696\n",
      "    num_agent_steps_trained: 9213696\n",
      "    num_env_steps_sampled: 9213696\n",
      "    num_env_steps_trained: 9213696\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-47-51\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -188973.80251063875\n",
      "  episode_reward_mean: -194945.18636626416\n",
      "  episode_reward_min: -224474.71976204612\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 9204\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 2.9296135902404785\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0017119917320087552\n",
      "          model: {}\n",
      "          policy_loss: 0.0021296690683811903\n",
      "          total_loss: 10.002180099487305\n",
      "          vf_explained_var: -4.0763989090919495e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 9213696\n",
      "    num_agent_steps_trained: 9213696\n",
      "    num_env_steps_sampled: 9213696\n",
      "    num_env_steps_trained: 9213696\n",
      "  iterations_since_restore: 144\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 9213696\n",
      "  num_agent_steps_trained: 9213696\n",
      "  num_env_steps_sampled: 9213696\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 9213696\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.31428571428572\n",
      "    ram_util_percent: 79.5047619047619\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11822764934628338\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5128558594098024\n",
      "    mean_inference_ms: 1.5987626118179474\n",
      "    mean_raw_obs_processing_ms: 0.16252984503030407\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -188973.80251063875\n",
      "    episode_reward_mean: -194945.18636626416\n",
      "    episode_reward_min: -224474.71976204612\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -190823.20688398962\n",
      "      - -194645.13915585226\n",
      "      - -195772.0650070471\n",
      "      - -190070.03989072907\n",
      "      - -193903.3395866511\n",
      "      - -204380.82588569613\n",
      "      - -191879.760018292\n",
      "      - -190423.7809396721\n",
      "      - -207261.93915559948\n",
      "      - -198872.72659747084\n",
      "      - -193848.85998142752\n",
      "      - -194332.33178901504\n",
      "      - -190868.6943613094\n",
      "      - -210198.09933946945\n",
      "      - -189209.76786696774\n",
      "      - -193262.73523517192\n",
      "      - -196055.40539806566\n",
      "      - -189119.0242521609\n",
      "      - -196652.60372009498\n",
      "      - -195805.16192131033\n",
      "      - -195420.5912258319\n",
      "      - -205170.79414240038\n",
      "      - -193024.85454042073\n",
      "      - -195102.39777575008\n",
      "      - -192719.2185217361\n",
      "      - -197049.21886932448\n",
      "      - -191961.11769391975\n",
      "      - -194306.3741172189\n",
      "      - -197634.9955066721\n",
      "      - -200510.55054735616\n",
      "      - -220175.5933046717\n",
      "      - -191056.49993282818\n",
      "      - -190218.00708405834\n",
      "      - -193481.54940755153\n",
      "      - -191214.71524198522\n",
      "      - -200745.2642076779\n",
      "      - -189532.74294177108\n",
      "      - -197212.35073803147\n",
      "      - -192292.60368712666\n",
      "      - -195609.31324296762\n",
      "      - -189154.64430624666\n",
      "      - -194804.60455503556\n",
      "      - -224474.71976204612\n",
      "      - -191205.62788969226\n",
      "      - -192678.44333456564\n",
      "      - -192599.5215632564\n",
      "      - -198264.40407694707\n",
      "      - -191632.18433285487\n",
      "      - -190401.90626072348\n",
      "      - -190479.66761661303\n",
      "      - -194642.77194053863\n",
      "      - -189892.54694964227\n",
      "      - -189388.30276757112\n",
      "      - -190701.88590396268\n",
      "      - -203248.2166812314\n",
      "      - -190661.63510934488\n",
      "      - -193687.71179761927\n",
      "      - -193551.08858960035\n",
      "      - -193247.62581782092\n",
      "      - -194509.93491186804\n",
      "      - -195304.43816899825\n",
      "      - -200461.9633816212\n",
      "      - -191087.98670353412\n",
      "      - -201552.50176953257\n",
      "      - -189951.64587800278\n",
      "      - -191941.675239624\n",
      "      - -197979.9655580773\n",
      "      - -192674.1044780856\n",
      "      - -204978.90607830064\n",
      "      - -193069.360290634\n",
      "      - -190781.8277951271\n",
      "      - -192294.08588765468\n",
      "      - -195560.5567071867\n",
      "      - -192714.49810236265\n",
      "      - -191488.27692912775\n",
      "      - -194557.53242802943\n",
      "      - -201233.55085694452\n",
      "      - -191309.5690621749\n",
      "      - -188973.80251063875\n",
      "      - -191387.86907174936\n",
      "      - -192124.9577222415\n",
      "      - -196496.8094679532\n",
      "      - -191491.26540698143\n",
      "      - -194127.12551436498\n",
      "      - -194836.13387695688\n",
      "      - -194473.07008670608\n",
      "      - -190167.8011344623\n",
      "      - -190731.70078409594\n",
      "      - -193558.31407759557\n",
      "      - -196625.47312784192\n",
      "      - -191303.04328031282\n",
      "      - -193841.36986470694\n",
      "      - -190462.96065533964\n",
      "      - -204023.47524178406\n",
      "      - -193051.2233067235\n",
      "      - -194309.96047965964\n",
      "      - -190564.7644346829\n",
      "      - -189512.16668384755\n",
      "      - -193056.708790497\n",
      "      - -209404.49190977795\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11822764934628338\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5128558594098024\n",
      "      mean_inference_ms: 1.5987626118179474\n",
      "      mean_raw_obs_processing_ms: 0.16252984503030407\n",
      "  time_since_restore: 2253.173314809799\n",
      "  time_this_iter_s: 15.156900405883789\n",
      "  time_total_s: 2253.173314809799\n",
      "  timers:\n",
      "    learn_throughput: 25518.16\n",
      "    learn_time_ms: 2507.391\n",
      "    load_throughput: 537036.361\n",
      "    load_time_ms: 119.143\n",
      "    training_iteration_time_ms: 15627.708\n",
      "    update_time_ms: 4.474\n",
      "  timestamp: 1665744471\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 9213696\n",
      "  training_iteration: 144\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:47:51 (running for 00:37:54.15)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   144</td><td style=\"text-align: right;\">         2253.17</td><td style=\"text-align: right;\">9.2137e+06</td><td style=\"text-align: right;\"> -194945</td><td style=\"text-align: right;\">             -188974</td><td style=\"text-align: right;\">             -224475</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:47:56 (running for 00:37:59.15)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   144</td><td style=\"text-align: right;\">         2253.17</td><td style=\"text-align: right;\">9.2137e+06</td><td style=\"text-align: right;\"> -194945</td><td style=\"text-align: right;\">             -188974</td><td style=\"text-align: right;\">             -224475</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:48:01 (running for 00:38:04.16)<br>Memory usage on this node: 12.3/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   144</td><td style=\"text-align: right;\">         2253.17</td><td style=\"text-align: right;\">9.2137e+06</td><td style=\"text-align: right;\"> -194945</td><td style=\"text-align: right;\">             -188974</td><td style=\"text-align: right;\">             -224475</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:48:06 (running for 00:38:09.17)<br>Memory usage on this node: 12.4/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">        ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   144</td><td style=\"text-align: right;\">         2253.17</td><td style=\"text-align: right;\">9.2137e+06</td><td style=\"text-align: right;\"> -194945</td><td style=\"text-align: right;\">             -188974</td><td style=\"text-align: right;\">             -224475</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 9277680\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 9277680\n",
      "    num_agent_steps_trained: 9277680\n",
      "    num_env_steps_sampled: 9277680\n",
      "    num_env_steps_trained: 9277680\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-48-07\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -186738.2569470033\n",
      "  episode_reward_mean: -195122.0185361197\n",
      "  episode_reward_min: -240778.7402475682\n",
      "  episodes_this_iter: 72\n",
      "  episodes_total: 9276\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 2.9274704456329346\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0022702349815517664\n",
      "          model: {}\n",
      "          policy_loss: 0.0032234375830739737\n",
      "          total_loss: 10.003384590148926\n",
      "          vf_explained_var: -1.5226694358716486e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 9277680\n",
      "    num_agent_steps_trained: 9277680\n",
      "    num_env_steps_sampled: 9277680\n",
      "    num_env_steps_trained: 9277680\n",
      "  iterations_since_restore: 145\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 9277680\n",
      "  num_agent_steps_trained: 9277680\n",
      "  num_env_steps_sampled: 9277680\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 9277680\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 76.15909090909089\n",
      "    ram_util_percent: 79.55909090909091\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11833310884057871\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5130524475040452\n",
      "    mean_inference_ms: 1.599780584424788\n",
      "    mean_raw_obs_processing_ms: 0.16245431066147667\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -186738.2569470033\n",
      "    episode_reward_mean: -195122.0185361197\n",
      "    episode_reward_min: -240778.7402475682\n",
      "    episodes_this_iter: 72\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -195560.5567071867\n",
      "      - -192714.49810236265\n",
      "      - -191488.27692912775\n",
      "      - -194557.53242802943\n",
      "      - -201233.55085694452\n",
      "      - -191309.5690621749\n",
      "      - -188973.80251063875\n",
      "      - -191387.86907174936\n",
      "      - -192124.9577222415\n",
      "      - -196496.8094679532\n",
      "      - -191491.26540698143\n",
      "      - -194127.12551436498\n",
      "      - -194836.13387695688\n",
      "      - -194473.07008670608\n",
      "      - -190167.8011344623\n",
      "      - -190731.70078409594\n",
      "      - -193558.31407759557\n",
      "      - -196625.47312784192\n",
      "      - -191303.04328031282\n",
      "      - -193841.36986470694\n",
      "      - -190462.96065533964\n",
      "      - -204023.47524178406\n",
      "      - -193051.2233067235\n",
      "      - -194309.96047965964\n",
      "      - -190564.7644346829\n",
      "      - -189512.16668384755\n",
      "      - -193056.708790497\n",
      "      - -209404.49190977795\n",
      "      - -194695.04922422481\n",
      "      - -190487.0889818449\n",
      "      - -204551.09984817414\n",
      "      - -195467.71405267893\n",
      "      - -190903.91419345612\n",
      "      - -200954.70686503503\n",
      "      - -192492.4427643165\n",
      "      - -190552.2278623265\n",
      "      - -189102.3035346771\n",
      "      - -194129.7680814726\n",
      "      - -194211.23222552918\n",
      "      - -190553.71635127408\n",
      "      - -193941.6670951662\n",
      "      - -197750.06424636606\n",
      "      - -196727.29690101472\n",
      "      - -204576.82763032167\n",
      "      - -198695.35683496392\n",
      "      - -198979.62700833197\n",
      "      - -208715.66300664493\n",
      "      - -189994.7625856818\n",
      "      - -190288.54847966332\n",
      "      - -190754.25390831652\n",
      "      - -190049.42991576527\n",
      "      - -190241.96396359202\n",
      "      - -190279.92301674376\n",
      "      - -193234.4832543166\n",
      "      - -190785.1100111782\n",
      "      - -186738.2569470033\n",
      "      - -193294.62192746598\n",
      "      - -202772.34895952264\n",
      "      - -240778.7402475682\n",
      "      - -189232.04997333323\n",
      "      - -190690.0025398455\n",
      "      - -191312.3846224025\n",
      "      - -192220.35510074865\n",
      "      - -192061.85646562494\n",
      "      - -191232.44691451197\n",
      "      - -211523.7549931333\n",
      "      - -190978.68052046842\n",
      "      - -190708.33201268237\n",
      "      - -198488.58112596834\n",
      "      - -197399.79942902317\n",
      "      - -193538.2681218223\n",
      "      - -199887.29100059782\n",
      "      - -190170.78512452042\n",
      "      - -191652.1987177024\n",
      "      - -196315.57719160485\n",
      "      - -207426.59659668582\n",
      "      - -193330.04942492637\n",
      "      - -192518.54367765656\n",
      "      - -197481.469018578\n",
      "      - -196754.5041665551\n",
      "      - -191393.39202551887\n",
      "      - -198222.10345522733\n",
      "      - -193200.40814066998\n",
      "      - -198417.41951909167\n",
      "      - -192506.49491939758\n",
      "      - -197333.13169015545\n",
      "      - -190280.7232000396\n",
      "      - -192169.90170196738\n",
      "      - -194128.25783442915\n",
      "      - -192531.187355328\n",
      "      - -188221.15561797406\n",
      "      - -200701.16081007622\n",
      "      - -202993.46098422923\n",
      "      - -210736.93626341855\n",
      "      - -191288.2308308027\n",
      "      - -193246.46013866263\n",
      "      - -191638.4198596514\n",
      "      - -192554.889221086\n",
      "      - -191134.32814565772\n",
      "      - -206491.58372080943\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11833310884057871\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5130524475040452\n",
      "      mean_inference_ms: 1.599780584424788\n",
      "      mean_raw_obs_processing_ms: 0.16245431066147667\n",
      "  time_since_restore: 2268.8815121650696\n",
      "  time_this_iter_s: 15.708197355270386\n",
      "  time_total_s: 2268.8815121650696\n",
      "  timers:\n",
      "    learn_throughput: 25500.959\n",
      "    learn_time_ms: 2509.082\n",
      "    load_throughput: 539627.262\n",
      "    load_time_ms: 118.571\n",
      "    training_iteration_time_ms: 15674.814\n",
      "    update_time_ms: 4.506\n",
      "  timestamp: 1665744487\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 9277680\n",
      "  training_iteration: 145\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:48:12 (running for 00:38:14.92)<br>Memory usage on this node: 12.4/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   145</td><td style=\"text-align: right;\">         2268.88</td><td style=\"text-align: right;\">9.27768e+06</td><td style=\"text-align: right;\"> -195122</td><td style=\"text-align: right;\">             -186738</td><td style=\"text-align: right;\">             -240779</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:48:18 (running for 00:38:20.40)<br>Memory usage on this node: 12.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   145</td><td style=\"text-align: right;\">         2268.88</td><td style=\"text-align: right;\">9.27768e+06</td><td style=\"text-align: right;\"> -195122</td><td style=\"text-align: right;\">             -186738</td><td style=\"text-align: right;\">             -240779</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:48:23 (running for 00:38:25.41)<br>Memory usage on this node: 12.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   145</td><td style=\"text-align: right;\">         2268.88</td><td style=\"text-align: right;\">9.27768e+06</td><td style=\"text-align: right;\"> -195122</td><td style=\"text-align: right;\">             -186738</td><td style=\"text-align: right;\">             -240779</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 9341664\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 9341664\n",
      "    num_agent_steps_trained: 9341664\n",
      "    num_env_steps_sampled: 9341664\n",
      "    num_env_steps_trained: 9341664\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-48-23\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -187296.62922108348\n",
      "  episode_reward_mean: -194944.20631054798\n",
      "  episode_reward_min: -217968.84418870584\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 9336\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 2.9181976318359375\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0017985646845772862\n",
      "          model: {}\n",
      "          policy_loss: 0.0003789197653532028\n",
      "          total_loss: 10.000447273254395\n",
      "          vf_explained_var: -1.791398972272873e-06\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 9341664\n",
      "    num_agent_steps_trained: 9341664\n",
      "    num_env_steps_sampled: 9341664\n",
      "    num_env_steps_trained: 9341664\n",
      "  iterations_since_restore: 146\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 9341664\n",
      "  num_agent_steps_trained: 9341664\n",
      "  num_env_steps_sampled: 9341664\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 9341664\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 81.96363636363637\n",
      "    ram_util_percent: 80.47272727272728\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11828518700818534\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5132636522074698\n",
      "    mean_inference_ms: 1.5995195539220668\n",
      "    mean_raw_obs_processing_ms: 0.16263493959460104\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -187296.62922108348\n",
      "    episode_reward_mean: -194944.20631054798\n",
      "    episode_reward_min: -217968.84418870584\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -190690.0025398455\n",
      "      - -191312.3846224025\n",
      "      - -192220.35510074865\n",
      "      - -192061.85646562494\n",
      "      - -191232.44691451197\n",
      "      - -211523.7549931333\n",
      "      - -190978.68052046842\n",
      "      - -190708.33201268237\n",
      "      - -198488.58112596834\n",
      "      - -197399.79942902317\n",
      "      - -193538.2681218223\n",
      "      - -199887.29100059782\n",
      "      - -190170.78512452042\n",
      "      - -191652.1987177024\n",
      "      - -196315.57719160485\n",
      "      - -207426.59659668582\n",
      "      - -193330.04942492637\n",
      "      - -192518.54367765656\n",
      "      - -197481.469018578\n",
      "      - -196754.5041665551\n",
      "      - -191393.39202551887\n",
      "      - -198222.10345522733\n",
      "      - -193200.40814066998\n",
      "      - -198417.41951909167\n",
      "      - -192506.49491939758\n",
      "      - -197333.13169015545\n",
      "      - -190280.7232000396\n",
      "      - -192169.90170196738\n",
      "      - -194128.25783442915\n",
      "      - -192531.187355328\n",
      "      - -188221.15561797406\n",
      "      - -200701.16081007622\n",
      "      - -202993.46098422923\n",
      "      - -210736.93626341855\n",
      "      - -191288.2308308027\n",
      "      - -193246.46013866263\n",
      "      - -191638.4198596514\n",
      "      - -192554.889221086\n",
      "      - -191134.32814565772\n",
      "      - -206491.58372080943\n",
      "      - -193252.7966822379\n",
      "      - -196986.9060683581\n",
      "      - -195597.8582510179\n",
      "      - -187296.62922108348\n",
      "      - -194921.19798329833\n",
      "      - -190674.91398656313\n",
      "      - -200564.52055470823\n",
      "      - -190753.1956076968\n",
      "      - -190868.7814154488\n",
      "      - -199218.9847437185\n",
      "      - -194235.78055371426\n",
      "      - -188906.83358949146\n",
      "      - -187935.84005259105\n",
      "      - -194757.5224567554\n",
      "      - -191397.24402152895\n",
      "      - -189418.0443045315\n",
      "      - -192974.32314560236\n",
      "      - -195432.88221357542\n",
      "      - -196395.01207885088\n",
      "      - -197546.79817650185\n",
      "      - -193965.99959610554\n",
      "      - -191097.99105879766\n",
      "      - -194100.02948594463\n",
      "      - -188256.0970250352\n",
      "      - -191804.5208375228\n",
      "      - -192228.04212665197\n",
      "      - -189722.57386821441\n",
      "      - -212952.59068515452\n",
      "      - -191275.11561201198\n",
      "      - -214247.1885754935\n",
      "      - -197435.14945790448\n",
      "      - -192407.36182716166\n",
      "      - -193922.99582626796\n",
      "      - -195951.7190282584\n",
      "      - -192617.65843254447\n",
      "      - -193112.95273107314\n",
      "      - -193006.5108095845\n",
      "      - -194623.3083147182\n",
      "      - -188470.7962804572\n",
      "      - -193806.56564086003\n",
      "      - -194142.42622379397\n",
      "      - -192970.71028476604\n",
      "      - -191196.06401463848\n",
      "      - -193130.37373813463\n",
      "      - -217968.84418870584\n",
      "      - -188973.36096277853\n",
      "      - -194180.9182290797\n",
      "      - -193752.07490363307\n",
      "      - -192851.2403321264\n",
      "      - -191972.56751942233\n",
      "      - -201978.63088608914\n",
      "      - -193309.87127887158\n",
      "      - -191156.1940548028\n",
      "      - -192112.30323876234\n",
      "      - -193971.0145576269\n",
      "      - -191587.83531773672\n",
      "      - -194636.3544179577\n",
      "      - -200607.794909548\n",
      "      - -202005.55708932912\n",
      "      - -202894.1403807075\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11828518700818534\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5132636522074698\n",
      "      mean_inference_ms: 1.5995195539220668\n",
      "      mean_raw_obs_processing_ms: 0.16263493959460104\n",
      "  time_since_restore: 2285.2149815559387\n",
      "  time_this_iter_s: 16.33346939086914\n",
      "  time_total_s: 2285.2149815559387\n",
      "  timers:\n",
      "    learn_throughput: 25469.828\n",
      "    learn_time_ms: 2512.149\n",
      "    load_throughput: 542816.017\n",
      "    load_time_ms: 117.874\n",
      "    training_iteration_time_ms: 15745.008\n",
      "    update_time_ms: 4.444\n",
      "  timestamp: 1665744503\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 9341664\n",
      "  training_iteration: 146\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:48:29 (running for 00:38:31.59)<br>Memory usage on this node: 12.5/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   146</td><td style=\"text-align: right;\">         2285.21</td><td style=\"text-align: right;\">9.34166e+06</td><td style=\"text-align: right;\"> -194944</td><td style=\"text-align: right;\">             -187297</td><td style=\"text-align: right;\">             -217969</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:48:34 (running for 00:38:36.79)<br>Memory usage on this node: 12.4/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   146</td><td style=\"text-align: right;\">         2285.21</td><td style=\"text-align: right;\">9.34166e+06</td><td style=\"text-align: right;\"> -194944</td><td style=\"text-align: right;\">             -187297</td><td style=\"text-align: right;\">             -217969</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:48:39 (running for 00:38:41.79)<br>Memory usage on this node: 12.4/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   146</td><td style=\"text-align: right;\">         2285.21</td><td style=\"text-align: right;\">9.34166e+06</td><td style=\"text-align: right;\"> -194944</td><td style=\"text-align: right;\">             -187297</td><td style=\"text-align: right;\">             -217969</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPOTrainer_IBGym-v1_5b58d_00000:\n",
      "  agent_timesteps_total: 9405648\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 9405648\n",
      "    num_agent_steps_trained: 9405648\n",
      "    num_env_steps_sampled: 9405648\n",
      "    num_env_steps_trained: 9405648\n",
      "  custom_metrics: {}\n",
      "  date: 2022-10-14_12-48-39\n",
      "  done: false\n",
      "  episode_len_mean: 1000.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -188126.03252839172\n",
      "  episode_reward_mean: -195572.46924091992\n",
      "  episode_reward_min: -233796.34798798428\n",
      "  episodes_this_iter: 60\n",
      "  episodes_total: 9396\n",
      "  experiment_id: 60b1151648774b57ab89dde1fea079b7\n",
      "  hostname: hamza-Legion-5-15ACH6H\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 2.9999999242136255e-05\n",
      "          entropy: 2.916558027267456\n",
      "          entropy_coeff: 9.999999747378752e-05\n",
      "          kl: 0.0016570857260376215\n",
      "          model: {}\n",
      "          policy_loss: 0.0030780716333538294\n",
      "          total_loss: 10.003118515014648\n",
      "          vf_explained_var: -8.25151801109314e-07\n",
      "          vf_loss: 10.0\n",
      "        train: null\n",
      "    num_agent_steps_sampled: 9405648\n",
      "    num_agent_steps_trained: 9405648\n",
      "    num_env_steps_sampled: 9405648\n",
      "    num_env_steps_trained: 9405648\n",
      "  iterations_since_restore: 147\n",
      "  node_ip: 192.168.0.185\n",
      "  num_agent_steps_sampled: 9405648\n",
      "  num_agent_steps_trained: 9405648\n",
      "  num_env_steps_sampled: 9405648\n",
      "  num_env_steps_sampled_this_iter: 63984\n",
      "  num_env_steps_trained: 9405648\n",
      "  num_env_steps_trained_this_iter: 63984\n",
      "  num_healthy_workers: 12\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 77.86086956521739\n",
      "    ram_util_percent: 80.43478260869567\n",
      "  pid: 344251\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1183048264045111\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.5131447862590265\n",
      "    mean_inference_ms: 1.5994134921422427\n",
      "    mean_raw_obs_processing_ms: 0.1626015820280215\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 1000.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: -188126.03252839172\n",
      "    episode_reward_mean: -195572.46924091992\n",
      "    episode_reward_min: -233796.34798798428\n",
      "    episodes_this_iter: 60\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      - 1000\n",
      "      episode_reward:\n",
      "      - -193965.99959610554\n",
      "      - -191097.99105879766\n",
      "      - -194100.02948594463\n",
      "      - -188256.0970250352\n",
      "      - -191804.5208375228\n",
      "      - -192228.04212665197\n",
      "      - -189722.57386821441\n",
      "      - -212952.59068515452\n",
      "      - -191275.11561201198\n",
      "      - -214247.1885754935\n",
      "      - -197435.14945790448\n",
      "      - -192407.36182716166\n",
      "      - -193922.99582626796\n",
      "      - -195951.7190282584\n",
      "      - -192617.65843254447\n",
      "      - -193112.95273107314\n",
      "      - -193006.5108095845\n",
      "      - -194623.3083147182\n",
      "      - -188470.7962804572\n",
      "      - -193806.56564086003\n",
      "      - -194142.42622379397\n",
      "      - -192970.71028476604\n",
      "      - -191196.06401463848\n",
      "      - -193130.37373813463\n",
      "      - -217968.84418870584\n",
      "      - -188973.36096277853\n",
      "      - -194180.9182290797\n",
      "      - -193752.07490363307\n",
      "      - -192851.2403321264\n",
      "      - -191972.56751942233\n",
      "      - -201978.63088608914\n",
      "      - -193309.87127887158\n",
      "      - -191156.1940548028\n",
      "      - -192112.30323876234\n",
      "      - -193971.0145576269\n",
      "      - -191587.83531773672\n",
      "      - -194636.3544179577\n",
      "      - -200607.794909548\n",
      "      - -202005.55708932912\n",
      "      - -202894.1403807075\n",
      "      - -191454.8737432435\n",
      "      - -219595.30752714642\n",
      "      - -195552.90104770038\n",
      "      - -192291.99103115196\n",
      "      - -192071.02639270845\n",
      "      - -192637.90311568286\n",
      "      - -196272.82650586643\n",
      "      - -191075.44096869533\n",
      "      - -192701.29569641763\n",
      "      - -193067.52011429504\n",
      "      - -202200.71227187905\n",
      "      - -210025.0462508738\n",
      "      - -192300.11010808524\n",
      "      - -191002.4244284\n",
      "      - -196054.75793724466\n",
      "      - -190905.23321417707\n",
      "      - -188933.22610136523\n",
      "      - -193891.89040547115\n",
      "      - -193810.99954515893\n",
      "      - -193110.48209806523\n",
      "      - -208445.2957097524\n",
      "      - -200202.3789714926\n",
      "      - -188126.03252839172\n",
      "      - -194084.33032575075\n",
      "      - -190541.31315058377\n",
      "      - -194581.68763083752\n",
      "      - -189777.9572993163\n",
      "      - -194185.87480258144\n",
      "      - -191080.99159050387\n",
      "      - -217839.82893147567\n",
      "      - -194684.15223040504\n",
      "      - -191777.89938575702\n",
      "      - -207962.26656721614\n",
      "      - -195568.55644139292\n",
      "      - -188950.46086346984\n",
      "      - -191438.32825628488\n",
      "      - -195372.57411657626\n",
      "      - -191527.12698689848\n",
      "      - -194535.402907124\n",
      "      - -196116.8087056218\n",
      "      - -209029.44997199034\n",
      "      - -192923.0704497647\n",
      "      - -195721.93012070993\n",
      "      - -192960.7511045128\n",
      "      - -202581.10617282966\n",
      "      - -191410.48395737837\n",
      "      - -195026.83781764735\n",
      "      - -191837.49136840893\n",
      "      - -192339.86923817612\n",
      "      - -192041.94354611667\n",
      "      - -189476.95783915356\n",
      "      - -191342.73620952974\n",
      "      - -192561.69614451355\n",
      "      - -190078.8778414416\n",
      "      - -193752.11931483055\n",
      "      - -194079.569558513\n",
      "      - -190178.89824899271\n",
      "      - -233796.34798798428\n",
      "      - -192355.94811027363\n",
      "      - -197592.15943588907\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1183048264045111\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.5131447862590265\n",
      "      mean_inference_ms: 1.5994134921422427\n",
      "      mean_raw_obs_processing_ms: 0.1626015820280215\n",
      "  time_since_restore: 2300.7172968387604\n",
      "  time_this_iter_s: 15.502315282821655\n",
      "  time_total_s: 2300.7172968387604\n",
      "  timers:\n",
      "    learn_throughput: 25381.356\n",
      "    learn_time_ms: 2520.906\n",
      "    load_throughput: 533393.809\n",
      "    load_time_ms: 119.956\n",
      "    training_iteration_time_ms: 15777.225\n",
      "    update_time_ms: 4.466\n",
      "  timestamp: 1665744519\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 9405648\n",
      "  training_iteration: 147\n",
      "  trial_id: 5b58d_00000\n",
      "  warmup_time: 12.386338949203491\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:48:45 (running for 00:38:47.29)<br>Memory usage on this node: 12.4/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   147</td><td style=\"text-align: right;\">         2300.72</td><td style=\"text-align: right;\">9.40565e+06</td><td style=\"text-align: right;\"> -195572</td><td style=\"text-align: right;\">             -188126</td><td style=\"text-align: right;\">             -233796</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:48:50 (running for 00:38:52.30)<br>Memory usage on this node: 12.4/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   147</td><td style=\"text-align: right;\">         2300.72</td><td style=\"text-align: right;\">9.40565e+06</td><td style=\"text-align: right;\"> -195572</td><td style=\"text-align: right;\">             -188126</td><td style=\"text-align: right;\">             -233796</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-14 12:48:55,070\tWARNING tune.py:682 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:48:55 (running for 00:38:57.31)<br>Memory usage on this node: 12.4/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   147</td><td style=\"text-align: right;\">         2300.72</td><td style=\"text-align: right;\">9.40565e+06</td><td style=\"text-align: right;\"> -195572</td><td style=\"text-align: right;\">             -188126</td><td style=\"text-align: right;\">             -233796</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "== Status ==<br>Current time: 2022-10-14 12:48:55 (running for 00:38:57.32)<br>Memory usage on this node: 12.4/15.5 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 13.0/16 CPUs, 1.0/1 GPUs, 0.0/5.94 GiB heap, 0.0/2.97 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">         ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n</thead>\n<tbody>\n<tr><td>PPOTrainer_IBGym-v1_5b58d_00000</td><td>RUNNING </td><td>192.168.0.185:344251</td><td style=\"text-align: right;\">   147</td><td style=\"text-align: right;\">         2300.72</td><td style=\"text-align: right;\">9.40565e+06</td><td style=\"text-align: right;\"> -195572</td><td style=\"text-align: right;\">             -188126</td><td style=\"text-align: right;\">             -233796</td><td style=\"text-align: right;\">              1000</td></tr>\n</tbody>\n</table><br><br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-14 12:48:57,155\tERROR tune.py:743 -- Trials did not complete: [PPOTrainer_IBGym-v1_5b58d_00000]\n",
      "2022-10-14 12:48:57,156\tINFO tune.py:747 -- Total run time: 2339.42 seconds (2337.31 seconds for the tuning loop).\n",
      "2022-10-14 12:48:57,156\tWARNING tune.py:753 -- Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n"
     ]
    }
   ],
   "source": [
    "results = tune.run(\n",
    "        PPOTrainer,\n",
    "        config=config,\n",
    "        name=\"industrial_benchmark\",\n",
    "        local_dir=\"tmp/ray_exp_logs\",\n",
    "        checkpoint_freq=5,\n",
    "        # stop={\"training_iteration\": 5},\n",
    "        sync_config=tune.SyncConfig(\n",
    "            syncer=None  # Disable syncing\n",
    "        )\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "last_checkpoint = results.get_last_checkpoint()._local_path\n",
    "config[\"num_workers\"] = 1\n",
    "\n",
    "lstm_ppo_policy = LSTMPPOPolicy(config=config,checkpoint_path=last_checkpoint)\n",
    "save_path = 'ppo/lstm_ppo_policy.pkl'\n",
    "lstm_ppo_policy.save(save_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "'/home/hamza/PycharmProjects/StateCompression/tmp/ray_exp_logs/industrial_benchmark/PPOTrainer_IBGym-v1_5b58d_00000_0_2022-10-14_12-09-57/checkpoint_000145/checkpoint-145'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.get_last_checkpoint()._local_path"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
