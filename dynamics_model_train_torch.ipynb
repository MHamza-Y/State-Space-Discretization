{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dynamic_model.dataset import DynamicsModelDataset\n",
    "from dynamic_model.model import DynamicsModel\n",
    "from dynamic_model.train import train_model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "print(f\"Using Device: {device}\")\n",
    "torch.backends.cudnn.benchmark = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n",
    "def load_dataset(file_path, input_key, output_key, test_size= 0.3, device=device):\n",
    "\n",
    "    dataset = np.load(file_path, allow_pickle=True)\n",
    "    x = dataset[()][input_key]\n",
    "    y = dataset[()][output_key]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size)\n",
    "    train_dataset = DynamicsModelDataset(x_train,y_train, device)\n",
    "    validation_dataset = DynamicsModelDataset(x_test,y_test, device)\n",
    "    return train_dataset, validation_dataset\n",
    "\n",
    "\n",
    "dataset_input_key = 'merged_input'\n",
    "dataset_output_key = 'merged_output'\n",
    "dataset_file_path = 'tmp/ib-out/ib-samples.npy'\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 4000\n",
    "params = {'batch_size': batch_size,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 0,\n",
    "          'drop_last':True}\n",
    "\n",
    "\n",
    "\n",
    "train_dataset, val_dataset = load_dataset(file_path=dataset_file_path, input_key=dataset_input_key, output_key= dataset_output_key)\n",
    "train_loader = DataLoader(train_dataset, **params)\n",
    "val_loader = DataLoader(val_dataset, **params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "num_of_features = train_dataset.get_features_size()\n",
    "seq_len = train_dataset.get_seq_len()\n",
    "hidden_size = 32\n",
    "out_size = train_dataset.get_output_feature_size()\n",
    "\n",
    "model = DynamicsModel(features=num_of_features,hidden_size=hidden_size,out_size=out_size, batch_size=batch_size, seq_len=seq_len).to(device=device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained test\n",
      "--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([4000, 1, 6])) that is different to the input size (torch.Size([4000, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 13137.21965874566\n",
      "\n",
      "Epoch 0\n",
      "---------\n",
      "Train loss: 12969.214439256657\n",
      "Test loss: 12562.617933485242\n",
      "Epoch time: epoch_time = 6.650s\n",
      "Epoch 1\n",
      "---------\n",
      "Train loss: 12384.404747596154\n",
      "Test loss: 11998.84947374132\n",
      "Epoch time: epoch_time = 6.534s\n",
      "Epoch 2\n",
      "---------\n",
      "Train loss: 11849.525968472633\n",
      "Test loss: 11481.807427300348\n",
      "Epoch time: epoch_time = 6.631s\n",
      "Epoch 3\n",
      "---------\n",
      "Train loss: 11378.148633968196\n",
      "Test loss: 11038.979180230035\n",
      "Epoch time: epoch_time = 6.720s\n",
      "Epoch 4\n",
      "---------\n",
      "Train loss: 10953.792783838757\n",
      "Test loss: 10604.786499023438\n",
      "Epoch time: epoch_time = 6.735s\n",
      "Epoch 5\n",
      "---------\n",
      "Train loss: 10533.234652366864\n",
      "Test loss: 10221.70250108507\n",
      "Epoch time: epoch_time = 6.606s\n",
      "Epoch 6\n",
      "---------\n",
      "Train loss: 10171.76474089312\n",
      "Test loss: 9872.28369140625\n",
      "Epoch time: epoch_time = 6.669s\n",
      "Epoch 7\n",
      "---------\n",
      "Train loss: 9838.293899084689\n",
      "Test loss: 9538.961046006945\n",
      "Epoch time: epoch_time = 6.791s\n",
      "Epoch 8\n",
      "---------\n",
      "Train loss: 9531.50529308432\n",
      "Test loss: 9238.609130859375\n",
      "Epoch time: epoch_time = 6.724s\n",
      "Epoch 9\n",
      "---------\n",
      "Train loss: 9246.913036820451\n",
      "Test loss: 8967.356391059027\n",
      "Epoch time: epoch_time = 7.055s\n",
      "Epoch 10\n",
      "---------\n",
      "Train loss: 8983.106214173447\n",
      "Test loss: 8703.219787597656\n",
      "Epoch time: epoch_time = 6.830s\n",
      "Epoch 11\n",
      "---------\n",
      "Train loss: 8738.25099389793\n",
      "Test loss: 8465.320156521268\n",
      "Epoch time: epoch_time = 6.678s\n",
      "Epoch 12\n",
      "---------\n",
      "Train loss: 8511.950836723372\n",
      "Test loss: 8245.374905056424\n",
      "Epoch time: epoch_time = 6.765s\n",
      "Epoch 13\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "train_model(model=model, train_loader=train_loader, test_loader=val_loader, n_epochs=200)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}