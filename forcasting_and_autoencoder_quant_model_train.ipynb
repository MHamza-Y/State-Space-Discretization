{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from state_quantization.dataset import load_dataset\n",
    "from state_quantization.dataset import DynamicsModelDataset\n",
    "from state_quantization.forcasting_models import LSTMForcasting\n",
    "from state_quantization.quantization_models import DiscAutoEncoder\n",
    "from state_quantization.forcasting_quantization_models import ForcastingQuant, EmbeddedAEForcastingQuant, ForcastingQuantInferenceWrapper, SingleEmbeddedAEForcastingQuant\n",
    "from state_quantization.trainer import ForcastingQuantTrainer\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from state_quantization.train import train_model, test_step\n",
    "from state_quantization.eval import eval_model, compare_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "print(f\"Using Device: {device}\")\n",
    "torch.backends.cudnn.benchmark = True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clipping y\n",
      "torch.Size([672000, 39, 6])\n",
      "torch.Size([672000, 10, 2])\n",
      "torch.Size([288000, 39, 6])\n",
      "torch.Size([288000, 10, 2])\n",
      "{'batch_size': 8000, 'shuffle': True, 'num_workers': 0, 'drop_last': True, 'pin_memory': True}\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[ 0.2150, -0.3866],\n        [ 0.1820, -0.3868],\n        [-0.0793, -0.3695],\n        [-0.4569, -0.2246],\n        [-0.4772, -0.1375],\n        [-0.8559, -0.0775],\n        [-0.4930, -0.0668],\n        [-0.2192, -0.0804],\n        [-0.5532, -0.0335],\n        [-0.5682,  0.0518]])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_input_key = 'merged_input'\n",
    "dataset_output_key = 'merged_output'\n",
    "dataset_file_path = 'tmp/ib-out/ib-samples-la.npy'\n",
    "normalized_data_params_save_path = 'tmp/transformer/NormalizeInputConfigs.pkl'\n",
    "dataset_device = 'cpu'\n",
    "y_indexes = [4, 6]\n",
    "\n",
    "train_dataset, val_dataset = load_dataset(file_path=dataset_file_path, input_key=dataset_input_key,\n",
    "                                          output_key=dataset_output_key, dataset_class=DynamicsModelDataset,\n",
    "                                          normalize=True, device=dataset_device, y_clip_range=y_indexes,\n",
    "                                          normalized_input_data_params_save_path=normalized_data_params_save_path)\n",
    "\n",
    "batch_size = 8000\n",
    "params = {'batch_size': batch_size,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 0,\n",
    "          'drop_last': True,\n",
    "          'pin_memory': not train_dataset.x.is_cuda}\n",
    "print(params)\n",
    "train_loader = DataLoader(train_dataset, **params)\n",
    "val_loader = DataLoader(val_dataset, **params)\n",
    "train_dataset.y[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out Size:2\n",
      "LSTM Layers\n",
      "ModuleList(\n",
      "  (0): LSTMCell(6, 20)\n",
      ")\n",
      "LSTM Dropout Layers\n",
      "ModuleList()\n",
      "Fully Connected Layers\n",
      "Sequential(\n",
      "  (0): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (1): GELU(approximate=none)\n",
      "  (2): Dropout(p=0.1, inplace=False)\n",
      "  (3): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (4): GELU(approximate=none)\n",
      "  (5): Dropout(p=0.1, inplace=False)\n",
      "  (6): Linear(in_features=20, out_features=2, bias=True)\n",
      ")\n",
      "Encoder Layers\n",
      "Sequential(\n",
      "  (0): Linear(in_features=40, out_features=40, bias=True)\n",
      "  (1): GELU(approximate=none)\n",
      "  (2): Dropout(p=0, inplace=False)\n",
      "  (3): Linear(in_features=40, out_features=20, bias=True)\n",
      "  (4): GELU(approximate=none)\n",
      "  (5): Dropout(p=0, inplace=False)\n",
      "  (6): Linear(in_features=20, out_features=10, bias=True)\n",
      "  (7): GELU(approximate=none)\n",
      "  (8): Dropout(p=0, inplace=False)\n",
      ")\n",
      "Bottleneck Layers\n",
      "Sequential(\n",
      "  (0): Linear(in_features=10, out_features=20, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): StraightThroughEstimator()\n",
      ")\n",
      "Decoder Layers\n",
      "Sequential(\n",
      "  (0): Linear(in_features=20, out_features=10, bias=True)\n",
      "  (1): GELU(approximate=none)\n",
      "  (2): Dropout(p=0, inplace=False)\n",
      "  (3): Linear(in_features=10, out_features=20, bias=True)\n",
      "  (4): GELU(approximate=none)\n",
      "  (5): Dropout(p=0, inplace=False)\n",
      "  (6): Linear(in_features=20, out_features=40, bias=True)\n",
      "  (7): GELU(approximate=none)\n",
      "  (8): Dropout(p=0, inplace=False)\n",
      "  (9): Linear(in_features=40, out_features=40, bias=True)\n",
      ")\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "num_of_features = train_dataset.get_features_size()\n",
    "seq_len = train_dataset.get_seq_len()\n",
    "hidden_size = 20\n",
    "out_size = train_dataset.get_output_feature_size()\n",
    "print(f'Out Size:{out_size}')\n",
    "look_ahead = train_dataset.get_look_ahead_size()\n",
    "n_layers = 1\n",
    "dropout = 0.1\n",
    "\n",
    "forcasting_model = LSTMForcasting(features=num_of_features, hidden_size=hidden_size, out_size=out_size, seq_len=seq_len,\n",
    "                                  look_ahead=look_ahead, dropout=dropout, n_layers=n_layers)\n",
    "\n",
    "disc_autoencoder_input_size = hidden_size * 2\n",
    "bottleneck_size = 20\n",
    "ae_dropout = 0\n",
    "disc_autoencoder = DiscAutoEncoder(input_size=disc_autoencoder_input_size, bottleneck_size=bottleneck_size,\n",
    "                                   dropout=ae_dropout)\n",
    "model_path = f'tmp/state_quantization/model_aeq-{bottleneck_size}bits3'\n",
    "untrained_model_path = f'tmp/state_quantization/untrained_model_aeq-{bottleneck_size}bits'\n",
    "model = ForcastingQuant(forcasting_model=forcasting_model, autoencoder_quant_model=disc_autoencoder).to(device=device)\n",
    "eval_model = SingleEmbeddedAEForcastingQuant(model=model).to(device=device)\n",
    "torch.save(ForcastingQuantInferenceWrapper(model), untrained_model_path)\n",
    "load_to_gpu = model.is_cuda() and not train_dataset.x.is_cuda\n",
    "print(load_to_gpu)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Trainer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "gamma = 0.1\n",
    "\n",
    "forecasting_learning_rate = 1e-3\n",
    "autoencoder_learning_rate = 1e-3\n",
    "\n",
    "forecasting_lr_milestones = [35]\n",
    "autoencoder_lr_milestones = [100, 150]\n",
    "forecasting_optimizer = torch.optim.Adam(model.forcasting_model.parameters(),\n",
    "                                         lr=forecasting_learning_rate)\n",
    "autoencoder_optimizer = torch.optim.Adam(model.autoencoder_quant_model.parameters(),\n",
    "                                         lr=autoencoder_learning_rate)\n",
    "forecasting_lr_scheduler = MultiStepLR(forecasting_optimizer, milestones=forecasting_lr_milestones, gamma=gamma)\n",
    "autoencoder_lr_scheduler = MultiStepLR(autoencoder_optimizer, milestones=autoencoder_lr_milestones, gamma=gamma)\n",
    "n_epochs = 200\n",
    "\n",
    "trainer = ForcastingQuantTrainer(forcasting_quant_model=model, train_loader=train_loader, test_loader=val_loader,\n",
    "                                 load_to_gpu=load_to_gpu, forecasting_optimizer=forecasting_optimizer,\n",
    "                                 forecasting_lr_scheduler=forecasting_lr_scheduler,\n",
    "                                 autoencoder_lr_scheduler=autoencoder_lr_scheduler,\n",
    "                                 autoencoder_optimizer=autoencoder_optimizer,autoencoder_training_start=50,additional_eval_model=eval_model)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained test\n",
      "--------\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 1.023640751838684\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 1\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.7687051761008444\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.4156271517276764\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.792s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 2\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "Forcasting Train loss: 0.23456345800132977\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.09608472490476237\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.616s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 3\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.10938202492183163\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.06852507446375158\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.047s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 4\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.09194657135577429\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.0584231104908718\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.257s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 5\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.08129460417798587\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.049541502777073115\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.194s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 6\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.07352839640918232\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.04455053827000989\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.474s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 7\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.06840886432854902\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.0407126886356208\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.274s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 8\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.06511193487261023\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03884196488393678\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.196s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 9\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.0627545008347148\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03780964120394654\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.287s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 10\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.06116923898281086\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03688637436264091\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.349s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 11\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05977095246669792\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03633652254939079\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.050s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 12\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.058676382571104024\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03575532241827912\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.061s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 13\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05749046993220136\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.035062183108594686\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.331s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 14\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05654740816957894\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03409185871067974\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.018s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 15\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.055558878041449045\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.033494777149624295\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.218s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 16\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.054955538894448965\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03282234062337213\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.314s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 17\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.054146302420468556\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03241404239088297\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.209s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 18\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05355630761810711\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03175248293620017\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.263s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 19\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05283269321634656\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03198816068470478\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.005s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 20\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05237425974614564\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03142873358188404\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.161s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 21\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.051959711215680555\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03096345527511504\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.176s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 22\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.051626697714839666\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03069578530266881\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.208s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 23\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05117876517275969\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03059678716171119\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.049s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 24\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05084884344112305\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.030129698829518423\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.119s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 25\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.050536729262343476\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.030159984042661056\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.084s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 26\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.050236656153131096\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02983204782423046\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.181s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 27\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04999892533357654\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02971580634928412\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.153s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 28\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04971063208012354\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.030021948998586998\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.190s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 29\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.049534651628207596\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.029643126246001985\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.214s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 30\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04929876260991607\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02944366918462846\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.170s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 31\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04895362297871283\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02933028019550774\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.159s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 32\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.048806119355417434\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.029285048134624958\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.667s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 33\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04864196798631123\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02952696703788307\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.237s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 34\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04832756359662328\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02921733596465654\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.290s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 35\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04820056787381569\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028789803696175415\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.111s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 36\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04790871652464072\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028746351910134155\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.105s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 37\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04786247644750845\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028743149143540196\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.169s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 38\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04788928980096465\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028795340719322365\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.252s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 39\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04784414677747658\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028729212004691362\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.242s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 40\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04782447320896955\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028739298797316022\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.477s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 41\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.047806826331430956\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028655153543998797\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.215s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 42\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04777492290096624\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02869558096345928\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.576s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 43\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04777699522674084\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02870840108436015\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.272s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 44\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04783871268764848\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028700145323657326\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.746s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 45\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04768488400926193\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028637362385375634\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.112s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 46\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04766858369112015\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028734137045426503\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.207s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 47\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04766395080479838\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02871145395975974\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.294s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 48\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.047645559623127894\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028687678846634097\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.104s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 49\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.047624612271430944\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028738233571251232\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.142s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 50\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04761924594640732\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028691779718630843\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.611s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 51\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.2740397637798673\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.12497450452711847\n",
      "Eval Model Test loss: 0.3986181757516331\n",
      "First Out Loss: 0.02722652308228943\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.398s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 52\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.06883560076710724\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.05531128216534853\n",
      "Eval Model Test loss: 0.358819300101863\n",
      "First Out Loss: 0.02722652272010843\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.307s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 53\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.04683660906517789\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.03391665251304706\n",
      "Eval Model Test loss: 0.21098443948560291\n",
      "First Out Loss: 0.027226523185769718\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.359s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 54\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0276392905396365\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.02505126078095701\n",
      "Eval Model Test loss: 0.16419990774657992\n",
      "First Out Loss: 0.027226523185769718\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.332s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 55\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.02368622738867998\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.022711516461438604\n",
      "Eval Model Test loss: 0.1420838214043114\n",
      "First Out Loss: 0.027226523030549288\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.347s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 56\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.021181642676570585\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.019987666255070105\n",
      "Eval Model Test loss: 0.11520964383251137\n",
      "First Out Loss: 0.02722652308228943\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.399s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 57\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0185024178187762\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.01744566397327516\n",
      "Eval Model Test loss: 0.0805097408592701\n",
      "First Out Loss: 0.027226523030549288\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.402s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 58\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.01658241800032556\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.015833581642558176\n",
      "Eval Model Test loss: 0.07398863488601314\n",
      "First Out Loss: 0.027226522927069\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.566s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 59\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.015207092998371948\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.014778147865500715\n",
      "Eval Model Test loss: 0.0700313655866517\n",
      "First Out Loss: 0.027226522823588714\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.490s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 60\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.014332412897298733\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.014044085905576745\n",
      "Eval Model Test loss: 0.0673186197463009\n",
      "First Out Loss: 0.027226522927069\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.338s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 61\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.01374651177874988\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.013579498821248611\n",
      "Eval Model Test loss: 0.06284072395000193\n",
      "First Out Loss: 0.02722652308228943\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.625s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 62\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.013338661819164242\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.01316042999840445\n",
      "Eval Model Test loss: 0.06012030225247145\n",
      "First Out Loss: 0.027226522978809144\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.358s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 63\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.013049303675957379\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.012962855010603866\n",
      "Eval Model Test loss: 0.05928146207912101\n",
      "First Out Loss: 0.027226522927069\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.333s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 64\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.012798485268528262\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.01260376589683195\n",
      "Eval Model Test loss: 0.05937290108866162\n",
      "First Out Loss: 0.02722652272010843\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.711s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 65\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.01229439047165215\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.012183586264856987\n",
      "Eval Model Test loss: 0.05800628341320488\n",
      "First Out Loss: 0.027226522927069\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 7.925s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 66\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.012036420482521256\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.011946581304073334\n",
      "Eval Model Test loss: 0.058985891131063305\n",
      "First Out Loss: 0.027226522875328858\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 7.939s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 67\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.011806666773433486\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.011600536113190982\n",
      "Eval Model Test loss: 0.05833910053802861\n",
      "First Out Loss: 0.027226523185769718\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.023s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 68\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.011361521613296299\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.011191774133799804\n",
      "Eval Model Test loss: 0.05851096763379044\n",
      "First Out Loss: 0.027226523030549288\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.065s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 69\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.011004108835809998\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.010892860151620375\n",
      "Eval Model Test loss: 0.05761726893898514\n",
      "First Out Loss: 0.02722652323750986\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.499s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 70\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.010711813290115623\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.01054071867838502\n",
      "Eval Model Test loss: 0.05568210956537061\n",
      "First Out Loss: 0.027226523340990145\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.336s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 71\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.010369554494640656\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.010237597110163834\n",
      "Eval Model Test loss: 0.05502553998182217\n",
      "First Out Loss: 0.02722652308228943\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.219s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 72\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.010087965732617747\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.010002165075598491\n",
      "Eval Model Test loss: 0.05420107963598437\n",
      "First Out Loss: 0.027226522875328858\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.332s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 73\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009896196291915007\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009863845615958175\n",
      "Eval Model Test loss: 0.05316572243140803\n",
      "First Out Loss: 0.027226522927069\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.309s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 74\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00977977672370062\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009792428877618577\n",
      "Eval Model Test loss: 0.05373580060485336\n",
      "First Out Loss: 0.027226522978809144\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.350s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 75\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009798768686041945\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009774262809918987\n",
      "Eval Model Test loss: 0.0536929193056292\n",
      "First Out Loss: 0.02722652308228943\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.183s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 76\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009641825387786542\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00956969752183391\n",
      "Eval Model Test loss: 0.05287472510503398\n",
      "First Out Loss: 0.02722652308228943\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.332s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 77\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009454733924940228\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009414615290653374\n",
      "Eval Model Test loss: 0.05280703647683064\n",
      "First Out Loss: 0.027226523030549288\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.348s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 78\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009294201364918124\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009225592974366413\n",
      "Eval Model Test loss: 0.051866617571148604\n",
      "First Out Loss: 0.027226522927069\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.309s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 79\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009074620292743757\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00899672539283832\n",
      "Eval Model Test loss: 0.05084931653820806\n",
      "First Out Loss: 0.027226523030549288\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.252s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 80\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008830498571374587\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008727518919234475\n",
      "Eval Model Test loss: 0.050504730807410345\n",
      "First Out Loss: 0.027226522978809144\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.329s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 81\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008633292213614498\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008606109199010663\n",
      "Eval Model Test loss: 0.05040823399192757\n",
      "First Out Loss: 0.027226523340990145\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.350s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 82\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008494587382301688\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008412370251284705\n",
      "Eval Model Test loss: 0.0493373813935452\n",
      "First Out Loss: 0.027226523134029575\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.384s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 83\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008295116713270545\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00822055572643876\n",
      "Eval Model Test loss: 0.04900247645046976\n",
      "First Out Loss: 0.027226523134029575\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.288s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 84\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008137637427786277\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008122193678799603\n",
      "Eval Model Test loss: 0.0492861434403393\n",
      "First Out Loss: 0.027226522978809144\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.338s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 85\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.007970119238875452\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.007902949285279546\n",
      "Eval Model Test loss: 0.0489708422165778\n",
      "First Out Loss: 0.02722652323750986\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.370s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 86\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.007764238914075706\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.007638431813878317\n",
      "Eval Model Test loss: 0.04893537134759956\n",
      "First Out Loss: 0.027226523134029575\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.279s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 87\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.007511780419874759\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.007395737261200945\n",
      "Eval Model Test loss: 0.04850964258528418\n",
      "First Out Loss: 0.027226522978809144\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.275s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 88\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.007267203281766602\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.007177767990570929\n",
      "Eval Model Test loss: 0.04862137345804109\n",
      "First Out Loss: 0.027226522875328858\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.198s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 89\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0070741492146182625\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00702174116546909\n",
      "Eval Model Test loss: 0.04855692893680599\n",
      "First Out Loss: 0.02722652328925\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.275s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 90\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006955911455276821\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006998601447169979\n",
      "Eval Model Test loss: 0.048878740001883775\n",
      "First Out Loss: 0.027226523340990145\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.414s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 91\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006907852399828178\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006941006829341252\n",
      "Eval Model Test loss: 0.04872349121918281\n",
      "First Out Loss: 0.027226522875328858\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.199s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 92\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006862202936428643\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006818689845709337\n",
      "Eval Model Test loss: 0.049255292759173445\n",
      "First Out Loss: 0.027226522875328858\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.275s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 93\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0067995612764553655\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006729951218908859\n",
      "Eval Model Test loss: 0.0489705933464898\n",
      "First Out Loss: 0.027226523134029575\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.398s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 94\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006662564329980384\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006606022296990786\n",
      "Eval Model Test loss: 0.04847206506464216\n",
      "First Out Loss: 0.027226523030549288\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.373s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 95\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0065614953304507905\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006567191746499803\n",
      "Eval Model Test loss: 0.04866070196860366\n",
      "First Out Loss: 0.02722652308228943\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.154s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 96\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006519705461825998\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006509239216231638\n",
      "Eval Model Test loss: 0.04834243644856744\n",
      "First Out Loss: 0.027226523134029575\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.332s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 97\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006486902989092327\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006453693378716707\n",
      "Eval Model Test loss: 0.04863271945052677\n",
      "First Out Loss: 0.027226522927069\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.334s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 98\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006445826358339261\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006461640535336401\n",
      "Eval Model Test loss: 0.0485167775510086\n",
      "First Out Loss: 0.02722652323750986\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.753s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 99\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006396975745225237\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00639374578733825\n",
      "Eval Model Test loss: 0.04833872647335132\n",
      "First Out Loss: 0.027226522875328858\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 7.946s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 100\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006327122483136398\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006325977725080318\n",
      "Eval Model Test loss: 0.04828304321401649\n",
      "First Out Loss: 0.02722652323750986\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.282s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 101\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00625366826231281\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0062828406743291355\n",
      "Eval Model Test loss: 0.04832733308689462\n",
      "First Out Loss: 0.027226522978809144\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.126s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 102\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006241413032902139\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006270786630921066\n",
      "Eval Model Test loss: 0.04835277899271912\n",
      "First Out Loss: 0.027226522823588714\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.112s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 103\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006231724667096776\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006268644149208235\n",
      "Eval Model Test loss: 0.04834690420991845\n",
      "First Out Loss: 0.027226522978809144\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.021s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 104\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006222979171157238\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006258998881094158\n",
      "Eval Model Test loss: 0.04828029695070452\n",
      "First Out Loss: 0.027226522823588714\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.008s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 105\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006211632518984732\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006246975519590908\n",
      "Eval Model Test loss: 0.04830105499260955\n",
      "First Out Loss: 0.027226522875328858\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.800s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 106\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006202461247864578\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006231837711917858\n",
      "Eval Model Test loss: 0.04823123001390033\n",
      "First Out Loss: 0.027226523030549288\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.459s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 107\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006196259471055653\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006219565467391577\n",
      "Eval Model Test loss: 0.048159775531126395\n",
      "First Out Loss: 0.027226522978809144\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.628s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 108\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006183629761272598\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006216755227392746\n",
      "Eval Model Test loss: 0.048251280871530376\n",
      "First Out Loss: 0.027226522978809144\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.760s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 109\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006178137857378239\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006200863113109436\n",
      "Eval Model Test loss: 0.04807581597318252\n",
      "First Out Loss: 0.027226523134029575\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.700s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 110\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006162915112716811\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006193035217519436\n",
      "Eval Model Test loss: 0.0480657366828786\n",
      "First Out Loss: 0.02722652308228943\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.690s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 111\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006153486791022476\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006178738549351692\n",
      "Eval Model Test loss: 0.04808137358890639\n",
      "First Out Loss: 0.027226522875328858\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.763s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 112\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006147741561844235\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006175318784597848\n",
      "Eval Model Test loss: 0.04794760120825635\n",
      "First Out Loss: 0.027226522978809144\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 9.200s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 113\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006133193881916148\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006170547463827663\n",
      "Eval Model Test loss: 0.0479540280583832\n",
      "First Out Loss: 0.02722652328925\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.407s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 114\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006124751470495193\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006162113225501444\n",
      "Eval Model Test loss: 0.04791570589360264\n",
      "First Out Loss: 0.027226523185769718\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.366s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 115\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006117294974891203\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0061503746546804905\n",
      "Eval Model Test loss: 0.047929976859854326\n",
      "First Out Loss: 0.02722652308228943\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.189s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 116\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006105096977470177\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00615069377494769\n",
      "Eval Model Test loss: 0.047868388497995004\n",
      "First Out Loss: 0.027226523134029575\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.141s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 117\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006099728728821944\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006133202890244623\n",
      "Eval Model Test loss: 0.0478077901320325\n",
      "First Out Loss: 0.027226523185769718\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.925s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 118\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006088932831993415\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006126092022491826\n",
      "Eval Model Test loss: 0.04778735370685657\n",
      "First Out Loss: 0.027226522978809144\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.858s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 119\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006081251189157012\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006117656477726996\n",
      "Eval Model Test loss: 0.04768870222485728\n",
      "First Out Loss: 0.027226523185769718\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.770s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 120\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006070337934596907\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006106614859567748\n",
      "Eval Model Test loss: 0.04774344184746345\n",
      "First Out Loss: 0.02722652308228943\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.054s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 121\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006066333862864191\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006097377782377104\n",
      "Eval Model Test loss: 0.04768469888303015\n",
      "First Out Loss: 0.02722652308228943\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.345s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 122\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006054329331077281\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00609328147644798\n",
      "Eval Model Test loss: 0.04773989371541473\n",
      "First Out Loss: 0.027226522927069\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.844s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 123\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006048838940582105\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00607606705226418\n",
      "Eval Model Test loss: 0.047654235218134194\n",
      "First Out Loss: 0.027226522927069\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.674s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 124\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006036087865054253\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006076370081346896\n",
      "Eval Model Test loss: 0.047687453838686146\n",
      "First Out Loss: 0.027226522978809144\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.807s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 125\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006030043204581099\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0060636904478694005\n",
      "Eval Model Test loss: 0.04760332012342082\n",
      "First Out Loss: 0.02722652308228943\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.827s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 126\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00602264666286785\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006058005422043304\n",
      "Eval Model Test loss: 0.04762790321062008\n",
      "First Out Loss: 0.02722652308228943\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.848s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 127\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006013165111653507\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0060432041840006905\n",
      "Eval Model Test loss: 0.04767948016524315\n",
      "First Out Loss: 0.02722652323750986\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.933s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 128\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00600299516337968\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006040433382925888\n",
      "Eval Model Test loss: 0.04766417636225621\n",
      "First Out Loss: 0.027226522978809144\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.974s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 129\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005997009708413056\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006036381767545309\n",
      "Eval Model Test loss: 0.04764829400098986\n",
      "First Out Loss: 0.027226523030549288\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.111s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 130\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005990615724364207\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0060263337153527476\n",
      "Eval Model Test loss: 0.047735327751272254\n",
      "First Out Loss: 0.027226522978809144\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.358s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 131\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005982793662475333\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006017173718040188\n",
      "Eval Model Test loss: 0.04772247187793255\n",
      "First Out Loss: 0.027226522875328858\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.268s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 132\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0059711493418685025\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006005625046479206\n",
      "Eval Model Test loss: 0.047691270605557494\n",
      "First Out Loss: 0.027226523030549288\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.011s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 133\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0059651397944738465\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00599875302416169\n",
      "Eval Model Test loss: 0.047721911428703204\n",
      "First Out Loss: 0.02722652308228943\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.780s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 134\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0059550461148665775\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005990159128689104\n",
      "Eval Model Test loss: 0.04767612523088852\n",
      "First Out Loss: 0.027226522875328858\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.952s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 135\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005950367438518221\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005986218172539439\n",
      "Eval Model Test loss: 0.047666364763345986\n",
      "First Out Loss: 0.02722652272010843\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.113s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 136\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005939958450783577\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005965653211913175\n",
      "Eval Model Test loss: 0.0475708766736918\n",
      "First Out Loss: 0.027226522823588714\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.313s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 137\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005930542313892927\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005962579161860049\n",
      "Eval Model Test loss: 0.047618933125502534\n",
      "First Out Loss: 0.027226523134029575\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.802s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 138\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005923112083802975\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005955163842170603\n",
      "Eval Model Test loss: 0.047543983078665204\n",
      "First Out Loss: 0.027226522823588714\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.831s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 139\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00591631263073179\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005953775188471708\n",
      "Eval Model Test loss: 0.0475669771225916\n",
      "First Out Loss: 0.02722652328925\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.682s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 140\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00591390693582417\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005941435617084305\n",
      "Eval Model Test loss: 0.04747360603262981\n",
      "First Out Loss: 0.02722652328925\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.797s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 141\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005905186103302098\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005933376197289262\n",
      "Eval Model Test loss: 0.04728080332279205\n",
      "First Out Loss: 0.027226522875328858\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.864s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 142\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0059004745701150526\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005924737404307557\n",
      "Eval Model Test loss: 0.04731134604662657\n",
      "First Out Loss: 0.027226523030549288\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.764s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 143\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005895709552403007\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005922751009671224\n",
      "Eval Model Test loss: 0.047230240061051317\n",
      "First Out Loss: 0.027226522875328858\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.627s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 144\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005892945919185877\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005918549373745918\n",
      "Eval Model Test loss: 0.0471419095993042\n",
      "First Out Loss: 0.027226522875328858\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.871s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 145\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005892821194027506\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005924666649661958\n",
      "Eval Model Test loss: 0.04712714461816682\n",
      "First Out Loss: 0.027226522771848574\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.254s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 146\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005898443804610343\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005934374523349106\n",
      "Eval Model Test loss: 0.04705312806699011\n",
      "First Out Loss: 0.027226522978809144\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.386s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 147\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005901889215844373\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005934756805395914\n",
      "Eval Model Test loss: 0.04705431364062759\n",
      "First Out Loss: 0.027226523185769718\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.281s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 148\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005898636976434361\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005939565598964691\n",
      "Eval Model Test loss: 0.04708976702143749\n",
      "First Out Loss: 0.027226523030549288\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.520s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 149\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005893275757054133\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005917703616432846\n",
      "Eval Model Test loss: 0.04689266470571359\n",
      "First Out Loss: 0.027226522978809144\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.270s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 150\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005888030659185634\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005921565086787773\n",
      "Eval Model Test loss: 0.04691026618497239\n",
      "First Out Loss: 0.027226522875328858\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.321s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 151\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005878999984512727\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005918861405613522\n",
      "Eval Model Test loss: 0.04690172430127859\n",
      "First Out Loss: 0.027226522978809144\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.153s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 152\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0058784453708323695\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005915574910533097\n",
      "Eval Model Test loss: 0.0468765486859613\n",
      "First Out Loss: 0.027226522978809144\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.284s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 153\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005878115959820293\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005915155608413948\n",
      "Eval Model Test loss: 0.04686973326736026\n",
      "First Out Loss: 0.027226522978809144\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.262s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 154\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00587746537002247\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005913594530688392\n",
      "Eval Model Test loss: 0.04688159697171715\n",
      "First Out Loss: 0.027226523134029575\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.289s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 155\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00587599150215586\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005912710692630046\n",
      "Eval Model Test loss: 0.04689004044565889\n",
      "First Out Loss: 0.02722652323750986\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 7.757s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 156\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005874680632370568\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005911189752320449\n",
      "Eval Model Test loss: 0.04686413684652911\n",
      "First Out Loss: 0.027226523134029575\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.005s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 157\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005872846924744192\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005911938212294545\n",
      "Eval Model Test loss: 0.0468390512590607\n",
      "First Out Loss: 0.02722652308228943\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.123s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 158\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005873555433936417\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005912234670379096\n",
      "Eval Model Test loss: 0.046823419630527496\n",
      "First Out Loss: 0.02722652308228943\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 7.912s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 159\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005874712158748437\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0059124866707457435\n",
      "Eval Model Test loss: 0.04684321623709467\n",
      "First Out Loss: 0.02722652328925\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 7.758s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 160\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005873163585506734\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005913541419431567\n",
      "Eval Model Test loss: 0.04687674240105682\n",
      "First Out Loss: 0.027226522875328858\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 7.871s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 161\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005871998573032518\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0059088208169365926\n",
      "Eval Model Test loss: 0.04685373935434553\n",
      "First Out Loss: 0.027226522771848574\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 7.869s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 162\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0058718934998891895\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00590878785846548\n",
      "Eval Model Test loss: 0.04681104990757174\n",
      "First Out Loss: 0.027226523185769718\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.014s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 163\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005870997440069914\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0059085900817687316\n",
      "Eval Model Test loss: 0.0468291909330421\n",
      "First Out Loss: 0.027226523030549288\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.480s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 164\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005869239302618163\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005906608292005128\n",
      "Eval Model Test loss: 0.04681607004668978\n",
      "First Out Loss: 0.02722652308228943\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.178s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 165\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0058707081258208265\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005907126818783581\n",
      "Eval Model Test loss: 0.04681415928320752\n",
      "First Out Loss: 0.027226523134029575\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.615s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 166\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0058677758400638895\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0059084377587876385\n",
      "Eval Model Test loss: 0.04684599375145303\n",
      "First Out Loss: 0.027226523340990145\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.392s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 167\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0058694323524832726\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005902844882156286\n",
      "Eval Model Test loss: 0.04677282108200921\n",
      "First Out Loss: 0.027226523134029575\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.223s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 168\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005867812887854164\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005903052838726176\n",
      "Eval Model Test loss: 0.04681058031403356\n",
      "First Out Loss: 0.027226522823588714\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.364s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 169\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00586710809840865\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005901009206556612\n",
      "Eval Model Test loss: 0.04678183742281464\n",
      "First Out Loss: 0.027226522927069\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.357s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 170\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005867482539975927\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0059048490365967155\n",
      "Eval Model Test loss: 0.04680711175832483\n",
      "First Out Loss: 0.027226522978809144\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.308s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 171\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005866899471064764\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005902865384187963\n",
      "Eval Model Test loss: 0.04679034557193518\n",
      "First Out Loss: 0.027226523030549288\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.379s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 172\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005867329925032598\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0059022616284588976\n",
      "Eval Model Test loss: 0.0468000935183631\n",
      "First Out Loss: 0.027226522771848574\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.350s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 173\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005865296193708976\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005902650572049121\n",
      "Eval Model Test loss: 0.046763336596389614\n",
      "First Out Loss: 0.027226523134029575\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.449s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 174\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005863629813705172\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005901542725041509\n",
      "Eval Model Test loss: 0.046791325530244246\n",
      "First Out Loss: 0.02722652323750986\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.331s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 175\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005861999877240686\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005899593285802338\n",
      "Eval Model Test loss: 0.04677986063890987\n",
      "First Out Loss: 0.02722652328925\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.341s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 176\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005861587767001419\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005895251149518622\n",
      "Eval Model Test loss: 0.04671510567681657\n",
      "First Out Loss: 0.027226522978809144\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.516s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 177\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005860968420858539\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005895698533600403\n",
      "Eval Model Test loss: 0.04668327058768935\n",
      "First Out Loss: 0.02722652323750986\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.523s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 178\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005859058671852662\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005895622876576251\n",
      "Eval Model Test loss: 0.04672194210191568\n",
      "First Out Loss: 0.027226522823588714\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.408s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 179\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005858004470134065\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005897111026570201\n",
      "Eval Model Test loss: 0.04670318143649234\n",
      "First Out Loss: 0.027226523030549288\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.363s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 180\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0058548366318323785\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005892473725705511\n",
      "Eval Model Test loss: 0.046655839723017484\n",
      "First Out Loss: 0.027226523134029575\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.368s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 181\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005857153357716189\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005891695644499527\n",
      "Eval Model Test loss: 0.046708626879586115\n",
      "First Out Loss: 0.027226523030549288\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.381s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 182\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005855921772308648\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005886597675271332\n",
      "Eval Model Test loss: 0.04666243917826149\n",
      "First Out Loss: 0.027226522875328858\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.362s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 183\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005852231229211958\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005889333952735696\n",
      "Eval Model Test loss: 0.04667493018011252\n",
      "First Out Loss: 0.02722652308228943\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.364s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 184\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005851192211377479\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0058910891724129515\n",
      "Eval Model Test loss: 0.04668102040886879\n",
      "First Out Loss: 0.027226522978809144\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.436s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 185\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005850612019587841\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005886234886323412\n",
      "Eval Model Test loss: 0.04664633464482096\n",
      "First Out Loss: 0.027226523030549288\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.370s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 186\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005848685606560182\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005887418881886535\n",
      "Eval Model Test loss: 0.0466440651151869\n",
      "First Out Loss: 0.027226522875328858\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.430s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 187\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005847685643294383\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005883946523277296\n",
      "Eval Model Test loss: 0.0466644638735387\n",
      "First Out Loss: 0.027226522927069\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.270s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 188\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005845104488322423\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005885370787129634\n",
      "Eval Model Test loss: 0.04663368004063765\n",
      "First Out Loss: 0.027226523030549288\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.368s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 189\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005843278109317734\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005886009040599068\n",
      "Eval Model Test loss: 0.04665554708076848\n",
      "First Out Loss: 0.02722652308228943\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.364s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 190\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005842323991514388\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005880815804832512\n",
      "Eval Model Test loss: 0.0466487186236514\n",
      "First Out Loss: 0.027226522823588714\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.249s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 191\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0058405480369748105\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005881396484457784\n",
      "Eval Model Test loss: 0.04660975788202551\n",
      "First Out Loss: 0.027226522771848574\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.239s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 192\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005840237668183233\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005881084866511325\n",
      "Eval Model Test loss: 0.046616615313622684\n",
      "First Out Loss: 0.027226523134029575\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.446s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 193\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005838432116433978\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00587971606809232\n",
      "Eval Model Test loss: 0.04659799269090096\n",
      "First Out Loss: 0.027226523185769718\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.529s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 194\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0058382405799680525\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005875541505196856\n",
      "Eval Model Test loss: 0.046585980906254716\n",
      "First Out Loss: 0.027226523185769718\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.454s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 195\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0058369622454934175\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005875835428014398\n",
      "Eval Model Test loss: 0.04655753065728479\n",
      "First Out Loss: 0.027226523134029575\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.195s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 196\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005834875162690878\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0058770671150543624\n",
      "Eval Model Test loss: 0.046550785191357136\n",
      "First Out Loss: 0.027226523134029575\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.302s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 197\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005834135249079693\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005877783910060923\n",
      "Eval Model Test loss: 0.04658643373598655\n",
      "First Out Loss: 0.027226522927069\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.419s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 198\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005834718434406179\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005875418712902401\n",
      "Eval Model Test loss: 0.046576350202990904\n",
      "First Out Loss: 0.027226523134029575\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.653s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 199\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005831813844408663\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005876086160747541\n",
      "Eval Model Test loss: 0.04654005873534414\n",
      "First Out Loss: 0.027226523134029575\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.227s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 200\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005830299674666354\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005872827708824641\n",
      "Eval Model Test loss: 0.04650474701904588\n",
      "First Out Loss: 0.027226522927069\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.434s\n"
     ]
    }
   ],
   "source": [
    "trainer.train(n_epochs=n_epochs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "model = ForcastingQuantInferenceWrapper(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "torch.save(model, model_path)\n",
    "torch.cuda.empty_cache()\n",
    "del model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
