{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from state_quantization.dataset import load_dataset\n",
    "from state_quantization.dataset import DynamicsModelDataset\n",
    "from state_quantization.forcasting_models import LSTMForcasting\n",
    "from state_quantization.quantization_models import DiscAutoEncoder\n",
    "from state_quantization.forcasting_quantization_models import ForcastingQuant, EmbeddedAEForcastingQuant, ForcastingQuantInferenceWrapper, SingleEmbeddedAEForcastingQuant\n",
    "from state_quantization.trainer import ForcastingQuantTrainer\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from state_quantization.train import train_model, test_step\n",
    "from state_quantization.eval import eval_model, compare_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "print(f\"Using Device: {device}\")\n",
    "torch.backends.cudnn.benchmark = True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clipping y\n",
      "torch.Size([672000, 39, 6])\n",
      "torch.Size([672000, 10, 2])\n",
      "torch.Size([288000, 39, 6])\n",
      "torch.Size([288000, 10, 2])\n",
      "{'batch_size': 8000, 'shuffle': True, 'num_workers': 0, 'drop_last': True, 'pin_memory': True}\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[-1.0263, -0.0265],\n        [-1.0465, -0.0419],\n        [-1.0465,  0.0147],\n        [-1.0458,  0.1024],\n        [-1.0641,  0.1233],\n        [-1.0486,  0.0972],\n        [-1.0233,  0.1366],\n        [-1.0334,  0.1457],\n        [-1.0456,  0.2331],\n        [-1.0439,  0.2696]])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_input_key = 'merged_input'\n",
    "dataset_output_key = 'merged_output'\n",
    "dataset_file_path = 'tmp/ib-out/ib-samples-la.npy'\n",
    "normalized_data_params_save_path = 'tmp/transformer/NormalizeInputConfigs.pkl'\n",
    "dataset_device = 'cpu'\n",
    "y_indexes = [4, 6]\n",
    "\n",
    "train_dataset, val_dataset = load_dataset(file_path=dataset_file_path, input_key=dataset_input_key,\n",
    "                                          output_key=dataset_output_key, dataset_class=DynamicsModelDataset,\n",
    "                                          normalize=True, device=dataset_device, y_clip_range=y_indexes,\n",
    "                                          normalized_input_data_params_save_path=normalized_data_params_save_path)\n",
    "\n",
    "batch_size = 8000\n",
    "params = {'batch_size': batch_size,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 0,\n",
    "          'drop_last': True,\n",
    "          'pin_memory': not train_dataset.x.is_cuda}\n",
    "print(params)\n",
    "train_loader = DataLoader(train_dataset, **params)\n",
    "val_loader = DataLoader(val_dataset, **params)\n",
    "train_dataset.y[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out Size:2\n",
      "LSTM Layers\n",
      "ModuleList(\n",
      "  (0): LSTMCell(6, 20)\n",
      ")\n",
      "LSTM Dropout Layers\n",
      "ModuleList()\n",
      "Fully Connected Layers\n",
      "Sequential(\n",
      "  (0): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (1): GELU(approximate=none)\n",
      "  (2): Dropout(p=0.1, inplace=False)\n",
      "  (3): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (4): GELU(approximate=none)\n",
      "  (5): Dropout(p=0.1, inplace=False)\n",
      "  (6): Linear(in_features=20, out_features=2, bias=True)\n",
      ")\n",
      "Encoder Layers\n",
      "Sequential(\n",
      "  (0): Linear(in_features=40, out_features=40, bias=True)\n",
      "  (1): GELU(approximate=none)\n",
      "  (2): Dropout(p=0, inplace=False)\n",
      "  (3): Linear(in_features=40, out_features=20, bias=True)\n",
      "  (4): GELU(approximate=none)\n",
      "  (5): Dropout(p=0, inplace=False)\n",
      "  (6): Linear(in_features=20, out_features=10, bias=True)\n",
      "  (7): GELU(approximate=none)\n",
      "  (8): Dropout(p=0, inplace=False)\n",
      ")\n",
      "Bottleneck Layers\n",
      "Sequential(\n",
      "  (0): Linear(in_features=10, out_features=20, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): StraightThroughEstimator()\n",
      ")\n",
      "Decoder Layers\n",
      "Sequential(\n",
      "  (0): Linear(in_features=20, out_features=10, bias=True)\n",
      "  (1): GELU(approximate=none)\n",
      "  (2): Dropout(p=0, inplace=False)\n",
      "  (3): Linear(in_features=10, out_features=20, bias=True)\n",
      "  (4): GELU(approximate=none)\n",
      "  (5): Dropout(p=0, inplace=False)\n",
      "  (6): Linear(in_features=20, out_features=40, bias=True)\n",
      "  (7): GELU(approximate=none)\n",
      "  (8): Dropout(p=0, inplace=False)\n",
      "  (9): Linear(in_features=40, out_features=40, bias=True)\n",
      ")\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "num_of_features = train_dataset.get_features_size()\n",
    "seq_len = train_dataset.get_seq_len()\n",
    "hidden_size = 20\n",
    "out_size = train_dataset.get_output_feature_size()\n",
    "print(f'Out Size:{out_size}')\n",
    "look_ahead = train_dataset.get_look_ahead_size()\n",
    "n_layers = 1\n",
    "dropout = 0.1\n",
    "\n",
    "forcasting_model = LSTMForcasting(features=num_of_features, hidden_size=hidden_size, out_size=out_size, seq_len=seq_len,\n",
    "                                  look_ahead=look_ahead, dropout=dropout, n_layers=n_layers)\n",
    "\n",
    "disc_autoencoder_input_size = hidden_size * 2\n",
    "bottleneck_size = 20\n",
    "ae_dropout = 0\n",
    "disc_autoencoder = DiscAutoEncoder(input_size=disc_autoencoder_input_size, bottleneck_size=bottleneck_size,\n",
    "                                   dropout=ae_dropout)\n",
    "model_path = f'tmp/state_quantization/model_aeq-{bottleneck_size}bits2'\n",
    "untrained_model_path = f'tmp/state_quantization/untrained_model_aeq-{bottleneck_size}bits'\n",
    "model = ForcastingQuant(forcasting_model=forcasting_model, autoencoder_quant_model=disc_autoencoder).to(device=device)\n",
    "eval_model = SingleEmbeddedAEForcastingQuant(model=model).to(device=device)\n",
    "torch.save(ForcastingQuantInferenceWrapper(model), untrained_model_path)\n",
    "load_to_gpu = model.is_cuda() and not train_dataset.x.is_cuda\n",
    "print(load_to_gpu)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Trainer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "gamma = 0.1\n",
    "\n",
    "forecasting_learning_rate = 1e-3\n",
    "autoencoder_learning_rate = 1e-3\n",
    "\n",
    "forecasting_lr_milestones = [35]\n",
    "autoencoder_lr_milestones = [100, 150]\n",
    "forecasting_optimizer = torch.optim.Adam(model.forcasting_model.parameters(),\n",
    "                                         lr=forecasting_learning_rate)\n",
    "autoencoder_optimizer = torch.optim.Adam(model.autoencoder_quant_model.parameters(),\n",
    "                                         lr=autoencoder_learning_rate)\n",
    "forecasting_lr_scheduler = MultiStepLR(forecasting_optimizer, milestones=forecasting_lr_milestones, gamma=gamma)\n",
    "autoencoder_lr_scheduler = MultiStepLR(autoencoder_optimizer, milestones=autoencoder_lr_milestones, gamma=gamma)\n",
    "n_epochs = 200\n",
    "\n",
    "trainer = ForcastingQuantTrainer(forcasting_quant_model=model, train_loader=train_loader, test_loader=val_loader,\n",
    "                                 load_to_gpu=load_to_gpu, forecasting_optimizer=forecasting_optimizer,\n",
    "                                 forecasting_lr_scheduler=forecasting_lr_scheduler,\n",
    "                                 autoencoder_lr_scheduler=autoencoder_lr_scheduler,\n",
    "                                 autoencoder_optimizer=autoencoder_optimizer,autoencoder_training_start=50,additional_eval_model=eval_model)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained test\n",
      "--------\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 1.0200355052947998\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 1\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.7431840563104266\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.2598678804934025\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.928s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 2\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "Forcasting Train loss: 0.17498762178279104\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.09463226422667503\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.460s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 3\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.11219008240316596\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.07089876797464159\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.573s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 4\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.0914587319074642\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.05686664488166571\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.491s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 5\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.08032857777462118\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.04907625913619995\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.739s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 6\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.07228570839478857\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.0436574500054121\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.539s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 7\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.06770281688798041\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.040725926558176674\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.722s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 8\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.0646471158113508\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03902538741628329\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.386s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 9\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.06237556195507447\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.037164835466278925\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.472s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 10\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.060469550568433034\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03547213040292263\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.373s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 11\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.058859026724738736\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.034562836297684245\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.181s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 12\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.057380427162916886\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03363415360864666\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.764s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 13\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.0561574384392727\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03319412966569265\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.534s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 14\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05519395809443224\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.032315899048828416\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.778s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 15\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.054376127996615\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03175407715348734\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.593s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 16\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05372519143635318\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03142540632850594\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.628s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 17\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05296583158806676\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03100967924627993\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.643s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 18\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.052456071600317955\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.030714370051605835\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.715s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 19\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05191224418757927\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.030751210792611044\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.708s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 20\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05146163196435997\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.0303389482303626\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.621s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 21\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.050967722066811154\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02993976723195778\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.552s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 22\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05058704480706226\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02963176757718126\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.691s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 23\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.0503027429360719\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02995018536845843\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.962s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 24\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.049923839180597236\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.029950985840211313\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.797s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 25\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.0495196676236533\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.029153018206771877\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.724s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 26\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04929205034637735\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.029307551475034818\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.690s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 27\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04900477968511127\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.029198712048431236\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.878s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 28\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.048809557798362914\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028903946539180145\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.874s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 29\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04869969912050735\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02877454273402691\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.998s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 30\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.048311290153790085\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02875177003443241\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.765s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 31\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04810349004609244\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028593510958469577\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.735s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 32\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04792528608370395\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.0283467593188915\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.649s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 33\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04776930423187358\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028510529392709334\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.712s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 34\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.047548197342881134\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028411792798174754\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.655s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 35\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.047462105174504575\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028540794944597617\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.761s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 36\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04709795600779\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028175402173979416\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.792s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 37\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.0469977194886832\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028148079342726205\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.781s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 38\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04700107699526208\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02819191473018792\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.640s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 39\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.0470244838368325\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028117713207999866\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.799s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 40\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.047022384635749315\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028115076530310843\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.788s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 41\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04699664456503732\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028077728891124327\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.878s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 42\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.046952449007048494\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02803493906847305\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.603s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 43\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04689993802458048\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02809129872669776\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.603s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 44\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04694022996617215\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028133241925388575\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.642s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 45\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04688869097403118\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028080408254431352\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.546s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 46\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04691280127458629\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028045745256046455\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.650s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 47\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04689311861459698\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02810628805309534\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.505s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 48\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.046921979946394764\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02805760011283888\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.692s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 49\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04687124313343139\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02800175112982591\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.891s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 50\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04678563330145109\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028008843099491462\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.648s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 51\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.5832250182117734\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.2949759215116501\n",
      "Eval Model Test loss: 0.52485474695762\n",
      "First Out Loss: 0.02705095113358564\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.083s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 52\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.230134291130872\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.14967870256967014\n",
      "Eval Model Test loss: 0.3340945881274011\n",
      "First Out Loss: 0.027050951185325783\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 7.735s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 53\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.1006646974987927\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.07547340293725331\n",
      "Eval Model Test loss: 0.22440093921290505\n",
      "First Out Loss: 0.027050951030105352\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.578s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 54\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.06532604633165258\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.05940209453304609\n",
      "Eval Model Test loss: 0.17328555840584967\n",
      "First Out Loss: 0.027050951185325783\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.396s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 55\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.05715470064786218\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.05422653444111347\n",
      "Eval Model Test loss: 0.12832466471526358\n",
      "First Out Loss: 0.027050951288806066\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.935s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 56\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.051693277965698926\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.04979664025207361\n",
      "Eval Model Test loss: 0.10571049795382553\n",
      "First Out Loss: 0.027050951288806066\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 7.904s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 57\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.049051242880523205\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.04831291093594498\n",
      "Eval Model Test loss: 0.10250158421695232\n",
      "First Out Loss: 0.027050951237065926\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.105s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 58\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0475847108644389\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.04531761062228017\n",
      "Eval Model Test loss: 0.09968044422566891\n",
      "First Out Loss: 0.027050951030105352\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.259s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 59\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.03910949358361818\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.031493610754195184\n",
      "Eval Model Test loss: 0.09485200399325953\n",
      "First Out Loss: 0.027050950874884922\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 7.887s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 60\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0268612698252712\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.022739907519684896\n",
      "Eval Model Test loss: 0.08314341037637657\n",
      "First Out Loss: 0.02705095134054621\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 7.812s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 61\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.02062752689900143\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.01882368212358819\n",
      "Eval Model Test loss: 0.08008723809487289\n",
      "First Out Loss: 0.02705095113358564\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.013s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 62\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.017685764358334598\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.016630223486572504\n",
      "Eval Model Test loss: 0.07856572647061613\n",
      "First Out Loss: 0.02705095134054621\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 7.864s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 63\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.016041320039048082\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.015401433765267333\n",
      "Eval Model Test loss: 0.07430318142804834\n",
      "First Out Loss: 0.02705095113358564\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 7.848s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 64\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.014973231214320376\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.014478049732537733\n",
      "Eval Model Test loss: 0.0698340166774061\n",
      "First Out Loss: 0.027050951185325783\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.153s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 65\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.014173438273636358\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.013851105338997312\n",
      "Eval Model Test loss: 0.06708161367310418\n",
      "First Out Loss: 0.02705095113358564\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.299s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 66\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.013835587716173558\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.013731780151526133\n",
      "Eval Model Test loss: 0.06604831458793746\n",
      "First Out Loss: 0.02705095113358564\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.356s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 67\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.013558485024120836\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.013315504235732887\n",
      "Eval Model Test loss: 0.06495901052322653\n",
      "First Out Loss: 0.027050951392286353\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 7.908s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 68\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.013224982734148702\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.013254729487622777\n",
      "Eval Model Test loss: 0.06432133819907904\n",
      "First Out Loss: 0.02705095097836521\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.332s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 69\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.013067685322658647\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.012741935232447254\n",
      "Eval Model Test loss: 0.06280926190730599\n",
      "First Out Loss: 0.027050950926625066\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.891s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 70\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.012452284805476665\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.012208706259520518\n",
      "Eval Model Test loss: 0.06082763315902816\n",
      "First Out Loss: 0.02705095113358564\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.714s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 71\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.012067715914565184\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.011908920714631677\n",
      "Eval Model Test loss: 0.059558695596125394\n",
      "First Out Loss: 0.027050951030105352\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.279s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 72\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.01183892286471313\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.011766874515968893\n",
      "Eval Model Test loss: 0.05883739174654087\n",
      "First Out Loss: 0.027050951237065926\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.438s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 73\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.011562503818866043\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.01140239537279639\n",
      "Eval Model Test loss: 0.05824778104821841\n",
      "First Out Loss: 0.02705095097836521\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.467s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 74\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.011330690456642992\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.011198952095583081\n",
      "Eval Model Test loss: 0.05834406469431189\n",
      "First Out Loss: 0.027050951237065926\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.565s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 75\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.011220120170730211\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.01115267845388088\n",
      "Eval Model Test loss: 0.05888883997168806\n",
      "First Out Loss: 0.027050950926625066\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.530s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 76\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.011073284350069506\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.010971596697345376\n",
      "Eval Model Test loss: 0.056882209351493254\n",
      "First Out Loss: 0.027050951030105352\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.660s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 77\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.01094480384407299\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.010873481993459992\n",
      "Eval Model Test loss: 0.05634986454000076\n",
      "First Out Loss: 0.027050951237065926\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.597s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 78\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.010824415655363174\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.010824664547625516\n",
      "Eval Model Test loss: 0.05643678384108676\n",
      "First Out Loss: 0.02705095113358564\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.543s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 79\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.010824134007894568\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.010798366533385383\n",
      "Eval Model Test loss: 0.056119149861236416\n",
      "First Out Loss: 0.02705095113358564\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.465s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 80\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.010651961345935152\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.010485888329438038\n",
      "Eval Model Test loss: 0.05564912801815404\n",
      "First Out Loss: 0.027050951288806066\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.851s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 81\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.010479731751339776\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.010390887890631953\n",
      "Eval Model Test loss: 0.055514842375285096\n",
      "First Out Loss: 0.02705095134054621\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.472s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 82\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.010401376179375109\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.01035886162167622\n",
      "Eval Model Test loss: 0.05549580624534024\n",
      "First Out Loss: 0.027050951030105352\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.608s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 83\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.010324349150150305\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.010271840702949299\n",
      "Eval Model Test loss: 0.05563925103180938\n",
      "First Out Loss: 0.027050951081845496\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.412s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 84\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.010113097882519165\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00992471923948162\n",
      "Eval Model Test loss: 0.05223810403711266\n",
      "First Out Loss: 0.027050951237065926\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.490s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 85\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009896985587796994\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009858213416818116\n",
      "Eval Model Test loss: 0.05152325994438595\n",
      "First Out Loss: 0.02705095149576664\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.661s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 86\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009762703463257779\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009657187257996865\n",
      "Eval Model Test loss: 0.05159650039341715\n",
      "First Out Loss: 0.027050951237065926\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.829s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 87\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009650312696716614\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009617985510784719\n",
      "Eval Model Test loss: 0.05099130794405937\n",
      "First Out Loss: 0.027050950926625066\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.511s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 88\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009532923654963573\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009433963543011082\n",
      "Eval Model Test loss: 0.050672083265251584\n",
      "First Out Loss: 0.027050951288806066\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.508s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 89\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009418661495493282\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009376418518109454\n",
      "Eval Model Test loss: 0.05086753465649155\n",
      "First Out Loss: 0.027050951288806066\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.513s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 90\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009367200712274228\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009288395806733105\n",
      "Eval Model Test loss: 0.05027698694417874\n",
      "First Out Loss: 0.027050951185325783\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.795s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 91\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00925750840854432\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00921497323239843\n",
      "Eval Model Test loss: 0.05030306987464428\n",
      "First Out Loss: 0.027050950926625066\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.132s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 92\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009164345639181278\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009106572148286633\n",
      "Eval Model Test loss: 0.05120124605794748\n",
      "First Out Loss: 0.027050951081845496\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.339s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 93\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009113812597379797\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009061922060532702\n",
      "Eval Model Test loss: 0.050705549100206956\n",
      "First Out Loss: 0.027050951237065926\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.460s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 94\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009040412060650331\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00893763626097805\n",
      "Eval Model Test loss: 0.05038725326044692\n",
      "First Out Loss: 0.02705095113358564\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.469s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 95\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008946826093874517\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008893430181261566\n",
      "Eval Model Test loss: 0.05024710690809621\n",
      "First Out Loss: 0.027050951185325783\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 7.760s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 96\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008931855604584728\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008913157042115927\n",
      "Eval Model Test loss: 0.0502512709548076\n",
      "First Out Loss: 0.02705095149576664\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 7.932s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 97\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008938011003746874\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00892848596494231\n",
      "Eval Model Test loss: 0.05027943642603026\n",
      "First Out Loss: 0.027050951288806066\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 7.920s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 98\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008941904508641787\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00890129954657621\n",
      "Eval Model Test loss: 0.05028706509619951\n",
      "First Out Loss: 0.027050951030105352\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 7.906s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 99\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008897069176392896\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008850295225986175\n",
      "Eval Model Test loss: 0.04957882377008597\n",
      "First Out Loss: 0.027050950874884922\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 7.770s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 100\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008891852029288808\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008866962873273425\n",
      "Eval Model Test loss: 0.049332564075787864\n",
      "First Out Loss: 0.027050951081845496\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 7.841s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 101\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008887299181272587\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00885133921272225\n",
      "Eval Model Test loss: 0.0491376214971145\n",
      "First Out Loss: 0.02705095134054621\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.901s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 102\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008883574267938024\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008845768170431256\n",
      "Eval Model Test loss: 0.04919842123571369\n",
      "First Out Loss: 0.02705095113358564\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.855s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 103\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008880730119666882\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008851925066361824\n",
      "Eval Model Test loss: 0.04915735705031289\n",
      "First Out Loss: 0.02705095134054621\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.823s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 104\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008879406211365546\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00884308914343516\n",
      "Eval Model Test loss: 0.049060719501641065\n",
      "First Out Loss: 0.027050951392286353\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.936s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 105\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008876096302022537\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008849990269583132\n",
      "Eval Model Test loss: 0.049137528675297894\n",
      "First Out Loss: 0.027050951392286353\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.876s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 106\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008873765811412818\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008848512959149148\n",
      "Eval Model Test loss: 0.049236862195862666\n",
      "First Out Loss: 0.027050951081845496\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.880s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 107\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008873440059167998\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008841876587313082\n",
      "Eval Model Test loss: 0.04911253818621238\n",
      "First Out Loss: 0.027050951237065926\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.763s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 108\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00887301596369417\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008851459068763588\n",
      "Eval Model Test loss: 0.0491215456277132\n",
      "First Out Loss: 0.02705095082314478\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.881s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 109\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00887312521670191\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008835764058555165\n",
      "Eval Model Test loss: 0.04902951688402229\n",
      "First Out Loss: 0.027050951081845496\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.894s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 110\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00886955649946772\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008836226201512747\n",
      "Eval Model Test loss: 0.04904007497760984\n",
      "First Out Loss: 0.027050951392286353\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.884s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 111\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008870780445812713\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008835305459797382\n",
      "Eval Model Test loss: 0.04908174742013216\n",
      "First Out Loss: 0.027050951185325783\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.753s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 112\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008872536332568242\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008839603849790163\n",
      "Eval Model Test loss: 0.049058175231847495\n",
      "First Out Loss: 0.02705095082314478\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.892s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 113\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00887332224686231\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008842903473931883\n",
      "Eval Model Test loss: 0.0491938598247038\n",
      "First Out Loss: 0.02705095134054621\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.920s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 114\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00887791428803688\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008846447492639223\n",
      "Eval Model Test loss: 0.049201892481909856\n",
      "First Out Loss: 0.027050951030105352\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.879s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 115\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008878170401744899\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008849669765267108\n",
      "Eval Model Test loss: 0.04923612324313985\n",
      "First Out Loss: 0.027050951030105352\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.912s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 116\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008882547462625163\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008850279341762265\n",
      "Eval Model Test loss: 0.04915834104435311\n",
      "First Out Loss: 0.027050951185325783\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.898s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 117\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008891247867030046\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008865380607959297\n",
      "Eval Model Test loss: 0.049264647687474884\n",
      "First Out Loss: 0.027050951288806066\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.937s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 118\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00889589384730373\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008870833035972383\n",
      "Eval Model Test loss: 0.04932794512973891\n",
      "First Out Loss: 0.027050951185325783\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.922s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 119\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008902338388863774\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008872328714157144\n",
      "Eval Model Test loss: 0.049317659396264285\n",
      "First Out Loss: 0.027050951185325783\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.771s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 120\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008897978136138547\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00886203245156341\n",
      "Eval Model Test loss: 0.04919882698191537\n",
      "First Out Loss: 0.027050951030105352\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.881s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 121\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008886837577890782\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008846911006710596\n",
      "Eval Model Test loss: 0.04899570376922687\n",
      "First Out Loss: 0.027050951288806066\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.894s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 122\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008872552309185266\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008838203994350301\n",
      "Eval Model Test loss: 0.04852598005284866\n",
      "First Out Loss: 0.027050950926625066\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.855s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 123\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008863660850606504\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008833082366941703\n",
      "Eval Model Test loss: 0.0482135321944952\n",
      "First Out Loss: 0.027050951185325783\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.803s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 124\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008848821766497124\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008809384269018969\n",
      "Eval Model Test loss: 0.04826465662982729\n",
      "First Out Loss: 0.02705095149576664\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.886s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 125\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008831832391609038\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0087858479625235\n",
      "Eval Model Test loss: 0.04806707954655091\n",
      "First Out Loss: 0.02705095097836521\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.884s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 126\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008812446235900833\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008765663796414932\n",
      "Eval Model Test loss: 0.04786114849978023\n",
      "First Out Loss: 0.027050951444026496\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.888s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 127\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008792755016613574\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008748809548301829\n",
      "Eval Model Test loss: 0.04782263437906901\n",
      "First Out Loss: 0.027050951237065926\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.170s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 128\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008759241628771028\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008706624050521188\n",
      "Eval Model Test loss: 0.047914183077712856\n",
      "First Out Loss: 0.027050951185325783\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.895s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 129\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008739219368657186\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008685785552693738\n",
      "Eval Model Test loss: 0.04773006774485111\n",
      "First Out Loss: 0.02705095113358564\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.973s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 130\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008714651966112711\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008678636849961348\n",
      "Eval Model Test loss: 0.0476671906395091\n",
      "First Out Loss: 0.02705095134054621\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.970s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 131\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008692927658557892\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008651373468132483\n",
      "Eval Model Test loss: 0.04777081072744396\n",
      "First Out Loss: 0.027050950874884922\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.822s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 132\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008661719039082527\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008622282288140722\n",
      "Eval Model Test loss: 0.04768297624670797\n",
      "First Out Loss: 0.027050951599246927\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.995s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 133\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008639945460128643\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008616569245027171\n",
      "Eval Model Test loss: 0.04771290336632066\n",
      "First Out Loss: 0.027050951288806066\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.862s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 134\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008621787951726998\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008592657356833419\n",
      "Eval Model Test loss: 0.0476208972848124\n",
      "First Out Loss: 0.027050951237065926\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.812s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 135\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00860345751668016\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008565960426090492\n",
      "Eval Model Test loss: 0.04764062963012192\n",
      "First Out Loss: 0.02705095134054621\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.995s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 136\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008581529426876278\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008546736505296495\n",
      "Eval Model Test loss: 0.04753818973484966\n",
      "First Out Loss: 0.027050951237065926\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.035s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 137\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008560476480938849\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008539277335835828\n",
      "Eval Model Test loss: 0.047671612766053945\n",
      "First Out Loss: 0.02705095113358564\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.853s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 138\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008538940489026052\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0085128095621864\n",
      "Eval Model Test loss: 0.047397686168551445\n",
      "First Out Loss: 0.02705095097836521\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.197s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 139\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008516560020368723\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008498959734828936\n",
      "Eval Model Test loss: 0.047418929119077\n",
      "First Out Loss: 0.027050951392286353\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.756s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 140\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008498013673705004\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008483239087379642\n",
      "Eval Model Test loss: 0.04751706661449538\n",
      "First Out Loss: 0.027050951081845496\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.880s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 141\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008474113730092844\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008458350707466403\n",
      "Eval Model Test loss: 0.04751841423826085\n",
      "First Out Loss: 0.027050951081845496\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.950s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 142\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008458775767524327\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00844084367983871\n",
      "Eval Model Test loss: 0.04738430409795708\n",
      "First Out Loss: 0.02705095113358564\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.737s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 143\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008436537547303098\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008414399603174793\n",
      "Eval Model Test loss: 0.047197407111525536\n",
      "First Out Loss: 0.02705095097836521\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.436s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 144\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008415223187988713\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008403108093059726\n",
      "Eval Model Test loss: 0.04721282370802429\n",
      "First Out Loss: 0.027050951444026496\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.820s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 145\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008398472719515363\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00838573727135857\n",
      "Eval Model Test loss: 0.04729129198110766\n",
      "First Out Loss: 0.027050951392286353\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.127s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 146\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008379378045598665\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008358920381094018\n",
      "Eval Model Test loss: 0.04733228704167737\n",
      "First Out Loss: 0.027050951392286353\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.878s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 147\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008361590460741095\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00834773286866645\n",
      "Eval Model Test loss: 0.047198002226650715\n",
      "First Out Loss: 0.027050951081845496\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.762s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 148\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008341219309451324\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008334550592634413\n",
      "Eval Model Test loss: 0.047116409262849226\n",
      "First Out Loss: 0.027050951030105352\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.943s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 149\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00832590303339419\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008316856395039294\n",
      "Eval Model Test loss: 0.04716795858823591\n",
      "First Out Loss: 0.027050951237065926\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.836s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 150\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008311388748032706\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008302928931597207\n",
      "Eval Model Test loss: 0.04710845835506916\n",
      "First Out Loss: 0.02705095134054621\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.860s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 151\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008297903452157265\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008292009614201056\n",
      "Eval Model Test loss: 0.047068713853756584\n",
      "First Out Loss: 0.027050951185325783\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 7.776s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 152\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008292463973962836\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008292189281847741\n",
      "Eval Model Test loss: 0.04706759212745561\n",
      "First Out Loss: 0.027050951392286353\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 7.988s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 153\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008290240929151574\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00829025756360756\n",
      "Eval Model Test loss: 0.04704964140223132\n",
      "First Out Loss: 0.027050951185325783\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 7.850s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 154\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00828939739481679\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008288000943139195\n",
      "Eval Model Test loss: 0.047038865689602166\n",
      "First Out Loss: 0.02705095113358564\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 7.844s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 155\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008288498468963163\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008287317999121215\n",
      "Eval Model Test loss: 0.047035606681472726\n",
      "First Out Loss: 0.027050951288806066\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 7.793s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 156\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008286082828860907\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008285517649104198\n",
      "Eval Model Test loss: 0.04703914332720968\n",
      "First Out Loss: 0.027050951081845496\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 7.882s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 157\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008284534715736905\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008283871174272563\n",
      "Eval Model Test loss: 0.047024239889449544\n",
      "First Out Loss: 0.027050951081845496\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 7.832s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 158\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008283644349181227\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008281313840092884\n",
      "Eval Model Test loss: 0.04703182675358322\n",
      "First Out Loss: 0.027050951030105352\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.260s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 159\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008282171141001441\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008281977717868157\n",
      "Eval Model Test loss: 0.04699033312499523\n",
      "First Out Loss: 0.027050951444026496\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.525s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 160\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008279295638203621\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008278336065510908\n",
      "Eval Model Test loss: 0.047030419318212405\n",
      "First Out Loss: 0.02705095082314478\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.130s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 161\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008276746641578419\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008276214021154575\n",
      "Eval Model Test loss: 0.04703432621641292\n",
      "First Out Loss: 0.027050951237065926\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.219s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 162\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00827519256355507\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008276425224418441\n",
      "Eval Model Test loss: 0.04698676595257388\n",
      "First Out Loss: 0.027050951030105352\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.667s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 163\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008274153784094821\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008273097893430127\n",
      "Eval Model Test loss: 0.04700355614638991\n",
      "First Out Loss: 0.027050951237065926\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.356s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 164\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0082728995919405\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008272302362860905\n",
      "Eval Model Test loss: 0.04698800937169128\n",
      "First Out Loss: 0.02705095113358564\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.457s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 165\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008269554347775522\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008272694397924675\n",
      "Eval Model Test loss: 0.047003526240587234\n",
      "First Out Loss: 0.027050951081845496\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.534s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 166\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008268420262971804\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00827039190981951\n",
      "Eval Model Test loss: 0.046969996558295354\n",
      "First Out Loss: 0.027050951392286353\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 9.721s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 167\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008267708943181094\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00826584097618858\n",
      "Eval Model Test loss: 0.04697549332761102\n",
      "First Out Loss: 0.027050951392286353\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.901s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 168\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00826497805038733\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008265598470138179\n",
      "Eval Model Test loss: 0.046973503919111356\n",
      "First Out Loss: 0.02705095077140464\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.073s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 169\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008262290586052197\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008263316833310656\n",
      "Eval Model Test loss: 0.04694246956043773\n",
      "First Out Loss: 0.027050951288806066\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.102s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 170\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008260771377189528\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008262595446366403\n",
      "Eval Model Test loss: 0.046991575612790056\n",
      "First Out Loss: 0.02705095134054621\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.984s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 171\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00825843478863438\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008261525253247883\n",
      "Eval Model Test loss: 0.04692699604978164\n",
      "First Out Loss: 0.027050951081845496\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.038s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 172\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008256602854955764\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008258835050380893\n",
      "Eval Model Test loss: 0.04695963549117247\n",
      "First Out Loss: 0.02705095113358564\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 7.925s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 173\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008256645984060708\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008259360031742189\n",
      "Eval Model Test loss: 0.04698481327957577\n",
      "First Out Loss: 0.027050951237065926\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.162s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 174\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008253423208814292\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008254431550287537\n",
      "Eval Model Test loss: 0.046945761785739\n",
      "First Out Loss: 0.027050951547506783\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.111s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 175\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008252159481690753\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008253425670166811\n",
      "Eval Model Test loss: 0.04691284025708834\n",
      "First Out Loss: 0.027050951237065926\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.018s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 176\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008248116865399339\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008253192658432655\n",
      "Eval Model Test loss: 0.04691404362933503\n",
      "First Out Loss: 0.027050951081845496\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.358s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 177\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008244792797735758\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0082495610954033\n",
      "Eval Model Test loss: 0.04692086080710093\n",
      "First Out Loss: 0.027050951392286353\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.035s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 178\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008242885992374448\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00824702642340627\n",
      "Eval Model Test loss: 0.04688147952159246\n",
      "First Out Loss: 0.02705095113358564\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.171s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 179\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00824315880336577\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008244275270650784\n",
      "Eval Model Test loss: 0.04691921722971731\n",
      "First Out Loss: 0.027050951392286353\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 7.950s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 180\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00824067183947634\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008242439530375931\n",
      "Eval Model Test loss: 0.04685828565723366\n",
      "First Out Loss: 0.027050951237065926\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.190s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 181\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008238716838171794\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008241425708143247\n",
      "Eval Model Test loss: 0.04689439075688521\n",
      "First Out Loss: 0.027050950926625066\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.396s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 182\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008235092418977902\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00824013181651632\n",
      "Eval Model Test loss: 0.046899034124281674\n",
      "First Out Loss: 0.027050951030105352\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 9.192s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 183\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008234356186308321\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008234973117295239\n",
      "Eval Model Test loss: 0.04686224181205034\n",
      "First Out Loss: 0.027050951237065926\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.133s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 184\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008232869385253815\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008237434783950448\n",
      "Eval Model Test loss: 0.04690152913745907\n",
      "First Out Loss: 0.027050951081845496\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 7.941s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 185\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008229474137936319\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008237707894295454\n",
      "Eval Model Test loss: 0.04688227611283461\n",
      "First Out Loss: 0.027050951288806066\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.377s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 186\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008228608695346685\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008234650000101991\n",
      "Eval Model Test loss: 0.04686214081529114\n",
      "First Out Loss: 0.02705095077140464\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.064s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 187\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008227461583114095\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008231525593954656\n",
      "Eval Model Test loss: 0.04688600812935167\n",
      "First Out Loss: 0.02705095113358564\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 7.860s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 188\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00822434056594613\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008225524073673619\n",
      "Eval Model Test loss: 0.046870334487822324\n",
      "First Out Loss: 0.027050951288806066\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 7.892s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 189\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008223492253039564\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008227026374596689\n",
      "Eval Model Test loss: 0.046869727265503675\n",
      "First Out Loss: 0.027050950926625066\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.430s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 190\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008218630250277264\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0082257106486294\n",
      "Eval Model Test loss: 0.046862011361453265\n",
      "First Out Loss: 0.02705095113358564\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.530s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 191\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008218229460042147\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008222198165539239\n",
      "Eval Model Test loss: 0.04686337668034765\n",
      "First Out Loss: 0.027050951185325783\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 7.944s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 192\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008216503342347485\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008219219692465331\n",
      "Eval Model Test loss: 0.04683552051170005\n",
      "First Out Loss: 0.027050951237065926\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 7.964s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 193\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008214357153822979\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008219328372635774\n",
      "Eval Model Test loss: 0.0468471177543203\n",
      "First Out Loss: 0.027050951444026496\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 9.214s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 194\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008214744839019008\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008216982086499533\n",
      "Eval Model Test loss: 0.04685836254308621\n",
      "First Out Loss: 0.027050951030105352\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 9.086s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 195\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008213158053833814\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008214499516826537\n",
      "Eval Model Test loss: 0.046851936934722796\n",
      "First Out Loss: 0.027050951392286353\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.003s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 196\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008210699883333984\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00821527580006255\n",
      "Eval Model Test loss: 0.04683629102591011\n",
      "First Out Loss: 0.027050951185325783\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.100s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 197\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008209222617248694\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008214970015817218\n",
      "Eval Model Test loss: 0.04685440856135554\n",
      "First Out Loss: 0.02705095113358564\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.023s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 198\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00820610656713446\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00821182762997018\n",
      "Eval Model Test loss: 0.04686677476598157\n",
      "First Out Loss: 0.027050951444026496\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 7.923s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 199\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008204674459106866\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008213938446715474\n",
      "Eval Model Test loss: 0.04684560735606485\n",
      "First Out Loss: 0.02705095097836521\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.160s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 200\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00820517883680406\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008207920033277737\n",
      "Eval Model Test loss: 0.04678672500368622\n",
      "First Out Loss: 0.02705095113358564\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.758s\n"
     ]
    }
   ],
   "source": [
    "trainer.train(n_epochs=n_epochs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "model = ForcastingQuantInferenceWrapper(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "torch.save(model, model_path)\n",
    "torch.cuda.empty_cache()\n",
    "del model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
