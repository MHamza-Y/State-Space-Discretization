{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from state_quantization.dataset import load_dataset\n",
    "from state_quantization.dataset import DynamicsModelDataset\n",
    "from state_quantization.forcasting_models import LSTMForcasting\n",
    "from state_quantization.quantization_models import DiscAutoEncoder\n",
    "from state_quantization.forcasting_quantization_models import ForcastingQuant, EmbeddedAEForcastingQuant, ForcastingQuantInferenceWrapper, SingleEmbeddedAEForcastingQuant\n",
    "from state_quantization.trainer import ForcastingQuantTrainer\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from state_quantization.train import train_model, test_step\n",
    "from state_quantization.eval import eval_model, compare_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "print(f\"Using Device: {device}\")\n",
    "torch.backends.cudnn.benchmark = True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clipping y\n",
      "torch.Size([672000, 39, 6])\n",
      "torch.Size([672000, 10, 2])\n",
      "torch.Size([288000, 39, 6])\n",
      "torch.Size([288000, 10, 2])\n",
      "{'batch_size': 8000, 'shuffle': True, 'num_workers': 0, 'drop_last': True, 'pin_memory': True}\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[-0.5704, -0.4076],\n        [-0.4757, -0.4104],\n        [-0.6644, -0.3520],\n        [-0.5751, -0.2997],\n        [-0.5395, -0.3250],\n        [-0.5805, -0.2798],\n        [-0.5117, -0.3026],\n        [-0.4582, -0.2790],\n        [-0.5483, -0.2665],\n        [-0.5995, -0.2484]])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_input_key = 'merged_input'\n",
    "dataset_output_key = 'merged_output'\n",
    "dataset_file_path = 'tmp/ib-out/ib-samples-la.npy'\n",
    "normalized_data_params_save_path = 'tmp/transformer/NormalizeInputConfigs.pkl'\n",
    "dataset_device = 'cpu'\n",
    "y_indexes = [4, 6]\n",
    "\n",
    "train_dataset, val_dataset = load_dataset(file_path=dataset_file_path, input_key=dataset_input_key,\n",
    "                                          output_key=dataset_output_key, dataset_class=DynamicsModelDataset,\n",
    "                                          normalize=True, device=dataset_device, y_clip_range=y_indexes,\n",
    "                                          normalized_input_data_params_save_path=normalized_data_params_save_path)\n",
    "\n",
    "batch_size = 8000\n",
    "params = {'batch_size': batch_size,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 0,\n",
    "          'drop_last': True,\n",
    "          'pin_memory': not train_dataset.x.is_cuda}\n",
    "print(params)\n",
    "train_loader = DataLoader(train_dataset, **params)\n",
    "val_loader = DataLoader(val_dataset, **params)\n",
    "train_dataset.y[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out Size:2\n",
      "LSTM Layers\n",
      "ModuleList(\n",
      "  (0): LSTMCell(6, 20)\n",
      ")\n",
      "LSTM Dropout Layers\n",
      "ModuleList()\n",
      "Fully Connected Layers\n",
      "Sequential(\n",
      "  (0): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (1): GELU(approximate=none)\n",
      "  (2): Dropout(p=0.1, inplace=False)\n",
      "  (3): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (4): GELU(approximate=none)\n",
      "  (5): Dropout(p=0.1, inplace=False)\n",
      "  (6): Linear(in_features=20, out_features=2, bias=True)\n",
      ")\n",
      "Encoder Layers\n",
      "Sequential(\n",
      "  (0): Linear(in_features=40, out_features=40, bias=True)\n",
      "  (1): GELU(approximate=none)\n",
      "  (2): Dropout(p=0, inplace=False)\n",
      "  (3): Linear(in_features=40, out_features=20, bias=True)\n",
      "  (4): GELU(approximate=none)\n",
      "  (5): Dropout(p=0, inplace=False)\n",
      "  (6): Linear(in_features=20, out_features=10, bias=True)\n",
      "  (7): GELU(approximate=none)\n",
      "  (8): Dropout(p=0, inplace=False)\n",
      ")\n",
      "Bottleneck Layers\n",
      "Sequential(\n",
      "  (0): Linear(in_features=10, out_features=20, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): StraightThroughEstimator()\n",
      ")\n",
      "Decoder Layers\n",
      "Sequential(\n",
      "  (0): Linear(in_features=20, out_features=10, bias=True)\n",
      "  (1): GELU(approximate=none)\n",
      "  (2): Dropout(p=0, inplace=False)\n",
      "  (3): Linear(in_features=10, out_features=20, bias=True)\n",
      "  (4): GELU(approximate=none)\n",
      "  (5): Dropout(p=0, inplace=False)\n",
      "  (6): Linear(in_features=20, out_features=40, bias=True)\n",
      "  (7): GELU(approximate=none)\n",
      "  (8): Dropout(p=0, inplace=False)\n",
      "  (9): Linear(in_features=40, out_features=40, bias=True)\n",
      ")\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "num_of_features = train_dataset.get_features_size()\n",
    "seq_len = train_dataset.get_seq_len()\n",
    "hidden_size = 20\n",
    "out_size = train_dataset.get_output_feature_size()\n",
    "print(f'Out Size:{out_size}')\n",
    "look_ahead = train_dataset.get_look_ahead_size()\n",
    "n_layers = 1\n",
    "dropout = 0.1\n",
    "\n",
    "forcasting_model = LSTMForcasting(features=num_of_features, hidden_size=hidden_size, out_size=out_size, seq_len=seq_len,\n",
    "                                  look_ahead=look_ahead, dropout=dropout, n_layers=n_layers)\n",
    "\n",
    "disc_autoencoder_input_size = hidden_size * 2\n",
    "bottleneck_size = 20\n",
    "ae_dropout = 0\n",
    "disc_autoencoder = DiscAutoEncoder(input_size=disc_autoencoder_input_size, bottleneck_size=bottleneck_size,\n",
    "                                   dropout=ae_dropout)\n",
    "model_path = f'tmp/state_quantization/model_aeq-{bottleneck_size}bits3'\n",
    "untrained_model_path = f'tmp/state_quantization/untrained_model_aeq-{bottleneck_size}bits'\n",
    "model = ForcastingQuant(forcasting_model=forcasting_model, autoencoder_quant_model=disc_autoencoder).to(device=device)\n",
    "eval_model = SingleEmbeddedAEForcastingQuant(model=model).to(device=device)\n",
    "torch.save(ForcastingQuantInferenceWrapper(model), untrained_model_path)\n",
    "load_to_gpu = model.is_cuda() and not train_dataset.x.is_cuda\n",
    "print(load_to_gpu)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Trainer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "gamma = 0.1\n",
    "\n",
    "forecasting_learning_rate = 1e-3\n",
    "autoencoder_learning_rate = 1e-3\n",
    "\n",
    "forecasting_lr_milestones = [35]\n",
    "autoencoder_lr_milestones = [100, 150]\n",
    "forecasting_optimizer = torch.optim.Adam(model.forcasting_model.parameters(),\n",
    "                                         lr=forecasting_learning_rate)\n",
    "autoencoder_optimizer = torch.optim.Adam(model.autoencoder_quant_model.parameters(),\n",
    "                                         lr=autoencoder_learning_rate)\n",
    "forecasting_lr_scheduler = MultiStepLR(forecasting_optimizer, milestones=forecasting_lr_milestones, gamma=gamma)\n",
    "autoencoder_lr_scheduler = MultiStepLR(autoencoder_optimizer, milestones=autoencoder_lr_milestones, gamma=gamma)\n",
    "n_epochs = 200\n",
    "\n",
    "trainer = ForcastingQuantTrainer(forcasting_quant_model=model, train_loader=train_loader, test_loader=val_loader,\n",
    "                                 load_to_gpu=load_to_gpu, forecasting_optimizer=forecasting_optimizer,\n",
    "                                 forecasting_lr_scheduler=forecasting_lr_scheduler,\n",
    "                                 autoencoder_lr_scheduler=autoencoder_lr_scheduler,\n",
    "                                 autoencoder_optimizer=autoencoder_optimizer,autoencoder_training_start=50,additional_eval_model=eval_model)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained test\n",
      "--------\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 1.0088192092047796\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 1\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.7365802349079222\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.34217649201552075\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.821s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 2\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "Forcasting Train loss: 0.19300446863330545\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.0916418596688244\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.993s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 3\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.1102408692240715\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.0717052806996637\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.944s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 4\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.09268462320878393\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.05941266204333968\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.423s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 5\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.08205107040703297\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.05174228041950199\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.311s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 6\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.07454750598186538\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.046262993994686336\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.125s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 7\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.06945469310241086\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.04261166726549467\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.153s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 8\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.06551332492381334\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03947092934201161\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.671s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 9\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.06237578059413603\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.037069809002180897\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.976s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 10\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.0601381774370869\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03541379711694188\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.234s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 11\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05826883572375491\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03431990732335382\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.936s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 12\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05709464386815116\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03317072780595885\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.822s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 13\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05613328512048438\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03294613486569789\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.701s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 14\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05531808290453184\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03240740532055497\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.612s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 15\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05452144021789233\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.0321465476623012\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.725s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 16\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.053991026777241914\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03175344271585345\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.647s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 17\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05341606924221629\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.031043685972690582\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.482s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 18\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05299274144428117\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.031225956976413727\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.599s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 19\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05256370756597746\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03090053279366758\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.845s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 20\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05231897124931926\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.030825491373737652\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.676s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 21\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.0518045099008651\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.030484004618806973\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.485s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 22\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.051525517499872615\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.030644752447389893\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.585s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 23\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05110189686751082\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03016444140424331\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.501s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 24\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05083639170264914\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03052360098809004\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.547s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 25\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05051026391308932\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.029479801499595244\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.579s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 26\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05016720401389258\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.029562326044672065\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.549s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 27\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04995062800922564\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.029833103167927928\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.341s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 28\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.049613760074689275\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.029121153211841982\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.055s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 29\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04926341989388069\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.029363614817460377\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.439s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 30\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04926733242436534\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.0289026176970866\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.265s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 31\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04895779849695308\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02879534935992625\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.997s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 32\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.0486370911821723\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02908410183671448\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.848s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 33\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04847635630340803\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02876619968770279\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.313s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 34\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04831100148814065\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028290253960424\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.056s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 35\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04818514237801234\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028218859237515263\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.338s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 36\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04779272007622889\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02823260731788145\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.123s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 37\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.047704379384716354\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028181613009009097\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.968s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 38\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04770910447197301\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02821658391298519\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.872s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 39\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.047661625247980864\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028180021947870653\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.880s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 40\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.047638398595154285\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028136273121668234\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.898s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 41\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.047665629269821305\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02812635184576114\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.882s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 42\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.047668409533798695\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02812742514328824\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.899s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 43\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.047567730370376794\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02817987919681602\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.829s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 44\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.047537630423903465\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02800658805709746\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.801s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 45\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04754801143315576\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02813540378378497\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.857s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 46\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04750241729475203\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028075421487705574\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.896s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 47\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04749616749939464\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02804282871592376\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.884s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 48\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04742494323069141\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028185674868937995\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.951s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 49\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04747112241706678\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028019519471045997\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.030s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 50\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04732082234252067\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028052099256051913\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.819s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 51\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.274361858942679\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.19171801871723598\n",
      "Eval Model Test loss: 0.46601780090067124\n",
      "First Out Loss: 0.9624067727062438\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.042s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 52\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.12327497629892259\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.06170110642496082\n",
      "Eval Model Test loss: 0.2651109803054068\n",
      "First Out Loss: 0.5400205800930659\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 7.975s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 53\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.04758769353585584\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.03559230143825213\n",
      "Eval Model Test loss: 0.16476263312829864\n",
      "First Out Loss: 0.3734492336710294\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.060s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 54\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.030374549750593446\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.025826046915931836\n",
      "Eval Model Test loss: 0.11397850368585852\n",
      "First Out Loss: 0.26190971003638375\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.075s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 55\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.023860824782223927\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.021890130411419604\n",
      "Eval Model Test loss: 0.09368815314438608\n",
      "First Out Loss: 0.20852596933643022\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.423s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 56\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.020918171608909256\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.01993171042866177\n",
      "Eval Model Test loss: 0.08257568793164359\n",
      "First Out Loss: 0.18157006055116653\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.204s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 57\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.019124116238561414\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.018083961732271645\n",
      "Eval Model Test loss: 0.07708625681698322\n",
      "First Out Loss: 0.15918051617013085\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.458s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 58\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.017516829250823884\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.01681690037043558\n",
      "Eval Model Test loss: 0.07011781032714579\n",
      "First Out Loss: 0.14637419250276354\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.162s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 59\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.016480725081194015\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.016086076231052477\n",
      "Eval Model Test loss: 0.06887718228002389\n",
      "First Out Loss: 0.14273976741565597\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.192s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 60\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.015862804094684265\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.015445995377376676\n",
      "Eval Model Test loss: 0.06666694229675664\n",
      "First Out Loss: 0.13655877568655544\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 7.951s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 61\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.01517674085196285\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.01485640361594657\n",
      "Eval Model Test loss: 0.0652753407549527\n",
      "First Out Loss: 0.1287115199698342\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 7.924s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 62\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.014716018989150013\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.01448237945118712\n",
      "Eval Model Test loss: 0.0643738154321909\n",
      "First Out Loss: 0.12328761940201123\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 7.837s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 63\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.014342071499586814\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.014103415137570765\n",
      "Eval Model Test loss: 0.06357809425228172\n",
      "First Out Loss: 0.11679720775120789\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 7.964s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 64\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.01391802623956686\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.013619877527364425\n",
      "Eval Model Test loss: 0.061711569109724626\n",
      "First Out Loss: 0.1077015967004829\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.281s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 65\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.013426699476050479\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.013177568455123238\n",
      "Eval Model Test loss: 0.059736322404609785\n",
      "First Out Loss: 0.09781957500510746\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.883s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 66\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.013025676332680243\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.012813972593802545\n",
      "Eval Model Test loss: 0.06072010886338022\n",
      "First Out Loss: 0.09633664414286613\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.841s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 67\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.012639004936707872\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.012417160362626115\n",
      "Eval Model Test loss: 0.05971131639348136\n",
      "First Out Loss: 0.09198037597040336\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.222s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 68\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.012194851923379161\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.01188205495580203\n",
      "Eval Model Test loss: 0.058802022909124695\n",
      "First Out Loss: 0.08897392120626238\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.181s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 69\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.01161977372664426\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.011333180772554543\n",
      "Eval Model Test loss: 0.05804549033443133\n",
      "First Out Loss: 0.08447978790435526\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 7.960s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 70\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.011133509045023294\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.010936699548943175\n",
      "Eval Model Test loss: 0.0580315390187833\n",
      "First Out Loss: 0.08158130157325003\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.141s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 71\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.010819171411207034\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.010667929037784537\n",
      "Eval Model Test loss: 0.05721320118755102\n",
      "First Out Loss: 0.07979994515577953\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.406s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 72\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.010497043918197354\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.010257029983525475\n",
      "Eval Model Test loss: 0.05701512801978323\n",
      "First Out Loss: 0.07941029200123416\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.397s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 73\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009843151495304136\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00950445811678138\n",
      "Eval Model Test loss: 0.05701090943896108\n",
      "First Out Loss: 0.08162340583900611\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.128s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 74\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009329927131711017\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009167124698352482\n",
      "Eval Model Test loss: 0.057012630730039544\n",
      "First Out Loss: 0.08235138406356175\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.133s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 75\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009057817459549932\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008918940141383145\n",
      "Eval Model Test loss: 0.056844319941269025\n",
      "First Out Loss: 0.0817771614011791\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.286s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 76\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008860087299364664\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00876258324003882\n",
      "Eval Model Test loss: 0.05716518799049987\n",
      "First Out Loss: 0.08101607714262274\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.150s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 77\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008683716213064534\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00859446458828946\n",
      "Eval Model Test loss: 0.056423802135719195\n",
      "First Out Loss: 0.07957670278847218\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.127s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 78\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008510010128486015\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00843034301780992\n",
      "Eval Model Test loss: 0.056290658501287304\n",
      "First Out Loss: 0.07881031040516165\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.217s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 79\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008386441096219988\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008295324941476187\n",
      "Eval Model Test loss: 0.056424064044323236\n",
      "First Out Loss: 0.07861423264775011\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.128s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 80\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008252904661709354\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008205550800388059\n",
      "Eval Model Test loss: 0.056329729656378426\n",
      "First Out Loss: 0.07828316133883265\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.382s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 81\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008158637077680655\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008126838831230998\n",
      "Eval Model Test loss: 0.056312320857412286\n",
      "First Out Loss: 0.07779023175438245\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 7.932s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 82\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008082010805429448\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008037841309689812\n",
      "Eval Model Test loss: 0.05598762186451091\n",
      "First Out Loss: 0.0781380051953925\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 7.989s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 83\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008001213211433164\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.007972917234939005\n",
      "Eval Model Test loss: 0.055889569222927094\n",
      "First Out Loss: 0.07776968760622872\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.022s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 84\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.007945753489842727\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.007941288783008026\n",
      "Eval Model Test loss: 0.055914062903159194\n",
      "First Out Loss: 0.07731719522012605\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.052s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 85\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.007910392263771169\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.007906027280518578\n",
      "Eval Model Test loss: 0.05585818396260341\n",
      "First Out Loss: 0.07774678907460636\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.254s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 86\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.007866906778266033\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.007832929078075621\n",
      "Eval Model Test loss: 0.055746794781751104\n",
      "First Out Loss: 0.07585808324317138\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.353s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 87\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.007814171657498394\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.007781042807942463\n",
      "Eval Model Test loss: 0.055484206726153694\n",
      "First Out Loss: 0.07561842745376958\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 7.969s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 88\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.007754558154071371\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0077301483834162354\n",
      "Eval Model Test loss: 0.05543466512527731\n",
      "First Out Loss: 0.07526088630159695\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.035s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 89\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0076915088409025755\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.007673491723835468\n",
      "Eval Model Test loss: 0.05551848612311813\n",
      "First Out Loss: 0.07503237720164987\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.012s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 90\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.007631029473573324\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.007599556728059219\n",
      "Eval Model Test loss: 0.05519504545049535\n",
      "First Out Loss: 0.07449487307005459\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.097s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 91\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.007569701238978831\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.007534215084484054\n",
      "Eval Model Test loss: 0.054517109878361225\n",
      "First Out Loss: 0.07377144570151965\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 7.909s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 92\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00751845150010749\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.007506796223525371\n",
      "Eval Model Test loss: 0.055161271140807204\n",
      "First Out Loss: 0.0741264774567551\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.033s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 93\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.007470784331893637\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00743178637801773\n",
      "Eval Model Test loss: 0.05424525754319297\n",
      "First Out Loss: 0.07413915441268021\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.088s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 94\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.007419828148115249\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.007389873524920808\n",
      "Eval Model Test loss: 0.05456918633232514\n",
      "First Out Loss: 0.07384179884360896\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.000s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 95\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.007357923114406211\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.007324991695996787\n",
      "Eval Model Test loss: 0.055052006617188454\n",
      "First Out Loss: 0.07442864030599594\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 7.858s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 96\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.007274926229867907\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.007255164583006667\n",
      "Eval Model Test loss: 0.054860609169635505\n",
      "First Out Loss: 0.07390819448563787\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.102s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 97\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.007210942062859734\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.007160156189153592\n",
      "Eval Model Test loss: 0.054425746409429446\n",
      "First Out Loss: 0.0735058252596193\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.101s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 98\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.007151707524566778\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0071344982392879\n",
      "Eval Model Test loss: 0.053931612624890275\n",
      "First Out Loss: 0.0737840657432874\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.132s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 99\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.007108719769998321\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.007122306153178215\n",
      "Eval Model Test loss: 0.0537766989113556\n",
      "First Out Loss: 0.07376850851707989\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 7.941s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 100\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.007083834875153289\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.007046848897718721\n",
      "Eval Model Test loss: 0.05342144819183482\n",
      "First Out Loss: 0.07262588954634136\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.054s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 101\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.007033241968158455\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00701514274502794\n",
      "Eval Model Test loss: 0.05320279186384545\n",
      "First Out Loss: 0.0726594500657585\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.058s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 102\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0070297932252287865\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.007017239255623685\n",
      "Eval Model Test loss: 0.053240330061978765\n",
      "First Out Loss: 0.07270199060440063\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.067s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 103\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.007027332615550785\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00701888063405123\n",
      "Eval Model Test loss: 0.05310821543551154\n",
      "First Out Loss: 0.07261230920751889\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.946s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 104\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.007024744026628988\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0070171631070681745\n",
      "Eval Model Test loss: 0.053115625865757465\n",
      "First Out Loss: 0.07242218715449174\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.079s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 105\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.007020640902088157\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.007004971227919062\n",
      "Eval Model Test loss: 0.052992052088181175\n",
      "First Out Loss: 0.0723483521077368\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.045s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 106\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.007019629230767134\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0070140021077046795\n",
      "Eval Model Test loss: 0.053013830135265984\n",
      "First Out Loss: 0.07230441023906072\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.055s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 107\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00701668100719828\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.007005826091497309\n",
      "Eval Model Test loss: 0.05290819983929396\n",
      "First Out Loss: 0.07231329712602827\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.994s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 108\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.007015912993145841\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.007002975144940946\n",
      "Eval Model Test loss: 0.05295696585542626\n",
      "First Out Loss: 0.07241549798183972\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.071s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 109\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.007013009057291562\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.007001200884891053\n",
      "Eval Model Test loss: 0.05275440319544739\n",
      "First Out Loss: 0.07226251334779793\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.053s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 110\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00700855888758919\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006996154384170141\n",
      "Eval Model Test loss: 0.052668157344063125\n",
      "First Out Loss: 0.07222749934428269\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.046s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 111\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.007004028579796709\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006996341385982103\n",
      "Eval Model Test loss: 0.05275903259300523\n",
      "First Out Loss: 0.07221631002095011\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.995s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 112\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.007002351134793744\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00698799795160691\n",
      "Eval Model Test loss: 0.05270333722647694\n",
      "First Out Loss: 0.07210984143118064\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.134s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 113\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0069988999526859035\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006986763768105043\n",
      "Eval Model Test loss: 0.05249349928150574\n",
      "First Out Loss: 0.07197186309430334\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.112s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 114\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006996465852439758\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006978659748306705\n",
      "Eval Model Test loss: 0.052433589887287885\n",
      "First Out Loss: 0.07205948212908374\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.050s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 115\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006989007788000717\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006980711038017439\n",
      "Eval Model Test loss: 0.05243433463490672\n",
      "First Out Loss: 0.07200034231775337\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.981s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 116\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006983806090872912\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00696629218550192\n",
      "Eval Model Test loss: 0.052390448128183685\n",
      "First Out Loss: 0.07184482034709719\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.055s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 117\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006977254835267861\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006966910156835284\n",
      "Eval Model Test loss: 0.05241254437714815\n",
      "First Out Loss: 0.07181912412246068\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.033s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 118\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006970975315198302\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006961009529833164\n",
      "Eval Model Test loss: 0.05236911432196697\n",
      "First Out Loss: 0.07186216757529312\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.008s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 119\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006963724392421898\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006951595669508808\n",
      "Eval Model Test loss: 0.05235318746417761\n",
      "First Out Loss: 0.07182109811239773\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.926s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 120\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006957333978442918\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006942926737893786\n",
      "Eval Model Test loss: 0.05223346046275563\n",
      "First Out Loss: 0.07164836054046948\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.112s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 121\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006951740826480091\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006939576473087072\n",
      "Eval Model Test loss: 0.05224544182419777\n",
      "First Out Loss: 0.0716669491181771\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.074s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 122\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006944272384446647\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006938058908821808\n",
      "Eval Model Test loss: 0.0523542964624034\n",
      "First Out Loss: 0.07190016408761342\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.033s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 123\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006938051166278976\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006929423828195367\n",
      "Eval Model Test loss: 0.0520940168450276\n",
      "First Out Loss: 0.07149787143700653\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.956s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 124\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006932900714067121\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00693694244708038\n",
      "Eval Model Test loss: 0.05210554268625048\n",
      "First Out Loss: 0.07159607898857859\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.041s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 125\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006926393746176646\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00692635429246972\n",
      "Eval Model Test loss: 0.05199995533459716\n",
      "First Out Loss: 0.07151733276744683\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.029s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 126\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006923058114591099\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006922705461167627\n",
      "Eval Model Test loss: 0.052082865291999444\n",
      "First Out Loss: 0.07153950817883015\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.048s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 127\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006917257726724658\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0069166241705210674\n",
      "Eval Model Test loss: 0.0521052483883169\n",
      "First Out Loss: 0.07173730991780758\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.971s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 128\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006914110094796689\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006913386130084594\n",
      "Eval Model Test loss: 0.052016522735357285\n",
      "First Out Loss: 0.07150961293114556\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.046s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 129\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006906768645248597\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006912569838782979\n",
      "Eval Model Test loss: 0.05209515450729264\n",
      "First Out Loss: 0.071712924581435\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.031s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 130\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0069056394831499175\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006910078602636026\n",
      "Eval Model Test loss: 0.05199469284464916\n",
      "First Out Loss: 0.07152187741465038\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.104s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 131\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006901754487660669\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006903005647473037\n",
      "Eval Model Test loss: 0.051945315673947334\n",
      "First Out Loss: 0.07166635389957163\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.439s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 132\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006890082382597029\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006899948956237899\n",
      "Eval Model Test loss: 0.0520627535879612\n",
      "First Out Loss: 0.07158061179021995\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.169s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 133\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006887562961007158\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006890103958236675\n",
      "Eval Model Test loss: 0.0519465571269393\n",
      "First Out Loss: 0.0715261875755257\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.274s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 134\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006879344305378341\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0068820588833962875\n",
      "Eval Model Test loss: 0.05182651202711794\n",
      "First Out Loss: 0.07150122399131457\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.315s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 135\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006873780129743474\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006876683729286823\n",
      "Eval Model Test loss: 0.05191414410041438\n",
      "First Out Loss: 0.07174160807496971\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.728s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 136\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006870563918103774\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006875227891012198\n",
      "Eval Model Test loss: 0.051945046418242984\n",
      "First Out Loss: 0.07171809031731552\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.816s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 137\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006861454956898732\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006871907234502335\n",
      "Eval Model Test loss: 0.051872011067138776\n",
      "First Out Loss: 0.07147711349858178\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.805s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 138\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006855514776405124\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006858521619708174\n",
      "Eval Model Test loss: 0.051955367541975446\n",
      "First Out Loss: 0.07150892830557293\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.770s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 139\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006849281002013456\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006854686498021086\n",
      "Eval Model Test loss: 0.051933319411344\n",
      "First Out Loss: 0.07167529356148508\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.604s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 140\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006845534657172504\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0068468034733086824\n",
      "Eval Model Test loss: 0.052016733317739434\n",
      "First Out Loss: 0.0715417888843351\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.707s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 141\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006838877325034922\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006839455157104466\n",
      "Eval Model Test loss: 0.05199873850991329\n",
      "First Out Loss: 0.07161490474310186\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.771s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 142\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006831844337284565\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00683267990178946\n",
      "Eval Model Test loss: 0.05200136276996798\n",
      "First Out Loss: 0.07164132429493798\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.792s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 143\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006825989145519478\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006820708991856211\n",
      "Eval Model Test loss: 0.05184271393550767\n",
      "First Out Loss: 0.07145385982261764\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.644s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 144\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006822618822168026\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00682434615575605\n",
      "Eval Model Test loss: 0.051980313948459096\n",
      "First Out Loss: 0.07147595431241724\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.836s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 145\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006813413895932692\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006813221391186946\n",
      "Eval Model Test loss: 0.05199310525010029\n",
      "First Out Loss: 0.07137222546670172\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 7.746s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 146\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006808622141501733\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00680723889834351\n",
      "Eval Model Test loss: 0.05189364465574423\n",
      "First Out Loss: 0.07143979540301694\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.064s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 147\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006800834039625313\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006806730292737484\n",
      "Eval Model Test loss: 0.0519604729488492\n",
      "First Out Loss: 0.07156916542185678\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.176s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 148\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006798736706730865\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0067904468936224776\n",
      "Eval Model Test loss: 0.05181804382138782\n",
      "First Out Loss: 0.07135164406564501\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.452s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 149\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00679436166371618\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006792231863881979\n",
      "Eval Model Test loss: 0.052032111005650625\n",
      "First Out Loss: 0.07168897655275133\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.430s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 150\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006789164185257894\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006783204360140694\n",
      "Eval Model Test loss: 0.051979224714967937\n",
      "First Out Loss: 0.07157416683104303\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.594s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 151\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006786766705945844\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006779119230082465\n",
      "Eval Model Test loss: 0.052085081529286176\n",
      "First Out Loss: 0.07170895155933169\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.503s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 152\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006783674909023657\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006778026064340439\n",
      "Eval Model Test loss: 0.05210995819005701\n",
      "First Out Loss: 0.07174013120432694\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.438s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 153\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006785194727680867\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006778492139548891\n",
      "Eval Model Test loss: 0.0521549413808518\n",
      "First Out Loss: 0.07176179024908277\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.198s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 154\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006784071652440443\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00677760420108421\n",
      "Eval Model Test loss: 0.05213168356567621\n",
      "First Out Loss: 0.0717287804517481\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.420s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 155\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006784183915615792\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006777415996313923\n",
      "Eval Model Test loss: 0.05214316563473807\n",
      "First Out Loss: 0.07170715803901355\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.279s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 156\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006782795319200626\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00677854139616506\n",
      "Eval Model Test loss: 0.052144928835332394\n",
      "First Out Loss: 0.07172863454454476\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.355s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 157\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0067823408282406275\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006775880232453346\n",
      "Eval Model Test loss: 0.05217053917133146\n",
      "First Out Loss: 0.071751585851113\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.252s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 158\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006782674818255362\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006773732059324781\n",
      "Eval Model Test loss: 0.052151100916994944\n",
      "First Out Loss: 0.07171113126807743\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.307s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 159\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00678086880084482\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0067771689371309346\n",
      "Eval Model Test loss: 0.0521760576715072\n",
      "First Out Loss: 0.07171480937136544\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.187s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 160\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0067812792480080614\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006773730274289846\n",
      "Eval Model Test loss: 0.05212283041328192\n",
      "First Out Loss: 0.07166308495733473\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.342s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 161\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0067800159089355955\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0067756167199048735\n",
      "Eval Model Test loss: 0.0521662671946817\n",
      "First Out Loss: 0.0717414447830783\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.592s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 162\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006779674939545137\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00677349900878552\n",
      "Eval Model Test loss: 0.052161196867624916\n",
      "First Out Loss: 0.07172353400124444\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.434s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 163\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006778266402848419\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006773832538682554\n",
      "Eval Model Test loss: 0.05219787431673871\n",
      "First Out Loss: 0.07174275318781535\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.770s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 164\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006780150041560687\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006772017610880236\n",
      "Eval Model Test loss: 0.052199967515965305\n",
      "First Out Loss: 0.07178093410200542\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.681s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 165\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006777761531772003\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006770500369990866\n",
      "Eval Model Test loss: 0.05216662513299121\n",
      "First Out Loss: 0.07167891081836489\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.747s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 166\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006777308604103469\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006769879074353311\n",
      "Eval Model Test loss: 0.052201665834420256\n",
      "First Out Loss: 0.07172203333013588\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.490s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 167\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0067776404321193695\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0067683791276067495\n",
      "Eval Model Test loss: 0.05218058959063557\n",
      "First Out Loss: 0.07170036973224746\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.390s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 168\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006777599769910532\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006768677590621842\n",
      "Eval Model Test loss: 0.0522384038195014\n",
      "First Out Loss: 0.07184352622263962\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.706s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 169\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006775874029179769\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0067682725429120995\n",
      "Eval Model Test loss: 0.052251679305401116\n",
      "First Out Loss: 0.07182360875109832\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.487s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 170\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006775494542948547\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006763503071852028\n",
      "Eval Model Test loss: 0.05216495496117406\n",
      "First Out Loss: 0.07168670557439327\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.540s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 171\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006773005029009212\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006766136347626646\n",
      "Eval Model Test loss: 0.05220840985162391\n",
      "First Out Loss: 0.07176627756820785\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 9.172s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 172\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0067745009548075144\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006763604922323591\n",
      "Eval Model Test loss: 0.05223750633498033\n",
      "First Out Loss: 0.07177817097140683\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 9.123s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 173\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006774761608713085\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006764238881361153\n",
      "Eval Model Test loss: 0.052277129557397634\n",
      "First Out Loss: 0.07178130290574497\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.433s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 174\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006774247546369831\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006764703223274814\n",
      "Eval Model Test loss: 0.05228282097313139\n",
      "First Out Loss: 0.07184925716784266\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.494s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 175\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006772734158273254\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006764494969199101\n",
      "Eval Model Test loss: 0.052250121927095786\n",
      "First Out Loss: 0.0717794599218501\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.394s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 176\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006772966018789226\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0067648851804228294\n",
      "Eval Model Test loss: 0.05227269232273102\n",
      "First Out Loss: 0.07180196212397681\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.811s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 177\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006772174333621349\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006760726359465884\n",
      "Eval Model Test loss: 0.05224821002533039\n",
      "First Out Loss: 0.07173668655256431\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.712s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 178\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006772440170780534\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006761414503368239\n",
      "Eval Model Test loss: 0.052274915700157486\n",
      "First Out Loss: 0.07177674749659167\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 7.936s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 179\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006772415196922209\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006760816865911086\n",
      "Eval Model Test loss: 0.05230143583483166\n",
      "First Out Loss: 0.07177042340238889\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.494s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 180\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006770384309458591\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0067606894040687215\n",
      "Eval Model Test loss: 0.052274459041655064\n",
      "First Out Loss: 0.07174928796788056\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.645s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 181\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00677128483740879\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006760886611623896\n",
      "Eval Model Test loss: 0.052263025297886796\n",
      "First Out Loss: 0.07172853209906155\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.747s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 182\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0067716008273973356\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006759842094551358\n",
      "Eval Model Test loss: 0.05231990096055799\n",
      "First Out Loss: 0.07181508694258001\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.558s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 183\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006769971655947822\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0067613113335230285\n",
      "Eval Model Test loss: 0.052279211994674474\n",
      "First Out Loss: 0.07174497470259666\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.887s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 184\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0067698317801668535\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006758672896669143\n",
      "Eval Model Test loss: 0.05231389879352517\n",
      "First Out Loss: 0.07175588690572315\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.510s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 185\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006769072774442888\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006756654086833199\n",
      "Eval Model Test loss: 0.0523270545527339\n",
      "First Out Loss: 0.07173016977806886\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.719s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 186\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006768258216436065\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006758322758186195\n",
      "Eval Model Test loss: 0.052300776768889695\n",
      "First Out Loss: 0.07177687560518582\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 9.417s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 187\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006766830715129063\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006755749462172389\n",
      "Eval Model Test loss: 0.05230759808586703\n",
      "First Out Loss: 0.07177492665747802\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.496s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 188\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006764792720787227\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006757235296794938\n",
      "Eval Model Test loss: 0.052329319425755076\n",
      "First Out Loss: 0.0717797614634037\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 9.026s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 189\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006765611713663453\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0067584158904436566\n",
      "Eval Model Test loss: 0.05233605330189069\n",
      "First Out Loss: 0.0718122250917885\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 9.124s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 190\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006763398098493261\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006755339305123521\n",
      "Eval Model Test loss: 0.05235155671834946\n",
      "First Out Loss: 0.07180502576132615\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 9.443s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 191\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006763404906017794\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006755689301321076\n",
      "Eval Model Test loss: 0.052362619899213314\n",
      "First Out Loss: 0.07176721965273221\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.446s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 192\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006762495092559783\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006753689803493519\n",
      "Eval Model Test loss: 0.052308652756942645\n",
      "First Out Loss: 0.0717499843902058\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 9.000s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 193\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00676191289399174\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006752620295931895\n",
      "Eval Model Test loss: 0.05233847380926212\n",
      "First Out Loss: 0.07177605686916246\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.276s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 194\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00676218650880314\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006752923609585398\n",
      "Eval Model Test loss: 0.05235822954111629\n",
      "First Out Loss: 0.07176982342369026\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.814s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 195\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006758761109917292\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006753595144901838\n",
      "Eval Model Test loss: 0.05240603939940532\n",
      "First Out Loss: 0.07185915443632337\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.474s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 196\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006757990856255803\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006753056116091709\n",
      "Eval Model Test loss: 0.05234261726339658\n",
      "First Out Loss: 0.07176282670762804\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.650s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 197\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006757849095655339\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006752392729847795\n",
      "Eval Model Test loss: 0.05237191946556171\n",
      "First Out Loss: 0.07175334708558188\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.367s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 198\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006756939531658732\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006750976084731519\n",
      "Eval Model Test loss: 0.05236158147454262\n",
      "First Out Loss: 0.07179212963415517\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 7.966s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 199\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006754153252889712\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006750754326478475\n",
      "Eval Model Test loss: 0.05234815180301666\n",
      "First Out Loss: 0.07180173881351948\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.133s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 200\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0067547969132040935\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006749740258480112\n",
      "Eval Model Test loss: 0.05234766182386213\n",
      "First Out Loss: 0.07177314886616336\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.224s\n"
     ]
    }
   ],
   "source": [
    "trainer.train(n_epochs=n_epochs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "model = ForcastingQuantInferenceWrapper(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "torch.save(model, model_path)\n",
    "torch.cuda.empty_cache()\n",
    "del model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
