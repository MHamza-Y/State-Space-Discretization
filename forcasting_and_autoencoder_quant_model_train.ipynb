{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from state_quantization.dataset import load_dataset\n",
    "from state_quantization.dataset import DynamicsModelDataset\n",
    "from state_quantization.forcasting_models import LSTMForcasting\n",
    "from state_quantization.quantization_models import DiscAutoEncoder\n",
    "from state_quantization.forcasting_quantization_models import ForcastingQuant\n",
    "from state_quantization.trainer import ForcastingQuantTrainer\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from state_quantization.train import train_model, test_step\n",
    "from state_quantization.eval import eval_model, compare_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "print(f\"Using Device: {device}\")\n",
    "torch.backends.cudnn.benchmark = True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clipping y\n",
      "torch.Size([672000, 39, 6])\n",
      "torch.Size([672000, 10, 2])\n",
      "torch.Size([288000, 39, 6])\n",
      "torch.Size([288000, 10, 2])\n",
      "{'batch_size': 8000, 'shuffle': True, 'num_workers': 0, 'drop_last': True, 'pin_memory': True}\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[ 1.6728, -0.8214],\n        [ 1.6070, -0.8535],\n        [ 1.7155, -0.8366],\n        [ 1.7236, -0.8397],\n        [ 1.7005, -0.8373],\n        [ 1.6969, -0.8373],\n        [ 1.8305, -0.8712],\n        [ 1.7238, -0.8689],\n        [ 1.8825, -0.8338],\n        [ 1.7376, -0.8298]])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_input_key = 'merged_input'\n",
    "dataset_output_key = 'merged_output'\n",
    "dataset_file_path = 'tmp/ib-out/ib-samples-la.npy'\n",
    "normalized_data_params_save_path = 'state_quantization/NormalizeInputConfigs.pkl'\n",
    "dataset_device = 'cpu'\n",
    "y_indexes = [4, 6]\n",
    "\n",
    "train_dataset, val_dataset = load_dataset(file_path=dataset_file_path, input_key=dataset_input_key,\n",
    "                                          output_key=dataset_output_key, dataset_class=DynamicsModelDataset,\n",
    "                                          normalize=True, device=dataset_device, y_clip_range=y_indexes,\n",
    "                                          normalized_data_params_save_path=normalized_data_params_save_path)\n",
    "\n",
    "batch_size = 8000\n",
    "params = {'batch_size': batch_size,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 0,\n",
    "          'drop_last': True,\n",
    "          'pin_memory': not train_dataset.x.is_cuda}\n",
    "print(params)\n",
    "train_loader = DataLoader(train_dataset, **params)\n",
    "val_loader = DataLoader(val_dataset, **params)\n",
    "train_dataset.y[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out Size:2\n",
      "LSTM Layers\n",
      "ModuleList(\n",
      "  (0): LSTMCell(6, 20)\n",
      ")\n",
      "LSTM Dropout Layers\n",
      "ModuleList()\n",
      "Fully Connected Layers\n",
      "Sequential(\n",
      "  (0): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (1): GELU(approximate=none)\n",
      "  (2): Dropout(p=0.1, inplace=False)\n",
      "  (3): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (4): GELU(approximate=none)\n",
      "  (5): Dropout(p=0.1, inplace=False)\n",
      "  (6): Linear(in_features=20, out_features=2, bias=True)\n",
      ")\n",
      "[40, 20, 10]\n",
      "[10, 20, 40]\n",
      "Encoder Layers\n",
      "Sequential(\n",
      "  (0): Linear(in_features=40, out_features=40, bias=True)\n",
      "  (1): GELU(approximate=none)\n",
      "  (2): Dropout(p=0.0, inplace=False)\n",
      "  (3): Linear(in_features=40, out_features=20, bias=True)\n",
      "  (4): GELU(approximate=none)\n",
      "  (5): Dropout(p=0.0, inplace=False)\n",
      "  (6): Linear(in_features=20, out_features=10, bias=True)\n",
      "  (7): GELU(approximate=none)\n",
      "  (8): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "Bottleneck Layers\n",
      "Sequential(\n",
      "  (0): Linear(in_features=10, out_features=20, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): StraightThroughEstimator()\n",
      ")\n",
      "Decoded Layers\n",
      "Sequential(\n",
      "  (0): Linear(in_features=20, out_features=10, bias=True)\n",
      "  (1): GELU(approximate=none)\n",
      "  (2): Dropout(p=0.0, inplace=False)\n",
      "  (3): Linear(in_features=10, out_features=20, bias=True)\n",
      "  (4): GELU(approximate=none)\n",
      "  (5): Dropout(p=0.0, inplace=False)\n",
      "  (6): Linear(in_features=20, out_features=40, bias=True)\n",
      "  (7): GELU(approximate=none)\n",
      "  (8): Dropout(p=0.0, inplace=False)\n",
      "  (9): Linear(in_features=40, out_features=40, bias=True)\n",
      ")\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "model_path = 'state_quantization/model'\n",
    "\n",
    "num_of_features = train_dataset.get_features_size()\n",
    "seq_len = train_dataset.get_seq_len()\n",
    "hidden_size = 20\n",
    "out_size = train_dataset.get_output_feature_size()\n",
    "print(f'Out Size:{out_size}')\n",
    "look_ahead = train_dataset.get_look_ahead_size()\n",
    "n_layers = 1\n",
    "dropout = 0.1\n",
    "\n",
    "forcasting_model = LSTMForcasting(features=num_of_features, hidden_size=hidden_size, out_size=out_size, seq_len=seq_len,\n",
    "                                  look_ahead=look_ahead, dropout=dropout, n_layers=n_layers)\n",
    "\n",
    "disc_autoencoder_input_size = hidden_size * 2\n",
    "bottleneck_size = 20\n",
    "ae_dropout = 0.0\n",
    "disc_autoencoder = DiscAutoEncoder(input_size=disc_autoencoder_input_size, bottleneck_size=bottleneck_size,\n",
    "                                   dropout=ae_dropout)\n",
    "\n",
    "model = ForcastingQuant(forcasting_model=forcasting_model, autoencoder_quant_model=disc_autoencoder).to(device=device)\n",
    "\n",
    "load_to_gpu = model.is_cuda() and not train_dataset.x.is_cuda\n",
    "print(load_to_gpu)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Trainer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "gamma = 0.1\n",
    "\n",
    "forecasting_learning_rate = 1e-3\n",
    "autoencoder_learning_rate = 1e-3\n",
    "\n",
    "forecasting_lr_milestones = [35]\n",
    "autoencoder_lr_milestones = [100, 150]\n",
    "forecasting_optimizer = torch.optim.Adam(model.forcasting_model.parameters(),\n",
    "                                         lr=forecasting_learning_rate)\n",
    "autoencoder_optimizer = torch.optim.Adam(model.autoencoder_quant_model.parameters(),\n",
    "                                         lr=autoencoder_learning_rate)\n",
    "forecasting_lr_scheduler = MultiStepLR(forecasting_optimizer, milestones=forecasting_lr_milestones, gamma=gamma)\n",
    "autoencoder_lr_scheduler = MultiStepLR(autoencoder_optimizer, milestones=autoencoder_lr_milestones, gamma=gamma)\n",
    "n_epochs = 200\n",
    "\n",
    "trainer = ForcastingQuantTrainer(forcasting_quant_model=model, train_loader=train_loader, test_loader=val_loader,\n",
    "                                 load_to_gpu=load_to_gpu, forecasting_optimizer=forecasting_optimizer,\n",
    "                                 forecasting_lr_scheduler=forecasting_lr_scheduler,\n",
    "                                 autoencoder_lr_scheduler=autoencoder_lr_scheduler,\n",
    "                                 autoencoder_optimizer=autoencoder_optimizer,autoencoder_training_start=50)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained test\n",
      "--------\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 1.0063083602322473\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 1\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.7652150293191274\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.39165402121014065\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.020s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 2\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "Forcasting Train loss: 0.22361169276492937\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.09681832873158985\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.090s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 3\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.11247902168404489\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.07131622524725066\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.814s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 4\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.09254223729173343\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.05791924003925589\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.492s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 5\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.07998624390789441\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.04906853226323923\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.967s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 6\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.07165306460644517\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.042846108993722334\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.161s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 7\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.06654583254740351\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03961052714536587\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.833s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 8\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.06346889381252584\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.038178874283201165\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.735s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 9\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.06121647437768323\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03712477017607954\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.835s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 10\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.059744225593195074\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03548032831814554\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.083s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 11\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05832853926611798\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.0352479542295138\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.788s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 12\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.057412698244055115\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03438143525272608\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.952s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 13\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05648504951525302\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03381618495202727\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.224s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 14\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05585936984668175\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.0332183503649301\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.338s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 15\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.0551333852289688\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03338274825364351\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.931s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 16\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05445914542568581\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03242317333610521\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.022s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 17\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05395552143454552\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.032002698371393815\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.087s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 18\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.053377515237246244\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03189428264482154\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.103s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 19\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.053026210117552965\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03151612796096338\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.952s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 20\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05242782977542707\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03128111372805304\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.788s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 21\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05199722604205211\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.031082763181378443\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.857s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 22\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.051627262051971184\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.030712022446095943\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.177s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 23\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.051320734877316726\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03061558326913251\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.218s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 24\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05101496411398763\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03019187402808004\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.169s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 25\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.050676519760773295\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.030357201480203204\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.891s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 26\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.050329871919183505\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.030072441997213498\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.828s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 27\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.049995042161927336\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.030355297442939546\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.088s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 28\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04988216591023263\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02948813181784418\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.451s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 29\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04957010539337283\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02954419060713715\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.817s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 30\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.049249280066717235\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.029639083943847153\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.582s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 31\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.0490476196809184\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.029362543020397425\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.825s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 32\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04888370406946966\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.029132775600171752\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.945s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 33\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04865047153795049\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028945639884720247\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.917s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 34\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04843176967863526\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028738232277747657\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.931s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 35\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04833090292023761\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.029268399243139558\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.961s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 36\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.047997581373367994\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028659120460765228\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.922s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 37\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04794814694850218\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028707887252999678\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.940s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 38\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04786478178132148\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028715062524295516\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.973s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 39\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.047942458385867734\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028661423311051395\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.891s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 40\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04785312486014196\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02859639034916957\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.702s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 41\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.0478121806823072\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028622890149967536\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.798s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 42\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.0478309401355329\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028641972225159407\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.926s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 43\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.047830417131384216\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028613184216535754\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.901s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 44\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.0478263862342352\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028575286217447784\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.935s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 45\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04778662935963699\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028506338078942563\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.739s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 46\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04777878531742664\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [6]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_epochs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/StateCompression/state_quantization/trainer.py:50\u001B[0m, in \u001B[0;36mTrainer.train\u001B[0;34m(self, n_epochs)\u001B[0m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpre_epoch_hook()\n\u001B[1;32m     49\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining_step()\n\u001B[0;32m---> 50\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluation_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpost_epoch_hook()\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwriter\u001B[38;5;241m.\u001B[39mflush()\n",
      "File \u001B[0;32m~/PycharmProjects/StateCompression/state_quantization/trainer.py:138\u001B[0m, in \u001B[0;36mForcastingQuantTrainer.evaluation_step\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    136\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39meval()\n\u001B[1;32m    137\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m--> 138\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m X, y \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtest_loader:\n\u001B[1;32m    139\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mload_to_gpu:\n\u001B[1;32m    140\u001B[0m             X, y \u001B[38;5;241m=\u001B[39m X\u001B[38;5;241m.\u001B[39mcuda(non_blocking\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m), y\u001B[38;5;241m.\u001B[39mcuda(non_blocking\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:652\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    649\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    650\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    651\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 652\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    653\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    654\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    655\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    656\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:692\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    690\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    691\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 692\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    693\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    694\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m~/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch\u001B[39m(\u001B[38;5;28mself\u001B[39m, possibly_batched_index):\n\u001B[1;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[0;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[0;32m~/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch\u001B[39m(\u001B[38;5;28mself\u001B[39m, possibly_batched_index):\n\u001B[1;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[0;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[0;32m~/PycharmProjects/StateCompression/state_quantization/dataset.py:21\u001B[0m, in \u001B[0;36mDynamicsModelDataset.__getitem__\u001B[0;34m(self, index)\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, index) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m T_co:\n\u001B[0;32m---> 21\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx[index], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39my[index]\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train(n_epochs=n_epochs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "torch.save(model, model_path)\n",
    "torch.cuda.empty_cache()\n",
    "del model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 39, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n",
      "WARNING: The shape inference of prim::PythonOp type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "ONNX export failed: Couldn't export Python operator STEFunction\n\nDefined at:\n/home/hamza/PycharmProjects/StateCompression/state_quantization/activations.py(21): forward\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/module.py(1118): _slow_forward\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/module.py(1130): _call_impl\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/container.py(139): forward\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/module.py(1118): _slow_forward\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/module.py(1130): _call_impl\n/home/hamza/PycharmProjects/StateCompression/state_quantization/quantization_models.py(201): forward\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/module.py(1118): _slow_forward\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/module.py(1130): _call_impl\n/home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_quantization_models.py(19): forward\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/module.py(1118): _slow_forward\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/module.py(1130): _call_impl\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/jit/_trace.py(118): wrapper\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/jit/_trace.py(127): forward\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/module.py(1130): _call_impl\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/jit/_trace.py(1175): _get_trace_graph\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/onnx/utils.py(517): _trace_and_get_graph_from_model\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/onnx/utils.py(602): _create_jit_graph\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/onnx/utils.py(727): _model_to_graph\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/onnx/utils.py(1074): _export\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/onnx/utils.py(163): export\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/onnx/__init__.py(350): export\n/tmp/ipykernel_39079/2477727706.py(7): <cell line: 7>\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3398): run_code\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3338): run_ast_nodes\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3135): run_cell_async\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/IPython/core/async_helpers.py(129): _pseudo_sync_runner\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py(2936): _run_cell\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py(2881): run_cell\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/ipykernel/zmqshell.py(528): run_cell\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/ipykernel/ipkernel.py(383): do_execute\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/ipykernel/kernelbase.py(730): execute_request\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/ipykernel/kernelbase.py(406): dispatch_shell\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/ipykernel/kernelbase.py(499): process_one\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/ipykernel/kernelbase.py(510): dispatch_queue\n/usr/lib/python3.8/asyncio/events.py(81): _run\n/usr/lib/python3.8/asyncio/base_events.py(1859): _run_once\n/usr/lib/python3.8/asyncio/base_events.py(570): run_forever\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/tornado/platform/asyncio.py(215): start\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/ipykernel/kernelapp.py(712): start\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/traitlets/config/application.py(976): launch_instance\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/ipykernel_launcher.py(17): <module>\n/usr/lib/python3.8/runpy.py(87): _run_code\n/usr/lib/python3.8/runpy.py(194): _run_module_as_main\n\n\nGraph we tried to export:\ngraph(%onnx::Gather_0 : Float(2, 39, 6, strides=[234, 6, 1], requires_grad=0, device=cpu),\n      %forcasting_model.lstm_layers.0.weight_ih : Float(80, 6, strides=[6, 1], requires_grad=1, device=cpu),\n      %forcasting_model.lstm_layers.0.weight_hh : Float(80, 20, strides=[20, 1], requires_grad=1, device=cpu),\n      %forcasting_model.lstm_layers.0.bias_ih : Float(80, strides=[1], requires_grad=1, device=cpu),\n      %forcasting_model.lstm_layers.0.bias_hh : Float(80, strides=[1], requires_grad=1, device=cpu),\n      %forcasting_model.fully_connected_layers.0.weight : Float(20, 20, strides=[20, 1], requires_grad=1, device=cpu),\n      %forcasting_model.fully_connected_layers.0.bias : Float(20, strides=[1], requires_grad=1, device=cpu),\n      %forcasting_model.fully_connected_layers.3.weight : Float(20, 20, strides=[20, 1], requires_grad=1, device=cpu),\n      %forcasting_model.fully_connected_layers.3.bias : Float(20, strides=[1], requires_grad=1, device=cpu),\n      %forcasting_model.fully_connected_layers.6.weight : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu),\n      %forcasting_model.fully_connected_layers.6.bias : Float(2, strides=[1], requires_grad=1, device=cpu),\n      %autoencoder_quant_model.encoder_layers.0.weight : Float(40, 40, strides=[40, 1], requires_grad=1, device=cpu),\n      %autoencoder_quant_model.encoder_layers.0.bias : Float(40, strides=[1], requires_grad=1, device=cpu),\n      %autoencoder_quant_model.encoder_layers.3.weight : Float(20, 40, strides=[40, 1], requires_grad=1, device=cpu),\n      %autoencoder_quant_model.encoder_layers.3.bias : Float(20, strides=[1], requires_grad=1, device=cpu),\n      %autoencoder_quant_model.encoder_layers.6.weight : Float(10, 20, strides=[20, 1], requires_grad=1, device=cpu),\n      %autoencoder_quant_model.encoder_layers.6.bias : Float(10, strides=[1], requires_grad=1, device=cpu),\n      %autoencoder_quant_model.bottleneck_layers.0.weight : Float(20, 10, strides=[10, 1], requires_grad=1, device=cpu),\n      %autoencoder_quant_model.bottleneck_layers.0.bias : Float(20, strides=[1], requires_grad=1, device=cpu),\n      %autoencoder_quant_model.decoder_layers.0.weight : Float(10, 20, strides=[20, 1], requires_grad=1, device=cpu),\n      %autoencoder_quant_model.decoder_layers.0.bias : Float(10, strides=[1], requires_grad=1, device=cpu),\n      %autoencoder_quant_model.decoder_layers.3.weight : Float(20, 10, strides=[10, 1], requires_grad=1, device=cpu),\n      %autoencoder_quant_model.decoder_layers.3.bias : Float(20, strides=[1], requires_grad=1, device=cpu),\n      %autoencoder_quant_model.decoder_layers.6.weight : Float(40, 20, strides=[20, 1], requires_grad=1, device=cpu),\n      %autoencoder_quant_model.decoder_layers.6.bias : Float(40, strides=[1], requires_grad=1, device=cpu),\n      %autoencoder_quant_model.decoder_layers.9.weight : Float(40, 40, strides=[40, 1], requires_grad=1, device=cpu),\n      %autoencoder_quant_model.decoder_layers.9.bias : Float(40, strides=[1], requires_grad=1, device=cpu),\n      %onnx::Equal_1401 : Long(2, strides=[1], requires_grad=0, device=cpu),\n      %onnx::ConstantOfShape_1402 : Long(1, strides=[1], requires_grad=0, device=cpu)):\n  %onnx::ConstantOfShape_1435 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::ConstantOfShape_1402)\n  %onnx::ConstantOfShape_1434 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::ConstantOfShape_1402)\n  %onnx::Equal_1433 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::Equal_1401)\n  %onnx::ConstantOfShape_1431 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::ConstantOfShape_1402)\n  %onnx::ConstantOfShape_1430 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::ConstantOfShape_1402)\n  %onnx::Equal_1429 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::Equal_1401)\n  %onnx::ConstantOfShape_1427 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::ConstantOfShape_1402)\n  %onnx::ConstantOfShape_1426 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::ConstantOfShape_1402)\n  %onnx::Equal_1425 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::Equal_1401)\n  %onnx::ConstantOfShape_1423 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::ConstantOfShape_1402)\n  %onnx::ConstantOfShape_1422 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::ConstantOfShape_1402)\n  %onnx::Equal_1421 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::Equal_1401)\n  %onnx::ConstantOfShape_1419 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::ConstantOfShape_1402)\n  %onnx::ConstantOfShape_1418 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::ConstantOfShape_1402)\n  %onnx::Equal_1417 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::Equal_1401)\n  %onnx::ConstantOfShape_1415 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::ConstantOfShape_1402)\n  %onnx::ConstantOfShape_1414 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::ConstantOfShape_1402)\n  %onnx::Equal_1413 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::Equal_1401)\n  %onnx::ConstantOfShape_1411 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::ConstantOfShape_1402)\n  %onnx::ConstantOfShape_1410 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::ConstantOfShape_1402)\n  %onnx::Equal_1409 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::Equal_1401)\n  %onnx::ConstantOfShape_1407 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::ConstantOfShape_1402)\n  %onnx::ConstantOfShape_1406 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::ConstantOfShape_1402)\n  %onnx::Equal_1405 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::Equal_1401)\n  %onnx::ConstantOfShape_1403 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::ConstantOfShape_1402)\n  %onnx::Gather_27 : Long(device=cpu) = onnx::Constant[value={0}]()\n  %onnx::Gemm_28 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_27) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Gemm_29 : Float(2, 20, strides=[20, 1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:118:0\n  %onnx::Add_30 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_29, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_31 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_28, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_32 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_30, %onnx::Add_31) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_33 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_34 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_35 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_36 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_37 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_32, %onnx::Split_33) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_38 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_34) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_39 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_35) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_40 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_36) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_41 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_37) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_42 : Float(2, 20, strides=[20, 1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:119:0\n  %onnx::Add_43 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_39, %onnx::Mul_42) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_44 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_38, %onnx::Mul_40) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_45 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_43, %onnx::Add_44) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_46 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_45) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_47 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_41, %onnx::Mul_46) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_48 : Long(device=cpu) = onnx::Constant[value={1}]()\n  %onnx::Gemm_49 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_48) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_50 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_47, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_51 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_49, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_52 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_50, %onnx::Add_51) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_53 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_54 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_55 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_56 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_57 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_52, %onnx::Split_53) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_58 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_54) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_59 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_55) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_60 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_56) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_61 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_57) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_62 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_59, %onnx::Tanh_45) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_63 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_58, %onnx::Mul_60) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_64 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_62, %onnx::Add_63) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_65 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_64) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_66 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_61, %onnx::Mul_65) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_67 : Long(device=cpu) = onnx::Constant[value={2}]()\n  %onnx::Gemm_68 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_67) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_69 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_66, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_70 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_68, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_71 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_69, %onnx::Add_70) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_72 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_73 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_74 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_75 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_76 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_71, %onnx::Split_72) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_77 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_73) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_78 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_74) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_79 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_75) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_80 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_76) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_81 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_78, %onnx::Tanh_64) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_82 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_77, %onnx::Mul_79) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_83 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_81, %onnx::Add_82) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_84 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_83) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_85 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_80, %onnx::Mul_84) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_86 : Long(device=cpu) = onnx::Constant[value={3}]()\n  %onnx::Gemm_87 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_86) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_88 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_85, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_89 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_87, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_90 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_88, %onnx::Add_89) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_91 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_92 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_93 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_94 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_95 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_90, %onnx::Split_91) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_96 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_92) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_97 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_93) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_98 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_94) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_99 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_95) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_100 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_97, %onnx::Tanh_83) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_101 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_96, %onnx::Mul_98) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_102 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_100, %onnx::Add_101) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_103 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_102) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_104 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_99, %onnx::Mul_103) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_105 : Long(device=cpu) = onnx::Constant[value={4}]()\n  %onnx::Gemm_106 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_105) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_107 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_104, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_108 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_106, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_109 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_107, %onnx::Add_108) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_110 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_111 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_112 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_113 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_114 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_109, %onnx::Split_110) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_115 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_111) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_116 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_112) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_117 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_113) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_118 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_114) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_119 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_116, %onnx::Tanh_102) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_120 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_115, %onnx::Mul_117) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_121 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_119, %onnx::Add_120) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_122 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_121) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_123 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_118, %onnx::Mul_122) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_124 : Long(device=cpu) = onnx::Constant[value={5}]()\n  %onnx::Gemm_125 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_124) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_126 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_123, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_127 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_125, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_128 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_126, %onnx::Add_127) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_129 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_130 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_131 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_132 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_133 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_128, %onnx::Split_129) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_134 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_130) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_135 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_131) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_136 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_132) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_137 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_133) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_138 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_135, %onnx::Tanh_121) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_139 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_134, %onnx::Mul_136) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_140 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_138, %onnx::Add_139) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_141 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_140) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_142 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_137, %onnx::Mul_141) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_143 : Long(device=cpu) = onnx::Constant[value={6}]()\n  %onnx::Gemm_144 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_143) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_145 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_142, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_146 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_144, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_147 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_145, %onnx::Add_146) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_148 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_149 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_150 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_151 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_152 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_147, %onnx::Split_148) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_153 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_149) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_154 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_150) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_155 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_151) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_156 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_152) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_157 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_154, %onnx::Tanh_140) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_158 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_153, %onnx::Mul_155) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_159 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_157, %onnx::Add_158) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_160 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_159) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_161 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_156, %onnx::Mul_160) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_162 : Long(device=cpu) = onnx::Constant[value={7}]()\n  %onnx::Gemm_163 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_162) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_164 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_161, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_165 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_163, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_166 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_164, %onnx::Add_165) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_167 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_168 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_169 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_170 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_171 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_166, %onnx::Split_167) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_172 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_168) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_173 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_169) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_174 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_170) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_175 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_171) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_176 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_173, %onnx::Tanh_159) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_177 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_172, %onnx::Mul_174) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_178 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_176, %onnx::Add_177) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_179 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_178) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_180 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_175, %onnx::Mul_179) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_181 : Long(device=cpu) = onnx::Constant[value={8}]()\n  %onnx::Gemm_182 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_181) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_183 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_180, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_184 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_182, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_185 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_183, %onnx::Add_184) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_186 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_187 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_188 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_189 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_190 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_185, %onnx::Split_186) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_191 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_187) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_192 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_188) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_193 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_189) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_194 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_190) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_195 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_192, %onnx::Tanh_178) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_196 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_191, %onnx::Mul_193) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_197 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_195, %onnx::Add_196) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_198 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_197) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_199 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_194, %onnx::Mul_198) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_200 : Long(device=cpu) = onnx::Constant[value={9}]()\n  %onnx::Gemm_201 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_200) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_202 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_199, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_203 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_201, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_204 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_202, %onnx::Add_203) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_205 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_206 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_207 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_208 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_209 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_204, %onnx::Split_205) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_210 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_206) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_211 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_207) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_212 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_208) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_213 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_209) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_214 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_211, %onnx::Tanh_197) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_215 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_210, %onnx::Mul_212) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_216 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_214, %onnx::Add_215) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_217 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_216) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_218 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_213, %onnx::Mul_217) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_219 : Long(device=cpu) = onnx::Constant[value={10}]()\n  %onnx::Gemm_220 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_219) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_221 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_218, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_222 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_220, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_223 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_221, %onnx::Add_222) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_224 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_225 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_226 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_227 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_228 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_223, %onnx::Split_224) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_229 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_225) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_230 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_226) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_231 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_227) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_232 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_228) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_233 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_230, %onnx::Tanh_216) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_234 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_229, %onnx::Mul_231) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_235 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_233, %onnx::Add_234) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_236 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_235) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_237 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_232, %onnx::Mul_236) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_238 : Long(device=cpu) = onnx::Constant[value={11}]()\n  %onnx::Gemm_239 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_238) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_240 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_237, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_241 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_239, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_242 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_240, %onnx::Add_241) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_243 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_244 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_245 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_246 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_247 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_242, %onnx::Split_243) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_248 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_244) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_249 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_245) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_250 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_246) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_251 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_247) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_252 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_249, %onnx::Tanh_235) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_253 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_248, %onnx::Mul_250) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_254 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_252, %onnx::Add_253) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_255 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_254) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_256 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_251, %onnx::Mul_255) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_257 : Long(device=cpu) = onnx::Constant[value={12}]()\n  %onnx::Gemm_258 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_257) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_259 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_256, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_260 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_258, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_261 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_259, %onnx::Add_260) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_262 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_263 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_264 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_265 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_266 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_261, %onnx::Split_262) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_267 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_263) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_268 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_264) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_269 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_265) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_270 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_266) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_271 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_268, %onnx::Tanh_254) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_272 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_267, %onnx::Mul_269) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_273 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_271, %onnx::Add_272) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_274 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_273) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_275 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_270, %onnx::Mul_274) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_276 : Long(device=cpu) = onnx::Constant[value={13}]()\n  %onnx::Gemm_277 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_276) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_278 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_275, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_279 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_277, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_280 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_278, %onnx::Add_279) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_281 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_282 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_283 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_284 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_285 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_280, %onnx::Split_281) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_286 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_282) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_287 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_283) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_288 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_284) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_289 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_285) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_290 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_287, %onnx::Tanh_273) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_291 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_286, %onnx::Mul_288) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_292 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_290, %onnx::Add_291) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_293 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_292) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_294 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_289, %onnx::Mul_293) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_295 : Long(device=cpu) = onnx::Constant[value={14}]()\n  %onnx::Gemm_296 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_295) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_297 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_294, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_298 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_296, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_299 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_297, %onnx::Add_298) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_300 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_301 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_302 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_303 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_304 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_299, %onnx::Split_300) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_305 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_301) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_306 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_302) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_307 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_303) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_308 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_304) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_309 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_306, %onnx::Tanh_292) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_310 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_305, %onnx::Mul_307) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_311 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_309, %onnx::Add_310) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_312 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_311) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_313 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_308, %onnx::Mul_312) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_314 : Long(device=cpu) = onnx::Constant[value={15}]()\n  %onnx::Gemm_315 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_314) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_316 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_313, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_317 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_315, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_318 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_316, %onnx::Add_317) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_319 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_320 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_321 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_322 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_323 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_318, %onnx::Split_319) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_324 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_320) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_325 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_321) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_326 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_322) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_327 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_323) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_328 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_325, %onnx::Tanh_311) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_329 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_324, %onnx::Mul_326) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_330 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_328, %onnx::Add_329) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_331 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_330) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_332 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_327, %onnx::Mul_331) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_333 : Long(device=cpu) = onnx::Constant[value={16}]()\n  %onnx::Gemm_334 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_333) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_335 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_332, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_336 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_334, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_337 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_335, %onnx::Add_336) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_338 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_339 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_340 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_341 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_342 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_337, %onnx::Split_338) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_343 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_339) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_344 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_340) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_345 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_341) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_346 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_342) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_347 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_344, %onnx::Tanh_330) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_348 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_343, %onnx::Mul_345) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_349 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_347, %onnx::Add_348) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_350 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_349) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_351 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_346, %onnx::Mul_350) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_352 : Long(device=cpu) = onnx::Constant[value={17}]()\n  %onnx::Gemm_353 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_352) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_354 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_351, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_355 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_353, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_356 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_354, %onnx::Add_355) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_357 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_358 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_359 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_360 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_361 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_356, %onnx::Split_357) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_362 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_358) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_363 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_359) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_364 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_360) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_365 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_361) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_366 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_363, %onnx::Tanh_349) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_367 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_362, %onnx::Mul_364) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_368 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_366, %onnx::Add_367) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_369 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_368) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_370 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_365, %onnx::Mul_369) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_371 : Long(device=cpu) = onnx::Constant[value={18}]()\n  %onnx::Gemm_372 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_371) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_373 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_370, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_374 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_372, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_375 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_373, %onnx::Add_374) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_376 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_377 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_378 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_379 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_380 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_375, %onnx::Split_376) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_381 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_377) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_382 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_378) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_383 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_379) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_384 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_380) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_385 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_382, %onnx::Tanh_368) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_386 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_381, %onnx::Mul_383) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_387 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_385, %onnx::Add_386) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_388 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_387) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_389 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_384, %onnx::Mul_388) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_390 : Long(device=cpu) = onnx::Constant[value={19}]()\n  %onnx::Gemm_391 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_390) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_392 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_389, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_393 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_391, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_394 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_392, %onnx::Add_393) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_395 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_396 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_397 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_398 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_399 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_394, %onnx::Split_395) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_400 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_396) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_401 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_397) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_402 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_398) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_403 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_399) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_404 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_401, %onnx::Tanh_387) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_405 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_400, %onnx::Mul_402) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_406 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_404, %onnx::Add_405) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_407 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_406) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_408 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_403, %onnx::Mul_407) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_409 : Long(device=cpu) = onnx::Constant[value={20}]()\n  %onnx::Gemm_410 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_409) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_411 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_408, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_412 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_410, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_413 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_411, %onnx::Add_412) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_414 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_415 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_416 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_417 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_418 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_413, %onnx::Split_414) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_419 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_415) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_420 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_416) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_421 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_417) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_422 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_418) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_423 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_420, %onnx::Tanh_406) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_424 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_419, %onnx::Mul_421) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_425 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_423, %onnx::Add_424) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_426 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_425) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_427 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_422, %onnx::Mul_426) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_428 : Long(device=cpu) = onnx::Constant[value={21}]()\n  %onnx::Gemm_429 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_428) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_430 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_427, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_431 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_429, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_432 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_430, %onnx::Add_431) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_433 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_434 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_435 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_436 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_437 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_432, %onnx::Split_433) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_438 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_434) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_439 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_435) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_440 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_436) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_441 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_437) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_442 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_439, %onnx::Tanh_425) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_443 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_438, %onnx::Mul_440) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_444 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_442, %onnx::Add_443) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_445 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_444) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_446 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_441, %onnx::Mul_445) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_447 : Long(device=cpu) = onnx::Constant[value={22}]()\n  %onnx::Gemm_448 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_447) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_449 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_446, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_450 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_448, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_451 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_449, %onnx::Add_450) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_452 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_453 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_454 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_455 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_456 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_451, %onnx::Split_452) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_457 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_453) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_458 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_454) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_459 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_455) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_460 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_456) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_461 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_458, %onnx::Tanh_444) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_462 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_457, %onnx::Mul_459) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_463 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_461, %onnx::Add_462) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_464 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_463) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_465 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_460, %onnx::Mul_464) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_466 : Long(device=cpu) = onnx::Constant[value={23}]()\n  %onnx::Gemm_467 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_466) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_468 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_465, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_469 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_467, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_470 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_468, %onnx::Add_469) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_471 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_472 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_473 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_474 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_475 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_470, %onnx::Split_471) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_476 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_472) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_477 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_473) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_478 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_474) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_479 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_475) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_480 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_477, %onnx::Tanh_463) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_481 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_476, %onnx::Mul_478) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_482 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_480, %onnx::Add_481) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_483 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_482) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_484 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_479, %onnx::Mul_483) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_485 : Long(device=cpu) = onnx::Constant[value={24}]()\n  %onnx::Gemm_486 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_485) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_487 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_484, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_488 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_486, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_489 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_487, %onnx::Add_488) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_490 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_491 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_492 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_493 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_494 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_489, %onnx::Split_490) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_495 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_491) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_496 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_492) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_497 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_493) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_498 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_494) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_499 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_496, %onnx::Tanh_482) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_500 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_495, %onnx::Mul_497) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_501 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_499, %onnx::Add_500) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_502 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_501) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_503 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_498, %onnx::Mul_502) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_504 : Long(device=cpu) = onnx::Constant[value={25}]()\n  %onnx::Gemm_505 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_504) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_506 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_503, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_507 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_505, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_508 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_506, %onnx::Add_507) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_509 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_510 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_511 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_512 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_513 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_508, %onnx::Split_509) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_514 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_510) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_515 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_511) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_516 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_512) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_517 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_513) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_518 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_515, %onnx::Tanh_501) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_519 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_514, %onnx::Mul_516) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_520 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_518, %onnx::Add_519) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_521 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_520) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_522 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_517, %onnx::Mul_521) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_523 : Long(device=cpu) = onnx::Constant[value={26}]()\n  %onnx::Gemm_524 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_523) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_525 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_522, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_526 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_524, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_527 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_525, %onnx::Add_526) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_528 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_529 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_530 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_531 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_532 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_527, %onnx::Split_528) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_533 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_529) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_534 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_530) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_535 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_531) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_536 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_532) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_537 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_534, %onnx::Tanh_520) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_538 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_533, %onnx::Mul_535) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_539 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_537, %onnx::Add_538) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_540 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_539) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_541 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_536, %onnx::Mul_540) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_542 : Long(device=cpu) = onnx::Constant[value={27}]()\n  %onnx::Gemm_543 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_542) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_544 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_541, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_545 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_543, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_546 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_544, %onnx::Add_545) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_547 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_548 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_549 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_550 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_551 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_546, %onnx::Split_547) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_552 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_548) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_553 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_549) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_554 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_550) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_555 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_551) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_556 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_553, %onnx::Tanh_539) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_557 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_552, %onnx::Mul_554) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_558 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_556, %onnx::Add_557) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_559 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_558) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_560 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_555, %onnx::Mul_559) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_561 : Long(device=cpu) = onnx::Constant[value={28}]()\n  %onnx::Gemm_562 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_561) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_563 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_560, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_564 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_562, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_565 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_563, %onnx::Add_564) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_566 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_567 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_568 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_569 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_570 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_565, %onnx::Split_566) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_571 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_567) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_572 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_568) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_573 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_569) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_574 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_570) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_575 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_572, %onnx::Tanh_558) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_576 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_571, %onnx::Mul_573) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_577 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_575, %onnx::Add_576) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_578 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_577) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_579 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_574, %onnx::Mul_578) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_580 : Long(device=cpu) = onnx::Constant[value={29}]()\n  %onnx::Gemm_581 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_580) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_582 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_579, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_583 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_581, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_584 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_582, %onnx::Add_583) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_585 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_586 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_587 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_588 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_589 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_584, %onnx::Split_585) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_590 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_586) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_591 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_587) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_592 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_588) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_593 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_589) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_594 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_591, %onnx::Tanh_577) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_595 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_590, %onnx::Mul_592) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_596 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_594, %onnx::Add_595) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_597 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_596) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Concat_598 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_593, %onnx::Mul_597) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_599 : Float(2, 40, strides=[40, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%onnx::Concat_598, %onnx::Tanh_596) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:88:0\n  %onnx::Div_600 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Concat_598, %forcasting_model.fully_connected_layers.0.weight, %forcasting_model.fully_connected_layers.0.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_601 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_602 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Div(%onnx::Div_600, %onnx::Div_601) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_603 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Erf(%onnx::Erf_602) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_604 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_605 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Add(%onnx::Add_603, %onnx::Add_604) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_606 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Mul(%onnx::Div_600, %onnx::Mul_605) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_607 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_606, %onnx::Mul_607) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Div_609 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input, %forcasting_model.fully_connected_layers.3.weight, %forcasting_model.fully_connected_layers.3.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_610 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_611 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Div(%onnx::Div_609, %onnx::Div_610) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_612 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Erf(%onnx::Erf_611) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_613 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_614 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Add(%onnx::Add_612, %onnx::Add_613) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_615 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Mul(%onnx::Div_609, %onnx::Mul_614) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_616 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.3 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_615, %onnx::Mul_616) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Unsqueeze_618 : Float(2, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.3, %forcasting_model.fully_connected_layers.6.weight, %forcasting_model.fully_connected_layers.6.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Unsqueeze_619 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:91:0\n  %onnx::Concat_620 : Float(2, 1, 2, strides=[2, 2, 1], requires_grad=1, device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_618, %onnx::Unsqueeze_619) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:91:0\n  %onnx::Gather_621 : Long(device=cpu) = onnx::Constant[value={30}]()\n  %onnx::Slice_622 : Float(2, 6, strides=[6, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_621) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:93:0\n  %onnx::Slice_623 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_624 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_625 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={6}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_626 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Shape_627 : Float(2, 2, strides=[6, 1], requires_grad=0, device=cpu) = onnx::Slice(%onnx::Slice_622, %onnx::Slice_624, %onnx::Slice_625, %onnx::Slice_623, %onnx::Slice_626) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_628 : Long(2, strides=[1], device=cpu) = onnx::Shape(%onnx::Shape_627) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Reshape_629 : Float(2, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Expand(%onnx::Unsqueeze_618, %onnx::Expand_628) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_630 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 4  5 [ CPULongType{2} ]]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_631 : Long(2, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Constant[value= 0  1 [ CPULongType{2,1} ]]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_637 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%onnx::ConstantOfShape_1402) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_638 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Equal_639 : Long(2, strides=[1], device=cpu) = onnx::Mul(%onnx::Mul_637, %onnx::Mul_638) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Where_640 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%onnx::Equal_1401, %onnx::Equal_639) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_641 : Long(2, strides=[1], device=cpu) = onnx::Where(%onnx::Where_640, %onnx::Mul_637, %onnx::Equal_1401) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_642 : Long(2, 2, device=cpu) = onnx::Expand(%onnx::Expand_631, %onnx::Expand_641) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_643 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_644 : Long(2, 2, 1, strides=[2, 1, 1], device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_642, %onnx::Unsqueeze_643) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_646 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%onnx::ConstantOfShape_1403) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_647 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Equal_648 : Long(2, strides=[1], device=cpu) = onnx::Mul(%onnx::Mul_646, %onnx::Mul_647) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Where_649 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%onnx::Equal_1401, %onnx::Equal_648) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_650 : Long(2, strides=[1], device=cpu) = onnx::Where(%onnx::Where_649, %onnx::Mul_646, %onnx::Equal_1401) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_651 : Long(2, 2, device=cpu) = onnx::Expand(%onnx::Expand_630, %onnx::Expand_650) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_652 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_653 : Long(2, 2, 1, strides=[2, 1, 1], device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_651, %onnx::Unsqueeze_652) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::ScatterND_654 : Long(2, 2, 2, strides=[4, 2, 1], device=cpu) = onnx::Concat[axis=-1](%onnx::Concat_644, %onnx::Concat_653) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_655 : Long(2, strides=[1], device=cpu) = onnx::Shape(%onnx::Slice_622) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_656 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_657 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_658 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_659 : Long(0, strides=[1], device=cpu) = onnx::Slice(%onnx::Slice_655, %onnx::Slice_657, %onnx::Slice_658, %onnx::Slice_656) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Reshape_660 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Equal_1401, %onnx::Concat_659) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::ScatterND_661 : Float(2, 2, device=cpu) = onnx::Reshape(%onnx::Reshape_629, %onnx::Reshape_660) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Gemm_662 : Float(2, 6, strides=[6, 1], requires_grad=1, device=cpu) = onnx::ScatterND(%onnx::Slice_622, %onnx::ScatterND_654, %onnx::ScatterND_661) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Add_663 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Concat_598, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_664 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_662, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_665 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_663, %onnx::Add_664) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_666 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_667 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_668 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_669 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_670 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_665, %onnx::Split_666) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_671 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_667) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_672 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_668) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_673 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_669) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_674 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_670) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_675 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_672, %onnx::Tanh_596) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_676 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_671, %onnx::Mul_673) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_677 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_675, %onnx::Add_676) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_678 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_677) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_679 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_674, %onnx::Mul_678) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Div_680 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_679, %forcasting_model.fully_connected_layers.0.weight, %forcasting_model.fully_connected_layers.0.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_681 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_682 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Div(%onnx::Div_680, %onnx::Div_681) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_683 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Erf(%onnx::Erf_682) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_684 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_685 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Add(%onnx::Add_683, %onnx::Add_684) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_686 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Mul(%onnx::Div_680, %onnx::Mul_685) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_687 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.7 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_686, %onnx::Mul_687) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Div_689 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.7, %forcasting_model.fully_connected_layers.3.weight, %forcasting_model.fully_connected_layers.3.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_690 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_691 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Div(%onnx::Div_689, %onnx::Div_690) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_692 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Erf(%onnx::Erf_691) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_693 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_694 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Add(%onnx::Add_692, %onnx::Add_693) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_695 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Mul(%onnx::Div_689, %onnx::Mul_694) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_696 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.11 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_695, %onnx::Mul_696) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Unsqueeze_698 : Float(2, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.11, %forcasting_model.fully_connected_layers.6.weight, %forcasting_model.fully_connected_layers.6.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Unsqueeze_699 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:99:0\n  %onnx::Concat_700 : Float(2, 1, 2, strides=[2, 2, 1], requires_grad=1, device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_698, %onnx::Unsqueeze_699) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:99:0\n  %onnx::Gather_701 : Long(device=cpu) = onnx::Constant[value={31}]()\n  %onnx::Slice_702 : Float(2, 6, strides=[6, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_701) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:93:0\n  %onnx::Slice_703 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_704 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_705 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={6}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_706 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Shape_707 : Float(2, 2, strides=[6, 1], requires_grad=0, device=cpu) = onnx::Slice(%onnx::Slice_702, %onnx::Slice_704, %onnx::Slice_705, %onnx::Slice_703, %onnx::Slice_706) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_708 : Long(2, strides=[1], device=cpu) = onnx::Shape(%onnx::Shape_707) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Reshape_709 : Float(2, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Expand(%onnx::Unsqueeze_698, %onnx::Expand_708) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_710 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 4  5 [ CPULongType{2} ]]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_711 : Long(2, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Constant[value= 0  1 [ CPULongType{2,1} ]]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_717 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%onnx::ConstantOfShape_1406) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_718 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Equal_719 : Long(2, strides=[1], device=cpu) = onnx::Mul(%onnx::Mul_717, %onnx::Mul_718) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Where_720 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%onnx::Equal_1405, %onnx::Equal_719) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_721 : Long(2, strides=[1], device=cpu) = onnx::Where(%onnx::Where_720, %onnx::Mul_717, %onnx::Equal_1405) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_722 : Long(2, 2, device=cpu) = onnx::Expand(%onnx::Expand_711, %onnx::Expand_721) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_723 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_724 : Long(2, 2, 1, strides=[2, 1, 1], device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_722, %onnx::Unsqueeze_723) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_726 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%onnx::ConstantOfShape_1407) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_727 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Equal_728 : Long(2, strides=[1], device=cpu) = onnx::Mul(%onnx::Mul_726, %onnx::Mul_727) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Where_729 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%onnx::Equal_1405, %onnx::Equal_728) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_730 : Long(2, strides=[1], device=cpu) = onnx::Where(%onnx::Where_729, %onnx::Mul_726, %onnx::Equal_1405) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_731 : Long(2, 2, device=cpu) = onnx::Expand(%onnx::Expand_710, %onnx::Expand_730) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_732 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_733 : Long(2, 2, 1, strides=[2, 1, 1], device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_731, %onnx::Unsqueeze_732) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::ScatterND_734 : Long(2, 2, 2, strides=[4, 2, 1], device=cpu) = onnx::Concat[axis=-1](%onnx::Concat_724, %onnx::Concat_733) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_735 : Long(2, strides=[1], device=cpu) = onnx::Shape(%onnx::Slice_702) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_736 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_737 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_738 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_739 : Long(0, strides=[1], device=cpu) = onnx::Slice(%onnx::Slice_735, %onnx::Slice_737, %onnx::Slice_738, %onnx::Slice_736) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Reshape_740 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Equal_1405, %onnx::Concat_739) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::ScatterND_741 : Float(2, 2, device=cpu) = onnx::Reshape(%onnx::Reshape_709, %onnx::Reshape_740) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Gemm_742 : Float(2, 6, strides=[6, 1], requires_grad=1, device=cpu) = onnx::ScatterND(%onnx::Slice_702, %onnx::ScatterND_734, %onnx::ScatterND_741) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Add_743 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_679, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_744 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_742, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_745 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_743, %onnx::Add_744) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_746 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_747 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_748 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_749 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_750 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_745, %onnx::Split_746) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_751 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_747) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_752 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_748) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_753 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_749) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_754 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_750) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_755 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_752, %onnx::Tanh_677) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_756 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_751, %onnx::Mul_753) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_757 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_755, %onnx::Add_756) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_758 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_757) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_759 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_754, %onnx::Mul_758) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Div_760 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_759, %forcasting_model.fully_connected_layers.0.weight, %forcasting_model.fully_connected_layers.0.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_761 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_762 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Div(%onnx::Div_760, %onnx::Div_761) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_763 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Erf(%onnx::Erf_762) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_764 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_765 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Add(%onnx::Add_763, %onnx::Add_764) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_766 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Mul(%onnx::Div_760, %onnx::Mul_765) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_767 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.15 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_766, %onnx::Mul_767) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Div_769 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.15, %forcasting_model.fully_connected_layers.3.weight, %forcasting_model.fully_connected_layers.3.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_770 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_771 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Div(%onnx::Div_769, %onnx::Div_770) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_772 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Erf(%onnx::Erf_771) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_773 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_774 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Add(%onnx::Add_772, %onnx::Add_773) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_775 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Mul(%onnx::Div_769, %onnx::Mul_774) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_776 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.19 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_775, %onnx::Mul_776) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Unsqueeze_778 : Float(2, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.19, %forcasting_model.fully_connected_layers.6.weight, %forcasting_model.fully_connected_layers.6.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Unsqueeze_779 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:99:0\n  %onnx::Concat_780 : Float(2, 1, 2, strides=[2, 2, 1], requires_grad=1, device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_778, %onnx::Unsqueeze_779) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:99:0\n  %onnx::Gather_781 : Long(device=cpu) = onnx::Constant[value={32}]()\n  %onnx::Slice_782 : Float(2, 6, strides=[6, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_781) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:93:0\n  %onnx::Slice_783 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_784 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_785 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={6}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_786 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Shape_787 : Float(2, 2, strides=[6, 1], requires_grad=0, device=cpu) = onnx::Slice(%onnx::Slice_782, %onnx::Slice_784, %onnx::Slice_785, %onnx::Slice_783, %onnx::Slice_786) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_788 : Long(2, strides=[1], device=cpu) = onnx::Shape(%onnx::Shape_787) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Reshape_789 : Float(2, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Expand(%onnx::Unsqueeze_778, %onnx::Expand_788) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_790 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 4  5 [ CPULongType{2} ]]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_791 : Long(2, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Constant[value= 0  1 [ CPULongType{2,1} ]]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_797 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%onnx::ConstantOfShape_1410) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_798 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Equal_799 : Long(2, strides=[1], device=cpu) = onnx::Mul(%onnx::Mul_797, %onnx::Mul_798) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Where_800 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%onnx::Equal_1409, %onnx::Equal_799) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_801 : Long(2, strides=[1], device=cpu) = onnx::Where(%onnx::Where_800, %onnx::Mul_797, %onnx::Equal_1409) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_802 : Long(2, 2, device=cpu) = onnx::Expand(%onnx::Expand_791, %onnx::Expand_801) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_803 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_804 : Long(2, 2, 1, strides=[2, 1, 1], device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_802, %onnx::Unsqueeze_803) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_806 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%onnx::ConstantOfShape_1411) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_807 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Equal_808 : Long(2, strides=[1], device=cpu) = onnx::Mul(%onnx::Mul_806, %onnx::Mul_807) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Where_809 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%onnx::Equal_1409, %onnx::Equal_808) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_810 : Long(2, strides=[1], device=cpu) = onnx::Where(%onnx::Where_809, %onnx::Mul_806, %onnx::Equal_1409) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_811 : Long(2, 2, device=cpu) = onnx::Expand(%onnx::Expand_790, %onnx::Expand_810) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_812 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_813 : Long(2, 2, 1, strides=[2, 1, 1], device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_811, %onnx::Unsqueeze_812) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::ScatterND_814 : Long(2, 2, 2, strides=[4, 2, 1], device=cpu) = onnx::Concat[axis=-1](%onnx::Concat_804, %onnx::Concat_813) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_815 : Long(2, strides=[1], device=cpu) = onnx::Shape(%onnx::Slice_782) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_816 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_817 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_818 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_819 : Long(0, strides=[1], device=cpu) = onnx::Slice(%onnx::Slice_815, %onnx::Slice_817, %onnx::Slice_818, %onnx::Slice_816) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Reshape_820 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Equal_1409, %onnx::Concat_819) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::ScatterND_821 : Float(2, 2, device=cpu) = onnx::Reshape(%onnx::Reshape_789, %onnx::Reshape_820) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Gemm_822 : Float(2, 6, strides=[6, 1], requires_grad=1, device=cpu) = onnx::ScatterND(%onnx::Slice_782, %onnx::ScatterND_814, %onnx::ScatterND_821) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Add_823 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_759, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_824 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_822, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_825 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_823, %onnx::Add_824) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_826 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_827 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_828 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_829 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_830 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_825, %onnx::Split_826) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_831 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_827) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_832 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_828) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_833 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_829) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_834 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_830) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_835 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_832, %onnx::Tanh_757) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_836 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_831, %onnx::Mul_833) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_837 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_835, %onnx::Add_836) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_838 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_837) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_839 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_834, %onnx::Mul_838) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Div_840 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_839, %forcasting_model.fully_connected_layers.0.weight, %forcasting_model.fully_connected_layers.0.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_841 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_842 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Div(%onnx::Div_840, %onnx::Div_841) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_843 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Erf(%onnx::Erf_842) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_844 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_845 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Add(%onnx::Add_843, %onnx::Add_844) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_846 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Mul(%onnx::Div_840, %onnx::Mul_845) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_847 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.23 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_846, %onnx::Mul_847) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Div_849 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.23, %forcasting_model.fully_connected_layers.3.weight, %forcasting_model.fully_connected_layers.3.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_850 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_851 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Div(%onnx::Div_849, %onnx::Div_850) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_852 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Erf(%onnx::Erf_851) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_853 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_854 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Add(%onnx::Add_852, %onnx::Add_853) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_855 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Mul(%onnx::Div_849, %onnx::Mul_854) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_856 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.27 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_855, %onnx::Mul_856) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Unsqueeze_858 : Float(2, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.27, %forcasting_model.fully_connected_layers.6.weight, %forcasting_model.fully_connected_layers.6.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Unsqueeze_859 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:99:0\n  %onnx::Concat_860 : Float(2, 1, 2, strides=[2, 2, 1], requires_grad=1, device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_858, %onnx::Unsqueeze_859) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:99:0\n  %onnx::Gather_861 : Long(device=cpu) = onnx::Constant[value={33}]()\n  %onnx::Slice_862 : Float(2, 6, strides=[6, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_861) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:93:0\n  %onnx::Slice_863 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_864 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_865 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={6}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_866 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Shape_867 : Float(2, 2, strides=[6, 1], requires_grad=0, device=cpu) = onnx::Slice(%onnx::Slice_862, %onnx::Slice_864, %onnx::Slice_865, %onnx::Slice_863, %onnx::Slice_866) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_868 : Long(2, strides=[1], device=cpu) = onnx::Shape(%onnx::Shape_867) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Reshape_869 : Float(2, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Expand(%onnx::Unsqueeze_858, %onnx::Expand_868) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_870 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 4  5 [ CPULongType{2} ]]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_871 : Long(2, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Constant[value= 0  1 [ CPULongType{2,1} ]]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_877 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%onnx::ConstantOfShape_1414) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_878 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Equal_879 : Long(2, strides=[1], device=cpu) = onnx::Mul(%onnx::Mul_877, %onnx::Mul_878) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Where_880 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%onnx::Equal_1413, %onnx::Equal_879) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_881 : Long(2, strides=[1], device=cpu) = onnx::Where(%onnx::Where_880, %onnx::Mul_877, %onnx::Equal_1413) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_882 : Long(2, 2, device=cpu) = onnx::Expand(%onnx::Expand_871, %onnx::Expand_881) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_883 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_884 : Long(2, 2, 1, strides=[2, 1, 1], device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_882, %onnx::Unsqueeze_883) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_886 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%onnx::ConstantOfShape_1415) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_887 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Equal_888 : Long(2, strides=[1], device=cpu) = onnx::Mul(%onnx::Mul_886, %onnx::Mul_887) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Where_889 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%onnx::Equal_1413, %onnx::Equal_888) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_890 : Long(2, strides=[1], device=cpu) = onnx::Where(%onnx::Where_889, %onnx::Mul_886, %onnx::Equal_1413) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_891 : Long(2, 2, device=cpu) = onnx::Expand(%onnx::Expand_870, %onnx::Expand_890) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_892 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_893 : Long(2, 2, 1, strides=[2, 1, 1], device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_891, %onnx::Unsqueeze_892) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::ScatterND_894 : Long(2, 2, 2, strides=[4, 2, 1], device=cpu) = onnx::Concat[axis=-1](%onnx::Concat_884, %onnx::Concat_893) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_895 : Long(2, strides=[1], device=cpu) = onnx::Shape(%onnx::Slice_862) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_896 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_897 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_898 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_899 : Long(0, strides=[1], device=cpu) = onnx::Slice(%onnx::Slice_895, %onnx::Slice_897, %onnx::Slice_898, %onnx::Slice_896) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Reshape_900 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Equal_1413, %onnx::Concat_899) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::ScatterND_901 : Float(2, 2, device=cpu) = onnx::Reshape(%onnx::Reshape_869, %onnx::Reshape_900) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Gemm_902 : Float(2, 6, strides=[6, 1], requires_grad=1, device=cpu) = onnx::ScatterND(%onnx::Slice_862, %onnx::ScatterND_894, %onnx::ScatterND_901) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Add_903 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_839, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_904 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_902, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_905 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_903, %onnx::Add_904) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_906 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_907 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_908 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_909 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_910 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_905, %onnx::Split_906) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_911 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_907) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_912 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_908) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_913 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_909) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_914 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_910) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_915 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_912, %onnx::Tanh_837) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_916 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_911, %onnx::Mul_913) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_917 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_915, %onnx::Add_916) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_918 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_917) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_919 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_914, %onnx::Mul_918) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Div_920 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_919, %forcasting_model.fully_connected_layers.0.weight, %forcasting_model.fully_connected_layers.0.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_921 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_922 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Div(%onnx::Div_920, %onnx::Div_921) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_923 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Erf(%onnx::Erf_922) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_924 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_925 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Add(%onnx::Add_923, %onnx::Add_924) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_926 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Mul(%onnx::Div_920, %onnx::Mul_925) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_927 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.31 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_926, %onnx::Mul_927) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Div_929 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.31, %forcasting_model.fully_connected_layers.3.weight, %forcasting_model.fully_connected_layers.3.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_930 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_931 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Div(%onnx::Div_929, %onnx::Div_930) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_932 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Erf(%onnx::Erf_931) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_933 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_934 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Add(%onnx::Add_932, %onnx::Add_933) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_935 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Mul(%onnx::Div_929, %onnx::Mul_934) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_936 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.35 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_935, %onnx::Mul_936) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Unsqueeze_938 : Float(2, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.35, %forcasting_model.fully_connected_layers.6.weight, %forcasting_model.fully_connected_layers.6.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Unsqueeze_939 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:99:0\n  %onnx::Concat_940 : Float(2, 1, 2, strides=[2, 2, 1], requires_grad=1, device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_938, %onnx::Unsqueeze_939) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:99:0\n  %onnx::Gather_941 : Long(device=cpu) = onnx::Constant[value={34}]()\n  %onnx::Slice_942 : Float(2, 6, strides=[6, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_941) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:93:0\n  %onnx::Slice_943 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_944 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_945 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={6}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_946 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Shape_947 : Float(2, 2, strides=[6, 1], requires_grad=0, device=cpu) = onnx::Slice(%onnx::Slice_942, %onnx::Slice_944, %onnx::Slice_945, %onnx::Slice_943, %onnx::Slice_946) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_948 : Long(2, strides=[1], device=cpu) = onnx::Shape(%onnx::Shape_947) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Reshape_949 : Float(2, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Expand(%onnx::Unsqueeze_938, %onnx::Expand_948) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_950 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 4  5 [ CPULongType{2} ]]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_951 : Long(2, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Constant[value= 0  1 [ CPULongType{2,1} ]]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_957 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%onnx::ConstantOfShape_1418) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_958 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Equal_959 : Long(2, strides=[1], device=cpu) = onnx::Mul(%onnx::Mul_957, %onnx::Mul_958) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Where_960 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%onnx::Equal_1417, %onnx::Equal_959) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_961 : Long(2, strides=[1], device=cpu) = onnx::Where(%onnx::Where_960, %onnx::Mul_957, %onnx::Equal_1417) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_962 : Long(2, 2, device=cpu) = onnx::Expand(%onnx::Expand_951, %onnx::Expand_961) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_963 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_964 : Long(2, 2, 1, strides=[2, 1, 1], device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_962, %onnx::Unsqueeze_963) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_966 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%onnx::ConstantOfShape_1419) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_967 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Equal_968 : Long(2, strides=[1], device=cpu) = onnx::Mul(%onnx::Mul_966, %onnx::Mul_967) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Where_969 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%onnx::Equal_1417, %onnx::Equal_968) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_970 : Long(2, strides=[1], device=cpu) = onnx::Where(%onnx::Where_969, %onnx::Mul_966, %onnx::Equal_1417) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_971 : Long(2, 2, device=cpu) = onnx::Expand(%onnx::Expand_950, %onnx::Expand_970) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_972 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_973 : Long(2, 2, 1, strides=[2, 1, 1], device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_971, %onnx::Unsqueeze_972) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::ScatterND_974 : Long(2, 2, 2, strides=[4, 2, 1], device=cpu) = onnx::Concat[axis=-1](%onnx::Concat_964, %onnx::Concat_973) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_975 : Long(2, strides=[1], device=cpu) = onnx::Shape(%onnx::Slice_942) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_976 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_977 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_978 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_979 : Long(0, strides=[1], device=cpu) = onnx::Slice(%onnx::Slice_975, %onnx::Slice_977, %onnx::Slice_978, %onnx::Slice_976) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Reshape_980 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Equal_1417, %onnx::Concat_979) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::ScatterND_981 : Float(2, 2, device=cpu) = onnx::Reshape(%onnx::Reshape_949, %onnx::Reshape_980) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Gemm_982 : Float(2, 6, strides=[6, 1], requires_grad=1, device=cpu) = onnx::ScatterND(%onnx::Slice_942, %onnx::ScatterND_974, %onnx::ScatterND_981) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Add_983 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_919, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_984 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_982, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_985 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_983, %onnx::Add_984) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_986 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_987 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_988 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_989 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_990 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_985, %onnx::Split_986) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_991 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_987) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_992 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_988) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_993 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_989) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_994 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_990) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_995 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_992, %onnx::Tanh_917) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_996 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_991, %onnx::Mul_993) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_997 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_995, %onnx::Add_996) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_998 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_997) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_999 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_994, %onnx::Mul_998) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Div_1000 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_999, %forcasting_model.fully_connected_layers.0.weight, %forcasting_model.fully_connected_layers.0.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_1001 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_1002 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Div(%onnx::Div_1000, %onnx::Div_1001) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1003 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Erf(%onnx::Erf_1002) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1004 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1005 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Add(%onnx::Add_1003, %onnx::Add_1004) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1006 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Mul(%onnx::Div_1000, %onnx::Mul_1005) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1007 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.39 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1006, %onnx::Mul_1007) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Div_1009 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.39, %forcasting_model.fully_connected_layers.3.weight, %forcasting_model.fully_connected_layers.3.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_1010 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_1011 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Div(%onnx::Div_1009, %onnx::Div_1010) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1012 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Erf(%onnx::Erf_1011) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1013 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1014 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Add(%onnx::Add_1012, %onnx::Add_1013) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1015 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Mul(%onnx::Div_1009, %onnx::Mul_1014) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1016 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.43 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1015, %onnx::Mul_1016) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Unsqueeze_1018 : Float(2, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.43, %forcasting_model.fully_connected_layers.6.weight, %forcasting_model.fully_connected_layers.6.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Unsqueeze_1019 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:99:0\n  %onnx::Concat_1020 : Float(2, 1, 2, strides=[2, 2, 1], requires_grad=1, device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_1018, %onnx::Unsqueeze_1019) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:99:0\n  %onnx::Gather_1021 : Long(device=cpu) = onnx::Constant[value={35}]()\n  %onnx::Slice_1022 : Float(2, 6, strides=[6, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_1021) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:93:0\n  %onnx::Slice_1023 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1024 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1025 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={6}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1026 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Shape_1027 : Float(2, 2, strides=[6, 1], requires_grad=0, device=cpu) = onnx::Slice(%onnx::Slice_1022, %onnx::Slice_1024, %onnx::Slice_1025, %onnx::Slice_1023, %onnx::Slice_1026) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_1028 : Long(2, strides=[1], device=cpu) = onnx::Shape(%onnx::Shape_1027) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Reshape_1029 : Float(2, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Expand(%onnx::Unsqueeze_1018, %onnx::Expand_1028) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_1030 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 4  5 [ CPULongType{2} ]]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_1031 : Long(2, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Constant[value= 0  1 [ CPULongType{2,1} ]]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_1037 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%onnx::ConstantOfShape_1422) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_1038 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Equal_1039 : Long(2, strides=[1], device=cpu) = onnx::Mul(%onnx::Mul_1037, %onnx::Mul_1038) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Where_1040 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%onnx::Equal_1421, %onnx::Equal_1039) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_1041 : Long(2, strides=[1], device=cpu) = onnx::Where(%onnx::Where_1040, %onnx::Mul_1037, %onnx::Equal_1421) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_1042 : Long(2, 2, device=cpu) = onnx::Expand(%onnx::Expand_1031, %onnx::Expand_1041) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_1043 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_1044 : Long(2, 2, 1, strides=[2, 1, 1], device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_1042, %onnx::Unsqueeze_1043) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_1046 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%onnx::ConstantOfShape_1423) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_1047 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Equal_1048 : Long(2, strides=[1], device=cpu) = onnx::Mul(%onnx::Mul_1046, %onnx::Mul_1047) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Where_1049 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%onnx::Equal_1421, %onnx::Equal_1048) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_1050 : Long(2, strides=[1], device=cpu) = onnx::Where(%onnx::Where_1049, %onnx::Mul_1046, %onnx::Equal_1421) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_1051 : Long(2, 2, device=cpu) = onnx::Expand(%onnx::Expand_1030, %onnx::Expand_1050) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_1052 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_1053 : Long(2, 2, 1, strides=[2, 1, 1], device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_1051, %onnx::Unsqueeze_1052) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::ScatterND_1054 : Long(2, 2, 2, strides=[4, 2, 1], device=cpu) = onnx::Concat[axis=-1](%onnx::Concat_1044, %onnx::Concat_1053) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1055 : Long(2, strides=[1], device=cpu) = onnx::Shape(%onnx::Slice_1022) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1056 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1057 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1058 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_1059 : Long(0, strides=[1], device=cpu) = onnx::Slice(%onnx::Slice_1055, %onnx::Slice_1057, %onnx::Slice_1058, %onnx::Slice_1056) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Reshape_1060 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Equal_1421, %onnx::Concat_1059) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::ScatterND_1061 : Float(2, 2, device=cpu) = onnx::Reshape(%onnx::Reshape_1029, %onnx::Reshape_1060) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Gemm_1062 : Float(2, 6, strides=[6, 1], requires_grad=1, device=cpu) = onnx::ScatterND(%onnx::Slice_1022, %onnx::ScatterND_1054, %onnx::ScatterND_1061) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Add_1063 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_999, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_1064 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_1062, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_1065 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_1063, %onnx::Add_1064) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_1066 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_1067 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_1068 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_1069 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_1070 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_1065, %onnx::Split_1066) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_1071 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_1067) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_1072 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_1068) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_1073 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_1069) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_1074 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_1070) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_1075 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1072, %onnx::Tanh_997) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_1076 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1071, %onnx::Mul_1073) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_1077 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_1075, %onnx::Add_1076) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_1078 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_1077) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_1079 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1074, %onnx::Mul_1078) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Div_1080 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_1079, %forcasting_model.fully_connected_layers.0.weight, %forcasting_model.fully_connected_layers.0.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_1081 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_1082 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Div(%onnx::Div_1080, %onnx::Div_1081) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1083 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Erf(%onnx::Erf_1082) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1084 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1085 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Add(%onnx::Add_1083, %onnx::Add_1084) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1086 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Mul(%onnx::Div_1080, %onnx::Mul_1085) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1087 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.47 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1086, %onnx::Mul_1087) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Div_1089 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.47, %forcasting_model.fully_connected_layers.3.weight, %forcasting_model.fully_connected_layers.3.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_1090 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_1091 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Div(%onnx::Div_1089, %onnx::Div_1090) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1092 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Erf(%onnx::Erf_1091) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1093 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1094 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Add(%onnx::Add_1092, %onnx::Add_1093) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1095 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Mul(%onnx::Div_1089, %onnx::Mul_1094) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1096 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.51 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1095, %onnx::Mul_1096) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Unsqueeze_1098 : Float(2, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.51, %forcasting_model.fully_connected_layers.6.weight, %forcasting_model.fully_connected_layers.6.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Unsqueeze_1099 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:99:0\n  %onnx::Concat_1100 : Float(2, 1, 2, strides=[2, 2, 1], requires_grad=1, device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_1098, %onnx::Unsqueeze_1099) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:99:0\n  %onnx::Gather_1101 : Long(device=cpu) = onnx::Constant[value={36}]()\n  %onnx::Slice_1102 : Float(2, 6, strides=[6, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_1101) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:93:0\n  %onnx::Slice_1103 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1104 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1105 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={6}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1106 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Shape_1107 : Float(2, 2, strides=[6, 1], requires_grad=0, device=cpu) = onnx::Slice(%onnx::Slice_1102, %onnx::Slice_1104, %onnx::Slice_1105, %onnx::Slice_1103, %onnx::Slice_1106) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_1108 : Long(2, strides=[1], device=cpu) = onnx::Shape(%onnx::Shape_1107) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Reshape_1109 : Float(2, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Expand(%onnx::Unsqueeze_1098, %onnx::Expand_1108) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_1110 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 4  5 [ CPULongType{2} ]]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_1111 : Long(2, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Constant[value= 0  1 [ CPULongType{2,1} ]]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_1117 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%onnx::ConstantOfShape_1426) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_1118 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Equal_1119 : Long(2, strides=[1], device=cpu) = onnx::Mul(%onnx::Mul_1117, %onnx::Mul_1118) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Where_1120 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%onnx::Equal_1425, %onnx::Equal_1119) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_1121 : Long(2, strides=[1], device=cpu) = onnx::Where(%onnx::Where_1120, %onnx::Mul_1117, %onnx::Equal_1425) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_1122 : Long(2, 2, device=cpu) = onnx::Expand(%onnx::Expand_1111, %onnx::Expand_1121) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_1123 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_1124 : Long(2, 2, 1, strides=[2, 1, 1], device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_1122, %onnx::Unsqueeze_1123) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_1126 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%onnx::ConstantOfShape_1427) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_1127 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Equal_1128 : Long(2, strides=[1], device=cpu) = onnx::Mul(%onnx::Mul_1126, %onnx::Mul_1127) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Where_1129 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%onnx::Equal_1425, %onnx::Equal_1128) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_1130 : Long(2, strides=[1], device=cpu) = onnx::Where(%onnx::Where_1129, %onnx::Mul_1126, %onnx::Equal_1425) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_1131 : Long(2, 2, device=cpu) = onnx::Expand(%onnx::Expand_1110, %onnx::Expand_1130) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_1132 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_1133 : Long(2, 2, 1, strides=[2, 1, 1], device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_1131, %onnx::Unsqueeze_1132) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::ScatterND_1134 : Long(2, 2, 2, strides=[4, 2, 1], device=cpu) = onnx::Concat[axis=-1](%onnx::Concat_1124, %onnx::Concat_1133) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1135 : Long(2, strides=[1], device=cpu) = onnx::Shape(%onnx::Slice_1102) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1136 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1137 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1138 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_1139 : Long(0, strides=[1], device=cpu) = onnx::Slice(%onnx::Slice_1135, %onnx::Slice_1137, %onnx::Slice_1138, %onnx::Slice_1136) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Reshape_1140 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Equal_1425, %onnx::Concat_1139) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::ScatterND_1141 : Float(2, 2, device=cpu) = onnx::Reshape(%onnx::Reshape_1109, %onnx::Reshape_1140) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Gemm_1142 : Float(2, 6, strides=[6, 1], requires_grad=1, device=cpu) = onnx::ScatterND(%onnx::Slice_1102, %onnx::ScatterND_1134, %onnx::ScatterND_1141) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Add_1143 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_1079, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_1144 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_1142, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_1145 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_1143, %onnx::Add_1144) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_1146 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_1147 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_1148 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_1149 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_1150 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_1145, %onnx::Split_1146) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_1151 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_1147) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_1152 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_1148) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_1153 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_1149) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_1154 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_1150) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_1155 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1152, %onnx::Tanh_1077) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_1156 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1151, %onnx::Mul_1153) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_1157 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_1155, %onnx::Add_1156) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_1158 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_1157) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_1159 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1154, %onnx::Mul_1158) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Div_1160 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_1159, %forcasting_model.fully_connected_layers.0.weight, %forcasting_model.fully_connected_layers.0.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_1161 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_1162 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Div(%onnx::Div_1160, %onnx::Div_1161) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1163 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Erf(%onnx::Erf_1162) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1164 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1165 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Add(%onnx::Add_1163, %onnx::Add_1164) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1166 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Mul(%onnx::Div_1160, %onnx::Mul_1165) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1167 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.55 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1166, %onnx::Mul_1167) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Div_1169 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.55, %forcasting_model.fully_connected_layers.3.weight, %forcasting_model.fully_connected_layers.3.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_1170 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_1171 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Div(%onnx::Div_1169, %onnx::Div_1170) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1172 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Erf(%onnx::Erf_1171) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1173 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1174 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Add(%onnx::Add_1172, %onnx::Add_1173) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1175 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Mul(%onnx::Div_1169, %onnx::Mul_1174) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1176 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.59 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1175, %onnx::Mul_1176) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Unsqueeze_1178 : Float(2, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.59, %forcasting_model.fully_connected_layers.6.weight, %forcasting_model.fully_connected_layers.6.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Unsqueeze_1179 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:99:0\n  %onnx::Concat_1180 : Float(2, 1, 2, strides=[2, 2, 1], requires_grad=1, device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_1178, %onnx::Unsqueeze_1179) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:99:0\n  %onnx::Gather_1181 : Long(device=cpu) = onnx::Constant[value={37}]()\n  %onnx::Slice_1182 : Float(2, 6, strides=[6, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_1181) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:93:0\n  %onnx::Slice_1183 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1184 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1185 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={6}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1186 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Shape_1187 : Float(2, 2, strides=[6, 1], requires_grad=0, device=cpu) = onnx::Slice(%onnx::Slice_1182, %onnx::Slice_1184, %onnx::Slice_1185, %onnx::Slice_1183, %onnx::Slice_1186) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_1188 : Long(2, strides=[1], device=cpu) = onnx::Shape(%onnx::Shape_1187) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Reshape_1189 : Float(2, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Expand(%onnx::Unsqueeze_1178, %onnx::Expand_1188) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_1190 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 4  5 [ CPULongType{2} ]]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_1191 : Long(2, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Constant[value= 0  1 [ CPULongType{2,1} ]]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_1197 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%onnx::ConstantOfShape_1430) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_1198 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Equal_1199 : Long(2, strides=[1], device=cpu) = onnx::Mul(%onnx::Mul_1197, %onnx::Mul_1198) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Where_1200 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%onnx::Equal_1429, %onnx::Equal_1199) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_1201 : Long(2, strides=[1], device=cpu) = onnx::Where(%onnx::Where_1200, %onnx::Mul_1197, %onnx::Equal_1429) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_1202 : Long(2, 2, device=cpu) = onnx::Expand(%onnx::Expand_1191, %onnx::Expand_1201) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_1203 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_1204 : Long(2, 2, 1, strides=[2, 1, 1], device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_1202, %onnx::Unsqueeze_1203) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_1206 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%onnx::ConstantOfShape_1431) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_1207 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Equal_1208 : Long(2, strides=[1], device=cpu) = onnx::Mul(%onnx::Mul_1206, %onnx::Mul_1207) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Where_1209 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%onnx::Equal_1429, %onnx::Equal_1208) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_1210 : Long(2, strides=[1], device=cpu) = onnx::Where(%onnx::Where_1209, %onnx::Mul_1206, %onnx::Equal_1429) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_1211 : Long(2, 2, device=cpu) = onnx::Expand(%onnx::Expand_1190, %onnx::Expand_1210) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_1212 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_1213 : Long(2, 2, 1, strides=[2, 1, 1], device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_1211, %onnx::Unsqueeze_1212) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::ScatterND_1214 : Long(2, 2, 2, strides=[4, 2, 1], device=cpu) = onnx::Concat[axis=-1](%onnx::Concat_1204, %onnx::Concat_1213) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1215 : Long(2, strides=[1], device=cpu) = onnx::Shape(%onnx::Slice_1182) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1216 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1217 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1218 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_1219 : Long(0, strides=[1], device=cpu) = onnx::Slice(%onnx::Slice_1215, %onnx::Slice_1217, %onnx::Slice_1218, %onnx::Slice_1216) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Reshape_1220 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Equal_1429, %onnx::Concat_1219) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::ScatterND_1221 : Float(2, 2, device=cpu) = onnx::Reshape(%onnx::Reshape_1189, %onnx::Reshape_1220) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Gemm_1222 : Float(2, 6, strides=[6, 1], requires_grad=1, device=cpu) = onnx::ScatterND(%onnx::Slice_1182, %onnx::ScatterND_1214, %onnx::ScatterND_1221) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Add_1223 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_1159, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_1224 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_1222, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_1225 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_1223, %onnx::Add_1224) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_1226 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_1227 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_1228 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_1229 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_1230 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_1225, %onnx::Split_1226) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_1231 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_1227) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_1232 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_1228) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_1233 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_1229) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_1234 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_1230) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_1235 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1232, %onnx::Tanh_1157) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_1236 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1231, %onnx::Mul_1233) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_1237 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_1235, %onnx::Add_1236) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_1238 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_1237) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_1239 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1234, %onnx::Mul_1238) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Div_1240 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_1239, %forcasting_model.fully_connected_layers.0.weight, %forcasting_model.fully_connected_layers.0.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_1241 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_1242 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Div(%onnx::Div_1240, %onnx::Div_1241) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1243 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Erf(%onnx::Erf_1242) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1244 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1245 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Add(%onnx::Add_1243, %onnx::Add_1244) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1246 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Mul(%onnx::Div_1240, %onnx::Mul_1245) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1247 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.63 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1246, %onnx::Mul_1247) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Div_1249 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.63, %forcasting_model.fully_connected_layers.3.weight, %forcasting_model.fully_connected_layers.3.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_1250 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_1251 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Div(%onnx::Div_1249, %onnx::Div_1250) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1252 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Erf(%onnx::Erf_1251) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1253 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1254 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Add(%onnx::Add_1252, %onnx::Add_1253) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1255 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Mul(%onnx::Div_1249, %onnx::Mul_1254) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1256 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.67 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1255, %onnx::Mul_1256) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Unsqueeze_1258 : Float(2, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.67, %forcasting_model.fully_connected_layers.6.weight, %forcasting_model.fully_connected_layers.6.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Unsqueeze_1259 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:99:0\n  %onnx::Concat_1260 : Float(2, 1, 2, strides=[2, 2, 1], requires_grad=1, device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_1258, %onnx::Unsqueeze_1259) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:99:0\n  %onnx::Gather_1261 : Long(device=cpu) = onnx::Constant[value={38}]()\n  %onnx::Slice_1262 : Float(2, 6, strides=[6, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_1261) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:93:0\n  %onnx::Slice_1263 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1264 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1265 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={6}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1266 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Shape_1267 : Float(2, 2, strides=[6, 1], requires_grad=0, device=cpu) = onnx::Slice(%onnx::Slice_1262, %onnx::Slice_1264, %onnx::Slice_1265, %onnx::Slice_1263, %onnx::Slice_1266) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_1268 : Long(2, strides=[1], device=cpu) = onnx::Shape(%onnx::Shape_1267) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Reshape_1269 : Float(2, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Expand(%onnx::Unsqueeze_1258, %onnx::Expand_1268) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_1270 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 4  5 [ CPULongType{2} ]]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_1271 : Long(2, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Constant[value= 0  1 [ CPULongType{2,1} ]]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_1277 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%onnx::ConstantOfShape_1434) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_1278 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Equal_1279 : Long(2, strides=[1], device=cpu) = onnx::Mul(%onnx::Mul_1277, %onnx::Mul_1278) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Where_1280 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%onnx::Equal_1433, %onnx::Equal_1279) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_1281 : Long(2, strides=[1], device=cpu) = onnx::Where(%onnx::Where_1280, %onnx::Mul_1277, %onnx::Equal_1433) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_1282 : Long(2, 2, device=cpu) = onnx::Expand(%onnx::Expand_1271, %onnx::Expand_1281) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_1283 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_1284 : Long(2, 2, 1, strides=[2, 1, 1], device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_1282, %onnx::Unsqueeze_1283) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_1286 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%onnx::ConstantOfShape_1435) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_1287 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Equal_1288 : Long(2, strides=[1], device=cpu) = onnx::Mul(%onnx::Mul_1286, %onnx::Mul_1287) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Where_1289 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%onnx::Equal_1433, %onnx::Equal_1288) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_1290 : Long(2, strides=[1], device=cpu) = onnx::Where(%onnx::Where_1289, %onnx::Mul_1286, %onnx::Equal_1433) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_1291 : Long(2, 2, device=cpu) = onnx::Expand(%onnx::Expand_1270, %onnx::Expand_1290) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_1292 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_1293 : Long(2, 2, 1, strides=[2, 1, 1], device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_1291, %onnx::Unsqueeze_1292) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::ScatterND_1294 : Long(2, 2, 2, strides=[4, 2, 1], device=cpu) = onnx::Concat[axis=-1](%onnx::Concat_1284, %onnx::Concat_1293) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1295 : Long(2, strides=[1], device=cpu) = onnx::Shape(%onnx::Slice_1262) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1296 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1297 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1298 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_1299 : Long(0, strides=[1], device=cpu) = onnx::Slice(%onnx::Slice_1295, %onnx::Slice_1297, %onnx::Slice_1298, %onnx::Slice_1296) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Reshape_1300 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Equal_1433, %onnx::Concat_1299) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::ScatterND_1301 : Float(2, 2, device=cpu) = onnx::Reshape(%onnx::Reshape_1269, %onnx::Reshape_1300) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Gemm_1302 : Float(2, 6, strides=[6, 1], requires_grad=1, device=cpu) = onnx::ScatterND(%onnx::Slice_1262, %onnx::ScatterND_1294, %onnx::ScatterND_1301) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Add_1303 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_1239, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_1304 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_1302, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_1305 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_1303, %onnx::Add_1304) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_1306 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_1307 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_1308 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_1309 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_1310 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_1305, %onnx::Split_1306) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_1311 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_1307) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_1312 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_1308) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_1313 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_1309) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_1314 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_1310) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_1315 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1312, %onnx::Tanh_1237) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_1316 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1311, %onnx::Mul_1313) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_1317 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_1315, %onnx::Add_1316) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_1318 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_1317) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_1319 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1314, %onnx::Mul_1318) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Div_1320 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_1319, %forcasting_model.fully_connected_layers.0.weight, %forcasting_model.fully_connected_layers.0.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_1321 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_1322 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Div(%onnx::Div_1320, %onnx::Div_1321) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1323 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Erf(%onnx::Erf_1322) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1324 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1325 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Add(%onnx::Add_1323, %onnx::Add_1324) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1326 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Mul(%onnx::Div_1320, %onnx::Mul_1325) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1327 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.71 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1326, %onnx::Mul_1327) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Div_1329 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.71, %forcasting_model.fully_connected_layers.3.weight, %forcasting_model.fully_connected_layers.3.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_1330 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_1331 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Div(%onnx::Div_1329, %onnx::Div_1330) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1332 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Erf(%onnx::Erf_1331) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1333 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1334 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Add(%onnx::Add_1332, %onnx::Add_1333) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1335 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Mul(%onnx::Div_1329, %onnx::Mul_1334) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1336 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.75 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1335, %onnx::Mul_1336) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Unsqueeze_1338 : Float(2, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.75, %forcasting_model.fully_connected_layers.6.weight, %forcasting_model.fully_connected_layers.6.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Unsqueeze_1339 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:99:0\n  %onnx::Concat_1340 : Float(2, 1, 2, strides=[2, 2, 1], requires_grad=1, device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_1338, %onnx::Unsqueeze_1339) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:99:0\n  %1341 : Float(2, 10, 2, strides=[20, 2, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1](%onnx::Concat_620, %onnx::Concat_700, %onnx::Concat_780, %onnx::Concat_860, %onnx::Concat_940, %onnx::Concat_1020, %onnx::Concat_1100, %onnx::Concat_1180, %onnx::Concat_1260, %onnx::Concat_1340) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:101:0\n  %onnx::Div_1342 : Float(2, 40, strides=[40, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_599, %autoencoder_quant_model.encoder_layers.0.weight, %autoencoder_quant_model.encoder_layers.0.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_1343 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_1344 : Float(2, 40, strides=[40, 1], device=cpu) = onnx::Div(%onnx::Div_1342, %onnx::Div_1343) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1345 : Float(2, 40, strides=[40, 1], device=cpu) = onnx::Erf(%onnx::Erf_1344) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1346 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1347 : Float(2, 40, strides=[40, 1], device=cpu) = onnx::Add(%onnx::Add_1345, %onnx::Add_1346) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1348 : Float(2, 40, strides=[40, 1], device=cpu) = onnx::Mul(%onnx::Div_1342, %onnx::Mul_1347) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1349 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.79 : Float(2, 40, strides=[40, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1348, %onnx::Mul_1349) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Div_1351 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.79, %autoencoder_quant_model.encoder_layers.3.weight, %autoencoder_quant_model.encoder_layers.3.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_1352 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_1353 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Div(%onnx::Div_1351, %onnx::Div_1352) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1354 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Erf(%onnx::Erf_1353) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1355 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1356 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Add(%onnx::Add_1354, %onnx::Add_1355) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1357 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Mul(%onnx::Div_1351, %onnx::Mul_1356) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1358 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.83 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1357, %onnx::Mul_1358) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Div_1360 : Float(2, 10, strides=[10, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.83, %autoencoder_quant_model.encoder_layers.6.weight, %autoencoder_quant_model.encoder_layers.6.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_1361 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_1362 : Float(2, 10, strides=[10, 1], device=cpu) = onnx::Div(%onnx::Div_1360, %onnx::Div_1361) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1363 : Float(2, 10, strides=[10, 1], device=cpu) = onnx::Erf(%onnx::Erf_1362) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1364 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1365 : Float(2, 10, strides=[10, 1], device=cpu) = onnx::Add(%onnx::Add_1363, %onnx::Add_1364) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1366 : Float(2, 10, strides=[10, 1], device=cpu) = onnx::Mul(%onnx::Div_1360, %onnx::Mul_1365) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1367 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.87 : Float(2, 10, strides=[10, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1366, %onnx::Mul_1367) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Tanh_1369 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.87, %autoencoder_quant_model.bottleneck_layers.0.weight, %autoencoder_quant_model.bottleneck_layers.0.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %x : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_1369) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:354:0\n  %onnx::Gemm_1371 : Float(*, *, strides=[20, 1], requires_grad=1, device=cpu) = ^STEFunction()(%x) # /home/hamza/PycharmProjects/StateCompression/state_quantization/activations.py:21:0\n  %onnx::Div_1372 : Float(*, *, strides=[10, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_1371, %autoencoder_quant_model.decoder_layers.0.weight, %autoencoder_quant_model.decoder_layers.0.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_1373 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_1374 : Float(*, *, device=cpu) = onnx::Div(%onnx::Div_1372, %onnx::Div_1373) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1375 : Float(*, *, device=cpu) = onnx::Erf(%onnx::Erf_1374) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1376 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1377 : Float(*, *, device=cpu) = onnx::Add(%onnx::Add_1375, %onnx::Add_1376) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1378 : Float(*, *, device=cpu) = onnx::Mul(%onnx::Div_1372, %onnx::Mul_1377) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1379 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.91 : Float(*, *, strides=[10, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1378, %onnx::Mul_1379) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Div_1381 : Float(*, *, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.91, %autoencoder_quant_model.decoder_layers.3.weight, %autoencoder_quant_model.decoder_layers.3.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_1382 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_1383 : Float(*, *, device=cpu) = onnx::Div(%onnx::Div_1381, %onnx::Div_1382) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1384 : Float(*, *, device=cpu) = onnx::Erf(%onnx::Erf_1383) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1385 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1386 : Float(*, *, device=cpu) = onnx::Add(%onnx::Add_1384, %onnx::Add_1385) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1387 : Float(*, *, device=cpu) = onnx::Mul(%onnx::Div_1381, %onnx::Mul_1386) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1388 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.95 : Float(*, *, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1387, %onnx::Mul_1388) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Div_1390 : Float(*, *, strides=[40, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.95, %autoencoder_quant_model.decoder_layers.6.weight, %autoencoder_quant_model.decoder_layers.6.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_1391 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_1392 : Float(*, *, device=cpu) = onnx::Div(%onnx::Div_1390, %onnx::Div_1391) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1393 : Float(*, *, device=cpu) = onnx::Erf(%onnx::Erf_1392) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1394 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1395 : Float(*, *, device=cpu) = onnx::Add(%onnx::Add_1393, %onnx::Add_1394) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1396 : Float(*, *, device=cpu) = onnx::Mul(%onnx::Div_1390, %onnx::Mul_1395) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1397 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.99 : Float(*, *, strides=[40, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1396, %onnx::Mul_1397) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %1399 : Float(*, *, strides=[40, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.99, %autoencoder_quant_model.decoder_layers.9.weight, %autoencoder_quant_model.decoder_layers.9.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  return (%1341, %1399)\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[0;32mIn [7]\u001B[0m, in \u001B[0;36m<cell line: 7>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      5\u001B[0m model \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mload(model_path)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(train_dataset\u001B[38;5;241m.\u001B[39mx[\u001B[38;5;241m0\u001B[39m:\u001B[38;5;241m2\u001B[39m]\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m----> 7\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43monnx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexport\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mstate_quantization/model.onnx\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/onnx/__init__.py:350\u001B[0m, in \u001B[0;36mexport\u001B[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions)\u001B[0m\n\u001B[1;32m     74\u001B[0m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;124;03mExports a model into ONNX format. If ``model`` is not a\u001B[39;00m\n\u001B[1;32m     76\u001B[0m \u001B[38;5;124;03m:class:`torch.jit.ScriptModule` nor a :class:`torch.jit.ScriptFunction`, this runs\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    345\u001B[0m \u001B[38;5;124;03m    model to the file ``f`` even if this is raised.\u001B[39;00m\n\u001B[1;32m    346\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    348\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01monnx\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m utils\n\u001B[0;32m--> 350\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mutils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexport\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    351\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    352\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    353\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    354\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexport_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    355\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    356\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    357\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    358\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    359\u001B[0m \u001B[43m    \u001B[49m\u001B[43moperator_export_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    360\u001B[0m \u001B[43m    \u001B[49m\u001B[43mopset_version\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    361\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdo_constant_folding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    362\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdynamic_axes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    363\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkeep_initializers_as_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    364\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcustom_opsets\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    365\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexport_modules_as_functions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    366\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/onnx/utils.py:163\u001B[0m, in \u001B[0;36mexport\u001B[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions)\u001B[0m\n\u001B[1;32m    145\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mexport\u001B[39m(\n\u001B[1;32m    146\u001B[0m     model,\n\u001B[1;32m    147\u001B[0m     args,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    160\u001B[0m     export_modules_as_functions\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    161\u001B[0m ):\n\u001B[0;32m--> 163\u001B[0m     \u001B[43m_export\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    164\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    165\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    166\u001B[0m \u001B[43m        \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    167\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexport_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    168\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    169\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    170\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    171\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    172\u001B[0m \u001B[43m        \u001B[49m\u001B[43moperator_export_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moperator_export_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    173\u001B[0m \u001B[43m        \u001B[49m\u001B[43mopset_version\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mopset_version\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    174\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdo_constant_folding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdo_constant_folding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdynamic_axes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdynamic_axes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    176\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkeep_initializers_as_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeep_initializers_as_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    177\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcustom_opsets\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_opsets\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    178\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexport_modules_as_functions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexport_modules_as_functions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    179\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/onnx/utils.py:1110\u001B[0m, in \u001B[0;36m_export\u001B[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions)\u001B[0m\n\u001B[1;32m   1101\u001B[0m params_dict \u001B[38;5;241m=\u001B[39m _C\u001B[38;5;241m.\u001B[39m_jit_pass_onnx_deduplicate_initializers(  \u001B[38;5;66;03m# type: ignore[assignment]\u001B[39;00m\n\u001B[1;32m   1102\u001B[0m     graph, params_dict, \u001B[38;5;28mgetattr\u001B[39m(model, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtraining\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m)  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[1;32m   1103\u001B[0m )\n\u001B[1;32m   1104\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m export_params:\n\u001B[1;32m   1105\u001B[0m     (\n\u001B[1;32m   1106\u001B[0m         proto,\n\u001B[1;32m   1107\u001B[0m         export_map,\n\u001B[1;32m   1108\u001B[0m         val_use_external_data_format,\n\u001B[1;32m   1109\u001B[0m         node_names,\n\u001B[0;32m-> 1110\u001B[0m     ) \u001B[38;5;241m=\u001B[39m \u001B[43mgraph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_export_onnx\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[attr-defined]\u001B[39;49;00m\n\u001B[1;32m   1111\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1112\u001B[0m \u001B[43m        \u001B[49m\u001B[43mopset_version\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1113\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdynamic_axes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1114\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdefer_weight_export\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1115\u001B[0m \u001B[43m        \u001B[49m\u001B[43moperator_export_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1116\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1117\u001B[0m \u001B[43m        \u001B[49m\u001B[43mval_keep_init_as_ip\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1118\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcustom_opsets\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1119\u001B[0m \u001B[43m        \u001B[49m\u001B[43mval_add_node_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1120\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_file_location\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1121\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnode_attr_to_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1122\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1123\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1124\u001B[0m     (\n\u001B[1;32m   1125\u001B[0m         proto,\n\u001B[1;32m   1126\u001B[0m         export_map,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1140\u001B[0m         node_attr_to_name,\n\u001B[1;32m   1141\u001B[0m     )\n",
      "\u001B[0;31mRuntimeError\u001B[0m: ONNX export failed: Couldn't export Python operator STEFunction\n\nDefined at:\n/home/hamza/PycharmProjects/StateCompression/state_quantization/activations.py(21): forward\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/module.py(1118): _slow_forward\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/module.py(1130): _call_impl\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/container.py(139): forward\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/module.py(1118): _slow_forward\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/module.py(1130): _call_impl\n/home/hamza/PycharmProjects/StateCompression/state_quantization/quantization_models.py(201): forward\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/module.py(1118): _slow_forward\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/module.py(1130): _call_impl\n/home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_quantization_models.py(19): forward\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/module.py(1118): _slow_forward\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/module.py(1130): _call_impl\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/jit/_trace.py(118): wrapper\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/jit/_trace.py(127): forward\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/module.py(1130): _call_impl\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/jit/_trace.py(1175): _get_trace_graph\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/onnx/utils.py(517): _trace_and_get_graph_from_model\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/onnx/utils.py(602): _create_jit_graph\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/onnx/utils.py(727): _model_to_graph\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/onnx/utils.py(1074): _export\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/onnx/utils.py(163): export\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/onnx/__init__.py(350): export\n/tmp/ipykernel_39079/2477727706.py(7): <cell line: 7>\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3398): run_code\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3338): run_ast_nodes\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3135): run_cell_async\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/IPython/core/async_helpers.py(129): _pseudo_sync_runner\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py(2936): _run_cell\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py(2881): run_cell\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/ipykernel/zmqshell.py(528): run_cell\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/ipykernel/ipkernel.py(383): do_execute\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/ipykernel/kernelbase.py(730): execute_request\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/ipykernel/kernelbase.py(406): dispatch_shell\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/ipykernel/kernelbase.py(499): process_one\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/ipykernel/kernelbase.py(510): dispatch_queue\n/usr/lib/python3.8/asyncio/events.py(81): _run\n/usr/lib/python3.8/asyncio/base_events.py(1859): _run_once\n/usr/lib/python3.8/asyncio/base_events.py(570): run_forever\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/tornado/platform/asyncio.py(215): start\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/ipykernel/kernelapp.py(712): start\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/traitlets/config/application.py(976): launch_instance\n/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/ipykernel_launcher.py(17): <module>\n/usr/lib/python3.8/runpy.py(87): _run_code\n/usr/lib/python3.8/runpy.py(194): _run_module_as_main\n\n\nGraph we tried to export:\ngraph(%onnx::Gather_0 : Float(2, 39, 6, strides=[234, 6, 1], requires_grad=0, device=cpu),\n      %forcasting_model.lstm_layers.0.weight_ih : Float(80, 6, strides=[6, 1], requires_grad=1, device=cpu),\n      %forcasting_model.lstm_layers.0.weight_hh : Float(80, 20, strides=[20, 1], requires_grad=1, device=cpu),\n      %forcasting_model.lstm_layers.0.bias_ih : Float(80, strides=[1], requires_grad=1, device=cpu),\n      %forcasting_model.lstm_layers.0.bias_hh : Float(80, strides=[1], requires_grad=1, device=cpu),\n      %forcasting_model.fully_connected_layers.0.weight : Float(20, 20, strides=[20, 1], requires_grad=1, device=cpu),\n      %forcasting_model.fully_connected_layers.0.bias : Float(20, strides=[1], requires_grad=1, device=cpu),\n      %forcasting_model.fully_connected_layers.3.weight : Float(20, 20, strides=[20, 1], requires_grad=1, device=cpu),\n      %forcasting_model.fully_connected_layers.3.bias : Float(20, strides=[1], requires_grad=1, device=cpu),\n      %forcasting_model.fully_connected_layers.6.weight : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu),\n      %forcasting_model.fully_connected_layers.6.bias : Float(2, strides=[1], requires_grad=1, device=cpu),\n      %autoencoder_quant_model.encoder_layers.0.weight : Float(40, 40, strides=[40, 1], requires_grad=1, device=cpu),\n      %autoencoder_quant_model.encoder_layers.0.bias : Float(40, strides=[1], requires_grad=1, device=cpu),\n      %autoencoder_quant_model.encoder_layers.3.weight : Float(20, 40, strides=[40, 1], requires_grad=1, device=cpu),\n      %autoencoder_quant_model.encoder_layers.3.bias : Float(20, strides=[1], requires_grad=1, device=cpu),\n      %autoencoder_quant_model.encoder_layers.6.weight : Float(10, 20, strides=[20, 1], requires_grad=1, device=cpu),\n      %autoencoder_quant_model.encoder_layers.6.bias : Float(10, strides=[1], requires_grad=1, device=cpu),\n      %autoencoder_quant_model.bottleneck_layers.0.weight : Float(20, 10, strides=[10, 1], requires_grad=1, device=cpu),\n      %autoencoder_quant_model.bottleneck_layers.0.bias : Float(20, strides=[1], requires_grad=1, device=cpu),\n      %autoencoder_quant_model.decoder_layers.0.weight : Float(10, 20, strides=[20, 1], requires_grad=1, device=cpu),\n      %autoencoder_quant_model.decoder_layers.0.bias : Float(10, strides=[1], requires_grad=1, device=cpu),\n      %autoencoder_quant_model.decoder_layers.3.weight : Float(20, 10, strides=[10, 1], requires_grad=1, device=cpu),\n      %autoencoder_quant_model.decoder_layers.3.bias : Float(20, strides=[1], requires_grad=1, device=cpu),\n      %autoencoder_quant_model.decoder_layers.6.weight : Float(40, 20, strides=[20, 1], requires_grad=1, device=cpu),\n      %autoencoder_quant_model.decoder_layers.6.bias : Float(40, strides=[1], requires_grad=1, device=cpu),\n      %autoencoder_quant_model.decoder_layers.9.weight : Float(40, 40, strides=[40, 1], requires_grad=1, device=cpu),\n      %autoencoder_quant_model.decoder_layers.9.bias : Float(40, strides=[1], requires_grad=1, device=cpu),\n      %onnx::Equal_1401 : Long(2, strides=[1], requires_grad=0, device=cpu),\n      %onnx::ConstantOfShape_1402 : Long(1, strides=[1], requires_grad=0, device=cpu)):\n  %onnx::ConstantOfShape_1435 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::ConstantOfShape_1402)\n  %onnx::ConstantOfShape_1434 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::ConstantOfShape_1402)\n  %onnx::Equal_1433 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::Equal_1401)\n  %onnx::ConstantOfShape_1431 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::ConstantOfShape_1402)\n  %onnx::ConstantOfShape_1430 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::ConstantOfShape_1402)\n  %onnx::Equal_1429 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::Equal_1401)\n  %onnx::ConstantOfShape_1427 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::ConstantOfShape_1402)\n  %onnx::ConstantOfShape_1426 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::ConstantOfShape_1402)\n  %onnx::Equal_1425 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::Equal_1401)\n  %onnx::ConstantOfShape_1423 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::ConstantOfShape_1402)\n  %onnx::ConstantOfShape_1422 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::ConstantOfShape_1402)\n  %onnx::Equal_1421 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::Equal_1401)\n  %onnx::ConstantOfShape_1419 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::ConstantOfShape_1402)\n  %onnx::ConstantOfShape_1418 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::ConstantOfShape_1402)\n  %onnx::Equal_1417 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::Equal_1401)\n  %onnx::ConstantOfShape_1415 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::ConstantOfShape_1402)\n  %onnx::ConstantOfShape_1414 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::ConstantOfShape_1402)\n  %onnx::Equal_1413 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::Equal_1401)\n  %onnx::ConstantOfShape_1411 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::ConstantOfShape_1402)\n  %onnx::ConstantOfShape_1410 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::ConstantOfShape_1402)\n  %onnx::Equal_1409 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::Equal_1401)\n  %onnx::ConstantOfShape_1407 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::ConstantOfShape_1402)\n  %onnx::ConstantOfShape_1406 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::ConstantOfShape_1402)\n  %onnx::Equal_1405 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::Equal_1401)\n  %onnx::ConstantOfShape_1403 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::ConstantOfShape_1402)\n  %onnx::Gather_27 : Long(device=cpu) = onnx::Constant[value={0}]()\n  %onnx::Gemm_28 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_27) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Gemm_29 : Float(2, 20, strides=[20, 1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:118:0\n  %onnx::Add_30 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_29, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_31 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_28, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_32 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_30, %onnx::Add_31) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_33 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_34 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_35 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_36 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_37 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_32, %onnx::Split_33) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_38 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_34) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_39 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_35) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_40 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_36) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_41 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_37) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_42 : Float(2, 20, strides=[20, 1], requires_grad=0, device=cpu) = onnx::Constant[value=<Tensor>]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:119:0\n  %onnx::Add_43 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_39, %onnx::Mul_42) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_44 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_38, %onnx::Mul_40) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_45 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_43, %onnx::Add_44) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_46 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_45) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_47 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_41, %onnx::Mul_46) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_48 : Long(device=cpu) = onnx::Constant[value={1}]()\n  %onnx::Gemm_49 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_48) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_50 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_47, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_51 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_49, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_52 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_50, %onnx::Add_51) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_53 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_54 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_55 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_56 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_57 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_52, %onnx::Split_53) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_58 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_54) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_59 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_55) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_60 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_56) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_61 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_57) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_62 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_59, %onnx::Tanh_45) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_63 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_58, %onnx::Mul_60) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_64 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_62, %onnx::Add_63) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_65 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_64) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_66 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_61, %onnx::Mul_65) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_67 : Long(device=cpu) = onnx::Constant[value={2}]()\n  %onnx::Gemm_68 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_67) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_69 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_66, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_70 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_68, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_71 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_69, %onnx::Add_70) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_72 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_73 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_74 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_75 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_76 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_71, %onnx::Split_72) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_77 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_73) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_78 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_74) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_79 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_75) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_80 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_76) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_81 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_78, %onnx::Tanh_64) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_82 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_77, %onnx::Mul_79) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_83 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_81, %onnx::Add_82) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_84 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_83) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_85 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_80, %onnx::Mul_84) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_86 : Long(device=cpu) = onnx::Constant[value={3}]()\n  %onnx::Gemm_87 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_86) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_88 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_85, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_89 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_87, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_90 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_88, %onnx::Add_89) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_91 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_92 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_93 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_94 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_95 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_90, %onnx::Split_91) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_96 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_92) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_97 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_93) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_98 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_94) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_99 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_95) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_100 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_97, %onnx::Tanh_83) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_101 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_96, %onnx::Mul_98) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_102 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_100, %onnx::Add_101) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_103 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_102) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_104 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_99, %onnx::Mul_103) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_105 : Long(device=cpu) = onnx::Constant[value={4}]()\n  %onnx::Gemm_106 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_105) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_107 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_104, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_108 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_106, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_109 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_107, %onnx::Add_108) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_110 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_111 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_112 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_113 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_114 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_109, %onnx::Split_110) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_115 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_111) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_116 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_112) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_117 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_113) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_118 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_114) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_119 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_116, %onnx::Tanh_102) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_120 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_115, %onnx::Mul_117) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_121 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_119, %onnx::Add_120) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_122 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_121) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_123 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_118, %onnx::Mul_122) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_124 : Long(device=cpu) = onnx::Constant[value={5}]()\n  %onnx::Gemm_125 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_124) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_126 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_123, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_127 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_125, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_128 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_126, %onnx::Add_127) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_129 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_130 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_131 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_132 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_133 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_128, %onnx::Split_129) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_134 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_130) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_135 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_131) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_136 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_132) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_137 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_133) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_138 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_135, %onnx::Tanh_121) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_139 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_134, %onnx::Mul_136) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_140 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_138, %onnx::Add_139) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_141 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_140) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_142 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_137, %onnx::Mul_141) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_143 : Long(device=cpu) = onnx::Constant[value={6}]()\n  %onnx::Gemm_144 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_143) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_145 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_142, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_146 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_144, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_147 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_145, %onnx::Add_146) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_148 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_149 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_150 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_151 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_152 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_147, %onnx::Split_148) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_153 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_149) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_154 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_150) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_155 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_151) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_156 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_152) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_157 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_154, %onnx::Tanh_140) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_158 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_153, %onnx::Mul_155) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_159 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_157, %onnx::Add_158) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_160 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_159) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_161 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_156, %onnx::Mul_160) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_162 : Long(device=cpu) = onnx::Constant[value={7}]()\n  %onnx::Gemm_163 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_162) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_164 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_161, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_165 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_163, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_166 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_164, %onnx::Add_165) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_167 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_168 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_169 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_170 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_171 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_166, %onnx::Split_167) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_172 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_168) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_173 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_169) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_174 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_170) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_175 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_171) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_176 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_173, %onnx::Tanh_159) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_177 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_172, %onnx::Mul_174) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_178 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_176, %onnx::Add_177) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_179 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_178) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_180 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_175, %onnx::Mul_179) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_181 : Long(device=cpu) = onnx::Constant[value={8}]()\n  %onnx::Gemm_182 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_181) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_183 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_180, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_184 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_182, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_185 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_183, %onnx::Add_184) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_186 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_187 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_188 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_189 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_190 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_185, %onnx::Split_186) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_191 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_187) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_192 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_188) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_193 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_189) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_194 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_190) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_195 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_192, %onnx::Tanh_178) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_196 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_191, %onnx::Mul_193) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_197 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_195, %onnx::Add_196) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_198 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_197) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_199 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_194, %onnx::Mul_198) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_200 : Long(device=cpu) = onnx::Constant[value={9}]()\n  %onnx::Gemm_201 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_200) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_202 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_199, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_203 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_201, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_204 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_202, %onnx::Add_203) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_205 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_206 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_207 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_208 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_209 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_204, %onnx::Split_205) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_210 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_206) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_211 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_207) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_212 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_208) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_213 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_209) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_214 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_211, %onnx::Tanh_197) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_215 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_210, %onnx::Mul_212) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_216 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_214, %onnx::Add_215) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_217 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_216) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_218 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_213, %onnx::Mul_217) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_219 : Long(device=cpu) = onnx::Constant[value={10}]()\n  %onnx::Gemm_220 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_219) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_221 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_218, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_222 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_220, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_223 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_221, %onnx::Add_222) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_224 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_225 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_226 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_227 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_228 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_223, %onnx::Split_224) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_229 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_225) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_230 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_226) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_231 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_227) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_232 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_228) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_233 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_230, %onnx::Tanh_216) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_234 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_229, %onnx::Mul_231) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_235 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_233, %onnx::Add_234) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_236 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_235) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_237 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_232, %onnx::Mul_236) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_238 : Long(device=cpu) = onnx::Constant[value={11}]()\n  %onnx::Gemm_239 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_238) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_240 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_237, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_241 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_239, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_242 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_240, %onnx::Add_241) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_243 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_244 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_245 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_246 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_247 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_242, %onnx::Split_243) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_248 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_244) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_249 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_245) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_250 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_246) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_251 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_247) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_252 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_249, %onnx::Tanh_235) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_253 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_248, %onnx::Mul_250) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_254 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_252, %onnx::Add_253) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_255 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_254) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_256 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_251, %onnx::Mul_255) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_257 : Long(device=cpu) = onnx::Constant[value={12}]()\n  %onnx::Gemm_258 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_257) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_259 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_256, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_260 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_258, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_261 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_259, %onnx::Add_260) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_262 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_263 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_264 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_265 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_266 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_261, %onnx::Split_262) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_267 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_263) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_268 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_264) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_269 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_265) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_270 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_266) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_271 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_268, %onnx::Tanh_254) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_272 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_267, %onnx::Mul_269) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_273 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_271, %onnx::Add_272) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_274 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_273) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_275 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_270, %onnx::Mul_274) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_276 : Long(device=cpu) = onnx::Constant[value={13}]()\n  %onnx::Gemm_277 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_276) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_278 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_275, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_279 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_277, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_280 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_278, %onnx::Add_279) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_281 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_282 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_283 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_284 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_285 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_280, %onnx::Split_281) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_286 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_282) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_287 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_283) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_288 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_284) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_289 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_285) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_290 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_287, %onnx::Tanh_273) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_291 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_286, %onnx::Mul_288) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_292 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_290, %onnx::Add_291) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_293 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_292) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_294 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_289, %onnx::Mul_293) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_295 : Long(device=cpu) = onnx::Constant[value={14}]()\n  %onnx::Gemm_296 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_295) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_297 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_294, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_298 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_296, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_299 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_297, %onnx::Add_298) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_300 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_301 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_302 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_303 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_304 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_299, %onnx::Split_300) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_305 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_301) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_306 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_302) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_307 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_303) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_308 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_304) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_309 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_306, %onnx::Tanh_292) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_310 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_305, %onnx::Mul_307) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_311 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_309, %onnx::Add_310) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_312 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_311) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_313 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_308, %onnx::Mul_312) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_314 : Long(device=cpu) = onnx::Constant[value={15}]()\n  %onnx::Gemm_315 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_314) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_316 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_313, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_317 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_315, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_318 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_316, %onnx::Add_317) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_319 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_320 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_321 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_322 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_323 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_318, %onnx::Split_319) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_324 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_320) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_325 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_321) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_326 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_322) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_327 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_323) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_328 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_325, %onnx::Tanh_311) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_329 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_324, %onnx::Mul_326) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_330 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_328, %onnx::Add_329) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_331 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_330) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_332 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_327, %onnx::Mul_331) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_333 : Long(device=cpu) = onnx::Constant[value={16}]()\n  %onnx::Gemm_334 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_333) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_335 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_332, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_336 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_334, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_337 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_335, %onnx::Add_336) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_338 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_339 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_340 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_341 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_342 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_337, %onnx::Split_338) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_343 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_339) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_344 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_340) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_345 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_341) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_346 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_342) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_347 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_344, %onnx::Tanh_330) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_348 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_343, %onnx::Mul_345) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_349 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_347, %onnx::Add_348) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_350 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_349) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_351 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_346, %onnx::Mul_350) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_352 : Long(device=cpu) = onnx::Constant[value={17}]()\n  %onnx::Gemm_353 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_352) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_354 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_351, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_355 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_353, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_356 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_354, %onnx::Add_355) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_357 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_358 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_359 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_360 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_361 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_356, %onnx::Split_357) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_362 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_358) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_363 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_359) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_364 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_360) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_365 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_361) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_366 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_363, %onnx::Tanh_349) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_367 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_362, %onnx::Mul_364) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_368 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_366, %onnx::Add_367) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_369 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_368) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_370 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_365, %onnx::Mul_369) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_371 : Long(device=cpu) = onnx::Constant[value={18}]()\n  %onnx::Gemm_372 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_371) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_373 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_370, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_374 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_372, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_375 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_373, %onnx::Add_374) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_376 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_377 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_378 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_379 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_380 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_375, %onnx::Split_376) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_381 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_377) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_382 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_378) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_383 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_379) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_384 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_380) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_385 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_382, %onnx::Tanh_368) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_386 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_381, %onnx::Mul_383) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_387 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_385, %onnx::Add_386) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_388 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_387) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_389 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_384, %onnx::Mul_388) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_390 : Long(device=cpu) = onnx::Constant[value={19}]()\n  %onnx::Gemm_391 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_390) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_392 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_389, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_393 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_391, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_394 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_392, %onnx::Add_393) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_395 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_396 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_397 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_398 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_399 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_394, %onnx::Split_395) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_400 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_396) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_401 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_397) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_402 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_398) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_403 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_399) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_404 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_401, %onnx::Tanh_387) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_405 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_400, %onnx::Mul_402) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_406 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_404, %onnx::Add_405) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_407 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_406) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_408 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_403, %onnx::Mul_407) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_409 : Long(device=cpu) = onnx::Constant[value={20}]()\n  %onnx::Gemm_410 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_409) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_411 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_408, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_412 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_410, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_413 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_411, %onnx::Add_412) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_414 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_415 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_416 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_417 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_418 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_413, %onnx::Split_414) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_419 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_415) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_420 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_416) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_421 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_417) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_422 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_418) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_423 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_420, %onnx::Tanh_406) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_424 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_419, %onnx::Mul_421) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_425 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_423, %onnx::Add_424) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_426 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_425) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_427 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_422, %onnx::Mul_426) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_428 : Long(device=cpu) = onnx::Constant[value={21}]()\n  %onnx::Gemm_429 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_428) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_430 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_427, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_431 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_429, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_432 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_430, %onnx::Add_431) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_433 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_434 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_435 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_436 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_437 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_432, %onnx::Split_433) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_438 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_434) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_439 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_435) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_440 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_436) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_441 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_437) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_442 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_439, %onnx::Tanh_425) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_443 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_438, %onnx::Mul_440) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_444 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_442, %onnx::Add_443) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_445 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_444) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_446 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_441, %onnx::Mul_445) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_447 : Long(device=cpu) = onnx::Constant[value={22}]()\n  %onnx::Gemm_448 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_447) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_449 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_446, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_450 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_448, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_451 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_449, %onnx::Add_450) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_452 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_453 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_454 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_455 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_456 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_451, %onnx::Split_452) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_457 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_453) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_458 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_454) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_459 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_455) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_460 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_456) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_461 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_458, %onnx::Tanh_444) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_462 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_457, %onnx::Mul_459) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_463 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_461, %onnx::Add_462) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_464 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_463) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_465 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_460, %onnx::Mul_464) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_466 : Long(device=cpu) = onnx::Constant[value={23}]()\n  %onnx::Gemm_467 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_466) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_468 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_465, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_469 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_467, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_470 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_468, %onnx::Add_469) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_471 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_472 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_473 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_474 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_475 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_470, %onnx::Split_471) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_476 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_472) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_477 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_473) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_478 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_474) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_479 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_475) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_480 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_477, %onnx::Tanh_463) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_481 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_476, %onnx::Mul_478) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_482 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_480, %onnx::Add_481) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_483 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_482) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_484 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_479, %onnx::Mul_483) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_485 : Long(device=cpu) = onnx::Constant[value={24}]()\n  %onnx::Gemm_486 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_485) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_487 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_484, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_488 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_486, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_489 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_487, %onnx::Add_488) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_490 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_491 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_492 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_493 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_494 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_489, %onnx::Split_490) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_495 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_491) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_496 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_492) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_497 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_493) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_498 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_494) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_499 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_496, %onnx::Tanh_482) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_500 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_495, %onnx::Mul_497) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_501 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_499, %onnx::Add_500) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_502 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_501) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_503 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_498, %onnx::Mul_502) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_504 : Long(device=cpu) = onnx::Constant[value={25}]()\n  %onnx::Gemm_505 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_504) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_506 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_503, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_507 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_505, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_508 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_506, %onnx::Add_507) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_509 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_510 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_511 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_512 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_513 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_508, %onnx::Split_509) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_514 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_510) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_515 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_511) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_516 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_512) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_517 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_513) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_518 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_515, %onnx::Tanh_501) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_519 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_514, %onnx::Mul_516) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_520 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_518, %onnx::Add_519) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_521 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_520) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_522 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_517, %onnx::Mul_521) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_523 : Long(device=cpu) = onnx::Constant[value={26}]()\n  %onnx::Gemm_524 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_523) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_525 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_522, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_526 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_524, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_527 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_525, %onnx::Add_526) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_528 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_529 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_530 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_531 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_532 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_527, %onnx::Split_528) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_533 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_529) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_534 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_530) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_535 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_531) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_536 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_532) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_537 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_534, %onnx::Tanh_520) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_538 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_533, %onnx::Mul_535) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_539 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_537, %onnx::Add_538) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_540 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_539) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_541 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_536, %onnx::Mul_540) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_542 : Long(device=cpu) = onnx::Constant[value={27}]()\n  %onnx::Gemm_543 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_542) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_544 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_541, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_545 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_543, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_546 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_544, %onnx::Add_545) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_547 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_548 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_549 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_550 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_551 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_546, %onnx::Split_547) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_552 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_548) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_553 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_549) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_554 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_550) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_555 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_551) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_556 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_553, %onnx::Tanh_539) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_557 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_552, %onnx::Mul_554) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_558 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_556, %onnx::Add_557) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_559 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_558) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_560 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_555, %onnx::Mul_559) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_561 : Long(device=cpu) = onnx::Constant[value={28}]()\n  %onnx::Gemm_562 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_561) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_563 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_560, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_564 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_562, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_565 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_563, %onnx::Add_564) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_566 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_567 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_568 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_569 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_570 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_565, %onnx::Split_566) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_571 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_567) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_572 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_568) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_573 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_569) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_574 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_570) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_575 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_572, %onnx::Tanh_558) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_576 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_571, %onnx::Mul_573) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_577 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_575, %onnx::Add_576) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_578 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_577) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_579 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_574, %onnx::Mul_578) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gather_580 : Long(device=cpu) = onnx::Constant[value={29}]()\n  %onnx::Gemm_581 : Float(2, 6, strides=[234, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_580) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:86:0\n  %onnx::Add_582 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_579, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_583 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_581, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_584 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_582, %onnx::Add_583) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_585 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_586 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_587 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_588 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_589 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_584, %onnx::Split_585) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_590 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_586) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_591 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_587) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_592 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_588) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_593 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_589) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_594 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_591, %onnx::Tanh_577) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_595 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_590, %onnx::Mul_592) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_596 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_594, %onnx::Add_595) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_597 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_596) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Concat_598 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_593, %onnx::Mul_597) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_599 : Float(2, 40, strides=[40, 1], requires_grad=0, device=cpu) = onnx::Concat[axis=1](%onnx::Concat_598, %onnx::Tanh_596) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:88:0\n  %onnx::Div_600 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Concat_598, %forcasting_model.fully_connected_layers.0.weight, %forcasting_model.fully_connected_layers.0.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_601 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_602 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Div(%onnx::Div_600, %onnx::Div_601) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_603 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Erf(%onnx::Erf_602) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_604 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_605 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Add(%onnx::Add_603, %onnx::Add_604) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_606 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Mul(%onnx::Div_600, %onnx::Mul_605) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_607 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_606, %onnx::Mul_607) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Div_609 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input, %forcasting_model.fully_connected_layers.3.weight, %forcasting_model.fully_connected_layers.3.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_610 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_611 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Div(%onnx::Div_609, %onnx::Div_610) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_612 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Erf(%onnx::Erf_611) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_613 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_614 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Add(%onnx::Add_612, %onnx::Add_613) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_615 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Mul(%onnx::Div_609, %onnx::Mul_614) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_616 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.3 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_615, %onnx::Mul_616) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Unsqueeze_618 : Float(2, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.3, %forcasting_model.fully_connected_layers.6.weight, %forcasting_model.fully_connected_layers.6.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Unsqueeze_619 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:91:0\n  %onnx::Concat_620 : Float(2, 1, 2, strides=[2, 2, 1], requires_grad=1, device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_618, %onnx::Unsqueeze_619) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:91:0\n  %onnx::Gather_621 : Long(device=cpu) = onnx::Constant[value={30}]()\n  %onnx::Slice_622 : Float(2, 6, strides=[6, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_621) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:93:0\n  %onnx::Slice_623 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_624 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_625 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={6}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_626 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Shape_627 : Float(2, 2, strides=[6, 1], requires_grad=0, device=cpu) = onnx::Slice(%onnx::Slice_622, %onnx::Slice_624, %onnx::Slice_625, %onnx::Slice_623, %onnx::Slice_626) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_628 : Long(2, strides=[1], device=cpu) = onnx::Shape(%onnx::Shape_627) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Reshape_629 : Float(2, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Expand(%onnx::Unsqueeze_618, %onnx::Expand_628) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_630 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 4  5 [ CPULongType{2} ]]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_631 : Long(2, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Constant[value= 0  1 [ CPULongType{2,1} ]]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_637 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%onnx::ConstantOfShape_1402) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_638 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Equal_639 : Long(2, strides=[1], device=cpu) = onnx::Mul(%onnx::Mul_637, %onnx::Mul_638) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Where_640 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%onnx::Equal_1401, %onnx::Equal_639) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_641 : Long(2, strides=[1], device=cpu) = onnx::Where(%onnx::Where_640, %onnx::Mul_637, %onnx::Equal_1401) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_642 : Long(2, 2, device=cpu) = onnx::Expand(%onnx::Expand_631, %onnx::Expand_641) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_643 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_644 : Long(2, 2, 1, strides=[2, 1, 1], device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_642, %onnx::Unsqueeze_643) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_646 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%onnx::ConstantOfShape_1403) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_647 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Equal_648 : Long(2, strides=[1], device=cpu) = onnx::Mul(%onnx::Mul_646, %onnx::Mul_647) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Where_649 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%onnx::Equal_1401, %onnx::Equal_648) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_650 : Long(2, strides=[1], device=cpu) = onnx::Where(%onnx::Where_649, %onnx::Mul_646, %onnx::Equal_1401) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_651 : Long(2, 2, device=cpu) = onnx::Expand(%onnx::Expand_630, %onnx::Expand_650) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_652 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_653 : Long(2, 2, 1, strides=[2, 1, 1], device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_651, %onnx::Unsqueeze_652) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::ScatterND_654 : Long(2, 2, 2, strides=[4, 2, 1], device=cpu) = onnx::Concat[axis=-1](%onnx::Concat_644, %onnx::Concat_653) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_655 : Long(2, strides=[1], device=cpu) = onnx::Shape(%onnx::Slice_622) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_656 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_657 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_658 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_659 : Long(0, strides=[1], device=cpu) = onnx::Slice(%onnx::Slice_655, %onnx::Slice_657, %onnx::Slice_658, %onnx::Slice_656) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Reshape_660 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Equal_1401, %onnx::Concat_659) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::ScatterND_661 : Float(2, 2, device=cpu) = onnx::Reshape(%onnx::Reshape_629, %onnx::Reshape_660) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Gemm_662 : Float(2, 6, strides=[6, 1], requires_grad=1, device=cpu) = onnx::ScatterND(%onnx::Slice_622, %onnx::ScatterND_654, %onnx::ScatterND_661) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Add_663 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Concat_598, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_664 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_662, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_665 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_663, %onnx::Add_664) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_666 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_667 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_668 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_669 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_670 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_665, %onnx::Split_666) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_671 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_667) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_672 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_668) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_673 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_669) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_674 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_670) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_675 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_672, %onnx::Tanh_596) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_676 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_671, %onnx::Mul_673) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_677 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_675, %onnx::Add_676) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_678 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_677) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_679 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_674, %onnx::Mul_678) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Div_680 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_679, %forcasting_model.fully_connected_layers.0.weight, %forcasting_model.fully_connected_layers.0.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_681 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_682 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Div(%onnx::Div_680, %onnx::Div_681) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_683 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Erf(%onnx::Erf_682) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_684 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_685 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Add(%onnx::Add_683, %onnx::Add_684) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_686 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Mul(%onnx::Div_680, %onnx::Mul_685) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_687 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.7 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_686, %onnx::Mul_687) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Div_689 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.7, %forcasting_model.fully_connected_layers.3.weight, %forcasting_model.fully_connected_layers.3.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_690 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_691 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Div(%onnx::Div_689, %onnx::Div_690) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_692 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Erf(%onnx::Erf_691) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_693 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_694 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Add(%onnx::Add_692, %onnx::Add_693) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_695 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Mul(%onnx::Div_689, %onnx::Mul_694) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_696 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.11 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_695, %onnx::Mul_696) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Unsqueeze_698 : Float(2, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.11, %forcasting_model.fully_connected_layers.6.weight, %forcasting_model.fully_connected_layers.6.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Unsqueeze_699 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:99:0\n  %onnx::Concat_700 : Float(2, 1, 2, strides=[2, 2, 1], requires_grad=1, device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_698, %onnx::Unsqueeze_699) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:99:0\n  %onnx::Gather_701 : Long(device=cpu) = onnx::Constant[value={31}]()\n  %onnx::Slice_702 : Float(2, 6, strides=[6, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_701) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:93:0\n  %onnx::Slice_703 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_704 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_705 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={6}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_706 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Shape_707 : Float(2, 2, strides=[6, 1], requires_grad=0, device=cpu) = onnx::Slice(%onnx::Slice_702, %onnx::Slice_704, %onnx::Slice_705, %onnx::Slice_703, %onnx::Slice_706) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_708 : Long(2, strides=[1], device=cpu) = onnx::Shape(%onnx::Shape_707) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Reshape_709 : Float(2, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Expand(%onnx::Unsqueeze_698, %onnx::Expand_708) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_710 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 4  5 [ CPULongType{2} ]]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_711 : Long(2, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Constant[value= 0  1 [ CPULongType{2,1} ]]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_717 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%onnx::ConstantOfShape_1406) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_718 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Equal_719 : Long(2, strides=[1], device=cpu) = onnx::Mul(%onnx::Mul_717, %onnx::Mul_718) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Where_720 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%onnx::Equal_1405, %onnx::Equal_719) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_721 : Long(2, strides=[1], device=cpu) = onnx::Where(%onnx::Where_720, %onnx::Mul_717, %onnx::Equal_1405) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_722 : Long(2, 2, device=cpu) = onnx::Expand(%onnx::Expand_711, %onnx::Expand_721) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_723 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_724 : Long(2, 2, 1, strides=[2, 1, 1], device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_722, %onnx::Unsqueeze_723) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_726 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%onnx::ConstantOfShape_1407) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_727 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Equal_728 : Long(2, strides=[1], device=cpu) = onnx::Mul(%onnx::Mul_726, %onnx::Mul_727) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Where_729 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%onnx::Equal_1405, %onnx::Equal_728) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_730 : Long(2, strides=[1], device=cpu) = onnx::Where(%onnx::Where_729, %onnx::Mul_726, %onnx::Equal_1405) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_731 : Long(2, 2, device=cpu) = onnx::Expand(%onnx::Expand_710, %onnx::Expand_730) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_732 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_733 : Long(2, 2, 1, strides=[2, 1, 1], device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_731, %onnx::Unsqueeze_732) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::ScatterND_734 : Long(2, 2, 2, strides=[4, 2, 1], device=cpu) = onnx::Concat[axis=-1](%onnx::Concat_724, %onnx::Concat_733) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_735 : Long(2, strides=[1], device=cpu) = onnx::Shape(%onnx::Slice_702) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_736 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_737 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_738 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_739 : Long(0, strides=[1], device=cpu) = onnx::Slice(%onnx::Slice_735, %onnx::Slice_737, %onnx::Slice_738, %onnx::Slice_736) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Reshape_740 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Equal_1405, %onnx::Concat_739) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::ScatterND_741 : Float(2, 2, device=cpu) = onnx::Reshape(%onnx::Reshape_709, %onnx::Reshape_740) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Gemm_742 : Float(2, 6, strides=[6, 1], requires_grad=1, device=cpu) = onnx::ScatterND(%onnx::Slice_702, %onnx::ScatterND_734, %onnx::ScatterND_741) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Add_743 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_679, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_744 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_742, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_745 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_743, %onnx::Add_744) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_746 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_747 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_748 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_749 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_750 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_745, %onnx::Split_746) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_751 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_747) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_752 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_748) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_753 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_749) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_754 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_750) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_755 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_752, %onnx::Tanh_677) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_756 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_751, %onnx::Mul_753) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_757 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_755, %onnx::Add_756) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_758 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_757) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_759 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_754, %onnx::Mul_758) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Div_760 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_759, %forcasting_model.fully_connected_layers.0.weight, %forcasting_model.fully_connected_layers.0.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_761 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_762 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Div(%onnx::Div_760, %onnx::Div_761) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_763 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Erf(%onnx::Erf_762) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_764 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_765 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Add(%onnx::Add_763, %onnx::Add_764) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_766 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Mul(%onnx::Div_760, %onnx::Mul_765) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_767 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.15 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_766, %onnx::Mul_767) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Div_769 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.15, %forcasting_model.fully_connected_layers.3.weight, %forcasting_model.fully_connected_layers.3.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_770 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_771 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Div(%onnx::Div_769, %onnx::Div_770) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_772 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Erf(%onnx::Erf_771) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_773 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_774 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Add(%onnx::Add_772, %onnx::Add_773) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_775 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Mul(%onnx::Div_769, %onnx::Mul_774) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_776 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.19 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_775, %onnx::Mul_776) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Unsqueeze_778 : Float(2, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.19, %forcasting_model.fully_connected_layers.6.weight, %forcasting_model.fully_connected_layers.6.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Unsqueeze_779 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:99:0\n  %onnx::Concat_780 : Float(2, 1, 2, strides=[2, 2, 1], requires_grad=1, device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_778, %onnx::Unsqueeze_779) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:99:0\n  %onnx::Gather_781 : Long(device=cpu) = onnx::Constant[value={32}]()\n  %onnx::Slice_782 : Float(2, 6, strides=[6, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_781) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:93:0\n  %onnx::Slice_783 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_784 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_785 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={6}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_786 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Shape_787 : Float(2, 2, strides=[6, 1], requires_grad=0, device=cpu) = onnx::Slice(%onnx::Slice_782, %onnx::Slice_784, %onnx::Slice_785, %onnx::Slice_783, %onnx::Slice_786) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_788 : Long(2, strides=[1], device=cpu) = onnx::Shape(%onnx::Shape_787) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Reshape_789 : Float(2, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Expand(%onnx::Unsqueeze_778, %onnx::Expand_788) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_790 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 4  5 [ CPULongType{2} ]]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_791 : Long(2, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Constant[value= 0  1 [ CPULongType{2,1} ]]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_797 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%onnx::ConstantOfShape_1410) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_798 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Equal_799 : Long(2, strides=[1], device=cpu) = onnx::Mul(%onnx::Mul_797, %onnx::Mul_798) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Where_800 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%onnx::Equal_1409, %onnx::Equal_799) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_801 : Long(2, strides=[1], device=cpu) = onnx::Where(%onnx::Where_800, %onnx::Mul_797, %onnx::Equal_1409) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_802 : Long(2, 2, device=cpu) = onnx::Expand(%onnx::Expand_791, %onnx::Expand_801) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_803 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_804 : Long(2, 2, 1, strides=[2, 1, 1], device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_802, %onnx::Unsqueeze_803) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_806 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%onnx::ConstantOfShape_1411) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_807 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Equal_808 : Long(2, strides=[1], device=cpu) = onnx::Mul(%onnx::Mul_806, %onnx::Mul_807) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Where_809 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%onnx::Equal_1409, %onnx::Equal_808) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_810 : Long(2, strides=[1], device=cpu) = onnx::Where(%onnx::Where_809, %onnx::Mul_806, %onnx::Equal_1409) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_811 : Long(2, 2, device=cpu) = onnx::Expand(%onnx::Expand_790, %onnx::Expand_810) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_812 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_813 : Long(2, 2, 1, strides=[2, 1, 1], device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_811, %onnx::Unsqueeze_812) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::ScatterND_814 : Long(2, 2, 2, strides=[4, 2, 1], device=cpu) = onnx::Concat[axis=-1](%onnx::Concat_804, %onnx::Concat_813) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_815 : Long(2, strides=[1], device=cpu) = onnx::Shape(%onnx::Slice_782) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_816 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_817 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_818 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_819 : Long(0, strides=[1], device=cpu) = onnx::Slice(%onnx::Slice_815, %onnx::Slice_817, %onnx::Slice_818, %onnx::Slice_816) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Reshape_820 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Equal_1409, %onnx::Concat_819) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::ScatterND_821 : Float(2, 2, device=cpu) = onnx::Reshape(%onnx::Reshape_789, %onnx::Reshape_820) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Gemm_822 : Float(2, 6, strides=[6, 1], requires_grad=1, device=cpu) = onnx::ScatterND(%onnx::Slice_782, %onnx::ScatterND_814, %onnx::ScatterND_821) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Add_823 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_759, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_824 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_822, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_825 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_823, %onnx::Add_824) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_826 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_827 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_828 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_829 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_830 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_825, %onnx::Split_826) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_831 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_827) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_832 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_828) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_833 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_829) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_834 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_830) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_835 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_832, %onnx::Tanh_757) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_836 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_831, %onnx::Mul_833) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_837 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_835, %onnx::Add_836) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_838 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_837) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_839 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_834, %onnx::Mul_838) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Div_840 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_839, %forcasting_model.fully_connected_layers.0.weight, %forcasting_model.fully_connected_layers.0.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_841 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_842 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Div(%onnx::Div_840, %onnx::Div_841) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_843 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Erf(%onnx::Erf_842) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_844 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_845 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Add(%onnx::Add_843, %onnx::Add_844) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_846 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Mul(%onnx::Div_840, %onnx::Mul_845) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_847 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.23 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_846, %onnx::Mul_847) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Div_849 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.23, %forcasting_model.fully_connected_layers.3.weight, %forcasting_model.fully_connected_layers.3.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_850 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_851 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Div(%onnx::Div_849, %onnx::Div_850) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_852 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Erf(%onnx::Erf_851) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_853 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_854 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Add(%onnx::Add_852, %onnx::Add_853) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_855 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Mul(%onnx::Div_849, %onnx::Mul_854) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_856 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.27 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_855, %onnx::Mul_856) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Unsqueeze_858 : Float(2, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.27, %forcasting_model.fully_connected_layers.6.weight, %forcasting_model.fully_connected_layers.6.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Unsqueeze_859 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:99:0\n  %onnx::Concat_860 : Float(2, 1, 2, strides=[2, 2, 1], requires_grad=1, device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_858, %onnx::Unsqueeze_859) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:99:0\n  %onnx::Gather_861 : Long(device=cpu) = onnx::Constant[value={33}]()\n  %onnx::Slice_862 : Float(2, 6, strides=[6, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_861) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:93:0\n  %onnx::Slice_863 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_864 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_865 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={6}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_866 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Shape_867 : Float(2, 2, strides=[6, 1], requires_grad=0, device=cpu) = onnx::Slice(%onnx::Slice_862, %onnx::Slice_864, %onnx::Slice_865, %onnx::Slice_863, %onnx::Slice_866) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_868 : Long(2, strides=[1], device=cpu) = onnx::Shape(%onnx::Shape_867) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Reshape_869 : Float(2, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Expand(%onnx::Unsqueeze_858, %onnx::Expand_868) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_870 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 4  5 [ CPULongType{2} ]]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_871 : Long(2, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Constant[value= 0  1 [ CPULongType{2,1} ]]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_877 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%onnx::ConstantOfShape_1414) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_878 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Equal_879 : Long(2, strides=[1], device=cpu) = onnx::Mul(%onnx::Mul_877, %onnx::Mul_878) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Where_880 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%onnx::Equal_1413, %onnx::Equal_879) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_881 : Long(2, strides=[1], device=cpu) = onnx::Where(%onnx::Where_880, %onnx::Mul_877, %onnx::Equal_1413) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_882 : Long(2, 2, device=cpu) = onnx::Expand(%onnx::Expand_871, %onnx::Expand_881) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_883 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_884 : Long(2, 2, 1, strides=[2, 1, 1], device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_882, %onnx::Unsqueeze_883) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_886 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%onnx::ConstantOfShape_1415) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_887 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Equal_888 : Long(2, strides=[1], device=cpu) = onnx::Mul(%onnx::Mul_886, %onnx::Mul_887) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Where_889 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%onnx::Equal_1413, %onnx::Equal_888) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_890 : Long(2, strides=[1], device=cpu) = onnx::Where(%onnx::Where_889, %onnx::Mul_886, %onnx::Equal_1413) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_891 : Long(2, 2, device=cpu) = onnx::Expand(%onnx::Expand_870, %onnx::Expand_890) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_892 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_893 : Long(2, 2, 1, strides=[2, 1, 1], device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_891, %onnx::Unsqueeze_892) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::ScatterND_894 : Long(2, 2, 2, strides=[4, 2, 1], device=cpu) = onnx::Concat[axis=-1](%onnx::Concat_884, %onnx::Concat_893) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_895 : Long(2, strides=[1], device=cpu) = onnx::Shape(%onnx::Slice_862) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_896 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_897 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_898 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_899 : Long(0, strides=[1], device=cpu) = onnx::Slice(%onnx::Slice_895, %onnx::Slice_897, %onnx::Slice_898, %onnx::Slice_896) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Reshape_900 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Equal_1413, %onnx::Concat_899) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::ScatterND_901 : Float(2, 2, device=cpu) = onnx::Reshape(%onnx::Reshape_869, %onnx::Reshape_900) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Gemm_902 : Float(2, 6, strides=[6, 1], requires_grad=1, device=cpu) = onnx::ScatterND(%onnx::Slice_862, %onnx::ScatterND_894, %onnx::ScatterND_901) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Add_903 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_839, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_904 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_902, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_905 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_903, %onnx::Add_904) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_906 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_907 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_908 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_909 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_910 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_905, %onnx::Split_906) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_911 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_907) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_912 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_908) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_913 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_909) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_914 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_910) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_915 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_912, %onnx::Tanh_837) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_916 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_911, %onnx::Mul_913) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_917 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_915, %onnx::Add_916) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_918 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_917) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_919 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_914, %onnx::Mul_918) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Div_920 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_919, %forcasting_model.fully_connected_layers.0.weight, %forcasting_model.fully_connected_layers.0.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_921 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_922 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Div(%onnx::Div_920, %onnx::Div_921) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_923 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Erf(%onnx::Erf_922) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_924 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_925 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Add(%onnx::Add_923, %onnx::Add_924) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_926 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Mul(%onnx::Div_920, %onnx::Mul_925) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_927 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.31 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_926, %onnx::Mul_927) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Div_929 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.31, %forcasting_model.fully_connected_layers.3.weight, %forcasting_model.fully_connected_layers.3.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_930 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_931 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Div(%onnx::Div_929, %onnx::Div_930) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_932 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Erf(%onnx::Erf_931) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_933 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_934 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Add(%onnx::Add_932, %onnx::Add_933) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_935 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Mul(%onnx::Div_929, %onnx::Mul_934) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_936 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.35 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_935, %onnx::Mul_936) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Unsqueeze_938 : Float(2, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.35, %forcasting_model.fully_connected_layers.6.weight, %forcasting_model.fully_connected_layers.6.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Unsqueeze_939 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:99:0\n  %onnx::Concat_940 : Float(2, 1, 2, strides=[2, 2, 1], requires_grad=1, device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_938, %onnx::Unsqueeze_939) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:99:0\n  %onnx::Gather_941 : Long(device=cpu) = onnx::Constant[value={34}]()\n  %onnx::Slice_942 : Float(2, 6, strides=[6, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_941) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:93:0\n  %onnx::Slice_943 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_944 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_945 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={6}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_946 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Shape_947 : Float(2, 2, strides=[6, 1], requires_grad=0, device=cpu) = onnx::Slice(%onnx::Slice_942, %onnx::Slice_944, %onnx::Slice_945, %onnx::Slice_943, %onnx::Slice_946) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_948 : Long(2, strides=[1], device=cpu) = onnx::Shape(%onnx::Shape_947) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Reshape_949 : Float(2, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Expand(%onnx::Unsqueeze_938, %onnx::Expand_948) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_950 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 4  5 [ CPULongType{2} ]]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_951 : Long(2, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Constant[value= 0  1 [ CPULongType{2,1} ]]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_957 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%onnx::ConstantOfShape_1418) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_958 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Equal_959 : Long(2, strides=[1], device=cpu) = onnx::Mul(%onnx::Mul_957, %onnx::Mul_958) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Where_960 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%onnx::Equal_1417, %onnx::Equal_959) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_961 : Long(2, strides=[1], device=cpu) = onnx::Where(%onnx::Where_960, %onnx::Mul_957, %onnx::Equal_1417) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_962 : Long(2, 2, device=cpu) = onnx::Expand(%onnx::Expand_951, %onnx::Expand_961) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_963 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_964 : Long(2, 2, 1, strides=[2, 1, 1], device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_962, %onnx::Unsqueeze_963) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_966 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%onnx::ConstantOfShape_1419) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_967 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Equal_968 : Long(2, strides=[1], device=cpu) = onnx::Mul(%onnx::Mul_966, %onnx::Mul_967) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Where_969 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%onnx::Equal_1417, %onnx::Equal_968) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_970 : Long(2, strides=[1], device=cpu) = onnx::Where(%onnx::Where_969, %onnx::Mul_966, %onnx::Equal_1417) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_971 : Long(2, 2, device=cpu) = onnx::Expand(%onnx::Expand_950, %onnx::Expand_970) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_972 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_973 : Long(2, 2, 1, strides=[2, 1, 1], device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_971, %onnx::Unsqueeze_972) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::ScatterND_974 : Long(2, 2, 2, strides=[4, 2, 1], device=cpu) = onnx::Concat[axis=-1](%onnx::Concat_964, %onnx::Concat_973) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_975 : Long(2, strides=[1], device=cpu) = onnx::Shape(%onnx::Slice_942) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_976 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_977 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_978 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_979 : Long(0, strides=[1], device=cpu) = onnx::Slice(%onnx::Slice_975, %onnx::Slice_977, %onnx::Slice_978, %onnx::Slice_976) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Reshape_980 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Equal_1417, %onnx::Concat_979) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::ScatterND_981 : Float(2, 2, device=cpu) = onnx::Reshape(%onnx::Reshape_949, %onnx::Reshape_980) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Gemm_982 : Float(2, 6, strides=[6, 1], requires_grad=1, device=cpu) = onnx::ScatterND(%onnx::Slice_942, %onnx::ScatterND_974, %onnx::ScatterND_981) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Add_983 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_919, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_984 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_982, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_985 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_983, %onnx::Add_984) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_986 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_987 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_988 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_989 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_990 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_985, %onnx::Split_986) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_991 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_987) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_992 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_988) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_993 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_989) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_994 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_990) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_995 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_992, %onnx::Tanh_917) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_996 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_991, %onnx::Mul_993) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_997 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_995, %onnx::Add_996) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_998 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_997) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_999 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_994, %onnx::Mul_998) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Div_1000 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_999, %forcasting_model.fully_connected_layers.0.weight, %forcasting_model.fully_connected_layers.0.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_1001 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_1002 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Div(%onnx::Div_1000, %onnx::Div_1001) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1003 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Erf(%onnx::Erf_1002) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1004 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1005 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Add(%onnx::Add_1003, %onnx::Add_1004) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1006 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Mul(%onnx::Div_1000, %onnx::Mul_1005) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1007 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.39 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1006, %onnx::Mul_1007) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Div_1009 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.39, %forcasting_model.fully_connected_layers.3.weight, %forcasting_model.fully_connected_layers.3.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_1010 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_1011 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Div(%onnx::Div_1009, %onnx::Div_1010) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1012 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Erf(%onnx::Erf_1011) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1013 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1014 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Add(%onnx::Add_1012, %onnx::Add_1013) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1015 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Mul(%onnx::Div_1009, %onnx::Mul_1014) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1016 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.43 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1015, %onnx::Mul_1016) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Unsqueeze_1018 : Float(2, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.43, %forcasting_model.fully_connected_layers.6.weight, %forcasting_model.fully_connected_layers.6.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Unsqueeze_1019 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:99:0\n  %onnx::Concat_1020 : Float(2, 1, 2, strides=[2, 2, 1], requires_grad=1, device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_1018, %onnx::Unsqueeze_1019) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:99:0\n  %onnx::Gather_1021 : Long(device=cpu) = onnx::Constant[value={35}]()\n  %onnx::Slice_1022 : Float(2, 6, strides=[6, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_1021) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:93:0\n  %onnx::Slice_1023 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1024 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1025 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={6}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1026 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Shape_1027 : Float(2, 2, strides=[6, 1], requires_grad=0, device=cpu) = onnx::Slice(%onnx::Slice_1022, %onnx::Slice_1024, %onnx::Slice_1025, %onnx::Slice_1023, %onnx::Slice_1026) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_1028 : Long(2, strides=[1], device=cpu) = onnx::Shape(%onnx::Shape_1027) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Reshape_1029 : Float(2, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Expand(%onnx::Unsqueeze_1018, %onnx::Expand_1028) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_1030 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 4  5 [ CPULongType{2} ]]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_1031 : Long(2, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Constant[value= 0  1 [ CPULongType{2,1} ]]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_1037 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%onnx::ConstantOfShape_1422) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_1038 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Equal_1039 : Long(2, strides=[1], device=cpu) = onnx::Mul(%onnx::Mul_1037, %onnx::Mul_1038) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Where_1040 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%onnx::Equal_1421, %onnx::Equal_1039) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_1041 : Long(2, strides=[1], device=cpu) = onnx::Where(%onnx::Where_1040, %onnx::Mul_1037, %onnx::Equal_1421) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_1042 : Long(2, 2, device=cpu) = onnx::Expand(%onnx::Expand_1031, %onnx::Expand_1041) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_1043 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_1044 : Long(2, 2, 1, strides=[2, 1, 1], device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_1042, %onnx::Unsqueeze_1043) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_1046 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%onnx::ConstantOfShape_1423) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_1047 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Equal_1048 : Long(2, strides=[1], device=cpu) = onnx::Mul(%onnx::Mul_1046, %onnx::Mul_1047) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Where_1049 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%onnx::Equal_1421, %onnx::Equal_1048) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_1050 : Long(2, strides=[1], device=cpu) = onnx::Where(%onnx::Where_1049, %onnx::Mul_1046, %onnx::Equal_1421) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_1051 : Long(2, 2, device=cpu) = onnx::Expand(%onnx::Expand_1030, %onnx::Expand_1050) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_1052 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_1053 : Long(2, 2, 1, strides=[2, 1, 1], device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_1051, %onnx::Unsqueeze_1052) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::ScatterND_1054 : Long(2, 2, 2, strides=[4, 2, 1], device=cpu) = onnx::Concat[axis=-1](%onnx::Concat_1044, %onnx::Concat_1053) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1055 : Long(2, strides=[1], device=cpu) = onnx::Shape(%onnx::Slice_1022) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1056 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1057 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1058 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_1059 : Long(0, strides=[1], device=cpu) = onnx::Slice(%onnx::Slice_1055, %onnx::Slice_1057, %onnx::Slice_1058, %onnx::Slice_1056) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Reshape_1060 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Equal_1421, %onnx::Concat_1059) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::ScatterND_1061 : Float(2, 2, device=cpu) = onnx::Reshape(%onnx::Reshape_1029, %onnx::Reshape_1060) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Gemm_1062 : Float(2, 6, strides=[6, 1], requires_grad=1, device=cpu) = onnx::ScatterND(%onnx::Slice_1022, %onnx::ScatterND_1054, %onnx::ScatterND_1061) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Add_1063 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_999, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_1064 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_1062, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_1065 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_1063, %onnx::Add_1064) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_1066 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_1067 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_1068 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_1069 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_1070 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_1065, %onnx::Split_1066) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_1071 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_1067) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_1072 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_1068) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_1073 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_1069) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_1074 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_1070) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_1075 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1072, %onnx::Tanh_997) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_1076 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1071, %onnx::Mul_1073) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_1077 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_1075, %onnx::Add_1076) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_1078 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_1077) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_1079 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1074, %onnx::Mul_1078) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Div_1080 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_1079, %forcasting_model.fully_connected_layers.0.weight, %forcasting_model.fully_connected_layers.0.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_1081 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_1082 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Div(%onnx::Div_1080, %onnx::Div_1081) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1083 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Erf(%onnx::Erf_1082) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1084 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1085 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Add(%onnx::Add_1083, %onnx::Add_1084) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1086 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Mul(%onnx::Div_1080, %onnx::Mul_1085) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1087 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.47 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1086, %onnx::Mul_1087) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Div_1089 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.47, %forcasting_model.fully_connected_layers.3.weight, %forcasting_model.fully_connected_layers.3.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_1090 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_1091 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Div(%onnx::Div_1089, %onnx::Div_1090) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1092 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Erf(%onnx::Erf_1091) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1093 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1094 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Add(%onnx::Add_1092, %onnx::Add_1093) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1095 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Mul(%onnx::Div_1089, %onnx::Mul_1094) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1096 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.51 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1095, %onnx::Mul_1096) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Unsqueeze_1098 : Float(2, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.51, %forcasting_model.fully_connected_layers.6.weight, %forcasting_model.fully_connected_layers.6.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Unsqueeze_1099 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:99:0\n  %onnx::Concat_1100 : Float(2, 1, 2, strides=[2, 2, 1], requires_grad=1, device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_1098, %onnx::Unsqueeze_1099) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:99:0\n  %onnx::Gather_1101 : Long(device=cpu) = onnx::Constant[value={36}]()\n  %onnx::Slice_1102 : Float(2, 6, strides=[6, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_1101) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:93:0\n  %onnx::Slice_1103 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1104 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1105 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={6}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1106 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Shape_1107 : Float(2, 2, strides=[6, 1], requires_grad=0, device=cpu) = onnx::Slice(%onnx::Slice_1102, %onnx::Slice_1104, %onnx::Slice_1105, %onnx::Slice_1103, %onnx::Slice_1106) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_1108 : Long(2, strides=[1], device=cpu) = onnx::Shape(%onnx::Shape_1107) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Reshape_1109 : Float(2, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Expand(%onnx::Unsqueeze_1098, %onnx::Expand_1108) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_1110 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 4  5 [ CPULongType{2} ]]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_1111 : Long(2, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Constant[value= 0  1 [ CPULongType{2,1} ]]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_1117 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%onnx::ConstantOfShape_1426) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_1118 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Equal_1119 : Long(2, strides=[1], device=cpu) = onnx::Mul(%onnx::Mul_1117, %onnx::Mul_1118) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Where_1120 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%onnx::Equal_1425, %onnx::Equal_1119) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_1121 : Long(2, strides=[1], device=cpu) = onnx::Where(%onnx::Where_1120, %onnx::Mul_1117, %onnx::Equal_1425) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_1122 : Long(2, 2, device=cpu) = onnx::Expand(%onnx::Expand_1111, %onnx::Expand_1121) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_1123 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_1124 : Long(2, 2, 1, strides=[2, 1, 1], device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_1122, %onnx::Unsqueeze_1123) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_1126 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%onnx::ConstantOfShape_1427) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_1127 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Equal_1128 : Long(2, strides=[1], device=cpu) = onnx::Mul(%onnx::Mul_1126, %onnx::Mul_1127) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Where_1129 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%onnx::Equal_1425, %onnx::Equal_1128) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_1130 : Long(2, strides=[1], device=cpu) = onnx::Where(%onnx::Where_1129, %onnx::Mul_1126, %onnx::Equal_1425) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_1131 : Long(2, 2, device=cpu) = onnx::Expand(%onnx::Expand_1110, %onnx::Expand_1130) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_1132 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_1133 : Long(2, 2, 1, strides=[2, 1, 1], device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_1131, %onnx::Unsqueeze_1132) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::ScatterND_1134 : Long(2, 2, 2, strides=[4, 2, 1], device=cpu) = onnx::Concat[axis=-1](%onnx::Concat_1124, %onnx::Concat_1133) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1135 : Long(2, strides=[1], device=cpu) = onnx::Shape(%onnx::Slice_1102) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1136 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1137 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1138 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_1139 : Long(0, strides=[1], device=cpu) = onnx::Slice(%onnx::Slice_1135, %onnx::Slice_1137, %onnx::Slice_1138, %onnx::Slice_1136) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Reshape_1140 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Equal_1425, %onnx::Concat_1139) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::ScatterND_1141 : Float(2, 2, device=cpu) = onnx::Reshape(%onnx::Reshape_1109, %onnx::Reshape_1140) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Gemm_1142 : Float(2, 6, strides=[6, 1], requires_grad=1, device=cpu) = onnx::ScatterND(%onnx::Slice_1102, %onnx::ScatterND_1134, %onnx::ScatterND_1141) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Add_1143 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_1079, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_1144 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_1142, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_1145 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_1143, %onnx::Add_1144) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_1146 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_1147 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_1148 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_1149 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_1150 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_1145, %onnx::Split_1146) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_1151 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_1147) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_1152 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_1148) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_1153 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_1149) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_1154 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_1150) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_1155 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1152, %onnx::Tanh_1077) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_1156 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1151, %onnx::Mul_1153) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_1157 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_1155, %onnx::Add_1156) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_1158 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_1157) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_1159 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1154, %onnx::Mul_1158) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Div_1160 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_1159, %forcasting_model.fully_connected_layers.0.weight, %forcasting_model.fully_connected_layers.0.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_1161 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_1162 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Div(%onnx::Div_1160, %onnx::Div_1161) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1163 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Erf(%onnx::Erf_1162) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1164 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1165 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Add(%onnx::Add_1163, %onnx::Add_1164) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1166 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Mul(%onnx::Div_1160, %onnx::Mul_1165) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1167 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.55 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1166, %onnx::Mul_1167) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Div_1169 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.55, %forcasting_model.fully_connected_layers.3.weight, %forcasting_model.fully_connected_layers.3.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_1170 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_1171 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Div(%onnx::Div_1169, %onnx::Div_1170) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1172 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Erf(%onnx::Erf_1171) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1173 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1174 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Add(%onnx::Add_1172, %onnx::Add_1173) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1175 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Mul(%onnx::Div_1169, %onnx::Mul_1174) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1176 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.59 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1175, %onnx::Mul_1176) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Unsqueeze_1178 : Float(2, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.59, %forcasting_model.fully_connected_layers.6.weight, %forcasting_model.fully_connected_layers.6.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Unsqueeze_1179 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:99:0\n  %onnx::Concat_1180 : Float(2, 1, 2, strides=[2, 2, 1], requires_grad=1, device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_1178, %onnx::Unsqueeze_1179) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:99:0\n  %onnx::Gather_1181 : Long(device=cpu) = onnx::Constant[value={37}]()\n  %onnx::Slice_1182 : Float(2, 6, strides=[6, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_1181) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:93:0\n  %onnx::Slice_1183 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1184 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1185 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={6}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1186 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Shape_1187 : Float(2, 2, strides=[6, 1], requires_grad=0, device=cpu) = onnx::Slice(%onnx::Slice_1182, %onnx::Slice_1184, %onnx::Slice_1185, %onnx::Slice_1183, %onnx::Slice_1186) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_1188 : Long(2, strides=[1], device=cpu) = onnx::Shape(%onnx::Shape_1187) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Reshape_1189 : Float(2, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Expand(%onnx::Unsqueeze_1178, %onnx::Expand_1188) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_1190 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 4  5 [ CPULongType{2} ]]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_1191 : Long(2, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Constant[value= 0  1 [ CPULongType{2,1} ]]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_1197 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%onnx::ConstantOfShape_1430) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_1198 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Equal_1199 : Long(2, strides=[1], device=cpu) = onnx::Mul(%onnx::Mul_1197, %onnx::Mul_1198) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Where_1200 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%onnx::Equal_1429, %onnx::Equal_1199) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_1201 : Long(2, strides=[1], device=cpu) = onnx::Where(%onnx::Where_1200, %onnx::Mul_1197, %onnx::Equal_1429) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_1202 : Long(2, 2, device=cpu) = onnx::Expand(%onnx::Expand_1191, %onnx::Expand_1201) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_1203 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_1204 : Long(2, 2, 1, strides=[2, 1, 1], device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_1202, %onnx::Unsqueeze_1203) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_1206 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%onnx::ConstantOfShape_1431) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_1207 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Equal_1208 : Long(2, strides=[1], device=cpu) = onnx::Mul(%onnx::Mul_1206, %onnx::Mul_1207) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Where_1209 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%onnx::Equal_1429, %onnx::Equal_1208) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_1210 : Long(2, strides=[1], device=cpu) = onnx::Where(%onnx::Where_1209, %onnx::Mul_1206, %onnx::Equal_1429) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_1211 : Long(2, 2, device=cpu) = onnx::Expand(%onnx::Expand_1190, %onnx::Expand_1210) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_1212 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_1213 : Long(2, 2, 1, strides=[2, 1, 1], device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_1211, %onnx::Unsqueeze_1212) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::ScatterND_1214 : Long(2, 2, 2, strides=[4, 2, 1], device=cpu) = onnx::Concat[axis=-1](%onnx::Concat_1204, %onnx::Concat_1213) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1215 : Long(2, strides=[1], device=cpu) = onnx::Shape(%onnx::Slice_1182) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1216 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1217 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1218 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_1219 : Long(0, strides=[1], device=cpu) = onnx::Slice(%onnx::Slice_1215, %onnx::Slice_1217, %onnx::Slice_1218, %onnx::Slice_1216) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Reshape_1220 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Equal_1429, %onnx::Concat_1219) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::ScatterND_1221 : Float(2, 2, device=cpu) = onnx::Reshape(%onnx::Reshape_1189, %onnx::Reshape_1220) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Gemm_1222 : Float(2, 6, strides=[6, 1], requires_grad=1, device=cpu) = onnx::ScatterND(%onnx::Slice_1182, %onnx::ScatterND_1214, %onnx::ScatterND_1221) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Add_1223 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_1159, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_1224 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_1222, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_1225 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_1223, %onnx::Add_1224) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_1226 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_1227 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_1228 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_1229 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_1230 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_1225, %onnx::Split_1226) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_1231 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_1227) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_1232 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_1228) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_1233 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_1229) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_1234 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_1230) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_1235 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1232, %onnx::Tanh_1157) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_1236 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1231, %onnx::Mul_1233) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_1237 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_1235, %onnx::Add_1236) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_1238 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_1237) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_1239 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1234, %onnx::Mul_1238) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Div_1240 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_1239, %forcasting_model.fully_connected_layers.0.weight, %forcasting_model.fully_connected_layers.0.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_1241 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_1242 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Div(%onnx::Div_1240, %onnx::Div_1241) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1243 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Erf(%onnx::Erf_1242) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1244 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1245 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Add(%onnx::Add_1243, %onnx::Add_1244) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1246 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Mul(%onnx::Div_1240, %onnx::Mul_1245) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1247 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.63 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1246, %onnx::Mul_1247) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Div_1249 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.63, %forcasting_model.fully_connected_layers.3.weight, %forcasting_model.fully_connected_layers.3.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_1250 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_1251 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Div(%onnx::Div_1249, %onnx::Div_1250) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1252 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Erf(%onnx::Erf_1251) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1253 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1254 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Add(%onnx::Add_1252, %onnx::Add_1253) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1255 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Mul(%onnx::Div_1249, %onnx::Mul_1254) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1256 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.67 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1255, %onnx::Mul_1256) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Unsqueeze_1258 : Float(2, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.67, %forcasting_model.fully_connected_layers.6.weight, %forcasting_model.fully_connected_layers.6.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Unsqueeze_1259 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:99:0\n  %onnx::Concat_1260 : Float(2, 1, 2, strides=[2, 2, 1], requires_grad=1, device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_1258, %onnx::Unsqueeze_1259) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:99:0\n  %onnx::Gather_1261 : Long(device=cpu) = onnx::Constant[value={38}]()\n  %onnx::Slice_1262 : Float(2, 6, strides=[6, 1], requires_grad=0, device=cpu) = onnx::Gather[axis=1](%onnx::Gather_0, %onnx::Gather_1261) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:93:0\n  %onnx::Slice_1263 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1264 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={4}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1265 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={6}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1266 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Shape_1267 : Float(2, 2, strides=[6, 1], requires_grad=0, device=cpu) = onnx::Slice(%onnx::Slice_1262, %onnx::Slice_1264, %onnx::Slice_1265, %onnx::Slice_1263, %onnx::Slice_1266) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_1268 : Long(2, strides=[1], device=cpu) = onnx::Shape(%onnx::Shape_1267) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Reshape_1269 : Float(2, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Expand(%onnx::Unsqueeze_1258, %onnx::Expand_1268) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_1270 : Long(2, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value= 4  5 [ CPULongType{2} ]]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_1271 : Long(2, 1, strides=[1, 1], requires_grad=0, device=cpu) = onnx::Constant[value= 0  1 [ CPULongType{2,1} ]]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_1277 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%onnx::ConstantOfShape_1434) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_1278 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Equal_1279 : Long(2, strides=[1], device=cpu) = onnx::Mul(%onnx::Mul_1277, %onnx::Mul_1278) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Where_1280 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%onnx::Equal_1433, %onnx::Equal_1279) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_1281 : Long(2, strides=[1], device=cpu) = onnx::Where(%onnx::Where_1280, %onnx::Mul_1277, %onnx::Equal_1433) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_1282 : Long(2, 2, device=cpu) = onnx::Expand(%onnx::Expand_1271, %onnx::Expand_1281) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_1283 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_1284 : Long(2, 2, 1, strides=[2, 1, 1], device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_1282, %onnx::Unsqueeze_1283) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_1286 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%onnx::ConstantOfShape_1435) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Mul_1287 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Equal_1288 : Long(2, strides=[1], device=cpu) = onnx::Mul(%onnx::Mul_1286, %onnx::Mul_1287) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Where_1289 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%onnx::Equal_1433, %onnx::Equal_1288) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Expand_1290 : Long(2, strides=[1], device=cpu) = onnx::Where(%onnx::Where_1289, %onnx::Mul_1286, %onnx::Equal_1433) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_1291 : Long(2, 2, device=cpu) = onnx::Expand(%onnx::Expand_1270, %onnx::Expand_1290) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Unsqueeze_1292 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_1293 : Long(2, 2, 1, strides=[2, 1, 1], device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_1291, %onnx::Unsqueeze_1292) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::ScatterND_1294 : Long(2, 2, 2, strides=[4, 2, 1], device=cpu) = onnx::Concat[axis=-1](%onnx::Concat_1284, %onnx::Concat_1293) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1295 : Long(2, strides=[1], device=cpu) = onnx::Shape(%onnx::Slice_1262) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1296 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1297 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Slice_1298 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Concat_1299 : Long(0, strides=[1], device=cpu) = onnx::Slice(%onnx::Slice_1295, %onnx::Slice_1297, %onnx::Slice_1298, %onnx::Slice_1296) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Reshape_1300 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%onnx::Equal_1433, %onnx::Concat_1299) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::ScatterND_1301 : Float(2, 2, device=cpu) = onnx::Reshape(%onnx::Reshape_1269, %onnx::Reshape_1300) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Gemm_1302 : Float(2, 6, strides=[6, 1], requires_grad=1, device=cpu) = onnx::ScatterND(%onnx::Slice_1262, %onnx::ScatterND_1294, %onnx::ScatterND_1301) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:95:0\n  %onnx::Add_1303 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_1239, %forcasting_model.lstm_layers.0.weight_hh, %forcasting_model.lstm_layers.0.bias_hh) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_1304 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_1302, %forcasting_model.lstm_layers.0.weight_ih, %forcasting_model.lstm_layers.0.bias_ih) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_1305 : Float(2, 80, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_1303, %onnx::Add_1304) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Split_1306 : Long(4, strides=[1], device=cpu) = onnx::Constant[value= 20  20  20  20 [ CPULongType{4} ]]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Sigmoid_1307 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_1308 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Tanh_1309 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu), %onnx::Sigmoid_1310 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Split[axis=1](%onnx::Split_1305, %onnx::Split_1306) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_1311 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_1307) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_1312 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_1308) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_1313 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_1309) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_1314 : Float(2, 20, strides=[80, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%onnx::Sigmoid_1310) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_1315 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1312, %onnx::Tanh_1237) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Add_1316 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1311, %onnx::Mul_1313) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Tanh_1317 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Add(%onnx::Add_1315, %onnx::Add_1316) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Mul_1318 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_1317) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Gemm_1319 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1314, %onnx::Mul_1318) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:1189:0\n  %onnx::Div_1320 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_1319, %forcasting_model.fully_connected_layers.0.weight, %forcasting_model.fully_connected_layers.0.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_1321 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_1322 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Div(%onnx::Div_1320, %onnx::Div_1321) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1323 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Erf(%onnx::Erf_1322) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1324 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1325 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Add(%onnx::Add_1323, %onnx::Add_1324) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1326 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Mul(%onnx::Div_1320, %onnx::Mul_1325) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1327 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.71 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1326, %onnx::Mul_1327) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Div_1329 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.71, %forcasting_model.fully_connected_layers.3.weight, %forcasting_model.fully_connected_layers.3.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_1330 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_1331 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Div(%onnx::Div_1329, %onnx::Div_1330) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1332 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Erf(%onnx::Erf_1331) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1333 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1334 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Add(%onnx::Add_1332, %onnx::Add_1333) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1335 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Mul(%onnx::Div_1329, %onnx::Mul_1334) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1336 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.75 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1335, %onnx::Mul_1336) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Unsqueeze_1338 : Float(2, 2, strides=[2, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.75, %forcasting_model.fully_connected_layers.6.weight, %forcasting_model.fully_connected_layers.6.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Unsqueeze_1339 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:99:0\n  %onnx::Concat_1340 : Float(2, 1, 2, strides=[2, 2, 1], requires_grad=1, device=cpu) = onnx::Unsqueeze(%onnx::Unsqueeze_1338, %onnx::Unsqueeze_1339) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:99:0\n  %1341 : Float(2, 10, 2, strides=[20, 2, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1](%onnx::Concat_620, %onnx::Concat_700, %onnx::Concat_780, %onnx::Concat_860, %onnx::Concat_940, %onnx::Concat_1020, %onnx::Concat_1100, %onnx::Concat_1180, %onnx::Concat_1260, %onnx::Concat_1340) # /home/hamza/PycharmProjects/StateCompression/state_quantization/forcasting_models.py:101:0\n  %onnx::Div_1342 : Float(2, 40, strides=[40, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_599, %autoencoder_quant_model.encoder_layers.0.weight, %autoencoder_quant_model.encoder_layers.0.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_1343 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_1344 : Float(2, 40, strides=[40, 1], device=cpu) = onnx::Div(%onnx::Div_1342, %onnx::Div_1343) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1345 : Float(2, 40, strides=[40, 1], device=cpu) = onnx::Erf(%onnx::Erf_1344) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1346 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1347 : Float(2, 40, strides=[40, 1], device=cpu) = onnx::Add(%onnx::Add_1345, %onnx::Add_1346) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1348 : Float(2, 40, strides=[40, 1], device=cpu) = onnx::Mul(%onnx::Div_1342, %onnx::Mul_1347) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1349 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.79 : Float(2, 40, strides=[40, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1348, %onnx::Mul_1349) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Div_1351 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.79, %autoencoder_quant_model.encoder_layers.3.weight, %autoencoder_quant_model.encoder_layers.3.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_1352 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_1353 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Div(%onnx::Div_1351, %onnx::Div_1352) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1354 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Erf(%onnx::Erf_1353) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1355 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1356 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Add(%onnx::Add_1354, %onnx::Add_1355) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1357 : Float(2, 20, strides=[20, 1], device=cpu) = onnx::Mul(%onnx::Div_1351, %onnx::Mul_1356) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1358 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.83 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1357, %onnx::Mul_1358) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Div_1360 : Float(2, 10, strides=[10, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.83, %autoencoder_quant_model.encoder_layers.6.weight, %autoencoder_quant_model.encoder_layers.6.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_1361 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_1362 : Float(2, 10, strides=[10, 1], device=cpu) = onnx::Div(%onnx::Div_1360, %onnx::Div_1361) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1363 : Float(2, 10, strides=[10, 1], device=cpu) = onnx::Erf(%onnx::Erf_1362) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1364 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1365 : Float(2, 10, strides=[10, 1], device=cpu) = onnx::Add(%onnx::Add_1363, %onnx::Add_1364) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1366 : Float(2, 10, strides=[10, 1], device=cpu) = onnx::Mul(%onnx::Div_1360, %onnx::Mul_1365) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1367 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.87 : Float(2, 10, strides=[10, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1366, %onnx::Mul_1367) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Tanh_1369 : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.87, %autoencoder_quant_model.bottleneck_layers.0.weight, %autoencoder_quant_model.bottleneck_layers.0.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %x : Float(2, 20, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Tanh(%onnx::Tanh_1369) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:354:0\n  %onnx::Gemm_1371 : Float(*, *, strides=[20, 1], requires_grad=1, device=cpu) = ^STEFunction()(%x) # /home/hamza/PycharmProjects/StateCompression/state_quantization/activations.py:21:0\n  %onnx::Div_1372 : Float(*, *, strides=[10, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%onnx::Gemm_1371, %autoencoder_quant_model.decoder_layers.0.weight, %autoencoder_quant_model.decoder_layers.0.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_1373 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_1374 : Float(*, *, device=cpu) = onnx::Div(%onnx::Div_1372, %onnx::Div_1373) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1375 : Float(*, *, device=cpu) = onnx::Erf(%onnx::Erf_1374) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1376 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1377 : Float(*, *, device=cpu) = onnx::Add(%onnx::Add_1375, %onnx::Add_1376) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1378 : Float(*, *, device=cpu) = onnx::Mul(%onnx::Div_1372, %onnx::Mul_1377) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1379 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.91 : Float(*, *, strides=[10, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1378, %onnx::Mul_1379) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Div_1381 : Float(*, *, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.91, %autoencoder_quant_model.decoder_layers.3.weight, %autoencoder_quant_model.decoder_layers.3.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_1382 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_1383 : Float(*, *, device=cpu) = onnx::Div(%onnx::Div_1381, %onnx::Div_1382) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1384 : Float(*, *, device=cpu) = onnx::Erf(%onnx::Erf_1383) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1385 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1386 : Float(*, *, device=cpu) = onnx::Add(%onnx::Add_1384, %onnx::Add_1385) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1387 : Float(*, *, device=cpu) = onnx::Mul(%onnx::Div_1381, %onnx::Mul_1386) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1388 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.95 : Float(*, *, strides=[20, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1387, %onnx::Mul_1388) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Div_1390 : Float(*, *, strides=[40, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.95, %autoencoder_quant_model.decoder_layers.6.weight, %autoencoder_quant_model.decoder_layers.6.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  %onnx::Div_1391 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Erf_1392 : Float(*, *, device=cpu) = onnx::Div(%onnx::Div_1390, %onnx::Div_1391) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1393 : Float(*, *, device=cpu) = onnx::Erf(%onnx::Erf_1392) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Add_1394 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1395 : Float(*, *, device=cpu) = onnx::Add(%onnx::Add_1393, %onnx::Add_1394) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1396 : Float(*, *, device=cpu) = onnx::Mul(%onnx::Div_1390, %onnx::Mul_1395) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %onnx::Mul_1397 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]() # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %input.99 : Float(*, *, strides=[40, 1], requires_grad=1, device=cpu) = onnx::Mul(%onnx::Mul_1396, %onnx::Mul_1397) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/activation.py:681:0\n  %1399 : Float(*, *, strides=[40, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input.99, %autoencoder_quant_model.decoder_layers.9.weight, %autoencoder_quant_model.decoder_layers.9.bias) # /home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114:0\n  return (%1341, %1399)\n"
     ]
    }
   ],
   "source": [
    "model_path = 'state_quantization/model'\n",
    "\n",
    "model_dict_path = 'state_quantization/model_dict.pt'\n",
    "device = 'cpu'\n",
    "model = torch.load(model_path).to(device)\n",
    "print(train_dataset.x[0:2].shape)\n",
    "torch.onnx.export(model, train_dataset.x[0:2].to(device), 'state_quantization/model.onnx')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
