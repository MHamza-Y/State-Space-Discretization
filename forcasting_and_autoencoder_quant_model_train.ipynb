{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from state_quantization.dataset import load_dataset\n",
    "from state_quantization.dataset import DynamicsModelDataset\n",
    "from state_quantization.forcasting_models import LSTMForcasting\n",
    "from state_quantization.quantization_models import DiscAutoEncoder\n",
    "from state_quantization.forcasting_quantization_models import ForcastingQuant, EmbeddedAEForcastingQuant, ForcastingQuantInferenceWrapper, SingleEmbeddedAEForcastingQuant\n",
    "from state_quantization.trainer import ForcastingQuantTrainer\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from state_quantization.train import train_model, test_step\n",
    "from state_quantization.eval import eval_model, compare_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "print(f\"Using Device: {device}\")\n",
    "torch.backends.cudnn.benchmark = True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clipping y\n",
      "torch.Size([672000, 39, 6])\n",
      "torch.Size([672000, 10, 2])\n",
      "torch.Size([288000, 39, 6])\n",
      "torch.Size([288000, 10, 2])\n",
      "{'batch_size': 8000, 'shuffle': True, 'num_workers': 0, 'drop_last': True, 'pin_memory': True}\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[ 1.1986, -0.6009],\n        [ 1.1176, -0.5843],\n        [ 0.9471, -0.5778],\n        [ 0.9027, -0.5656],\n        [ 0.7599, -0.5536],\n        [ 0.6621, -0.5364],\n        [ 0.5412, -0.5377],\n        [ 0.7430, -0.5081],\n        [ 0.4802, -0.5025],\n        [ 0.4481, -0.4743]])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_input_key = 'merged_input'\n",
    "dataset_output_key = 'merged_output'\n",
    "dataset_file_path = 'tmp/ib-out/ib-samples-la.npy'\n",
    "normalized_data_params_save_path = 'tmp/transformer/NormalizeInputConfigs.pkl'\n",
    "dataset_device = 'cpu'\n",
    "y_indexes = [4, 6]\n",
    "\n",
    "train_dataset, val_dataset = load_dataset(file_path=dataset_file_path, input_key=dataset_input_key,\n",
    "                                          output_key=dataset_output_key, dataset_class=DynamicsModelDataset,\n",
    "                                          normalize=True, device=dataset_device, y_clip_range=y_indexes,\n",
    "                                          normalized_input_data_params_save_path=normalized_data_params_save_path)\n",
    "\n",
    "batch_size = 8000\n",
    "params = {'batch_size': batch_size,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 0,\n",
    "          'drop_last': True,\n",
    "          'pin_memory': not train_dataset.x.is_cuda}\n",
    "print(params)\n",
    "train_loader = DataLoader(train_dataset, **params)\n",
    "val_loader = DataLoader(val_dataset, **params)\n",
    "train_dataset.y[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out Size:2\n",
      "LSTM Layers\n",
      "ModuleList(\n",
      "  (0): LSTMCell(6, 20)\n",
      ")\n",
      "LSTM Dropout Layers\n",
      "ModuleList()\n",
      "Fully Connected Layers\n",
      "Sequential(\n",
      "  (0): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (1): GELU(approximate=none)\n",
      "  (2): Dropout(p=0.1, inplace=False)\n",
      "  (3): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (4): GELU(approximate=none)\n",
      "  (5): Dropout(p=0.1, inplace=False)\n",
      "  (6): Linear(in_features=20, out_features=2, bias=True)\n",
      ")\n",
      "Encoder Layers\n",
      "Sequential(\n",
      "  (0): Linear(in_features=40, out_features=40, bias=True)\n",
      "  (1): GELU(approximate=none)\n",
      "  (2): Dropout(p=0, inplace=False)\n",
      "  (3): Linear(in_features=40, out_features=20, bias=True)\n",
      "  (4): GELU(approximate=none)\n",
      "  (5): Dropout(p=0, inplace=False)\n",
      "  (6): Linear(in_features=20, out_features=10, bias=True)\n",
      "  (7): GELU(approximate=none)\n",
      "  (8): Dropout(p=0, inplace=False)\n",
      ")\n",
      "Bottleneck Layers\n",
      "Sequential(\n",
      "  (0): Linear(in_features=10, out_features=20, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): StraightThroughEstimator()\n",
      ")\n",
      "Decoder Layers\n",
      "Sequential(\n",
      "  (0): Linear(in_features=20, out_features=10, bias=True)\n",
      "  (1): GELU(approximate=none)\n",
      "  (2): Dropout(p=0, inplace=False)\n",
      "  (3): Linear(in_features=10, out_features=20, bias=True)\n",
      "  (4): GELU(approximate=none)\n",
      "  (5): Dropout(p=0, inplace=False)\n",
      "  (6): Linear(in_features=20, out_features=40, bias=True)\n",
      "  (7): GELU(approximate=none)\n",
      "  (8): Dropout(p=0, inplace=False)\n",
      "  (9): Linear(in_features=40, out_features=40, bias=True)\n",
      ")\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "num_of_features = train_dataset.get_features_size()\n",
    "seq_len = train_dataset.get_seq_len()\n",
    "hidden_size = 20\n",
    "out_size = train_dataset.get_output_feature_size()\n",
    "print(f'Out Size:{out_size}')\n",
    "look_ahead = train_dataset.get_look_ahead_size()\n",
    "n_layers = 1\n",
    "dropout = 0.1\n",
    "\n",
    "forcasting_model = LSTMForcasting(features=num_of_features, hidden_size=hidden_size, out_size=out_size, seq_len=seq_len,\n",
    "                                  look_ahead=look_ahead, dropout=dropout, n_layers=n_layers)\n",
    "\n",
    "disc_autoencoder_input_size = hidden_size * 2\n",
    "bottleneck_size = 20\n",
    "ae_dropout = 0\n",
    "disc_autoencoder = DiscAutoEncoder(input_size=disc_autoencoder_input_size, bottleneck_size=bottleneck_size,\n",
    "                                   dropout=ae_dropout)\n",
    "model_path = f'tmp/state_quantization/model_aeq-{bottleneck_size}bits4'\n",
    "untrained_model_path = f'tmp/state_quantization/untrained_model_aeq-{bottleneck_size}bits'\n",
    "model = ForcastingQuant(forcasting_model=forcasting_model, autoencoder_quant_model=disc_autoencoder).to(device=device)\n",
    "eval_model = EmbeddedAEForcastingQuant(model=model).to(device=device)\n",
    "torch.save(ForcastingQuantInferenceWrapper(model), untrained_model_path)\n",
    "load_to_gpu = model.is_cuda() and not train_dataset.x.is_cuda\n",
    "print(load_to_gpu)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Trainer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "gamma = 0.1\n",
    "\n",
    "forecasting_learning_rate = 1e-3\n",
    "autoencoder_learning_rate = 1e-3\n",
    "\n",
    "forecasting_lr_milestones = [35]\n",
    "autoencoder_lr_milestones = [100, 150]\n",
    "forecasting_optimizer = torch.optim.Adam(model.forcasting_model.parameters(),\n",
    "                                         lr=forecasting_learning_rate)\n",
    "autoencoder_optimizer = torch.optim.Adam(model.autoencoder_quant_model.parameters(),\n",
    "                                         lr=autoencoder_learning_rate)\n",
    "forecasting_lr_scheduler = MultiStepLR(forecasting_optimizer, milestones=forecasting_lr_milestones, gamma=gamma)\n",
    "autoencoder_lr_scheduler = MultiStepLR(autoencoder_optimizer, milestones=autoencoder_lr_milestones, gamma=gamma)\n",
    "n_epochs = 200\n",
    "\n",
    "trainer = ForcastingQuantTrainer(forcasting_quant_model=model, train_loader=train_loader, test_loader=val_loader,\n",
    "                                 load_to_gpu=load_to_gpu, forecasting_optimizer=forecasting_optimizer,\n",
    "                                 forecasting_lr_scheduler=forecasting_lr_scheduler,\n",
    "                                 autoencoder_lr_scheduler=autoencoder_lr_scheduler,\n",
    "                                 autoencoder_optimizer=autoencoder_optimizer,autoencoder_training_start=50,additional_eval_model=eval_model)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained test\n",
      "--------\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 1.0147619595130284\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 1\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.7849209007053148\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.48292966021431816\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.390s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 2\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "Forcasting Train loss: 0.27827018153454575\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.10112147716184457\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.421s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 3\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.10516906609492642\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.06328931233535211\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.162s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 4\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.08707155030043352\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.054515741455058254\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.413s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 5\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.07828292153066113\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.04875864874985483\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.317s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 6\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.07176292572347891\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.04407693383594354\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.394s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 7\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.06706035722579275\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.0408330015424225\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.344s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 8\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.06382179686001369\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.038514249958097935\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.595s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 9\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.061509321754177414\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.036979521003862224\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.693s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 10\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.059725588586713584\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03609860626359781\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.366s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 11\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05848632961334217\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03584773848868079\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.436s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 12\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05754611033591486\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.034754139474696584\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.555s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 13\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.056675096752033347\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.034829933299786515\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.526s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 14\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05587124310079075\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03369506241546737\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.165s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 15\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05524616630836612\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.033112370409071445\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.041s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 16\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05457816853941906\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03299217795332273\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.960s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 17\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05400097782590559\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.032567487150016755\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.129s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 18\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.053473063301117646\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03201971104782489\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.218s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 19\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05303432051801965\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.031709864269942045\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.147s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 20\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.052529318524258475\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03145182536294063\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.153s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 21\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.0520609404359545\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03139243833720684\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.151s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 22\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05167943523043678\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.0312397965333528\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.121s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 23\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05125379886123396\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.030875663686957624\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.081s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 24\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05098429925384976\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03111504339095619\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.198s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 25\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05070291574866999\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.030042489524930716\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.099s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 26\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05039777167673622\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.029881366890751652\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.980s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 27\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05004198170666184\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02973839237044255\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.158s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 28\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.049814721037234576\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.029895845904118486\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.218s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 29\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04947784223726818\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02972791985505157\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.946s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 30\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04930231800036771\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.029634212298939627\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.171s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 31\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.049025673020098894\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.029214789263076253\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.996s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 32\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04874738567464408\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02939082133687205\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.229s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 33\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04845333831118686\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02917045892940627\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.217s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 34\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.048285797593139466\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.029031359642330144\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.230s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 35\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.048189712688326836\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028774045045591064\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.139s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 36\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04780376196971962\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028736152944879398\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.048s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 37\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.047832177774537174\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02865794626995921\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.165s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 38\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04778942776223024\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028647010990728933\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.057s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 39\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04784284363545123\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02877618268960052\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.161s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 40\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04772395059643757\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028734295008083183\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.139s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 41\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04766053861627976\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028595873154699802\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.097s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 42\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.047672326100014505\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028666120281236038\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.024s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 43\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04764105219926153\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02856652071285579\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.177s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 44\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04763602771397148\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028713290579617023\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.101s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 45\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.047543251576522984\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02859353232714865\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.153s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 46\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.0475742496283991\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028587160269833274\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.098s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 47\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04754475282416457\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028650996326986287\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.193s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 48\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.047527761021185486\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028578197687036462\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.211s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 49\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04749092362111523\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02852074010297656\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.137s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 50\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.047460714754249365\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028520821490221553\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.103s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 51\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.2605228596145198\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.15718202375703388\n",
      "Eval Model Test loss: 0.6686565279960632\n",
      "First Out Loss: 0.567846354511049\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.412s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 52\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.11600192254852681\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.06589780002832413\n",
      "Eval Model Test loss: 0.6443165457910962\n",
      "First Out Loss: 0.5360797279410892\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.282s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 53\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.04549113479221151\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.03498877688414521\n",
      "Eval Model Test loss: 0.5059721486435996\n",
      "First Out Loss: 0.4590072375204828\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.404s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 54\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.031888232389021484\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.02993314356232683\n",
      "Eval Model Test loss: 0.48306600087218815\n",
      "First Out Loss: 0.4303803998563025\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.389s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 55\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.02841933843280588\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.026815721816900704\n",
      "Eval Model Test loss: 0.6422464963462617\n",
      "First Out Loss: 0.5688962257570691\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.302s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 56\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.02343351398372934\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.02011032195554839\n",
      "Eval Model Test loss: 0.37624333550532657\n",
      "First Out Loss: 0.3297937744193607\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.370s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 57\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.01859453526724662\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.017110246181901958\n",
      "Eval Model Test loss: 0.32897739195161396\n",
      "First Out Loss: 0.2938094006644355\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.393s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 58\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.016257026698440313\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.015427153350578414\n",
      "Eval Model Test loss: 0.45945750094122356\n",
      "First Out Loss: 0.39114227145910263\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.432s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 59\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.014122685783409647\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.01307545710975925\n",
      "Eval Model Test loss: 0.4674731567502022\n",
      "First Out Loss: 0.4078636086649365\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.310s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 60\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.012558663097609366\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.012033121712091897\n",
      "Eval Model Test loss: 0.5214922212892108\n",
      "First Out Loss: 0.4416947488983472\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.405s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 61\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.01170152096476938\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.011303257119531432\n",
      "Eval Model Test loss: 0.5297496914863586\n",
      "First Out Loss: 0.41347818490531707\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.560s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 62\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.011015937109256075\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.010693363457297286\n",
      "Eval Model Test loss: 0.5134967565536499\n",
      "First Out Loss: 0.4520837946070565\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.447s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 63\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.010531806154176593\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.010330014448199008\n",
      "Eval Model Test loss: 0.38690200613604653\n",
      "First Out Loss: 0.3388861111468739\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.388s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 64\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.010127822779828594\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009832849726080894\n",
      "Eval Model Test loss: 0.346125522421466\n",
      "First Out Loss: 0.29925426344076794\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.441s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 65\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009605252760506812\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009351901632423202\n",
      "Eval Model Test loss: 0.3155899652176433\n",
      "First Out Loss: 0.2789110433724191\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.482s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 66\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009125361307745888\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008895595532117618\n",
      "Eval Model Test loss: 0.2825017761853006\n",
      "First Out Loss: 0.2529125201205413\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.448s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 67\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008715448391047261\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008509867979834477\n",
      "Eval Model Test loss: 0.29342810147338444\n",
      "First Out Loss: 0.2611373948554198\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.382s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 68\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008366573967837862\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008190413264350759\n",
      "Eval Model Test loss: 0.291702716714806\n",
      "First Out Loss: 0.2615228063530392\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.439s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 69\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008089798923936627\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.007974175037816167\n",
      "Eval Model Test loss: 0.2888946740163697\n",
      "First Out Loss: 0.258771894292699\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.438s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 70\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.007898581463710539\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0077993496217661435\n",
      "Eval Model Test loss: 0.2782969863878356\n",
      "First Out Loss: 0.2533918217652374\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.493s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 71\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0077655582877230785\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.007706318658569621\n",
      "Eval Model Test loss: 0.26003577932715416\n",
      "First Out Loss: 0.23388225005732644\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.467s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 72\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0076842662057883685\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0076327374877615106\n",
      "Eval Model Test loss: 0.2583589880830712\n",
      "First Out Loss: 0.22839075409703785\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.514s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 73\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.007626403599888796\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.007569355256338086\n",
      "Eval Model Test loss: 0.26168235060241485\n",
      "First Out Loss: 0.2305876219438182\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.453s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 74\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.007526908740623011\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.007463977452264064\n",
      "Eval Model Test loss: 0.257106254912085\n",
      "First Out Loss: 0.2364753559231758\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.544s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 75\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.007405875267327896\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.007336788409803476\n",
      "Eval Model Test loss: 0.2656707904405064\n",
      "First Out Loss: 0.24398480024602678\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.473s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 76\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.007284170166323227\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.007234650689901577\n",
      "Eval Model Test loss: 0.26435703080561423\n",
      "First Out Loss: 0.2431342957748307\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.531s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 77\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.007193467064228441\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.007161835040379729\n",
      "Eval Model Test loss: 0.27024561497900224\n",
      "First Out Loss: 0.24859646749165323\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.433s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 78\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.007119417933392383\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0071287247766223215\n",
      "Eval Model Test loss: 0.2691185192929374\n",
      "First Out Loss: 0.2490361366007063\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.435s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 79\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.007067349412301112\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0070203997375857495\n",
      "Eval Model Test loss: 0.26735709317856365\n",
      "First Out Loss: 0.2436445090505812\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.411s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 80\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.007019744055079562\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.007003224829936193\n",
      "Eval Model Test loss: 0.2578146192762587\n",
      "First Out Loss: 0.23362351747022736\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.540s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 81\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006965531374416536\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006948975561600592\n",
      "Eval Model Test loss: 0.25778751861717963\n",
      "First Out Loss: 0.23548639689882597\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.556s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 82\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006930277100764215\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006911147321160469\n",
      "Eval Model Test loss: 0.26724548679259086\n",
      "First Out Loss: 0.2456333769692315\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.579s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 83\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006888560146935994\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006895373989310529\n",
      "Eval Model Test loss: 0.26886288324991864\n",
      "First Out Loss: 0.24732207217150265\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.322s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 84\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006852989971992515\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0068094664925916325\n",
      "Eval Model Test loss: 0.2745755116144816\n",
      "First Out Loss: 0.2518058957325088\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.465s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 85\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006809117250321876\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006797748048686319\n",
      "Eval Model Test loss: 0.28411098072926205\n",
      "First Out Loss: 0.2634541392326355\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.460s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 86\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006774496592004739\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006736985019718607\n",
      "Eval Model Test loss: 0.2896343444784482\n",
      "First Out Loss: 0.2683021728363302\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.456s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 87\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006747151542055819\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006710771225496299\n",
      "Eval Model Test loss: 0.2945648166868422\n",
      "First Out Loss: 0.2752464637160301\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.391s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 88\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00670812670363202\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006693904378658367\n",
      "Eval Model Test loss: 0.29957738435930675\n",
      "First Out Loss: 0.28200966368118924\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.468s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 89\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006660107656248978\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006633936362858448\n",
      "Eval Model Test loss: 0.2896159423722161\n",
      "First Out Loss: 0.2637993312544293\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.440s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 90\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00661052103775243\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006567831565108564\n",
      "Eval Model Test loss: 0.29771211908923256\n",
      "First Out Loss: 0.2686826007233726\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.447s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 91\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00652841336670376\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0064967495466892915\n",
      "Eval Model Test loss: 0.31152145398987663\n",
      "First Out Loss: 0.2838360054625405\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.416s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 92\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006454531447074953\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006420491987632381\n",
      "Eval Model Test loss: 0.29979251987404293\n",
      "First Out Loss: 0.2692287936806679\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.533s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 93\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006388159568554589\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006358743451225261\n",
      "Eval Model Test loss: 0.3068480259842343\n",
      "First Out Loss: 0.2813449800014496\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.471s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 94\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006337718566923979\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006308991345576942\n",
      "Eval Model Test loss: 0.32597796453369987\n",
      "First Out Loss: 0.30605368150605095\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.494s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 95\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0063010296351941565\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00629087916523632\n",
      "Eval Model Test loss: 0.32522694932089913\n",
      "First Out Loss: 0.30661048077874714\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.371s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 96\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006285005853333999\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00627432557909439\n",
      "Eval Model Test loss: 0.3271105471584532\n",
      "First Out Loss: 0.30547971692350173\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.461s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 97\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006252966483034903\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006239213450397883\n",
      "Eval Model Test loss: 0.32266655067602795\n",
      "First Out Loss: 0.3006404290596644\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.454s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 98\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006231550526406083\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006225477244394521\n",
      "Eval Model Test loss: 0.33163027299775016\n",
      "First Out Loss: 0.31078259232971406\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.416s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 99\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0062095297034829855\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006195127317267988\n",
      "Eval Model Test loss: 0.3303537741303444\n",
      "First Out Loss: 0.31052106204960084\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.280s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 100\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006187903883290433\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0061549060693424605\n",
      "Eval Model Test loss: 0.31868939929538304\n",
      "First Out Loss: 0.2971866503357887\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.403s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 101\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006146551775080817\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006141331913467083\n",
      "Eval Model Test loss: 0.3197844492064582\n",
      "First Out Loss: 0.29854974067873424\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.367s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 102\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0061432367323764735\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006137149809445772\n",
      "Eval Model Test loss: 0.3216646843486362\n",
      "First Out Loss: 0.3001101662715276\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.356s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 103\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006139251553187413\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006136509357020259\n",
      "Eval Model Test loss: 0.31894863065746093\n",
      "First Out Loss: 0.29739684280421996\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.320s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 104\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006136493557798011\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006136612475125326\n",
      "Eval Model Test loss: 0.3195931820405854\n",
      "First Out Loss: 0.2982117260495822\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.457s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 105\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006135625470917495\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0061288482716514\n",
      "Eval Model Test loss: 0.321104995906353\n",
      "First Out Loss: 0.29944615066051483\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.477s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 106\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006130701452050181\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00612738601759904\n",
      "Eval Model Test loss: 0.31929757611619103\n",
      "First Out Loss: 0.2973929386999872\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.449s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 107\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006128541155097385\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006118810502812266\n",
      "Eval Model Test loss: 0.320126184158855\n",
      "First Out Loss: 0.29833488994174534\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.316s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 108\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0061243598604397405\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006117721101165646\n",
      "Eval Model Test loss: 0.31901680181423825\n",
      "First Out Loss: 0.2971537262201309\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.431s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 109\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0061204876152000254\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006110661055168344\n",
      "Eval Model Test loss: 0.3208976768785053\n",
      "First Out Loss: 0.29938847406042945\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.383s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 110\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006114436479817543\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006114196342726548\n",
      "Eval Model Test loss: 0.31924206349584794\n",
      "First Out Loss: 0.29702401492330766\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.417s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 111\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0061126234553133445\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006104911263618205\n",
      "Eval Model Test loss: 0.31801767233345246\n",
      "First Out Loss: 0.29623546699682873\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.266s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 112\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0061099215333039565\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006100812111981213\n",
      "Eval Model Test loss: 0.32000557747152114\n",
      "First Out Loss: 0.29801029629177517\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.360s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 113\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00610447465442121\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006100439466536045\n",
      "Eval Model Test loss: 0.3187328775723775\n",
      "First Out Loss: 0.29624660478697884\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.358s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 114\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006104229988219838\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006097431527450681\n",
      "Eval Model Test loss: 0.3171168921722306\n",
      "First Out Loss: 0.29531243195136386\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.384s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 115\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006098063036222898\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006091750408005383\n",
      "Eval Model Test loss: 0.3140418628851573\n",
      "First Out Loss: 0.29183900107940036\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.285s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 116\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006093138424191801\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006082687087150084\n",
      "Eval Model Test loss: 0.3157399396101634\n",
      "First Out Loss: 0.2934226103954845\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.371s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 117\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006087768662144386\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006079374217531747\n",
      "Eval Model Test loss: 0.3179810361729728\n",
      "First Out Loss: 0.2960374802350998\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.381s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 118\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0060841319251007265\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006078581674955785\n",
      "Eval Model Test loss: 0.3188680700129933\n",
      "First Out Loss: 0.29653346207406783\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.368s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 119\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00608023176235812\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006073841165440778\n",
      "Eval Model Test loss: 0.31588316791587406\n",
      "First Out Loss: 0.2931029631031884\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.240s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 120\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006075684352600504\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006069359705886907\n",
      "Eval Model Test loss: 0.3185131425658862\n",
      "First Out Loss: 0.29530738294124603\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.374s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 121\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006068311958751153\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006062492016806371\n",
      "Eval Model Test loss: 0.31898656901386047\n",
      "First Out Loss: 0.29620952407519024\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.411s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 122\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006063037385631885\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006060889236525529\n",
      "Eval Model Test loss: 0.31923888872067135\n",
      "First Out Loss: 0.29595917297734153\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.398s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 123\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006058925385808661\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0060568551739884745\n",
      "Eval Model Test loss: 0.3193901942835914\n",
      "First Out Loss: 0.29697224911716247\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.287s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 124\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006053792085454222\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006049169615531961\n",
      "Eval Model Test loss: 0.3195919079913033\n",
      "First Out Loss: 0.29606229563554126\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.348s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 125\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006046488942090599\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006041034551647802\n",
      "Eval Model Test loss: 0.3195582603414853\n",
      "First Out Loss: 0.29635968142085606\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.297s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 126\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006042495652634118\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006034321423309545\n",
      "Eval Model Test loss: 0.3200233793920941\n",
      "First Out Loss: 0.2966777980327606\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.331s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 127\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006036685757516395\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006035531871020794\n",
      "Eval Model Test loss: 0.31864839212761986\n",
      "First Out Loss: 0.2952781700425678\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.215s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 128\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006030074259754093\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00602277025528666\n",
      "Eval Model Test loss: 0.3197627001338535\n",
      "First Out Loss: 0.2965335307849778\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.308s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 129\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00602636338278119\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006014919244787759\n",
      "Eval Model Test loss: 0.3229088650809394\n",
      "First Out Loss: 0.30009681979815167\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.341s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 130\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00601834524422884\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006015292834490538\n",
      "Eval Model Test loss: 0.3213038709428575\n",
      "First Out Loss: 0.2983006313443184\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.304s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 131\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.006012313478138475\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006013582796893186\n",
      "Eval Model Test loss: 0.3238084548049503\n",
      "First Out Loss: 0.30081669903463787\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.191s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 132\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00600716104686615\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00600573170878407\n",
      "Eval Model Test loss: 0.31980174283186596\n",
      "First Out Loss: 0.2965516390071975\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.300s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 133\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005999809901584827\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005998143719302284\n",
      "Eval Model Test loss: 0.32314320736461216\n",
      "First Out Loss: 0.30020905037720996\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.385s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 134\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005993491642931033\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0059977851730460925\n",
      "Eval Model Test loss: 0.3235606741574075\n",
      "First Out Loss: 0.30085256530178917\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.355s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 135\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005990985736605667\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0059942246362980865\n",
      "Eval Model Test loss: 0.3210362237360742\n",
      "First Out Loss: 0.2976825477348434\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.235s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 136\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005982703119072886\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.006002307830688854\n",
      "Eval Model Test loss: 0.32404517382383347\n",
      "First Out Loss: 0.3012302898698383\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.373s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 137\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005977445897380156\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005986381102249854\n",
      "Eval Model Test loss: 0.32046455724371803\n",
      "First Out Loss: 0.29757408135467106\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.356s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 138\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0059703230203705885\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0059720479314112\n",
      "Eval Model Test loss: 0.32203156169917846\n",
      "First Out Loss: 0.29974181536171174\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.390s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 139\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005964642229844772\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005970172920367784\n",
      "Eval Model Test loss: 0.3242081080873807\n",
      "First Out Loss: 0.3021416241923968\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.199s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 140\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005960170684071879\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005959472218010988\n",
      "Eval Model Test loss: 0.31929809517330593\n",
      "First Out Loss: 0.29645414236519074\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.320s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 141\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005952054551536483\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005957138194288645\n",
      "Eval Model Test loss: 0.3228756884733836\n",
      "First Out Loss: 0.3004632674985462\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.332s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 142\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005946915086713575\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005945895190557672\n",
      "Eval Model Test loss: 0.3224916590584649\n",
      "First Out Loss: 0.3004615878065427\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.314s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 143\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005940304769735251\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005943570674086611\n",
      "Eval Model Test loss: 0.3257781383064058\n",
      "First Out Loss: 0.30344782107406193\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.188s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 144\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005933923402889853\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0059321734588593245\n",
      "Eval Model Test loss: 0.3197306493918101\n",
      "First Out Loss: 0.2974501864777671\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.350s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 145\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0059293691911512895\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005924837922470437\n",
      "Eval Model Test loss: 0.32038891398244435\n",
      "First Out Loss: 0.29771556291315293\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.304s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 146\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00592025192565329\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0059214460715237595\n",
      "Eval Model Test loss: 0.3200215771794319\n",
      "First Out Loss: 0.2973539274599817\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.298s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 147\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005917208673920305\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005914340791706409\n",
      "Eval Model Test loss: 0.3245551933844884\n",
      "First Out Loss: 0.3025371887617641\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.219s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 148\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00590819937531792\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0059068047751983\n",
      "Eval Model Test loss: 0.32158828030029935\n",
      "First Out Loss: 0.2995370684398545\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.450s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 149\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005903046738932885\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00591095120439099\n",
      "Eval Model Test loss: 0.32710860090123284\n",
      "First Out Loss: 0.304518128434817\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.361s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 150\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005900194768660835\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005899707282272478\n",
      "Eval Model Test loss: 0.32904234197404647\n",
      "First Out Loss: 0.3067472767498758\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.344s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 151\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005889819530282347\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0058950778329744935\n",
      "Eval Model Test loss: 0.3263473047150506\n",
      "First Out Loss: 0.30414915333191556\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.244s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 152\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005888173822313547\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005895296512689028\n",
      "Eval Model Test loss: 0.32601383494006264\n",
      "First Out Loss: 0.30377008186446297\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.344s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 153\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00588818529199454\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005895003133142988\n",
      "Eval Model Test loss: 0.32623568260007435\n",
      "First Out Loss: 0.3039191315571467\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.362s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 154\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00588806018987227\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005895969949455725\n",
      "Eval Model Test loss: 0.3266562107536528\n",
      "First Out Loss: 0.30465660492579144\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.323s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 155\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005888180241787008\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005893391298337115\n",
      "Eval Model Test loss: 0.3251681352655093\n",
      "First Out Loss: 0.3031911899646123\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.203s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 156\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005887077805320067\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005893983425469034\n",
      "Eval Model Test loss: 0.32636228452126187\n",
      "First Out Loss: 0.30416775825950837\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.337s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 157\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0058870740523118345\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005891412069710593\n",
      "Eval Model Test loss: 0.3267318598098225\n",
      "First Out Loss: 0.30472046467992997\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.317s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 158\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005885762095983539\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005892720810758571\n",
      "Eval Model Test loss: 0.32610774288574856\n",
      "First Out Loss: 0.30390070213211906\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.317s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 159\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005885589064010197\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005892457828546564\n",
      "Eval Model Test loss: 0.3274387965599696\n",
      "First Out Loss: 0.30530640565686756\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.236s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 160\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005884443365392231\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005891906692542964\n",
      "Eval Model Test loss: 0.32625556737184525\n",
      "First Out Loss: 0.3040143797794978\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.334s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 161\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005884811742275599\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00589030413215773\n",
      "Eval Model Test loss: 0.32530921945969266\n",
      "First Out Loss: 0.3032539288202922\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.370s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 162\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0058842312455886885\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0058884336871819366\n",
      "Eval Model Test loss: 0.3261887513928943\n",
      "First Out Loss: 0.3040303099486563\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.362s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 163\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005883043709521492\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005886871626393663\n",
      "Eval Model Test loss: 0.32646941559182274\n",
      "First Out Loss: 0.3046982056564755\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.238s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 164\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005882936851343229\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005887039380872415\n",
      "Eval Model Test loss: 0.3253061912126011\n",
      "First Out Loss: 0.30341363201538724\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.409s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 165\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005880648874500323\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0058858769609489376\n",
      "Eval Model Test loss: 0.3247709514366256\n",
      "First Out Loss: 0.30291297286748886\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.399s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 166\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005881961235510451\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005885517302279671\n",
      "Eval Model Test loss: 0.32564934839804965\n",
      "First Out Loss: 0.303865066005124\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.352s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 167\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005881324815120371\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005884636555694872\n",
      "Eval Model Test loss: 0.3256206255820062\n",
      "First Out Loss: 0.30363500118255615\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.245s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 168\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005880241820012175\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005883781963752376\n",
      "Eval Model Test loss: 0.3252820885843701\n",
      "First Out Loss: 0.30356835905048585\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.367s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 169\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005879745192249261\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005885127453236944\n",
      "Eval Model Test loss: 0.32502277195453644\n",
      "First Out Loss: 0.3033718789617221\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.328s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 170\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005878785835756432\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0058846503573780256\n",
      "Eval Model Test loss: 0.3256562153498332\n",
      "First Out Loss: 0.30399130781491596\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.358s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 171\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005878161871805787\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005882292390904493\n",
      "Eval Model Test loss: 0.3255487291349305\n",
      "First Out Loss: 0.30403336385885876\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.207s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 172\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005877062184957876\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00588161912229326\n",
      "Eval Model Test loss: 0.32578089005417293\n",
      "First Out Loss: 0.3040388648708661\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.330s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 173\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005876178975172695\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005883380214476751\n",
      "Eval Model Test loss: 0.32392943733268315\n",
      "First Out Loss: 0.30215581754843396\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.344s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 174\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005876056389838812\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005881820068073769\n",
      "Eval Model Test loss: 0.32600439836581546\n",
      "First Out Loss: 0.30427668740351993\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.374s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 175\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005875612875180585\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005880836293929153\n",
      "Eval Model Test loss: 0.3244503256347444\n",
      "First Out Loss: 0.3025146433048778\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.229s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 176\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005874942378362729\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005878830639024575\n",
      "Eval Model Test loss: 0.32596614211797714\n",
      "First Out Loss: 0.3042934031950103\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.304s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 177\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005873975449330395\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005877703764579362\n",
      "Eval Model Test loss: 0.32552247328890693\n",
      "First Out Loss: 0.30417074428664315\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.350s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 178\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005873704866860949\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005876297946088016\n",
      "Eval Model Test loss: 0.3248206501205762\n",
      "First Out Loss: 0.3033289876249101\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.354s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 179\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005872392622266142\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00587616551719192\n",
      "Eval Model Test loss: 0.3243509241276317\n",
      "First Out Loss: 0.3028089677294095\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.216s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 180\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005872141819314233\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005877046716502971\n",
      "Eval Model Test loss: 0.32377199911408955\n",
      "First Out Loss: 0.30223296334346134\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.403s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 181\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005871179474828144\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005875760353066855\n",
      "Eval Model Test loss: 0.3236837436755498\n",
      "First Out Loss: 0.30211036735110813\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.357s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 182\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005870689410671946\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005875867636253436\n",
      "Eval Model Test loss: 0.32448623991674846\n",
      "First Out Loss: 0.3030543699860573\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.369s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 183\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0058685607842302746\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00587332996332811\n",
      "Eval Model Test loss: 0.3256004957689179\n",
      "First Out Loss: 0.30432156721750897\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.300s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 184\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005869730602994207\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005874561973743969\n",
      "Eval Model Test loss: 0.325988775326146\n",
      "First Out Loss: 0.3043655943539407\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.402s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 185\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005868703997250469\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0058731187341941726\n",
      "Eval Model Test loss: 0.3229958613713582\n",
      "First Out Loss: 0.30138466755549115\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.304s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 186\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005867456080436352\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005872063675067491\n",
      "Eval Model Test loss: 0.3243247527215216\n",
      "First Out Loss: 0.3030348593990008\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.367s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 187\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005866760521062783\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005871494986220366\n",
      "Eval Model Test loss: 0.32513797365956837\n",
      "First Out Loss: 0.3040327818857299\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.250s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 188\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005867748316155658\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0058693224952245755\n",
      "Eval Model Test loss: 0.3238173888789283\n",
      "First Out Loss: 0.3027665871712897\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.337s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 189\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00586500797154648\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005867764599517816\n",
      "Eval Model Test loss: 0.3240799986653858\n",
      "First Out Loss: 0.30291839440663654\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.396s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 190\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005865269434815716\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005867510736506019\n",
      "Eval Model Test loss: 0.32487672567367554\n",
      "First Out Loss: 0.30363443079921937\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.381s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 191\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005864833065840814\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005865321054847704\n",
      "Eval Model Test loss: 0.32394510755936307\n",
      "First Out Loss: 0.3029778798421224\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.256s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 192\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005864625874285896\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0058647282680289615\n",
      "Eval Model Test loss: 0.3257117205195957\n",
      "First Out Loss: 0.30487802459133995\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.372s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 193\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00586291477416775\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005865510203875601\n",
      "Eval Model Test loss: 0.32625516917970443\n",
      "First Out Loss: 0.30525771776835126\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.340s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 194\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0058627650751510545\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005864034937177267\n",
      "Eval Model Test loss: 0.32539383073647815\n",
      "First Out Loss: 0.304240469303396\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.380s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 195\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005861343427871664\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005860699547661675\n",
      "Eval Model Test loss: 0.3243742775585916\n",
      "First Out Loss: 0.3033643787105878\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.252s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 196\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0058615762973204255\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005861582661358018\n",
      "Eval Model Test loss: 0.3254694408840603\n",
      "First Out Loss: 0.304669600394037\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.436s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 197\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005860247089350153\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005860397902627786\n",
      "Eval Model Test loss: 0.32522741787963444\n",
      "First Out Loss: 0.3042132266693645\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.404s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 198\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005859861765722079\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005860149705161651\n",
      "Eval Model Test loss: 0.3249196948276626\n",
      "First Out Loss: 0.3042477410700586\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.460s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 199\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0058592491162319975\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0058568092968521845\n",
      "Eval Model Test loss: 0.32598809980683857\n",
      "First Out Loss: 0.3051057863566611\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.259s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 200\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.005859655893540808\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.005859968575855924\n",
      "Eval Model Test loss: 0.3251669738027785\n",
      "First Out Loss: 0.30439766496419907\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.369s\n"
     ]
    }
   ],
   "source": [
    "trainer.train(n_epochs=n_epochs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "emb_model_path = f'{model_path}emb'\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "model = ForcastingQuantInferenceWrapper(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "torch.save(eval_model, emb_model_path)\n",
    "torch.save(model, model_path)\n",
    "torch.cuda.empty_cache()\n",
    "del model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
