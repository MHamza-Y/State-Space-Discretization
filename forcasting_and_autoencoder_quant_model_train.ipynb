{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from state_quantization.dataset import load_dataset\n",
    "from state_quantization.dataset import DynamicsModelDataset\n",
    "from state_quantization.forcasting_models import LSTMForcasting\n",
    "from state_quantization.quantization_models import DiscAutoEncoder\n",
    "from state_quantization.forcasting_quantization_models import ForcastingQuant, EmbeddedAEForcastingQuant, ForcastingQuantInferenceWrapper\n",
    "from state_quantization.trainer import ForcastingQuantTrainer\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from state_quantization.train import train_model, test_step\n",
    "from state_quantization.eval import eval_model, compare_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "print(f\"Using Device: {device}\")\n",
    "torch.backends.cudnn.benchmark = True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clipping y\n",
      "torch.Size([672000, 39, 6])\n",
      "torch.Size([672000, 10, 2])\n",
      "torch.Size([288000, 39, 6])\n",
      "torch.Size([288000, 10, 2])\n",
      "{'batch_size': 8000, 'shuffle': True, 'num_workers': 0, 'drop_last': True, 'pin_memory': True}\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[ 1.6792, -0.8336],\n        [ 1.6763, -0.8298],\n        [ 1.4791, -0.8124],\n        [ 1.6555, -0.7719],\n        [ 1.6520, -0.7387],\n        [ 1.4680, -0.7181],\n        [ 1.4315, -0.7320],\n        [ 1.5838, -0.7297],\n        [ 1.5961, -0.7246],\n        [ 1.6831, -0.7258]])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_input_key = 'merged_input'\n",
    "dataset_output_key = 'merged_output'\n",
    "dataset_file_path = 'tmp/ib-out/ib-samples-la.npy'\n",
    "normalized_data_params_save_path = 'state_quantization/NormalizeInputConfigs.pkl'\n",
    "dataset_device = 'cpu'\n",
    "y_indexes = [4, 6]\n",
    "\n",
    "train_dataset, val_dataset = load_dataset(file_path=dataset_file_path, input_key=dataset_input_key,\n",
    "                                          output_key=dataset_output_key, dataset_class=DynamicsModelDataset,\n",
    "                                          normalize=True, device=dataset_device, y_clip_range=y_indexes,\n",
    "                                          normalized_data_params_save_path=normalized_data_params_save_path)\n",
    "\n",
    "batch_size = 8000\n",
    "params = {'batch_size': batch_size,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 0,\n",
    "          'drop_last': True,\n",
    "          'pin_memory': not train_dataset.x.is_cuda}\n",
    "print(params)\n",
    "train_loader = DataLoader(train_dataset, **params)\n",
    "val_loader = DataLoader(val_dataset, **params)\n",
    "train_dataset.y[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out Size:2\n",
      "LSTM Layers\n",
      "ModuleList(\n",
      "  (0): LSTMCell(6, 20)\n",
      ")\n",
      "LSTM Dropout Layers\n",
      "ModuleList()\n",
      "Fully Connected Layers\n",
      "Sequential(\n",
      "  (0): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (1): GELU(approximate=none)\n",
      "  (2): Dropout(p=0.1, inplace=False)\n",
      "  (3): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (4): GELU(approximate=none)\n",
      "  (5): Dropout(p=0.1, inplace=False)\n",
      "  (6): Linear(in_features=20, out_features=2, bias=True)\n",
      ")\n",
      "Encoder Layers\n",
      "Sequential(\n",
      "  (0): Linear(in_features=40, out_features=40, bias=True)\n",
      "  (1): GELU(approximate=none)\n",
      "  (2): Dropout(p=0.0, inplace=False)\n",
      "  (3): Linear(in_features=40, out_features=20, bias=True)\n",
      "  (4): GELU(approximate=none)\n",
      "  (5): Dropout(p=0.0, inplace=False)\n",
      "  (6): Linear(in_features=20, out_features=10, bias=True)\n",
      "  (7): GELU(approximate=none)\n",
      "  (8): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "Bottleneck Layers\n",
      "Sequential(\n",
      "  (0): Linear(in_features=10, out_features=20, bias=True)\n",
      "  (1): Tanh()\n",
      "  (2): StraightThroughEstimator()\n",
      ")\n",
      "Decoded Layers\n",
      "Sequential(\n",
      "  (0): Linear(in_features=20, out_features=10, bias=True)\n",
      "  (1): GELU(approximate=none)\n",
      "  (2): Dropout(p=0.0, inplace=False)\n",
      "  (3): Linear(in_features=10, out_features=20, bias=True)\n",
      "  (4): GELU(approximate=none)\n",
      "  (5): Dropout(p=0.0, inplace=False)\n",
      "  (6): Linear(in_features=20, out_features=40, bias=True)\n",
      "  (7): GELU(approximate=none)\n",
      "  (8): Dropout(p=0.0, inplace=False)\n",
      "  (9): Linear(in_features=40, out_features=40, bias=True)\n",
      ")\n",
      "LSTM Layers\n",
      "ModuleList(\n",
      "  (0): LSTMCell(6, 20)\n",
      ")\n",
      "LSTM Dropout Layers\n",
      "ModuleList()\n",
      "Fully Connected Layers\n",
      "Sequential(\n",
      "  (0): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (1): GELU(approximate=none)\n",
      "  (2): Dropout(p=0.1, inplace=False)\n",
      "  (3): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (4): GELU(approximate=none)\n",
      "  (5): Dropout(p=0.1, inplace=False)\n",
      "  (6): Linear(in_features=20, out_features=2, bias=True)\n",
      ")\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "model_path = 'tmp/state_quantization/model_aeq_new'\n",
    "untrained_model_path = 'tmp/state_quantization/untrained_model_aeq'\n",
    "num_of_features = train_dataset.get_features_size()\n",
    "seq_len = train_dataset.get_seq_len()\n",
    "hidden_size = 20\n",
    "out_size = train_dataset.get_output_feature_size()\n",
    "print(f'Out Size:{out_size}')\n",
    "look_ahead = train_dataset.get_look_ahead_size()\n",
    "n_layers = 1\n",
    "dropout = 0.1\n",
    "\n",
    "forcasting_model = LSTMForcasting(features=num_of_features, hidden_size=hidden_size, out_size=out_size, seq_len=seq_len,\n",
    "                                  look_ahead=look_ahead, dropout=dropout, n_layers=n_layers)\n",
    "\n",
    "disc_autoencoder_input_size = hidden_size * 2\n",
    "bottleneck_size = 20\n",
    "ae_dropout = 0.0\n",
    "disc_autoencoder = DiscAutoEncoder(input_size=disc_autoencoder_input_size, bottleneck_size=bottleneck_size,\n",
    "                                   dropout=ae_dropout)\n",
    "\n",
    "model = ForcastingQuant(forcasting_model=forcasting_model, autoencoder_quant_model=disc_autoencoder).to(device=device)\n",
    "eval_model = EmbeddedAEForcastingQuant(features=num_of_features, hidden_size=hidden_size, out_size=out_size, seq_len=seq_len,\n",
    "                                  look_ahead=look_ahead, dropout=dropout, n_layers=n_layers, autoencoder_quant_model=disc_autoencoder).to(device=device)\n",
    "torch.save(ForcastingQuantInferenceWrapper(model), untrained_model_path)\n",
    "load_to_gpu = model.is_cuda() and not train_dataset.x.is_cuda\n",
    "print(load_to_gpu)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Trainer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "gamma = 0.1\n",
    "\n",
    "forecasting_learning_rate = 1e-3\n",
    "autoencoder_learning_rate = 1e-3\n",
    "\n",
    "forecasting_lr_milestones = [35]\n",
    "autoencoder_lr_milestones = [100, 150]\n",
    "forecasting_optimizer = torch.optim.Adam(model.forcasting_model.parameters(),\n",
    "                                         lr=forecasting_learning_rate)\n",
    "autoencoder_optimizer = torch.optim.Adam(model.autoencoder_quant_model.parameters(),\n",
    "                                         lr=autoencoder_learning_rate)\n",
    "forecasting_lr_scheduler = MultiStepLR(forecasting_optimizer, milestones=forecasting_lr_milestones, gamma=gamma)\n",
    "autoencoder_lr_scheduler = MultiStepLR(autoencoder_optimizer, milestones=autoencoder_lr_milestones, gamma=gamma)\n",
    "n_epochs = 200\n",
    "\n",
    "trainer = ForcastingQuantTrainer(forcasting_quant_model=model, train_loader=train_loader, test_loader=val_loader,\n",
    "                                 load_to_gpu=load_to_gpu, forecasting_optimizer=forecasting_optimizer,\n",
    "                                 forecasting_lr_scheduler=forecasting_lr_scheduler,\n",
    "                                 autoencoder_lr_scheduler=autoencoder_lr_scheduler,\n",
    "                                 autoencoder_optimizer=autoencoder_optimizer,autoencoder_training_start=50,additional_eval_model=eval_model)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained test\n",
      "--------\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 1.0113959428336885\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 1\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.6881995119509243\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.25023671570751405\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.501s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 2\n",
      "---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamza/PycharmProjects/StateCompression/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "Forcasting Train loss: 0.158347257279924\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.08156348806288508\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.367s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 3\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.10313189961016178\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.06504983268678188\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.524s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 4\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.08750603915680022\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.056390467203325696\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.364s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 5\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.07747894667443775\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.04854913004156616\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.854s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 6\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.07029608672573454\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.04392353921300835\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.849s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 7\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.06530417714800153\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.04062221778763665\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.841s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 8\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.06246095740546783\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03857279506822427\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.483s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 9\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.06071375873649404\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03799794759187433\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.349s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 10\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05913923844872486\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03631509002298117\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.239s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 11\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05800728539803198\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.035306504306693874\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.740s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 12\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.0569707490503788\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03508648928254843\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.329s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 13\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.056094992063229994\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03427198529243469\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.245s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 14\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05534492676988954\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.033499950956967145\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.303s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 15\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05454590867850043\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03307210374623537\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.465s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 16\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05385040398687124\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03258997108787298\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.338s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 17\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.053382745899614836\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03248968089206351\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.442s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 18\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.052682994598788876\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.0325074540451169\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.254s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 19\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.052027576292554535\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03161423384315438\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.291s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 20\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05167919197785003\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.030976709288855393\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.719s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 21\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05121634319602024\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.031130208789060514\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.777s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 22\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05079167172135342\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.030967481951746676\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 10.009s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 23\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05042193155913126\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.030297987525247864\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.361s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 24\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.05009051501041367\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03034362683279647\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.611s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 25\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04973696349632172\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.03009584949662288\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.427s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 26\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04945908145358165\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.029911895799967978\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.485s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 27\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.049219163755575814\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02971274472980036\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.433s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 28\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.048984188497776075\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.029770490454716816\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.343s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 29\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.048650571943393776\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.029274311641024217\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.477s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 30\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04836547667426722\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02926407630244891\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.342s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 31\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.048158383484752404\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.029042100740803614\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.437s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 32\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.0479797309353238\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028949505390806332\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.467s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 33\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04790322779722157\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02887705434113741\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.692s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 34\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04750890160600344\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02939881156716082\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.460s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 35\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.047317552247217724\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028915402220769063\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.421s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 36\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04701583384580556\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028611927862382598\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.373s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 37\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04710498540883973\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02852997664983074\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.399s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 38\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04705907586252406\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028541698689675994\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.408s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 39\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.047065005371613164\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028608209557003446\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.403s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 40\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04704107561459144\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028445951226684783\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.369s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 41\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04698022011490095\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028525347614453897\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.334s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 42\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04695274450239681\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028457427242149908\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.486s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 43\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04701483795153243\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028533732570293877\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.341s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 44\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04689122594538189\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02853321149531338\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.469s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 45\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04689241120857852\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.02849615142784185\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.520s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 46\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04692325337479512\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028530625057303242\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.457s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 47\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04682839058694385\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028554011343253985\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.384s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 48\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.04681056507286571\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028349624170611303\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.538s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 49\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.046825774368785676\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028381369231889646\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.626s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 50\n",
      "---------\n",
      "--------------------------------------\n",
      "Forcasting Train loss: 0.046797456308489756\n",
      "--------------------------------------\n",
      "Forcasting Test loss: 0.028454893061684236\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.630s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 51\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.540598451381638\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.2384693862663375\n",
      "Eval Model Test loss: 1.0236693339215384\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.567s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 52\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.16317811235785484\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.11670557740661833\n",
      "Eval Model Test loss: 1.022812666164504\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.029s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 53\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.09848418964871339\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.08535317124591933\n",
      "Eval Model Test loss: 1.022689441839854\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.679s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 54\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.07509444751555011\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.06349059597899516\n",
      "Eval Model Test loss: 1.024115530980958\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.940s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 55\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.05035386021648135\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.04215782373729679\n",
      "Eval Model Test loss: 1.024682879447937\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.691s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 56\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.04001044131638039\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0381628048295776\n",
      "Eval Model Test loss: 1.0243160476287205\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.590s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 57\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.03704112985481819\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.03585559791988797\n",
      "Eval Model Test loss: 1.0246081335677042\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.842s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 58\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.034677313906805854\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.03139073003290428\n",
      "Eval Model Test loss: 1.0246247715420194\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.370s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 59\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.025677406628217016\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.02200364000681374\n",
      "Eval Model Test loss: 1.0241257184081607\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.460s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 60\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.020432872121177968\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.018976464453670714\n",
      "Eval Model Test loss: 1.0242308908038669\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.524s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 61\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.017940008081495762\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.016956450055456825\n",
      "Eval Model Test loss: 1.0242496016952727\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.715s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 62\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.01623157544859818\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.015553715147284998\n",
      "Eval Model Test loss: 1.024013747771581\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.878s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 63\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.014951246746239207\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.014402311243530776\n",
      "Eval Model Test loss: 1.0243892818689346\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.062s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 64\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.01395025807211087\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.013562297500256035\n",
      "Eval Model Test loss: 1.024430318011178\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.033s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 65\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.013219876891179453\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.012918835143662162\n",
      "Eval Model Test loss: 1.0244719435771306\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.965s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 66\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.01266067762238284\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.01244969769484467\n",
      "Eval Model Test loss: 1.0243839290406969\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.457s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 67\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.012261375718350922\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.012170519446954131\n",
      "Eval Model Test loss: 1.0244778361585405\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.400s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 68\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.012064300167063871\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.012000292099805342\n",
      "Eval Model Test loss: 1.0243455916643143\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.304s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 69\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.011918943319913177\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.011911871610209346\n",
      "Eval Model Test loss: 1.0244066450330946\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.246s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 70\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.011660742296260736\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.011520147039037611\n",
      "Eval Model Test loss: 1.0244615541564093\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.248s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 71\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.011366089495519796\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.011228092971982228\n",
      "Eval Model Test loss: 1.024551898241043\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.342s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 72\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.011100107171971883\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.011029158304962847\n",
      "Eval Model Test loss: 1.024630046553082\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.291s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 73\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.01090340570191897\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.010831114241025515\n",
      "Eval Model Test loss: 1.0244582576884165\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.291s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 74\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.010753000953367777\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.010666669863793585\n",
      "Eval Model Test loss: 1.02466309732861\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.321s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 75\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.010597477389854334\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.010509336677690348\n",
      "Eval Model Test loss: 1.0247114880217447\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.247s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 76\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.010455669236502476\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.010399795965188079\n",
      "Eval Model Test loss: 1.024682492017746\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.204s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 77\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.010344620805145019\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.010278378690903386\n",
      "Eval Model Test loss: 1.0246677332454257\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.213s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 78\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.010239358603333434\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.01015581855446928\n",
      "Eval Model Test loss: 1.0247821791304483\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.353s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 79\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.010129260985801617\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.010077208461653855\n",
      "Eval Model Test loss: 1.024777548180686\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.219s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 80\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.01003920023019115\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.010046517761010263\n",
      "Eval Model Test loss: 1.0246712333626218\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.230s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 81\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009981542393299086\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009954544353402324\n",
      "Eval Model Test loss: 1.0247121188375685\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.299s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 82\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009944697420689323\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009931041341688897\n",
      "Eval Model Test loss: 1.024551174706883\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.194s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 83\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009910474376132091\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009876483120024204\n",
      "Eval Model Test loss: 1.0245664003822539\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.758s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 84\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009874098823361453\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009865424440552792\n",
      "Eval Model Test loss: 1.0245517078373167\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.833s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 85\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009861578632678305\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009870199409003058\n",
      "Eval Model Test loss: 1.0245993468496535\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.536s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 86\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009859788342423383\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009857967288957702\n",
      "Eval Model Test loss: 1.0247447573476367\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.712s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 87\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009838363188984138\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009825170221221115\n",
      "Eval Model Test loss: 1.024868408838908\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.303s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 88\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009796335450595333\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009799063774860568\n",
      "Eval Model Test loss: 1.02484197417895\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.030s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 89\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00977539796648281\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009749378827917907\n",
      "Eval Model Test loss: 1.0249732981125514\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.186s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 90\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009730372821823471\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009721280644751258\n",
      "Eval Model Test loss: 1.0250798910856247\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.971s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 91\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009705838447968875\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009707589426802265\n",
      "Eval Model Test loss: 1.0250696904129453\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.769s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 92\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009675213989491263\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009662467365463575\n",
      "Eval Model Test loss: 1.0251565360360675\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.726s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 93\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009643815701738709\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009673355483553477\n",
      "Eval Model Test loss: 1.0251360022359424\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 9.402s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 94\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009622590638519753\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009601635961896844\n",
      "Eval Model Test loss: 1.0251642217238743\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.586s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 95\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009595268095533053\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00959889150948988\n",
      "Eval Model Test loss: 1.025152188208368\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.342s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 96\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00957704258949629\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00957485500516163\n",
      "Eval Model Test loss: 1.025195610192087\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.312s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 97\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00956309801854548\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00954912007889814\n",
      "Eval Model Test loss: 1.0252413170205221\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.241s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 98\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009548675457370422\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009558232992680537\n",
      "Eval Model Test loss: 1.025164556172159\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.261s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 99\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009543512160668061\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009608028818749718\n",
      "Eval Model Test loss: 1.025169829527537\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.317s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 100\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009520400980753558\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009490909132485589\n",
      "Eval Model Test loss: 1.0251051088174183\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.001]\n",
      "Epoch time: epoch_time = 8.289s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 101\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009460020400140257\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009449823474925425\n",
      "Eval Model Test loss: 1.0250758594936795\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.326s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 102\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009448749445644873\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009443592668200532\n",
      "Eval Model Test loss: 1.0250720232725143\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 9.348s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 103\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009444667558584894\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009439246082264516\n",
      "Eval Model Test loss: 1.0250743296411302\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 9.118s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 104\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009432184698414944\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009429132074324621\n",
      "Eval Model Test loss: 1.0250707351499133\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 9.232s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 105\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009422389568672293\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009413957725175552\n",
      "Eval Model Test loss: 1.0250589284631941\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.926s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 106\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009411752401363282\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009406430232856009\n",
      "Eval Model Test loss: 1.0250521931383345\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.963s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 107\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009398848827307424\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009391827560547326\n",
      "Eval Model Test loss: 1.0250680910216436\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 9.122s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 108\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009386555779547919\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009377338975254033\n",
      "Eval Model Test loss: 1.025062620639801\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.282s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 109\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00937104429162684\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009365687043302588\n",
      "Eval Model Test loss: 1.0250549630986319\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.415s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 110\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00935789585734407\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009355876310211089\n",
      "Eval Model Test loss: 1.025055804186397\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.247s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 111\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009343023179098964\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009336756956246164\n",
      "Eval Model Test loss: 1.0250591552919812\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.472s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 112\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009321096153663737\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009316582905335559\n",
      "Eval Model Test loss: 1.0250586022933323\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 9.196s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 113\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009303980695438526\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009298241645511653\n",
      "Eval Model Test loss: 1.0250488138861127\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 9.419s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 114\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.0092840145918585\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00928522059176531\n",
      "Eval Model Test loss: 1.0250346776511934\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.940s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 115\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009264941549017316\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009254388511180878\n",
      "Eval Model Test loss: 1.0250451730357275\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.874s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 116\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00924008376231151\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009234644550209245\n",
      "Eval Model Test loss: 1.0250433550940619\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.987s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 117\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009216318405898554\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009209436364471912\n",
      "Eval Model Test loss: 1.0250504199001524\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.894s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 118\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00919444837962233\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009187872625059552\n",
      "Eval Model Test loss: 1.0250556435849931\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.949s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 119\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009169400647459995\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009162013807023564\n",
      "Eval Model Test loss: 1.0250554498698976\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.914s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 120\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009142640967010743\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009135266377901038\n",
      "Eval Model Test loss: 1.0250662648015552\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.886s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 121\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009114437603524752\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009104642163341245\n",
      "Eval Model Test loss: 1.0250649932358\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.859s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 122\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009082409896932188\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009074997363819016\n",
      "Eval Model Test loss: 1.0250761128134198\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.858s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 123\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009052971777107035\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009048408518234888\n",
      "Eval Model Test loss: 1.025084740585751\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.954s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 124\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.009025004869770436\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009018520126119256\n",
      "Eval Model Test loss: 1.02509224249257\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.988s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 125\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008995669239777185\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.009005856881332066\n",
      "Eval Model Test loss: 1.0251109351714451\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.690s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 126\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008971583796665072\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008979073725640774\n",
      "Eval Model Test loss: 1.0251102099816005\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.790s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 127\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008944335925791944\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008939008228480816\n",
      "Eval Model Test loss: 1.0251119401719835\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 9.105s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 128\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008918497722507232\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008921348231120242\n",
      "Eval Model Test loss: 1.0251095874441996\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 9.098s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 129\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008888656816755732\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008902544880078899\n",
      "Eval Model Test loss: 1.0251232352521684\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 9.332s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 130\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008868871855416469\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008868549277798997\n",
      "Eval Model Test loss: 1.0251161373323865\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 9.229s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 131\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008847299187133709\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008840734397785531\n",
      "Eval Model Test loss: 1.0251138657331467\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 9.773s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 132\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008821520355663129\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008821230821518434\n",
      "Eval Model Test loss: 1.0251155710882611\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 9.996s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 133\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008800016372420248\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008797298340747753\n",
      "Eval Model Test loss: 1.0251204089985952\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 9.397s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 134\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008778501734403628\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008778340933430526\n",
      "Eval Model Test loss: 1.0251407374938328\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.899s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 135\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008761429959642035\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00877084476976759\n",
      "Eval Model Test loss: 1.0251422226428986\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.887s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 136\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00874381420379948\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008736541287766563\n",
      "Eval Model Test loss: 1.0251370734638638\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.980s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 137\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008719419073756961\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00873168591513402\n",
      "Eval Model Test loss: 1.025127285056644\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 9.280s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 138\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00870528400299095\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008712692263846597\n",
      "Eval Model Test loss: 1.0251439114411671\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.970s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 139\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008692052337296662\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008701881626620889\n",
      "Eval Model Test loss: 1.0251307206021414\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.296s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 140\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008676204486705717\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008686163126387529\n",
      "Eval Model Test loss: 1.0251272718111675\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.245s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 141\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008659489264356949\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00867661021442877\n",
      "Eval Model Test loss: 1.0251298480563693\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.328s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 142\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00864909870904826\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008669311180710793\n",
      "Eval Model Test loss: 1.025143908129798\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.239s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 143\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008633957976209266\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008654569560247991\n",
      "Eval Model Test loss: 1.0251339591211743\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.277s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 144\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00861949504663547\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008644339318076769\n",
      "Eval Model Test loss: 1.0251550989018545\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.283s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 145\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008603601705371625\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008623447760732638\n",
      "Eval Model Test loss: 1.025128851334254\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.303s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 146\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008594686498067208\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008614930375996564\n",
      "Eval Model Test loss: 1.0251343349615734\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.234s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 147\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008584166477833475\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008606567435587445\n",
      "Eval Model Test loss: 1.0251230200131733\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.212s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 148\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008574576638195486\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008597783744335175\n",
      "Eval Model Test loss: 1.0251293331384659\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.232s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 149\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008564903644756192\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008583836878339449\n",
      "Eval Model Test loss: 1.0251086387369368\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.285s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 150\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008553494544078907\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008573871985491779\n",
      "Eval Model Test loss: 1.0251121371984482\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [0.0001]\n",
      "Epoch time: epoch_time = 8.254s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 151\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008543786437561115\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008578194615741571\n",
      "Eval Model Test loss: 1.0250877059168286\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.257s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 152\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008542496300790282\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008573929158349832\n",
      "Eval Model Test loss: 1.0250910520553589\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.296s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 153\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008539810122567274\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008573173959222104\n",
      "Eval Model Test loss: 1.0250954611433878\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.186s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 154\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00854074084643452\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008571084666376313\n",
      "Eval Model Test loss: 1.025089078479343\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.146s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 155\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008539254777133465\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008571872901585367\n",
      "Eval Model Test loss: 1.0250914129945967\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.169s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 156\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008537584294875463\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008571231892953316\n",
      "Eval Model Test loss: 1.0250891115930345\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.371s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 157\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008536835910663718\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008570307425947653\n",
      "Eval Model Test loss: 1.025088123149342\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.256s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 158\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008535904443955846\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008567184468524324\n",
      "Eval Model Test loss: 1.0250828547610178\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.219s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 159\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008535054601019337\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008569094016113214\n",
      "Eval Model Test loss: 1.0250888350937102\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.217s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 160\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008534602676740005\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00856699597918325\n",
      "Eval Model Test loss: 1.0250865552160475\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.215s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 161\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008533540913569075\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008567674214848213\n",
      "Eval Model Test loss: 1.025082442495558\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.190s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 162\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008532887701654718\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008566626890872916\n",
      "Eval Model Test loss: 1.0250834822654724\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.188s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 163\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008531923638656735\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008562957376448644\n",
      "Eval Model Test loss: 1.0250832935174305\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.228s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 164\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00853082215014313\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008564688342933854\n",
      "Eval Model Test loss: 1.0250815086894565\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.202s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 165\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008530541478345791\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008563629377426373\n",
      "Eval Model Test loss: 1.025083151128557\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.274s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 166\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008528874366588536\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00856447530289491\n",
      "Eval Model Test loss: 1.0250788811180327\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.280s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 167\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008529739787003823\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00855982991763287\n",
      "Eval Model Test loss: 1.0250830550988514\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.327s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 168\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008526308051798315\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008561656758603122\n",
      "Eval Model Test loss: 1.0250823299090068\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.296s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 169\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008527858759320918\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008559531583968136\n",
      "Eval Model Test loss: 1.0250816427999072\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.305s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 170\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008524940659602484\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0085611200839695\n",
      "Eval Model Test loss: 1.025076127714581\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.527s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 171\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008524853048757428\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00855917286955648\n",
      "Eval Model Test loss: 1.0250804391172197\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 9.006s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 172\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008523667951868404\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008557134721842077\n",
      "Eval Model Test loss: 1.025079490409957\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 9.395s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 173\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00852432751673318\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008558162617393665\n",
      "Eval Model Test loss: 1.0250785135560565\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.925s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 174\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00852286864426874\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00855341548514035\n",
      "Eval Model Test loss: 1.0250717732641432\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 9.789s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 175\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008521343603552807\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008558066225507192\n",
      "Eval Model Test loss: 1.0250673393408458\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 9.448s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 176\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008520568587950297\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008552866884403758\n",
      "Eval Model Test loss: 1.0250718080335193\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.926s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 177\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008520294102795777\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.0085508872806612\n",
      "Eval Model Test loss: 1.0250733478201761\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 9.402s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 178\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008518527461481946\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00855276032557918\n",
      "Eval Model Test loss: 1.0250703129503462\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.693s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 179\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008518857260545095\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00855435542244878\n",
      "Eval Model Test loss: 1.0250678658485413\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.865s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 180\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008516308940237477\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008550343440017767\n",
      "Eval Model Test loss: 1.0250702914264467\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.643s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 181\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008514966970930496\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008550434114618434\n",
      "Eval Model Test loss: 1.0250652614567015\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.535s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 182\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008515553360450127\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008552884993453821\n",
      "Eval Model Test loss: 1.0250644468598895\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.469s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 183\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008511384217334645\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008551294604937235\n",
      "Eval Model Test loss: 1.0250664585166507\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.511s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 184\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008511833547215377\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008547054914136728\n",
      "Eval Model Test loss: 1.0250679237975016\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.450s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 185\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008509387472821843\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008550225343141291\n",
      "Eval Model Test loss: 1.0250658227337732\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.520s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 186\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008509722915256307\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00854558401948048\n",
      "Eval Model Test loss: 1.0250687218374677\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.502s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 187\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.00850825131471668\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008543707301012345\n",
      "Eval Model Test loss: 1.0250661571820576\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.550s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 188\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008507792039641313\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008545675056262149\n",
      "Eval Model Test loss: 1.025062296125624\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.902s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 189\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008506935477877656\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008546124626364972\n",
      "Eval Model Test loss: 1.0250647101137373\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 9.019s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 190\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008506365242369827\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008539124391973019\n",
      "Eval Model Test loss: 1.025059151980612\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 9.154s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 191\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008503255434334278\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008538961643353105\n",
      "Eval Model Test loss: 1.0250649783346388\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 9.015s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 192\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008504177233026851\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008537707384675741\n",
      "Eval Model Test loss: 1.0250598639249802\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 9.399s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 193\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008501873872730704\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008537847755683793\n",
      "Eval Model Test loss: 1.0250572777456708\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.862s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 194\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008502725578312362\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.00853480830685132\n",
      "Eval Model Test loss: 1.0250624401701822\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.830s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 195\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008500875228838552\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008532525945661796\n",
      "Eval Model Test loss: 1.0250615080197651\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.808s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 196\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008498367931072911\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008530910514915982\n",
      "Eval Model Test loss: 1.0250568505790498\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.847s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 197\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008496334998025781\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008534302624563376\n",
      "Eval Model Test loss: 1.025063607427809\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 9.196s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 198\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008495470431322852\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008531713547805945\n",
      "Eval Model Test loss: 1.0250521550575893\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 9.034s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 199\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008495413653907321\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008527830243110657\n",
      "Eval Model Test loss: 1.02505271964603\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.815s\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Epoch 200\n",
      "---------\n",
      "--------------------------------------\n",
      "Autoencoder Train loss: 0.008492314833260718\n",
      "--------------------------------------\n",
      "Autoencoder Test loss: 0.008526998960102597\n",
      "Eval Model Test loss: 1.025057993001408\n",
      "--------------------------------------\n",
      "Forecasting lr: [0.0001]\n",
      "Autoencoder lr: [1e-05]\n",
      "Epoch time: epoch_time = 8.704s\n"
     ]
    }
   ],
   "source": [
    "trainer.train(n_epochs=n_epochs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "model = ForcastingQuantInferenceWrapper(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "torch.save(model, model_path)\n",
    "torch.cuda.empty_cache()\n",
    "del model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
